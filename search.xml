<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>如何阅读一本书</title>
      <link href="/2026/02/08/ru_he_yue_du_yi_ben_shu/"/>
      <url>/2026/02/08/ru_he_yue_du_yi_ben_shu/</url>
      
        <content type="html"><![CDATA[<h2 id="核心观点总结（AI总结）">核心观点总结（AI总结）</h2><h3 id="一、阅读的本质">一、阅读的本质</h3><p>阅读是<strong>主动的学习过程</strong>，是与"缺席的老师"对话。它要求读者运用观察、记忆、想象力和分析能力，通过自我发现来获取知识。阅读的艺术包含了所有非辅助型自我发现学习的技巧。</p><hr><h3 id="二、阅读的四个层次">二、阅读的四个层次</h3><table><thead><tr><th style="text-align:left">层次</th><th style="text-align:left">核心特征</th><th style="text-align:left">关键问题</th></tr></thead><tbody><tr><td style="text-align:left"><strong>基础阅读</strong></td><td style="text-align:left">摆脱文盲状态，理解句子含义</td><td style="text-align:left">“这个句子在说什么？”</td></tr><tr><td style="text-align:left"><strong>检视阅读</strong></td><td style="text-align:left">有限时间内抓重点，系统略读</td><td style="text-align:left">“这本书在谈什么？”</td></tr><tr><td style="text-align:left"><strong>分析阅读</strong></td><td style="text-align:left">全盘、完整、优质的阅读，咀嚼消化</td><td style="text-align:left">提出系统性问题，深入理解</td></tr><tr><td style="text-align:left"><strong>主题阅读</strong></td><td style="text-align:left">读多本书，建立共识，架构新主题</td><td style="text-align:left">最主动、最花力气的阅读</td></tr></tbody></table><hr><h3 id="三、检视阅读的具体方法">三、检视阅读的具体方法</h3><p><strong>第一阶段：有系统的略读</strong></p><ol><li>看书名、副标题、序言，快速归类</li><li>研究目录页，理解基本架构</li><li>检阅索引，评估议题范围</li><li>读出版者介绍（如有）</li><li>挑关键篇章读摘要</li><li>东翻翻西翻翻，留意结尾两三页</li></ol><p><strong>第二阶段：粗浅的阅读</strong></p><ul><li>头一次面对难读的书，<strong>从头到尾先读完一遍</strong>，不懂的地方不停下来查询</li><li>只注意能理解的部分，集中精神，将全书读完</li></ul><hr><h3 id="四、主动阅读的核心：四个基本问题">四、主动阅读的核心：四个基本问题</h3><ol><li><strong>整体来说，这本书到底在谈些什么？</strong>（主题与结构）</li><li><strong>作者细部说了什么，怎么说的？</strong>（主要想法与论点）</li><li><strong>这本书说得有道理吗？</strong>（批判性思考）</li><li><strong>这本书跟你有什么关系？</strong>（实际应用与启发）</li></ol><hr><h3 id="五、分析阅读的三阶段（11个规则）">五、分析阅读的三阶段（11个规则）</h3><p><strong>第一阶段：找出一本书在谈什么</strong></p><ol><li>依照书的种类与主题分类</li><li>用最简短的文字说明整本书内容</li><li>列出全书大纲及各部分纲要</li><li>确定作者想要解决的问题</li></ol><p><strong>第二阶段：诠释一本书的内容</strong></p><ol start="5"><li>诠释作者关键字，达成共识</li><li>从关键句中抓出主旨</li><li>找出论述，重新架构</li><li>确定作者已解决和未解决的问题</li></ol><p><strong>第三阶段：评论一本书</strong></p><ol start="9"><li><strong>先完整了解，不轻易批评</strong>（"我懂了"之前不说同意/不同意）</li><li><strong>理性表达，不争强好胜</strong></li><li><strong>区分知识与个人观点</strong>，找出理论基础</li></ol><hr><h3 id="六、主题阅读的五个步骤">六、主题阅读的五个步骤</h3><ol><li><strong>找到相关章节</strong>：检视阅读所有书籍，找出与主题最相关的部分</li><li><strong>带引作者与你达成共识</strong>：建立中立词汇，翻译不同作者的语言</li><li><strong>厘清问题</strong>：建立一组不偏不倚的主旨问题</li><li><strong>界定议题</strong>：找出不同作者间的争议点</li><li><strong>分析讨论</strong>：按顺序排列问题和议题，保持客观立场</li></ol><hr><h3 id="七、阅读不同读物的原则">七、阅读不同读物的原则</h3><ul><li><strong>实用性书籍</strong>：明确作者目的和方法，但书不能解决实际问题，只能靠行动</li><li><strong>想象文学</strong>：不要抗拒想象，不要找共识、主旨或论述</li><li><strong>历史书</strong>：了解史实背后的理论，关注普遍性</li><li><strong>科学/数学</strong>：掌握基本概念，面对数学问题</li><li><strong>哲学/社会科学</strong>：厘清思绪，注意容易处与困难处</li></ul><hr><h3 id="八、好书与阅读的成长价值">八、好书与阅读的成长价值</h3><p><strong>书的金字塔理论</strong>：</p><ul><li>99%的书只需检视阅读，不值得分析阅读</li><li>少数好书值得分析阅读，能增进技巧和理解</li><li>极少数<strong>伟大的书</strong>（不到100种）可以与你一起成长，每次重读都有新收获</li></ul><p><strong>阅读的最终目的</strong>：好的阅读不只是获取信息或娱乐，而是帮助心智保持活力与成长，让人成为更有智慧的智者，而非只是更有知识的人。</p><hr><h3 id="九、关键金句">九、关键金句</h3><blockquote><p>“阅读就是学习：指导型的学习，以及自我发现型的学习之间的差异。”</p></blockquote><blockquote><p>“阅读是跟一位缺席的老师学习。”</p></blockquote><blockquote><p>“分析阅读就是要咀嚼与消化一本书。”</p></blockquote><blockquote><p>“主题阅读是最主动、也最花力气的一种阅读。”</p></blockquote><blockquote><p>“如果你的阅读目的是想变成一个更好的阅读者，你就不能摸到任何书或文章都读。”</p></blockquote><blockquote><p>“一本好书能教你了解这个世界以及你自己。你不只更懂得如何读得更好，还更懂得生命。”</p></blockquote><h2 id="读书笔记">读书笔记</h2><h3 id="阅读就是学习：指导型的学习，以及自我发现型的学习之间的差异">阅读就是学习：指导型的学习，以及自我发现型的学习之间的差异</h3><p><strong>思考</strong>只是<strong>主动阅读</strong>的一部分。一个人还必须运用他的<strong>感觉与想象力</strong>。一个人必须观察，记忆，在看不到的地方<strong>运用想象力</strong>。</p><p>阅读的艺术包括了所有非辅助型自我发现学习的技巧：<strong>敏锐的观察、灵敏可靠的记忆、想象的空间</strong>，再者当然就是训练有素的<strong>分析、省思能力</strong>。</p><p>阅读也就<strong>是一种发现</strong>。</p><h3 id="老师的出席与缺席">老师的出席与缺席</h3><p>阅读是跟一位缺席的老师学习。</p><p>如果你<strong>问一本书一个问题</strong>，你就必须<strong>自己回答这个问题</strong>。在这样的情况下，这本书就跟自然或世界一样。当你提出问题时，<strong>只有等你自己作了思考与分析之后，才会在书本上找到答案</strong>。</p><p>如果一本书就是你的老师的话，你就得<strong>一切靠自己了</strong>。</p><p>我们这些已经不在学校的人来说，当我们试着要读一本既非主修也非选修的书籍时，也就是我们的成人教育要完全依赖书籍本身的时候，我们就<strong>不能再有老师的帮助</strong>了。因此，如果我们打算继续学习与发现，我们就要<strong>懂得如何让书本来教导我们</strong>。</p><h3 id="基础阅读（初级阅读、基本阅读或初步阅读）">基础阅读（初级阅读、基本阅读或初步阅读）</h3><p>在熟练这个层次的过程中，一个人可以学习到阅读的基本艺术，接受基础的阅读训练，获得初步的阅读技巧。这个阅读层次的学习通常是在小学时完成的。在这个层次的阅读中，要问读者的问题是：“<strong>这个句子在说什么？</strong>”</p><h3 id="检视阅读（略读或预读）">检视阅读（略读或预读）</h3><p><strong>强调时间</strong>。在这个阅读层次，学生必须在规定的时间内完成一项阅读的功课。譬如他可能要用十五分钟读完一本书，或是同样时间内念完两倍厚的书。就是<strong>在一定的时间之内，抓出一本书的重点——通常是很短</strong>，而且总是（就定义上说）过短，很难掌握一本书所有重点。在这个层次的阅读上，你的目标是<strong>从表面去观察这本书，学习到光是书的表象所教给你的一切</strong>。在这个层次要问的典型问题就是：“<strong>这本书在谈什么？</strong>”还有些类似的问题是：“<strong>这本书的架构如何？</strong>”或是：“<strong>这本书包哪些部分？</strong>”</p><p>用检视阅读读完一本书之后，无论你用了多短的时间，你都该回答得出这样的问题：“这是哪一类的书——小说、历史，还是科学论文？”</p><h3 id="分析阅读">分析阅读</h3><p><strong>要更复杂，更系统化</strong>。随内文难读的程度有所不同，读者在使用这种阅读法的时候，<strong>多少会相当吃力</strong>。</p><p>分析阅读就是<strong>全盘的阅读、完整的阅读</strong>，或是说优质的阅读——你能做到的最好的阅读方式。如果说检视阅读是在有限的时间内，最好也最完整的阅读，那么<strong>分析阅读就是在无限的时间里，最好也最完整的阅读</strong>。</p><p>一个分析型的阅读者一定会对自己所读的东西<strong>提出许多有系统的问题</strong>。<strong>分析阅读永远是一种专注的活动</strong>。在这个层次的阅读中，读者会紧抓住一本书——这个比喻蛮恰当的——<strong>一直要读到这本书成为他自己为止</strong>。<strong>分析阅读就是要咀嚼与消化一本书。</strong></p><p>如果你的目标<strong>只是获得资讯或消遣，就完全没有必要用到分析阅读</strong>。分析阅读就是特别在<strong>追寻理解的</strong>。</p><h3 id="主题阅读（比较阅读）">主题阅读（比较阅读）</h3><p>在做主题阅读时，阅读者会读很多书，而不是一本书，并列举出这些书之间相关之处，<strong>提出一个所有的书都谈到的主题</strong>。主题阅读涉及的远不止此。借助他所阅读的书籍，主题阅读者要能够<strong>架构出一个可能在哪一本书里都没提过的主题分析</strong>。因此，很显然的，<strong>主题阅读是最主动、也最花力气的一种阅读。</strong></p><h3 id="阅读的第一个层次：基础阅读">阅读的第一个层次：基础阅读</h3><p>第一个阶段被称为“阅读准备阶段”。</p><p>第二个阶段，孩子会学习读一些简单的读物。</p><p>第三个阶段的特征是快速建立字汇的能力，所用的方法是从上下文所提供的线索，“揭发”不熟悉的字眼。</p><p>第四个阶段的特征是精练与增进前面所学的技巧。</p><p><strong>基础阅读的四个阶段</strong>：</p><p>第一个阶段——<strong>阅读准备阶段</strong>——相当于学前教育或幼稚园的学习经验。</p><p>第二阶段——<strong>认字</strong>——相当于一年级学生典型的学习经验（尽管相当多正常的孩子在某方面来说并非都很“典型”）。这个阶段的成果是，孩子学会了我们称之为第二阶段的阅读技巧，或是一年级的阅读能力，或最初级的读写能力。</p><p>第三个阶段——<strong>字汇的增长及对课文的运用</strong>——通常是（但非全面性，就算正常孩子也一样）在四年级结束时就学会的方法，这个阶段的成果可以称作是“四年级读写能力”（fourth grade literacy）或是“功能性读写能力”（functional literacy）——也就是有能力很轻易地阅读交通号志，或图片说明，填写政府的有关简单表格等等。</p><p>第四个阶段，也就是最后一个阶段，到这个时期，学生要从小学或初中毕业了。这个阶段有时候称之为八年级、九年级或十年级的读写能力。在某方面来说，这个孩子已经是一个“<strong>成熟”的阅读者</strong>，他几乎可以阅读所有的读物了，但是<strong>却还不够老练</strong>。简单来说，他的成熟度是可以上高中的课程了。</p><h3 id="阅读的第二个层次：检视阅读">阅读的第二个层次：检视阅读</h3><p><strong>检视阅读，才算是真正进入阅读的层次</strong>。这和前一个层次（基础阅读）相当不同，也跟自然而来的下一个层次（分析阅读）大有差异。</p><h4 id="检视阅读一：有系统的略读或粗读">检视阅读一：有系统的略读或粗读</h4><p>这是一本书，或任何读物，而那是你的头脑。你会做的第一件事是什么？</p><p>让我们再假设在这情况中还有两个相当常见的因素。</p><p>第一，你并<strong>不知道自己想不想读这本书</strong>。你<strong>也不知道这本书是否值得做分析阅读</strong>。但你觉得，或<strong>只要你能挖掘出来</strong>，书中的资讯及观点就起码会<strong>对你有用处</strong>。</p><p>其次，让我们假设——常会有这样的状况——<strong>你想要发掘所有的东西，但时间却很有限</strong>。</p><p>在这样的情况下，你<strong>一定要做的就是“略读”（skim）整本书</strong>，或是有人说成是**粗读（pre-read）**一样。略读或粗读是检视阅读的第一个子层次。</p><p><strong>用这种快速浏览的方式来阅读一本书，就像是一个打谷的过程，能帮助你从糙糠中过滤出真正营养的谷核</strong>。当你浏览过后，你<strong>可能会发现这本书仅只是对你目前有用而已</strong>。<strong>这本书的价值不过如此而已</strong>。但至少你<strong>知道作者重要的主张是什么了，或是他到底写的是怎样的一本书</strong>。因此，<strong>你花在略读这本书上的时间绝没有浪费</strong>。</p><p>略读的习惯应该用不着花太多时间。下面是要如何去做的一些建议：</p><p><strong>（1）先看书名页，然后如果有序就先看序</strong></p><p><strong>要很快地看过去</strong>。<strong>特别注意副标题</strong>，或<strong>其他的相关说明或宗旨</strong>，或是<strong>作者写作本书的特殊角度</strong>。在完成这个步骤之前，你对这本书的主题已经有概念了。如果你愿意，你会暂停一下，在你脑海中将这本书归类为某个特定的类型。而在那个类型中，已经包含了哪些书。</p><p><strong>（2）研究目录页，对这本书的基本架构做概括性的理解</strong></p><p>这<strong>就像是在出发旅行之前，要先看一下地图一样</strong>。很惊讶的是，除非是真的要用到那本书了，许多人连目录页是看都不看一眼的。事实上，<strong>许多作者花了很多时间来创作目录页</strong>，想到这些努力往往都浪费了，不免让人伤心。</p><p><strong>目录纲要还是很有价值的</strong>，在你开始阅读整本书之前，你应该先仔细阅读目录才对。</p><p>谈到这里，如果你还没看过本书的目录页，你可能会想翻回去看一下了，我们尽可能地将目录页写得完整又说明清楚。检视一下这个目录页，你就会明白我们想要做的是什么了。</p><p><strong>（3）如果书中附有索引，也要检阅一下——大多数论说类的书籍都会有索引</strong></p><p><strong>快速评估一下这本书涵盖了哪些议题的范围，以及所提到的书籍种类与作者</strong>等等。如果你发现<strong>列举出来的哪一条词汇很重要，至少要看一下引用到这个词目的某几页内文</strong>。你<strong>所阅读的段落很可能就是个要点——这本书的关键点——或是关系到作者意图与态度的新方法</strong>。</p><p>就跟目录页一样，现在你可能要检查一下本书的索引。你会辨认出一些我们已经讨论过的重要词目。那你能不能再找出其他一些也很重要的词目呢？</p><p><strong>（4）如果那是本包着书衣的新书，不妨读一下出版者的介绍</strong></p><p>许多人对广告文案的印象无非是些吹牛夸张的文字。但这往往失之偏颇，尤其是一些论说性的作品更是如此，大致来说，许多书的宣传文案都是作者在出版公司企宣部门的协助下亲自写就的。这些作者尽力将书中的主旨正确地摘要出来，已经不是稀奇的事了。这些努力不应该被忽视。当然，如果宣传文案什么重点也没写到，只是在瞎吹牛，你也可以很容易看穿。不过，这也有助于你对这本书多一点了解，或许这本书根本没什么重要的东西可谈——而这也正是他们宣传文案一无可取的原因。</p><p><strong>完成这四个步骤，你对一本书已经有足够的资讯，让你判断是想要更仔细地读这本书，还是根本不想读下去了</strong>。不管是哪一种情况，现在你都可能会先将这本书放在一边一阵子。<strong>如果不是的话，现在你就准备好要真正地略读一本书了。</strong></p><p>（5）从你<strong>对一本书的目录很概略，甚至有点模糊的印象当中，开始挑几个看来跟主题息息相关的篇章来看</strong>。如果这些篇章在开头或结尾有摘要说明（很多会有），就要仔细地阅读这些说明。</p><p>（6）最后一步，把书打开来，<strong>东翻翻西翻翻，念个一两段，有时候连续读几页</strong>，但不要太多。</p><p>就用这样的方法把全书翻过一遍，随时寻找主要论点的讯号，留意主题的基本脉动。<strong>最重要的是，不要忽略最后的两三页。就算最后有后记，一本书最后结尾的两三页也还是不可忽视的</strong>。很少有作者能拒绝这样的诱惑，而不在结尾几页将自己认为既新又重要的观点重新整理一遍的。虽然有时候作者自己的看法不一定正确，但你不应该错过这个部分。</p><p>附带一提的是，这<strong>是一种非常主动的阅读</strong>。<strong>一个人如果不够灵活，不能够集中精神来阅读，就没法进行检视阅读</strong>。如果你跟随着我们提议的步骤来做，就绝不会发生这样的事——因为你<strong>始终有一个可以依循作者思路的系统了</strong>。</p><p>你<strong>可以把自己想成是一个侦探，在找寻一本书的主题或思想的线索。随时保持敏感，就很容易让一切状况清楚</strong>。留意我们所提出的建议，会帮助你保持这样的态度。你会很惊讶地发现自己节省了更多时间，高兴自己掌握了更多重点，然后轻松地发现原来阅读是比想象中还更要简单的一件事。</p><h4 id="检视阅读二：粗浅的阅读">检视阅读二：粗浅的阅读</h4><p>对一本难读的书抱着高度的期望，以为它能启发我们，结果却只是在徒劳无益地挣扎而已。很自然的，我们会下个结论：一开始想读这本书就是个错误。但这并不是错误，而只是打从开始就对阅读一本难读的书期望过高。<strong>只要找到对的方向，不论是多难读的书，只要原来就是想写给大众读者看的，那就不该有望之却步的理由</strong>。</p><p>头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或思索。</p><p><strong>只注意你能理解的部分，不要为一些没法立即了解的东西而停顿。继续读下去，略过那些不懂的部分，很快你会读到你看得懂的地方</strong>。集中精神在这个部分。继续这样读下去。将全书读完，不要被一个看不懂的章节、注解、评论或参考资料阻挠或泄气。如果你让自己被困住了，如果你容许自己被某个顽固的段落绑住了，你就是被打败了。在大多数情况里，你一旦和它纠缠，就很难脱困而出。在读第二遍的时候，你对那个地方的了解可能会多一些，但是<strong>在那之前，你必须至少将这本书先从头到尾读一遍才行</strong>。</p><p>你<strong>从头到尾读了一遍之后的了解——就算只有50%或更少——能帮助你在后来重读第一次略过的部分时，增进理解</strong>。就算你不重读，对一本难度很高的书了解了一半，也比什么都不了解来得要好些——如果你让自己在一碰上困难的地方就停住，最后就可能对这本书真的一无所知了。</p><p>我们大多数人所受的教育，都说是要去注意那些我们不懂的地方。我们被教导说，碰到生字，就去查字典。我们被教导说，读到一些不明白的隐喻或论说，就去查百科全书或其他相关资料。我们被教导说，要去查注脚、学者的注释或其他的二手资料以获得帮助。<strong>但是如果时候不到就做这些事，却只会妨碍我们的阅读，而非帮助。</strong></p><h4 id="阅读的速度">阅读的速度</h4><p>要了解一本难读的书，其间的障碍，非一般所谓生理或心理障碍所能比拟甚或涵盖。会有这些障碍，主要是因为阅读者在面对一本困难——值得读——的书时，完全不知道如何是好。他不知道阅读的规则，也不懂得运用心智的力量来做这件事。不论他读得多快，也不会获得更多，因为事实上，他根本不知道自己在寻找什么，就算找到了，也不清楚是不是自己想要的东西。</p><p>所谓阅读速度，理想上来说，<strong>不只是要能读得快，还要能用不同的速度来阅读——要知道什么时候用什么样的速度是恰当的</strong>。<strong>检视阅读是一种训练有素的快速阅读</strong>，但这不只是因为你读的速度快——虽然你真的读得很快——而是因为在检视阅读时，你只读书中的一小部分，而且是用不同的方式来读，不一样的目标来读。<strong>分析阅读通常比检视阅读来得慢一些</strong>，但就算你拿到一本书要做分析阅读，也不该用同样的速度读完全书。每一本书，不论是多么难读的书，<strong>在无关紧要的间隙部分就可以读快一点</strong>。而<strong>一本好书，总会包含一些比较困难，应该慢慢阅读的内容</strong>。</p><h4 id="逗留与倒退">逗留与倒退</h4><p>要矫正眼睛逗留于一点的工具有很多种，有些很复杂又很昂贵。无论如何，任何复杂的工具其实都比不上你的一双手来得有用，你可以利用双手训练自己的眼睛，跟着章节段落移动得越来越快。你可以自己做这样的训练：将大拇指与食指、中指合并在一起，用这个“指针”顺着一行一行的字移动下去，速度要比你眼睛感觉的还要快一点。强迫自己的眼睛跟着手部的动作移动。一旦你的眼睛能跟着手移动时，你就能读到那些字句了。继续练习下去，继续增快手的动作，等到你发觉以前，你的速度已经可以比以前快两三倍了。</p><h4 id="理解的问题">理解的问题</h4><h4 id="检视阅读的摘要">检视阅读的摘要</h4><p>阅读的速度并非只有单一的一种，重点在如何读出不同的速度感，知道在阅读某种读物时该用什么样的速度。超快的速读法是引人怀疑的一种成就，那只是表现你在阅读一种根本不值得读的读物。更好的秘方是：在阅读一本书的时候，慢不该慢到不值得，快不该快到有损于满足与理解。不论怎么说，阅读的速度，不论是快还是慢，只不过是阅读问题一个微小的部分而已。</p><p>略读或粗读一本书总是个好主意。尤其<strong>当你并不清楚手边的一本书是否值得细心阅读时（经常发生这种情况），必须先略读一下。略读过后，你就会很清楚了</strong>。一般来说，就算你想要仔细阅读的书也要先略读一下，从基本架构上先找到一些想法。</p><p>最后，<strong>在第一次阅读一本难读的书时，不要企图了解每一个字句</strong>。这是最最重要的一个规则。这也是检视阅读的基本概念。不要害怕，或是担忧自己似乎读得很肤浅。就算是最难读的书也快快地读一遍。当你再读第二次时，你就已经准备好要读这本书了。</p><h4 id="小节">小节</h4><p><strong>第一阶段的检视阅读——我们称作有系统的略读或粗读——帮助阅读者分析在这个阶段一定要回答的问题</strong>。换句话说，有系统略读，就是准备要了解本书的架构。</p><p><strong>第二阶段的检视阅读——我们称之为粗浅的阅读——帮助阅读者在分析阅读中进入第二个阶段</strong>。粗浅的阅读，是阅读者想要了解全书内容的第一个必要步骤。</p><h3 id="如何做一个自我要求的读者">如何做一个自我要求的读者</h3><h4 id="主动的阅读基础：一个阅读者要提出的四个基本问题"><strong>主动的阅读基础：一个阅读者要提出的四个基本问题</strong></h4><p><strong>（1）整体来说，这本书到底在谈些什么？</strong></p><p>你一定要想办法找出这本书的主题，作者如何依次发展这个主题，如何逐步从核心主题分解出从属的关键议题来。</p><p><strong>（2）作者细部说了什么，怎么说的？</strong></p><p>你一定要想办法找出主要的想法、声明与论点。这些组合成作者想要传达的特殊讯息。</p><p><strong>（3）这本书说得有道理吗？是全部有道理，还是部分有道理？</strong></p><p>除非你能回答前两个问题，否则你没法回答这个问题。在你判断这本书是否有道理之前，你必须先了解整本书在说些什么才行。然而，等你了解了一本书，如果你又读得很认真的话，你会觉得有责任为这本书做个自己的判断。光是知道作者的想法是不够的。</p><p><strong>（4）这本书跟你有什么关系？</strong></p><p>如果这本书给了你一些资讯，你一定要问问这些资讯有什么意义。为什么这位作者会认为知道这件事很重要？你真的有必要去了解吗？如果这本书不只提供了资讯，还启发了你，就更有必要找出其他相关的、更深的含意或建议，以获得更多的启示。</p><h4 id="如何让一本书真正属于你自己">如何让一本书真正属于你自己</h4><p>为什么对阅读来说，在书上做笔记是不可或缺的事？</p><p>第一，那会让你保持清醒——不只是不昏睡，还是非常清醒。</p><p>第二，阅读，如果是主动的，就是一种思考，而思考倾向于用语言表达出来——不管是用讲的还是写的。一个人如果说他知道他在想些什么，却说不出来，通常是他其实并不知道自己在想些什么。</p><p>第三，将你的感想写下来，能帮助你记住作者的思想。</p><p>阅读一本书应该像是你与作者之间的对话。有关这个主题，他知道的应该比你还多，否则你根本用不着去跟这本书打交道了。但是了解是一种双向沟通的过程，学生必须向自己提问题，也要向老师提问题。一旦他了解老师的说法后，还要能够跟老师争辩。在书上做笔记，其实就是在表达你跟作者之间相异或相同的观点。这是你对作者所能付出的最高的敬意。</p><p><strong>做笔记</strong>有各式各样，多彩多姿的方法。以下是几个可以采用的方法：</p><p>（1）画底线——在主要的重点，或重要又有力量的句子下画线。</p><p>（2）在画底线处的栏外再加画一道线——把你已经画线的部分再强调一遍，或是某一段很重要，但要画底线太长了，便在这一整段外加上一个记号。</p><p>（3）在空白处做星号或其他符号——要慎用，只用来强调书中十来个最重要的声明或段落即可。你可能想要将做过这样记号的地方每页折一个角，或是夹一张书签。这样你随时从书架上拿起这本书，打开你做记号的地方，就能唤醒你的记忆。</p><p>（4）在空白处编号——作者的某个论点发展出一连串的重要陈述时，可以做顺序编号。</p><p>（5）在空白处记下其他的页码——强调作者在书中其他部分也有过同样的论点，或相关的要点，或是与此处观点不同的地方。这样做能让散布全书的想法统一集中起来。许多读者会用Cf这样的记号，表示比较或参照的意思。</p><p>（6）将关键字或句子圈出来——这跟画底线是同样的功能。</p><p>（7）在书页的空白处做笔记——在阅读某一章节时，你可能会有些问题（或答案），在空白处记下来，这样可以帮你回想起你的问题或答案。你也可以将复杂的论点简化说明在书页的空白处。或是记下全书所有主要论点的发展顺序。书中最后一页可以用来作为个人的索引页，将作者的主要观点依序记下来。</p><h4 id="三种做笔记的方法">三种做笔记的方法</h4><h4 id="培养阅读的习惯">培养阅读的习惯</h4><h4 id="由许多规则中养成一个习惯">由许多规则中养成一个习惯</h4><p>要学习做一个很好的阅读者并不容易。而且不单单只是阅读，还是分析式的阅读。那是非常复杂的阅读技巧——比滑雪复杂多了。那更是一种心智的活动。考虑到心智上的活动却困难许多，尤其是在刚开始做分析阅读时更是如此，因为他总是在想着自己的想法。大多数人都不习惯这样的阅读。虽然如此，但仍然是可以训练出来的。而一旦学会了，你的阅读技巧就会越来越好。</p><h3 id="阅读的第三个层次：分析阅读">阅读的第三个层次：分析阅读</h3><h4 id="书籍分类的重要性">书籍分类的重要性</h4><p>分析阅读的第一个规则：<strong>你一定要知道自己在读的是哪一类书，而且要越早知道越好。最好早在你开始阅读之前就先知道</strong>。</p><p>一开始时，你要先检视这本书——用检视阅读先浏览一遍。你读读书名、副标题、目录，然后最少要看看作者的序言、摘要介绍及索引。如果这本书有书衣，要看看出版者的宣传文案。这些都是作者在向你传递讯号，让你知道风朝哪个方向吹。如果你不肯停、看、听，那也不是他的错。</p><h4 id="从一本书的书名中你能学到什么">从一本书的书名中你能学到什么</h4><p>阅读书名，换句话说，可以让阅读者在开始阅读之前，获得一些基本的资讯。</p><h4 id="实用性-vs-理论性作品">实用性 vs. 理论性作品</h4><p>要让知识变成实用，就要有操作的规则。我们一定要超越“知道这是怎么回事”，进而明白“如果我们想做些什么，应该怎么利用它”。概括来说，这也就是知与行的区别。理论性的作品是在教你这是什么，实用性的作品在教你如何去做你想要做的事，或你认为应该做的事。</p><p>一本实用的书会很快就显露它的特质，因为它经常会出现“应该”和“应当”、“好”和“坏”、“结果”和“意义”之类的字眼。实用书所用到的典型陈述，是某件事应该做完（或做到）；这样做（或制造）某个东西是对的；这样做会比那样做的结果好；这样选择要比那样好，等等。相反的，理论型的作品却常常说“是”，没有“应该”或“应当”之类的字眼。那是在表示某件事是真实的，这些就是事实，不会说怎样换一个样子更好，或者按照这个方法会让事情变得更好等等。</p><p>分析阅读的第二个规则是：<strong>使用一个单一的句子，或最多几句话（一小段文字）来叙述整本书的内容</strong>。</p><p>第三个规则可以说成是：<strong>将书中重要篇章列举出来，说明它们如何按照顺序组成一个整体的架构</strong>。</p><p>就像一栋房子多少可以居住一样，一本书多少也可以阅读一下。可读性最高的作品是作者达到了建筑学上最完整的整体架构。最好的书都有最睿智的架构。虽然他们通常比一些差一点的书要复杂一些，但他们的复杂也是一种单纯，因为他们的各个部分都组织得更完善，也更统一。</p><p>这也是<strong>为什么最好的书，也是可读性最高的书的理由之一</strong>。比较次级的作品，在阅读时真的会有一些比较多的困扰。但是要读好这些书——就它们原本所值得的程度读好——你就要从中找出它们的规划，当初如果这些作者自己把规划弄得更清楚一些，这些书都可能再更好一些。但只要大致还可以，只要内容不仅是集合体，还够得上是某种程度的整体组合，那其中就必然有一个架构规划，而你一定要找出来才行。</p><h4 id="结构与规划：叙述整本书的大意">结构与规划：叙述整本书的大意</h4><p>也就是要你说出整本书的大意。对这个规则的运用再作一些说明，或许能帮助你确实用上这个技巧。</p><p>首先，<strong>一位作者，特别是好的作者，会经常想要帮助你整理出他书中的重点</strong>。尽管如此，当你要求读者择要说出一本书的重点时，大多数人都会一脸茫然。一个原因是今天的人们普遍不会用简明的语言表达自己，另一个原因，则是他们忽视了阅读的这一条规则。当然，这也说明太多读者根本就不注意作者的前言，也不注意书名，才会有这样的结果。</p><p>其次，<strong>是要小心，不要把我们提供给你的那些书的重点摘要，当作是它们绝对又唯一的说明</strong>。一本书的整体精神可以有各种不同的诠释，没有哪一种一定对。当然，某些诠释因为够精简、准确、容易理解，就是比另一些诠释好。不过，也有些南辕北辙的诠释，不是高明得不相上下，就是烂得不相上下。</p><h4 id="阅读与写作的互惠技巧">阅读与写作的互惠技巧</h4><p>我们可以用一句老话来概括以上所有的概念，<strong>那就是一个作品应该有整体感，清楚明白，前后连贯。这确实是优秀写作的基本准则</strong>。我们在本章所讨论的两个规则，都是跟随这个写作准则而来的。如果这本书有整体的精神，那我们就一定要找出来。如果全书是清楚明白又前后一贯的，我们就要找出其间的纲要区隔，与重点的秩序来当作回报。<strong>所谓文章的清楚明白，就是跟纲要的区隔是否清楚有关，所谓文章的前后一贯，就是能把不同的重点条理有序地排列出来</strong>。</p><p>这两个规则可以帮助我们区分好的作品与坏的作品。如果你运用得已经成熟了，却不论花了多少努力来了解一本书的重点，还是没法分辨出其间的重点，也找不出彼此之间的关系，那么不管这本书多有名，应该还是一本坏书。不过你不该太快下这样的结论，或许错误出在你身上，而不是书的本身。无论如何，千万不要在读不出头绪的时候，就总以为是自己的问题。事实上，无论你身为一个读者的感受如何，通常问题还是出在书的本身。因为大多数的书——绝大多数——的作者，都没有依照这些规则来写作，因而就这一点来说，都可以说是很糟。</p><h4 id="发现作者的意图">发现作者的意图</h4><p>找出作者要问的问题。一本书的作者在开始写作时，都是有一个问题或一连串的问题，而这本书的内容就是一个答案，或许多答案。</p><h4 id="分析阅读的第一个阶段">分析阅读的第一个阶段</h4><p>整本书谈的是什么？你也会想起，我们说这是要找出整本书的主题，以及作者是如何运用一些根本性的次要主题或议题，按部就班来发展这个主题。很明显的，运用这前四个阅读规则，能提供你可以回答这个问题的大部分内容——不过这里要指出一点，等你可以运用其他规则来回答其他问题的时候，你回答这个问题的精确度会提高许多。</p><p>分析阅读的第一阶段，或，找出一本书在谈些什么的四个规则：</p><p><strong>（1）依照书本的种类与主题作分类</strong></p><p><strong>（2）用最简短的句子说出整本书在谈些什么</strong></p><p><strong>（3）按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出</strong></p><p><strong>（4）找出作者在问的问题，或作者想要解决的问题</strong></p><p>规则五，<strong>找出重要单字，透过它们与作者达成共识</strong>。要注意到这个规则共分两个部分，第一个部分是<strong>找出重要单字</strong>，那些举足轻重的单字。第二部分是<strong>确认这些单字在使用时的最精确的意义</strong>。</p><p>这是分析阅读第二阶段的第一个规则，目标不是列出一本书的架构纲要，而是诠释内容与讯息。这个阶段的其他规则将会在下一章讨论到，意义也跟这个规则一样。那些规则也需要你采取两个步骤：<strong>第一个步骤是处理语言的问题。第二个步骤是超越语言，处理语言背后的思想涵义。</strong></p><p>当我们谈到“阅读”时，可能是指：</p><p>（1）为娱乐而阅读</p><p>（2）为获得资讯而阅读</p><p>（3）为追求理解力而阅读</p><h4 id="找出关键字">找出关键字</h4><h4 id="专门用语及特殊字汇">专门用语及特殊字汇</h4><h4 id="找出字义">找出字义</h4><h4 id="句子与主旨">句子与主旨</h4><h4 id="找出关键句">找出关键句</h4><h4 id="找出主旨">找出主旨</h4><p>第六个规则：<strong>将一本书中最重要的句子圈出来，找出其中的主旨</strong>。</p><h4 id="找出论述">找出论述</h4><p>第七个规则：<strong>从相关文句的关联中，设法架构出一本书的基本论述</strong>。</p><h4 id="找出解答">找出解答</h4><p>规则八，<strong>找出作者的解答</strong>。</p><h4 id="分析阅读的第二个阶段">分析阅读的第二个阶段</h4><p>分析阅读的第二个阶段，或找出一本书到底在说什么的规则（诠释一本书的内容）。</p><p><strong>（5）诠释作者使用的关键字，与作者达成共识</strong></p><p><strong>（6）从最重要的句子中抓出作者的重要主旨</strong></p><p><strong>（7）找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张</strong></p><p><strong>（8）确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，确定哪些是作者认为自己无法解决的问题</strong></p><h4 id="受教是一种美德">受教是一种美德</h4><p>是因为要能受教必须先完全听懂老师的话，而且在批评以前要能完全了解。我们还要加一句：光是努力，并不足以称得上受教。读者必须懂得如何评断一本书，就像他必须懂得如何才能了解一本书的内容。这第三组的阅读规则，也就是引导读者在最后一个阶段训练自己受教的能力。</p><h4 id="修辞的作用">修辞的作用</h4><h4 id="暂缓评论的重要性">暂缓评论的重要性</h4><p>第九个规则：<strong>在你说出“我同意”，“我不同意”，或“我暂缓评论”之前，你一定要能肯定地说：“我了解了。”</strong></p><p>第一点，许多人会将评论与不同意混为一谈（就算是“建设性”的批评也是不同意）。</p><p>其次，虽然这些规则看起来很有理，在我们的经验中却发现很少有人能真正运用。这就是古人说的光说不练的道理。</p><p>当然，说出“我不懂”也是个很重要的评断，但这只能在你尽过最大努力之后，因为书而不是你自己的理由才能说这样的话。如果你已经尽力，却仍然无法理解，可能是这本书真的不能理解。对一本书，尤其是一本好书来说，这样的假设是有利的。在阅读一本好书时，无法理解这本书通常是读者的错。因此，在分析阅读中，要进入第三阶段之前，必须花很多时间准备前面两个阶段的工作。所以当你说“我不懂”时，要特别注意其中并没有错在你自己身上的可能。</p><h4 id="避免争强好辩的重要性">避免争强好辩的重要性</h4><p>规则十：<strong>当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论</strong>。如果你知道或怀疑自己是错的，就没有必要去赢得那场争辩。事实上，你赢得争辩可能真的会在世上名噪一时，但长程来说，诚实才是更好的策略。</p><h4 id="化解争议">化解争议</h4><p>规则十一，<strong>尊重知识与个人观点的不同，在作任何评断之前，都要找出理论基础</strong>。</p><h4 id="小节-2">小节</h4><p>这三个规则在一起所说明的是批评式阅读的条件，而在这样的阅读中，读者应该能够与作者“辩论”。</p><p><strong>第一：要求读者先完整地了解一本书，不要急着开始批评。</strong></p><p><strong>第二：恳请读者不要争强好辩或盲目反对。</strong></p><p><strong>第三：将知识上的不同意见看作是大体上可以解决的问题。</strong></p><p>这个规则再进一步的话，就是要求读者要为自己不同的意见找到理论基础，这样这个议题才不只是被说出来，而且会解释清楚。只有这样，才有希望解决这个问题。</p><h4 id="偏见与公正">偏见与公正</h4><p>第一点，<strong>因为人有理性的一面，又有动物的一面，所以在争辩时就要注意你会带进去的情绪，或是在当场引发的脾气</strong>。否则你的争论会流于情绪化，而不是在说理了。当你的情绪很强烈时，你可能会认为自己很有道理。</p><p>第二点，<strong>你要把自己的前提或假设摊出来</strong>。你要知道你的偏见是什么——这也是你的预先评断。否则你就不容易接受对手也有不同假设的权利。一场好的辩论是不会为假设而争吵的。譬如作者明白地请你接受某个前提假设，你就不该因为也可以接受相反的前提假设就不听他的请求。如果你的偏见正好在相反的那一边，而你又不肯承认那就是偏见，你就不能给作者一个公平的机会表达意见了。</p><p>第三点也是最后一点，<strong>派别之争几乎难以避免地会造成一些盲点，要化解这些盲点，应尽力尝试不偏不倚</strong>。当然，争论而不想有派别之分是不可能的事。但是在争论时应该多一点理性的光，少一点激情的热，每个参与辩论的人至少都该从对方的立场来着想。如果你不能用同理心来阅读一本书，你的反对意见会更像是争吵，而不是文明的意见交流。</p><h4 id="判断作者的论点是否正确">判断作者的论点是否正确</h4><h4 id="判断作者论述的完整性">判断作者论述的完整性</h4><h4 id="分析阅读的三阶段">分析阅读的三阶段</h4><p>一、分析阅读的第一阶段：找出一本书在谈些什么的规则</p><p>（1）依照书的种类与主题来分类。</p><p>（2）使用最简短的文字说明整本书在谈些什么。</p><p>（3）将主要部分按顺序与关联性列举出来。将全书的大纲列举出来，并将各个部分的大纲也列出来。</p><p>（4）确定作者想要解决的问题。</p><p>二、分析阅读的第二阶段：诠释一本书的内容规则</p><p>（5）诠释作者的关键字，与他达成共识。</p><p>（6）由最重要的句子中，抓住作者的重要主旨。</p><p>（7）知道作者的论述是什么，从内容中找出相关的句子，再重新架构出来。</p><p>（8）确定作者已经解决了哪些问题，还有哪些是没解决的。再判断哪些是作者知道他没解决的问题。</p><p>三、分析阅读的第三阶段：像是沟通知识一样地评论一本书的规则</p><p>A．智慧礼节的一般规则</p><p>（9）除非你已经完成大纲架构，也能诠释整本书了，否则不要轻易批评。（在你说出：“我读懂了!”之前，不要说你同意、不同意或暂缓评论。）</p><p>（10）不要争强好胜，非辩到底不可。</p><p>（11）在说出评论之前，你要能证明自己区别得出真正的知识与个人观点的不同。</p><p>B．批评观点的特别标准</p><p>（12）证明作者的知识不足。</p><p>（13）证明作者的知识错误。</p><p>（14）证明作者不合逻辑。</p><p>（15）证明作者的分析与理由是不完整的。</p><h4 id="辅助阅读">辅助阅读</h4><p>内在阅读”（intrinsic reading），意思是指阅读书籍的本身，与所有其他的书都是不相关的。</p><p>而“外在阅读”（extrinsic reading）指的是我们借助其他一些书籍来阅读一本书。</p><p>外在的辅助来源可以分成四个部分。在这一章中，我们会依照以下的顺序讨论出来：<strong>第一，相关经验。第二，其他的书。第三，导论与摘要。第四，工具书。</strong></p><h4 id="相关经验的角色">相关经验的角色</h4><h4 id="其他的书可以当作阅读时的外在助力">其他的书可以当作阅读时的外在助力</h4><h4 id="如何运用导读与摘要">如何运用导读与摘要</h4><p>第三种外在的辅助阅读包括导读（ commentary ） 与摘要（abstract）。这里要强调的是，在运用这些资料时要特别聪明，也就是要尽量少用。这么说有两个理由。</p><p>第一，一本书的导读并不一定都是对的。第二个原因是，就算他们写对了，可能也不完整。</p><p>还有另一个重点。如果你养成了依赖导读的习惯，当你找不到这类书时，你会完全不知所措。你可能可以借着导读来了解某一本作品，但一般而言，你不会是个好读者。</p><p>第一，如果你已经读过一本书，这些摘要能唤醒你的记忆。理想上，在分析阅读时，你就该自己作这样的摘要。但如果你还没这样做，一份内容摘要对你来说是有帮助的。</p><p>第二，在主题阅读时，摘要的用处很大，你可以因此知道某些特定的议题是与你的主题密切相关的。摘要绝不能代替真正的阅读，但有时却能告诉你，你想不想或需不需要读这本书。</p><h4 id="如何运用工具书">如何运用工具书</h4><p>要善用工具书，<strong>首先你必须有一些想法，不管是多模糊的想法，那就是你想要知道些什么</strong>？你的无知就像是被光圈围绕着的黑暗。你一定要能将光线带进黑暗之中才行。而除非光圈围绕着黑暗，否则你是无法这么做的。换句话说，你一定要能对工具书问一个明智的问题。否则如果你只是彷徨迷失在无知的黑幕中，工具书也帮不上你的忙。</p><p><strong>其次，你一定要知道在哪里找到你要找的答案</strong>。你要知道自己问的是哪一类的问题，而哪一类的工具书是回答这类问题的。没有一本工具书能回答所有的问题，无论过去或现在，所有的工具书都是针对特定问题而来的。尤其是，事实上，在你能有效运用工具书之前，你必须要对主要类型的工具书有一个全盘的了解。</p><p>在工具书对你发挥功用之前，你还必须有第三种知识。<strong>你必须要知道这本书是怎么组织的</strong>。如果你不知道要如何使用这本工具书的特殊功能，那就无助于你知道自己想要的是什么，也不知道该用哪种工具书。因此，阅读工具书跟阅读其他的书籍一样，也是有阅读的艺术的。此外，编辑工具书的技巧也有关系。作者或编者应该知道读者在找的是什么样的资料，然后编排出读者需要的内容。不过，他可能没办法先预测到这一点，这也是为什么这个规则要你在阅读一本书之前，先看序言与前言的原因。在阅读工具书时也一样，要看完编辑说明如何使用这本书之后，才开始阅读内容。</p><p>要明智地运用工具书的第四个条件就是：<strong>你必须知道你想要找的是什么，在哪一种工具书中能找到这样的东西</strong>。你也要知道如何在工具书中找到你要的资料，还要能确定该书的编者或作者知道哪个答案。在你使用工具书之前，这些都是你应该清楚知道的事。对一无所知的人来说，工具书可说是毫无用处。工具书并不是茫然无知的指南。</p><h4 id="如何使用字典">如何使用字典</h4><p>（1）文字是物质的——可以写成字，也可以说出声音。</p><p>（2）文字是语言的一部分。在一个较复杂的句子或段落的结构中，文字扮演了文法上的角色。</p><p>（3）文字是符号——这些符号是有意义的，不止一种意义，而是很多种意义。</p><p>（4）文字是约定俗成的——这是人类创造的符号。</p><p>一本好字典能回答这四个不同类型的有关文字的问题。要善用一本字典，就是要知道问什么样的问题，如何找到答案。我们已经将问题建议出来了，字典应该告诉你如何找到解答。</p><p>字典是一种完美的自修工具书，因为它告诉你要注意什么，如何诠释不同的缩写字，以及上面所说的四种有关文字符号的知识。任何人不善读一本字典开头时所作的解释以及所列的缩写符号，那用不好字典就只能怪他自己了。</p><h4 id="如何使用百科全书">如何使用百科全书</h4><p>在百科全书的例子中，与事实相关的要点是相同的。因为字典是关于文字的，而百科全书是关于事实的。</p><p>（1）事实是一种说法（proposition）——说明一个事实时，会用一组文字来表达。</p><p>（2）事实是一种“真实”的说法（“True”proposition）——事实不是观点。当有人说：“事实上……”的时候，表示他在说的是一般人同意的事。</p><p>（3）事实是真相的反映——事实可能是（1）一个资讯；（2）不受怀疑的推论。不管是哪一种，都代表着事情的真相。</p><p>（4）事实是某种程度上的约定俗成——我们说事实会改变。我们的意思是，某个时代的事实，到了另一个时代却不是事实了。</p><p>百科全书有两个明显的缺失。照理说，百科全书是不记载论点的。除非这个论点已经被广泛接受了，或已成为历史性的趣味话题。因此，在百科全书中，主要缺少的是说理的写法。此外，百科全书虽然记载了有关诗集与诗人的事实，但是其中却不包含诗与想象的文学作品。因为想象与理性都是追求理解必要的条件，因此在求知的过程中，百科全书无法让人完全满意，也就不可避免了。</p><h3 id="阅读不同读物的方法">阅读不同读物的方法</h3><h4 id="两种实用性的书">两种实用性的书</h4><p>关于实用性的书有一件事要牢记在心：<strong>任何实用性的书都不能解决该书所关心的实际问题</strong>。一本理论性的作品可以解决自己提出的问题。但是实际的问题却只能靠行动来解决。当你的实际问题是如何赚钱谋生时，一本教你如何交朋友或影响别人的书，虽然可能建议你很多事，但却不能替你解决问题。没有任何捷径能解决这个问题，只能靠你自己去赚钱谋生才能解决。</p><p>实用性的书因此可分为两种类型。其中一种，就像本书一样，或是烹饪书、驾驶指南，基本上都是在说明规则的。无论其中谈论到什么问题，都是为了说明规则而来的。这类书很少有伟大的作品。另一类的实用书主要是在阐述形成规则的原理。许多伟大的经济、政治、道德巨著就属于这一类。</p><h4 id="说服的角色">说服的角色</h4><p>当你在阅读任何一种实用书时，一定要问你自己两个主要的问题。**第一：作者的目的是什么？第二：他建议用什么方法达到这个目的？**以原理为主的书要比以规则为主的书还要难回答这两个问题。在这些书中，目的与方法可能都不很明显。但如果你想要了解与评论实用性的书，就必须回答这两个问题。</p><h4 id="赞同实用书之后">赞同实用书之后</h4><p>我们确定你已经看出来了，你在读一本书时要提出的四个问题，到了读实用性的书时有了一点变化。我们就来说明一下这些变化。</p><p>第一个问题：这本书是在谈些什么？</p><p>第二个问题的变化也不大。为了要能回答关于这本书的意义或内容，你仍然要能够找出作者的共识、主旨与论述。</p><p>第三个问题：内容真实吗？</p><p>第四个问题：这本书与我何干？可说全部改变了。如果在阅读一本理论性的书之后，你对那个主题的观点多少有点变化了，你对一般事物的看法也就会多少有些调整。</p><p>如果读完本书的第二部分，你（1）同意分析阅读是值得做的。（2）接受这些阅读规则，当作是达到目标的基本要件，你会像我们现在所说的一样，开始照着阅读起来。如果没有这么做，可能并不是你偷懒或太累了，而是你并不真的同意（1）或（2）。</p><h4 id="读想象文学的“不要”">读想象文学的“不要”</h4><h4 id="阅读想象文学的一般规则">阅读想象文学的一般规则</h4><h4 id="如何阅读故事书">如何阅读故事书</h4><h4 id="关于史诗的重点">关于史诗的重点</h4><h4 id="如何阅读戏剧">如何阅读戏剧</h4><h4 id="关于悲剧的重点">关于悲剧的重点</h4><h4 id="如何阅读抒情诗（Lyric-Poetry）">如何阅读抒情诗（Lyric Poetry）</h4><h4 id="难以捉摸的史实">难以捉摸的史实</h4><h4 id="历史的理论">历史的理论</h4><h4 id="历史中的普遍性">历史中的普遍性</h4><h4 id="阅读历史书要提出的问题">阅读历史书要提出的问题</h4><h4 id="如何阅读传记与自传">如何阅读传记与自传</h4><h4 id="如何阅读关于当前的事件">如何阅读关于当前的事件</h4><h4 id="关于文摘的注意事项">关于文摘的注意事项</h4><h4 id="了解科学这一门行业">了解科学这一门行业</h4><h4 id="阅读科学经典名著的建议">阅读科学经典名著的建议</h4><h4 id="面对数学的问题">面对数学的问题</h4><h4 id="掌握科学作品中的数学问题">掌握科学作品中的数学问题</h4><h4 id="关于科普书的重点">关于科普书的重点</h4><h4 id="哲学家提出的问题">哲学家提出的问题</h4><h4 id="现代哲学与传承">现代哲学与传承</h4><h4 id="哲学的方法">哲学的方法</h4><h4 id="哲学的风格">哲学的风格</h4><h4 id="阅读哲学的提示">阅读哲学的提示</h4><h4 id="厘清你的思绪">厘清你的思绪</h4><h4 id="关于神学的重点">关于神学的重点</h4><h4 id="何阅读“经书”">何阅读“经书”</h4><h4 id="什么是社会科学？">什么是社会科学？</h4><h4 id="阅读社会科学的容易处">阅读社会科学的容易处</h4><h4 id="阅读社会科学的困难处">阅读社会科学的困难处</h4><h4 id="阅读社会科学作品">阅读社会科学作品</h4><h3 id="阅读的第四个层次：主题阅读">阅读的第四个层次：主题阅读</h3><h4 id="在主题阅读中，检视阅读所扮演的角色">在主题阅读中，检视阅读所扮演的角色</h4><p>我们已经说过很多次，阅读的层次是渐进累积的。较高层次的阅读中也包括了前面的，或较低层次的阅读。在主题阅读中，我们就要说明这一点。</p><p>在解说检视阅读与分析阅读的关系时，我们指出在检视阅读中的两个步骤——<strong>第一个是浏览，第二个是粗浅地阅读——也就是分析阅读的前两个步骤</strong>。浏览能帮助你准备做分析阅读的第一个步骤：你能确定自己在读的是什么主题，能说明这是什么样的书，并拟出大纲架构。粗浅的阅读对分析阅读的第一步骤也有帮助。基本上这是进入第二步骤的准备动作。在第二个步骤中，你要能够与作者达成共识，说明他的主旨，跟随他的论述，才能够诠释整本书的内容。</p><p>同样的，检视阅读与分析阅读也可以当作是进入主题阅读的前置作业或准备动作。<strong>事实上，在这个阶段，检视阅读已经是读者在阅读时主要的工具或手段了。</strong></p><p>举例来说，你有上百本的参考书目，看起来全是与爱有关的主题。如果你全部用分析阅读来阅读，你不只会很清楚你在研究的主题是什么——主题阅读中的“同一主题”——你还会知道你所阅读的书中，那些跟主题无关，是你不需要的书。但是要用分析阅读将一百本书读完，会花上你十年的时间。就算你能全心投注在这个研究上，仍然要花上好几个月的时间。再加上我们前面谈过的主题阅读中会出现的矛盾问题，显然必要有一些捷径。</p><p>这个捷径是要靠你的检视阅读技巧来建立的。你收集好书目之后，要做的第一件事是检视书单上所有的书。在做检视阅读之前，绝不要用分析阅读来阅读。检视阅读不会让你明白有关主题的所有错综复杂的内容，或是作者所有的洞察力，但却具有两种基本的功能。<strong>第一，它会让你对自己想要研究的主题有个清晰的概念，这样接下来你针对某几本书做分析阅读时，会大有助益。第二，它会简化你的书目到一个合理的程度。</strong></p><p>对学生，尤其是研究生来说，我们很难想到还有比这更管用的方式。只要他们肯照着做，一定会有帮助。根据我们的经验，在研究生程度的学生中，<strong>确实有些人能做到主动的阅读与分析阅读</strong>。这对他们来说还不够，他们或许不是完美的读者，但是至少他们知道要如何掌握一本书的重点，能明确地说出书中的要点，并把这些观点纳入他们研究主题的一部分。但是他们的努力有一大半是浪费掉了，因为他们不知道要如何才能比别人读得快一点。他们阅读每一本书或每一篇文章都花上同样的时间与努力，结果他们该花精神好好阅读的书却没有读好，倒把时间花在那些不太值得注意的书上了。</p><p><strong>能够熟练检视阅读的读者，不但能在心中将书籍分类，而且能对内容有一个粗浅的了解。他也会用非常短的时间就发现，这本书谈的内容对他研究的主题到底重不重要</strong>。这时他可能还不清楚哪些资料才是最重要的——这可能要等到读下本书的时候才能发现。但是有两件事至少他已经知道其中之一。那就是他不是发现这本书必须回头再读一次，以获得启发，便是知道不论这本书多有趣又多丰富，却毫无启发性，因此不值得重新再读。</p><p>这个忠告通常会被忽略是有原因的。我们说过，在分析阅读中，技巧熟练的阅读者可以同时用上许多技巧，而初学者却必须把步骤分开来。同样的，主<strong>题阅读的准备工作——先检视书目上所有的书，在开始做分析阅读之前先检视一遍——可以在做分析阅读时一并进行</strong>。但我们不相信任何读者能做到这一点，就算技巧再熟练也不行。这也是许多年轻研究生所犯的毛病。他们自以为两个步骤可以融合为一个，结果阅读任何书都用同样的速度，对某些特殊的作品来说不是太快就是太慢，但无论如何，对他们阅读的大部分书来说，这样的方法都是不对的。</p><p>一旦你检视过，确定某些书跟你研究的主题相关后，你就可以开始做主题阅读了。要注意的是，我们并没有像你以为的说：“开始做分析阅读”。当然，你需要研读每一本书，再组合起跟你主题相关的资料，你在做分析阅读时就已经学会了这些技巧。但是绝不要忘了，<strong>分析阅读的技巧只适用于单一的作品，主要的目标是要了解这本书。而我们会看到，主题阅读的目标却大不相同。</strong></p><h4 id="主题阅读的五个步骤">主题阅读的五个步骤</h4><p>在主题阅读中一共有五个步骤。这些步骤我们不该称之为规则——虽然也许我们会——因为只要漏掉其中一个步骤，主题阅读就会变得很困难，甚至读不下去了。我们会简略地介绍一下这些步骤的顺序，不过这些步骤彼此之间还是可以互相取代的。</p><p><strong>主题阅读步骤一：找到相关的章节</strong>。当然，我们假设你已经学会分析阅读了，如果你愿意，你能把所有相关的书都看透彻了。但是你可能会把阅读单本的书放在第一顺位，而把自己的主题放在其次。事实上，这个顺序应该颠倒过来，在主题阅读中，你及你关心的主题才是基本的重点，而不是你阅读的书。</p><p>在你已经确定哪些书是相关的之后，<strong>主题阅读的第一个步骤就是把这些书整体检视阅读一遍。你的目标是找出书中与你的主题极为相关的章节</strong>。你选择的书不太可能全本都与你的主题或问题相关。就算是如此，也一定是少数，你应该很快地把这本书读完。你不该忘了，你的阅读是别有用心的——也就是说，你是为了要解决自己的问题才阅读——而不是为了这本书本身的目的而阅读。</p><p>在主题阅读中，能够把你所阅读的第一批书，与你后来针对这个主题阅读的许多本书的差别区分出来，是很重要的事。对后来的这些书来说，你可能对自己的主题已经有了很清楚的概念，这时就可以把两种检视阅读合并在一起。但是在一开始时，却要明显地区分出来，否则你在找相关章节时会犯下严重的错误，到后来要更正这些错误时又要花上很多的时间与精力。</p><p>总之，<strong>要记得你最主要的工作不是理解整本书的内容，而是找出这本书对你的主题有什么帮助，而这可能与作者本身的写作目的相去甚远</strong>。在这个阶段的过程中，这并不重要。作者可能是在无意之间帮你解决了问题。我们已经说过，在主题阅读中，是书在服务你，而不是你在服务书。因此，主题阅读是最主动的一种阅读法。当然，分析阅读也需要主动的阅读方式。但是你在分析阅读一本书时，你就像是把书当作主人，供他使唤。而你<strong>在做主题阅读时，却一定要做书的主人。</strong></p><p><strong>主题阅读步骤二：带引作者与你达成共识</strong>。在诠释阅读中（分析阅读的第二步骤），第一个规则是要你与作者达成共识，也就是要能找出关键字，发现他是如何使用这些字的。但是现在你面对的是许多不同的作者，他们不可能每个人都使用同样的字眼，或相同的共识。在这时候就是要由你来建立起共识，带引你的作者们与你达成共识，而不是你跟着他们走。</p><p>在主题阅读中，这可能是最困难的一个步骤。真正的困难在于要强迫作者使用你的语言，而不是使用他的语言。这跟我们一般的阅读习惯都不相同。我们也指出过很多次，我们假设：我们想要用分析阅读来阅读的作者，是比我们优秀的人。尤其如果这是一本伟大的著作时，就更可能如此。无论我们在了解他的过程中花了多少力气，我们都会倾向于接受他的词义与他安排的主题结构。但在主题阅读中，如果我们接受任何一位作者所提出来的词汇（terminology），我们很快就会迷失。我们可能会了解他的书，却无法了解别人的书。我们也很难找到与自己感兴趣的主题的资料。</p><p>简单来说，主题阅读是一种大量的翻译工作。我们并不是将一种语言翻成另一种语言，像法语翻成英语，但是我们要将一种共通的词汇加诸在许多作者身上，无论他们所使用的是不是相同的语言，或是不是关心我们想解决的问题，是否创造了理想的词汇供我们使用。</p><p>这就是说，在进行主题阅读时，我们要建立一组词汇，首先帮助我们了解所有的作者，而不是其中一两个作者；其次帮助我们解决我们的问题。这一点认识会带我们进入第三个步骤。</p><p><strong>主题阅读步骤三：厘清问题</strong>。诠释阅读的第二个规则是要我们找出作者的关键句子。然后从中逐步了解作者的主旨。主旨是由词义组成的，在主题阅读中，当然我们也要做同样的工作。但是因为这时是由我们自己来建立词汇，因此，我们也得建立起一组不偏不倚的主旨。最好的方法是先列出一些可以把我们的问题说得比较明白的问题，然后让那些作者来回答这些问题。</p><p>我们不该期望所有的作者都用同一种方法来回答我们的问题。如果他们这么做了，我们就又没有问题要解决了。那个问题会被一致的意见解决了。正因为每个作者都不相同，因此我们要再面对主题阅读的下一个步骤。</p><p><strong>主题阅读步骤四：界定议题</strong>。如果一个问题很清楚，如果我们也确定各个作者会用不同的方式来回答——不论赞成或反对——那么这个议题就被定义出来了。这是介于用这种方法回答问题的作者，和用另外一种（可能是相反的）方法来回答问题的作者之间的议题。</p><p><strong>主题阅读步骤五：分析讨论</strong>。到目前为止，我们已经检验过作品，找出相关的章节，设定了一个不偏不倚的共识，适用于所有被检视过的作者，再设定出一整套的问题，其中大部分都能在作者的说明中找到答案。然后就不同的答案界定并安排出议题。接下来该怎么做呢？</p><p>前面四个步骤与分析阅读的前两组规则是互相辉映的。这些规则应用在任何一本书中，都会要我们回答一个问题：这本书在说些什么？是如何说明的？在主题阅读中，对于与我们的问题相关的讨论，我们也要回答类似的问题。在只阅读一本书的分析阅读中，剩下还有两个问题要回答：这是真实的吗？这与我何干？而在主题阅读中，我们对于讨论也要准备回答同样的问题。</p><p>对一个问题完整地分析过后，将来其他人对同一个问题要作研究时，我们的分析讨论就会提供他一个很好的研究基础。那会清除一些障碍，理出一条路，让一个原创性的思考者能突破困境。如果没有这个分析的工作，就没法做到这一点，因为这个问题的各个层面就无法显现出来。</p><h4 id="客观的必要性">客观的必要性</h4><p>要完整地分析一个问题或某个主题，得指出这个讨论中的主要议题，或是一些基本的知性反对立场。这并不是说在所有的讨论中，反对的意见总是占主导的。相反，同意或反对的意见总是互相并存的。也就是说，在大多数的议题中，正反两面的意见总是有几个，甚至许多作者在支持。在一个争议性的立场上，我们很少看到一个孤零零的支持者或反对者。</p><p><strong>主题阅读的目的，并不是给阅读过程中发展出来的问题提供最终答案，也不是给这个计划开始时候的问题提供最终解答</strong>。当我们要给这样的主题阅读写一份读者报告的时候，这个道理特别清楚。如果这份报告就任何所界定并分析过的重要议题，想要主张或证明某一种观点的真实或虚假，都会太过教条，失去对话的意义。如果这么做，主题阅读就不再是主题阅读，而只是讨论过程中的另一个声音，失去了疏离与客观性。</p><p><strong>主题阅读就是要能面面俱到，而自己并不预设立场</strong>。当然，这是个严格的理想，一般人是没法做到的。而绝对的客观也不是人类所能做到的事。他可能可以做到不预设立场，毫无偏见地呈现出任何观点，对不同的意见也保持中立。但是采取中立比面面俱到要容易多了。在这一方面，主题阅读的读者注定会失败的。一个议题有各种不同的观点，不可能巨细靡遗地全都列出来。虽然如此，读者还是要努力一试。</p><p>要避免这样的危险，谨慎的主题阅读的读者可以采取一个明显的手段，尽量多加利用。那就是他要不断回头参阅诸多作者的原文，重新再阅读相关的章节。并且，当他要让更多的人能应用他的研究结果时，他必须照原作者的原文来引用他的观点或论述。虽然看起来有点矛盾，但这并不影响我们前面所说的，在分析问题时必须先建立一套中立的词汇。这样的中立语言还是必要的，而且在总结一个作者的论述时，一定要用这套中立的语言，而不是作者的语言。但是伴随着总结，一定要有仔细引用的作者原文，以免对文意有所扭曲，这样阅读者才能自己判断你对作者所作的诠释是否正确。</p><p>主题阅读的读者必须能够坚决地避免这个问题，才不会偏离公正客观的立场。要达到这样的理想，必须要能不偏不倚地在各种相对立的问题中保持平衡，放下一切偏见，反省自己是否有过与不及的倾向。在最后的分析中，一份主题阅读的书面报告是否达到对话形式的客观，虽然也可以由读者来判断，但只有写这份报告的人才真正明白自己是否达到这些要求。</p><h4 id="主题阅读的练习实例：进步论">主题阅读的练习实例：进步论</h4><h4 id="如何应用主题工具书">如何应用主题工具书</h4><p>主题阅读加上主题工具书，还能从三种不同的方向指导关系。事实上，这是这个层次的阅读最有利的地方。</p><p><strong>第一，读者阅读的章节所涉及的主题，能够给他一个诠释这些章节的方向</strong>。但这并不是告诉他这些章节是什么意思，因为一个章节可能从好几个或许多个方向与主题相关。而读者的责任就是要找出这个章节与主题真正相关的地方在哪里。要学习这一点，需要拥有很重要的阅读技巧。</p><p><strong>第二，针对同一个主题，从许多不同的作者与书籍中收集出来的章节，能帮助读者强化对各个章节的诠释能力</strong>。有时候我们从同一本书中依照顺序来阅读的章节，以及挑出来比对阅读的章节，相互对照之下可以让我们更了解其中的含意。有时候从不同书中摘出来的章节是互相冲突的，但是当你读到彼此冲突的论点时，就会更明白其中的意义了。有时候从一个作者的书中摘出来的章节，由另一个作者的书的某个章节作补充或评论，实际上可以帮助读者对第二位作者有更多的了解。</p><p><strong>第三，如果主题阅读运用在许多不同的主题上，当你发现同一个章节被主题工具书引述在许多不同主题之下的时候，这件事情本身就很有指导阅读的效果</strong>。随着读者针对不同的主题要对这些章节进行多少不同的诠释，他会发现这些章节含有丰富的意义。这种多重诠释的技巧，不只是阅读技巧中的基本练习，同时也会训练我们的头脑面对任何含义丰富的章节时，能习惯性地作出适当的调整。</p><h4 id="构成主题阅读的原则">构成主题阅读的原则</h4><h4 id="主题阅读精华摘要">主题阅读精华摘要</h4><p>在主题阅读中有两个阶段。一个是准备阶段，另一个是主题阅读本身。让我们复习一下这些不同的步骤：<br><strong>一、观察研究范围：主题阅读的准备阶段</strong></p><p>（1）针对你要研究的主题，设计一份试验性的书目。你可以参考图书馆目录、专家的建议与书中的书目索引。</p><p>（2）浏览这份书目上所有的书，确定哪些与你的主题相关，并就你的主题建立起清楚的概念。</p><p><strong>二、主题阅读：阅读所有第一阶段收集到的书籍</strong></p><p>（1）浏览所有在第一阶段被认定与你主题相关的书，找出最相关的章节。</p><p>（2）根据主题创造出一套中立的词汇，带引作者与你达成共识——无论作者是否实际用到这些词汇，所有的作者，或至少绝大部分的作者都可以用这套词汇来诠释。</p><p>（3）建立一个中立的主旨，列出一连串的问题——无论作者是否明白谈过这些问题，所有的作者，或者至少大多数的作者都要能解读为针对这些问题提供了他们的回答。</p><p>（4）界定主要及次要的议题。然后将作者针对各个问题的不同意见整理陈列在各个议题之旁。你要记住，各个作者之间或之中，不见得一定存在着某个议题。有时候，你需要针对一些不是作者主要关心范围的事情，把他的观点解读，才能建构出这种议题。</p><p>（5）分析这些讨论。这得把问题和议题按顺序排列，以求突显主题。比较有共通性的议题，要放在比较没有共通性的议题之前。各个议题之间的关系也要清楚地界定出来。</p><h4 id="好书能给我们什么帮助">好书能给我们什么帮助</h4><p>“手段”（means）这两个字可以解释成两种意义。在前面的章节中，我们将手段当作是阅读的规则，也就是使你变成一个更好的阅读者的方法。但是手段也可以解释为你所阅读的东西。空有方法却没有可以运用的材料，就和空有材料却没有可以运用的方法一样是毫无用处的。</p><p>以“手段”的后一种意思来说，未来提升你阅读能力的手段其实是你将阅读的那些书。我们说过，这套阅读方法适用于任何一本，以及任何一种你所阅读的书——无论是小说还是非小说，想象文学还是论说性作品，实用性还是理论性。但是事实上，<strong>起码就我们在探讨分析阅读与主题阅读过程中所显示的这套方法并不适用于所有的书</strong>。原因是<strong>有些书根本用不上这样的阅读</strong>。</p><p>我们在前面已经提过这一点了，但我们想要再提一遍，因为这<strong>与你马上要做的工作有关。如果你的阅读目的是想变成一个更好的阅读者，你就不能摸到任何书或文章都读</strong>。如果你所读的书都在你的能力范围之内，你就没法提升自己的阅读能力。你必须能操纵超越你能力的书，或像我们所说的，阅读超越你头脑的书。只有那样的书能帮助你的思想增长。除非你能增长心智，否则你学不到东西。</p><p>因此，对你来说最重要的是，你<strong>不只要能读得好，还要有能力分辨出哪些书能帮助你增进阅读能力</strong>。一本消遣或娱乐性的书可能会给你带来一时的欢愉，但是除了享乐之外，你也不可能再期待其他的收获了。</p><p><strong>一个好的读者也是自我要求很高的读者。他在阅读时很主动，努力不懈</strong>。现在我们要谈的是另外一些观念。你想要用来练习阅读技巧，尤其是分析阅读技巧的书，一定要对你也有所要求。这些书一定要看起来是超越你的能力才行。你大可不必担心真的如此，只要你能运用我们所说的阅读技巧，没有一本书能逃开你的掌握。当然，这并不是说所有的技巧可以一下子像变魔术一样让你达到目标。<strong>无论你多么努力，总会有些书是跑在你前面的。事实上，这些书就是你要找的书，因为它们能让你变成一个更有技巧的读者。</strong></p><p>阅读一本烂书也是很困难的事，因为那样的书会抵消你为分析阅读所作的努力，每当你认为能掌握到什么的时候又会溜走。事实上，一本烂书根本不值得你花时间去努力，甚至根本不值得作这样的尝试。你努力半天还是一无所获。</p><p><strong>读一本好书，却会让你的努力有所回报。最好的书对你的回馈也最多</strong>。当然，这样的回馈分成两种：第一，当你成功地阅读了一本难读的好书之后，你的阅读技巧必然增进了。第二——长期来说这一点更重要——一本好书能教你了解这个世界以及你自己。你不只更懂得如何读得更好，还更懂得生命。你变得更有智慧，而不只是更有知识——像只提供讯息的书所形成的那样。你会成为一位智者，对人类生命中永恒的真理有更深刻的体认。</p><h4 id="书的金字塔">书的金字塔</h4><p>你怎么知道不用再读那本书了呢？因为你在阅读时，你的心智反应已经与书中的经验合而为一了。这样的书会增长你的心智，增进你的理解力。就在你的心智成长，理解力增加之后，你了解到——这是多少有点神秘的经验——这本书对你以后的心智成长不会再有帮助了。你知道你已经掌握这本书的精髓了。你将精华完全吸收了。你很感激这本书对你的贡献，但你知道它能付出的仅止于此了。</p><p>在几千本这样的书里，还有更少的一些书——很可能不到一百种——却是你读得再通，也不可能尽其究竟。你要如何分辨哪些书是属于这一类的呢？这又是有点神秘的事了，不过当你尽最大的努力用分析阅读读完一本书，把书放回架上的时候，你心中会有点疑惑，好像还有什么你没弄清楚的事。我们说“疑惑”，是因为在这个阶段可能仅只是这种状态。如果你确知你错过了什么，身为分析阅读者，就有义务立刻重新打开书来，厘清自己的问题是什么。事实上，你没法一下子指出问题在哪里，但你知道在哪里。你会发现自己忘不了这本书，一直想着这本书的内容，以及自己的反应。最后，你又重看一次。然后非常特殊的事就发生了。</p><p>一本书怎么会跟你一起成长呢？当然这是不可能的。一本书只要写完出版了，就不会改变了。只是你到这时才会开始明白，你最初阅读这本书的时候，这本书的层次就远超过你，现在你重读时仍然超过你，未来很可能也一直超过你。因为这是<strong>一本真正的好书——我们可说是伟大的书——所以可以适应不同层次的需要</strong>。你先前读过的时候感到心智上的成长，并不是虚假的。那本书的确提升了你。但是现在，<strong>就算你已经变得更有智慧也更有知识，这样的书还是能提升你，而且直到你生命的尽头。</strong></p><h4 id="生命与心智的成长">生命与心智的成长</h4><p>好的阅读，也就是主动的阅读，不只是对阅读本身有用，也不只是对我们的工作或事业有帮助，更能帮助我们的心智保持活力与成长。</p>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>R 语言实战（第2版）第一部分 入门</title>
      <link href="/2021/08/16/r_yu_yan_shi_zhan_di_2_ban_di_yi_bu_fen_ru_men/"/>
      <url>/2021/08/16/r_yu_yan_shi_zhan_di_2_ban_di_yi_bu_fen_ru_men/</url>
      
        <content type="html"><![CDATA[<h2 id="第一部分-入门">第一部分 入门</h2><h3 id="第-1-章-R-语言介绍">第 1 章 R 语言介绍</h3><blockquote><p>本章内容<br>❑ R 的安装<br>❑ 熟悉 R 语言<br>❑ 运行 R 程序</p></blockquote><h4 id="1-1-为何要使用-R">1.1 为何要使用 R</h4><h4 id="1-2-R-的获取和安装">1.2 R 的获取和安装</h4><h4 id="1-3-R-的使用">1.3 R 的使用</h4><p>R是一种区分大小写的解释型语言。你可以在命令提示符（&gt;）后每次输入并执行一条命令，或者一次性执行写在脚本文件中的一组命令。R中有多种数据类型，包括向量、矩阵、数据框（与数据集类似）以及列表（各种对象的集合）。将在第 2 章中讨论这些数据类型。</p><p>R中的多数功能是由程序内置函数、用户自编函数和对对象的创建和操作所提供的。一个对象可以是任何能被赋值的东西。对于R来说，对象可以是任何东西（数据、函数、图形、分析结果，等等）。每一个对象都有一个类属性，类属性可以告诉R怎么对之进行处理。</p><p>一次交互式会话期间的所有数据对象都被保存在内存中。一些基本函数是默认直接可用的，而其他高级函数则包含于按需加载的程序包中。</p><p>R语句由函数和赋值构成。R使用&lt;-，而不是传统的=作为赋值符号。例如，以下语句：</p><pre><code class="highlight R">x <span class="operator">&lt;-</span> rnorm<span class="punctuation">(</span><span class="number">5</span><span class="punctuation">)</span></code></pre><p>创建了一个名为x的向量对象，它包含5个来自标准正态分布的随机偏差</p><blockquote><p>x &lt;- rnorm(5)<br>x<br>[1] -2.4698221 -0.5653149  0.2730340  1.1408878<br>[5]  0.6336379</p></blockquote><p>注意 R允许使用=为对象赋值，但是这样写的R程序并不多，因为它不是标准语法。一些情况下，用等号赋值会出现问题，R程序员可能会因此取笑你。你还可以反转赋值方向。例如，rnorm(5) -&gt; x 与上面的语句等价。重申一下，使用等号赋值的做法并不常见，不推荐使用。</p><h5 id="1-3-1-新手上路">1.3.1 新手上路</h5><p>如果你使用的是 Windows，从开始菜单中启动 R。在 Mac 上，则需要双击应用程序文件夹中的R图标。对于 Linux，在终端窗口中的命令提示符下敲入 R 并回车。这些方式都可以启动R.</p><p>我们通过一个简单的虚构示例来直观地感受一下这个界面。假设我们正在研究生理发育问题，并收集了 10 名婴儿在出生后一年内的月龄和体重数据（见表1-1）。我们感兴趣的是体重的分布及体重和月龄的关系。</p><p><strong>表1-1  10名婴儿的月龄和体重</strong></p><table><thead><tr><th style="text-align:center">年龄（月）</th><th style="text-align:center">体重（kg）</th><th style="text-align:center">年龄（月）</th><th style="text-align:center">体重（kg）</th></tr></thead><tbody><tr><td style="text-align:center">01</td><td style="text-align:center">4.4</td><td style="text-align:center">09</td><td style="text-align:center">7.3</td></tr><tr><td style="text-align:center">03</td><td style="text-align:center">5.3</td><td style="text-align:center">03</td><td style="text-align:center">6.0</td></tr><tr><td style="text-align:center">05</td><td style="text-align:center">7.2</td><td style="text-align:center">09</td><td style="text-align:center">10.4</td></tr><tr><td style="text-align:center">02</td><td style="text-align:center">5.2</td><td style="text-align:center">12</td><td style="text-align:center">10.2</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">8.5</td><td style="text-align:center">03</td><td style="text-align:center">6.1</td></tr></tbody></table><p><strong>注：以上为虚构数据。</strong></p><p>代码清单1-1 给出了分析的过程。可以使用函数 c() 以向量的形式输入月龄和体重数据，此函数可将其参数组合成一个向量或列表。然后用 mean()、sd() 和 cor() 函数分别获得体重的均值和标准差，以及月龄和体重的相关度。最后使用 plot() 函数，从而用图形展示月龄和体重的关系，这样就可以用可视化的方式检查其中可能存在的趋势。函数 q() 将结束会话并允许你退出 R。</p><p><strong>代码清单1-1 一个 R 会话示例</strong></p><pre><code class="highlight R">age <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">11</span><span class="punctuation">,</span><span class="number">9</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="number">9</span><span class="punctuation">,</span><span class="number">12</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">)</span>weight <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">4.4</span><span class="punctuation">,</span><span class="number">5.3</span><span class="punctuation">,</span><span class="number">7.2</span><span class="punctuation">,</span><span class="number">5.2</span><span class="punctuation">,</span><span class="number">8.5</span><span class="punctuation">,</span><span class="number">7.3</span><span class="punctuation">,</span><span class="number">6.0</span><span class="punctuation">,</span><span class="number">10.4</span><span class="punctuation">,</span><span class="number">10.2</span><span class="punctuation">,</span><span class="number">6.1</span><span class="punctuation">)</span></code></pre><pre><code class="highlight R">mean<span class="punctuation">(</span>weight<span class="punctuation">)</span></code></pre><p>输出：[1] 7.06</p><pre><code class="highlight R">sd<span class="punctuation">(</span>weight<span class="punctuation">)</span></code></pre><p>输出：[1] 2.077498</p><pre><code class="highlight R">cor<span class="punctuation">(</span>age<span class="punctuation">,</span>weight<span class="punctuation">)</span></code></pre><p>输出：[1] 0.9075655</p><pre><code class="highlight R">plot<span class="punctuation">(</span>age<span class="punctuation">,</span>weight<span class="punctuation">)</span>q<span class="punctuation">(</span><span class="punctuation">)</span></code></pre><p>从代码清单1-1 中可以看到，这 10 名婴儿的平均体重是 7.06kg，标准差为 2.08kg，月龄和体重之间存在较强的线性关系（相关度=0.91）。这种关系也可以从图1-4所示的散点图中看到。不出意料，随着月龄的增长，婴儿的体重也趋于增加。</p><p>散点图1-4 的信息量充足，但过于“功利”，也不够美观。接下来的几章里，我们会讲到如何自定义图形以契合需要。</p><blockquote><p>小提示 若想大致了解R能够作出何种图形，在命令行中运行demo()即可。生成的部分图形如图1-5所示。其他的演示还有demo(Hershey)、demo(persp)和demo(image)。要看到完整的演示列表，不加参数直接运行demo()即可。</p></blockquote><img src="/medias/image-20210813143754843.png" style="zoom:50%;" alt="图1-4 婴儿体重（千克）和年龄（月）的散点图"><img src="/medias/image-20210813143913120.png" alt="图1-5 函数demo()绘制的图形示例" style="zoom:50%;"><h5 id="1-3-2-获取帮助">1.3.2 获取帮助</h5><p>R提供了大量的帮助功能，学会如何使用这些帮助文档可以在相当程度上助力你的编程工作。R的内置帮助系统提供了当前已安装包中所有函数①的细节、参考文献以及使用示例。你可以通过表1-2中列出的函数查看帮助文档。</p><p>① 确切地说，这里的“所有”是指那些已导出的（exported）、对用户可见的函数。</p><p><strong>表1-2 R 中的帮助函数</strong></p><table><thead><tr><th style="text-align:left">函  数</th><th style="text-align:left">功 能</th></tr></thead><tbody><tr><td style="text-align:left">help.start()</td><td style="text-align:left">打开帮助文档首页</td></tr><tr><td style="text-align:left">help(“foo”)或?foo</td><td style="text-align:left">查看函数 foo 的帮助（引号可以省略）</td></tr><tr><td style="text-align:left">help.search(“foo”)或??foo</td><td style="text-align:left">以 foo 为关键词搜索本地帮助文档</td></tr><tr><td style="text-align:left">example(“foo”)</td><td style="text-align:left">函数 foo 的使用示例（引号可以省略）</td></tr><tr><td style="text-align:left">RSiteSearch(“foo”)</td><td style="text-align:left">以 foo 为关键词搜索在线文档和邮件列表存档</td></tr><tr><td style="text-align:left">apropos(“foo”, mode=“function”)</td><td style="text-align:left">列出名称中含有 foo 的所有可用函数</td></tr><tr><td style="text-align:left">data()</td><td style="text-align:left">列出当前已加载包中所含的所有可用示例数据集</td></tr><tr><td style="text-align:left">vignette()</td><td style="text-align:left">列出当前已安装包中所有可用的 vignette 文档</td></tr><tr><td style="text-align:left">vignette(“foo”)</td><td style="text-align:left">为主题  foo 显示指定的 vignette 文档</td></tr></tbody></table><p>函数 help.start() 会打开一个浏览器窗口，我们可在其中查看入门和高级的帮助手册、常见问题集，以及参考材料。函数 RSiteSearch() 可在在线帮助手册和 R-Help 邮件列表的讨论存档中搜索指定主题，并在浏览器中返回结果。由函数 vignette() 函数返回的 vignette 文档一般是 PDF 格式的实用介绍性文章。不过，并非所有的包都提供了 vignette 文档。不难发现，R 提供了大量的帮助功能，学会如何使用这些帮助文档，毫无疑问有助于编程。我经常使用?来查看某些函数的功能（如选项或返回值）。</p><h5 id="1-3-3-工作空间">1.3.3 工作空间</h5><p>工作空间（workspace）就是当前 R 的工作环境，它存储着所有用户定义的对象（向量、矩阵、函数、数据框、列表）。在一个 R 会话结束时，你可以将当前工作空间保存到一个镜像中，并在下次启动R时自动载入它。各种命令可在R命令行中交互式地输入。使用上下方向键查看已输入命令的历史记录。这样我们就可以选择一个之前输入过的命令并适当修改，最后按回车重新执行它。</p><p>当前的工作目录（working directory）是 R 用来读取文件和保存结果的默认目录。我们可以使用函数 getwd() 来查看当前的工作目录，或使用函数 setwd() 设定当前的工作目录。如果需要读入一个不在当前工作目录下的文件，则需在调用语句中写明完整的路径。记得使用引号闭合这些目录名和文件名。用于管理工作空间的部分标准命令见表1-3。</p><p><strong>表1-3  用于管理R工作空间的函数</strong></p><table><thead><tr><th>函  数</th><th>功  能</th></tr></thead><tbody><tr><td>getwd()</td><td>显示当前的工作目录</td></tr><tr><td>setwd(“mydirectory”)</td><td>修改当前的工作目录为 mydirectory</td></tr><tr><td>ls()</td><td>列出当前工作空间中的对象</td></tr><tr><td>rm(objectlist)</td><td>移除（删除）一个或多个对象</td></tr><tr><td>help(options)</td><td>显示可用选项的说明</td></tr><tr><td>options()</td><td>显示或设置当前选项</td></tr><tr><td>history(<em>#</em>)</td><td>显示最近使用过的 # 个命令（默认值为 25）</td></tr><tr><td>savehistory(“myfile”)</td><td>保存命令历史到文件 myfile 中（默认值为.Rhistory）</td></tr><tr><td>loadhistory(“myfile”)</td><td>载入一个命令历史文件（默认值为.Rhistory）</td></tr><tr><td>save.image(“myfile”)</td><td>保存工作空间到文件 myfile 中（默认值为.RData）</td></tr><tr><td>save(objectlist, file=“myfile”)</td><td>保存指定对象到一个文件中</td></tr><tr><td>load(“myfile”)</td><td>读取一个工作空间到当前会话中（默认值为.RData）</td></tr><tr><td>q()</td><td>退出 R。将会询问你是否保存工作空间</td></tr></tbody></table><p>要了解这些命令是如何运作的，运行代码清单1-2 中的代码并查看结果。</p><p><strong>代码清单1-2 用于管理 R 工作空间的命令使用示例</strong></p><pre><code class="highlight R">setwd<span class="punctuation">(</span><span class="string">"D:/Rprojects"</span><span class="punctuation">)</span> options<span class="punctuation">(</span><span class="punctuation">)</span>options<span class="punctuation">(</span>digits<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span> x <span class="operator">&lt;-</span> runif<span class="punctuation">(</span><span class="number">20</span><span class="punctuation">)</span> summary<span class="punctuation">(</span>x<span class="punctuation">)</span> hist<span class="punctuation">(</span>x<span class="punctuation">)</span>q<span class="punctuation">(</span><span class="punctuation">)</span></code></pre><p>首先，当前工作目录被设置为 D:/Rprojects，当前的选项设置情况将显示出来，而数字将被格式化，显示为具有小数点后三位有效数字的格式。然后，我们创建了一个包含 20 个均匀分布随机变量的向量，生成了此数据的摘要统计量和直方图。当 q() 函数被运行的时候，程序将向用户询问是否保存工作空间。如果用户输入y，命令的历史记录保存到文件 .Rhistory 中，工作空间（包含向量x）保存到当前目录中的文件 .RData 中，会话结束，R程序退出。</p><p>注意 setwd() 命令的路径中使用了正斜杠。R将反斜杠（\）作为一个转义符。即使你在Windows 平台上运行 R，在路径中也要使用正斜杠。同时注意，函数 setwd() 不会自动创建一个不存在的目录。如果必要的话，可以使用函数 dir.create() 来创建新目录，然后使用 setwd() 将工作目录指向这个新目录。</p><p>在独立的目录中保存项目是一个好主意。你也许会在启动一个 R 会话时使用 setwd() 命令指定到某一个项目的路径，后接不加选项的 load(“.RData”) 命令。这样做可以让你从上一次会话结束的地方重新开始，并保证各个项目之间的数据和设置互不干扰。在 Windows 和 Mac OS X 平台上就更简单了。跳转到项目所在目录并双击之前保存的镜像文件即可。这样做可以启动 R，载入保存的工作空间，并设置当前工作目录到这个文件夹中。</p><h5 id="1-3-4-输入和输出">1.3.4 输入和输出</h5><p>启动 R 后将默认开始一个交互式的会话，从键盘接受输入并从屏幕进行输出。不过你也可以处理写在一个脚本文件（一个包含了R语句的文件）中的命令集并直接将结果输出到多类目标中。</p><ol><li><strong>输入</strong></li></ol><p>函数 source(“filename”) 可在当前会话中执行一个脚本。如果文件名中不包含路径，R 将假设此脚本在当前工作目录中。举例来说，source(“myscript.R”) 将执行包含在文件 myscript.R 中的 R 语句集合。依照惯例，脚本文件以.R作为扩展名，不过这并不是必需的。</p><ol start="2"><li><strong>文本输出</strong></li></ol><p>函数 sink(“filename”) 将输出重定向到文件 filename 中。默认情况下，如果文件已经存在， 则它的内容将被覆盖。使用参数 append=TRUE 可以将文本追加到文件后，而不是覆盖它。参数  split=TRUE 可将输出同时发送到屏幕和输出文件中。不加参数调用命令 sink() 将仅向屏幕返回输出结果。</p><ol start="3"><li><strong>图形输出</strong></li></ol><p>虽然 sink() 可以重定向文本输出，但它对图形输出没有影响。要重定向图形输出，使用表1-4 中列出的函数即可。最后使用 dev.off() 将输出返回到终端。</p><p><strong>表1-4  用于保存图形输出的函数</strong></p><table><thead><tr><th>函  数</th><th>输 出</th></tr></thead><tbody><tr><td>bmp(“filename.bmp”)</td><td>BMP 文件</td></tr><tr><td>jpeg(“filename.jpg”)</td><td>JPEG 文件</td></tr><tr><td>pdf(“filename.pdf”)</td><td>PDF 文件</td></tr><tr><td>png(“filename.png”)</td><td>PNG 文件</td></tr><tr><td>postscript(“<a href="http://filename.ps">filename.ps</a>”)</td><td>PostScript 文件</td></tr><tr><td>svg(“filename.svg”)</td><td>SVG 文件</td></tr><tr><td>win.metafile(“filename.wmf”)</td><td>Windows 图元文件</td></tr></tbody></table><p>让我们通过一个示例来了解整个流程。假设我们有包含R代码的三个脚本文件 script1.R、</p><p>script2.R 和 script3.R。执行语句：</p><pre><code class="highlight R">source<span class="punctuation">(</span><span class="string">"script1.R"</span><span class="punctuation">)</span></code></pre><p>将会在当前会话中执行 script1.R 中的 R 代码，结果将出现在屏幕上。</p><p>如果执行语句：</p><pre><code class="highlight R">sink<span class="punctuation">(</span><span class="string">"myoutput"</span><span class="punctuation">,</span> append<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> split<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> pdf<span class="punctuation">(</span><span class="string">"mygraphs.pdf"</span><span class="punctuation">)</span>source<span class="punctuation">(</span><span class="string">"script2.R"</span><span class="punctuation">)</span></code></pre><p>文件 script2.R 中的 R 代码将执行，结果也将显示在屏幕上。除此之外，文本输出将被追加到文件 myoutput 中，图形输出将保存到文件 mygraphs.pdf 中。</p><p>最后，如果我们执行语句：</p><pre><code class="highlight R">sink<span class="punctuation">(</span><span class="punctuation">)</span> dev.off<span class="punctuation">(</span><span class="punctuation">)</span>source<span class="punctuation">(</span><span class="string">"script3.R"</span><span class="punctuation">)</span></code></pre><p>文件 script3.R 中的 R 代码将执行，结果将显示在屏幕上。这一次，没有文本或图形输出保存到文件中。整个流程大致如图1-6 所示</p><img src="/medias/image-20210813160847195.png" alt="图1-6 使用函数source()进行输入并使用函数sink()进行输出" style="zoom:80%;"><p>R 对输入来源和输出走向的处理相当灵活，可控性很强。</p><h4 id="1-4-包">1.4 包</h4><p>R 提供了大量开箱即用的功能，但它最激动人心的一部分功能是通过可选模块的下载和安装来实现的。目前有 5500 多个称为包（ package ） 的用户贡献模块可从 <a href="http://cran.r-project.org/web/packages">http://cran.r-project.org/web/packages</a> 下载。这些包提供了横跨各种领域、数量惊人的新功能，包括分析地理数据、处理蛋白质质谱，甚至是心理测验分析的功能。</p><h5 id="1-4-1-什么是包">1.4.1 什么是包</h5><p>包是 R 函数、数据、预编译代码以一种定义完善的格式组成的集合。计算机上存储包的目录称为库（library）。函数 .libPaths() 能够显示库所在的位置， 函数 library() 则可以显示库中有哪些包。</p><p>R自带了一系列默认包（包括 base、datasets、utils、grDevices、graphics、stats 以及methods），它们提供了种类繁多的默认函数和数据集。其他包可通过下载来进行安装。安装好以后，它们必须被载入到会话中才能使用。命令 search() 可以告诉你哪些包已加载并可使用。</p><h5 id="1-4-2-包的安装">1.4.2 包的安装</h5><p>有许多R函数可以用来管理包。第一次安装一个包，使用命令 install.packages() 即可。举例来说，不加参数执行命令 install.packages() 将显示一个 CRAN 镜像站点的列表，选择 其中一个镜像站点之后，将看到所有可用包的列表，选择其中的一个包即可进行下载和安装。 如果知道自己想安装的包的名称，可以直接将包名作为参数提供给这个函数。例如，包 gclus 中提供了创建增强型散点图的函数。可以使用命令 install.packages(“gclus”) 来下载和安装它。</p><p>一个包仅需安装一次。但和其他软件类似，包经常被其作者更新。使用命令 update.packages() 可以更新已经安装的包。要查看已安装包的描述，可以使用 installed.packages()命令，这将列出安装的包，以及它们的版本号、依赖关系等信息。</p><h5 id="1-4-3-包的载入">1.4.3 包的载入</h5><p>包的安装是指从某个 CRAN 镜像站点下载它并将其放入库中的过程。要在 R 会话中使用它， 还需要使用 library() 命令载入这个包。例如，要使用 gclus 包，执行命令 library(gclus) 即可。当然，在载入一个包之前必须已经安装了这个包。在一个会话中，包只需载入一次。如果需要，你可以自定义启动环境以自动载入会频繁使用的那些包。启动环境的自定义在附录 B 中有详细描述。</p><h5 id="1-4-4-包的使用方法">1.4.4 包的使用方法</h5><p>载入一个包之后，就可以使用一系列新的函数和数据集了。包中往往提供了演示性的小型数据集和示例代码，能够让我们尝试这些新功能。帮助系统包含了每个函数的一个描述（同时带有示例），每个数据集的信息也被包括其中。命令 help(package=“package_name”)  可以输出某个包的简短描述以及包中的函数名称和数据集名称的列表。使用函数help()可以查看其中任意函数或数据集的更多细节。这些信息也能以 PDF 帮助手册的形式从 CRAN 下载。</p><blockquote><p>R语言编程中的常见错误</p><p>有一些错误是R的初学者和经验丰富的R程序员都可能常犯的。如果程序出错了，请检查以下几方面。</p><p>❑ **使用了错误的大小写。**help()、Help() 和 HELP() 是三个不同的函数（只有第一个是正确的）。</p><p>❑ **忘记使用必要的引号。**install.packages(“gclus”) 能够正常执行，然而</p><p>Install.packages(gclus) 将会报错。</p><p>❑ **在函数调用时忘记使用括号。**例如，要使用 help() 而非 help。即使函数无需参数，仍需加上 ()。</p><p>❑ <strong>在Windows 上，路径名中使用了</strong>\ **。**R 将反斜杠视为一个转义字符。</p><p>setwd(“c:\mydata”) 会报错。正确的写法是 setwd(“c:/mydata”) 或 setwd(“c:\ \mydata”)。</p><p>❑ **使用了一个尚未载入包中的函数。**函数 order.clusters() 包含在包 gclus 中。如果还没有载入这个包就使用它，将会报错。</p></blockquote><p>R 的报错信息可能是含义模糊的，但如果谨慎遵守了以上要点，就应该可以避免许多错误。</p><h4 id="1-5-批处理">1.5 批处理</h4><p>多数情况下，我们都会交互式地使用 R：在提示符后输入命令，接着等待该命令的输出结果。偶尔，我们可能想要以一种重复的、标准化的、无人值守的方式执行某个R程序。例如，你可能需要每个月生成一次相同的报告，这时就可以在R中编写程序，在批处理模式下执行它。</p><p>如何以批处理模式运行R与使用的操作系统有关。在Linux或Mac OS X系统下，可以在终端窗口中使用如下命令：</p><pre><code class="highlight R">R CMD BATCH options infile outfile</code></pre><p>其中 infile 是包含了要执行的R代码所在文件的文件名，outfile 是接收输出文件的文件名，</p><p>options 部分则列出了控制执行细节的选项。依照惯例，infile 的扩展名是 .R， outfile 的扩展名为 .Rout。</p><p>对于Windows，则需使用：</p><pre><code class="highlight plaintext">"C:\Program Files\R\R-3.1.0\bin\R.exe" CMD BATCH --vanilla --slave "c:\my projects\myscript.R"</code></pre><p>将路径调整为 R.exe 所在的相应位置和脚本文件所在位置。要进一步了解如何调用 R，包括命令行选项的使用方法，请参考 CRAN（<a href="http://cran.r-project.org/">http://cran.r-project.org</a>）上的文档  “Introduction to R” ①。</p><p>① 中文版文档名为“R 导论”。CRAN 上的下载地址为<a href="http://cran.r-project.org/doc/contrib/Ding-R-intro_cn.pdf%E3%80%82">http://cran.r-project.org/doc/contrib/Ding-R-intro_cn.pdf。</a></p><h4 id="1-6-将输出用为输入：结果的重用">1.6 将输出用为输入：结果的重用</h4><p>R的一个非常实用的特点是，分析的输出结果可轻松保存，并作为进一步分析的输入使用。让我们通过一个R中已经预先安装好的数据集作为示例阐明这一点。如果你无法理解这里涉及的统计知识，也别担心，我们在这里关注的只是一般原理。</p><p>首先，利用汽车数据 mtcars 执行一次简单线性回归，通过车身重量（wt）预测每加仑行驶的英里数（mpg）。可以通过以下语句实现：</p><pre><code class="highlight R">lm<span class="punctuation">(</span>mpg<span class="operator">~</span>wt<span class="punctuation">,</span> data<span class="operator">=</span>mtcars<span class="punctuation">)</span></code></pre><p>结果将显示在屏幕上，不会保存任何信息。</p><p>下一步，执行回归，区别是在一个对象中保存结果：</p><pre><code class="highlight R">lmfit <span class="operator">&lt;-</span> lm<span class="punctuation">(</span>mpg<span class="operator">~</span>wt<span class="punctuation">,</span> data<span class="operator">=</span>mtcars<span class="punctuation">)</span></code></pre><p>以上赋值语句创建了一个名为 lmfit 的列表对象，其中包含了分析的大量信息（包括预测值、残差、回归系数等）。虽然屏幕上没有显示任何输出，但分析结果可在稍后被显示和继续使用。</p><p>键入 summary(lmfit) 将显示分析结果的统计概要，plot(lmfit) 将生成回归诊断图形， 而语句 cook&lt;-cooks.distance(lmfit) 将计算和保存影响度量统计量①，plot(cook) 对其绘图。要在新的车身重量数据上对每加仑行驶的英里数进行预测，不妨使用 predict(lmfit, mynewdata)。</p><p>要了解某个函数的返回值，查阅这个函数在线帮助文档中的 “Value” 部分即可。本例中应当查阅 help(lm) 或 ?lm 中的对应部分。这样就可以知道将某个函数的结果赋值到一个对象时， 保存下来的结果具体是什么。</p><p>① 这里使用了 Cook 距离作为度量影响的统计量，详见第8章。</p><h4 id="1-7-处理大数据集">1.7 处理大数据集</h4><p>程序员经常问我R是否可以处理大数据问题。他们往往需要处理来自互联网、气候学、遗传学等研究领域的海量数据。由于 R 在内存中存储对象，往往会受限于可用的内存量。举例来说， 在我服役了 5 年的 2G 内存 Windows PC 上，我可以轻松地处理含有 1000 万个元素的数据集（100 个变量 × 100 000 个观测）。在一台 4 G 内存的 iMac 上，我通常可以不费力地处理含有上亿元素的数据。</p><p>但是也要考虑到两个问题：数据集的大小和要应用的统计方法。R 可以处理 GB 级到 TB 级的数据分析问题，但需要专门的手段。大数据集的管理和分析问题留待附录 F 中讨论。</p><h4 id="1-8-示例实践">1.8 示例实践</h4><p>我们将以一个结合了以上各种命令的示例结束本章。以下是任务描述。</p><p>(1) 打开帮助文档首页，并查阅其中的 “Introduction to R”。</p><p>(2) 安装 vcd 包（一个用于可视化类别数据的包，将在第 11 章中使用）。</p><p>(3) 列出此包中可用的函数和数据集。</p><p>(4) 载入这个包并阅读数据集 Arthritis 的描述。</p><p>(5) 显示数据集Arthritis的内容（直接输入一个对象的名称将列出它的内容）。</p><p>(6) 运行数据集 Arthritis 自带的示例。如果不理解输出结果，也不要担心。它基本上显示了接受治疗的关节炎患者较接受安慰剂的患者在病情上有了更多改善。</p><p>(7) 退出。</p><p>所需的代码如代码清单1-3 所示，图1-7 显示了结果的示例。如本例所示，我们只需使用少量 R 代码即可完成大量工作。</p><p><strong>代码清单1-3 使用一个新的包</strong></p><pre><code class="highlight R">help.start<span class="punctuation">(</span><span class="punctuation">)</span> install.packages<span class="punctuation">(</span><span class="string">"vcd"</span><span class="punctuation">)</span> help<span class="punctuation">(</span>package<span class="operator">=</span><span class="string">"vcd"</span><span class="punctuation">)</span> library<span class="punctuation">(</span>vcd<span class="punctuation">)</span> help<span class="punctuation">(</span>Arthritis<span class="punctuation">)</span> Arthritis example<span class="punctuation">(</span>Arthritis<span class="punctuation">)</span>q<span class="punctuation">(</span><span class="punctuation">)</span></code></pre><img src="/medias/image-20210813180222196.png" alt="图1-7 代码清单1-3 的输出。（从左至右）为关节炎示例的输出结果、帮助文档首页、vcd 包的信息、Arthritis 数据集的信息，以及一幅展示关节炎治疗情况和治疗结果之间关系的图" style="zoom:67%;"><p>图1-7 代码清单1-3 的输出。（从左至右）为关节炎示例的输出结果、帮助文档首页、vcd 包的信息、Arthritis 数据集的信息，以及一幅展示关节炎治疗情况和治疗结果之间关系的图</p><h4 id="1-9-小结">1.9 小结</h4><p>本章中，我们了解了 R 的一些优点，正是这些优点吸引了学生、研究者、统计学家以及数据分析师等希望理解数据所具有意义的人。我们从程序的安装出发，讨论了如何通过下载附加包来增强R的功能。探索了 R 的基本界面，以交互和批处理两种方式运行了 R 程序，并绘制了一些示例图形。还学习了如何将工作保存到文本和图形文件中。由于 R 的复杂性，我们花了一些时间来了解如何访问大量现成可用的帮助文档。希望你对这个免费软件的强大之处有了一个总体的感觉。既然已经能够正常运行R，那么是时候把玩你自己的数据了。在下一章中，我们将着眼于 R 能够处理的各种数据类型，以及如何从文本文件、其他程序和数据库管理系统中导入数据。</p><h3 id="第2章-创建数据集">第2章 创建数据集</h3><blockquote><p>本章内容<br>❑ 探索 R 中的数据结构<br>❑ 输入数据<br>❑ 导入数据<br>❑ 标注数据</p></blockquote><p>按照个人要求的格式来创建含有研究信息的数据集，这是任何数据分析的第一步。在 R 中， 这个任务包括以下两步：</p><ul><li><p>选择一种数据结构来存储数据；</p></li><li><p>将数据输入或导入到这个数据结构中。</p></li></ul><p>本章的第一部分（2.1～2.2节）叙述了 R 中用于存储数据的多种结构。其中，2.2节描述了向量、因子、矩阵、数据框以及列表的用法。熟悉这些数据结构（以及访问其中元素的表述方法） 将十分有助于了解 R 的工作方式，因此你可能需要耐心消化这一节的内容。</p><p>本章的第二部分（2.3节）涵盖了多种向R中导入数据的可行方法。可以手工输入数据，亦可从外部源导入数据。数据源可为文本文件、电子表格、统计软件和各类数据库管理系统。举例来说，我在工作中使用的数据往往来自于 SQL 数据库。偶尔，我也会接受从 DOS 时代遗留下的数据， 或是从现有的 SAS 和 SPSS 中导出的数据。通常，你仅仅需要本节中描述的一两种方法，因此根据需求有选择地阅读即可。</p><p>创建数据集后，往往需要对它进行标注，也就是为变量和变量代码添加描述性的标签。本章的第三部分（2.4节）将讨论数据集的标注问题，并介绍一些处理数据集的实用函数（2.5节）。下面我们从基本知识讲起。</p><h4 id="2-1-数据集的概念">2.1 数据集的概念</h4><p>数据集通常是由数据构成的一个矩形数组，行表示观测，列表示变量。表2-1 提供了一个假想的病例数据集。</p><p><strong>表2-1 病例数据</strong></p><table><thead><tr><th style="text-align:center">病人编号</th><th style="text-align:center">入院时间</th><th style="text-align:center">年龄</th><th style="text-align:center">糖尿病类型</th><th>病情</th></tr></thead><tbody><tr><td style="text-align:center">（PatientID）</td><td style="text-align:center">（AdmDate）</td><td style="text-align:center">（Age）</td><td style="text-align:center">（Diabetes）</td><td>（Status）</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">10/15/2009</td><td style="text-align:center">25</td><td style="text-align:center">Type 1</td><td>Poor</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">11/01/2009</td><td style="text-align:center">34</td><td style="text-align:center">Type 2</td><td>Improved</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">10/21/2009</td><td style="text-align:center">28</td><td style="text-align:center">Type 1</td><td>Excellent</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">10/28/2009</td><td style="text-align:center">52</td><td style="text-align:center">Type 1</td><td>Poor</td></tr></tbody></table><p>不同的行业对于数据集的行和列叫法不同。统计学家称它们为观测（observation）和变量（variable），数据库分析师则称其为记录（record）和字段（field），数据挖掘和机器学习学科的研究者则把它们叫作示例（example）和属性（attribute）。我们在本书中通篇使用术语观测和变量。</p><p>你可以清楚地看到此数据集的结构（本例中是一个矩形数组）以及其中包含的内容和数据类型。在表2-1 所示的数据集中，PatientID 是行/实例标识符，AdmDate 是日期型变量，Age 是连续型变量，Diabetes 是名义型变量，Status 是有序型变量。</p><p>R中有许多用于存储数据的结构，包括标量、向量、数组、数据框和列表。表2-1实际上对应着R中的一个数据框。多样化的数据结构赋予了 R 极其灵活的数据处理能力。</p><p>R可以处理的数据类型（模式）包括数值型、字符型、逻辑型（TRUE/FALSE）、复数型（虚数）和原生型（字节）。在 R 中，PatientID、AdmDate 和 Age 为数值型变量，而Diabetes 和 Status 则为字符型变量。另外，你需要分别告诉 R：PatientID 是实例标识符，AdmDate 含有日期数据，Diabetes 和 Status 别是名义型和有序型变量。R将实例标识符称为 rownames（行名），将类别型（包括名义型和有序型）变量称为因子（factors）。在下一节中讲解这些内容，并在第 3 章中介绍日期型数据的处理。</p><h4 id="2-2-数据结构">2.2 数据结构</h4><p>R 拥有许多用于存储数据的对象类型，包括标量、向量、矩阵、数组、数据框和列表。它们在存储数据的类型、创建方式、结构复杂度，以及用于定位和访问其中个别元素的标记等方面均有所不同。图2-1给出了这些数据结构的一个示意图。</p><p><img src="/medias/image-20210813181139496.png" alt="图2-1 R 中的数据结构"></p><p>让我们从向量开始，逐个探究每一种数据结构。</p><blockquote><p><strong>一些定义</strong></p><p>R 中有一些术语较为独特，可能会对新用户造成困扰。</p><p>在 R 中，<strong>对象</strong>（object）是指可以赋值给变量的任何事物，包括常量、数据结构、函数， 甚至图形。对象都拥有某种<strong>模式</strong>，描述了此对象是如何存储的，以及某个<strong>类</strong>，像 print 这样的泛型函数表明如何处理此对象。</p><p>与其他标准统计软件（如SAS、SPSS和Stata）中的数据集类似，<strong>数据框</strong>（data frame）是 R 中用于存储数据的一种结构：列表示变量，行表示观测。在同一个数据框中可以存储不同类型（如数值型、字符型）的变量。数据框将是你用来存储数据集的主要数据结构。</p><p><strong>因子</strong>（factor）是名义型变量或有序型变量。它们在 R 中被特殊地存储和处理。你将在2.2.5 节中学习因子的处理。</p><p>其他多数术语你应该比较熟悉了，它们基本都遵循统计和计算中术语的定义。</p></blockquote><h5 id="2-2-1-向量">2.2.1   向量</h5><p>向量是用于存储数值型、字符型或逻辑型数据的一维数组。执行组合功能的函数 c() 可用来创建向量。各类向量如下例所示：</p><pre><code class="highlight R">a <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">6</span><span class="punctuation">,</span> <span class="operator">-</span><span class="number">2</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">)</span>b <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"one"</span><span class="punctuation">,</span> <span class="string">"two"</span><span class="punctuation">,</span> <span class="string">"three"</span><span class="punctuation">)</span><span class="built_in">c</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="literal">TRUE</span><span class="punctuation">,</span> <span class="literal">TRUE</span><span class="punctuation">,</span> <span class="literal">TRUE</span><span class="punctuation">,</span> <span class="literal">FALSE</span><span class="punctuation">,</span> <span class="literal">TRUE</span><span class="punctuation">,</span> <span class="literal">FALSE</span><span class="punctuation">)</span></code></pre><img src="/medias/image-20210814101409565.png" alt="输出内容" style="zoom:67%;"><p>这里，a 是数值型向量，b 是字符型向量，而 c 是逻辑型向量。注意，单个向量中的数据必须拥有相同的类型或模式（数值型、字符型或逻辑型）。同一向量中无法混杂不同模式的数据。</p><p><strong>注意：</strong> <strong>标量</strong>是只含一个元素的向量，例如 f &lt;- 3、g &lt;- “US” 和h &lt;- TRUE。它们用于保存常量。</p><p>通过在方括号中给定元素所处位置的数值，我们可以访问向量中的元素。例如，a[c(2, 4)] 用于访问向量 a 中的第二个和第四个元素。更多示例如下：</p><pre><code class="highlight R"><span class="operator">&gt;</span> a <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"k"</span><span class="punctuation">,</span> <span class="string">"j"</span><span class="punctuation">,</span> <span class="string">"h"</span><span class="punctuation">,</span> <span class="string">"a"</span><span class="punctuation">,</span> <span class="string">"c"</span><span class="punctuation">,</span> <span class="string">"m"</span><span class="punctuation">)</span><span class="operator">&gt;</span> <span class="operator">&gt;</span> a<span class="punctuation">[</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"h"</span><span class="operator">&gt;</span> <span class="operator">&gt;</span> a<span class="punctuation">[</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">)</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"k"</span> <span class="string">"h"</span> <span class="string">"c"</span><span class="operator">&gt;</span> <span class="operator">&gt;</span> a<span class="punctuation">[</span><span class="number">2</span><span class="operator">:</span><span class="number">6</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"j"</span> <span class="string">"h"</span> <span class="string">"a"</span> <span class="string">"c"</span> <span class="string">"m"</span></code></pre><p>最后一个语句中使用的冒号用于生成一个数值序列。例如，a &lt;- c(2:6) 等价于 a &lt;- c(2, 3, 4, 5, 6)。</p><pre><code class="highlight R"><span class="operator">&gt;</span> a <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">2</span><span class="operator">:</span><span class="number">6</span><span class="punctuation">)</span><span class="operator">&gt;</span> a<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span></code></pre><h5 id="2-2-2-矩阵">2.2.2 矩阵</h5><p>矩阵是一个二维数组，只是每个元素都拥有相同的模式（数值型、字符型或逻辑型）。可通过函数 matrix() 创建矩阵。一般使用格式为：</p><p>myymatrix &lt;- matrix(vector, nrow=number_of_rows, ncol=number_of_columns,  byrow=logical_value, dimnames=list(char_vector_rownames, char_vector_colnames))</p><p>其中 vector 包含了矩阵的元素，nrow 和 ncol 用以指定行和列的维数，dimnames 包含了可选的、以字符型向量表示的行名和列名。选项 byrow 则表明矩阵应当按行填充（byrow=TRUE） 还是按列填充（byrow=FALSE），默认情况下按列填充。代码清单2-1中的代码演示了matrix 函数的用法。</p><p><strong>代码清单2-1 创建矩阵</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> y <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">20</span><span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">5</span><span class="punctuation">,</span> ncol<span class="operator">=</span><span class="number">4</span><span class="punctuation">)</span><span class="operator">&gt;</span> y     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">1</span>    <span class="number">6</span>   <span class="number">11</span>   <span class="number">16</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">2</span>    <span class="number">7</span>   <span class="number">12</span>   <span class="number">17</span><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">3</span>    <span class="number">8</span>   <span class="number">13</span>   <span class="number">18</span><span class="punctuation">[</span><span class="number">4</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">4</span>    <span class="number">9</span>   <span class="number">14</span>   <span class="number">19</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">5</span>   <span class="number">10</span>   <span class="number">15</span>   <span class="number">20</span><span class="operator">&gt;</span> cells  <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">26</span><span class="punctuation">,</span><span class="number">24</span><span class="punctuation">,</span><span class="number">68</span><span class="punctuation">)</span><span class="operator">&gt;</span> rnames  <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"R1"</span><span class="punctuation">,</span> <span class="string">"R2"</span><span class="punctuation">)</span><span class="operator">&gt;</span> cnames  <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"C1"</span><span class="punctuation">,</span> <span class="string">"C2"</span><span class="punctuation">)</span><span class="operator">&gt;</span> mymatrix <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span>cells<span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> ncol<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> byrow<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> <span class="built_in">dimnames</span><span class="operator">=</span><span class="built_in">list</span><span class="punctuation">(</span>rnames<span class="punctuation">,</span> cnames<span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">&gt;</span> mymatrix   C1 C2R1  <span class="number">1</span> <span class="number">26</span>R2 <span class="number">24</span> <span class="number">68</span><span class="operator">&gt;</span> mymatrix <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span>cells<span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> ncol<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> byrow<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">,</span> <span class="built_in">dimnames</span><span class="operator">=</span><span class="built_in">list</span><span class="punctuation">(</span>rnames<span class="punctuation">,</span> cnames<span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">&gt;</span> mymatrix   C1 C2R1  <span class="number">1</span> <span class="number">24</span>R2 <span class="number">26</span> <span class="number">68</span></code></pre><img src="/medias/image-20210814104127943.png" alt="变量信息" style="zoom:67%;"><p>我们首先创建了一个 5×4 的矩阵，接着创建了一个 2×2 的含列名标签的矩阵，并按行进行填充，最后创建了一个 2×2 的矩阵并按列进行了填充。</p><p>我们可以使用下标和方括号来选择矩阵中的行、列或元素。X[i,] 指矩阵 X 中的第 i 行，X[,j] 指第j列，X[i, j] 指第 i 行第 j 个元素。选择多行或多列时，下标i和j可为数值型向量，如代码清单2-2 所示。</p><p><strong>代码清单2-2 矩阵下标的使用</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> x <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">&gt;</span> x     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">1</span>    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span>    <span class="number">9</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span>   <span class="number">10</span><span class="operator">&gt;</span> x<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span>  <span class="number">2</span>  <span class="number">4</span>  <span class="number">6</span>  <span class="number">8</span> <span class="number">10</span><span class="operator">&gt;</span> x<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">3</span> <span class="number">4</span><span class="operator">&gt;</span> x<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">7</span><span class="operator">&gt;</span> x<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">)</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">7</span> <span class="number">9</span></code></pre><img src="/medias/image-20210814104636694.png" alt="变量信息" style="zoom:67%;"><p>首先，我们创建了一个内容为数字 1 到 10 的 2×5 矩阵。默认情况下，矩阵按列填充。然后，我们分别选择了第二行和第二列的元素。接着，又选择了第一行第四列的元素。最后选择了位于第一行第四、第五列的元素。</p><p>矩阵都是二维的，和向量类似，矩阵中也仅能包含一种数据类型。当维度超过2时，不妨使用数组（2.2.3 节）。当有多种模式的数据时，你们可以使用数据框（2.2.4 节）。</p><h5 id="2-2-3-数组">2.2.3 数组</h5><p>数组（array）与矩阵类似，但是维度可以大于 2。数组可通过 array 函数创建，形式如下：</p><p>myarray &lt;- array(vector, dimensions, dimnames)</p><p>其中 vector 包含了数组中的数据， dimensions 是一个数值型向量，给出了各个维度下标的最大值，而 dimnames 是可选的、各维度名称标签的列表。代码清单2-3 给出了一个创建三维（2×3×4） 数值型数组的示例。</p><p><strong>代码清单2-3 创建一个数组</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> dim1 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"A1"</span><span class="punctuation">,</span> <span class="string">"A2"</span><span class="punctuation">)</span><span class="operator">&gt;</span> dim2 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"B1"</span><span class="punctuation">,</span> <span class="string">"B2"</span><span class="punctuation">,</span> <span class="string">"B3"</span><span class="punctuation">)</span><span class="operator">&gt;</span> dim3 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"C1"</span><span class="punctuation">,</span> <span class="string">"C2"</span><span class="punctuation">,</span> <span class="string">"C3"</span><span class="punctuation">,</span> <span class="string">"C4"</span><span class="punctuation">)</span><span class="operator">&gt;</span> z <span class="operator">&lt;-</span> array<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">24</span><span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">)</span><span class="punctuation">,</span> <span class="built_in">dimnames</span><span class="operator">=</span><span class="built_in">list</span><span class="punctuation">(</span>dim1<span class="punctuation">,</span> dim2<span class="punctuation">,</span> dim3<span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">&gt;</span> z<span class="punctuation">,</span> <span class="punctuation">,</span> C1   B1 B2 B3A1  <span class="number">1</span>  <span class="number">3</span>  <span class="number">5</span>A2  <span class="number">2</span>  <span class="number">4</span>  <span class="number">6</span><span class="punctuation">,</span> <span class="punctuation">,</span> C2   B1 B2 B3A1  <span class="number">7</span>  <span class="number">9</span> <span class="number">11</span>A2  <span class="number">8</span> <span class="number">10</span> <span class="number">12</span><span class="punctuation">,</span> <span class="punctuation">,</span> C3   B1 B2 B3A1 <span class="number">13</span> <span class="number">15</span> <span class="number">17</span>A2 <span class="number">14</span> <span class="number">16</span> <span class="number">18</span><span class="punctuation">,</span> <span class="punctuation">,</span> C4   B1 B2 B3A1 <span class="number">19</span> <span class="number">21</span> <span class="number">23</span>A2 <span class="number">20</span> <span class="number">22</span> <span class="number">24</span></code></pre><p>如你所见，数组是矩阵的一个自然推广。它们在编写新的统计方法时可能很有用。像矩阵一样，数组中的数据也只能拥有一种模式。从数组中选取元素的方式与矩阵相同。上例中，元素z[1,2,3]为15。</p><h5 id="2-2-4-数据框">2.2.4  数据框</h5><p>由于不同的列可以包含不同模式（数值型、字符型等）的数据，数据框的概念较矩阵来说更为一般。它与你通常在 SAS、SPSS 和 Stata 中看到的数据集类似。数据框将是你在 R 中最常处理的数据结构。</p><p>表2-1 所示的病例数据集包含了数值型和字符型数据。由于数据有多种模式，无法将此数据集放入一个矩阵。在这种情况下，使用数据框是最佳选择。</p><p>数据框可通过函数 data.frame() 创建：</p><p>mydata &lt;- data.frame(col1, col2, col3,…)</p><p>其中的列向量 col1、col2、col3 等可为任何类型（如字符型、数值型或逻辑型）。每一列的名称可由函数 names 指定。代码清单2-4 清晰地展示了相应用法。</p><p><strong>代码清单2-4 创建一个数据框</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> patientID <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">)</span><span class="operator">&gt;</span> age <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">25</span><span class="punctuation">,</span> <span class="number">34</span><span class="punctuation">,</span> <span class="number">28</span><span class="punctuation">,</span> <span class="number">52</span><span class="punctuation">)</span><span class="operator">&gt;</span> diabetes <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"Type1"</span><span class="punctuation">,</span> <span class="string">"Type2"</span><span class="punctuation">,</span> <span class="string">"Type1"</span><span class="punctuation">,</span> <span class="string">"Type1"</span><span class="punctuation">)</span><span class="operator">&gt;</span> status <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"Poor"</span><span class="punctuation">,</span> <span class="string">"Improved"</span><span class="punctuation">,</span> <span class="string">"Excellent"</span><span class="punctuation">,</span> <span class="string">"Poor"</span><span class="punctuation">)</span><span class="operator">&gt;</span> patientdata <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>patientID<span class="punctuation">,</span> age<span class="punctuation">,</span> diabetes<span class="punctuation">,</span> status<span class="punctuation">)</span><span class="operator">&gt;</span> patientdata  patientID age diabetes    status<span class="number">1</span>         <span class="number">1</span>  <span class="number">25</span>    Type1      Poor<span class="number">2</span>         <span class="number">2</span>  <span class="number">34</span>    Type2  Improved<span class="number">3</span>         <span class="number">3</span>  <span class="number">28</span>    Type1 Excellent<span class="number">4</span>         <span class="number">4</span>  <span class="number">52</span>    Type1      Poor</code></pre> <img src="/medias/image-20210814105939906.png" alt="变量信息" style="zoom: 80%;"><p>每一列数据的模式必须唯一，不过你却可以将多个模式的不同列放到一起组成数据框。由于数据框与分析人员通常设想的数据集的形态较为接近，我们在讨论数据框时将交替使用术语列和变量。</p><p>选取数据框中元素的方式有若干种。你可以使用前述（如矩阵中的）下标记号，亦可直接指定列名。代码清单2-5使用之前创建的 patientdata 数据框演示了这些方式。</p><p>代码清单2-5 选取数据框中的元素</p><pre><code class="highlight R"><span class="operator">&gt;</span> patientdata<span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">2</span><span class="punctuation">]</span>  patientID age<span class="number">1</span>         <span class="number">1</span>  <span class="number">25</span><span class="number">2</span>         <span class="number">2</span>  <span class="number">34</span><span class="number">3</span>         <span class="number">3</span>  <span class="number">28</span><span class="number">4</span>         <span class="number">4</span>  <span class="number">52</span></code></pre><pre><code class="highlight R"><span class="operator">&gt;</span> patientdata<span class="punctuation">[</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"diabetes"</span><span class="punctuation">,</span> <span class="string">"status"</span><span class="punctuation">)</span><span class="punctuation">]</span>   diabetes    status<span class="number">1</span>    Type1      Poor<span class="number">2</span>    Type2  Improved<span class="number">3</span>    Type1 Excellent<span class="number">4</span>    Type1      Poor</code></pre><pre><code class="highlight R"><span class="operator">&gt;</span> patientdata<span class="operator">$</span>age<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">25</span> <span class="number">34</span> <span class="number">28</span> <span class="number">52</span></code></pre><p>表示 <strong>patientdata</strong> 数据框中的变量 <strong>age</strong></p><p>第三个例子中的记号$是新出现的。它被用来选取一个给定数据框中的某个特定变量。例如，如果你想生成糖尿病类型变量 diabetes 和病情变量 status 的列联表，使用以下代码即可：</p><pre><code class="highlight R"><span class="operator">&gt;</span> table<span class="punctuation">(</span>patientdata<span class="operator">$</span>diabetes<span class="punctuation">,</span> patientdata<span class="operator">$</span>status<span class="punctuation">)</span>               Excellent Improved Poor  Type1         <span class="number">1</span>        <span class="number">0</span>    <span class="number">2</span>  Type2         <span class="number">0</span>        <span class="number">1</span>    <span class="number">0</span></code></pre><p>在每个变量名前都键入一次 patientdata$ 可能会让人生厌，所以不妨走一些捷径。可以联合使用函数 attach() 和 detach() 或单独使用函数 with() 来简化代码。</p><p><strong>1.</strong>  <strong>attach()</strong>、<strong>detach()<strong>和</strong>with()</strong></p><p>函数 attach() 可将数据框添加到R的搜索路径中。R在遇到一个变量名以后，将检查搜索路径中的数据框。以第 1 章中的 mtcars 数据框为例，可以使用以下代码获取每加仑行驶英里数（mpg） 变量的描述性统计量，并分别绘制此变量与发动机排量（disp）和车身重量（wt）的散点图：</p><pre><code class="highlight R"><span class="operator">&gt;</span> summary<span class="punctuation">(</span>mtcars<span class="operator">$</span>mpg<span class="punctuation">)</span>    Min. <span class="number">1</span>st Qu.  Median    Mean <span class="number">3</span>rd Qu.    Max.   <span class="number">10.40</span>   <span class="number">15.43</span>   <span class="number">19.20</span>   <span class="number">20.09</span>   <span class="number">22.80</span>   <span class="number">33.90</span></code></pre><pre><code class="highlight R">plot<span class="punctuation">(</span>mtcars<span class="operator">$</span>mpg<span class="punctuation">,</span> mtcars<span class="operator">$</span>disp<span class="punctuation">)</span></code></pre><img src="/medias/image-20210814111100135.png" alt="plot(mtcars$mpg, mtcars$disp)" style="zoom:67%;"><pre><code class="highlight R">plot<span class="punctuation">(</span>mtcars<span class="operator">$</span>mpg<span class="punctuation">,</span> mtcars<span class="operator">$</span>wt<span class="punctuation">)</span></code></pre><img src="/medias/image-20210814111138852.png" alt="plot(mtcars$mpg, mtcars$wt)" style="zoom:67%;"><p>以上代码也可写成：</p><pre><code class="highlight R"><span class="operator">&gt;</span> attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span> <span class="operator">&gt;</span> summary<span class="punctuation">(</span>mpg<span class="punctuation">)</span>   Min. <span class="number">1</span>st Qu.  Median    Mean <span class="number">3</span>rd Qu.    Max.   <span class="number">10.40</span>   <span class="number">15.43</span>   <span class="number">19.20</span>   <span class="number">20.09</span>   <span class="number">22.80</span>   <span class="number">33.90</span></code></pre><pre><code class="highlight R">plot<span class="punctuation">(</span>mpg<span class="punctuation">,</span> disp<span class="punctuation">)</span></code></pre><img src="/medias/image-20210814111356333.png" alt="plot(mpg, disp) " style="zoom:67%;"><pre><code class="highlight R">plot<span class="punctuation">(</span>mpg<span class="punctuation">,</span> wt<span class="punctuation">)</span></code></pre><img src="/medias/image-20210814111415786.png" alt="plot(mpg, wt)" style="zoom:67%;"><pre><code class="highlight R">detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre><p>函数 detach() 将数据框从搜索路径中移除。值得注意的是，detach() 并不会对数据框本身做任何处理。这句是可以省略的，但其实它应当被例行地放入代码中，因为这是一个好的编程习惯。（接下来的几章中，为了保持代码片段的简约和简短，可能会不时地忽略这条良训。）</p><p>当名称相同的对象不止一个时，这种方法的局限性就很明显了。考虑以下代码：</p><pre><code class="highlight R"><span class="operator">&gt;</span> mpg <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">25</span><span class="punctuation">,</span> <span class="number">36</span><span class="punctuation">,</span> <span class="number">47</span><span class="punctuation">)</span><span class="operator">&gt;</span> attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>The following object is masked _by_ .GlobalEnv<span class="operator">:</span>    mpg<span class="operator">&gt;</span> plot<span class="punctuation">(</span>mpg<span class="punctuation">,</span> wt<span class="punctuation">)</span>Error <span class="keyword">in</span> xy.coords<span class="punctuation">(</span>x<span class="punctuation">,</span> y<span class="punctuation">,</span> xlabel<span class="punctuation">,</span> ylabel<span class="punctuation">,</span> <span class="built_in">log</span><span class="punctuation">)</span> <span class="operator">:</span>   <span class="string">'x'</span> and <span class="string">'y'</span> lengths differ<span class="operator">&gt;</span> mpg<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">25</span> <span class="number">36</span> <span class="number">47</span></code></pre><p>这里，在数据框 mtcars 被绑定（attach）之前，你们的环境中已经有了一个名为 mpg 的对象。在这种情况下，原始对象将取得优先权，这与你们想要的结果有所出入。由于 mpg 中有 3 个元素而 disp 中有 32 个元素，故 plot 语句出错。函数 attach() 和 detach() 最好在你分析一个单独的数据框，并且不太可能有多个同名对象时使用。任何情况下，都要当心那些告知某个对象已被屏蔽（masked）的警告。</p><p>除此之外，另一种方式是使用函数 with()。可以这样重写上例：</p><pre><code class="highlight R">with<span class="punctuation">(</span>mtcars<span class="punctuation">,</span> <span class="punctuation">{</span> print<span class="punctuation">(</span>summary<span class="punctuation">(</span>mpg<span class="punctuation">)</span><span class="punctuation">)</span> plot<span class="punctuation">(</span>mpg<span class="punctuation">,</span> disp<span class="punctuation">)</span> plot<span class="punctuation">(</span>mpg<span class="punctuation">,</span> wt<span class="punctuation">)</span><span class="punctuation">}</span><span class="punctuation">)</span></code></pre><p>在这种情况下，花括号 {} 之间的语句都针对数据框 mtcars 执行，这样就无需担心名称冲突了。如果仅有一条语句（例如 summary(mpg)），那么花括号 {} 可以省略。</p><p>函数 with() 的局限性在于，赋值仅在此函数的括号内生效。考虑以下代码：</p><pre><code class="highlight R"><span class="operator">&gt;</span> with<span class="punctuation">(</span>mtcars<span class="punctuation">,</span> <span class="punctuation">{</span><span class="operator">+</span>     stats <span class="operator">&lt;-</span> summary<span class="punctuation">(</span>mpg<span class="punctuation">)</span><span class="operator">+</span>     stats<span class="operator">+</span> <span class="punctuation">}</span><span class="punctuation">)</span>   Min. <span class="number">1</span>st Qu.  Median    Mean <span class="number">3</span>rd Qu.    Max.   <span class="number">10.40</span>   <span class="number">15.43</span>   <span class="number">19.20</span>   <span class="number">20.09</span>   <span class="number">22.80</span>   <span class="number">33.90</span> <span class="operator">&gt;</span> statsError<span class="operator">:</span> object <span class="string">'stats'</span> not found</code></pre><p>如果你需要创建在 with() 结构以外存在的对象，使用特殊赋值符 &lt;&lt;- 替代标准赋值符（&lt;-） 即可，它可将对象保存到 with() 之外的全局环境中。这一点可通过以下代码阐明：</p><pre><code class="highlight R"><span class="operator">&gt;</span> with<span class="punctuation">(</span>mtcars<span class="punctuation">,</span> <span class="punctuation">{</span><span class="operator">+</span>     nokeepstats <span class="operator">&lt;-</span> summary<span class="punctuation">(</span>mpg<span class="punctuation">)</span> <span class="operator">+</span>     keepstats <span class="operator">&lt;&lt;-</span> summary<span class="punctuation">(</span>mpg<span class="punctuation">)</span><span class="operator">+</span> <span class="punctuation">}</span><span class="punctuation">)</span><span class="operator">&gt;</span> nokeepstatsError<span class="operator">:</span> object <span class="string">'nokeepstats'</span> not found<span class="operator">&gt;</span> keepstats   Min. <span class="number">1</span>st Qu.  Median    Mean <span class="number">3</span>rd Qu.    Max.   <span class="number">10.40</span>   <span class="number">15.43</span>   <span class="number">19.20</span>   <span class="number">20.09</span>   <span class="number">22.80</span>   <span class="number">33.90</span></code></pre><p>相对于 attach()，多数的 R 书籍更推荐使用 with()。个人认为从根本上说，选择哪一个是自己的偏好问题，并且应当根据你的目的和对于这两个函数含义的理解而定。本书中你们会交替使用这两个函数。</p><p><strong>2.</strong>  <strong>实例标识符</strong></p><p>在病例数据中，病人编号（patientID）用于区分数据集中不同的个体。在R中，实例标识符（case identifier）可通过数据框操作函数中的 rowname 选项指定。例如，语句：</p><pre><code class="highlight R">patientdata <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>patientID<span class="punctuation">,</span> age<span class="punctuation">,</span> diabetes<span class="punctuation">,</span> status<span class="punctuation">,</span> row.names<span class="operator">=</span>patientID<span class="punctuation">)</span></code></pre><p>将 patientID 指定为 R 中标记各类打印输出和图形中实例名称所用的变量。</p><h5 id="2-2-5-因子">2.2.5   因子</h5><p>如你所见，变量可归结为名义型、有序型或连续型变量。名义型变量是没有顺序之分的类别变量。糖尿病类型 Diabetes（Type1、Type2）是名义型变量的一例。即使在数据中 Type1 编码为 1 而 Type2 编码为 2，这也并不意味着二者是有序的。有序型变量表示一种顺序关系，而非数量关系。病情Status（poor、improved、excellent）是顺序型变量的一个上佳示例。我们明白，病情为poor（较差）病人的状态不如 improved（病情好转）的病人，但并不知道相差多少。连续型变量可以呈现为某个范围内的任意值，并同时表示了顺序和数量。年龄 Age 就是一个连续型变量，它能够表示像 14.5 或 22.8 这样的值以及其间的其他任意值。很清楚，15 岁的人比 14 岁的人年长一岁。</p><p>类别（名义型）变量和有序类别（有序型）变量在R中称为因子（factor）。因子在R中非常重要，因为它决定了数据的分析方式以及如何进行视觉呈现。你将在本书中通篇看到这样的例子。</p><p>函数 factor() 以一个整数向量的形式存储类别值，整数的取值范围是 [1…<em>k</em>]（其中 k 是名义型变量中唯一值的个数），同时一个由字符串（原始值）组成的内部向量将映射到这些整数上。</p><p>举例来说，假设有向量：</p><pre><code class="highlight R">diabetes <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"Type1"</span><span class="punctuation">,</span> <span class="string">"Type2"</span><span class="punctuation">,</span> <span class="string">"Type1"</span><span class="punctuation">,</span> <span class="string">"Type1"</span><span class="punctuation">)</span></code></pre><p>语句 diabetes &lt;- factor(diabetes) 将此向量存储为 (1, 2, 1, 1)，并在内部将其关联为</p><p>1=Type1和2=Type2（具体赋值根据字母顺序而定）。针对向量 diabetes 进行的任何分析都会将其作为名义型变量对待，并自动选择适合这一测量尺度①的统计方法。</p><p>① 这里的测量尺度是指定类尺度、定序尺度、定距尺度、定比尺度中的定类尺度。</p><p>要表示有序型变量，需要为函数 factor() 指定参数 ordered=TRUE。给定向量：</p><pre><code class="highlight R">status <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"Poor"</span><span class="punctuation">,</span> <span class="string">"Improved"</span><span class="punctuation">,</span> <span class="string">"Excellent"</span><span class="punctuation">,</span> <span class="string">"Poor"</span><span class="punctuation">)</span></code></pre><p>语句 status &lt;- factor(status, ordered=TRUE) 会将向量编码为 (3, 2, 1, 3)，并在内部将这些值关联为1=Excellent、2=Improved 以及 3=Poor。另外，针对此向量进行的任何分析都会将其作为有序型变量对待，并自动选择合适的统计方法。</p><p>对于字符型向量，因子的水平默认依字母顺序创建。这对于因子status是有意义的，因为 “Excellent” “Improved” “Poor” 的排序方式恰好与逻辑顺序相一致。如果 “Poor” 被编码为 “Ailing”，会有问题，因为顺序将为 “Ailing” “Excellent” “Improved”。如果理想中的顺序是 “Poor” “Improved” “Excellent”，则会出现类似的问题。按默认的字母顺序排序的因子很少能够让人满意。</p><p>你可以通过指定 levels 选项来覆盖默认排序。例如：</p><p>status &lt;- factor(status, order=TRUE, levels=c(“Poor”, “Improved”, “Excellent”))</p><p>各水平的赋值将为 1=Poor、2=Improved、3=Excellent。请保证指定的水平与数据中的真实值相匹配，因为任何在数据中出现而未在参数中列举的数据都将被设为缺失值。</p><p>数值型变量可以用 levels 和 labels 参数来编码成因子。如果男性被编码成 1，女性被编码成 2，则以下语句：</p><p>sex &lt;- factor(sex, levels=c(1, 2), labels=c(“Male”, “Female”))</p><p>把变量转换成一个无序因子。注意到标签的顺序必须和水平相一致。在这个例子中，性别将被当成类别型变量，标签 “Male” 和 “Female” 将替代 1 和 2 在结果中输出，而且所有不是 1 或 2 的性别变量将被设为缺失值。</p><p>代码清单2-6 演示了普通因子和有序因子的不同是如何影响数据分析的。</p><p><strong>代码清单2-6 因子的使用</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> patientID <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">)</span> <span class="operator">&gt;</span> age <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">25</span><span class="punctuation">,</span> <span class="number">34</span><span class="punctuation">,</span> <span class="number">28</span><span class="punctuation">,</span> <span class="number">52</span><span class="punctuation">)</span><span class="operator">&gt;</span> diabetes <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"Type1"</span><span class="punctuation">,</span> <span class="string">"Type2"</span><span class="punctuation">,</span> <span class="string">"Type1"</span><span class="punctuation">,</span> <span class="string">"Type1"</span><span class="punctuation">)</span><span class="operator">&gt;</span> status <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"Poor"</span><span class="punctuation">,</span> <span class="string">"Improved"</span><span class="punctuation">,</span> <span class="string">"Excellent"</span><span class="punctuation">,</span> <span class="string">"Poor"</span><span class="punctuation">)</span>   <span class="comment"># 以向量形式输入数据</span><span class="operator">&gt;</span> diabetes <span class="operator">&lt;-</span> factor<span class="punctuation">(</span>diabetes<span class="punctuation">)</span><span class="operator">&gt;</span> status <span class="operator">&lt;-</span> factor<span class="punctuation">(</span>status<span class="punctuation">,</span> order<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span><span class="operator">&gt;</span> patientdata <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>patientID<span class="punctuation">,</span> age<span class="punctuation">,</span> diabetes<span class="punctuation">,</span> status<span class="punctuation">)</span><span class="operator">&gt;</span> str<span class="punctuation">(</span>patientdata<span class="punctuation">)</span><span class="comment"># 显示对象的结构</span><span class="string">'data.frame'</span><span class="operator">:</span><span class="number">4</span> obs. of  <span class="number">4</span> variables<span class="operator">:</span> <span class="operator">$</span> patientID<span class="operator">:</span> num  <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="operator">$</span> age      <span class="operator">:</span> num  <span class="number">25</span> <span class="number">34</span> <span class="number">28</span> <span class="number">52</span> <span class="operator">$</span> diabetes <span class="operator">:</span> Factor w<span class="operator">/</span> <span class="number">2</span> levels <span class="string">"Type1"</span><span class="punctuation">,</span><span class="string">"Type2"</span><span class="operator">:</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="operator">$</span> status   <span class="operator">:</span> Ord.factor w<span class="operator">/</span> <span class="number">3</span> levels <span class="string">"Excellent"</span><span class="operator">&lt;</span><span class="string">"Improved"</span><span class="operator">&lt;</span>..<span class="operator">:</span> <span class="number">3</span> <span class="number">2</span> <span class="number">1</span> <span class="number">3</span><span class="operator">&gt;</span> summary<span class="punctuation">(</span>patientdata<span class="punctuation">)</span><span class="comment"># 显示对象的统计概要</span>   patientID         age         diabetes       status  Min.   <span class="operator">:</span><span class="number">1.00</span>   Min.   <span class="operator">:</span><span class="number">25.00</span>   Type1<span class="operator">:</span><span class="number">3</span>   Excellent<span class="operator">:</span><span class="number">1</span>   <span class="number">1</span>st Qu.<span class="operator">:</span><span class="number">1.75</span>   <span class="number">1</span>st Qu.<span class="operator">:</span><span class="number">27.25</span>   Type2<span class="operator">:</span><span class="number">1</span>   Improved <span class="operator">:</span><span class="number">1</span>   Median <span class="operator">:</span><span class="number">2.50</span>   Median <span class="operator">:</span><span class="number">31.00</span>             Poor     <span class="operator">:</span><span class="number">2</span>   Mean   <span class="operator">:</span><span class="number">2.50</span>   Mean   <span class="operator">:</span><span class="number">34.75</span>                           <span class="number">3</span>rd Qu.<span class="operator">:</span><span class="number">3.25</span>   <span class="number">3</span>rd Qu.<span class="operator">:</span><span class="number">38.50</span>                           Max.   <span class="operator">:</span><span class="number">4.00</span>   Max.   <span class="operator">:</span><span class="number">52.00</span></code></pre><img src="/medias/image-20210814113837729.png" alt="变量信息" style="zoom:67%;"><p>首先，以向量的形式输入数据。然后，将 diabetes 和 status 分别指定为一个普通因子和一个有序型因子。最后，将数据合并为一个数据框。函数 str(object) 可提供R中某个对象（本例中为数据框）的信息。它清楚地显示diabetes 是一个因子，而 status 是一个有序型因子， 以及此数据框在内部是如何进行编码的。注意，函数 summary() 会区别对待各个变量。它显示了连续型变量 age 的最小值、最大值、均值和各四分位数，并显示了类别型变量 diabetes 和 status（各水平）的频数值。</p><h5 id="2-2-6-列表">2.2.6 列表</h5><p>列表（list）是 R 的数据类型中最为复杂的一种。一般来说，列表就是一些对象（或成分，component）的有序集合。列表允许你整合若干（可能无关的）对象到单个对象名下。例如，某个列表中可能是若干向量、矩阵、数据框，甚至其他列表的组合。可以使用函数 list() 创建列表：</p><pre><code class="highlight R">mylist <span class="operator">&lt;-</span> <span class="built_in">list</span><span class="punctuation">(</span>object1<span class="punctuation">,</span> object2<span class="punctuation">,</span> ...<span class="punctuation">)</span></code></pre><p>其中的对象可以是目前为止讲到的任何结构。你还可以为列表中的对象命名：</p><pre><code class="highlight R">mylist <span class="operator">&lt;-</span> <span class="built_in">list</span><span class="punctuation">(</span>name1<span class="operator">=</span>object1<span class="punctuation">,</span> name2<span class="operator">=</span>object2<span class="punctuation">,</span> ...<span class="punctuation">)</span></code></pre><p>代码清单2-7展示了一个例子。</p><p><strong>代码清单2-7 创建一个列表</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> g <span class="operator">&lt;-</span> <span class="string">"My First List"</span><span class="operator">&gt;</span> h <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">25</span><span class="punctuation">,</span> <span class="number">26</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">39</span><span class="punctuation">)</span><span class="operator">&gt;</span> j <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">5</span><span class="punctuation">)</span><span class="operator">&gt;</span> k <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"one"</span><span class="punctuation">,</span> <span class="string">"two"</span><span class="punctuation">,</span> <span class="string">"three"</span><span class="punctuation">)</span><span class="operator">&gt;</span> mylist <span class="operator">&lt;-</span> <span class="built_in">list</span><span class="punctuation">(</span>title<span class="operator">=</span>g<span class="punctuation">,</span> ages<span class="operator">=</span>h<span class="punctuation">,</span> j<span class="punctuation">,</span> k<span class="punctuation">)</span>   <span class="comment"># 创建列表</span><span class="operator">&gt;</span> mylist<span class="comment"># 输出整个列表</span><span class="operator">$</span>title<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"My First List"</span><span class="operator">$</span>ages<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">25</span> <span class="number">26</span> <span class="number">18</span> <span class="number">39</span><span class="punctuation">[[</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">]</span>     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span> <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">1</span>    <span class="number">6</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">2</span>    <span class="number">7</span><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">3</span>    <span class="number">8</span><span class="punctuation">[</span><span class="number">4</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">4</span>    <span class="number">9</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">,</span><span class="punctuation">]</span>    <span class="number">5</span>   <span class="number">10</span><span class="punctuation">[[</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"one"</span>   <span class="string">"two"</span>   <span class="string">"three"</span><span class="operator">&gt;</span> mylist<span class="punctuation">[[</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="comment"># 输出第二个成分</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">25</span> <span class="number">26</span> <span class="number">18</span> <span class="number">39</span><span class="operator">&gt;</span> mylist<span class="punctuation">[[</span><span class="string">"ages"</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">25</span> <span class="number">26</span> <span class="number">18</span> <span class="number">39</span></code></pre><img src="/medias/image-20210814115028147.png" alt="变量信息" style="zoom:67%;"><p>本例创建了一个列表，其中有四个成分：一个字符串、一个数值型向量、一个矩阵以及一个字符型向量。可以组合任意多的对象，并将它们保存为一个列表。</p><p>你也可以通过在双重方括号中指明代表某个成分的数字或名称来访问列表中的元素。此例中， mylist[[2]] 和mylist[[“ages”]] 均指那个含有四个元素的向量。对于命名成分，</p><p>mylist$ages 也可以正常运行。由于两个原因，列表成为了 R 中的重要数据结构。首先，列表允许以一种简单的方式组织和重新调用不相干的信息。其次，许多R函数的运行结果都是以列表的形式返回的。需要取出其中哪些成分由分析人员决定。你将在后续各章发现许多返回列表的函数示例。</p><pre><code class="highlight plaintext">提醒程序员注意的一些事项经验丰富的程序员通常会发现R语言的某些方面不太寻常。以下是这门语言中你需要了解的一些特性。❑ 对象名称中的句点（.）没有特殊意义，但美元符号（$）却有着和其他语言中的句点类似的含义，即指定一个数据框或列表中的某些部分。例如，A$x 是指数据框 A 中的变量x。❑ R 不提供多行注释或块注释功能。你必须以 # 作为多行注释每行的开始。出于调试目的， 你也可以把想让解释器忽略的代码放到语句 if(FALSE){... } 中。将 FALSE 改为TRUE 即允许这块代码执行。❑ 将一个值赋给某个向量、矩阵、数组或列表中一个不存在的元素时，R 将自动扩展这个数据结构以容纳新值。举例来说，考虑以下代码：&gt; x &lt;- c(8, 6, 4)&gt; x[7] &lt;- 10&gt; x[1] 8 6 4 NA NA NA 10通过赋值，向量 x 由三个元素扩展到了七个元素。x &lt;- x[1:3] 会重新将其缩减回三个元素。❑ R 中没有标量。标量以单元素向量的形式出现。❑ R 中的下标不从 0 开始，而从 1 开始。在上述向量中，x[1] 的值为 8。❑ 变量无法被声明。它们在首次被赋值时生成。要了解更多，参阅 John Cook 的优秀博文 “R programming for those coming from other languages”(http://www.johndcook.com/Rlanguagefor_programmers.html)）。那些正在寻找编码风格指南的程序员不妨看看“Google’s R Style Guide”①(http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html）。① 搜索“来自Google的R语言编码风格指南”可以找到这份文档的中文版。</code></pre><h4 id="2-3-数据的输入">2.3 数据的输入</h4><p>现在你已经掌握了各种数据结构，可以放一些数据进去了。作为一名数据分析人员，你通常会面对来自多种数据源和数据格式的数据，你的任务是将这些数据导入你的工具，分析数据，并汇报分析结果。R提供了适用范围广泛的数据导入工具。向R中导入数据的权威指南参见可在<a href="http://cran.r-project.org/doc/manuals/R-data.pdf">http://cran.r-project.org/doc/manuals/R-data.pdf </a> 下载的R <em>Data Import/Export</em>手册②。</p><p>② 此手册对应的中译名为《R数据的导入和导出》，可在网上找到。</p><p>如图2-2 所示，R 可从键盘、文本文件、Microsoft Excel 和 Access、流行的统计软件、特殊格式的文件、多种关系型数据库管理系统、专业数据库、网站和在线服务中导入数据。由于我们无从得知你的数据将来自何处，故会在下文论及各种数据源。读者按需参阅即可。</p><img src="/medias/image-20210814152820621.png" alt="图2-2 可供 R 导入的数据源" style="zoom:67%;"><h5 id="2-3-1-使用键盘输入数据">2.3.1   使用键盘输入数据</h5><p>也许输入数据最简单的方式就是使用键盘了。有两种常见的方式：用 R 内置的文本编辑器和直接在代码中嵌入数据。我们首先考虑文本编辑器。</p><p>R 中的函数 edit() 会自动调用一个允许手动输入数据的文本编辑器。具体步骤如下：</p><p>(1) 创建一个空数据框（或矩阵），其中变量名和变量的模式需与理想中的最终数据集一致；</p><p>(2) 针对这个数据对象调用文本编辑器，输入你的数据，并将结果保存回此数据对象中。 在下例中，你将创建一个名为 mydata 的数据框，它含有三个变量：age（数值型）、gender</p><p>（字符型）和weight（数值型）。然后你将调用文本编辑器，键入数据，最后保存结果。</p><pre><code class="highlight R">mydata <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>age<span class="operator">=</span>numeric<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span><span class="punctuation">,</span> gender<span class="operator">=</span>character<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span><span class="punctuation">,</span> weight<span class="operator">=</span>numeric<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span><span class="punctuation">)</span>mydata <span class="operator">&lt;-</span> edit<span class="punctuation">(</span>mydata<span class="punctuation">)</span></code></pre><p>类似于 age=numeric(0) 的赋值语句将创建一个指定模式但不含实际数据的变量。注意，编辑的结果需要赋值回对象本身。函数 edit() 事实上是在对象的一个副本上进行操作的。如果你不将其赋值到一个目标，你的所有修改将会全部丢失！</p><p>在 Windows 上调用函数edit()的结果如图2-3 所示。如图2-3 所示，我已经自主添加了一些数据。单击列的标题，你就可以用编辑器修改变量名和变量类型（数值型、字符型）。你还可以通过单击未使用列的标题来添加新的变量。编辑器关闭后，结果会保存到之前赋值的对象中（本例中为 mydata）。再次调用 mydata &lt;- edit(mydata)，就能够编辑已经输入的数据并添加新的数据。语句 mydata &lt;- edit(mydata) 的一种简捷的等价写法是 fix(mydata)。</p><img src="/medias/image-20210814153306041.png" alt="图2-3 通过 Windows 上内建的编辑器输入数据" style="zoom:67%;"><p>此外，你可以直接在你的程序中嵌入数据集。比如说，参见以下代码：</p><pre><code class="highlight R">mydatatxt<span class="operator">&lt;-</span><span class="string">"</span><span class="string">age gender weight</span><span class="string">25 m 166</span><span class="string">30 f 115</span><span class="string">18 f 120</span><span class="string">"</span>mydata<span class="operator">&lt;-</span>read.table<span class="punctuation">(</span>header<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span>text<span class="operator">=</span>mydatatxt<span class="punctuation">)</span>View<span class="punctuation">(</span>mydata<span class="punctuation">)</span></code></pre><p>以上代码创建了和之前用 edit() 函数所创建的一样的数据框。一个字符型变量被创建于存储原始数据，然后 read.table() 函数被用于处理字符串并返回数据框。函数 read.table() 将在下一节描述。</p><p>键盘输入数据的方式在你在处理小数据集的时候很有效。对于较大的数据集，你所期望的也许是我们接下来要介绍的方式：从现有的文本文件、Excel 电子表格、统计软件或数据库中导入数据。</p><h5 id="2-3-2-从带分隔符的文本文件导入数据">2.3.2   从带分隔符的文本文件导入数据</h5><p>你可以使用 read.table() 从带分隔符的文本文件中导入数据。此函数可读入一个表格格式的文件并将其保存为一个数据框。表格的每一行分别出现在文件中每一行。其语法如下：</p><pre><code class="highlight R">mydataframe <span class="operator">&lt;-</span> read.table<span class="punctuation">(</span>file<span class="punctuation">,</span> options<span class="punctuation">)</span></code></pre><p>其中，file 是一个带分隔符的 ASCII 文本文件，options 是控制如何处理数据的选项。表2-2 列出了常见的选项。</p><p><strong>表2-2 函数 read.table() 的选项</strong></p><table><thead><tr><th>选  项</th><th>描  述</th></tr></thead><tbody><tr><td>header</td><td>一个表示文件是否在第一行包含了变量名的逻辑型变量</td></tr><tr><td>sep</td><td>分开数据值的分隔符。默认是 sep=“”，这表示了一个或多个空格、制表符、换行或回车。使用 sep=",“来读取用逗号来分隔行内数据的文件，使用 sep=”\t"来读取使用制表符来分割行内数据的文件</td></tr><tr><td>row.names</td><td>一个用于指定一个或多个行标记符的可选参数</td></tr><tr><td>col.names</td><td>如果数据文件的第一行不包括变量名（header=FASLE），你可以用 col.names 去指定一个包含变量名的字符向量。如果 header=FALSE 以及 col.names 选项被省略了，变量会被分别命名为 V1、V2，以此类推</td></tr><tr><td>na.strings</td><td>可选的用于表示缺失值的字符向量。比如说，na.strings=c(“-9”, “?”) 把 -9 和 ? 值在读取数据的时候转换成 NA</td></tr><tr><td>colClasses</td><td>可选的分配到每一列的类向量。比如说，colClasses=c(“numeric”, “numeric”, “character”, “NULL”, “numeric”) 把前两列读取为数值型变量，把第三列读取为字符型向量，跳过第四列，把第五列读取为数值型向量。如果数据有多余五列，colClasses 的值会被循环。当你在读取大型文本文件的时候，加上 colClasses 选项可以可观地提升处理的速度</td></tr><tr><td>quote</td><td>用于对有特殊字符的字符串划定界限的自负床。默认值是双引号（"）或单引号（'）</td></tr><tr><td>skip</td><td>读取数据前跳过的行的数目。这个选项在跳过头注释的时候比较有用</td></tr><tr><td>stringsAsFactors</td><td>一个逻辑变量，标记处字符向量是否需要转化成因子。默认值是 TRUE，除非它被 colClases 所覆盖。当你在处理大型文本文件的时候，设置成 stringsAsFactors=FALSE 可以提升处理速度</td></tr><tr><td>text</td><td>一个指定文字进行处理的字符串。如果 text 被设置了，file 应该被留空。</td></tr></tbody></table><p>考虑一个名为 studentgrades.csv 的文本文件，它包含了学生在数学、科学、和社会学习的分数。文件中每一行表示一个学生，第一行包含了变量名，用逗号分隔。每一个单独的行都包含了学生的信息，它们也是用逗号进行分隔的。文件的前几行如下：</p><p>StudentID,First,Last,Math,Science,Social Studies</p><p>011,Bob,Smith,90,80,67</p><p>012,Jane,Weary,75,80</p><p>010,Dan,“Thornton, III”,65,75,70</p><p>040,Mary,“O’Leary”,90,95,92</p><p>这个文件可以用以下语句来读入成一个数据框：</p><p>grades &lt;- read.table(“studentgrades.csv”, header=TRUE, row.names=“StudentID”, sep=“,”)</p><p>结果如下：</p><pre><code class="highlight R"><span class="operator">&gt;</span> gradesFirst      Last Math Science Social.Studies<span class="number">11</span>BobSmith<span class="number">90</span><span class="number">80</span><span class="number">67</span><span class="number">12</span>JaneWeary<span class="number">75</span>   <span class="literal">NA</span><span class="number">80</span><span class="number">10</span>DanThornton<span class="punctuation">,</span> III<span class="number">65</span><span class="number">75</span><span class="number">70</span><span class="number">40</span>MaryO<span class="string">'Leary909592</span><span class="string"></span><span class="string">&gt; str(grades)</span><span class="string">'</span>data.frame<span class="string">':  4 obs. of 5 variables:</span><span class="string">$ First     : Factor w/ 4 levels "Bob","Dan","Jane",..: 1 3 2 4</span><span class="string">$ Last     : Factor w/ 4 levels "O'</span>Leary<span class="string">","</span>Smith<span class="string">",..: 2 4 3 1</span><span class="string">$ Math     : int 90 75 65 90</span><span class="string">$ Science    : int 80 NA 75 95</span><span class="string">$ Social.Studies: int 67 80 70 92</span></code></pre><p>如何导入数据有很多有趣的要点。变量名Social Studies被自动地根据R的习惯所重命名。列StudentID现在是行名，不再有标签，也失去了前置的0。Jane的缺失的科学课成绩被正确地识别为缺失值。我不得不在Dan的姓周围用引号包围住，从而能够避免Thornton和III之间的空格。否则，R会在那一行读出七个值而不是六个值。我也在O’Leary左右用引号包围住了，负载R会把单引号读取为分隔符（而这不是我想要的）。最后，姓和名都被转化成为因子。</p><p>默认地，read.table()把字符变量转化为因子，这并不一定都是我们想要的情况。比如说， 很少情况下，我们才会把回答者的评论转化成为因子。你可用多种方法去掉这个行为。加上选项stringsAsFactors=FALSE对所有的字符变量都去掉这个行为。此外，你可以用colClasses 选项去对每一列都指定一个类（比如说，逻辑型、数值型、字符型或因子型）。</p><p>用以下代码导入同一个函数：</p><pre><code class="highlight R">grades <span class="operator">&lt;-</span> read.table<span class="punctuation">(</span><span class="string">"studentgrades.csv"</span><span class="punctuation">,</span> header<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> row.names<span class="operator">=</span><span class="string">"StudentID"</span><span class="punctuation">,</span> sep<span class="operator">=</span><span class="string">","</span><span class="punctuation">,</span> colClasses<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"character"</span><span class="punctuation">,</span> <span class="string">"character"</span><span class="punctuation">,</span> <span class="string">"character"</span><span class="punctuation">,</span> <span class="string">"numeric"</span><span class="punctuation">,</span> <span class="string">"numeric"</span><span class="punctuation">,</span> <span class="string">"numeric"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>得到以下数据框：</p><pre><code class="highlight r"><span class="operator">&gt;</span> gradesFirstLastMathScienceSocial.Studies <span class="number">011</span>BobSmith<span class="number">90</span><span class="number">80</span><span class="number">67</span>             <span class="number">012</span>JaneWeary<span class="number">75</span><span class="literal">NA</span><span class="number">80</span>             <span class="number">010</span>DanThornton<span class="punctuation">,</span> III<span class="number">65</span><span class="number">75</span><span class="number">70</span>             <span class="number">040</span>MaryO<span class="string">'Leary909592  </span><span class="string"></span><span class="string">&gt; str(grades)</span><span class="string">'</span>data.frame<span class="string">':  4 obs. of 5 variables:</span><span class="string">$ First     : chr "Bob" "Jane" "Dan" "Mary"</span><span class="string">$ Last     : chr "Smith" "Weary" "Thornton, III" "O'</span>Leary<span class="string">"</span><span class="string">$ Math     : num 90 75 65 90</span><span class="string">$ Science    : num 80 NA 75 95</span><span class="string">$ Social.Studies: num 67 80 70 92</span></code></pre><p>注意，行名保留了前缀 0，而且 First 和 Last 不再是因子。此外，grades 作为实数而不是整数来进行排序。</p><p>函数 read.table() 还拥有许多微调数据导入方式的追加选项。更多详情，请参阅 help(read.table)。</p><blockquote><p><strong>用连接来导入数据</strong></p><p>本章中的许多示例都是从用户计算机上已经存在的文件中导入数据。R 也提供了若干种通过连接（connection）来访问数据的机制。例如，函数 file()、gzfile()、bzfile()、xzfile()、 unz() 和 url() 可作为文件名参数使用。函数 file() 允许你访问文件、剪贴板和 C 级别的标准输入。函数 gzfile()、bzfile()、xzfile() 和 unz() 允许你读取压缩文件。 函数 url() 能够让你通过一个含有 http://、ftp:// 或 file:// 的完整 URL 访问网络上的文件，还可以为 HTTP 和 FTP 连接指定代理。为了方便，（用双引号围住的）完整的 URL 也经常直接用来代替文件名使用。更多详情，参见 help(file)。</p></blockquote><h5 id="2-3-3-导入-Excel-数据">2.3.3   导入 Excel 数据</h5><p>读取一个 Excel 文件的最好方式，就是在 Excel 中将其导出为一个逗号分隔文件（csv），并使用前文描述的方式将其导入 R 中。此外，你可以用 xlsx 包直接地导入 Excel 工作表。请确保在第一次使用它之前先进行下载和安装。你也需要 xlsxjars 和 rJava 包，以及一个正常工作的Java 安装（<a href="http://java.com/">http://java.com</a>）。</p><p>xlsx 包可以用来对 Excel  97/2000/XP/2003/2007 文件进行读取、写入和格式转换。函数</p><p>read.xlsx()导入一个工作表到一个数据框中。最简单的格式是 read.xlsx(file, <em>n</em>)，其中</p><p>file 是 Excel 工作簿的所在路径，n 则为要导入的工作表序号。举例说明，在 Windows 上，以下代码：</p><pre><code class="highlight r">library<span class="punctuation">(</span>xlsx<span class="punctuation">)</span>workbook <span class="operator">&lt;-</span> <span class="string">"c:/myworkbook.xlsx"</span> mydataframe <span class="operator">&lt;-</span> read.xlsx<span class="punctuation">(</span>workbook<span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span></code></pre><p>从位于 C 盘根目录的工作簿 myworkbook.xlsx 中导入了第一个工作表，并将其保存为一个数据框 mydataframe。</p><p>函数 read.xlsx() 有些选项可以允许你指定工作表中特定的行（rowIndex）和列</p><p>（colIndex），配合上对应每一列的类（colClasses）。对于大型的工作簿（比如说，100 000+个单元格），你也可以使用 read.xlsx2() 函数。这个函数用 Java 来运行更加多的处理过程，因此能够获得可观的质量提升。请查阅 help(read.xlsx) 获得更多细节。</p><p>也有其他包可以帮助你处理 Excel 文件。替代的包包含了 XLConnect 和 openxlsx 包；</p><p>XLConnect 依赖于 Java，不过 openxlsx 并不是。所有这些软件包都可以做比导入数据更加多的事情——它们也可以创建和操作 Excel 文件。那些需要创建 R 和 Excel 之间的接口的程序员应该要仔细查看这些软件包中的一个或多个。</p><h5 id="2-3-4-导入-XML-数据">2.3.4   导入 XML 数据</h5><p>以 XML 格式编码的数据正在逐渐增多。R中有若干用于处理 XML 文件的包。例如，由Duncan Temple Lang 编写的 XML 包允许你读取、写入和操作 XML 文件。XML 格式本身已经超出了本书的范围。对使用 R 存取 XML 文档感兴趣的读者可以参阅 <a href="http://www.omegahat.org/RSXML">www.omegahat.org/RSXML</a>，从中可以找到若干份优秀的软件包文档。</p><h5 id="2-3-5-从网页抓取数据">2.3.5   从网页抓取数据</h5><p>网络上的数据，可以通过所谓Web数据抓取（Webscraping）的过程，或对应用程序接口（application programming interface，API）的使用来获得。</p><p>一般地说，在 Web 数据抓取过程中，用户从互联网上提取嵌入在网页中的信息，并将其保存为 R 中的数据结构以做进一步的分析。比如说，一个网页上的文字可以使用函数 readLines() 来下载到一个R的字符向量中，然后使用如 grep() 和 gsub() 一类的函数处理它。对于结构复杂的网页，可以使用 RCurl 包和 XML 包来提取其中想要的信息。更多信息和示例，请参考网站Programming with R（<a href="http://www.programmingr.com/">www.programmingr.com</a>）上的 “Webscraping using readLines and RCurl” 一文。</p><p>API 指定了软件组件如何互相进行交互。有很多 R 包使用这个方法来从网上资源中获取数据。这些资源包括了生物、医药、地球科学、物理科学、经济学，以及商业、金融、文学、销售、新闻和运动等的数据源。</p><p>比如说，如果你对社交媒体感兴趣，可以用 twitteR 来获取 Twitter 数据，用 Rfacebook来获取 Facebook 数据，用 Rflickr 来获取 Flicker 数据。其他软件包允许你连接上如 Google、Amazon、Dropbox、Salesforce 等所提供的广受欢迎的网上服务。可以查看 CRAN Task View 中的子版块 Web Technologies and Services（<a href="https://cran.r-project.org/web/views/WebTechnologies.html%EF%BC%89%E6%9D%A5%E8%8E%B7%E5%BE%97%E4%B8%80%E4%B8%AA%E5%85%A8%E9%9D%A2%E7%9A%84%E5%88%97%E8%A1%A8%EF%BC%8C%E6%AD%A4%E5%88%97%E8%A1%A8%E5%88%97%E5%87%BA%E4%BA%86%E8%83%BD%E5%B8%AE%E5%8A%A9%E4%BD%A0%E8%8E%B7%E5%8F%96%E7%BD%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%9A%84%E5%90%84%E7%A7%8D">https://cran.r-project.org/web/views/WebTechnologies.html）来获得一个全面的列表，此列表列出了能帮助你获取网上资源的各种</a> R 包。</p><h5 id="2-3-6-导入-SPSS-数据">2.3.6   导入 SPSS 数据</h5><p>IBM SPSS 数据集可以通过 foreign 包中的函数 read.spss() 导入到 R 中，也可以使用Hmisc 包中的 spss.get() 函数。函数 spss.get() 是对 read.spss() 的一个封装，它可以为你自动设置后者的许多参数，让整个转换过程更加简单一致，最后得到数据分析人员所期望的结果。</p><p>首先，下载并安装 Hmisc 包（ foreign 包已被默认安装）：</p><pre><code class="highlight R">install.packages<span class="punctuation">(</span><span class="string">"Hmisc"</span><span class="punctuation">)</span></code></pre><p>然后使用以下代码导入数据：</p><pre><code class="highlight R">library<span class="punctuation">(</span>Hmisc<span class="punctuation">)</span>mydataframe <span class="operator">&lt;-</span> spss.get<span class="punctuation">(</span><span class="string">"mydata.sav"</span><span class="punctuation">,</span> use.value.labels<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span></code></pre><p>这段代码中，mydata.sav 是要导入的 SPSS 数据文件，use.value.labels=TRUE 表示让函数将带有值标签的变量导入为 R 中水平对应相同的因子，mydataframe 是导入后的 R 数据框。</p><h5 id="2-3-7-导入-SAS-数据">2.3.7   导入 SAS 数据</h5><p>R 中设计了若干用来导入 SAS 数据集的函数，包括 foreign 包中的 read.ssd()，Hmisc包中的 sas.get()，以及 sas7bdat 包中的 read.sas7bdat()。如果你安装了 SAS，sas.get() 是一个好的选择。</p><p>比如说，你想导入一个名为 clients.sas7bdat 的 SAS 数据集文件，它位于一台 Windows 机器上的 C:/mydata 文件夹中，以下代码导入了数据，并且保存为一个 R 数据框:</p><pre><code class="highlight R">library<span class="punctuation">(</span>Hmisc<span class="punctuation">)</span>datadir <span class="operator">&lt;-</span> <span class="string">"C:/mydata"</span>sasexe <span class="operator">&lt;-</span> <span class="string">"C:/Program Files/SASHome/SASFoundation/9.4/sas.exe"</span>mydata <span class="operator">&lt;-</span> sas.get<span class="punctuation">(</span>libraryName<span class="operator">=</span>datadir<span class="punctuation">,</span> member<span class="operator">=</span><span class="string">"clients"</span><span class="punctuation">,</span> sasprog<span class="operator">=</span>sasexe<span class="punctuation">)</span></code></pre><p>libraryName 是一个包含了 SAS 数据集的文件夹，member 是数据集名字（去除掉后缀名 sas7bdat），sasprog 是到 SAS 可运行程序的完整路径。有很多可用的选项；查看 help(sas.get) 获得更多细节。</p><p>你也可以在 SAS 中使用 PROC EXPORT 将 SAS 数据集保存为一个逗号分隔的文本文件，并使用 2.3.2 节中叙述的方法将导出的文件读取到 R 中。下面是一个示例：</p><p>SAS程序：</p><pre><code class="highlight SAS"><span class="keyword">libname</span> datadir <span class="string">"C:\mydata"</span>; proc export data=datadir.clientsoutfile=<span class="string">"clients.csv"</span> dbms=csv;<span class="keyword">run;</span></code></pre><p>R程序：</p><pre><code class="highlight R">mydata <span class="operator">&lt;-</span> read.table<span class="punctuation">(</span><span class="string">"clients.csv"</span><span class="punctuation">,</span> header<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> sep<span class="operator">=</span><span class="string">","</span><span class="punctuation">)</span></code></pre><p>前面两种方法要求你安装了一套完整的可运行的 SAS 程序。如果你没有连接 SAS 的途径，函数 read.sas7dbat() 也许是一个好的候选项。这个函数可以直接读取 sas7dbat 格式的 SAS 数据集。这个例子的对应代码是：</p><pre><code class="highlight R">library<span class="punctuation">(</span>sas7bdat<span class="punctuation">)</span>mydata <span class="operator">&lt;-</span> read.sas7bdat<span class="punctuation">(</span><span class="string">"C:/mydata/clients.sas7bdat"</span><span class="punctuation">)</span></code></pre><p>不像 sas.get()，read.sas7dbat() 忽略了 SAS 用户自定义格式。此外，这个函数用了明显更多的时间来进行处理。尽管我使用这个包的时候比较好运，它依然应该被认为是实验性质的。</p><p>最后，一款名为 Stat/Transfer 的商业软件（在 2.3.12 节介绍）可以完好地将 SAS 数据集（包括任何已知的变量格式）保存为R数据框。与 read.sas7dbat() 一样，它也不要求安装 SAS。</p><h5 id="2-3-8-导入-Stata-数据">2.3.8  导入 Stata 数据</h5><p>要将 Stata 数据导入 R 中非常简单直接。所需代码类似于：</p><pre><code class="highlight R">library<span class="punctuation">(</span>foreign<span class="punctuation">)</span>mydataframe <span class="operator">&lt;-</span> read.dta<span class="punctuation">(</span><span class="string">"mydata.dta"</span><span class="punctuation">)</span></code></pre><p>这里，mydata.dta 是 Stata 数据集，mydataframe 是返回的 R 数据框。</p><h5 id="2-3-9-导入-NetCDF-数据">2.3.9  导入 NetCDF 数据</h5><p>Unidata 项目主导的开源软件库 NetCDF（Network Common Data Form，网络通用数据格式） 定义了一种机器无关的数据格式，可用于创建和分发面向数组的科学数据。NetCDF 格式通常用来存储地球物理数据。ncdf 包和 ncdf4 包为 NetCDF 文件提供了高层的 R 接口。</p><p>ncdf 包为通过 Unidata 的 NetCDF 库（版本 3 或更早）创建的数据文件提供了支持，而且在 Windows、Mac OS X 和 Linux 上均可使用。ncdf4 包支持 NetCDF 4 或更早的版本，但在 Windows 上尚不可用。</p><p>考虑如下代码：</p><pre><code class="highlight R">library<span class="punctuation">(</span>ncdf<span class="punctuation">)</span>nc <span class="operator">&lt;-</span> nc_open<span class="punctuation">(</span><span class="string">"mynetCDFfile"</span><span class="punctuation">)</span> myarray <span class="operator">&lt;-</span> get.var.ncdf<span class="punctuation">(</span>nc<span class="punctuation">,</span> myvar<span class="punctuation">)</span></code></pre><p>在本例中，对于包含在 NetCDF 文件 mynetCDFfile 中的变量 myvar，其所有数据都被读取并保存到了一个名为 myarray 的 R 数组中。</p><p>值得注意的是，ncdf 包和 ncdf4 包最近进行了重大升级，使用方式可能与旧版本不同。另外， 这两个包中的函数名称也不同。请阅读在线帮助以了解详情。</p><h5 id="2-3-10-导入-HDF5-数据">2.3.10 导入 HDF5 数据</h5><p>HDF5（Hierarchical Data Format，分层数据格式）是一套用于管理超大型和结构极端复杂数据集的软件技术方案。rhdf5 包为 R 提供了一个 HDF5 的接口。这个包在Bioconductor 网站上而不是 CRAN 上提供。你可以用以下代码对之进行安装：</p><pre><code class="highlight R">source<span class="punctuation">(</span><span class="string">"http://bioconductor.org/biocLite.R"</span><span class="punctuation">)</span>biocLite<span class="punctuation">(</span><span class="string">"rhdf5"</span><span class="punctuation">)</span></code></pre><p>像 XML 一样，HDF5 格式超出了本书的内容范围。如果想学习更多相关知识，可访问HDF Group 网站（ <a href="http://www.hdf5group.org/">http://www.hdf5group.org/ </a>）。由 Bernd Fischer 编写的 <a href="http://www.bioconductor.org/packages/release/bioc/vignettes/rhdf5/inst/doc/rhdf5.pdf%E6%98%AF%E4%B8%80%E4%B8%AA">http://www.bioconductor.org/packages/release/bioc/vignettes/rhdf5/inst/doc/rhdf5.pdf是一个</a> rhdf5 包的优秀指南。</p><h5 id="2-3-11-访问数据库管理系统">2.3.11 访问数据库管理系统</h5><p>R中有多种面向关系型数据库管理系统（DBMS）的接口，包括 Microsoft SQL Server、Microsoft Access、MySQL、Oracle、PostgreSQL、DB2、Sybase、Teradata 以及 SQLite。其中一些包通过原生的数据库驱动来提供访问功能，另一些则是通过 ODBC 或 JDBC 来实现访问的。使用R来访问存储在外部数据库中的数据是一种分析大数据集的有效手段（参见附录F），并且能够发挥 SQL 和 R 各自的优势。</p><p><strong>1. ODBC 接口</strong></p><p>在 R 中通过 RODBC 包访问一个数据库也许是最流行的方式，这种方式允许 R 连接到任意一种拥有 ODBC 驱动的数据库，这包含了前文所列的所有数据库。</p><p>第一步是针对你的系统和数据库类型安装和配置合适的 ODBC 驱动——它们并不是R的一部分。如果你的机器尚未安装必要的驱动，上网搜索一下应该就可以找到。</p><p>针对选择的数据库安装并配置好驱动后， 请安装 RODBC 包。你可以使用命令 install.packages(“RODBC”) 来安装它。RODBC 包中的主要函数列于表2-3 中。</p><p><strong>表2-3  RODBC中的函数</strong></p><table><thead><tr><th>函  数</th><th>描   述</th></tr></thead><tbody><tr><td>odbcConnect(dsn,uid=“”,pwd=“”)</td><td>建立一个到 ODBC 数据库的连接</td></tr><tr><td>sqlFetch(channel,sqltable)</td><td>读取 ODBC 数据库中的某个表到一个数据框中</td></tr><tr><td>sqlQuery(channel,query)</td><td>向 ODBC 数据库提交一个查询并返回结果</td></tr><tr><td>sqlSave(channel,mydf,tablename=sqtable,append=FALSE)</td><td>将数据框写入或更新（append=TRUE）到 ODBC 数据库的某个表中</td></tr><tr><td>sqlDrop(channel,sqtable)</td><td>删除 ODBC 数据库中的某个表</td></tr><tr><td>close(channel)</td><td>关闭连接</td></tr></tbody></table><p>RODBC 包允许 R 和一个通过 ODBC 连接的 SQL 数据库之间进行双向通信。这就意味着你不仅可以读取数据库中的数据到 R 中，同时也可以使用 R 修改数据库中的内容。假设你想将某个数据库中的两个表（Crime和Punishment）分别导入为 R 中的两个名为 crimedat 和 pundat 的数据框，可以通过如下代码完成这个任务：</p><pre><code class="highlight R">library<span class="punctuation">(</span>RODBC<span class="punctuation">)</span>myconn <span class="operator">&lt;-</span>odbcConnect<span class="punctuation">(</span><span class="string">"mydsn"</span><span class="punctuation">,</span> uid<span class="operator">=</span><span class="string">"Rob"</span><span class="punctuation">,</span> pwd<span class="operator">=</span><span class="string">"aardvark"</span><span class="punctuation">)</span> crimedat <span class="operator">&lt;-</span> sqlFetch<span class="punctuation">(</span>myconn<span class="punctuation">,</span> Crime<span class="punctuation">)</span>pundat <span class="operator">&lt;-</span> sqlQuery<span class="punctuation">(</span>myconn<span class="punctuation">,</span> <span class="string">"select * from Punishment"</span><span class="punctuation">)</span> close<span class="punctuation">(</span>myconn<span class="punctuation">)</span></code></pre><p>这里首先载入了 RODBC 包，并通过一个已注册的数据源名称（mydsn）和用户名（rob）以及密码（aardvark）打开了一个 ODBC 数据库连接。连接字符串被传递给 sqlFetch()，它将</p><p>Crime 表复制到R数据框 crimedat 中。然后我们对 Punishment 表执行了 SQL 语句 select 并将结果保存到数据框 pundat 中。最后，我们关闭了连接。</p><p>函数 sqlQuery() 非常强大，因为其中可以插入任意的有效 SQL 语句。这种灵活性赋予了你选择指定变量、对数据取子集、创建新变量，以及重编码和重命名现有变量的能力。</p><p><strong>2. DBI 相关包</strong></p><p>DBI 包为访问数据库提供了一个通用且一致的客户端接口。构建于这个框架之上的 RJDBC 包提供了通过 JDBC 驱动访问数据库的方案。使用时请确保安装了针对你的系统和数据库的必要</p><p>JDBC 驱动。其他有用的、基于 DBI 的包有 RMySQL、ROracle、RPostgreSQL 和 RSQLite。这些包都为对应的数据库提供了原生的数据库驱动，但可能不是在所有系统上都可用。详情请参阅 CRAN（<a href="http://cran.r-project.org/">http://cran.r-project.org</a>）上的相应文档。</p><h5 id="2-3-12-通过-Stat-Transfer-导入数据">2.3.12   通过 Stat/Transfer 导入数据</h5><p>在我们结束数据导入的讨论之前，值得提到一款能让上述任务的难度显著降低的商业软件。Stat/Transfer（<a href="http://www.stattransfer.com/">www.stattransfer.com</a>）是一款可在34种数据格式之间作转换的独立应用程序，其中包括R中的数据格式（见图2-4）。</p><img src="/medias/image-20210814171404644.png" alt="图2-4  Windows 上 Stat/Transfer 的主对话框" style="zoom:67%;"><p>此软件拥有 Windows、Mac 和 Unix 版本，并且支持我们目前讨论过的各种统计软件的最新版本，也可通过 ODBC 访问如 Oracle、Sybase、Informix 和 DB/2 一类的数据库管理系统。</p><h4 id="2-4-数据集的标注">2.4 数据集的标注</h4><p>为了使结果更易解读，数据分析人员通常会对数据集进行标注。这种标注包括为变量名添加描述性的标签，以及为类别型变量中的编码添加值标签。例如，对于变量 age，你可能想附加一个描述更详细的标签 “Age at hospitalization (in years)”（入院年龄）。对于编码为 1 或 2 的性别变量 gender，你可能想将其关联到标签 “male” 和 “female” 上。</p><h5 id="2-4-1-变量标签">2.4.1 变量标签</h5><p>遗憾的是，R 处理变量标签的能力有限。一种解决方法是将变量标签作为变量名，然后通过位置下标来访问这个变量。考虑之前病例数据框的例子。名为 age 的第二列包含着个体首次入院时的年龄。代码：</p><pre><code class="highlight R"><span class="built_in">names</span><span class="punctuation">(</span>patientdata<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Age at hospitalization (in years)"</span></code></pre><p>将 age 重命名为 “Age at hospitalization (in years)”。很明显，新的变量名太长，不适合重复输入。作为替代，你可以使用 patientdata[2] 来引用这个变量，而在本应输出 age 的地方输出字符串 “Age at hospitalization (in years)”。很显然，这个方法并不理想，如果你能尝试想出更好的命名（例如，admissionAge）可能会更好一点。</p><h5 id="2-4-2-值标签">2.4.2 值标签</h5><p>函数 factor() 可为类别型变量创建值标签。继续上例，假设你有一个名为 gender 的变量， 其中 1 表示男性，2 表示女性。你可以使用代码：</p><pre><code class="highlight R">patientdata<span class="operator">$</span>gender <span class="operator">&lt;-</span> factor<span class="punctuation">(</span>patientdata<span class="operator">$</span>gender<span class="punctuation">,</span>                              levels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">)</span><span class="punctuation">,</span>                              labels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"male"</span><span class="punctuation">,</span> <span class="string">"female"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>来创建值标签。</p><p>这里 levels 代表变量的实际值，而 labels 表示包含了理想值标签的字符型向量。</p><h4 id="2-5-处理数据对象的实用函数">2.5 处理数据对象的实用函数</h4><p>在本章末尾，我们来简要总结一下实用的数据对象处理函数（参见表2-4）。</p><table><thead><tr><th>函  数</th><th>用   途</th></tr></thead><tbody><tr><td>length(object)</td><td>显示对象中元素/成分的数量</td></tr><tr><td>dim(object)</td><td>显示某个对象的维度</td></tr><tr><td>str(object)</td><td>显示某个对象的结构</td></tr><tr><td>class(object)</td><td>显示某个对象的类或类型</td></tr><tr><td>mode(object)</td><td>显示某个对象的模式</td></tr><tr><td>names(object)</td><td>显示某对象中各成分的名称</td></tr><tr><td>c(object, object,…)</td><td>将对象合并入一个向量</td></tr><tr><td>cbind(object, object, …)</td><td>按列合并对象</td></tr><tr><td>rbind(object, object, …)</td><td>按行合并对象</td></tr><tr><td>object</td><td>输出某个对象</td></tr><tr><td>head(object)</td><td>列出某个对象的开始部分</td></tr><tr><td>tail(object)</td><td>列出某个对象的最后部分</td></tr><tr><td>ls()</td><td>显示当前的对象列表</td></tr><tr><td>rm(object, object, …)</td><td>删除一个或更多个对象。语句 rm(list = ls()) 将删除当前工作环境中的几乎所有对象① 以句点.开头的隐藏对象将不受影响。</td></tr><tr><td>newobject &lt;- edit(object)</td><td>编辑对象并另存为 newobject</td></tr><tr><td>fix(object)</td><td>直接编辑对象</td></tr></tbody></table><p>我们已经讨论过其中的大部分函数。函数 head() 和 tail() 对于快速浏览大数据集的结构非常有用。例如，head(patientdata) 将列出数据框的前六行，而 tail(patientdata) 将列出最后六行。我们将在下一章中介绍length()、cbind() 和 rbind() 等函数。我们将其汇总于此， 仅作参考。</p><h4 id="2-6-小结">2.6 小结</h4><p>数据的准备可能是数据分析中最具挑战性的任务之一。我们在本章中概述了 R 中用于存储数据的多种数据结构，以及从键盘和外部来源导入数据的许多可能方式，这是一个不错的起点。特别是，我们将在后续各章中反复地使用向量、矩阵、数据框和列表的概念。掌握通过括号表达式选取元素的能力，对数据的选择、取子集和变换将是非常重要的。</p><p>如你所见，R 提供了丰富的函数用以访问外部数据，包括普通文本文件、网页、统计软件、电子表格和数据库的数据。虽然本章的焦点是将数据导入到R中，你同样也可以将数据从 R 导出为这些外部格式。数据的导出在附录 C 中论及，处理大数据集（GB 级到 TB 级）的方法在附录 F 中讨论。</p><p>将数据集读入 R 之后，你很有可能需要将其转化为一种更有助于分析的格式（事实上，我发现处理数据的紧迫感有助于促进学习）。在第 4 章，我们将会探索创建新变量、变换和重编码已有变量、合并数据集和选择观测的方法。</p><p>在转而探讨数据管理之前，让我们先花些时间在 R 的绘图上。许多读者都是因为对 R 绘图怀有强烈的兴趣而开始学习 R 的，为了不让你们久等，我们在下一章将直接讨论图形的创建。关注的重点是管理和定制图形的通用方法，它们在本书余下章节都会用到。</p><h3 id="第3章-图形初阶">第3章 图形初阶</h3><blockquote><p>本章内容<br>❑ 图形的创建和保存<br>❑ 自定义符号、线条、颜色和坐标轴<br>❑ 标注文本和标题<br>❑ 控制图形维度<br>❑ 组合多个图形</p></blockquote><h4 id="3-1-使用图形">3.1 使用图形</h4><p>R 是一个惊艳的图形构建平台。这里我特意使用了构建一词。在通常的交互式会话中，你可以通过逐条输入语句构建图形，逐渐完善图形特征，直至得到想要的效果。</p><p>考虑以下五行代码：</p><pre><code class="highlight R">attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span> plot<span class="punctuation">(</span>wt<span class="punctuation">,</span> mpg<span class="punctuation">)</span> abline<span class="punctuation">(</span>lm<span class="punctuation">(</span>mpg<span class="operator">~</span>wt<span class="punctuation">)</span><span class="punctuation">)</span>title<span class="punctuation">(</span><span class="string">"Regression of MPG on Weight"</span><span class="punctuation">)</span> detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre><p>首句绑定了数据框 mtcars。第二条语句打开了一个图形窗口并生成了一幅散点图，横轴表示车身重量，纵轴为每加仑汽油行驶的英里数。第三句向图形添加了一条最优拟合曲线。第四句添加了标题。最后一句为数据框解除了绑定。在 R 中，图形通常都是以这种交互式的风格绘制的（参见图3-1）。</p><img src="/medias/image-20210814184619755.png" alt="图3-1 创建图形" style="zoom:67%;"><p>可以通过代码或图形用户界面来保存图形。要通过代码保存图形，将绘图语句夹在开启目标图形设备的语句和关闭目标图形设备的语句之间即可。例如，以下代码会将图形保存到当前工作目录中名为 mygraph.pdf 的 PDF 文件中：</p><pre><code class="highlight R">pdf<span class="punctuation">(</span><span class="string">"mygraph.pdf"</span><span class="punctuation">)</span> attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>     plot<span class="punctuation">(</span>wt<span class="punctuation">,</span> mpg<span class="punctuation">)</span>     abline<span class="punctuation">(</span>lm<span class="punctuation">(</span>mpg<span class="operator">~</span>wt<span class="punctuation">)</span><span class="punctuation">)</span>    title<span class="punctuation">(</span><span class="string">"Regression of MPG on Weight"</span><span class="punctuation">)</span>     detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>dev.off<span class="punctuation">(</span><span class="punctuation">)</span></code></pre><p>除了 pdf()，还可以使用函数 win.metafile()、png()、jpeg()、bmp()、tiff()、xfig()  和 postscript() 将图形保存为其他格式。（注意，Windows 图元文件格式仅在 Windows 系统中可用。）关于保存图形输出到文件的更多细节，可以参考 1.3.4 节。</p><p>通过图形用户界面保存图形的方法因系统而异。对于 Windows，在图形窗口中选择“文件”→“另存为”，然后在弹出的对话框中选择想要的格式和保存位置即可。在 Mac 上，当 Quartz 图形窗口处于高亮状态时，点选菜单栏中的 “文件” → “另存为” 即可。其提供的输出格式仅有 PDF。在 UNIX 系统中，图形必须使用代码来保存。在附录 A 中，我们将考虑每个系统中可用的备选图形用户界面，这将给予你更多选择。</p><p>通过执行如 plot()、hist()（绘制直方图）或 boxplot() 这样的高级绘图命令来创建一幅新图形时，通常会覆盖掉先前的图形。如何才能创建多个图形并随时查看每一个呢？方法有若干。</p><p>第一种方法，你可以在创建一幅新图形之前打开一个新的图形窗口：</p><pre><code class="highlight R">dev.new<span class="punctuation">(</span><span class="punctuation">)</span>statements to create graph <span class="number">1</span>dev.new<span class="punctuation">(</span><span class="punctuation">)</span>statements to create a graph <span class="number">2</span> etc.</code></pre><p>每一幅新图形将出现在最近一次打开的窗口中。</p><p>第二种方法，你可以通过图形用户界面来查看多个图形。在 Mac 上，你可以使用 Quartz 菜单中的“后退”（Back）和“前进”（Forward）来逐个浏览图形。在 Windows 上，这个过程分为两步。在打开第一个图形窗口以后，勾选“历史”（History）→“记录”（Recording）。然后使用菜单中的 “上一个”（Previous）和 “下一个”（Next）来逐个查看已经绘制的图形。</p><p>最后一种方法，你可以使用函数 dev.new()、dev.next()、dev.prev()、dev.set() 和</p><p>dev.off() 同时打开多个图形窗口，并选择将哪个输出发送到哪个窗口中。这种方法全平台适用。关于这种方法的更多细节，请参考 help(dev.cur)。</p><p>R 将在保证用户输入最小化的前提下创建尽可能美观的图形。不过你依然可以使用图形参数来指定字体、颜色、线条类型、坐标轴、参考线和标注。其灵活度足以让我们实现对图形的高度定制。</p><p>我们将以一个简单的图形作为本章的开始，接着进一步探索按需修改和强化图形的方式。然后，我们将着眼于一些更复杂的示例，以阐明其他的图形定制方法。我们关注的焦点是那些可以应用于多种 R 图形的技术。对于本书中描述的所有图形，本章讨论的方法均有效，不过第 19 章中使用 ggplot2 包创建的图形是例外。（ggplot2 包拥有自己的图形外观定制方法。）在其他各章中，我们将探索各种特定的图形，并探讨它们每一个在何时何地最有用。</p><h4 id="3-2-一个简单的例子">3.2     一个简单的例子</h4><p>让我们从表3-1 中给出的假想数据集开始。它描述了病人对两种药物五个剂量水平上的响应情况。</p><p><strong>表3-1 病人对两种药物五个剂量水平上的响应情况</strong></p><table><thead><tr><th style="text-align:center">剂量</th><th style="text-align:center">对药物  A 的响应</th><th style="text-align:center">对药物  B 的响应</th></tr></thead><tbody><tr><td style="text-align:center">20</td><td style="text-align:center">16</td><td style="text-align:center">15</td></tr><tr><td style="text-align:center">30</td><td style="text-align:center">20</td><td style="text-align:center">18</td></tr><tr><td style="text-align:center">40</td><td style="text-align:center">27</td><td style="text-align:center">25</td></tr><tr><td style="text-align:center">45</td><td style="text-align:center">40</td><td style="text-align:center">31</td></tr><tr><td style="text-align:center">60</td><td style="text-align:center">60</td><td style="text-align:center">40</td></tr></tbody></table><p>可以使用以下代码输入数据：</p><pre><code class="highlight R">dose <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">20</span><span class="punctuation">,</span> <span class="number">30</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">45</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span>drugA <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">16</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">27</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span>drugB <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">15</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">31</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">)</span></code></pre><p>使用以下代码可以创建一幅描述药物 A 的剂量和响应关系的图形：</p><pre><code class="highlight R">plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">)</span></code></pre><p>plot() 是 R 中为对象作图的一个泛型函数（它的输出将根据所绘制对象类型的不同而变化）。本例中，plot(X, <em>y</em>, type=“b”) 将 x 置于横轴，将 y 置于纵轴，绘制点集 (x, y)，然后使用线段将其连接。选项 type=“b” 表示同时绘制点和线。使用 help(plot) 可以查看其他选项。结果如图3-2 所示。</p><img src="/medias/image-20210814185457705.png" alt="图3-2 药物 A 剂量和响应的折线图" style="zoom:67%;"><p>折线图将于第 11 章中详述。现在我们先来修改此图的外观。</p><h4 id="3-3-图形参数">3.3 图形参数</h4><p>我们可以通过修改称为图形参数的选项来自定义一幅图形的多个特征（字体、颜色、坐标轴、标签）。一种方法是通过函数 par() 来指定这些选项。以这种方式设定的参数值除非被再次修改， 否 则 将 在 会 话 结 束 前 一 直 有 效 。 其 调 用 格 式 为 par(optionname=value, optionname=name,…)。不加参数地执行 par() 将生成一个含有当前图形参数设置的列表。添加参数 no.readonly=TRUE 可以生成一个可以修改的当前图形参数列表。</p><p>继续我们的例子，假设你想使用实心三角而不是空心圆圈作为点的符号，并且想用虚线代替实线连接这些点。你可以使用以下代码完成修改：</p><pre><code class="highlight R">opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">17</span><span class="punctuation">)</span>plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">)</span> par<span class="punctuation">(</span>opar<span class="punctuation">)</span></code></pre><p>结果如图3-3所示。</p><img src="/medias/image-20210814185746256.png" alt="图3-3 药物A剂量和响应的折线图。修改了线条类型和点的符号" style="zoom:67%;"><p>首个语句复制了一份当前的图形参数设置。第二句将默认的线条类型修改为虚线（lty=2） 并将默认的点符号改为了实心三角（pch=17）。然后我们绘制了图形并还原了原始设置。线条类型和符号将在 3.3.1 节中详述。</p><p>你可以随心所欲地多次使用par()函数，即 par(lty=2, pch=17) 也可以写成：</p><pre><code class="highlight R">par<span class="punctuation">(</span>lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span> par<span class="punctuation">(</span>pch<span class="operator">=</span><span class="number">17</span><span class="punctuation">)</span></code></pre><p>指定图形参数的第二种方法是为高级绘图函数直接提供 optionname=value 的键值对。这种情况下，指定的选项仅对这幅图形本身有效。你可以通过代码：</p><pre><code class="highlight R">plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">17</span><span class="punctuation">)</span></code></pre><p>来生成与上图相同的图形。</p><p>并不是所有的高级绘图函数都允许指定全部可能的图形参数。你需要参考每个特定绘图函数的帮助（如 ?plot、?hist 或 ?boxplot）以确定哪些参数可以以这种方式设置。下面介绍可以设定的许多重要图形参数。</p><h5 id="3-3-1-符号和线条">3.3.1 符号和线条</h5><p>如你所见，可以使用图形参数来指定绘图时使用的符号和线条类型。相关参数如表3-2 所示。</p><p><strong>表3-2 用于指定符号和线条类型的参数</strong></p><table><thead><tr><th>参  数</th><th>描  述</th></tr></thead><tbody><tr><td>pch</td><td>指定绘制点时使用的符号（见图 3-4）</td></tr><tr><td>cex</td><td>指定符号的大小。cex 是一个数值，表示绘图符号相对于默认大小的缩放倍数。默认大小为 1，1.5 表示放大为默认值的 1.5 倍，0.5 表示缩小为默认值的 50%，等等</td></tr><tr><td>lty</td><td>指定线条类型（参见图 3-5）</td></tr><tr><td>lwd</td><td>指定线条宽度。lwd 是以默认值的相对大小来表示的（默认值为 1）。例如，lwd=2 将生成一条两倍于默认宽度的线条</td></tr></tbody></table><p>选项 pch= 用于指定绘制点时使用的符号。可能的值如图3-4 所示。<br><img src="/medias/image-20210815112437649.png" alt="图3-4 参数 pch 可指定的绘图符号" style="zoom:67%;"></p><p>对于符号 21~25，你还可以指定边界颜色（col=）和填充色（bg=）。选项 lty= 用于指定想要的线条类型。可用的值如图3-5 所示。</p><img src="/medias/image-20210815112647383.png" alt="图3-5 参数 lty 可指定的线条类型" style="zoom:67%;"><p>综合以上选项，以下代码：</p><pre><code class="highlight R">plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> lwd<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">15</span><span class="punctuation">,</span> cex<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span></code></pre><p>将绘制一幅图形，其线条类型为点线，宽度为默认宽度的3倍，点的符号为实心正方形，大小为默认符号大小的 2 倍。结果如图3-6 所示。</p><img src="/medias/image-20210815112818137.png" alt="图3-6 药物A剂量和响应的折线图。修改了线条类型、线条宽度、点的符号和符号大小" style="zoom:67%;"><p>接下来我们将讨论颜色的指定方法。</p><h5 id="3-3-2-颜色">3.3.2  颜色</h5><p>R 中有若干和颜色相关的参数。表3-3  列出了一些常用参数。<br><strong>表3-3  用于指定颜色的参数</strong></p><table><thead><tr><th>参  数</th><th>描  述</th></tr></thead><tbody><tr><td>col</td><td>默认的绘图颜色。某些函数（如 lines 和 pie）可以接受一个含有颜色值的向量并自动循环使用。例如，如果设定 col=c(“red”, “blue”) 并需要绘制三条线，则第一条线将为红色，第二条线为蓝色，第三条线又将为红色</td></tr><tr><td>col.axis</td><td>坐标轴刻度文字的颜色</td></tr><tr><td>col.lab</td><td>坐标轴标签（名称）的颜色</td></tr><tr><td>col.main</td><td>标题颜色</td></tr><tr><td>col.sub</td><td>副标题颜色</td></tr><tr><td>fg</td><td>图形的前景色</td></tr><tr><td>bg</td><td>图形的背景色</td></tr></tbody></table><p>在 R 中，可以通过颜色下标、颜色名称、十六进制的颜色值、RGB 值或 HSV 值来指定颜色。举例来说，col=1、col=“white”、col=“#FFFFFF”、col=rgb(1,1,1) 和col=hsv(0,0,1) 都是表示白色的等价方式。函数 rgb() 可基于红－绿－蓝三色值生成颜色，而 hsv() 则基于色相－ 饱和度－亮度值来生成颜色。请参考这些函数的帮助以了解更多细节。</p><p>函数 colors() 可以返回所有可用颜色的名称。Earl F. Glynn 为 R 中的色彩创建了一个优秀的在线图表，参见 <a href="http://research.stowers-institute.org/efg/R/Color/Chart%E3%80%82R">http://research.stowers-institute.org/efg/R/Color/Chart。R</a> 中也有多种用于创建连续型颜色向量的函数，包括 rainbow()、heat.colors()、terrain.colors()、topo.colors()  以及 cm.colors()。举例来说，rainbow(10) 可以生成10 种连续的“彩虹型”颜色。</p><p>对于创建吸引人的颜色配对，RColorBrewer 特别受到欢迎。注意在第一次使用它之前先进行下载(install.packages(“RColorBrewer”))。安装之后，使用函数 brewer.pal(n, name) 来创建一个颜色值的向量。比如说，以下代码：</p><pre><code class="highlight R">library<span class="punctuation">(</span>RColorBrewer<span class="punctuation">)</span> n <span class="operator">&lt;-</span> 7mycolors <span class="operator">&lt;-</span> brewer.pal<span class="punctuation">(</span>n<span class="punctuation">,</span> <span class="string">"Set1"</span><span class="punctuation">)</span> barplot<span class="punctuation">(</span><span class="built_in">rep</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span>n<span class="punctuation">)</span><span class="punctuation">,</span> col<span class="operator">=</span>mycolors<span class="punctuation">)</span></code></pre><img src="/medias/image-20210815115634151.png" style="zoom:67%;"><p>从 Set1 调色板中抽取了7种用十六进制表示的颜色并返回一个向量。若要得到所有可选调色板的列表，输入 <a href="http://brewer.pal.info">brewer.pal.info</a>；或者输入 display.brewer.all() 从而在一个显示输出中产生每个调色板的图形。请参阅 help(RColorBrewer)  获得更加详细的帮助。</p><p>最后，多阶灰度色可使用基础安装所自带的 gray() 函数生成。这时要通过一个元素值为 0 和 1 之间的向量来指定各颜色的灰度。gray(0:10/10) 将生成 10 阶灰度色。试着使用以下代码：</p><pre><code class="highlight R">n <span class="operator">&lt;-</span> 10mycolors <span class="operator">&lt;-</span> rainbow<span class="punctuation">(</span>n<span class="punctuation">)</span>pie<span class="punctuation">(</span><span class="built_in">rep</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> n<span class="punctuation">)</span><span class="punctuation">,</span> labels<span class="operator">=</span>mycolors<span class="punctuation">,</span> col<span class="operator">=</span>mycolors<span class="punctuation">)</span> mygrays <span class="operator">&lt;-</span> gray<span class="punctuation">(</span><span class="number">0</span><span class="operator">:</span>n<span class="operator">/</span>n<span class="punctuation">)</span>pie<span class="punctuation">(</span><span class="built_in">rep</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> n<span class="punctuation">)</span><span class="punctuation">,</span> labels<span class="operator">=</span>mygrays<span class="punctuation">,</span> col<span class="operator">=</span>mygrays<span class="punctuation">)</span></code></pre><img src="/medias/image-20210815115842815.png" style="zoom:67%;"><p>来观察这些函数的工作方式。</p><p>你可以看到，R 提供了多种创建颜色变量的方法。使用颜色参数的示例将贯穿本章。</p><h5 id="3-3-3-文本属性">3.3.3 文本属性</h5><p>图形参数同样可以用来指定字号、字体和字样。表3-4 阐释了用于控制文本大小的参数。字体族和字样可以通过字体选项进行控制（见表3-5）。<br><strong>表3-4 用于指定文本大小的参数</strong></p><table><thead><tr><th>参  数</th><th>描  述</th></tr></thead><tbody><tr><td>cex</td><td>表示相对于默认大小缩放倍数的数值。默认大小为 1，1.5 表示放大为默认值的 1.5 倍，0.5 表示缩小为默认值的 50%，等等</td></tr><tr><td>cex.axis</td><td>坐标轴刻度文字的缩放倍数。类似于 cex</td></tr><tr><td>cex.lab</td><td>坐标轴标签（名称）的缩放倍数。类似于 cex</td></tr><tr><td>cex.main</td><td>标 题 的 缩 放 倍 数 。 类 似 于 cex</td></tr><tr><td>cex.sub</td><td>副标题的缩放倍数。类似于 cex</td></tr></tbody></table><p><strong>表3-5 用于指定字体族、字号和字样的参数</strong></p><p>​</p><table><thead><tr><th>参  数</th><th>描  述</th></tr></thead><tbody><tr><td>font</td><td>整数。用于指定绘图使用的字体样式。1=常规，2=粗体，3=斜体，4=粗斜体，5=符号字体（以 Adobe 符号编码表示）</td></tr><tr><td>font.axis</td><td>坐标轴刻度文字的字体样式</td></tr><tr><td>font.lab</td><td>坐标轴标签（名称）的字体样式</td></tr><tr><td>font.main</td><td>标题的字体样式</td></tr><tr><td>font.sub</td><td>副标题的字体样式</td></tr><tr><td>ps</td><td>字体磅值（1 磅约为 1/72 英寸）。文本的最终大小为      ps*cex</td></tr><tr><td>family</td><td>绘制文本时使用的字体族。标准的取值为 serif（衬线）、sans（无衬线）和 mono（等宽）</td></tr></tbody></table><p>举例来说，在执行语句：</p><pre><code class="highlight R">par<span class="punctuation">(</span>font.lab<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> cex.lab<span class="operator">=</span><span class="number">1.5</span><span class="punctuation">,</span> font.main<span class="operator">=</span><span class="number">4</span><span class="punctuation">,</span> cex.main<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span></code></pre><p>之后创建的所有图形都将拥有斜体、1.5倍于默认文本大小的坐标轴标签（名称），以及粗斜体、2 倍于默认文本大小的标题。</p><p>我们可以轻松设置字号和字体样式，然而字体族的设置却稍显复杂。这是因为衬线、无衬线和等宽字体的具体映射是与图形设备相关的。举例来说，在 Windows系统中，等宽字体映射为 TT Courier New，衬线字体映射为 TT Times New Roman，无衬线字体则映射为 TT Arial（TT代表True Type）。如果你对以上映射表示满意，就可以使用类似于 family=“serif” 这样的参数获得想要的结果。如果不满意，则需要创建新的映射。在 Windows 中，可以通过函数 windowsFont() 来创建这类映射。例如，在执行语句：</p><pre><code class="highlight R">windowsFonts<span class="punctuation">(</span>    A<span class="operator">=</span>windowsFont<span class="punctuation">(</span><span class="string">"Arial Black"</span><span class="punctuation">)</span><span class="punctuation">,</span>    B<span class="operator">=</span>windowsFont<span class="punctuation">(</span><span class="string">"Bookman Old Style"</span><span class="punctuation">)</span><span class="punctuation">,</span>     C<span class="operator">=</span>windowsFont<span class="punctuation">(</span><span class="string">"Comic Sans MS"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>之后，即可使用 A、B 和 C 作为 family 的取值。在本例的情境下，par(family=“A”) 将指定 Arial Black 作为绘图字体。（3.4.2 节中的代码清单3-2 提供了一个修改文本参数的示例。）请注意，函数 windowsFont() 仅在 Windows 中有效。在 Mac 上，请改用 quartzFonts()。</p><p>如果以 PDF 或 PostScript 格式输出图形，则修改字体族会相对简单一些。对于 PDF 格式，可以使用 names(pdfFonts()) 找出你的系统中有哪些字体是可用的， 然后使用 pdf(file= “myplot.pdf”, family=“fontname”) 来生成图形。对于以 PostScript 格式输出的图形，则可以对应地使用 names(postscriptFonts()) 和 postscript(file=“<a href="http://myplot.ps">myplot.ps</a>”, family= “fontname”)。请参阅在线帮助以了解更多信息。</p><h5 id="3-3-4-图形尺寸与边界尺寸">3.3.4 图形尺寸与边界尺寸</h5><p>最后，可以使用表3-6 列出的参数来控制图形尺寸和边界大小。</p><p><strong>表3-6 用于控制图形尺寸和边界大小的参数</strong></p><table><thead><tr><th>参  数</th><th>描  述</th></tr></thead><tbody><tr><td>pin</td><td>以英寸表示的图形尺寸（宽和高）</td></tr><tr><td>mai</td><td>以数值向量表示的边界大小，顺序为“下、左、上、右”，单位为英寸</td></tr><tr><td>mar</td><td>以数值向量表示的边界大小，顺序为“下、左、上、右”，单位为英分①。默认值为 c(5, 4, 4, 2) + 0.1</td></tr></tbody></table><p>① 一英分等于十二分之一英寸（0.21 厘米）。</p><p>代码：</p><pre><code class="highlight R">par<span class="punctuation">(</span>pin<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">4</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">)</span><span class="punctuation">,</span> mai<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">.5</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">.2</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>可生成一幅4英寸宽、3英寸高、上下边界为 1 英寸、左边界为 0.5 英寸、右边界为 0.2 英寸的图形。让我们使用最近学到的选项来强化之前的简单图形示例。代码清单3-1 中的代码生成的图形如图3-7 所示。</p><p>代码清单3-1 使用图形参数控制图形外观</p><pre><code class="highlight R">dose <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">20</span><span class="punctuation">,</span> <span class="number">30</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">45</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span>drugA <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">16</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">27</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span>drugB <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">15</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">31</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">)</span>opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>pin<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">)</span><span class="punctuation">)</span>par<span class="punctuation">(</span>lwd<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> cex<span class="operator">=</span><span class="number">1.5</span><span class="punctuation">)</span> par<span class="punctuation">(</span>cex.axis<span class="operator">=</span><span class="number">.75</span><span class="punctuation">,</span> font.axis<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span>plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">19</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">)</span>plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugB<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">23</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">6</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">,</span> bg<span class="operator">=</span><span class="string">"green"</span><span class="punctuation">)</span> par<span class="punctuation">(</span>opar<span class="punctuation">)</span></code></pre> <img src="/medias/image-20210815121334464.png" alt="图3-7 药物 A 和药物 B 剂量与响应的折线图" style="zoom:67%;"><p>首先，你以向量的形式输入了数据，然后保存了当前的图形参数设置（这样就可以在稍后恢复设置）。接着，你修改了默认的图形参数，得到的图形将为 2 英寸宽、3 英寸高。除此之外，线条的宽度将为默认宽度的两倍，符号将为默认大小的 1.5 倍。坐标轴刻度文本被设置为斜体、缩小为默认大小的 75%。之后，我们使用红色实心圆圈和虚线创建了第一幅图形，并使用绿色填充的绿色菱形加蓝色边框和蓝色虚线创建了第二幅图形。最后，我们还原了初始的图形参数设置。</p><p>值得注意的是，通过 par() 设定的参数对两幅图都有效，而在plot()函数中指定的参数仅对那个特定图形有效。</p><p>观察图3-7 可以发现，图形的呈现上还有一定缺陷。这两幅图都缺少标题，并且纵轴的刻度单位不同，这无疑限制了我们直接比较两种药物的能力。同时，坐标轴的标签（名称）也应当提供更多的信息。</p><p>下一节中，我们将转而探讨如何自定义文本标注（如标题和标签）和坐标轴。要了解可用图形参数的更多信息，请参阅 help(par)。</p><h4 id="3-4-添加文本、自定义坐标轴和图例">3.4  添加文本、自定义坐标轴和图例</h4><p>除了图形参数，许多高级绘图函数（例如 plot、hist、boxplot）也允许自行设定坐标轴和文本标注选项。举例来说，以下代码在图形上添加了标题（main）、副标题（sub）、坐标轴标签（xlab、ylab）并指定了坐标轴范围（xlim、ylim）。结果如图3-8 所示。</p><pre><code class="highlight R">plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span>      col<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> lwd<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span>     main<span class="operator">=</span><span class="string">"Clinical Trials for Drug A"</span><span class="punctuation">,</span>      sub<span class="operator">=</span><span class="string">"This is hypothetical data"</span><span class="punctuation">,</span>      xlab<span class="operator">=</span><span class="string">"Dosage"</span><span class="punctuation">,</span> ylab<span class="operator">=</span><span class="string">"Drug Response"</span><span class="punctuation">,</span>      xlim<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span><span class="punctuation">,</span> ylim<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">70</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre> <img src="/medias/image-20210815121749774.png" alt="图3-8 药物 A 剂量和响应的折线图。添加了标题、副标题和自定义的坐标轴" style="zoom:67%;"><p>再次提醒，并非所有函数都支持这些选项。请参考相应函数的帮助以了解其可以接受哪些选项。从更精细的控制和模块化的角度考虑，你可以使用本节余下部分描述的函数来控制标题、坐标轴、图例和文本标注的外观。</p><blockquote><p><strong>注意</strong>：某些高级绘图函数已经包含了默认的标题和标签。你可以通过在 plot() 语句或单独的par() 语句中添加 ann=FALSE 来移除它们。</p></blockquote><h5 id="3-4-1-标题">3.4.1   标题</h5><p>可以使用 title() 函数为图形添加标题和坐标轴标签。调用格式为：</p><pre><code class="highlight R">title<span class="punctuation">(</span>main<span class="operator">=</span><span class="string">"main title"</span><span class="punctuation">,</span> sub<span class="operator">=</span><span class="string">"subtitle"</span><span class="punctuation">,</span>       xlab<span class="operator">=</span><span class="string">"x-axis label"</span><span class="punctuation">,</span> ylab<span class="operator">=</span><span class="string">"y-axis label"</span><span class="punctuation">)</span></code></pre><p>函数title()中亦可指定其他图形参数（如文本大小、字体、旋转角度和颜色）。举例来说， 以下代码将生成红色的标题和蓝色的副标题，以及比默认大小小 25 % 的绿色 x 轴、y 轴标签：</p><pre><code class="highlight R">title<span class="punctuation">(</span>main<span class="operator">=</span><span class="string">"My Title"</span><span class="punctuation">,</span> col.main<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">,</span>       sub<span class="operator">=</span><span class="string">"My Subtitle"</span><span class="punctuation">,</span> col.sub<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">,</span>       xlab<span class="operator">=</span><span class="string">"My X label"</span><span class="punctuation">,</span> ylab<span class="operator">=</span><span class="string">"My Y label"</span><span class="punctuation">,</span>       col.lab<span class="operator">=</span><span class="string">"green"</span><span class="punctuation">,</span> cex.lab<span class="operator">=</span><span class="number">0.75</span><span class="punctuation">)</span></code></pre><p>函数 title() 一般来说被用于添加信息到一个默认标题和坐标轴标签被 ann=FALSE 选项移除的图形中。</p><h5 id="3-4-2-坐标轴">3.4.2   坐标轴</h5><p>你可以使用函数 axis() 来创建自定义的坐标轴，而非使用 R 中的默认坐标轴。其格式为：</p><pre><code class="highlight R">axis<span class="punctuation">(</span>side<span class="punctuation">,</span> at<span class="operator">=</span><span class="punctuation">,</span> labels<span class="operator">=</span><span class="punctuation">,</span> pos<span class="operator">=</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="punctuation">,</span> las<span class="operator">=</span><span class="punctuation">,</span> tck<span class="operator">=</span><span class="punctuation">,</span> ...<span class="punctuation">)</span></code></pre><p>各参数已详述于表3-7 中。<br><strong>表3-7  坐标轴选项</strong></p><table><thead><tr><th>选  项</th><th>描  述</th></tr></thead><tbody><tr><td>side</td><td>一个整数，表示在图形的哪边绘制坐标轴（1=下，2=左，3=上，4=右）</td></tr><tr><td>at</td><td>一个数值型向量，表示需要绘制刻度线的位置</td></tr><tr><td>labels</td><td>一个字符型向量，表示置于刻度线旁边的文字标签（如果为 NULL，则将直接使用 at 中的值）</td></tr><tr><td>pos</td><td>坐标轴线绘制位置的坐标（即与另一条坐标轴相交位置的值）</td></tr><tr><td>lty</td><td>线条类型</td></tr><tr><td>col</td><td>线条和刻度线颜色</td></tr><tr><td>lass</td><td>标签是否平行于（=0）或垂直于（=2）坐标轴</td></tr><tr><td>tck</td><td>刻度线的长度，以相对于绘图区域大小的分数表示（负值表示在图形外侧，正值表示在图形内侧，0 表示禁用刻度，1 表示绘制网格线）；默认值为–0.01</td></tr><tr><td>(…)</td><td>其他图形参数</td></tr></tbody></table><p>创建自定义坐标轴时，你应当禁用高级绘图函数自动生成的坐标轴。参数 axes=FALSE 将禁用全部坐标轴（包括坐标轴框架线，除非你添加了参数 frame.plot=TRUE）。参数 xaxt=“n” 和 yaxt=“n” 将分别禁用 X 轴或 Y 轴（会留下框架线，只是去除了刻度）。代码清单3-2 中是一个稍显笨拙和夸张的例子，它演示了我们到目前为止讨论过的各种图形特征。结果如图3-9 所示。</p><p>代码清单3-2 自定义坐标轴的示例</p><pre><code class="highlight R">x <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">)</span><span class="comment"># 生成数据</span>y <span class="operator">&lt;-</span> x<span class="comment"># 生成数据</span>z <span class="operator">&lt;-</span> 10<span class="operator">/</span>x<span class="comment"># 生成数据</span>opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span>par<span class="punctuation">(</span>mar<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">5</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">8</span><span class="punctuation">)</span> <span class="operator">+</span> <span class="number">0.1</span><span class="punctuation">)</span><span class="comment"># 增加边界大小</span>plot<span class="punctuation">(</span>x<span class="punctuation">,</span> y<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">21</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">,</span> yaxt<span class="operator">=</span><span class="string">"n"</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> ann<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span>  <span class="comment"># 绘制 x 对 y 的图形</span>lines<span class="punctuation">(</span>x<span class="punctuation">,</span> z<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">22</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span>  <span class="comment"># 添加 x 对 1/x 的直线</span>axis<span class="punctuation">(</span><span class="number">2</span><span class="punctuation">,</span> at<span class="operator">=</span>x<span class="punctuation">,</span> labels<span class="operator">=</span>x<span class="punctuation">,</span> col.axis<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">,</span> las<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span> <span class="comment"># 绘制你自己的坐标轴</span>axis<span class="punctuation">(</span><span class="number">4</span><span class="punctuation">,</span> at<span class="operator">=</span>z<span class="punctuation">,</span> labels<span class="operator">=</span><span class="built_in">round</span><span class="punctuation">(</span>z<span class="punctuation">,</span> digits<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span><span class="punctuation">,</span> col.axis<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">,</span> las<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> cex.axis<span class="operator">=</span><span class="number">0.7</span><span class="punctuation">,</span> tck<span class="operator">=</span><span class="operator">-</span><span class="number">.01</span><span class="punctuation">)</span>     <span class="comment"># 绘制你自己的坐标轴</span>mtext<span class="punctuation">(</span><span class="string">"y=1/x"</span><span class="punctuation">,</span> side<span class="operator">=</span><span class="number">4</span><span class="punctuation">,</span> line<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> cex.lab<span class="operator">=</span><span class="number">1</span><span class="punctuation">,</span> las<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">)</span> <span class="comment"># 添加标题和文本</span>title<span class="punctuation">(</span><span class="string">"An Example of Creative Axes"</span><span class="punctuation">,</span> xlab<span class="operator">=</span><span class="string">"X values"</span><span class="punctuation">,</span> ylab<span class="operator">=</span><span class="string">"Y=X"</span><span class="punctuation">)</span> <span class="comment"># 添加标题和文本</span>par<span class="punctuation">(</span>opar<span class="punctuation">)</span></code></pre><img src="/medias/image-20210815123146422.png" alt="图3-9 各种坐标轴选项的演示" style="zoom:67%;"><p>到目前为止，我们已经讨论过代码清单3-2 中除 lines() 和 mtext() 以外的所有函数。使用 plot() 语句可以新建一幅图形。而使用 lines() 语句，你可以为一幅现有图形添加新的图形元素。在 3.4.4 节中，你会再次用到它，在同一幅图中绘制药物 A 和药物 B 的响应情况。函数 mtext() 用于在图形的边界添加文本。我们将在 3.4.5 节中讲到函数 mtext()，同时会在第 11 章中更充分地讨论 lines() 函数。</p><blockquote><p><strong>次要刻度线</strong><br>注意，我们最近创建的图形都只拥有主刻度线，却没有次要刻度线。要创建次要刻度线，你需要使用 Hmisc 包中的 minor.tick() 函数。如果你尚未安装 Hmisc 包，请先安装它（参考 1.4.2 节）。你可以使用代码：</p></blockquote><pre><code class="highlight R">install.packages<span class="punctuation">(</span><span class="string">'Hmisc'</span><span class="punctuation">)</span>library<span class="punctuation">(</span>Hmisc<span class="punctuation">)</span>minor.tick<span class="punctuation">(</span>nx<span class="operator">=</span>n<span class="punctuation">,</span> ny<span class="operator">=</span>n<span class="punctuation">,</span> tick.ratio<span class="operator">=</span>n<span class="punctuation">)</span></code></pre><blockquote><p>来添加次要刻度线。其中 nx 和 ny 分别指定了 X 轴和 Y 轴每两条主刻度线之间通过次要刻度线划分得到的区间个数。tick.ratio 表示次要刻度线相对于主刻度线的大小比例。当前的主刻度线长度可以使用 par(“tck”) 获取。举例来说，下列语句将在 X 轴的每两条主刻度线之间添加 1 条次要刻度线，并在 Y 轴的每两条主刻度线之间添加 2 条次要刻度线：</p></blockquote><pre><code class="highlight R">minor.tick<span class="punctuation">(</span>nx<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> ny<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> tick.ratio<span class="operator">=</span><span class="number">0.5</span><span class="punctuation">)</span></code></pre><blockquote><p>次要刻度线的长度将是主刻度线的一半。3.4.4节中给出了添加次要刻度线的一个例子（代码清单3-3 和图3-10）。</p></blockquote><h5 id="3-4-3-参考线">3.4.3   参考线</h5><p>函数 abline() 可以用来为图形添加参考线。其使用格式为：</p><pre><code class="highlight R">abline<span class="punctuation">(</span>h<span class="operator">=</span>yvalues<span class="punctuation">,</span> v<span class="operator">=</span>xvalues<span class="punctuation">)</span></code></pre><p>函数 abline() 中也可以指定其他图形参数（如线条类型、颜色和宽度）。举例来说：</p><pre><code class="highlight R">abline<span class="punctuation">(</span>h<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">7</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>在 y 为 1、5、7 的位置添加了水平实线，而代码：</p><pre><code class="highlight R">abline<span class="punctuation">(</span>v<span class="operator">=</span>seq<span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">10</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">)</span></code></pre><p>则在 x 为 1、3、5、7、9 的位置添加了垂直的蓝色虚线。下一节的代码清单3-3 为我们的药物效果图在 y 为 30 的位置创建了一条参考线。结果如下一节的图3-10 所示。</p><h5 id="3-4-4-图例">3.4.4 图例</h5><p>当图形中包含的数据不止一组时，图例可以帮助你辨别出每个条形、扇形区域或折线各代表哪一类数据。我们可以使用函数 legend() 来添加图例（果然不出所料）。其使用格式为：</p><pre><code class="highlight R">legend<span class="punctuation">(</span>location<span class="punctuation">,</span>  title <span class="punctuation">,</span> legend<span class="punctuation">,</span> ...<span class="punctuation">)</span></code></pre><p>常用选项详述于表3-8 中。<br><strong>表3-8  图例选项</strong></p><table><thead><tr><th>选  项</th><th>描  述</th></tr></thead><tbody><tr><td>location</td><td>有许多方式可以指定图例的位置。你可以直接给定图例左上角的 x、y 坐标，也可以执行 locator(1)， 然后通过鼠标单击给出图例的位置，还可以使用关键字 bottom、bottomleft、left、topleft、top、topright、right、bottomright 或 center 放置图例。如果你使用了以上某个关键字，那么可以同时使用参数 inset=指定图例向图形内侧移动的大小（以绘图区域大小的分数表示）</td></tr><tr><td>title</td><td>图例标题的字符串（可选）</td></tr><tr><td>legend</td><td>图例标签组成的字符型向量</td></tr><tr><td>…</td><td>其他选项。如果图例标示的是颜色不同的线条，需要指定 col=加上颜色值组成的向量。如果图例标示的是符号不同的点，则需指定 pch=加上符号的代码组成的向量。如果图例标示的是不同的线条宽度或线条类型，请使用 lwd=或 lty=加上宽度值或类型值组成的向量。要为图例创建颜色填充的盒形（常见于条形图、箱线图或饼图），需要使用参数 fill=加上颜色值组成的向量</td></tr></tbody></table><p>其他常用的图例选项包括用于指定盒子样式的 bty、指定背景色的 bg、指定大小的 cex，以及指定文本颜色的 text.col。指定 horiz=TRUE 将会水平放置图例，而不是垂直放置。关于图例的更多细节，请参考 help(legend)。这份帮助中给出的示例都特别有用。</p><p>让我们看看对药物数据作图的一个例子（代码清单3-3）。你将再次使用我们目前为止讲到的许多图形功能。结果如图3-10 所示。</p><p>代码清单3-3 依剂量对比药物 A 和药物 B 的响应情况</p><pre><code class="highlight R">dose <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">20</span><span class="punctuation">,</span> <span class="number">30</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">45</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span>drugA <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">16</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">27</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span>drugB <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">15</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">31</span><span class="punctuation">,</span> <span class="number">40</span><span class="punctuation">)</span>opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>lwd<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> cex<span class="operator">=</span><span class="number">1.5</span><span class="punctuation">,</span> font.lab<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span>   <span class="comment"># 增加线条、文本、符号、标签的宽度或大小</span>plot<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugA<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span>     pch<span class="operator">=</span><span class="number">15</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">1</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">,</span> ylim<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">60</span><span class="punctuation">)</span><span class="punctuation">,</span>      main<span class="operator">=</span><span class="string">"Drug A vs. Drug B"</span><span class="punctuation">,</span>     xlab<span class="operator">=</span><span class="string">"Drug Dosage"</span><span class="punctuation">,</span> ylab<span class="operator">=</span><span class="string">"Drug Response"</span><span class="punctuation">)</span>   <span class="comment"># 绘制图形</span>lines<span class="punctuation">(</span>dose<span class="punctuation">,</span> drugB<span class="punctuation">,</span> type<span class="operator">=</span><span class="string">"b"</span><span class="punctuation">,</span>       pch<span class="operator">=</span><span class="number">17</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">)</span><span class="comment"># 绘制图形</span>abline<span class="punctuation">(</span>h<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">30</span><span class="punctuation">)</span><span class="punctuation">,</span> lwd<span class="operator">=</span><span class="number">1.5</span><span class="punctuation">,</span> lty<span class="operator">=</span><span class="number">2</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"gray"</span><span class="punctuation">)</span> library<span class="punctuation">(</span>Hmisc<span class="punctuation">)</span><span class="comment"># 添加次要刻度线</span>minor.tick<span class="punctuation">(</span>nx<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> ny<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> tick.ratio<span class="operator">=</span><span class="number">0.5</span><span class="punctuation">)</span><span class="comment"># 添加次要刻度线</span>legend<span class="punctuation">(</span><span class="string">"topleft"</span><span class="punctuation">,</span> inset<span class="operator">=</span><span class="number">.05</span><span class="punctuation">,</span> title<span class="operator">=</span><span class="string">"Drug Type"</span><span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"A"</span><span class="punctuation">,</span><span class="string">"B"</span><span class="punctuation">)</span><span class="punctuation">,</span>       lty<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">15</span><span class="punctuation">,</span> <span class="number">17</span><span class="punctuation">)</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"red"</span><span class="punctuation">,</span> <span class="string">"blue"</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="comment"># 添加图例</span>par<span class="punctuation">(</span>opar<span class="punctuation">)</span></code></pre><img src="/medias/image-20210815125131399.png" alt="图3-10 进行标注后的图形，对比了药物A和药物B的效果" style="zoom:50%;"><p>图3-10 的几乎所有外观元素都可以使用本章中讨论过的选项进行修改。除此之外，还有很多其他方式可以指定想要的选项。最后一种需要研究的图形标注是向图形本身添加文本，请阅读下一节。</p><h5 id="3-4-5-文本标注">3.4.5   文本标注</h5><p>我们可以通过函数 text() 和 mtext() 将文本添加到图形上。text() 可向绘图区域内部添加文本，而 mtext() 则向图形的四个边界之一添加文本。使用格式分别为：</p><pre><code class="highlight R">text<span class="punctuation">(</span>location<span class="punctuation">,</span> <span class="string">"text to place"</span><span class="punctuation">,</span> pos<span class="punctuation">,</span> ...<span class="punctuation">)</span>mtext<span class="punctuation">(</span><span class="string">"text to place"</span><span class="punctuation">,</span> side<span class="punctuation">,</span> line<span class="operator">=</span>n<span class="punctuation">,</span> ...<span class="punctuation">)</span></code></pre><p>常用选项列于表3-9 中。<br><strong>表3-9 函数 text() 和 mtext() 的选项</strong></p><table><thead><tr><th>选  项</th><th>描  述</th></tr></thead><tbody><tr><td>location</td><td>文本的位置参数。可为一对 x、y 坐标，也可通过指定 location 为 locator(1) 使用鼠标交互式地确定摆放位置</td></tr><tr><td>pos</td><td>文本相对于位置参数的方位。1=下，2=左，3=上，4=右。如果指定了 pos，就可以同时指定参数 offset=作为偏移量，以相对于单个字符宽度的比例表示</td></tr><tr><td>side</td><td>指定用来放置文本的边。1=下，2=左，3=上，4=右。你可以指定参数 line=来内移或外移文本，随着值的增加，文本将外移。也可使用 adj=0 将文本向左下对齐，或使用 adj=1 右上对齐</td></tr></tbody></table><p>其他常用的选项有 cex、col 和 font（分别用来调整字号、颜色和字体样式）。</p><p>除了用来添加文本标注以外，text() 函数也通常用来标示图形中的点。我们只需指定一系列的 x、y 坐标作为位置参数，同时以向量的形式指定要放置的文本。x、y 和文本标签向量的长度应当相同。下面给出了一个示例，结果如图3-11 所示。</p><pre><code class="highlight R">attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span> plot<span class="punctuation">(</span>wt<span class="punctuation">,</span> mpg<span class="punctuation">,</span>     main<span class="operator">=</span><span class="string">"Mileage vs. Car Weight"</span><span class="punctuation">,</span>      xlab<span class="operator">=</span><span class="string">"Weight"</span><span class="punctuation">,</span> ylab<span class="operator">=</span><span class="string">"Mileage"</span><span class="punctuation">,</span>      pch<span class="operator">=</span><span class="number">18</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"blue"</span><span class="punctuation">)</span>text<span class="punctuation">(</span>wt<span class="punctuation">,</span> mpg<span class="punctuation">,</span>      row.names<span class="punctuation">(</span>mtcars<span class="punctuation">)</span><span class="punctuation">,</span>      cex<span class="operator">=</span><span class="number">0.6</span><span class="punctuation">,</span> pos<span class="operator">=</span><span class="number">4</span><span class="punctuation">,</span> col<span class="operator">=</span><span class="string">"red"</span><span class="punctuation">)</span>detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre> <img src="/medias/image-20210815125743404.png" alt="图3-11 一幅散点图（车重与每加仑汽油行驶英里数）的示例，各点均添加了标签（车型）" style="zoom:50%;"><p>这个例子中，我们针对数据框 mtcars 提供的 32 种车型的车重和每加仑汽油行驶英里数绘制了散点图。函数 text() 被用来在各个数据点右侧添加车辆型号。各点的标签大小被缩小了 40%， 颜色为红色。</p><p>作为第二个示例，以下是一段展示不同字体族的代码：</p><pre><code class="highlight R">opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>cex<span class="operator">=</span><span class="number">1.5</span><span class="punctuation">)</span> plot<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span><span class="number">7</span><span class="punctuation">,</span><span class="number">1</span><span class="operator">:</span><span class="number">7</span><span class="punctuation">,</span>type<span class="operator">=</span><span class="string">"n"</span><span class="punctuation">)</span>text<span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="string">"Example of default text"</span><span class="punctuation">)</span> text<span class="punctuation">(</span><span class="number">4</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span>family<span class="operator">=</span><span class="string">"mono"</span><span class="punctuation">,</span><span class="string">"Example of mono-spaced text"</span><span class="punctuation">)</span> text<span class="punctuation">(</span><span class="number">5</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span>family<span class="operator">=</span><span class="string">"serif"</span><span class="punctuation">,</span><span class="string">"Example of serif text"</span><span class="punctuation">)</span> par<span class="punctuation">(</span>opar<span class="punctuation">)</span></code></pre><p>在 Windows 系统中输出的结果如图3-12 所示。这里为了获得更好的显示效果，我们使用 par() 函数增大了字号。</p><img src="/medias/image-20210815130012800.png" alt="图3-12 Windows中不同字体族的示例" style="zoom:50%;"><p>本例所得结果因平台而异，因为不同系统中映射的常规字体、等宽字体和有衬线字体有所不同。在你的系统上，结果看起来如何呢？</p><h5 id="3-4-6-数学标注">3.4.6   数学标注</h5><p>最后， 你可以使用类似于 TeX 中的写法为图形添加数学符号和公式。 请参阅 help(plotmath) 以获得更多细节和示例。要即时看效果，可以尝试执行 demo(plotmath)。部分运行结果如图3-13 所示。函数plotmath() 可以为图形主体或边界上的标题、坐标轴名称或文本标注添加数学符号。</p><p><img src="/medias/image-20210815130719975.png" alt="图3-13 demo(plotmath) 的部分结果"></p><p>同时比较多幅图形，我们通常可以更好地洞察数据的性质。所以，作为本章的结尾，下面讨论将多幅图形组合为一幅图形的方法。</p><h5 id="3-5-图形的组合">3.5     图形的组合</h5><p>在R中使用函数 par() 或 layout() 可以容易地组合多幅图形为一幅总括图形。此时请不要担心所要组合图形的具体类型，这里我们只关注组合它们的一般方法。后续各章将讨论每类图形的绘制和解读问题。</p><p>你可以在 par() 函数中使用图形参数 mfrow=c(nrows, ncols) 来创建按行填充的、行数为</p><p>nrows、列数为 ncols 的图形矩阵。另外，可以使用 mfcol=c(nrows, ncols) 按列填充矩阵。举例来说，以下代码创建了四幅图形并将其排布在两行两列中：</p><pre><code class="highlight R">attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>mfrow<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">2</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">)</span><span class="punctuation">)</span>plot<span class="punctuation">(</span>wt<span class="punctuation">,</span>mpg<span class="punctuation">,</span> main<span class="operator">=</span><span class="string">"Scatterplot of wt vs. mpg"</span><span class="punctuation">)</span> plot<span class="punctuation">(</span>wt<span class="punctuation">,</span>disp<span class="punctuation">,</span> main<span class="operator">=</span><span class="string">"Scatterplot of wt vs. disp"</span><span class="punctuation">)</span> hist<span class="punctuation">(</span>wt<span class="punctuation">,</span> main<span class="operator">=</span><span class="string">"Histogram of wt"</span><span class="punctuation">)</span>boxplot<span class="punctuation">(</span>wt<span class="punctuation">,</span> main<span class="operator">=</span><span class="string">"Boxplot of wt"</span><span class="punctuation">)</span> par<span class="punctuation">(</span>opar<span class="punctuation">)</span>detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre><p>结果如图3-14所示。</p> <img src="/medias/image-20210815131251929.png" alt="图3-14 通过 par(mfrow=c(2,2)) 组合的四幅图形" style="zoom:50%;"><p>作为第二个示例，让我们依三行一列排布三幅图形。代码如下：</p><pre><code class="highlight R">attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>mfrow<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">)</span>hist<span class="punctuation">(</span>wt<span class="punctuation">)</span> hist<span class="punctuation">(</span>mpg<span class="punctuation">)</span> hist<span class="punctuation">(</span>disp<span class="punctuation">)</span> par<span class="punctuation">(</span>opar<span class="punctuation">)</span> detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre><p>所得图形如图3-15 所示。请注意，高级绘图函数 hist() 包含了一个默认的标题（<strong>使用 main=“” 可以禁用它，抑或使用 ann=FALSE 来禁用所有标题和标签</strong>）。</p><img src="/medias/image-20210815131613159.png" alt="图3-15 通过 par(mfrow=c(3,1)) 组合的三幅图形" style="zoom:50%;"><p>函数 layout() 的调用形式为 layout(mat)，其中的 mat 是一个矩阵，它指定了所要组合的多个图形的所在位置。在以下代码中，一幅图被置于第 1 行，另两幅图则被置于第 2 行：</p><pre><code class="highlight R">attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>layout<span class="punctuation">(</span>matrix<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">)</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> byrow <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span><span class="punctuation">)</span> hist<span class="punctuation">(</span>wt<span class="punctuation">)</span>hist<span class="punctuation">(</span>mpg<span class="punctuation">)</span> hist<span class="punctuation">(</span>disp<span class="punctuation">)</span> detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre><p>结果如图3-16所示。</p><img src="/medias/image-20210815131823369.png" alt="图3-16 使用函数 layout() 组合的三幅图形，各列宽度为默认值" style="zoom:50%;"><p>为了更精确地控制每幅图形的大小，可以有选择地在 layout() 函数中使用 widths= 和 heights= 两个参数。其形式为：</p><p>❑ widths = 各列宽度值组成的一个向量</p><p>❑ heights = 各行高度值组成的一个向量</p><p>相对宽度可以直接通过数值指定，绝对宽度（以厘米为单位）可以通过函数 lcm() 来指定。</p><p>在以下代码中，我们再次将一幅图形置于第 1 行，两幅图形置于第 2 行。但第 1 行中图形的高度是第 2 行中图形高度的二分之一。除此之外，右下角图形的宽度是左下角图形宽度的三分之一：</p><pre><code class="highlight R">attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span>layout<span class="punctuation">(</span>matrix<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">)</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> byrow <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span><span class="punctuation">,</span>        widths<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span> heights<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span><span class="punctuation">)</span>hist<span class="punctuation">(</span>wt<span class="punctuation">)</span>hist<span class="punctuation">(</span>mpg<span class="punctuation">)</span> hist<span class="punctuation">(</span>disp<span class="punctuation">)</span> detach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span></code></pre><p>所得图形如图3-17所示。</p><img src="/medias/image-20210815132318103.png" alt="图3-17 使用函数 layout() 组合的三幅图形，各列宽度为指定值" style="zoom:50%;"><p>如你所见，layout() 函数能够让我们轻松地控制最终图形中的子图数量和摆放方式，以及这些子图的相对大小。请参考 help(layout) 以了解更多细节。</p><p><strong>图形布局的精细控制</strong></p><p>可能有很多时候，你想通过排布或叠加若干图形来创建单幅的、有意义的图形，这需要有对图形布局的精细控制能力。你可以使用图形参数 fig=完成这个任务。代码清单3-4 通过在散点图上添加两幅箱线图，创建了单幅的增强型图形。结果如图3-18 所示。</p><p><strong>代码清单3-4 多幅图形布局的精细控制</strong></p><pre><code class="highlight R">opar <span class="operator">&lt;-</span> par<span class="punctuation">(</span>no.readonly<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> par<span class="punctuation">(</span>fig<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">0.8</span><span class="punctuation">,</span> <span class="number">0</span><span class="punctuation">,</span> <span class="number">0.8</span><span class="punctuation">)</span><span class="punctuation">)</span> plot<span class="punctuation">(</span>mtcars<span class="operator">$</span>wt<span class="punctuation">,</span> mtcars<span class="operator">$</span>mpg<span class="punctuation">,</span>     xlab<span class="operator">=</span><span class="string">"Miles Per Gallon"</span><span class="punctuation">,</span>      ylab<span class="operator">=</span><span class="string">"Car Weight"</span><span class="punctuation">)</span><span class="comment"># 设置散点图</span>par<span class="punctuation">(</span>fig<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">0.8</span><span class="punctuation">,</span> <span class="number">0.55</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span> new<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> <span class="comment"># 在上方添加箱线图</span>boxplot<span class="punctuation">(</span>mtcars<span class="operator">$</span>wt<span class="punctuation">,</span> horizontal<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> axes<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span><span class="comment"># 在上方添加箱线图</span>par<span class="punctuation">(</span>fig<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">0.65</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">0</span><span class="punctuation">,</span> <span class="number">0.8</span><span class="punctuation">)</span><span class="punctuation">,</span> new<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span> <span class="comment"># 在右侧添加箱线图</span>boxplot<span class="punctuation">(</span>mtcars<span class="operator">$</span>mpg<span class="punctuation">,</span> axes<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span><span class="comment"># 在右侧添加箱线图</span>mtext<span class="punctuation">(</span><span class="string">"Enhanced Scatterplot"</span><span class="punctuation">,</span> side<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> outer<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> line<span class="operator">=</span><span class="operator">-</span><span class="number">3</span><span class="punctuation">)</span> par<span class="punctuation">(</span>opar<span class="punctuation">)</span></code></pre><img src="/medias/image-20210815133335137.png" alt="图3-18 边界上添加了两幅箱线图的散点图" style="zoom:50%;"><p>要理解这幅图的绘制原理，请试想完整的绘图区域：左下角坐标为 (0, 0)，而右上角坐标为 (1, 1)。图3-19 是一幅示意图。参数 fig=的取值是一个形如 c(x1, x2, y1, y2) 的数值向量。</p><img src="/medias/image-20210815133514963.png" alt="图3-19  使用图形参数fig=指定位置" style="zoom:80%;"><p>第一个 fig=将散点图设定为占据横向范围0~0.8，纵向范围 0~0.8 。上方的箱线图横向占据 0~0.8 ，纵向 0.55~1 。右侧的箱线图横向占据 0.65~1 ，纵向 0~0.8。fig=默认会新建一幅图形，所以在添加一幅图到一幅现有图形上时，请设定参数 new=TRUE。</p><p>我将参数选择为 0.55 而不是 0.8，这样上方的图形就不会和散点图拉得太远。类似地，我选择了参数 0.65 以拉近右侧箱线图和散点图的距离。你需要不断尝试找到合适的位置参数。</p><blockquote><p><strong>注意</strong></p><p>各独立子图所需空间的大小可能与设备相关。如果你遇到了 “Error in plot.new(): figure margins too large” 这样的错误，请尝试在整个图形的范围内修改各个子图占据的区域位置和大小。</p></blockquote><p>你可以使用图形参数 fig=将若干图形以任意排布方式组合到单幅图形中。稍加练习，你就可以通过这种方法极其灵活地创建复杂的视觉呈现。</p><h4 id="3-6-小结">3.6 小结</h4><p>本章中，我们回顾了创建图形和以各种格式保存图形的方法。本章的主体则是关于如何修改R绘制的默认图形，以得到更加有用或更吸引人的图形。你学习了如何修改一幅图形的坐标轴、字体、绘图符号、线条和颜色，以及如何添加标题、副标题、标签、文本、图例和参考线，看到了如何指定图形和边界的大小，以及将多幅图形组合为实用的单幅图形。</p><p>本章的焦点是那些可以应用于所有图形的通用方法（第 19 章的 ggplot2 图形是一个例外）。后续各章将着眼于特定的图形类型。例如，第6章介绍了对单变量绘图的各种方法；对变量间关系绘图的方法将于第11章讨论；在第 19 章中，我们则讨论高级的绘图方法，包括显示多变量数据的创新性方法。</p><p>在其他各章中，我们将会讨论对于某些统计方法来说特别实用的数据可视化方法。图形是现代数据分析的核心组成部分，所以我将尽力将它们整合到各类统计方法的讨论中。</p><p>在前一章中，我们讨论了一系列输入或导入数据到R中的方法。遗憾的是，现实数据极少以直接可用的格式出现。下一章，我们将关注如何将数据转换或修改为更有助于分析的形式。</p><h3 id="第4章-基本数据管理">第4章   基本数据管理</h3><blockquote><p><strong>本章内容</strong><br>❑ 操纵日期和缺失值<br>❑ 熟悉数据类型的转换<br>❑ 变量的创建和重编码<br>❑ 数据集的排序、合并与取子集<br>❑ 选入和丢弃变量</p></blockquote><p>在第2章中，我们讨论了多种导入数据到 R 中的方法。遗憾的是，将你的数据表示为矩阵或数据框这样的矩形形式仅仅是数据准备的第一步。这里可以演绎 Kirk 船长在《星际迷航》“末日决战的滋味”一集中的台词（这完全验明了我的极客基因）：“数据是一件麻烦事——一件非常非常麻烦的事。”在我的工作中，有多达 60% 的数据分析时间都花在了实际分析前数据的准备上。我敢大胆地说，多数需要处理现实数据的分析师可能都面临着以某种形式存在的类似问题。让我们先看一个例子。</p><h4 id="4-1-一个示例">4.1     一个示例</h4><p>本人当前工作的研究主题之一是男性和女性在领导各自企业方式上的不同。典型的问题如下。</p><p>❑ 处于管理岗位的男性和女性在听从上级的程度上是否有所不同？</p><p>❑ 这种情况是否依国家的不同而有所不同，或者说这些由性别导致的不同是否普遍存在？</p><p>解答这些问题的一种方法是让多个国家的经理人的上司对其服从程度打分，使用的问题类似于：</p><table><thead><tr><th>这名经理在作出人事决策之前会询问我的意见</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>非常不同意</td><td>不同意</td><td>既不同意也不反对</td><td>同意</td><td>非常同意</td></tr></tbody></table><p>结果数据可能类似于表4-1。各行数据代表了某个经理人的上司对他的评分。</p><p><strong>表4-1  领导行为的性别差异</strong></p><table><thead><tr><th>经理人</th><th>日  期</th><th>国  籍</th><th>性  别</th><th>年  龄</th><th>q1</th><th>q2</th><th>q3</th><th>q4</th><th>q5</th></tr></thead><tbody><tr><td>1</td><td>10/24/14</td><td>US</td><td>M</td><td>32</td><td>5</td><td>4</td><td>5</td><td>5</td><td>5</td></tr><tr><td>2</td><td>10/28/14</td><td>US</td><td>F</td><td>45</td><td>3</td><td>5</td><td>2</td><td>5</td><td>5</td></tr><tr><td>3</td><td>10/01/14</td><td>UK</td><td>F</td><td>25</td><td>3</td><td>5</td><td>5</td><td>5</td><td>2</td></tr><tr><td>4</td><td>10/12/14</td><td>UK</td><td>M</td><td>39</td><td>3</td><td>3</td><td>4</td><td></td><td></td></tr><tr><td>5</td><td>05/01/14</td><td>UK</td><td>F</td><td>99</td><td>2</td><td>2</td><td>1</td><td>2</td><td>1</td></tr></tbody></table><p>在这里，每位经理人的上司根据与服从权威相关的五项陈述（q1 到 q5）对经理人进行评分。例如，经理人 1 是一位在美国工作的32岁男性，上司对他的评价是惯于顺从，而经理人 5 是一位在英国工作的，年龄未知（99 可能代表缺失）的女性，服从程度评分较低。日期一栏记录了进行评分的时间。</p><p>一个数据集中可能含有几十个变量和成千上万的观测，但为了简化示例，我们仅选取了 5 行 10 列的数据。另外，我们已将关于经理人服从行为的问题数量限制为 5。在现实的研究中，你很可能会使用 10 到 20 个类似的问题来提高结果的可靠性和有效性。可以使用代码清单4-1 中的代码创建一个包含表4-1 中数据的数据框。</p><p>代码清单4-1 创建 leadership 数据框</p><pre><code class="highlight R">manager <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">)</span>date <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"10/24/08"</span><span class="punctuation">,</span> <span class="string">"10/28/08"</span><span class="punctuation">,</span> <span class="string">"10/1/08"</span><span class="punctuation">,</span> <span class="string">"10/12/08"</span><span class="punctuation">,</span> <span class="string">"5/1/09"</span><span class="punctuation">)</span> country <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"US"</span><span class="punctuation">,</span> <span class="string">"US"</span><span class="punctuation">,</span> <span class="string">"UK"</span><span class="punctuation">,</span> <span class="string">"UK"</span><span class="punctuation">,</span> <span class="string">"UK"</span><span class="punctuation">)</span>gender <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"M"</span><span class="punctuation">,</span> <span class="string">"F"</span><span class="punctuation">,</span> <span class="string">"F"</span><span class="punctuation">,</span> <span class="string">"M"</span><span class="punctuation">,</span> <span class="string">"F"</span><span class="punctuation">)</span> age <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">32</span><span class="punctuation">,</span> <span class="number">45</span><span class="punctuation">,</span> <span class="number">25</span><span class="punctuation">,</span> <span class="number">39</span><span class="punctuation">,</span> <span class="number">99</span><span class="punctuation">)</span>q1 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">5</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span>q2 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">4</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span>q3 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">5</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span>q4 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">5</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="literal">NA</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span>q5 <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">5</span><span class="punctuation">,</span> <span class="number">5</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="literal">NA</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span>leadership <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>manager<span class="punctuation">,</span> date<span class="punctuation">,</span> country<span class="punctuation">,</span> gender<span class="punctuation">,</span> age<span class="punctuation">,</span>                          q1<span class="punctuation">,</span> q2<span class="punctuation">,</span> q3<span class="punctuation">,</span> q4<span class="punctuation">,</span> q5<span class="punctuation">,</span> stringsAsFactors<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span></code></pre><p>为了解决感兴趣的问题，你必须首先解决一些数据管理方面的问题。这里列出其中一部分。</p><p>❑ 五个评分（q1 到 q5）需要组合起来，即为每位经理人生成一个平均服从程度得分。</p><p>❑ 在问卷调查中，被调查者经常会跳过某些问题。例如，为 4 号经理人打分的上司跳过了问题 4 和问题 5。你需要一种处理不完整数据的方法，同时也需要将 99 岁这样的年龄值重编码为缺失值。</p><p>❑ 一个数据集中也许会有数百个变量，但你可能仅对其中的一些感兴趣。为了简化问题， 我们往往希望创建一个只包含那些感兴趣变量的数据集。</p><p>❑ 既往研究表明，领导行为可能随经理人的年龄而改变，二者存在函数关系。要检验这种观点，你希望将当前的年龄值重编码为类别型的年龄组（例如年轻、中年、年长）。</p><p>❑ 领导行为可能随时间推移而发生改变。你可能想重点研究最近全球金融危机期间的服从行为。为了做到这一点，你希望将研究范围限定在某一个特定时间段收集的数据上（比如，2009 年 1 月 1 日到 2009 年 12 月 31 日）。</p><p>我们将在本章中逐个解决这些问题，同时完成如数据集的组合与排序这样的基本数据管理任务。然后，在第 5 章，我们会讨论一些更为高级的话题。</p><h4 id="4-2-创建新变量">4.2    创建新变量</h4><p>在典型的研究项目中，你可能需要创建新变量或者对现有的变量进行变换。这可以通过以下形式的语句来完成：</p><pre><code class="highlight plaintext">变量名 &lt;- 表达式</code></pre><p>以上语句中的“表达式”部分可以包含多种运算符和函数。表4-2 列出了 R 中的算术运算符。算术运算符可用于构造公式（formula）。</p><p><strong>表4-2  算术运算符</strong></p><table><thead><tr><th>运 算 符</th><th>描  述</th></tr></thead><tbody><tr><td>+</td><td>加</td></tr><tr><td>-</td><td>减</td></tr><tr><td>*</td><td>乘</td></tr><tr><td>/</td><td>除</td></tr><tr><td>^或**</td><td>求幂</td></tr><tr><td>x%%y</td><td>求余（x mod y）。5%%2 的结果为 1</td></tr><tr><td>x%/%y</td><td>整数除法。5%/%2 的结果为 2</td></tr></tbody></table><p>假设你有一个名为 mydata 的数据框，其中的变量为 x1 和 x2，现在你想创建一个新变量 sumx 存储以上两个变量的加和，并创建一个名为 meanx 的新变量存储这两个变量的均值。如果使用代码：</p><pre><code class="highlight R">sumx <span class="operator">&lt;-</span> x1 <span class="operator">+</span> x2 meanx <span class="operator">&lt;-</span> <span class="punctuation">(</span>x1 <span class="operator">+</span> x2<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span></code></pre><p>你将得到一个错误，因为 R 并不知道 x1 和 x2 来自于数据框 mydata。如果你转而使用代码：</p><pre><code class="highlight R">sumx <span class="operator">&lt;-</span> mydata<span class="operator">$</span>x1 <span class="operator">+</span> mydata<span class="operator">$</span>x2 meanx <span class="operator">&lt;-</span> <span class="punctuation">(</span>mydata<span class="operator">$</span>x1 <span class="operator">+</span> mydata<span class="operator">$</span>x2<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span></code></pre><p>语句可成功执行，但是你只会得到一个数据框（mydata）和两个独立的向量（sumx 和 meanx）。这也许并不是你真的想要的。因为从根本上说，你希望将两个新变量整合到原始的数据框中。代码清单4-2 提供了三种不同的方式来实现这个目标，具体选择哪一个由你决定，所得结果都是相同的。</p><p>代码清单4-2 创建新变量</p><pre><code class="highlight R">mydata<span class="operator">&lt;-</span>data.frame<span class="punctuation">(</span>x1 <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">2</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">6</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">)</span><span class="punctuation">,</span>                   x2 <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">3</span><span class="punctuation">,</span> <span class="number">4</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">8</span><span class="punctuation">)</span><span class="punctuation">)</span>mydata<span class="operator">$</span>sumx <span class="operator">&lt;-</span> mydata<span class="operator">$</span>x1 <span class="operator">+</span> mydata<span class="operator">$</span>x2 mydata<span class="operator">$</span>meanx <span class="operator">&lt;-</span> <span class="punctuation">(</span>mydata<span class="operator">$</span>x1 <span class="operator">+</span> mydata<span class="operator">$</span>x2<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span>attach<span class="punctuation">(</span>mydata<span class="punctuation">)</span> mydata<span class="operator">$</span>sumx <span class="operator">&lt;-</span> x1 <span class="operator">+</span> x2mydata<span class="operator">$</span>meanx <span class="operator">&lt;-</span> <span class="punctuation">(</span>x1 <span class="operator">+</span> x2<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span> detach<span class="punctuation">(</span>mydata<span class="punctuation">)</span>mydata <span class="operator">&lt;-</span> transform<span class="punctuation">(</span>mydata<span class="punctuation">,</span>                    sumx <span class="operator">=</span> x1 <span class="operator">+</span> x2<span class="punctuation">,</span>                     meanx <span class="operator">=</span> <span class="punctuation">(</span>x1 <span class="operator">+</span> x2<span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span></code></pre><p>我个人倾向于第三种方式，即 transform() 函数的一个示例。这种方式简化了按需创建新变量并将其保存到数据框中的过程。</p><h4 id="4-3-变量的重编码">4.3    变量的重编码</h4><p>重编码涉及根据同一个变量和/或其他变量的现有值创建新值的过程。举例来说，你可能想：</p><p>❑ 将一个连续型变量修改为一组类别值；</p><p>❑ 将误编码的值替换为正确值；</p><p>❑ 基于一组分数线创建一个表示及格/不及格的变量。</p><p>要重编码数据，可以使用R中的一个或多个逻辑运算符（见表4-3）。逻辑运算符表达式可返回 TRUE 或 FALSE。</p><p><strong>表4-3  逻辑运算符</strong></p><table><thead><tr><th>运 算 符</th><th>描  述</th></tr></thead><tbody><tr><td>&lt;</td><td>小于</td></tr><tr><td>&lt;=</td><td>小于或等于</td></tr><tr><td>&gt;</td><td>大于</td></tr><tr><td>&gt;=</td><td>大于或等于</td></tr><tr><td>==</td><td>严格等于①</td></tr><tr><td>!=</td><td>不等于</td></tr><tr><td>!x</td><td>非x</td></tr><tr><td>x | y</td><td>x或y</td></tr><tr><td>x &amp; y</td><td>x和y</td></tr><tr><td>isTRUE(x)</td><td>测试x是否为TRUE</td></tr></tbody></table><p>① 类似于其他科学计算语言，在R中比较浮点型数值时请慎用==，以防出现误判。详情参考“R FAQ” 7.31节。</p><p>不妨假设你希望将 leadership 数据集中经理人的连续型年龄变量 age 重编码为类别型变量 agecat（Young、 Middle Aged、Elder）。首先，必须将 99 岁的年龄值重编码为缺失值，使用的代码为：</p><pre><code class="highlight R">leadership<span class="operator">$</span>age<span class="punctuation">[</span>leadership<span class="operator">$</span>age <span class="operator">==</span> <span class="number">99</span><span class="punctuation">]</span>  <span class="operator">&lt;-</span> <span class="literal">NA</span></code></pre><p>语句 variable[condition] &lt;- expression 将仅在 condition 的值为 TRUE 时执行赋值。在指定好年龄中的缺失值后，你可以接着使用以下代码创建 agecat 变量：</p><pre><code class="highlight R">leadership<span class="operator">$</span>agecat<span class="punctuation">[</span>leadership<span class="operator">$</span>age <span class="operator">&gt;</span> <span class="number">75</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Elder"</span> leadership<span class="operator">$</span>agecat<span class="punctuation">[</span>leadership<span class="operator">$</span>age <span class="operator">&gt;=</span> <span class="number">55</span> <span class="operator">&amp;</span>                  leadership<span class="operator">$</span>age <span class="operator">&lt;=</span> <span class="number">75</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Middle Aged"</span> leadership<span class="operator">$</span>agecat<span class="punctuation">[</span>leadership<span class="operator">$</span>age <span class="operator">&lt;</span> <span class="number">55</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Young"</span></code></pre><p>你在 leadership$agecat 中写上了数据框的名称，以确保新变量能够保存到数据框中。</p><p>（我将中年人（Middle Aged）定义为 55 到 75 岁，这样不会让我感觉自己是个老古董。）请注意， 如果你一开始没把 99 重编码为 age 的缺失值，那么经理人 5 就将在变量 agecat 中被错误地赋值为“老年人”（Elder）。</p><p>这段代码可以写成更紧凑的：</p><pre><code class="highlight R">leadership <span class="operator">&lt;-</span> within<span class="punctuation">(</span>leadership<span class="punctuation">,</span><span class="punctuation">{</span>    agecat <span class="operator">&lt;-</span> <span class="literal">NA</span>    agecat<span class="punctuation">[</span>age <span class="operator">&gt;</span> <span class="number">75</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Elder"</span>     agecat<span class="punctuation">[</span>age <span class="operator">&gt;=</span> <span class="number">55</span> <span class="operator">&amp;</span> age <span class="operator">&lt;=</span> <span class="number">75</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Middle Aged"</span>     agecat<span class="punctuation">[</span>age <span class="operator">&lt;</span> <span class="number">55</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"Young"</span> <span class="punctuation">}</span><span class="punctuation">)</span></code></pre><p>函数 within() 与函数 with() 类似（见2.2.4节），不同的是它允许你修改数据框。首先，创建了 agecat 变量，并将每一行都设为缺失值。括号中剩下的语句接下来依次执行。请记住 agecat 现在只是一个字符型变量，你可能更希望像 2.2.5 节讲解的那样把它转换成一个有序型因子。</p><p>若干程序包都提供了实用的变量重编码函数，特别地，car 包中的 recode() 函数可以十分简便地重编码数值型、字符型向量或因子。而 doBy 包提供了另外一个很受欢迎的函数 recodevar()。最后，R 中也自带了 cut()，可将一个数值型变量按值域切割为多个区间，并返回一个因子。</p><h4 id="4-4-变量的重命名">4.4    变量的重命名</h4><p>如果对现有的变量名称不满意，你可以交互地或者以编程的方式修改它们。假设你希望将变量名 manager 修改为 managerID，并将 date 修改为 testDate，那么可以使用语句：</p><pre><code class="highlight R">fix<span class="punctuation">(</span>leadership<span class="punctuation">)</span></code></pre><p>来调用一个交互式的编辑器。然后你单击变量名，然后在弹出的对话框中将其重命名（见图4-1）。</p><img src="/medias/image-20210815161058667.png" alt="图4-1 使用 fix() 函数交互式地进行变量重命名" style="zoom:67%;"><p>若以编程方式，可以通过 names() 函数来重命名变量。例如：</p><pre><code class="highlight R"><span class="built_in">names</span><span class="punctuation">(</span>leadership<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"testDate"</span></code></pre><p>将重命名 date 为 testDate，就像以下代码演示的一样：</p><pre><code class="highlight R"><span class="operator">&gt;</span> <span class="built_in">names</span><span class="punctuation">(</span>leadership<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"manager"</span> <span class="string">"date"</span>  <span class="string">"country"</span> <span class="string">"gender"</span> <span class="string">"age"</span>     <span class="string">"q1"</span>             <span class="string">"q2"</span> <span class="punctuation">[</span><span class="number">8</span><span class="punctuation">]</span> <span class="string">"q3"</span>   <span class="string">"q4"</span>   <span class="string">"q5"</span><span class="operator">&gt;</span> <span class="built_in">names</span><span class="punctuation">(</span>leadership<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"testDate"</span><span class="operator">&gt;</span> leadershipmanager testDate country gender age q1 q2 q3 q4 q5 <span class="number">1</span>    <span class="number">1</span> <span class="number">10</span><span class="operator">/</span><span class="number">24</span><span class="operator">/</span><span class="number">08</span>  US   M <span class="number">32</span> <span class="number">5</span> <span class="number">4</span> <span class="number">5</span> <span class="number">5</span> <span class="number">5</span><span class="number">2</span>    <span class="number">2</span> <span class="number">10</span><span class="operator">/</span><span class="number">28</span><span class="operator">/</span><span class="number">08</span>  US   <span class="built_in">F</span> <span class="number">45</span> <span class="number">3</span> <span class="number">5</span> <span class="number">2</span> <span class="number">5</span> <span class="number">5</span><span class="number">3</span>    <span class="number">3</span> <span class="number">10</span><span class="operator">/</span><span class="number">1</span><span class="operator">/</span><span class="number">08</span>   UK   <span class="built_in">F</span> <span class="number">25</span> <span class="number">3</span> <span class="number">5</span> <span class="number">5</span> <span class="number">5</span> <span class="number">2</span><span class="number">4</span>    <span class="number">4</span> <span class="number">10</span><span class="operator">/</span><span class="number">12</span><span class="operator">/</span><span class="number">08</span>  UK   M <span class="number">39</span> <span class="number">3</span> <span class="number">3</span> <span class="number">4</span> <span class="literal">NA</span> <span class="literal">NA</span><span class="number">5</span>    <span class="number">5</span>  <span class="number">5</span><span class="operator">/</span><span class="number">1</span><span class="operator">/</span><span class="number">09</span>   UK   <span class="built_in">F</span> <span class="number">99</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span></code></pre><p>以类似的方式：</p><pre><code class="highlight R"><span class="built_in">names</span><span class="punctuation">(</span>leadership<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">6</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"item1"</span><span class="punctuation">,</span> <span class="string">"item2"</span><span class="punctuation">,</span> <span class="string">"item3"</span><span class="punctuation">,</span> <span class="string">"item4"</span><span class="punctuation">,</span> <span class="string">"item5"</span><span class="punctuation">)</span></code></pre><p>将重命名 q1 到 q5 为 item1 到 item5。</p><p>最后，plyr 包中有一个 rename() 函数，可用于修改变量名。这个函数默认并没有被安装， 所以你首先要使用命令 install.packages(“plyr”) 对之进行安装。</p><p>rename() 函数的使用格式为：</p><pre><code class="highlight R">rename<span class="punctuation">(</span>dataframe<span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span>oldname<span class="operator">=</span><span class="string">"newname"</span><span class="punctuation">,</span> oldname<span class="operator">=</span><span class="string">"newname"</span><span class="punctuation">,</span>...<span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>这里是一个示例：</p><pre><code class="highlight R">library<span class="punctuation">(</span>plyr<span class="punctuation">)</span>leadership <span class="operator">&lt;-</span> rename<span class="punctuation">(</span>leadership<span class="punctuation">,</span>                      <span class="built_in">c</span><span class="punctuation">(</span>manager<span class="operator">=</span><span class="string">"managerID"</span><span class="punctuation">,</span> date<span class="operator">=</span><span class="string">"testDate"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>plyr 包拥有一系列强大的数据集操作函数，你可以在<a href="http://had.co.nz/plyr">http://had.co.nz/plyr</a> 获得更多信息。</p><h4 id="4-5-缺失值">4.5    缺失值</h4><p>在任何规模的项目中，数据都可能由于未作答问题、设备故障或误编码数据的缘故而不完整。在R中，缺失值以符号 NA（Not Available，不可用）表示。与 SAS 等程序不同，R 中字符型和数值型数据使用的缺失值符号是相同的。</p><p>R 提供了一些函数，用于识别包含缺失值的观测。函数 <a href="http://is.na">is.na</a>() 允许你检测缺失值是否存在。假设你有一个向量：</p><pre><code class="highlight R">y <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> <span class="literal">NA</span><span class="punctuation">)</span></code></pre><p>然后使用函数：</p><pre><code class="highlight R"><span class="built_in">is.na</span><span class="punctuation">(</span>y<span class="punctuation">)</span></code></pre><p>将返回 c(FALSE, FALSE, FALSE, TRUE)。</p><p>请注意 <a href="http://is.na">is.na</a>() 函数是如何作用于一个对象上的。它将返回一个相同大小的对象，如果某个元素是缺失值，相应的位置将被改写为 TRUE，不是缺失值的位置则为 FALSE。代码清单4-3 将此函数应用到了我们的 leadership 数据集上。</p><p><strong>代码清单4-3  使用 <a href="http://is.na">is.na</a>() 函数</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> <span class="built_in">is.na</span><span class="punctuation">(</span>leadership<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">6</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">]</span><span class="punctuation">)</span>  q1 q2     q3    q4   q5 <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="punctuation">[</span><span class="number">4</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">TRUE</span> <span class="literal">TRUE</span> <span class="punctuation">[</span><span class="number">5</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span> <span class="literal">FALSE</span></code></pre><p>这里的 leadership[,6:10] 将数据框限定到第 6 列至第 10 列，接下来 <a href="http://is.na">is.na</a>() 识别出了缺失值。</p><p>当你在处理缺失值的时候，你要一直记得两件重要的事情。第一，缺失值被认为是不可比较的，即便是与缺失值自身的比较。这意味着无法使用比较运算符来检测缺失值是否存在。例如， 逻辑测试 myvar == NA 的结果永远不会为 TRUE。作为替代，你只能使用处理缺失值的函数（如本节中所述的那些）来识别出 R 数据对象中的缺失值。</p><p>第二，R 并不把无限的或者不可能出现的数值标记成缺失值。再次地，这和其余像 SAS 之类类似的程序处理这类数值的方式所不同。正无穷和负无穷分别用 Inf 和 –Inf 所标记。因此 5/0 返回 Inf。不可能的值（比如说，sin(Inf)）用 NaN 符号来标记（not a number，不是一个数）。若要识别这些数值，你需要用到 is.infinite() 或 is.nan()。</p><h5 id="4-5-1-重编码某些值为缺失值">4.5.1   重编码某些值为缺失值</h5><p>如4.3 节中演示的那样，你可以使用赋值语句将某些值重编码为缺失值。在我们的 leadership 示例中，缺失的年龄值被编码为 99。在分析这一数据集之前，你必须让 R 明白本例中的 99 表示缺失值（否则这些样本的平均年龄将会高得离谱）。你可以通过重编码这个变量完成这项工作：</p><pre><code class="highlight R">leadership<span class="operator">$</span>age<span class="punctuation">[</span>leadership<span class="operator">$</span>age <span class="operator">==</span> <span class="number">99</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="literal">NA</span></code></pre><p>任何等于 99 的年龄值都将被修改为 NA。请确保所有的缺失数据已在分析之前被妥善地编码为缺失值，否则分析结果将失去意义。</p><h5 id="4-5-2-在分析中排除缺失值">4.5.2   在分析中排除缺失值</h5><p>确定了缺失值的位置以后，你需要在进一步分析数据之前以某种方式删除这些缺失值。原因是，含有缺失值的算术表达式和函数的计算结果也是缺失值。举例来说，考虑以下代码：</p><pre><code class="highlight R">x <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="literal">NA</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">)</span>y <span class="operator">&lt;-</span> x<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="operator">+</span> x<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">+</span> x<span class="punctuation">[</span><span class="number">3</span><span class="punctuation">]</span> <span class="operator">+</span> x<span class="punctuation">[</span><span class="number">4</span><span class="punctuation">]</span>z <span class="operator">&lt;-</span> <span class="built_in">sum</span><span class="punctuation">(</span>x<span class="punctuation">)</span></code></pre><p>由于 x 中的第 3 个元素是缺失值，所以 y 和 z 也都是 NA（缺失值）。</p><p>好在多数的数值函数都拥有一个 na.rm=TRUE 选项，可以在计算之前移除缺失值并使用剩余值进行计算：</p><pre><code class="highlight R">x <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="literal">NA</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">)</span>y <span class="operator">&lt;-</span> <span class="built_in">sum</span><span class="punctuation">(</span>x<span class="punctuation">,</span> na.rm<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span></code></pre><p>这里，y 等于 6。</p><p>在使用函数处理不完整的数据时，请务必查阅它们的帮助文档（例如，help(sum)），检查这些函数是如何处理缺失数据的。函数 sum() 只是我们将在第 5 章中讨论的众多函数之一，使用这些函数可以灵活而轻松地转换数据。</p><p>你可以通过函数 na.omit() 移除所有含有缺失值的观测。na.omit() 可以删除所有含有缺失数据的行。在代码清单4-4 中，我们将此函数应用到了 leadership 数据集上。</p><p><strong>代码清单4-4 使用 na.omit() 删除不完整的观测</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> leadershipmanager   date country gender age q1 q2 q3 q4 q5    <span class="comment"># 含有缺失数据的数据框</span><span class="number">1</span> <span class="number">1</span> <span class="number">10</span><span class="operator">/</span><span class="number">24</span><span class="operator">/</span><span class="number">08</span> US M <span class="number">32</span> <span class="number">5</span> <span class="number">4</span> <span class="number">5</span> <span class="number">5</span> <span class="number">5</span><span class="number">2</span> <span class="number">2</span> <span class="number">10</span><span class="operator">/</span><span class="number">28</span><span class="operator">/</span><span class="number">08</span>US <span class="built_in">F</span> <span class="number">40</span> <span class="number">3</span> <span class="number">5</span> <span class="number">2</span> <span class="number">5</span> <span class="number">5</span><span class="number">3</span> <span class="number">3</span> <span class="number">10</span><span class="operator">/</span><span class="number">01</span><span class="operator">/</span><span class="number">08</span> UK <span class="built_in">F</span> <span class="number">25</span> <span class="number">3</span> <span class="number">5</span> <span class="number">5</span> <span class="number">5</span> <span class="number">2</span><span class="number">4</span> <span class="number">4</span> <span class="number">10</span><span class="operator">/</span><span class="number">12</span><span class="operator">/</span><span class="number">08</span> UK M <span class="number">39</span> <span class="number">3</span> <span class="number">3</span> <span class="number">4</span> <span class="literal">NA</span> <span class="literal">NA</span><span class="number">5</span> <span class="number">5</span> <span class="number">05</span><span class="operator">/</span><span class="number">01</span><span class="operator">/</span><span class="number">09</span> UK <span class="built_in">F</span> <span class="literal">NA</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span><span class="operator">&gt;</span> newdata <span class="operator">&lt;-</span> na.omit<span class="punctuation">(</span>leadership<span class="punctuation">)</span><span class="operator">&gt;</span> newdatamanager   date country gender age q1 q2 q3 q4 q5     <span class="comment"># 仅含完整观测的数据框</span><span class="number">1</span> <span class="number">1</span> <span class="number">10</span><span class="operator">/</span><span class="number">24</span><span class="operator">/</span><span class="number">08</span> US M <span class="number">32</span> <span class="number">5</span> <span class="number">4</span> <span class="number">5</span> <span class="number">5</span> <span class="number">5</span><span class="number">2</span> <span class="number">2</span> <span class="number">10</span><span class="operator">/</span><span class="number">28</span><span class="operator">/</span><span class="number">08</span> US <span class="built_in">F</span> <span class="number">40</span> <span class="number">3</span> <span class="number">5</span> <span class="number">2</span> <span class="number">5</span> <span class="number">5</span><span class="number">3</span> <span class="number">3</span> <span class="number">10</span><span class="operator">/</span><span class="number">01</span><span class="operator">/</span><span class="number">08</span> UK <span class="built_in">F</span> <span class="number">25</span> <span class="number">3</span> <span class="number">5</span> <span class="number">5</span> <span class="number">5</span> <span class="number">2</span></code></pre><p>在结果被保存到 newdata 之前，所有包含缺失数据的行均已从 leadership 中删除。</p><p>删除所有含有缺失数据的观测（称为行删除，listwise deletion）是处理不完整数据集的若干手段之一。如果只有少数缺失值或者缺失值仅集中于一小部分观测中，行删除不失为解决缺失值问题的一种优秀方法。但如果缺失值遍布于数据之中，或者一小部分变量中包含大量的缺失数据， 行删除可能会剔除相当比例的数据。我们将在第 18 章中探索若干更为复杂精妙的缺失值处理方法。下面，让我们谈谈日期值。</p><h4 id="4-6-日期值">4.6    日期值</h4><p>日期值通常以字符串的形式输入到 R 中，然后转化为以数值形式存储的日期变量。函数 as.Date() 用于执行这种转化。其语法为 as.Date(x, “input_format”)，其中 x 是字符型数据，input_format 则给出了用于读入日期的适当格式（见表4-4）。</p><p><strong>表4-4 日期格式</strong></p><table><thead><tr><th>符号</th><th>含  义</th><th>示  例</th></tr></thead><tbody><tr><td>%d</td><td>数字表示的日期（0~31）</td><td>01~31</td></tr><tr><td>%a</td><td>缩写的星期名</td><td>Mon</td></tr><tr><td>%A</td><td>非缩写星期名</td><td>Monday</td></tr><tr><td>%m</td><td>月份（00~12）</td><td>00~12</td></tr><tr><td>%b</td><td>缩写的月份</td><td>Jan</td></tr><tr><td>%B</td><td>非缩写月份</td><td>January</td></tr><tr><td>%y</td><td>两位数的年份</td><td>07</td></tr><tr><td>%Y</td><td>四位数的年份</td><td>2007</td></tr></tbody></table><p>日期值的默认输入格式为 yyyy-mm-dd。语句：</p><pre><code class="highlight R">mydates <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"2007-06-22"</span><span class="punctuation">,</span> <span class="string">"2004-02-13"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>将默认格式的字符型数据转换为了对应日期。相反，</p><pre><code class="highlight R">strDates <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"01/05/1965"</span><span class="punctuation">,</span> <span class="string">"08/16/1975"</span><span class="punctuation">)</span> dates <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span>strDates<span class="punctuation">,</span> <span class="string">"%m/%d/%Y"</span><span class="punctuation">)</span></code></pre><p>则使用 mm/dd/yyyy 的格式读取数据。</p><p>在 leadership 数据集中，日期是以 mm/dd/yy 的格式编码为字符型变量的。因此：</p><pre><code class="highlight R">myformat <span class="operator">&lt;-</span> <span class="string">"%m/%d/%y"</span>leadership<span class="operator">$</span>date <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span>leadership<span class="operator">$</span>date<span class="punctuation">,</span> myformat<span class="punctuation">)</span></code></pre><p>使用指定格式读取字符型变量，并将其作为一个日期变量替换到数据框中。这种转换一旦完成， 你就可以使用后续各章中讲到的诸多分析方法对这些日期进行分析和绘图。</p><p>有两个函数对于处理时间戳数据特别实用。Sys.Date() 可以返回当天的日期，而 date() 则返回当前的日期和时间。我写下这段文字的时间是 2021年 8月 15日下午 4:39。所以执行这些函数的结果是：</p><pre><code class="highlight R"><span class="operator">&gt;</span> Sys.Date<span class="punctuation">(</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"2021-08-15"</span><span class="operator">&gt;</span> date<span class="punctuation">(</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Sun Aug 15 16:39:28 2021"</span></code></pre><p>你可以使用函数 format(x, format=“output_format”) 来输出指定格式的日期值，并且可以提取日期值中的某些部分：</p><pre><code class="highlight R"><span class="operator">&gt;</span> today <span class="operator">&lt;-</span> Sys.Date<span class="punctuation">(</span><span class="punctuation">)</span><span class="operator">&gt;</span> format<span class="punctuation">(</span>today<span class="punctuation">,</span> format<span class="operator">=</span><span class="string">"%B %d %Y"</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"八月 15 2021"</span><span class="operator">&gt;</span> format<span class="punctuation">(</span>today<span class="punctuation">,</span> format<span class="operator">=</span><span class="string">"%A"</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"星期日"</span></code></pre><p>format() 函数可接受一个参数（本例中是一个日期）并按某种格式输出结果（本例中使用了表4-4 中符号的组合）。这里最重要的结果是，距离周末只有两天时间了！</p><p>R的内部在存储日期时，是使用自 1970 年 1 月 1 日以来的天数表示的，更早的日期则表示为负数。这意味着可以在日期值上执行算术运算。例如：</p><pre><code class="highlight R"><span class="operator">&gt;</span> startdate <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span><span class="string">"2004-02-13"</span><span class="punctuation">)</span><span class="operator">&gt;</span> enddate  <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span><span class="string">"2011-01-22"</span><span class="punctuation">)</span><span class="operator">&gt;</span> days   <span class="operator">&lt;-</span> enddate <span class="operator">-</span> startdate<span class="operator">&gt;</span> daysTime difference of <span class="number">2535</span> days</code></pre><p>显示了 2004 年 2 月 13 日和 2011 年 1 月 22 日之间的天数。</p><p>最后，也可以使用函数 difftime() 来计算时间间隔，并以星期、天、时、分、秒来表示。假设我出生于 1996 年 1 月 27 日，我现在有多大呢？</p><pre><code class="highlight R"><span class="operator">&gt;</span> today <span class="operator">&lt;-</span> Sys.Date<span class="punctuation">(</span><span class="punctuation">)</span><span class="operator">&gt;</span> dob  <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span><span class="string">"1996-1-27"</span><span class="punctuation">)</span><span class="operator">&gt;</span> difftime<span class="punctuation">(</span>today<span class="punctuation">,</span> dob<span class="punctuation">,</span> units<span class="operator">=</span><span class="string">"weeks"</span><span class="punctuation">)</span>Time difference of <span class="number">1333.143</span> weeks</code></pre><p>很明显，我有 1333 周这么大，谁知道呢？最后一个小测验：猜猜我生于星期几？</p><h5 id="4-6-1-将日期转换为字符型变量">4.6.1 将日期转换为字符型变量</h5><p>你同样可以将日期变量转换为字符型变量。函数 as.character() 可将日期值转换为字符型：</p><pre><code class="highlight R">strDates <span class="operator">&lt;-</span> <span class="built_in">as.character</span><span class="punctuation">(</span>dates<span class="punctuation">)</span></code></pre><p>进行转换后，即可使用一系列字符处理函数处理数据（如取子集、替换、连接等）。我们将在第 5 章中详述字符处理函数。</p><h5 id="4-6-2-更进一步">4.6.2 更进一步</h5><p>要了解字符型数据转换为日期的更多细节，请查看 help(as.Date) 和 help(strftime)。要了解更多关于日期和时间格式的知识，请参考 help(ISOdatetime)。lubridate 包中包含了许多简化日期处理的函数，可以用于识别和解析日期—时间数据，抽取日期—时间成分（例如年份、月份、日期等），以及对日期—时间值进行算术运算。如果你需要对日期进行复杂的计算，那么 timeDate 包可能会有帮助。它提供了大量的日期处理函数，可以同时处理多个时区，并且提供了复杂的历法操作功能，支持工作日、周末以及假期。</p><h4 id="4-7-类型转换">4.7 类型转换</h4><p>在上节中，我们讨论了将字符数据转换为日期值以及逆向转换的方法。R 中提供了一系列用来判断某个对象的数据类型和将其转换为另一种数据类型的函数。</p><p>R 与其他统计编程语言有着类似的数据类型转换方式。举例来说，向一个数值型向量中添加一个字符串会将此向量中的所有元素转换为字符型。你可以使用表4-5 中列出的函数来判断数据的类型或者将其转换为指定类型。</p><p><strong>表4-5  类型转换函数</strong></p><table><thead><tr><th>判  断</th><th>转  换</th></tr></thead><tbody><tr><td>is.numeric()</td><td>as.numeric()</td></tr><tr><td>is.character()</td><td>as.character()</td></tr><tr><td>is.vector()</td><td>as.vector()</td></tr><tr><td>is.matrix()</td><td>as.matrix()</td></tr><tr><td>is.data.frame()</td><td>as.data.frame()</td></tr><tr><td>is.factor()</td><td>as.factor()</td></tr><tr><td>is.logical()</td><td>as.logical()</td></tr></tbody></table><p>名为 is.datatype() 这样的函数返回 TRUE 或 FALSE，而 as.datatype() 这样的函数则将其参数转换为对应的类型。代码清单4-5 提供了一个示例。</p><p><strong>代码清单4-5 转换数据类型</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> a <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">)</span><span class="operator">&gt;</span> a<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span><span class="operator">&gt;</span> <span class="built_in">is.numeric</span><span class="punctuation">(</span>a<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="literal">TRUE</span><span class="operator">&gt;</span> is.vector<span class="punctuation">(</span>a<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="literal">TRUE</span><span class="operator">&gt;</span> a <span class="operator">&lt;-</span> <span class="built_in">as.character</span><span class="punctuation">(</span>a<span class="punctuation">)</span><span class="operator">&gt;</span> a<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"1"</span> <span class="string">"2"</span> <span class="string">"3"</span><span class="operator">&gt;</span> <span class="built_in">is.numeric</span><span class="punctuation">(</span>a<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="literal">FALSE</span><span class="operator">&gt;</span> is.vector<span class="punctuation">(</span>a<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="literal">TRUE</span><span class="operator">&gt;</span> <span class="built_in">is.character</span><span class="punctuation">(</span>a<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="literal">TRUE</span></code></pre><p>当和第 5 章中讨论的控制流（如if-then）结合使用时，is.datatype() 这样的函数将成为一类强大的工具，即允许根据数据的具体类型以不同的方式处理数据。另外，某些 R 函数需要接受某个特定类型（字符型或数值型，矩阵或数据框）的数据，as.datatype() 这类函数可以让你在分析之前先行将数据转换为要求的格式。</p><h5 id="4-8-数据排序">4.8     数据排序</h5><p>有些情况下，查看排序后的数据集可以获得相当多的信息。例如，哪些经理人最具服从意识？ 在 R 中，可以使用 order() 函数对一个数据框进行排序。默认的排序顺序是升序。在排序变量的前边加一个减号即可得到降序的排序结果。以下示例使用 leadership 演示了数据框的排序。</p><p>语句：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>order<span class="punctuation">(</span>leadership<span class="operator">$</span>age<span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span></code></pre><p>创建了一个新的数据集，其中各行依经理人的年龄升序排序。语句：</p><pre><code class="highlight R">attach<span class="punctuation">(</span>leadership<span class="punctuation">)</span>newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>order<span class="punctuation">(</span>gender<span class="punctuation">,</span> age<span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span> detach<span class="punctuation">(</span>leadership<span class="punctuation">)</span></code></pre><p>则将各行依女性到男性、同样性别中按年龄升序排序。最后，</p><pre><code class="highlight R">attach<span class="punctuation">(</span>leadership<span class="punctuation">)</span>newdata <span class="operator">&lt;-</span>leadership<span class="punctuation">[</span>order<span class="punctuation">(</span>gender<span class="punctuation">,</span> <span class="operator">-</span>age<span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span>detach<span class="punctuation">(</span>leadership<span class="punctuation">)</span></code></pre><p>将各行依经理人的性别和年龄降序排序。</p><h4 id="4-9-数据集的合并">4.9 数据集的合并</h4><p>如果数据分散在多个地方，你就需要在继续下一步之前将其合并。本节展示了向数据框中添加列（变量）和行（观测）的方法。</p><h5 id="4-9-1-向数据框添加列">4.9.1   向数据框添加列</h5><p>要横向合并两个数据框（数据集），请使用 merge() 函数。在多数情况下，两个数据框是通过一个或多个共有变量进行联结的（即一种内联结，inner join）。例如：</p><pre><code class="highlight R">total <span class="operator">&lt;-</span> merge<span class="punctuation">(</span>dataframeA<span class="punctuation">,</span> dataframeB<span class="punctuation">,</span> by<span class="operator">=</span><span class="string">"ID"</span><span class="punctuation">)</span></code></pre><p>将 dataframeA 和 dataframeB 按照 ID 进行了合并。类似地，</p><pre><code class="highlight R">total <span class="operator">&lt;-</span> merge<span class="punctuation">(</span>dataframeA<span class="punctuation">,</span> dataframeB<span class="punctuation">,</span> by<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"ID"</span><span class="punctuation">,</span><span class="string">"Country"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>将两个数据框按照 ID 和 Country 进行了合并。类似的横向联结通常用于向数据框中添加变量。</p><blockquote><p><strong>用 cbind() 进行横向合并</strong></p><p>如果要直接横向合并两个矩阵或数据框，并且不需要指定一个公共索引，那么可以直接使用 cbind() 函数：</p><pre><code class="highlight R">total <span class="operator">&lt;-</span> cbind<span class="punctuation">(</span>A<span class="punctuation">,</span> B<span class="punctuation">)</span></code></pre><p>这个函数将横向合并对象 A 和对象 B。为了让它正常工作，每个对象必须拥有相同的行数， 以同顺序排序。</p></blockquote><h5 id="4-9-2-向数据框添加行">4.9.2   向数据框添加行</h5><p>要纵向合并两个数据框（数据集），请使用 rbind() 函数：</p><pre><code class="highlight R">total <span class="operator">&lt;-</span> rbind<span class="punctuation">(</span>dataframeA<span class="punctuation">,</span> dataframeB<span class="punctuation">)</span></code></pre><p>两个数据框必须拥有相同的变量，不过它们的顺序不必一定相同。如果 dataframeA 中拥有 dataframeB 中没有的变量，请在合并它们之前做以下某种处理：</p><p>❑ 删除 dataframeA 中的多余变量；</p><p>❑ 在 dataframeB 中创建追加的变量并将其值设为 NA（缺失）。</p><p>纵向联结通常用于向数据框中添加观测。</p><h4 id="4-10-数据集取子集">4.10 数据集取子集</h4><p>R拥有强大的索引特性，可以用于访问对象中的元素。也可利用这些特性对变量或观测进行选入和排除。以下几节演示了对变量和观测进行保留或删除的若干方法。</p><h5 id="4-10-1-选入（保留）变量">4.10.1 选入（保留）变量</h5><p>从一个大数据集中选择有限数量的变量来创建一个新的数据集是常有的事。在第2章中，数据框中的元素是通过dataframe[<em>row indices</em>, <em>column indices</em>]这样的记号来访问的。你可以沿用这种方法来选择变量。例如：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span><span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">6</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">)</span><span class="punctuation">]</span></code></pre><p>从 leadership 数据框中选择了变量 q1、q2、q3、q4 和 q5，并将它们保存到了数据框 newdata 中。将行下标留空（,）表示默认选择所有行。 语句：</p><pre><code class="highlight R">myvars <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"q1"</span><span class="punctuation">,</span> <span class="string">"q2"</span><span class="punctuation">,</span> <span class="string">"q3"</span><span class="punctuation">,</span> <span class="string">"q4"</span><span class="punctuation">,</span> <span class="string">"q5"</span><span class="punctuation">)</span> newdata <span class="operator">&lt;-</span>leadership<span class="punctuation">[</span>myvars<span class="punctuation">]</span></code></pre><p>实现了等价的变量选择。这里，（引号中的）变量名充当了列的下标，因此选择的列是相同的。</p><p>最后，其实你可以写：</p><pre><code class="highlight R">myvars <span class="operator">&lt;-</span> paste<span class="punctuation">(</span><span class="string">"q"</span><span class="punctuation">,</span> <span class="number">1</span><span class="operator">:</span><span class="number">5</span><span class="punctuation">,</span> sep<span class="operator">=</span><span class="string">""</span><span class="punctuation">)</span> newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>myvars<span class="punctuation">]</span></code></pre><p>本例使用 paste() 函数创建了与上例中相同的字符型向量。paste() 函数将在第 5 章中讲解。</p><h5 id="4-10-2-剔除（丢弃）变量">4.10.2 剔除（丢弃）变量</h5><p>剔除变量的原因有很多。举例来说，如果某个变量中有很多缺失值，你可能就想在进一步分析之前将其丢弃。下面是一些剔除变量的方法。</p><p>你可以使用语句：</p><pre><code class="highlight R">myvars <span class="operator">&lt;-</span> <span class="built_in">names</span><span class="punctuation">(</span>leadership<span class="punctuation">)</span> <span class="operator">%in%</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"q3"</span><span class="punctuation">,</span> <span class="string">"q4"</span><span class="punctuation">)</span> newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span><span class="operator">!</span>myvars<span class="punctuation">]</span></code></pre><p>剔除变量 q3 和 q4。为了理解以上语句的原理，你需要把它拆解如下。</p><p>(1)    names(leadership) 生成了一个包含所有变量名的字符型向量：c(“managerID”,“testDate”,“country”,“gender”,“age”,“q1”, “q2”,“q3”,“q4”,“q5”)。</p><p>(2)    names(leadership) %in% c(“q3”, “q4”) 返回了一个逻辑型向量，names(leadership) 中每个匹配 q3 或 q4 的元素的值为 TRUE，反之为FALSE：c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE)。</p><p>(3) 运算符非（!）将逻辑值反转：c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE)。</p><p>(4)  leadership[c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE)]选择了逻辑值为TRUE的列，于是 q3 和 q4 被剔除了。</p><p>在知道 q3 和 q4 是第 8 个和第 9 个变量的情况下，可以使用语句：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span><span class="built_in">c</span><span class="punctuation">(</span><span class="operator">-</span><span class="number">8</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">9</span><span class="punctuation">)</span><span class="punctuation">]</span></code></pre><p>将它们剔除。这种方式的工作原理是，在某一列的下标之前加一个减号（–）就会剔除那一列。最后，相同的变量删除工作亦可通过：</p><pre><code class="highlight R">leadership<span class="operator">$</span>q3 <span class="operator">&lt;-</span> leadership<span class="operator">$</span>q4 <span class="operator">&lt;-</span> <span class="literal">NULL</span></code></pre><p>来完成。这回你将 q3 和 q4 两列设为了未定义（NULL）。注意，NULL 与 NA（表示缺失）是不同的。</p><p>丢弃变量是保留变量的逆向操作。选择哪一种方式进行变量筛选依赖于两种方式的编码难易程度。如果有许多变量需要丢弃，那么直接保留需要留下的变量可能更简单，反之亦然。</p><h5 id="4-10-3-选入观测">4.10.3   选入观测</h5><p>选入或剔除观测（行）通常是成功的数据准备和数据分析的一个关键方面。代码清单4-6给出了一些例子。</p><p><strong>代码清单4-6 选入观测</strong></p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span>   <span class="comment"># 选择第 1 行到第 3 行（前三个观测）</span>newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>leadership<span class="operator">$</span>gender<span class="operator">==</span><span class="string">"M"</span> <span class="operator">&amp;</span> leadership<span class="operator">$</span>age <span class="operator">&gt;</span> <span class="number">30</span><span class="punctuation">,</span><span class="punctuation">]</span><span class="comment"># 选择所有 30 岁以上的男性</span>attach<span class="punctuation">(</span>leadership<span class="punctuation">)</span>  <span class="comment"># 使用了 attach() 函数，所以你就不必在变量名前加上数据框名称了</span>newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>gender<span class="operator">==</span><span class="string">'M'</span> <span class="operator">&amp;</span> age <span class="operator">&gt;</span> <span class="number">30</span><span class="punctuation">,</span><span class="punctuation">]</span> detach<span class="punctuation">(</span>leadership<span class="punctuation">)</span></code></pre><p>在以上每个示例中，你只提供了行下标，并将列下标留空（故选入了所有列）。在第一个示例中，你选择了第 1 行到第 3 行（前三个观测）。</p><p>让我们拆解第二行代码以便理解它。</p><p>(1)  逻辑比较 leadership$gender==“M” 生成了向量 c(TRUE, FALSE, FALSE, TRUE,</p><p>FALSE)。</p><p>(2) 逻辑比较 leadership$age &gt; 30 生成了向量 c(TRUE, TRUE, FALSE, TRUE, TRUE)。</p><p>(3) 逻辑比较 c(TRUE, FALSE, FALSE, TRUE, TRUE) &amp; c(TRUE, TRUE, FALSE, TRUE,</p><p>TRUE) 生成了向量 c(TRUE, FALSE, FALSE, TRUE, FALSE)。</p><p>(4)  leadership[c(TRUE, FALSE, FALSE, TRUE, FALSE),] 从数据框中选择了第一个和第四个观测（当对应行的索引是 TRUE，这一行被选入；当对应行的索引是 FALSE，这一行被剔除）。这就满足了我们的选取准则（30 岁以上的男性）。</p><p>在本章开始的时候，我曾经提到，你可能希望将研究范围限定在 2009 年 1 月 1 日到 2009 年12 月 31 日之间收集的观测上。怎么做呢？这里有一个办法：</p><pre><code class="highlight R">leadership<span class="operator">$</span>date <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span>leadership<span class="operator">$</span>date<span class="punctuation">,</span> <span class="string">"%m/%d/%y"</span><span class="punctuation">)</span> <span class="comment"># 使用格式 mm/dd/yy 将开始作为字符值读入的日期转换为日期值</span>startdate <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span><span class="string">"2009-01-01"</span><span class="punctuation">)</span> <span class="comment"># 创建开始日期</span>enddate <span class="operator">&lt;-</span> as.Date<span class="punctuation">(</span><span class="string">"2009-10-31"</span><span class="punctuation">)</span><span class="comment"># 创建结束日期</span>newdata <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>which<span class="punctuation">(</span>leadership<span class="operator">$</span>date <span class="operator">&gt;=</span> startdate <span class="operator">&amp;</span>                             leadership<span class="operator">$</span>date <span class="operator">&lt;=</span> enddate<span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="comment"># 像上例一样选取那些满足你期望中准则的个案</span></code></pre><p>注意，由于 as.Date() 函数的默认格式就是 yyyy-mm-dd，所以你无需在这里提供这个参数。</p><h5 id="4-10-4-subset-函数">4.10.4 subset() 函数</h5><p>前两节中的示例很重要，因为它们辅助描述了逻辑型向量和比较运算符在R中的解释方式。理解这些例子的工作原理在总体上将有助于你对 R 代码的解读。既然你已经用笨办法完成了任务， 现在不妨来看一种简便方法。</p><p>使用 subset() 函数大概是选择变量和观测最简单的方法了。两个示例如下：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> subset<span class="punctuation">(</span>leadership<span class="punctuation">,</span> age <span class="operator">&gt;=</span> <span class="number">35</span> <span class="operator">|</span> age <span class="operator">&lt;</span> <span class="number">24</span><span class="punctuation">,</span>                  select<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span>q1<span class="punctuation">,</span> q2<span class="punctuation">,</span> q3<span class="punctuation">,</span> q4<span class="punctuation">)</span><span class="punctuation">)</span><span class="comment"># 选择所有 age 值大于等于 35 或 age 值小于 24 的行，保留了变量 q1 到 q4 </span>newdata <span class="operator">&lt;-</span> subset<span class="punctuation">(</span>leadership<span class="punctuation">,</span> gender<span class="operator">==</span><span class="string">"M"</span> <span class="operator">&amp;</span> age <span class="operator">&gt;</span> <span class="number">25</span><span class="punctuation">,</span> select<span class="operator">=</span>gender<span class="operator">:</span>q4<span class="punctuation">)</span> <span class="comment"># 选择所有 25 岁以上的男性，并保留了变量 gender 到 q4（gender、q4 和其间所有列）</span></code></pre><p>你在第 2 章中已经看到了冒号运算符 from:to。在这里，它表示了数据框中变量 from 到变量 to 包含的所有变量。</p><h5 id="4-10-5-随机抽样">4.10.5  随机抽样</h5><p>在数据挖掘和机器学习领域，从更大的数据集中抽样是很常见的做法。举例来说，你可能希望选择两份随机样本，使用其中一份样本构建预测模型，使用另一份样本验证模型的有效性。</p><p>sample() 函数能够让你从数据集中（有放回或无放回地）抽取大小为n的一个随机样本。你可以使用以下语句从 leadership 数据集中随机抽取一个大小为 3 的样本：</p><pre><code class="highlight R">mysample <span class="operator">&lt;-</span> leadership<span class="punctuation">[</span>sample<span class="punctuation">(</span><span class="number">1</span><span class="operator">:</span>nrow<span class="punctuation">(</span>leadership<span class="punctuation">)</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">,</span> replace<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span></code></pre><p>sample() 函数中的第一个参数是一个由要从中抽样的元素组成的向量。在这里，这个向量是 1 到数据框中观测的数量，第二个参数是要抽取的元素数量，第三个参数表示无放回抽样。</p><p>sample() 函数会返回随机抽样得到的元素，之后即可用于选择数据框中的行。</p><p>R 中拥有齐全的抽样工具，包括抽取和校正调查样本（参见 sampling 包）以及分析复杂调查数据（参见 survey 包）的工具。其他依赖于抽样的方法，包括自助法和重抽样统计方法，详见第 12 章。</p><h4 id="4-11-使用-SQL-语句操作数据框">4.11 使用 SQL 语句操作数据框</h4><p>到目前为止，你一直在使用 R 语句操作数据。但是，许多数据分析人员在接触 R 之前就已经精通了结构化查询语言（SQL），要丢弃那么多积累下来的知识实为一件憾事。因此，在我们结束本章之前简述一下 sqldf 包。（如果你对 SQL 不熟，请尽管跳过本节。）</p><p>在下载并安装好这个包以后（install.packages(“sqldf”)），你可以使用 sqldf() 函数在数据框上使用 SQL 中的 SELECT 语句。代码清单4-7 给出了两个示例。</p><p><strong>代码清单4-7 使用 SQL 语句操作数据框</strong><br>从数据框 <strong>mtcars</strong> 中选择所有的变量（列），保留那些使用化油器（<strong>carb</strong>）的车型（行），按照 <strong>mpg</strong> 对车型进行了升序排序，并将结果保存为数据框 <strong>newdf</strong>。参数 <strong>row.names=TRUE</strong> 将原始数据框中的行名延续到了新数据框中</p><pre><code class="highlight R"><span class="operator">&gt;</span> library<span class="punctuation">(</span>sqldf<span class="punctuation">)</span>载入需要的程辑包：gsubfn载入需要的程辑包：proto载入需要的程辑包：RSQLite<span class="operator">&gt;</span> newdf <span class="operator">&lt;-</span> sqldf<span class="punctuation">(</span><span class="string">"select * from mtcars where carb=1 order by mpg"</span><span class="punctuation">,</span> row.names<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span><span class="operator">&gt;</span> newdf                mpg cyl  disp  hp drat    wtValiant        <span class="number">18.1</span>   <span class="number">6</span> <span class="number">225.0</span> <span class="number">105</span> <span class="number">2.76</span> <span class="number">3.460</span>Hornet <span class="number">4</span> Drive <span class="number">21.4</span>   <span class="number">6</span> <span class="number">258.0</span> <span class="number">110</span> <span class="number">3.08</span> <span class="number">3.215</span>Toyota Corona  <span class="number">21.5</span>   <span class="number">4</span> <span class="number">120.1</span>  <span class="number">97</span> <span class="number">3.70</span> <span class="number">2.465</span>Datsun <span class="number">710</span>     <span class="number">22.8</span>   <span class="number">4</span> <span class="number">108.0</span>  <span class="number">93</span> <span class="number">3.85</span> <span class="number">2.320</span>Fiat X1<span class="operator">-</span><span class="number">9</span>      <span class="number">27.3</span>   <span class="number">4</span>  <span class="number">79.0</span>  <span class="number">66</span> <span class="number">4.08</span> <span class="number">1.935</span>Fiat <span class="number">128</span>       <span class="number">32.4</span>   <span class="number">4</span>  <span class="number">78.7</span>  <span class="number">66</span> <span class="number">4.08</span> <span class="number">2.200</span>Toyota Corolla <span class="number">33.9</span>   <span class="number">4</span>  <span class="number">71.1</span>  <span class="number">65</span> <span class="number">4.22</span> <span class="number">1.835</span>                qsec vs am gear carbValiant        <span class="number">20.22</span>  <span class="number">1</span>  <span class="number">0</span>    <span class="number">3</span>    <span class="number">1</span>Hornet <span class="number">4</span> Drive <span class="number">19.44</span>  <span class="number">1</span>  <span class="number">0</span>    <span class="number">3</span>    <span class="number">1</span>Toyota Corona  <span class="number">20.01</span>  <span class="number">1</span>  <span class="number">0</span>    <span class="number">3</span>    <span class="number">1</span>Datsun <span class="number">710</span>     <span class="number">18.61</span>  <span class="number">1</span>  <span class="number">1</span>    <span class="number">4</span>    <span class="number">1</span>Fiat X1<span class="operator">-</span><span class="number">9</span>      <span class="number">18.90</span>  <span class="number">1</span>  <span class="number">1</span>    <span class="number">4</span>    <span class="number">1</span>Fiat <span class="number">128</span>       <span class="number">19.47</span>  <span class="number">1</span>  <span class="number">1</span>    <span class="number">4</span>    <span class="number">1</span>Toyota Corolla <span class="number">19.90</span>  <span class="number">1</span>  <span class="number">1</span>    <span class="number">4</span>    <span class="number">1</span><span class="operator">&gt;</span> sqldf<span class="punctuation">(</span><span class="string">"select avg(mpg) as avg_mpg, avg(disp) as avg_disp, gear from mtcars where cyl in (4, 6) group by gear"</span><span class="punctuation">)</span> <span class="comment"># 输出四缸和六缸车型每一gear水平的mpg和disp的平均值</span>   avg_mpg avg_disp gear<span class="number">1</span> <span class="number">20.33333</span> <span class="number">201.0333</span>    <span class="number">3</span><span class="number">2</span> <span class="number">24.53333</span> <span class="number">123.0167</span>    <span class="number">4</span><span class="number">3</span> <span class="number">25.36667</span> <span class="number">120.1333</span>    <span class="number">5</span></code></pre><p>经验丰富的 SQL 用户将会发现，sqldf 包是 R 中一个实用的数据管理辅助工具。请参阅项目主页（<a href="http://code.google.com/p/sqldf/%EF%BC%89%E4%BB%A5%E4%BA%86%E8%A7%A3%E8%AF%A6%E6%83%85%E3%80%82">http://code.google.com/p/sqldf/）以了解详情。</a></p><h4 id="4-12-小结">4.12 小结</h4><p>本章讲解了大量的基础知识。首先我们看到了R存储缺失值和日期值的方式，并探索了它们的多种处理方法。接着学习了如何确定一个对象的数据类型，以及如何将它转换为其他类型。还使用简单的公式创建了新变量并重编码了现有变量。你学习了如何对数据进行排序和对变量进行重命名，学习了如何对数据和其他数据集进行横向合并（添加变量）和纵向合并（添加观测）。最后，我们讨论了如何保留或丢弃变量，以及如何基于一系列的准则选取观测。</p><p>在下一章中，我们将着眼于 R 中不计其数的，用于创建和转换变量的算术函数、字符处理函数和统计函数。在探索了控制程序流程的方式之后，你将了解到如何编写自己的函数。我们也将探索如何使用这些函数来整合及概括数据。</p><p>在第 5 章结束时，你就能掌握管理复杂数据集的多数工具。（无论你走到哪里，都将成为数据分析师艳羡的人物！）</p><h3 id="第5章-高级数据管理">第5章  高级数据管理</h3><blockquote><p><strong>本章内容</strong></p><p>❑ 数学和统计函数</p><p>❑ 字符处理函数</p><p>❑ 循环和条件执行</p><p>❑ 自编函数</p><p>❑ 数据整合与重塑</p></blockquote><p>在第4章，我们审视了 R 中基本的数据集处理方法，本章我们将关注一些高级话题。本章分为三个基本部分。在第一部分中，我们将快速浏览 R 中的多种数学、统计和字符处理函数。为了让这一部分的内容相互关联，我们先引入一个能够使用这些函数解决的数据处理问题。在讲解过这些函数以后，再为这个数据处理问题提供一个可能的解决方案。</p><p>接下来，我们将讲解如何自己编写函数来完成数据处理和分析任务。首先，我们将探索控制程序流程的多种方式，包括循环和条件执行语句。然后，我们将研究用户自编函数的结构，以及在编写完成后如何调用它们。</p><p>最后，我们将了解数据的整合和概述方法，以及数据集的重塑和重构方法。在整合数据时， 你可以使用任何内建或自编函数来获取数据的概述，所以你在本章前两部分中学习的内容将会派上用场。</p><h4 id="5-1-一个数据处理难题">5.1 一个数据处理难题</h4><p>要讨论数值和字符处理函数，让我们首先考虑一个数据处理问题。一组学生参加了数学、科学和英语考试。为了给所有学生确定一个单一的成绩衡量指标，需要将这些科目的成绩组合起来。另外，你还想将前 20% 的学生评定为 A，接下来 20% 的学生评定为 B，依次类推。最后，你希望按字母顺序对学生排序。数据如表5-1 所示。</p><p><strong>表5-1   学生成绩数据</strong></p><table><thead><tr><th>学生姓名</th><th>数  学</th><th>科 学</th><th>英 语</th></tr></thead><tbody><tr><td>John Davis</td><td>502</td><td>95</td><td>25</td></tr><tr><td>Angela Williams</td><td>600</td><td>99</td><td>22</td></tr><tr><td>Bullwinkle Moose</td><td>412</td><td>80</td><td>18</td></tr><tr><td>David Jones</td><td>358</td><td>82</td><td>15</td></tr><tr><td>Janice Markhammer</td><td>495</td><td>75</td><td>20</td></tr><tr><td>Cheryl Cushing</td><td>512</td><td>85</td><td>28</td></tr><tr><td>Reuven Ytzrhak</td><td>410</td><td>80</td><td>15</td></tr><tr><td>Greg Knox</td><td>625</td><td>95</td><td>30</td></tr><tr><td>Joel England</td><td>573</td><td>89</td><td>27</td></tr><tr><td>Mary Rayburn</td><td>522</td><td>86</td><td>18</td></tr></tbody></table><p>观察此数据集，马上可以发现一些明显的障碍。首先，三科考试的成绩是无法比较的。由于它们的均值和标准差相去甚远，所以对它们求平均值是没有意义的。你在组合这些考试成绩之前， 必须将其变换为可比较的单元。其次，为了评定等级，你需要一种方法来确定某个学生在前述得分上百分比排名。再次，表示姓名的字段只有一个，这让排序任务复杂化了。为了正确地将其排序，需要将姓和名拆开。</p><p>以上每一个任务都可以巧妙地利用 R 中的数值和字符处理函数完成。在讲解完下一节中的各种函数之后，我们将考虑一套可行的解决方案，以解决这项数据处理难题。</p><h4 id="5-2-数值和字符处理函数">5.2 数值和字符处理函数</h4><p>本节我们将综述R中作为数据处理基石的函数，它们可分为数值（数学、统计、概率）函数和字符处理函数。在阐述过每一类函数以后，我将为你展示如何将函数应用到矩阵和数据框的列（变量）和行（观测）上（参见 5.2.6 节）。</p><h5 id="5-2-1-数学函数">5.2.1 数学函数</h5><p>表5-2 列出了常用的数学函数和简短的用例。</p><p><strong>表5-2 数学函数</strong></p><table><thead><tr><th>函  数</th><th>描  述</th></tr></thead><tbody><tr><td>abs(x)</td><td>绝对值</td></tr><tr><td></td><td>abs(-4) 返回值为 4</td></tr><tr><td>sqrt(x)</td><td>平方根</td></tr><tr><td></td><td>sqrt(25) 返回值为 5，和 25^(0.5) 等价</td></tr><tr><td>ceiling(x)</td><td>不小于 x 的最小整数</td></tr><tr><td></td><td>ceiling(3.475) 返回值为 4</td></tr><tr><td>floor(x)</td><td>不大于 x 的最大整数</td></tr><tr><td></td><td>floor(3.475) 返回值为 3</td></tr><tr><td>trunc(x)</td><td>向 0 的方向截取的 x 中的整数部分</td></tr><tr><td></td><td>trunc(5.99) 返回值为 5</td></tr><tr><td>round(x, digits=n)</td><td>将 x 舍入为指定位的小数</td></tr><tr><td></td><td>round(3.475, digits=2)，返回值为 3.48</td></tr><tr><td>signif(x, digits=n)</td><td>将 x 舍入为指定的有效数字位数</td></tr><tr><td></td><td>signif(3.475, digits=2) 返回值为 3.5</td></tr><tr><td>cos(x)、sin(x)、tan(x)</td><td>余弦、正弦和正切</td></tr><tr><td></td><td>cos(2) 返回值为 –0.416</td></tr><tr><td>acos(x)、asin(x)、atan(x)</td><td>反余弦、反正弦和反正切</td></tr><tr><td></td><td>acos(-0.416) 返回值为 2</td></tr><tr><td>cosh(x)、sinh(x)、tanh(x)</td><td>双曲余弦、双曲正弦和双曲正切</td></tr><tr><td></td><td>sinh(2) 返回值为 3.627</td></tr><tr><td>acosh(X)、asinh(X)、atanh(X)</td><td>反双曲余弦、反双曲正弦和反双曲正切</td></tr><tr><td></td><td>asinh(3.627) 返回值为 2</td></tr><tr><td>log(x,base=n)</td><td>对 x 取以 n 为底的对数</td></tr><tr><td>log(x)</td><td>为了方便起见：</td></tr><tr><td>log10(x)</td><td>• log(x) 为自然对数</td></tr><tr><td></td><td>• log10(x) 为常用对数</td></tr><tr><td></td><td>• log(10) 返回值为 2.3026</td></tr><tr><td></td><td>• log10(10) 返回值为 1</td></tr><tr><td>exp(x)</td><td>指数函数</td></tr><tr><td></td><td>exp(2.3026) 返回值为 10</td></tr></tbody></table><p>对数据做变换是这些函数的一个主要用途。例如，你经常会在进一步分析之前将收入这种存在明显偏倚的变量取对数。数学函数也被用作公式中的一部分，用于绘图函数（例如 x 对 sin(x)） 和在输出结果之前对数值做格式化。</p><p>表5-2 中的示例将数学函数应用到了标量（单独的数值）上。当这些函数被应用于数值向量、矩阵或数据框时，它们会作用于每一个独立的值。例如，sqrt(c(4, 16, 25)) 的返回值为 c(2, 4, 5)。</p><h5 id="5-2-2-统计函数">5.2.2 统计函数</h5><p>常用的统计函数如表5-3 所示，其中许多函数都拥有可以影响输出结果的可选参数。举例来说：</p><pre><code class="highlight R">y <span class="operator">&lt;-</span> mean<span class="punctuation">(</span>x<span class="punctuation">)</span></code></pre><p>提供了对象 x 中元素的算术平均数，而：</p><pre><code class="highlight R">z <span class="operator">&lt;-</span> mean<span class="punctuation">(</span>x<span class="punctuation">,</span> trim <span class="operator">=</span> <span class="number">0.05</span><span class="punctuation">,</span> na.rm<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span></code></pre><p>则提供了截尾平均数，即丢弃了最大 5% 和最小 5% 的数据和所有缺失值后的算术平均数。请使用 help() 了解以上每个函数和其参数的用法。</p><p><strong>表5-3  统计函数</strong></p><table><thead><tr><th>函  数</th><th>描  述</th></tr></thead><tbody><tr><td>mean(x)</td><td>平均数</td></tr><tr><td></td><td>mean(c(1,2,3,4)) 返回值为 2.5</td></tr><tr><td>median(x)</td><td>中位数</td></tr><tr><td></td><td>median(c(1,2,3,4)) 返回值为 2.5</td></tr><tr><td>sd(x)</td><td>标准差</td></tr><tr><td></td><td>sd(c(1,2,3,4)) 返回值为 1.29</td></tr><tr><td>var(x)</td><td>方差</td></tr><tr><td></td><td>var(c(1,2,3,4)) 返回值为 1.67</td></tr><tr><td>mad(x)</td><td>绝对中位差（median absolute deviation）</td></tr><tr><td></td><td>mad(c(1,2,3,4)) 返回值为 1.48</td></tr><tr><td>quantile(x,probs)</td><td>求分位数。其中 x 为待求分位数的数值型向量，probs 为一个由 [0,1] 之间的概率值组成的数值向量</td></tr><tr><td></td><td># 求 x 的 30% 和 84% 分位点</td></tr><tr><td></td><td>y &lt;- quantile(x, c(.3,.84))</td></tr><tr><td>range(x)</td><td>求值域</td></tr><tr><td></td><td>x &lt;- c(1,2,3,4)</td></tr><tr><td></td><td>range(x) 返回值为 c(1,4)</td></tr><tr><td></td><td>diff(range(x)) 返回值为 3</td></tr><tr><td>sum(x)</td><td>求和</td></tr><tr><td></td><td>sum(c(1,2,3,4)) 返回值为 10</td></tr><tr><td>diff(x, lag=n)</td><td>滞后差分，lag 用以指定滞后几项。默认的 lag 值为 1</td></tr><tr><td></td><td>x&lt;- c(1, 5, 23, 29)</td></tr><tr><td></td><td>diff(ddx) 返回值为 c(4, 18, 6)</td></tr><tr><td>min(x)</td><td>求最小值</td></tr><tr><td></td><td>min(c(1,2,3,4)) 返回值为 1</td></tr><tr><td>max(x)</td><td>求最大值</td></tr><tr><td></td><td>max(c(1,2,3,4))返回值为 4</td></tr><tr><td>scale(x,center=TRUE, scale=TRUE)</td><td>为数据对象 x 按列进行中心化(center=TRUE)或标准化(center=TRUE, scale=TRUE)； 代码清单 5-6 中给出了一个示例</td></tr><tr><td>要了解这些函数的实战应用，请参考代码清单5-1。这个例子演示了计算某个数值向量的均值和标准差的两种方式。</td><td></td></tr></tbody></table><p><strong>代码清单5-1 均值和标准差的计算</strong></p><pre><code class="highlight R"><span class="comment"># 简洁的方式</span><span class="operator">&gt;</span> x <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">,</span><span class="number">6</span><span class="punctuation">,</span><span class="number">7</span><span class="punctuation">,</span><span class="number">8</span><span class="punctuation">)</span><span class="operator">&gt;</span> mean<span class="punctuation">(</span>x<span class="punctuation">)</span> <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">4.5</span><span class="operator">&gt;</span> sd<span class="punctuation">(</span>x<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.44949</span><span class="comment"># 冗长的方式</span><span class="operator">&gt;</span> n <span class="operator">&lt;-</span> <span class="built_in">length</span><span class="punctuation">(</span>x<span class="punctuation">)</span><span class="operator">&gt;</span> meanx <span class="operator">&lt;-</span> <span class="built_in">sum</span><span class="punctuation">(</span>x<span class="punctuation">)</span><span class="operator">/</span>n<span class="operator">&gt;</span> css <span class="operator">&lt;-</span> <span class="built_in">sum</span><span class="punctuation">(</span><span class="punctuation">(</span>x <span class="operator">-</span> meanx<span class="punctuation">)</span><span class="operator">^</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">&gt;</span> sdx <span class="operator">&lt;-</span> <span class="built_in">sqrt</span><span class="punctuation">(</span>css <span class="operator">/</span> <span class="punctuation">(</span>n<span class="operator">-</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">&gt;</span> meanx<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">4.5</span><span class="operator">&gt;</span> sdx<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.44949</span></code></pre><p>第二种方式中修正平方和（css）的计算过程是很有启发性的：</p><p>(1) x 等于 c(1, 2, 3, 4, 5, 6, 7, 8)，x 的平均值等于 4.5（length(x) 返回了 x 中元素的数量）；</p><p>(2) (x – meanx) 从 x 的每个元素中减去了 4.5，结果为 c(-3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5)；</p><p>(3) (x – meanx)^2 将 (x - meanx) 的每个元素求平方，结果为 c(12.25, 6.25, 2.25, 0.25, 0.25, 2.25, 6.25, 12.25)；</p><p>(4) sum((x - meanx)^2) 对 (x - meanx)^2) 的所有元素求和，结果为 42。</p><p>R 中公式的写法和类似 MATLAB 的矩阵运算语言有着许多共同之处。（我们将在附录 D 中具体关注解决矩阵代数问题的方法。）</p><p><strong>数据的标准化</strong></p><p>默认情况下，函数 scale() 对矩阵或数据框的指定列进行均值为 0、标准差为 1 的标准化：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> scale<span class="punctuation">(</span>mydata<span class="punctuation">)</span></code></pre><p>要对每一列进行任意均值和标准差的标准化，可以使用如下的代码：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> scale<span class="punctuation">(</span>mydata<span class="punctuation">)</span><span class="operator">*</span>SD <span class="operator">+</span> M</code></pre><p>其中的 M 是想要的均值，SD 为想要的标准差。在非数值型的列上使用 scale() 函数将会报错。要对指定列而不是整个矩阵或数据框进行标准化，你可以使用这样的代码：</p><pre><code class="highlight R">newdata <span class="operator">&lt;-</span> transform<span class="punctuation">(</span>mydata<span class="punctuation">,</span> myvar <span class="operator">=</span> scale<span class="punctuation">(</span>myvar<span class="punctuation">)</span><span class="operator">*</span><span class="number">10</span><span class="operator">+</span><span class="number">50</span><span class="punctuation">)</span></code></pre><p>此句将变量 myvar 标准化为均值 50、标准差为 10 的变量。你将在 5.3 节数据处理问题的解决方法中用到 scale() 函数。</p><h5 id="5-2-3-概率函数">5.2.3 概率函数</h5><p>你可能在疑惑为何概率函数未和统计函数列在一起。（你真的对此有些困惑，对吧？）虽然根据定义，概率函数也属于统计类，但是它们非常独特，应独立设一节进行讲解。概率函数通常用来生成特征已知的模拟数据，以及在用户编写的统计函数中计算概率值。</p><p>在 R 中，概率函数形如：</p><pre><code class="highlight R"><span class="punctuation">[</span>dpqr<span class="punctuation">]</span>distribution_abbreviation<span class="punctuation">(</span><span class="punctuation">)</span></code></pre><p>其中第一个字母表示其所指分布的某一方面：</p><p>d = 密度函数（density）</p><p>p = 分布函数（distribution function）</p><p>q = 分位数函数（quantile function）</p><p>r = 生成随机数（随机偏差）</p><p>常用的概率函数列于表5-4 中。</p><p><strong>表5-4 概率分布</strong></p><table><thead><tr><th>分布名称</th><th>缩  写</th><th>分布名称</th><th>缩  写</th></tr></thead><tbody><tr><td>Beta 分布</td><td>beta</td><td>Logistic 分布</td><td>logis</td></tr><tr><td>二项分布</td><td>binom</td><td>多项分布</td><td>multinom</td></tr><tr><td>柯西分布</td><td>cauchy</td><td>负二项分布</td><td>nbinom</td></tr><tr><td>（非中心）卡方分布</td><td>chisq</td><td>正态分布</td><td>norm</td></tr><tr><td>指数分布</td><td>exp</td><td>泊松分布</td><td>pois</td></tr><tr><td>F 分布</td><td>f</td><td>Wilcoxon 符号秩分布</td><td>signrank</td></tr><tr><td>Gamma 分布</td><td>gamma</td><td>t 分布</td><td>t</td></tr><tr><td>几何分布</td><td>geom</td><td>均匀分布</td><td>unif</td></tr><tr><td>超几何分布</td><td>hyper</td><td>Weibull 分布</td><td>weibull</td></tr><tr><td>对数正态分布</td><td>lnorm</td><td>Wilcoxon 秩和分布</td><td>wilcox</td></tr></tbody></table><p>我们不妨先看看正态分布的有关函数，以了解这些函数的使用方法。如果不指定一个均值和一个标准差，则函数将假定其为标准正态分布（均值为 0，标准差为 1）。密度函数（dnorm）、分布函数（pnorm）、分位数函数（qnorm）和随机数生成函数（rnorm）的使用示例见表 5-5。</p><p><strong>表5-5 正态分布函数</strong></p><img src="/medias/image-20210815182029643.png" alt="**表5-5 正态分布函数**" style="zoom:67%;"><p>如果读者对 plot() 函数的选项不熟悉，请不要担心。这些选项在第 11 章中有详述。pretty() 在本章稍后的表5-7 中进行了解释。</p><p><strong>1. 设定随机数种子</strong></p><p>在每次生成伪随机数的时候，函数都会使用一个不同的种子，因此也会产生不同的结果。你可以通过函数 set.seed() 显式指定这个种子，让结果可以重现（reproducible）。代码清单5-2 给出了一个示例。这里的函数 runif() 用来生成 0 到 1 区间上服从均匀分布的伪随机数。</p><p><strong>代码清单5-2 生成服从正态分布的伪随机数</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> runif<span class="punctuation">(</span><span class="number">5</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.7596050</span> <span class="number">0.1670000</span> <span class="number">0.1864267</span> <span class="number">0.5590606</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">]</span> <span class="number">0.9861367</span><span class="operator">&gt;</span> runif<span class="punctuation">(</span><span class="number">5</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.9165886</span> <span class="number">0.6570878</span> <span class="number">0.9515263</span> <span class="number">0.7049961</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">]</span> <span class="number">0.6763119</span><span class="operator">&gt;</span> set.seed<span class="punctuation">(</span><span class="number">1234</span><span class="punctuation">)</span><span class="operator">&gt;</span> runif<span class="punctuation">(</span><span class="number">5</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.1137034</span> <span class="number">0.6222994</span> <span class="number">0.6092747</span> <span class="number">0.6233794</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">]</span> <span class="number">0.8609154</span><span class="operator">&gt;</span> set.seed<span class="punctuation">(</span><span class="number">1234</span><span class="punctuation">)</span><span class="operator">&gt;</span> runif<span class="punctuation">(</span><span class="number">5</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.1137034</span> <span class="number">0.6222994</span> <span class="number">0.6092747</span> <span class="number">0.6233794</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">]</span> <span class="number">0.8609154</span></code></pre><p>通过手动设定种子，就可以重现你的结果了。这种能力有助于我们创建会在未来取用的，以及可与他人分享的示例。</p><p><strong>2. 生成多元正态数据</strong></p><p>在模拟研究和蒙特卡洛方法中，你经常需要获取来自给定均值向量和协方差阵的多元正态分布的数据。MASS 包中的 mvrnorm() 函数可以让这个问题变得很容易。其调用格式为：</p><pre><code class="highlight R">mvrnorm<span class="punctuation">(</span>n<span class="punctuation">,</span> mean<span class="punctuation">,</span> sigma<span class="punctuation">)</span></code></pre><p>其中 n 是你想要的样本大小，mean 为均值向量，而 sigma 是方差-协方差矩阵（或相关矩阵）。代码清单5-3 从一个参数如下所示的三元正态分布中抽取 500 个观测。</p><table><thead><tr><th>------</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>均值向量</td><td>230.7</td><td>146.7</td><td>3.6</td></tr><tr><td>协方差阵</td><td>15360.8</td><td>6721.2</td><td>-47.1</td></tr><tr><td></td><td>6721.2</td><td>4700.9</td><td>-16.5</td></tr><tr><td></td><td>-47.1</td><td>-16.5</td><td>0.3</td></tr></tbody></table><p>代码清单5-3 生成服从多元正态分布的数据</p><pre><code class="highlight R"><span class="operator">&gt;</span> library<span class="punctuation">(</span>MASS<span class="punctuation">)</span><span class="operator">&gt;</span> options<span class="punctuation">(</span>digits<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span><span class="operator">&gt;</span> set.seed<span class="punctuation">(</span><span class="number">1234</span><span class="punctuation">)</span><span class="comment"># 设定随机数种子</span><span class="operator">&gt;</span> mean <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">230.7</span><span class="punctuation">,</span> <span class="number">146.7</span><span class="punctuation">,</span> <span class="number">3.6</span><span class="punctuation">)</span><span class="operator">&gt;</span> sigma <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="number">15360.8</span><span class="punctuation">,</span> <span class="number">6721.2</span><span class="punctuation">,</span> <span class="operator">-</span><span class="number">47.1</span><span class="punctuation">,</span><span class="operator">+</span>                   <span class="number">6721.2</span><span class="punctuation">,</span> <span class="number">4700.9</span><span class="punctuation">,</span> <span class="operator">-</span><span class="number">16.5</span><span class="punctuation">,</span><span class="operator">+</span>                   <span class="operator">-</span><span class="number">47.1</span><span class="punctuation">,</span>  <span class="operator">-</span><span class="number">16.5</span><span class="punctuation">,</span>  <span class="number">0.3</span><span class="punctuation">)</span><span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">3</span><span class="punctuation">,</span> ncol<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span> <span class="comment"># 指定均值向量、协方差阵</span><span class="operator">&gt;</span> mydata <span class="operator">&lt;-</span> mvrnorm<span class="punctuation">(</span><span class="number">500</span><span class="punctuation">,</span> mean<span class="punctuation">,</span> sigma<span class="punctuation">)</span><span class="operator">&gt;</span> mydata <span class="operator">&lt;-</span> as.data.frame<span class="punctuation">(</span>mydata<span class="punctuation">)</span><span class="operator">&gt;</span> <span class="built_in">names</span><span class="punctuation">(</span>mydata<span class="punctuation">)</span> <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"y"</span><span class="punctuation">,</span><span class="string">"x1"</span><span class="punctuation">,</span><span class="string">"x2"</span><span class="punctuation">)</span><span class="comment"># 生成数据</span><span class="operator">&gt;</span> <span class="operator">&gt;</span> <span class="built_in">dim</span><span class="punctuation">(</span>mydata<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">500</span>   <span class="number">3</span><span class="operator">&gt;</span> head<span class="punctuation">(</span>mydata<span class="punctuation">,</span> n<span class="operator">=</span><span class="number">10</span><span class="punctuation">)</span><span class="comment"># 查看结果</span>       y    x1   x2<span class="number">1</span>   <span class="number">98.8</span>  <span class="number">41.3</span> <span class="number">3.43</span><span class="number">2</span>  <span class="number">244.5</span> <span class="number">205.2</span> <span class="number">3.80</span><span class="number">3</span>  <span class="number">375.7</span> <span class="number">186.7</span> <span class="number">2.51</span><span class="number">4</span>  <span class="operator">-</span><span class="number">59.2</span>  <span class="number">11.2</span> <span class="number">4.71</span><span class="number">5</span>  <span class="number">313.0</span> <span class="number">111.0</span> <span class="number">3.45</span><span class="number">6</span>  <span class="number">288.8</span> <span class="number">185.1</span> <span class="number">2.72</span><span class="number">7</span>  <span class="number">134.8</span> <span class="number">165.0</span> <span class="number">4.39</span><span class="number">8</span>  <span class="number">171.7</span>  <span class="number">97.4</span> <span class="number">3.64</span><span class="number">9</span>  <span class="number">167.2</span> <span class="number">101.0</span> <span class="number">3.50</span><span class="number">10</span> <span class="number">121.1</span>  <span class="number">94.5</span> <span class="number">4.10</span></code></pre><p>代码清单5-3 中设定了一个随机数种子，这样就可以在之后重现结果➊。你指定了想要的均值向量和方差-协方差阵➋，并生成了 500 个伪随机观测➌。为了方便，结果从矩阵转换为数据框， 并为变量指定了名称。最后，你确认了拥有 500 个观测和 3 个变量，并输出了前 10 个观测➍。请注意，由于相关矩阵同时也是协方差阵，所以其实可以直接指定相关关系的结构。</p><p>R 中的概率函数允许生成模拟数据，这些数据是从服从已知特征的概率分布中抽样而得的。近年来，依赖于模拟数据的统计方法呈指数级增长，在后续各章中会有若干示例。</p><h5 id="5-2-4-字符处理函数">5.2.4 字符处理函数</h5><p>数学和统计函数是用来处理数值型数据的，而字符处理函数可以从文本型数据中抽取信息，或者为打印输出和生成报告重设文本的格式。举例来说，你可能希望将某人的姓和名连接在一起， 并保证姓和名的首字母大写，抑或想统计可自由回答的调查反馈信息中含有秽语的实例（instance）数量。一些最有用的字符处理函数见表5-6。</p><p><strong>表5-6  字符处理函数</strong></p><table><thead><tr><th>函  数</th><th>描  述</th></tr></thead><tbody><tr><td>nchar(x)</td><td>计算 x 中的字符数量</td></tr><tr><td></td><td>x &lt;- c(“ab”, “cde”, “fghij”)</td></tr><tr><td></td><td>length(x) 返回值为 3 （参见表 5-7）</td></tr><tr><td></td><td>nchar(x[3]) 返回值为 5</td></tr><tr><td>substr(x, start, stop)</td><td>提取或替换一个字符向量中的子串</td></tr><tr><td></td><td>x &lt;- “abcdef”</td></tr><tr><td></td><td>substr(x, 2, 4) 返回值为"bcd"</td></tr><tr><td></td><td>substr(x, 2, 4) &lt;- “22222”（x 将变成"a222ef"）</td></tr><tr><td>grep(pattern, x, ignore. case=FALSE, fixed=FALSE)</td><td>在 x 中搜索某种模式。若 fixed=FALSE，则 pattern 为一个正则表达式。若 fixed=TRUE，则 pattern 为一个文本字符串。返回值为匹配的下标 grep(“A”,c(“b”,“A”,“c”),fixed=TRUE) 返回值为 2</td></tr><tr><td>sub(pattern, replacement, x, ignore.case=FALSE, fixed=FALSE)</td><td>在 x 中搜索 pattern，并以文本 replacement 将其替换。若 fixed=FALSE，则 pattern 为一个正则表达式。若 fixed=TRUE，则 pattern 为一个文本字符串。sub(“\s”,“.”,“Hello There”)返回值为 Hello.There。注意，“\s"是一个用来查找空白的正则表达式；使用”\s"而不用"\"的原因是，后者是 R 中的转义字符（参见 1.3.3 节）</td></tr><tr><td>strsplit(x, split, fixed=FALSE)</td><td>在 split 处分割字符向量 x 中的元素。若 fixed=FALSE，则 pattern 为一个正则表达式。若 fixed=TRUE，则 pattern 为一个文本字符串</td></tr><tr><td></td><td>y &lt;- strsplit(“abc”, “”) 将返回一个含有 1 个成分、3 个元素的列表，包含的内容为"a" “b” “c”</td></tr><tr><td></td><td>unlist(y)[2] 和 sapply(y, “[”, 2)均会返回"b"</td></tr><tr><td>paste(…, sep=“”)</td><td>连接字符串，分隔符为 sep</td></tr><tr><td></td><td>paste(“x”, 1:3,sep=“”) 返回值为 c(“x1”, “x2”, “x3”)</td></tr><tr><td></td><td>paste(“x”,1:3,sep=“M”) 返回值为 c(“xM1”,“xM2” “xM3”)</td></tr><tr><td></td><td>paste(“Today is”, date()) 返回值为  Today is Sun Aug 15 20:54:49 2021</td></tr><tr><td>toupper(x)</td><td>大写转换</td></tr><tr><td></td><td>toupper(“abc”)返回值为"ABC"</td></tr><tr><td>tolower(x)</td><td>小写转换</td></tr><tr><td></td><td>tolower(“ABC”)   返回值为"abc"</td></tr></tbody></table><p>请注意，函数 grep()、sub() 和 strsplit() 能够搜索某个文本字符串（fixed=TRUE）或某个正则表达式（fixed=FALSE，默认值为 FALSE）。正则表达式为文本模式的匹配提供了一套清晰而简练的语法。例如，正则表达式：</p><pre><code class="highlight R"><span class="operator">^</span><span class="punctuation">[</span>hc<span class="punctuation">]</span><span class="operator">?</span>at</code></pre><p>可匹配任意以 0 个或 1 个 h 或 c 开头、后接at的字符串。因此，此表达式可以匹配 hat、cat 和 at，但不会匹配 bat。要了解更多，请参考维基百科的 regular expression（正则表达式）条目。</p><h5 id="5-2-5-其他实用函数">5.2.5 其他实用函数</h5><p>表5-7 中的函数对于数据管理和处理同样非常实用，只是它们无法清楚地划入其他分类中。</p><p><strong>表5-7  其他实用函数</strong></p><table><thead><tr><th>函  数</th><th>描  述</th></tr></thead><tbody><tr><td>length(x)</td><td>对象 x 的长度</td></tr><tr><td></td><td>x &lt;- c(2, 5, 6, 9)</td></tr><tr><td></td><td>length(x) 返回值为 4</td></tr><tr><td>seq(from, to, by)</td><td>生成一个序列</td></tr><tr><td></td><td>indices &lt;- seq(1,10,2)</td></tr><tr><td></td><td>indices 的值为c(1, 3, 5, 7, 9)</td></tr><tr><td>rep(x, n)</td><td>将 x 重复 n 次</td></tr><tr><td></td><td>y &lt;- rep(1:3, 2)</td></tr><tr><td></td><td>y 的值为 c(1, 2, 3, 1, 2, 3)</td></tr><tr><td>cut(x, n)</td><td>将连续型变量 x 分割为有着 n 个水平的因子</td></tr><tr><td></td><td>使用选项 ordered_result = TRUE 以创建一个有序型因子</td></tr><tr><td>pretty(x, n)</td><td>创建美观的分割点。通过选取 n+1 个等间距的取整值，将一个连续型变量 x 分割为 n 个区间。绘图中常用</td></tr><tr><td>cat(… , file =“myfile”, append =FALSE)</td><td>连接…中的对象，并将其输出到屏幕上或文件中（如果声明了一个的话）</td></tr><tr><td></td><td>firstname &lt;- c(“Jane”)</td></tr><tr><td></td><td>cat(“Hello” ,firstname, “\n”)</td></tr></tbody></table><p>表中的最后一个例子演示了在输出时转义字符的使用方法。\n 表示新行，\t 为制表符，\’ 为单引号，\b 为退格，等等。（键入 ?Quotes 以了解更多。）例如，代码：</p><pre><code class="highlight R">name <span class="operator">&lt;-</span> <span class="string">"Bob"</span>cat<span class="punctuation">(</span> <span class="string">"Hello"</span><span class="punctuation">,</span> name<span class="punctuation">,</span> <span class="string">"\b.\n"</span><span class="punctuation">,</span> <span class="string">"Isn\'t R"</span><span class="punctuation">,</span> <span class="string">"\t"</span><span class="punctuation">,</span> <span class="string">"GREAT?\n"</span><span class="punctuation">)</span></code></pre><p>可生成：<br>Hello Bob.<br>Isn’t R  GREAT?</p><p>请注意第二行缩进了一个空格。当 cat 输出连接后的对象时，它会将每一个对象都用空格分开。这就是在句号之前使用退格转义字符（\b）的原因。不然，生成的结果将是 “Hello Bob .”。</p><p>在数值、字符串和向量上使用我们最近学习的函数是直观而明确的，但是如何将它们应用到</p><p>矩阵和数据框上呢？这就是下一节的主题。</p><h5 id="5-2-6-将函数应用于矩阵和数据框">5.2.6 将函数应用于矩阵和数据框</h5><p>R 函数的诸多有趣特性之一，就是它们可以应用到一系列的数据对象上，包括标量、向量、矩阵、数组和数据框。代码清单5-4 提供了一个示例。</p><p>代码清单5-4 将函数应用于数据对象</p><pre><code class="highlight R"><span class="operator">&gt;</span> a <span class="operator">&lt;-</span> 5<span class="operator">&gt;</span> <span class="built_in">sqrt</span><span class="punctuation">(</span>a<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">2.24</span><span class="operator">&gt;</span> b <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1.243</span><span class="punctuation">,</span> <span class="number">5.654</span><span class="punctuation">,</span> <span class="number">2.99</span><span class="punctuation">)</span><span class="operator">&gt;</span> <span class="built_in">round</span><span class="punctuation">(</span>b<span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">1</span> <span class="number">6</span> <span class="number">3</span><span class="operator">&gt;</span> <span class="built_in">c</span> <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span>runif<span class="punctuation">(</span><span class="number">12</span><span class="punctuation">)</span><span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span><span class="operator">&gt;</span> <span class="built_in">c</span>      <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span>  <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span>   <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span>  <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="number">0.856</span> <span class="number">0.478</span> <span class="number">0.0904</span> <span class="number">0.873</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="number">0.350</span> <span class="number">0.395</span> <span class="number">0.0438</span> <span class="number">0.993</span><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="number">0.749</span> <span class="number">0.370</span> <span class="number">0.7149</span> <span class="number">0.855</span><span class="operator">&gt;</span> <span class="built_in">log</span><span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">)</span>       <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span>   <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span>   <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span>     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">0.156</span> <span class="operator">-</span><span class="number">0.738</span> <span class="operator">-</span><span class="number">2.404</span> <span class="operator">-</span><span class="number">0.13628</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">1.050</span> <span class="operator">-</span><span class="number">0.929</span> <span class="operator">-</span><span class="number">3.128</span> <span class="operator">-</span><span class="number">0.00751</span><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">0.289</span> <span class="operator">-</span><span class="number">0.995</span> <span class="operator">-</span><span class="number">0.336</span> <span class="operator">-</span><span class="number">0.15695</span><span class="operator">&gt;</span> mean<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="number">0.564</span></code></pre><p>请注意，在代码清单5-4 中对矩阵 c 求均值的结果为一个标量（0.444）。函数 mean() 求得的是矩阵中全部 12 个元素的均值。但如果希望求的是各行的均值或各列的均值呢？</p><p>R中提供了一个 apply() 函数，可将一个任意函数“应用”到矩阵、数组、数据框的任何维度上。apply()函数的使用格式为：</p><p>apply(X, MARGIN, FUN, …)</p><p>其中，x 为数据对象，<strong>MARGIN</strong> 是维度的下标，<strong>FUN</strong> 是由你指定的函数，而…则包括了任何想传递给 <strong>FUN</strong> 的参数。在矩阵或数据框中，MARGIN=1表示行，MARGIN=2 表示列。请看以下例子。</p><p><strong>代码清单5-5 将一个函数应用到矩阵的所有行（列）</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> mydata <span class="operator">&lt;-</span> matrix<span class="punctuation">(</span>rnorm<span class="punctuation">(</span><span class="number">30</span><span class="punctuation">)</span><span class="punctuation">,</span> nrow<span class="operator">=</span><span class="number">6</span><span class="punctuation">)</span>  <span class="comment"># 生成数据</span><span class="operator">&gt;</span> mydata       <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span>   <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span>   <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span>   <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">4</span><span class="punctuation">]</span>     <span class="punctuation">[</span><span class="punctuation">,</span><span class="number">5</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.902</span>  <span class="number">1.226</span> <span class="operator">-</span><span class="number">0.672</span>  <span class="number">1.077</span> <span class="operator">-</span><span class="number">1.75273</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.306</span>  <span class="number">2.666</span> <span class="operator">-</span><span class="number">0.744</span> <span class="operator">-</span><span class="number">1.253</span> <span class="operator">-</span><span class="number">1.28340</span><span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.524</span>  <span class="number">0.402</span>  <span class="number">2.380</span>  <span class="number">1.161</span> <span class="operator">-</span><span class="number">1.13352</span><span class="punctuation">[</span><span class="number">4</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">0.570</span> <span class="operator">-</span><span class="number">0.720</span> <span class="operator">-</span><span class="number">0.735</span>  <span class="number">1.535</span>  <span class="number">0.00802</span><span class="punctuation">[</span><span class="number">5</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.729</span> <span class="operator">-</span><span class="number">0.543</span> <span class="operator">-</span><span class="number">1.811</span> <span class="operator">-</span><span class="number">0.959</span> <span class="operator">-</span><span class="number">0.37033</span><span class="punctuation">[</span><span class="number">6</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">0.410</span>  <span class="number">0.814</span>  <span class="number">0.266</span>  <span class="number">0.392</span> <span class="operator">-</span><span class="number">0.37910</span><span class="operator">&gt;</span>  apply<span class="punctuation">(</span>mydata<span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> mean<span class="punctuation">)</span><span class="comment"># 计算每行的均值</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span>  <span class="number">0.1561</span> <span class="operator">-</span><span class="number">0.0618</span>  <span class="number">0.6668</span> <span class="operator">-</span><span class="number">0.0965</span> <span class="operator">-</span><span class="number">0.5909</span>  <span class="number">0.1368</span><span class="operator">&gt;</span> apply<span class="punctuation">(</span>mydata<span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> mean<span class="punctuation">)</span><span class="comment"># 计算每列的均值</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span>  <span class="number">0.247</span>  <span class="number">0.641</span> <span class="operator">-</span><span class="number">0.219</span>  <span class="number">0.325</span> <span class="operator">-</span><span class="number">0.819</span><span class="operator">&gt;</span> apply<span class="punctuation">(</span>mydata<span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> mean<span class="punctuation">,</span> trim<span class="operator">=</span><span class="number">0.2</span><span class="punctuation">)</span><span class="comment"># 计算每行的截尾均值</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span>  <span class="number">0.287</span>  <span class="number">0.475</span> <span class="operator">-</span><span class="number">0.471</span>  <span class="number">0.418</span> <span class="operator">-</span><span class="number">0.792</span></code></pre><p>首先生成了一个包含正态随机数的 6×5 矩阵。然后你计算了 6 行的均值，以及 5 列的均值。最后，你计算了每列的截尾均值（在本例中，截尾均值基于中间 60% 的数据，最高和最低 20% 的值均被忽略）。</p><p>FUN 可为任意 R 函数，这也包括你自行编写的函数（参见 5.4 节），所以apply() 是一种很强大的机制。apply() 可把函数应用到数组的某个维度上，而 lapply() 和 sapply() 则可将函数应用到列表（list）上。你将在下一节中看到 sapply()（它是 lapply() 的更好用的版本）的一个示例。</p><p>你已经拥有了解决5.1 节中数据处理问题所需的所有工具，现在，让我们小试身手。</p><h4 id="5-3-数据处理难题的一套解决方案">5.3 数据处理难题的一套解决方案</h4><p>5.1 节中提出的问题是：将学生的各科考试成绩组合为单一的成绩衡量指标，基于相对名次（前 20%、下 20%、等等）给出从A到F的评分，根据学生姓氏和名字的首字母对花名册进行排序。代码清单5-6 给出了一种解决方案。</p><p><strong>代码清单5-6 示例的一种解决方案</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> <span class="comment"># 步骤1</span><span class="operator">&gt;</span> options<span class="punctuation">(</span>digits<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">&gt;</span> Student <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"John Davis"</span><span class="punctuation">,</span> <span class="string">"Angela Williams"</span><span class="punctuation">,</span> <span class="string">"Bullwinkle Moose"</span><span class="punctuation">,</span> <span class="string">"David Jones"</span><span class="punctuation">,</span> <span class="string">"Janice Markhammer"</span><span class="punctuation">,</span> <span class="string">"Cheryl Cushing"</span><span class="punctuation">,</span> <span class="string">"Reuven Ytzrhak"</span><span class="punctuation">,</span> <span class="string">"Greg Knox"</span><span class="punctuation">,</span> <span class="string">"Joel England"</span><span class="punctuation">,</span> <span class="string">"Mary Rayburn"</span><span class="punctuation">)</span><span class="operator">&gt;</span> Math <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">502</span><span class="punctuation">,</span> <span class="number">600</span><span class="punctuation">,</span> <span class="number">412</span><span class="punctuation">,</span> <span class="number">358</span><span class="punctuation">,</span> <span class="number">495</span><span class="punctuation">,</span> <span class="number">512</span><span class="punctuation">,</span> <span class="number">410</span><span class="punctuation">,</span> <span class="number">625</span><span class="punctuation">,</span> <span class="number">573</span><span class="punctuation">,</span> <span class="number">522</span><span class="punctuation">)</span><span class="operator">&gt;</span> Science <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">95</span><span class="punctuation">,</span> <span class="number">99</span><span class="punctuation">,</span> <span class="number">80</span><span class="punctuation">,</span> <span class="number">82</span><span class="punctuation">,</span> <span class="number">75</span><span class="punctuation">,</span> <span class="number">85</span><span class="punctuation">,</span> <span class="number">80</span><span class="punctuation">,</span> <span class="number">95</span><span class="punctuation">,</span> <span class="number">89</span><span class="punctuation">,</span> <span class="number">86</span><span class="punctuation">)</span><span class="operator">&gt;</span> English <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">25</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">15</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">28</span><span class="punctuation">,</span> <span class="number">15</span><span class="punctuation">,</span> <span class="number">30</span><span class="punctuation">,</span> <span class="number">27</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">)</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>Student<span class="punctuation">,</span> Math<span class="punctuation">,</span> Science<span class="punctuation">,</span> English<span class="punctuation">,</span> stringsAsFactors<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span><span class="operator">&gt;</span> <span class="comment"># 步骤2</span><span class="operator">&gt;</span> z <span class="operator">&lt;-</span> scale<span class="punctuation">(</span>roster<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">)</span> <span class="comment"># 计算综合得分  </span><span class="operator">&gt;</span> <span class="comment"># 步骤3</span><span class="operator">&gt;</span> score <span class="operator">&lt;-</span> apply<span class="punctuation">(</span>z<span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> mean<span class="punctuation">)</span> <span class="comment"># 计算综合得分</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> cbind<span class="punctuation">(</span>roster<span class="punctuation">,</span> score<span class="punctuation">)</span><span class="comment"># 计算综合得分</span><span class="operator">&gt;</span> <span class="comment"># 步骤4</span><span class="operator">&gt;</span> y <span class="operator">&lt;-</span> quantile<span class="punctuation">(</span>score<span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">.8</span><span class="punctuation">,</span><span class="number">.6</span><span class="punctuation">,</span><span class="number">.4</span><span class="punctuation">,</span><span class="number">.2</span><span class="punctuation">)</span><span class="punctuation">)</span>    <span class="comment"># 对学生评分</span><span class="operator">&gt;</span> <span class="comment"># 步骤5</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"A"</span>    <span class="comment"># 对学生评分</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="operator">&amp;</span> score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"B"</span><span class="comment"># 对学生评分</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">&amp;</span> score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"C"</span><span class="comment"># 对学生评分</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">3</span><span class="punctuation">]</span> <span class="operator">&amp;</span> score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"D"</span><span class="comment"># 对学生评分</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"F"</span><span class="comment"># 对学生评分</span><span class="operator">&gt;</span> <span class="comment"># 步骤6</span><span class="operator">&gt;</span> name <span class="operator">&lt;-</span> strsplit<span class="punctuation">(</span><span class="punctuation">(</span>roster<span class="operator">$</span>Student<span class="punctuation">)</span><span class="punctuation">,</span> <span class="string">" "</span><span class="punctuation">)</span><span class="operator">&gt;</span> <span class="comment"># 步骤7</span><span class="operator">&gt;</span> Lastname <span class="operator">&lt;-</span> sapply<span class="punctuation">(</span>name<span class="punctuation">,</span> <span class="string">"["</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span>  <span class="comment"># 抽取姓氏和名字</span><span class="operator">&gt;</span> Firstname <span class="operator">&lt;-</span> sapply<span class="punctuation">(</span>name<span class="punctuation">,</span> <span class="string">"["</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span> <span class="comment"># 抽取姓氏和名字</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> cbind<span class="punctuation">(</span>Firstname<span class="punctuation">,</span>Lastname<span class="punctuation">,</span> roster<span class="punctuation">[</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">)</span> <span class="comment"># 抽取姓氏和名字</span><span class="operator">&gt;</span> <span class="comment"># 步骤8</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> roster<span class="punctuation">[</span>order<span class="punctuation">(</span>Lastname<span class="punctuation">,</span>Firstname<span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="comment"># 根据姓氏和名字排序</span><span class="operator">&gt;</span> roster    Firstname   Lastname Math Science English score grade<span class="number">6</span>      Cheryl    Cushing  <span class="number">512</span>      <span class="number">85</span>      <span class="number">28</span>  <span class="number">0.35</span>     C<span class="number">1</span>        John      Davis  <span class="number">502</span>      <span class="number">95</span>      <span class="number">25</span>  <span class="number">0.56</span>     B<span class="number">9</span>        Joel    England  <span class="number">573</span>      <span class="number">89</span>      <span class="number">27</span>  <span class="number">0.70</span>     B<span class="number">4</span>       David      Jones  <span class="number">358</span>      <span class="number">82</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.16</span>     <span class="built_in">F</span><span class="number">8</span>        Greg       Knox  <span class="number">625</span>      <span class="number">95</span>      <span class="number">30</span>  <span class="number">1.34</span>     A<span class="number">5</span>      Janice Markhammer  <span class="number">495</span>      <span class="number">75</span>      <span class="number">20</span> <span class="operator">-</span><span class="number">0.63</span>     D<span class="number">3</span>  Bullwinkle      Moose  <span class="number">412</span>      <span class="number">80</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.86</span>     D<span class="number">10</span>       Mary    Rayburn  <span class="number">522</span>      <span class="number">86</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.18</span>     C<span class="number">2</span>      Angela   Williams  <span class="number">600</span>      <span class="number">99</span>      <span class="number">22</span>  <span class="number">0.92</span>     A<span class="number">7</span>      Reuven    Ytzrhak  <span class="number">410</span>      <span class="number">80</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.05</span>     <span class="built_in">F</span></code></pre><p>以上代码写得比较紧凑，逐步分解如下。</p><p><strong>步骤1</strong>  原始的学生花名册已经给出了。options(digits=2) 限定了输出小数点后数字的位数，并且让输出更容易阅读：</p><pre><code class="highlight R"><span class="operator">&gt;</span> options<span class="punctuation">(</span>digits<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">&gt;</span> Student <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"John Davis"</span><span class="punctuation">,</span> <span class="string">"Angela Williams"</span><span class="punctuation">,</span> <span class="string">"Bullwinkle Moose"</span><span class="punctuation">,</span> <span class="string">"David Jones"</span><span class="punctuation">,</span> <span class="string">"Janice Markhammer"</span><span class="punctuation">,</span> <span class="string">"Cheryl Cushing"</span><span class="punctuation">,</span> <span class="string">"Reuven Ytzrhak"</span><span class="punctuation">,</span> <span class="string">"Greg Knox"</span><span class="punctuation">,</span> <span class="string">"Joel England"</span><span class="punctuation">,</span> <span class="string">"Mary Rayburn"</span><span class="punctuation">)</span><span class="operator">&gt;</span> Math <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">502</span><span class="punctuation">,</span> <span class="number">600</span><span class="punctuation">,</span> <span class="number">412</span><span class="punctuation">,</span> <span class="number">358</span><span class="punctuation">,</span> <span class="number">495</span><span class="punctuation">,</span> <span class="number">512</span><span class="punctuation">,</span> <span class="number">410</span><span class="punctuation">,</span> <span class="number">625</span><span class="punctuation">,</span> <span class="number">573</span><span class="punctuation">,</span> <span class="number">522</span><span class="punctuation">)</span><span class="operator">&gt;</span> Science <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">95</span><span class="punctuation">,</span> <span class="number">99</span><span class="punctuation">,</span> <span class="number">80</span><span class="punctuation">,</span> <span class="number">82</span><span class="punctuation">,</span> <span class="number">75</span><span class="punctuation">,</span> <span class="number">85</span><span class="punctuation">,</span> <span class="number">80</span><span class="punctuation">,</span> <span class="number">95</span><span class="punctuation">,</span> <span class="number">89</span><span class="punctuation">,</span> <span class="number">86</span><span class="punctuation">)</span><span class="operator">&gt;</span> English <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">25</span><span class="punctuation">,</span> <span class="number">22</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">,</span> <span class="number">15</span><span class="punctuation">,</span> <span class="number">20</span><span class="punctuation">,</span> <span class="number">28</span><span class="punctuation">,</span> <span class="number">15</span><span class="punctuation">,</span> <span class="number">30</span><span class="punctuation">,</span> <span class="number">27</span><span class="punctuation">,</span> <span class="number">18</span><span class="punctuation">)</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> data.frame<span class="punctuation">(</span>Student<span class="punctuation">,</span> Math<span class="punctuation">,</span> Science<span class="punctuation">,</span> English<span class="punctuation">,</span> stringsAsFactors<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span><span class="operator">&gt;</span> options<span class="punctuation">(</span>digits<span class="operator">=</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">&gt;</span> roster             Student Math Science English<span class="number">1</span>         John Davis  <span class="number">502</span>      <span class="number">95</span>      <span class="number">25</span><span class="number">2</span>    Angela Williams  <span class="number">600</span>      <span class="number">99</span>      <span class="number">22</span><span class="number">3</span>   Bullwinkle Moose  <span class="number">412</span>      <span class="number">80</span>      <span class="number">18</span><span class="number">4</span>        David Jones  <span class="number">358</span>      <span class="number">82</span>      <span class="number">15</span><span class="number">5</span>  Janice Markhammer  <span class="number">495</span>      <span class="number">75</span>      <span class="number">20</span><span class="number">6</span>     Cheryl Cushing  <span class="number">512</span>      <span class="number">85</span>      <span class="number">28</span><span class="number">7</span>     Reuven Ytzrhak  <span class="number">410</span>      <span class="number">80</span>      <span class="number">15</span><span class="number">8</span>          Greg Knox  <span class="number">625</span>      <span class="number">95</span>      <span class="number">30</span><span class="number">9</span>       Joel England  <span class="number">573</span>      <span class="number">89</span>      <span class="number">27</span><span class="number">10</span>      Mary Rayburn  <span class="number">522</span>      <span class="number">86</span>      <span class="number">18</span></code></pre><p><strong>步骤2</strong>  由于数学、科学和英语考试的分值不同（均值和标准差相去甚远），在组合之前需要先让它们变得可以比较。一种方法是将变量进行标准化，这样每科考试的成绩就都是用单位标准差来表示，而不是以原始的尺度来表示了。这个过程可以使用 scale() 函数来实现：</p><pre><code class="highlight R"><span class="operator">&gt;</span> z <span class="operator">&lt;-</span> scale<span class="punctuation">(</span>roster<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">)</span><span class="operator">&gt;</span> z        Math Science English <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.013</span>   <span class="number">1.078</span>   <span class="number">0.587</span> <span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">1.143</span>   <span class="number">1.591</span>   <span class="number">0.037</span> <span class="punctuation">[</span><span class="number">3</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">1.026</span>  <span class="operator">-</span><span class="number">0.847</span>  <span class="operator">-</span><span class="number">0.697</span> <span class="punctuation">[</span><span class="number">4</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">1.649</span>  <span class="operator">-</span><span class="number">0.590</span>  <span class="operator">-</span><span class="number">1.247</span> <span class="punctuation">[</span><span class="number">5</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">0.068</span>  <span class="operator">-</span><span class="number">1.489</span>  <span class="operator">-</span><span class="number">0.330</span> <span class="punctuation">[</span><span class="number">6</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.128</span>  <span class="operator">-</span><span class="number">0.205</span>   <span class="number">1.137</span> <span class="punctuation">[</span><span class="number">7</span><span class="punctuation">,</span><span class="punctuation">]</span> <span class="operator">-</span><span class="number">1.049</span>  <span class="operator">-</span><span class="number">0.847</span>  <span class="operator">-</span><span class="number">1.247</span> <span class="punctuation">[</span><span class="number">8</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">1.432</span>   <span class="number">1.078</span>   <span class="number">1.504</span> <span class="punctuation">[</span><span class="number">9</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.832</span>   <span class="number">0.308</span>   <span class="number">0.954</span><span class="punctuation">[</span><span class="number">10</span><span class="punctuation">,</span><span class="punctuation">]</span>  <span class="number">0.243</span>  <span class="operator">-</span><span class="number">0.077</span>  <span class="operator">-</span><span class="number">0.697</span><span class="built_in">attr</span><span class="punctuation">(</span><span class="punctuation">,</span><span class="string">"scaled:center"</span><span class="punctuation">)</span>   Math Science English     <span class="number">501</span>      <span class="number">87</span>      <span class="number">22</span> <span class="built_in">attr</span><span class="punctuation">(</span><span class="punctuation">,</span><span class="string">"scaled:scale"</span><span class="punctuation">)</span>   Math Science English</code></pre><p><strong>步骤3</strong>  然后，可以通过函数 mean() 来计算各行的均值以获得综合得分，并使用函数</p><p>cbind() 将其添加到花名册中：</p><pre><code class="highlight R"><span class="operator">&gt;</span> score <span class="operator">&lt;-</span> apply<span class="punctuation">(</span>z<span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> mean<span class="punctuation">)</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> cbind<span class="punctuation">(</span>roster<span class="punctuation">,</span> score<span class="punctuation">)</span><span class="operator">&gt;</span> roster             Student Math Science English score<span class="number">1</span>         John Davis  <span class="number">502</span>      <span class="number">95</span>      <span class="number">25</span>  <span class="number">0.56</span><span class="number">2</span>    Angela Williams  <span class="number">600</span>      <span class="number">99</span>      <span class="number">22</span>  <span class="number">0.92</span><span class="number">3</span>   Bullwinkle Moose  <span class="number">412</span>      <span class="number">80</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.86</span><span class="number">4</span>        David Jones  <span class="number">358</span>      <span class="number">82</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.16</span><span class="number">5</span>  Janice Markhammer  <span class="number">495</span>      <span class="number">75</span>      <span class="number">20</span> <span class="operator">-</span><span class="number">0.63</span><span class="number">6</span>     Cheryl Cushing  <span class="number">512</span>      <span class="number">85</span>      <span class="number">28</span>  <span class="number">0.35</span><span class="number">7</span>     Reuven Ytzrhak  <span class="number">410</span>      <span class="number">80</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.05</span><span class="number">8</span>          Greg Knox  <span class="number">625</span>      <span class="number">95</span>      <span class="number">30</span>  <span class="number">1.34</span><span class="number">9</span>       Joel England  <span class="number">573</span>      <span class="number">89</span>      <span class="number">27</span>  <span class="number">0.70</span><span class="number">10</span>      Mary Rayburn  <span class="number">522</span>      <span class="number">86</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.18</span></code></pre><p><strong>步骤4</strong> 函数 quantile() 给出了学生综合得分的百分位数。可以看到，成绩为 A 的分界点为 0.74，B 的分界点为 0.44，等等。</p><pre><code class="highlight R"><span class="operator">&gt;</span> y <span class="operator">&lt;-</span> quantile<span class="punctuation">(</span>roster<span class="operator">$</span>score<span class="punctuation">,</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">.8</span><span class="punctuation">,</span><span class="number">.6</span><span class="punctuation">,</span><span class="number">.4</span><span class="punctuation">,</span><span class="number">.2</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">&gt;</span> y  <span class="number">80</span><span class="operator">%   60%</span>   <span class="number">40</span><span class="operator">%   20%</span>  <span class="number">0.74</span>  <span class="number">0.44</span> <span class="operator">-</span><span class="number">0.36</span> <span class="operator">-</span><span class="number">0.89</span></code></pre><p><strong>步骤5</strong>  通过使用逻辑运算符，你可以将学生的百分位数排名重编码为一个新的类别型成绩变量。下面在数据框 roster 中创建了变量 grade。</p><pre><code class="highlight R"><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"A"</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="operator">&amp;</span> score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"B"</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> <span class="operator">&amp;</span> score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"C"</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">3</span><span class="punctuation">]</span> <span class="operator">&amp;</span> score <span class="operator">&gt;=</span> y<span class="punctuation">[</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"D"</span><span class="operator">&gt;</span> roster<span class="operator">$</span>grade<span class="punctuation">[</span>score <span class="operator">&lt;</span> y<span class="punctuation">[</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">]</span> <span class="operator">&lt;-</span> <span class="string">"F"</span><span class="operator">&gt;</span> roster             Student Math Science English score grade<span class="number">1</span>         John Davis  <span class="number">502</span>      <span class="number">95</span>      <span class="number">25</span>  <span class="number">0.56</span>     B<span class="number">2</span>    Angela Williams  <span class="number">600</span>      <span class="number">99</span>      <span class="number">22</span>  <span class="number">0.92</span>     A<span class="number">3</span>   Bullwinkle Moose  <span class="number">412</span>      <span class="number">80</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.86</span>     D<span class="number">4</span>        David Jones  <span class="number">358</span>      <span class="number">82</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.16</span>     <span class="built_in">F</span><span class="number">5</span>  Janice Markhammer  <span class="number">495</span>      <span class="number">75</span>      <span class="number">20</span> <span class="operator">-</span><span class="number">0.63</span>     D<span class="number">6</span>     Cheryl Cushing  <span class="number">512</span>      <span class="number">85</span>      <span class="number">28</span>  <span class="number">0.35</span>     C<span class="number">7</span>     Reuven Ytzrhak  <span class="number">410</span>      <span class="number">80</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.05</span>     <span class="built_in">F</span><span class="number">8</span>          Greg Knox  <span class="number">625</span>      <span class="number">95</span>      <span class="number">30</span>  <span class="number">1.34</span>     A<span class="number">9</span>       Joel England  <span class="number">573</span>      <span class="number">89</span>      <span class="number">27</span>  <span class="number">0.70</span>     B<span class="number">10</span>      Mary Rayburn  <span class="number">522</span>      <span class="number">86</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.18</span>     C</code></pre><p><strong>步骤6</strong>  你将使用函数 strsplit() 以空格为界把学生姓名拆分为姓氏和名字。把 strsplit() 应用到一个字符串组成的向量上会返回一个列表：</p><pre><code class="highlight R"><span class="operator">&gt;</span> name <span class="operator">&lt;-</span> strsplit<span class="punctuation">(</span><span class="punctuation">(</span>roster<span class="operator">$</span>Student<span class="punctuation">)</span><span class="punctuation">,</span> <span class="string">" "</span><span class="punctuation">)</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"John"</span>  <span class="string">"Davis"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Angela"</span>   <span class="string">"Williams"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Bullwinkle"</span> <span class="string">"Moose"</span>     <span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"David"</span> <span class="string">"Jones"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">5</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Janice"</span>     <span class="string">"Markhammer"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">6</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Cheryl"</span>  <span class="string">"Cushing"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">7</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Reuven"</span>  <span class="string">"Ytzrhak"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">8</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Greg"</span> <span class="string">"Knox"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">9</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Joel"</span>    <span class="string">"England"</span><span class="operator">&gt;</span> name <span class="punctuation">[[</span><span class="number">10</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Mary"</span>    <span class="string">"Rayburn"</span></code></pre><p><strong>步骤7</strong> 你可以使用函数 sapply() 提取列表中每个成分的第一个元素，放入一个储存名字的向量 Firstname，并提取每个成分的第二个元素，放入一个储存姓氏的向量 Lastname。“[” 是一个可以提取某个对象的一部分的函数——在这里它是用来提取列表 name 各成分中的第一个或第二个元素的。你将使用 cbind() 把它们添加到花名册中。由于已经不再需要 student 变量，可以将其丢弃（在下标中使用–1）。</p><pre><code class="highlight R"><span class="operator">&gt;</span> Firstname <span class="operator">&lt;-</span> sapply<span class="punctuation">(</span>name<span class="punctuation">,</span> <span class="string">"["</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span><span class="operator">&gt;</span> Lastname <span class="operator">&lt;-</span> sapply<span class="punctuation">(</span>name<span class="punctuation">,</span> <span class="string">"["</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">)</span><span class="operator">&gt;</span> roster <span class="operator">&lt;-</span> cbind<span class="punctuation">(</span>Firstname<span class="punctuation">,</span> Lastname<span class="punctuation">,</span> roster<span class="punctuation">[</span><span class="punctuation">,</span><span class="operator">-</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">)</span><span class="operator">&gt;</span> roster    Firstname   Lastname   Lastname Lastname.1 Math Science English score grade<span class="number">1</span>        John      Davis      Davis      Davis  <span class="number">502</span>      <span class="number">95</span>      <span class="number">25</span>  <span class="number">0.56</span>     B<span class="number">2</span>      Angela   Williams   Williams   Williams  <span class="number">600</span>      <span class="number">99</span>      <span class="number">22</span>  <span class="number">0.92</span>     A<span class="number">3</span>  Bullwinkle      Moose      Moose      Moose  <span class="number">412</span>      <span class="number">80</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.86</span>     D<span class="number">4</span>       David      Jones      Jones      Jones  <span class="number">358</span>      <span class="number">82</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.16</span>     <span class="built_in">F</span><span class="number">5</span>      Janice Markhammer Markhammer Markhammer  <span class="number">495</span>      <span class="number">75</span>      <span class="number">20</span> <span class="operator">-</span><span class="number">0.63</span>     D<span class="number">6</span>      Cheryl    Cushing    Cushing    Cushing  <span class="number">512</span>      <span class="number">85</span>      <span class="number">28</span>  <span class="number">0.35</span>     C<span class="number">7</span>      Reuven    Ytzrhak    Ytzrhak    Ytzrhak  <span class="number">410</span>      <span class="number">80</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.05</span>     <span class="built_in">F</span><span class="number">8</span>        Greg       Knox       Knox       Knox  <span class="number">625</span>      <span class="number">95</span>      <span class="number">30</span>  <span class="number">1.34</span>     A<span class="number">9</span>        Joel    England    England    England  <span class="number">573</span>      <span class="number">89</span>      <span class="number">27</span>  <span class="number">0.70</span>     B<span class="number">10</span>       Mary    Rayburn    Rayburn    Rayburn  <span class="number">522</span>      <span class="number">86</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.18</span>     C</code></pre><p><strong>步骤8</strong> 最后，可以使用函数 order() 依姓氏和名字对数据集进行排序：</p><pre><code class="highlight R"><span class="operator">&gt;</span> roster<span class="punctuation">[</span>order<span class="punctuation">(</span>Lastname<span class="punctuation">,</span>Firstname<span class="punctuation">)</span><span class="punctuation">,</span><span class="punctuation">]</span>    Firstname   Lastname   Lastname Lastname.1 Math Science English score grade<span class="number">6</span>      Cheryl    Cushing    Cushing    Cushing  <span class="number">512</span>      <span class="number">85</span>      <span class="number">28</span>  <span class="number">0.35</span>     C<span class="number">1</span>        John      Davis      Davis      Davis  <span class="number">502</span>      <span class="number">95</span>      <span class="number">25</span>  <span class="number">0.56</span>     B<span class="number">9</span>        Joel    England    England    England  <span class="number">573</span>      <span class="number">89</span>      <span class="number">27</span>  <span class="number">0.70</span>     B<span class="number">4</span>       David      Jones      Jones      Jones  <span class="number">358</span>      <span class="number">82</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.16</span>     <span class="built_in">F</span><span class="number">8</span>        Greg       Knox       Knox       Knox  <span class="number">625</span>      <span class="number">95</span>      <span class="number">30</span>  <span class="number">1.34</span>     A<span class="number">5</span>      Janice Markhammer Markhammer Markhammer  <span class="number">495</span>      <span class="number">75</span>      <span class="number">20</span> <span class="operator">-</span><span class="number">0.63</span>     D<span class="number">3</span>  Bullwinkle      Moose      Moose      Moose  <span class="number">412</span>      <span class="number">80</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.86</span>     D<span class="number">10</span>       Mary    Rayburn    Rayburn    Rayburn  <span class="number">522</span>      <span class="number">86</span>      <span class="number">18</span> <span class="operator">-</span><span class="number">0.18</span>     C<span class="number">2</span>      Angela   Williams   Williams   Williams  <span class="number">600</span>      <span class="number">99</span>      <span class="number">22</span>  <span class="number">0.92</span>     A<span class="number">7</span>      Reuven    Ytzrhak    Ytzrhak    Ytzrhak  <span class="number">410</span>      <span class="number">80</span>      <span class="number">15</span> <span class="operator">-</span><span class="number">1.05</span>     <span class="built_in">F</span></code></pre><p>瞧！小事一桩！</p><p>完成这些任务的方式有许多，只是以上代码体现了相应函数的设计初衷。现在到学习控制结构和自己编写函数的时候了。</p><h4 id="5-4-控制流">5.4 控制流</h4><p>在正常情况下，R 程序中的语句是从上至下顺序执行的。但有时你可能希望重复执行某些语句，仅在满足特定条件的情况下执行另外的语句。这就是控制流结构发挥作用的地方了。</p><p>R 拥有一般现代编程语言中都有的标准控制结构。首先你将看到用于条件执行的结构，接下来是用于循环执行的结构。</p><p>为了理解贯穿本节的语法示例，请牢记以下概念：</p><p>❑ 语句（statement）是一条单独的R语句或一组复合语句（包含在花括号 { } 中的一组 R 语句，使用分号分隔）；</p><p>❑ 条件（cond）是一条最终被解析为真（TRUE）或假（FALSE）的表达式；</p><p>❑ 表达式（expr）是一条数值或字符串的求值语句；</p><p>❑ 序列（seq）是一个数值或字符串序列。</p><p>在讨论过控制流的构造后，我们将学习如何编写函数。</p><h5 id="5-4-1-重复和循环">5.4.1 重复和循环</h5><p>循环结构重复地执行一个或一系列语句，直到某个条件不为真为止。循环结构包括 for 和 while 结构。</p><p><strong>1.  for 结构</strong></p><p>for 循环重复地执行一个语句，直到某个变量的值不再包含在序列 seq 中为止。语法为：</p><p>for (var in seq) statement</p><p>在下例中：</p><pre><code class="highlight R"><span class="operator">&gt;</span> <span class="keyword">for</span> <span class="punctuation">(</span>i <span class="keyword">in</span> <span class="number">1</span><span class="operator">:</span><span class="number">10</span><span class="punctuation">)</span> print<span class="punctuation">(</span><span class="string">"Hello"</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span></code></pre><p>单词 Hello 被输出了 10 次。</p><p><strong>2.  while 结构</strong></p><p>while 循环重复地执行一个语句，直到条件不为真为止。语法为：</p><p>while (cond) statement</p><p>作为第二个例子，代码：</p><pre><code class="highlight R"><span class="operator">&gt;</span> i <span class="operator">&lt;-</span> 10<span class="operator">&gt;</span> <span class="keyword">while</span> <span class="punctuation">(</span>i <span class="operator">&gt;</span> <span class="number">0</span><span class="punctuation">)</span> <span class="punctuation">{</span>print<span class="punctuation">(</span><span class="string">"Hello"</span><span class="punctuation">)</span>; i <span class="operator">&lt;-</span> i <span class="operator">-</span> <span class="number">1</span><span class="punctuation">}</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Hello"</span></code></pre><p>又将单词 Hello 输出了 10 次。请确保括号内 while 的条件语句能够改变，即让它在某个时刻不再为真——否则循环将永不停止！在上例中，语句：</p><p>i &lt;- i – 1<br>在每步循环中为对象 i 减去 1，这样在十次循环过后，它就不再大于 0 了。反之，如果在每步循环都加1的话，R 将不停地打招呼。这也是 while 循环可能较其他循环结构更危险的原因。</p><p>在处理大数据集中的行和列时，R 中的循环可能比较低效费时。只要可能，最好联用R中的内建数值/字符处理函数和 apply 族函数。</p><h5 id="5-4-2-条件执行">5.4.2 条件执行</h5><p>在条件执行结构中，一条或一组语句仅在满足一个指定条件时执行。条件执行结构包括</p><p>if-else、ifelse 和 switch。</p><p><strong>1.  if-else 结构</strong></p><p>控制结构 if-else 在某个给定条件为真时执行语句。也可以同时在条件为假时执行另外的语句。语法为：</p><p>if (cond) statement<br>if (cond) statement1 else statement2</p><p>示例如下：</p><pre><code class="highlight R"><span class="keyword">if</span> <span class="punctuation">(</span><span class="built_in">is.character</span><span class="punctuation">(</span>grade<span class="punctuation">)</span><span class="punctuation">)</span> grade <span class="operator">&lt;-</span> as.factor<span class="punctuation">(</span>grade<span class="punctuation">)</span><span class="keyword">if</span> <span class="punctuation">(</span><span class="operator">!</span>is.factor<span class="punctuation">(</span>grade<span class="punctuation">)</span><span class="punctuation">)</span> grade <span class="operator">&lt;-</span> as.factor<span class="punctuation">(</span>grade<span class="punctuation">)</span> <span class="keyword">else</span> print<span class="punctuation">(</span><span class="string">"Grade already is a factor"</span><span class="punctuation">)</span></code></pre><p>在第一个实例中，如果 grade 是一个字符向量，它就会被转换为一个因子。在第二个实例中， 两个语句择其一执行。如果 grade 不是一个因子（注意符号!），它就会被转换为一个因子。如果它是一个因子，就会输出一段信息。</p><p><strong>2. ifelse 结构</strong></p><p>ifelse 结构是 if-else 结构比较紧凑的向量化版本，其语法为：</p><p>ifelse(cond, statement1,  statement2)</p><p>若 cond 为 TRUE，则执行第一个语句；若 cond 为 FALSE，则执行第二个语句。示例如下：</p><pre><code class="highlight R">ifelse<span class="punctuation">(</span>score <span class="operator">&gt;</span> <span class="number">0.5</span><span class="punctuation">,</span> print<span class="punctuation">(</span><span class="string">"Passed"</span><span class="punctuation">)</span><span class="punctuation">,</span> print<span class="punctuation">(</span><span class="string">"Failed"</span><span class="punctuation">)</span><span class="punctuation">)</span> outcome <span class="operator">&lt;-</span> ifelse <span class="punctuation">(</span>score <span class="operator">&gt;</span> <span class="number">0.5</span><span class="punctuation">,</span> <span class="string">"Passed"</span><span class="punctuation">,</span> <span class="string">"Failed"</span><span class="punctuation">)</span></code></pre><p>在程序的行为是二元时，或者希望结构的输入和输出均为向量时，请使用 ifelse。</p><p><strong>3. switch 结构</strong></p><p>switch 根据一个表达式的值选择语句执行。语法为：</p><p>switch(expr, …)</p><p>其中的…表示与 expr 的各种可能输出值绑定的语句。通过观察代码清单5-7 中的代码，可以轻松地理解 switch 的工作原理。</p><p><strong>代码清单5-7 一个 switch 示例</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> feelings <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"sad"</span><span class="punctuation">,</span> <span class="string">"afraid"</span><span class="punctuation">)</span><span class="operator">&gt;</span> <span class="keyword">for</span> <span class="punctuation">(</span>i <span class="keyword">in</span> feelings<span class="punctuation">)</span> <span class="operator">+</span>     print<span class="punctuation">(</span><span class="operator">+</span>         <span class="built_in">switch</span><span class="punctuation">(</span>i<span class="punctuation">,</span><span class="operator">+</span>                happy <span class="operator">=</span> <span class="string">"I am glad you are happy"</span><span class="punctuation">,</span> <span class="operator">+</span>                afraid <span class="operator">=</span> <span class="string">"There is nothing to fear"</span><span class="punctuation">,</span> <span class="operator">+</span>                sad    <span class="operator">=</span> <span class="string">"Cheer up"</span><span class="punctuation">,</span><span class="operator">+</span>                angry <span class="operator">=</span> <span class="string">"Calm down now"</span><span class="operator">+</span>         <span class="punctuation">)</span><span class="operator">+</span>     <span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"Cheer up"</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"There is nothing to fear"</span></code></pre><p>虽然这个例子比较幼稚，但它展示了 switch 的主要功能。你将在下一节学习如何使用 switch 编写自己的函数。</p><h4 id="5-5-用户自编函数">5.5 用户自编函数</h4><p>R 的最大优点之一就是用户可以自行添加函数。事实上，R中的许多函数都是由已有函数构成的。一个函数的结构看起来大致如此：</p><pre><code class="highlight R">myfunction <span class="operator">&lt;-</span> <span class="keyword">function</span><span class="punctuation">(</span>arg1<span class="punctuation">,</span> arg2<span class="punctuation">,</span> ... <span class="punctuation">)</span><span class="punctuation">{</span>    statements    <span class="built_in">return</span><span class="punctuation">(</span>object<span class="punctuation">)</span><span class="punctuation">}</span></code></pre><p>函数中的对象只在函数内部使用。返回对象的数据类型是任意的，从标量到列表皆可。让我们看一个示例。</p><p>假设你想编写一个函数，用来计算数据对象的集中趋势和散布情况。此函数应当可以选择性地给出参数统计量（均值和标准差）和非参数统计量（中位数和绝对中位差）。结果应当以一个含名称列表的形式给出。另外，用户应当可以选择是否自动输出结果。除非另外指定，否则此函数的默认行为应当是计算参数统计量并且不输出结果。代码清单5-8 给出了一种解答。</p><p><strong>代码清单5-8  mystats()：一个由用户编写的描述性统计量计算函数</strong></p><pre><code class="highlight R">mystats <span class="operator">&lt;-</span> <span class="keyword">function</span><span class="punctuation">(</span>x<span class="punctuation">,</span> parametric<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">,</span> print<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">)</span> <span class="punctuation">{</span>     <span class="keyword">if</span> <span class="punctuation">(</span>parametric<span class="punctuation">)</span> <span class="punctuation">{</span>    center <span class="operator">&lt;-</span> mean<span class="punctuation">(</span>x<span class="punctuation">)</span>; spread <span class="operator">&lt;-</span> sd<span class="punctuation">(</span>x<span class="punctuation">)</span>    <span class="punctuation">}</span> <span class="keyword">else</span> <span class="punctuation">{</span>        center <span class="operator">&lt;-</span> median<span class="punctuation">(</span>x<span class="punctuation">)</span>; spread <span class="operator">&lt;-</span> mad<span class="punctuation">(</span>x<span class="punctuation">)</span>    <span class="punctuation">}</span>    <span class="keyword">if</span> <span class="punctuation">(</span>print <span class="operator">&amp;</span> parametric<span class="punctuation">)</span> <span class="punctuation">{</span>    cat<span class="punctuation">(</span><span class="string">"Mean="</span><span class="punctuation">,</span> center<span class="punctuation">,</span> <span class="string">"\n"</span><span class="punctuation">,</span> <span class="string">"SD="</span><span class="punctuation">,</span> spread<span class="punctuation">,</span> <span class="string">"\n"</span><span class="punctuation">)</span>    <span class="punctuation">}</span> <span class="keyword">else</span> <span class="keyword">if</span> <span class="punctuation">(</span>print <span class="operator">&amp;</span> <span class="operator">!</span>parametric<span class="punctuation">)</span> <span class="punctuation">{</span>cat<span class="punctuation">(</span><span class="string">"Median="</span><span class="punctuation">,</span> center<span class="punctuation">,</span> <span class="string">"\n"</span><span class="punctuation">,</span> <span class="string">"MAD="</span><span class="punctuation">,</span> spread<span class="punctuation">,</span> <span class="string">"\n"</span><span class="punctuation">)</span>    <span class="punctuation">}</span>    result <span class="operator">&lt;-</span> <span class="built_in">list</span><span class="punctuation">(</span>center<span class="operator">=</span>center<span class="punctuation">,</span> spread<span class="operator">=</span>spread<span class="punctuation">)</span>     <span class="built_in">return</span><span class="punctuation">(</span>result<span class="punctuation">)</span><span class="punctuation">}</span></code></pre><p>要看此函数的实战情况，首先需要生成一些数据（服从正态分布的，大小为 500 的随机样本）：</p><pre><code class="highlight R">set.seed<span class="punctuation">(</span><span class="number">1234</span><span class="punctuation">)</span> x <span class="operator">&lt;-</span> rnorm<span class="punctuation">(</span><span class="number">500</span><span class="punctuation">)</span></code></pre><p>在执行语句：</p><pre><code class="highlight R">y <span class="operator">&lt;-</span> mystats<span class="punctuation">(</span>x<span class="punctuation">)</span></code></pre><pre><code class="highlight R">之后，y<span class="operator">$</span>center 将包含均值（<span class="number">0.00184</span>），y<span class="operator">$</span>spread 将包含标准差（<span class="number">1.03</span>），并且没有输出结果。如果执行语句：y <span class="operator">&lt;-</span> mystats<span class="punctuation">(</span>x<span class="punctuation">,</span> parametric<span class="operator">=</span><span class="literal">FALSE</span><span class="punctuation">,</span> print<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span>y<span class="operator">$</span>center 将包含中位数（–<span class="number">0.0207</span>），y<span class="operator">$</span>spread 将包含绝对中位差（<span class="number">1.001</span>）。另外，还会输出以下结果：Median<span class="operator">=</span> <span class="operator">-</span><span class="number">0.0207</span> MAD<span class="operator">=</span> <span class="number">1</span></code></pre><p>下面让我们看一个使用了 switch 结构的用户自编函数，此函数可让用户选择输出当天日期的格式。在函数声明中为参数指定的值将作为其默认值。在函数 mydate() 中，如果未指定 type， 则 long 将为默认的日期格式：</p><pre><code class="highlight R">mydate <span class="operator">&lt;-</span> <span class="keyword">function</span><span class="punctuation">(</span>type<span class="operator">=</span><span class="string">"long"</span><span class="punctuation">)</span> <span class="punctuation">{</span> <span class="built_in">switch</span><span class="punctuation">(</span>type<span class="punctuation">,</span>long <span class="operator">=</span> format<span class="punctuation">(</span>Sys.time<span class="punctuation">(</span><span class="punctuation">)</span><span class="punctuation">,</span> <span class="string">"%A %B %d %Y"</span><span class="punctuation">)</span><span class="punctuation">,</span> short <span class="operator">=</span> format<span class="punctuation">(</span>Sys.time<span class="punctuation">(</span><span class="punctuation">)</span><span class="punctuation">,</span> <span class="string">"%m-%d-%y"</span><span class="punctuation">)</span><span class="punctuation">,</span> cat<span class="punctuation">(</span>type<span class="punctuation">,</span> <span class="string">"is not a recognized type\n"</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">}</span></code></pre><p>实战中的函数如下：</p><pre><code class="highlight R"><span class="operator">&gt;</span> mydate<span class="punctuation">(</span><span class="string">"long"</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"星期日 八月 15 2021"</span><span class="operator">&gt;</span> mydate<span class="punctuation">(</span><span class="string">"short"</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"08-15-21"</span><span class="operator">&gt;</span> mydate<span class="punctuation">(</span><span class="punctuation">)</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> <span class="string">"星期日 八月 15 2021"</span><span class="operator">&gt;</span> mydate<span class="punctuation">(</span><span class="string">"medium"</span><span class="punctuation">)</span>medium is not a recognized type</code></pre><p>请注意，函数 cat() 仅会在输入的日期格式类型不匹配 “long” 或 “short” 时执行。使用一个表达式来捕获用户的错误输入的参数值通常来说是一个好主意。</p><p>有若干函数可以用来为函数添加错误捕获和纠正功能。你可以使用函数 warning() 来生成一条错误提示信息，用 message() 来生成一条诊断信息，或用stop()停止当前表达式的执行并提示错误。20.5 节将会更加详细地讨论错误捕捉和调试。</p><p>在创建好自己的函数以后，你可能希望在每个会话中都能直接使用它们。附录 B 描述了如何定制R环境，以使 R 启动时自动读取用户编写的函数。我们将在第 6 章和第 8 章中看到更多的用户自编函数示例。</p><p>你可以使用本节中提供的基本技术完成很多工作。第 20 章的内容更加详细地涵盖了控制流和其他编程主题。第 21 章涵盖了如何创建包。如果你想要探索编写函数的微妙之处，或编写可以分发给他人使用的专业级代码，个人推荐阅读这两章，然后阅读两本优秀的书籍，你可在本书末尾的参考文献部分找到：Venables &amp; Ripley（2000）以及Chambers（2008）。这两本书共同提供了大量细节和众多示例。</p><p>函数的编写就讲到这里，我们将以对数据整合和重塑的讨论来结束本章。</p><h4 id="5-6-整合与重构">5.6 整合与重构</h4><p>R中提供了许多用来整合（aggregate）和重塑（reshape）数据的强大方法。在整合数据时， 往往将多组观测替换为根据这些观测计算的描述性统计量。在重塑数据时，则会通过修改数据的结构（行和列）来决定数据的组织方式。本节描述了用来完成这些任务的多种方式。</p><p>在接下来的两个小节中，我们将使用已包含在 R 基本安装中的数据框 mtcars。这个数据集是从 <em>Motor</em> <em>Trend</em> 杂志（1974）提取的，它描述了 34 种车型的设计和性能特点（汽缸数、排量、马力、每加仑汽油行驶的英里数，等等）。要了解此数据集的更多信息，请参阅 help(mtcars)。</p><h5 id="5-6-1-转置">5.6.1 转置</h5><p>转置（反转行和列）也许是重塑数据集的众多方法中最简单的一个了。使用函数t()即可对一个矩阵或数据框进行转置。对于后者，行名将成为变量（列）名。代码清单5-9 展示了一个例子。</p><p><strong>代码清单5-9 数据集的转置</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> cars <span class="operator">&lt;-</span> mtcars<span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">5</span><span class="punctuation">,</span><span class="number">1</span><span class="operator">:</span><span class="number">4</span><span class="punctuation">]</span><span class="operator">&gt;</span> cars                  mpg cyl disp  hpMazda RX4          <span class="number">21</span>   <span class="number">6</span>  <span class="number">160</span> <span class="number">110</span>Mazda RX4 Wag      <span class="number">21</span>   <span class="number">6</span>  <span class="number">160</span> <span class="number">110</span>Datsun <span class="number">710</span>         <span class="number">23</span>   <span class="number">4</span>  <span class="number">108</span>  <span class="number">93</span>Hornet <span class="number">4</span> Drive     <span class="number">21</span>   <span class="number">6</span>  <span class="number">258</span> <span class="number">110</span>Hornet Sportabout  <span class="number">19</span>   <span class="number">8</span>  <span class="number">360</span> <span class="number">175</span><span class="operator">&gt;</span> t<span class="punctuation">(</span>cars<span class="punctuation">)</span>     Mazda RX4 Mazda RX4 Wag Datsun <span class="number">710</span> Hornet <span class="number">4</span> Drive Hornet Sportaboutmpg         <span class="number">21</span>            <span class="number">21</span>         <span class="number">23</span>             <span class="number">21</span>                <span class="number">19</span>cyl          <span class="number">6</span>             <span class="number">6</span>          <span class="number">4</span>              <span class="number">6</span>                 <span class="number">8</span>disp       <span class="number">160</span>           <span class="number">160</span>        <span class="number">108</span>            <span class="number">258</span>               <span class="number">360</span>hp         <span class="number">110</span>           <span class="number">110</span>         <span class="number">93</span>            <span class="number">110</span>               <span class="number">175</span></code></pre><p>为了节约空间，代码清单5-9 仅使用了 mtcars 数据集的一个子集。在本节稍后讲解 reshape2 包的时候，你将看到一种更为灵活的数据转置方式。</p><h5 id="5-6-2-整合数据">5.6.2 整合数据</h5><p>在 R 中使用一个或多个 by 变量和一个预先定义好的函数来折叠（collapse）数据是比较容易的。调用格式为：</p><p><strong>aggregate(x, by, FUN)</strong></p><p>其中X是待折叠的数据对象，by 是一个变量名组成的列表，这些变量将被去掉以形成新的观测， 而 *FUN *则是用来计算描述性统计量的标量函数，它将被用来计算新观测中的值。</p><p>作为一个示例，我们将根据汽缸数和挡位数整合 mtcars 数据，并返回各个数值型变量的均值（见代码清单5-10）。</p><p><strong>代码清单5-10  整合数据</strong></p><pre><code class="highlight R"><span class="operator">&gt;</span> options<span class="punctuation">(</span>digits<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span><span class="operator">&gt;</span> attach<span class="punctuation">(</span>mtcars<span class="punctuation">)</span><span class="operator">&gt;</span> aggdata <span class="operator">&lt;-</span>aggregate<span class="punctuation">(</span>mtcars<span class="punctuation">,</span> by<span class="operator">=</span><span class="built_in">list</span><span class="punctuation">(</span>cyl<span class="punctuation">,</span>gear<span class="punctuation">)</span><span class="punctuation">,</span> FUN<span class="operator">=</span>mean<span class="punctuation">,</span> na.rm<span class="operator">=</span><span class="literal">TRUE</span><span class="punctuation">)</span><span class="operator">&gt;</span> aggdata  Group.1 Group.2  mpg cyl disp  hp drat   wt qsec  vs   am gear carb<span class="number">1</span>       <span class="number">4</span>       <span class="number">3</span> <span class="number">21.5</span>   <span class="number">4</span>  <span class="number">120</span>  <span class="number">97</span> <span class="number">3.70</span> <span class="number">2.46</span> <span class="number">20.0</span> <span class="number">1.0</span> <span class="number">0.00</span>    <span class="number">3</span> <span class="number">1.00</span><span class="number">2</span>       <span class="number">6</span>       <span class="number">3</span> <span class="number">19.8</span>   <span class="number">6</span>  <span class="number">242</span> <span class="number">108</span> <span class="number">2.92</span> <span class="number">3.34</span> <span class="number">19.8</span> <span class="number">1.0</span> <span class="number">0.00</span>    <span class="number">3</span> <span class="number">1.00</span><span class="number">3</span>       <span class="number">8</span>       <span class="number">3</span> <span class="number">15.1</span>   <span class="number">8</span>  <span class="number">358</span> <span class="number">194</span> <span class="number">3.12</span> <span class="number">4.10</span> <span class="number">17.1</span> <span class="number">0.0</span> <span class="number">0.00</span>    <span class="number">3</span> <span class="number">3.08</span><span class="number">4</span>       <span class="number">4</span>       <span class="number">4</span> <span class="number">26.9</span>   <span class="number">4</span>  <span class="number">103</span>  <span class="number">76</span> <span class="number">4.11</span> <span class="number">2.38</span> <span class="number">19.6</span> <span class="number">1.0</span> <span class="number">0.75</span>    <span class="number">4</span> <span class="number">1.50</span><span class="number">5</span>       <span class="number">6</span>       <span class="number">4</span> <span class="number">19.8</span>   <span class="number">6</span>  <span class="number">164</span> <span class="number">116</span> <span class="number">3.91</span> <span class="number">3.09</span> <span class="number">17.7</span> <span class="number">0.5</span> <span class="number">0.50</span>    <span class="number">4</span> <span class="number">4.00</span><span class="number">6</span>       <span class="number">4</span>       <span class="number">5</span> <span class="number">28.2</span>   <span class="number">4</span>  <span class="number">108</span> <span class="number">102</span> <span class="number">4.10</span> <span class="number">1.83</span> <span class="number">16.8</span> <span class="number">0.5</span> <span class="number">1.00</span>    <span class="number">5</span> <span class="number">2.00</span><span class="number">7</span>       <span class="number">6</span>       <span class="number">5</span> <span class="number">19.7</span>   <span class="number">6</span>  <span class="number">145</span> <span class="number">175</span> <span class="number">3.62</span> <span class="number">2.77</span> <span class="number">15.5</span> <span class="number">0.0</span> <span class="number">1.00</span>    <span class="number">5</span> <span class="number">6.00</span><span class="number">8</span>       <span class="number">8</span>       <span class="number">5</span> <span class="number">15.4</span>   <span class="number">8</span>  <span class="number">326</span> <span class="number">300</span> <span class="number">3.88</span> <span class="number">3.37</span> <span class="number">14.6</span> <span class="number">0.0</span> <span class="number">1.00</span>    <span class="number">5</span> <span class="number">6.00</span></code></pre><p>在结果中，Group.1 表示汽缸数量（4、6或8），Group.2 代表挡位数（3、4 或 5）。举例来说，拥有 4 个汽缸和 3 个挡位车型的每加仑汽油行驶英里数（mpg）均值为 21.5。</p><p>在使用 aggregate() 函数的时候，by 中的变量必须在一个列表中（即使只有一个变量）。你可以在列表中为各组声明自定义的名称， 例如 by=list(Group.cyl=cyl, Group.gears=gear)。指定的函数可为任意的内建或自编函数，这就为整合命令赋予了强大的力量。但说到力量，没有什么可以比 reshape2 包更强。</p><h5 id="5-6-3-reshape2-包">5.6.3   reshape2 包</h5><p>reshape2 包①是一套重构和整合数据集的绝妙的万能工具。由于它的这种万能特性，可能学起来会有一点难度。我们将慢慢地梳理整个过程，并使用一个小型数据集作为示例，这样每一步发生了什么就很清晰了。由于 reshape2 包并未包含在R的标准安装中，在第一次使用它之前需要使用 install.packages(“reshape2”)进行安装。</p><p>① 由同一作者开发的 reshape2 包是原 reshape 的重新设计版本，功能更为强大。</p><p>大致说来，你需要首先将数据融合（melt），以使每一行都是唯一的标识符-变量组合。然后将数据重铸（cast）为你想要的任何形状。在重铸过程中，你可以使用任何函数对数据进行整合。将使用的数据集如表5-8所示。</p><p><strong>表5-8 原始数据集（mydata）</strong></p><table><thead><tr><th>ID</th><th>Time</th><th>X1</th><th>X2</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>5</td><td>6</td></tr><tr><td>1</td><td>2</td><td>3</td><td>5</td></tr><tr><td>2</td><td>1</td><td>6</td><td>1</td></tr><tr><td>2</td><td>2</td><td>2</td><td>4</td></tr></tbody></table><p>在这个数据集中，测量（measurement）是指最后两列中的值（5、6、3、5、6、1、2、4）。每个测量都能够被标识符变量（在本例中，标识符是指 ID、Time 以及观测属于 X1 还是 X2）唯一地确定。举例来说，在知道 ID 为 1、Time 为 1，以及属于变量 X1 之后，即可确定测量值为第一行中的 5。</p><p><strong>1. 融合</strong></p><p>数据集的融合是将它重构为这样一种格式：每个测量变量独占一行，行中带有要唯一确定这个测量所需的标识符变量。要融合表5-8 中的数据，可使用以下代码：</p><pre><code class="highlight R">library<span class="punctuation">(</span>reshape2<span class="punctuation">)</span>md <span class="operator">&lt;-</span> melt<span class="punctuation">(</span>mydata<span class="punctuation">,</span> id<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"ID"</span><span class="punctuation">,</span> <span class="string">"Time"</span><span class="punctuation">)</span><span class="punctuation">)</span></code></pre><p>你将得到如表5-9 所示的结构。</p><p><strong>表5-9 融合后的数据集</strong></p><table><thead><tr><th style="text-align:center">ID</th><th style="text-align:center">Time</th><th style="text-align:center">变 量</th><th style="text-align:center">值</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">X1</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">X1</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">X1</td><td style="text-align:center">6</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">X1</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">X2</td><td style="text-align:center">6</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">X2</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">X2</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">2</td><td style="text-align:center">X2</td><td style="text-align:center">4</td></tr></tbody></table><p>注意，必须指定要唯一确定每个测量所需的变量（ID和Time），而表示测量变量名的变量（X1 或 X2）将由程序为你自动创建。</p><p>既然已经拥有了融合后的数据，现在就可以使用 dcast() 函数将它重铸为任意形状了。</p><p><strong>2. 重铸</strong></p><p>dcast() 函数读取已融合的数据，并使用你提供的公式和一个（可选的）用于整合数据的函数将其重塑。调用格式为：</p><p>newdata &lt;- dcast(md, formula, fun.aggregate)</p><p>其中的 md 为已融合的数据，formula 描述了想要的最后结果，而 fun.aggregate 是（可选的）数据整合函数。其接受的公式形如：</p><p>rowvar1 + rowvar2 + … ~ colvar1 + colvar2 + …</p><p>在这一公式中，rowvar1 + rowvar2 + …定义了要划掉的变量集合，以确定各行的内容， 而 colvar1 + colvar2 + …则定义了要划掉的、确定各列内容的变量集合。参见图5-1 中的示例。</p> <img src="/medias/image-20210815222148762.png" alt="图5-1 使用函数melt()和dcast()重塑数据" style="zoom:67%;"><p>由于右侧（d、e 和 f）的公式中并未包括某个函数，所以数据仅被重塑了。反之，左侧的示例（a、b 和 c）中指定了 mean 作为整合函数，从而就对数据同时进行了重塑与整合。例如，示例 (a) 中给出了每个观测所有时刻中在 X1 和 X2 上的均值；示例 (b) 则给出了 X1 和 X2 在时刻 1 和时刻 2 的均值，对不同的观测进行了平均；在 © 中则是每个观测在时刻 1 和时刻 2 的均值，对不同的 X1 和 X2 进行了平均。</p><p>如你所见，函数 melt() 和 dcast() 提供了令人惊叹的灵活性。很多时候，你不得不在进行分析之前重塑或整合数据。举例来说，在分析重复测量数据（为每个观测记录了多个测量的数据） 时，你通常需要将数据转化为类似于表5-9 中所谓的长格式。示例参见9.6 节。</p><h4 id="5-7-小结">5.7 小结</h4><p>本章总结了数十种用于处理数据的数学、统计和概率函数。我们看到了如何将这些函数应用到范围广泛的数据对象上，其中包括向量、矩阵和数据框。你学习了控制流结构的使用方法：用循环重复执行某些语句，或用分支在满足某些特定条件时执行另外的语句。然后你编写了自己的函数，并将它们应用到数据上。最后，我们探索了折叠、整合以及重构数据的多种方法。</p><p>既然已经集齐了数据塑形（没有别的意思）所需的工具，你就准备好告别第一部分并进入激动人心的数据分析世界了！在接下来的几章中，我们将探索多种将数据转化为信息的统计方法和图形方法。</p>]]></content>
      
      
      <categories>
          
          <category> R 语言实战（第2版） </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R语言实战（第2版） </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习推荐两本书</title>
      <link href="/2021/01/21/ji_qi_xue_xi_tui_jian_liang_ben_shu/"/>
      <url>/2021/01/21/ji_qi_xue_xi_tui_jian_liang_ben_shu/</url>
      
        <content type="html"><![CDATA[<h4 id="1、周志华教授的《机器学习》">1、周志华教授的《机器学习》</h4><h4 id="2、李航博士的《统计学习方法》第二版">2、李航博士的《统计学习方法》第二版</h4><p>想要学习机器学习的同学们可以看看哈！！！</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 统计学习方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第七章 机器学习入门</title>
      <link href="/2020/08/12/di_qi_zhang_ji_qi_xue_xi_ru_men/"/>
      <url>/2020/08/12/di_qi_zhang_ji_qi_xue_xi_ru_men/</url>
      
        <content type="html"><![CDATA[<h2 id="第七章-机器学习入门">第七章 机器学习入门</h2><h3 id="1、绪论">1、绪论</h3><p>学科定义、发展历程、机器学习方法、应用场景、难点与挑战</p><h4 id="1-1-什么是机器学习">1.1 什么是机器学习</h4><p><strong>机器学习是从人工智能中产生的一个重要学科分支，是实现智能化的关键</strong>。</p><p>机器学习( Machine Learning)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门硏究计算机怎样模拟或实现人类的学习行为，以获取新知识或技能，重新组织已有的知识结构使之不断改善自身的性能。——百度百科</p><p>Machine learning is the study of <strong>algorithms</strong> and mathematical <strong>models</strong> that computer systems use to progressively improve their performance on a specific task Machine learning algorithms build a<br>mathematical model of <strong>sample data</strong>， known as training data"， in order to make predictions or decisions without being explicitly programmed to perform the task.  ——Wikipedia</p><h4 id="1-2-机器学习的一般过程">1.2 机器学习的一般过程</h4><p><img src="/medias/image-20200709235542006.png" alt=""></p><h4 id="1-3-发展历程">1.3 发展历程</h4><p>☆ <strong>推理期(20世纪5070年代初)</strong></p><ol><li>认为只要给机器赋予<strong>逻辑推理</strong>能力，机器就能具有智能</li><li>A.Newe和H. Simon的“逻辑理论家”、“通用问题求解”程序，获得了1975年图灵奖</li></ol><p>★ 知识期(20世纪70年代中期)</p><ol><li>认为要使机器具有智能，就必须设法使机器<strong>拥有知识</strong></li><li>EA. Feigenbaum作为“知识工程”之父在1994年获得了图灵奖</li></ol><p>★ <strong>学科形成(20世纪80年代)</strong></p><ol><li>20世纪80年代是机器学习成为—个<strong>独立学科领域</strong>并开始快速发展、各种机器学习技术<strong>百花齐放</strong></li><li>1980年美国卡内基梅隆大学举行第一届机器学习研讨会</li><li>1990年《机器学习:风范与方法》出版</li></ol><p>★ 繁荣期(20世纪80年代至今)</p><ol><li>20世纪90年代后，<strong>统计学习方法</strong>占主导，代表为SVM</li><li>2006至今，大数据分析的需求，<strong>神经网络</strong>又被重视，成为<strong>深度学习理论的基础</strong></li></ol><h4 id="1-4-机器学习方法">1.4 机器学习方法</h4><p><strong>有监督学习(supervised learning)</strong>：从给定的<strong>有标注的训练数据集</strong>中学习出个函数(模型参数)，当新的数据到来时可以根据这个函数预测结果。常见任务包括<strong>分类</strong>与<strong>回归</strong>。</p><p><img src="/medias/image-20200710000421349.png" alt=""></p><p><strong>无监督学习(unsupervised learning)</strong>：<strong>没有标注的训练数据集</strong>，需要根据样本间的统计规律对样本集进行分析，常见任务如聚类等。</p><p><img src="/medias/image-20200710000743328.png" alt=""></p><p><strong>半监督学习(Semi-supervised learning)</strong>：结合**(少量的)标注训练数据<strong>和</strong>(大量的)未标注数据**来进行数据的分类学习。<br><strong>两个基本假设:</strong></p><ol><li>**聚类假设：**处在相同聚类中的样本示例有较大的可能拥有相同的标记。根据该假设，决策边界就应该尽量通过数据较为稀疏的地方。</li><li>**流形假设：**处于一个很小的局部区域内的样本示例具有相似的性质，因此，其标记也应该相似。在该假设下，大量未标记示例的作用就是让数据空间变得更加稠密，从而有助于更加准确地刻画局部特性，使得决策函数能够更好地进行数据拟合。</li></ol><p><img src="/medias/image-20200710001147408.png" alt=""></p><p><strong>增强学习(Reinforcement Learning)</strong>：<strong>外部环境对输岀只给岀评价信息而非正确答案</strong>，学习机通过强化受奖励的动作来改善自身的性能。<br>如：<strong>让计算机学着去玩 Flappy Bird</strong><br>我们不需要设置具体的策略，比如先飞到上面，再飞到下面，我们只是需要给算法定一个“小目标”！比如当计算机玩的好的时候，我们就给它一定的奖励，它玩的不好的时候，就给它一定的惩罚，在这个算法框架下，它就可以越来越好，超过人类玩家的水平。</p><p><strong>多任务学习(Multi-task Learning)</strong>：<strong>把多个相关(related)的任务放在一起同时学习</strong>。<br>单任务学习时，各个任务之间的模型空间( Trained Model)是相互独立的，但现实世界中很多问题不能分解为一个一个独立的子问题，且这样忽略了问题之间所包含的丰富的关联信息。多任务学习就是为了解决这个问题而诞生的。多个任务之间共享一些因素，它们可以在习过程中，共享它们所学到的信息，相关联的<strong>多任务学习比单任务学习具备更好的泛化(generalization)效果</strong>。</p><p><img src="/medias/image-20200710001830055.png" alt=""></p><p><img src="/medias/image-20200715173008577.png" alt=""></p><p><img src="/medias/image-20200715173309313.png" alt=""></p><p><img src="/medias/image-20200715173415195.png" alt=""></p><h4 id="1-5-机器学习面临的难题与挑战">1.5 机器学习面临的难题与挑战</h4><p><img src="/medias/image-20200715173607548.png" alt=""></p><p>◆<strong>数据稀疏性</strong>: 训练一个模型，需要大量(标注)数据，但是<strong>数据往往比较稀疏</strong>。比如，我们想训练一个模型表征某人“购物兴趣”，但是这个人在网站上浏览行为很少，购物历史很少，<strong>很难训练出一个“meaningful mode"<strong>来预测应该给这个人推荐什么商品等…<br>◆</strong>高数量和高质量标注数据需求</strong>: 获取标定数据需要耗费大量人力和财力。而且人会出错，有主观性。<strong>如何获取高数量和高质量标定数据，或者用机器学习方法只标注“关键”数据(active learning)值得深入硏究…</strong><br>◆<strong>冷启动问题</strong>: 一个好互联网产品，用的人多，得到的数据多；得到的数据越多模型训练的越好，产品会变得更好用，用的人就会更多…进入良性循环。对于<strong>一个新产品，在初期，要面临数据不足</strong>的冷启动问题….<br>◆<strong>泛化能力问题</strong>: 训练数据不能全面、均衡的代表真实数据。</p><p><img src="/medias/image-20200715174204776.png" alt=""></p><p>◆<strong>模型抽象困难</strong>:总结归纳实际问题中的数学表示非常困难。<br>◆<strong>模型评估困难</strong>:在很多实际问题中，很难形式化的、定量的评估一个模型的结果是好还是不好?<br>◆<strong>寻找最优解困难</strong>:要解决的实际问题非常复杂，将其形式化后的目标函数也非常复杂，往往在目前还不存在一个有效的算法能找到目标函数的最优值。</p><p><img src="/medias/image-20200729171807139.png" alt=""></p><p>◆ <strong>Scalability</strong>是互联网的核心问题之一。搜索引擎索引的重要网页超过100亿；<strong>如果1台机器每秒处理1000网页，需要至少100天</strong>。所以出现了 MapReduce，MPI，Spark，Pegasus，Pregel，Hama…等分布式计算构架。选择什么样的计算平台和算法设计紧密相关…<br>◆<strong>速度</strong>是互联网核心的用户体验。线下模型训练可以花费很长时间：比如， Google某个模型更新一次需要几干台机器，大约训练半年时间。但是，线上使用模型的时候要求一定要“<strong>快，实时(real-time)</strong>”…<br>◆ <strong>online learning</strong>:互联网每时每刻都在产生大量新数据，要求模型随之不停更新，所以online learning是机器学习的一个重要研究方向。</p><h3 id="2、问题提出">2、问题提出</h3><p>鸢尾花分类任务简介</p><p><img src="/medias/image-20200729180713670.png" alt=""></p><h3 id="3、机器如何学习">3、机器如何学习</h3><p>数据处理、特征工程、学习模型、模型评估</p><h4 id="3-1-数据预处理">3.1 数据预处理</h4><p><img src="/medias/image-20200729181057756.png" alt=""></p><h5 id="3-1-1-数据清洗">3.1.1 数据清洗</h5><p>对各种脏数据进行对应方式的处理，得到标准、干净、连续的数据，提供给数据统计、数据挖掘等使用。</p><p>● <strong>数据的完整性</strong><br>例如人的属性中缺少性别、籍贯、年龄等；<br>解决方法：信息补全(使用身份证件号码推算性别、籍贯、出生日期、年龄等);剔除;</p><p>● <strong>数据的唯一性</strong><br>例如不同来源的数据出现重复的情况等；<br>解决方法：按主键去重(用 sql 或者 excel “去除重复记录”) / 按规则去重(如不同渠道来的客户数据，可以通过相同的关键信息进行匹配，合并去重)</p><p>● <strong>数据的合法性</strong><br>例如获取数据与常识不符，年龄大于150岁:<br>解决方法：</p><p><strong>设置字段内容</strong>(日期字段格式为 ”2010-10-10“);</p><p><strong>类型的合法规则</strong>(性别 in [男、女、未知])</p><p>● <strong>数据的权威性</strong><br>例如出现多个来源的数据，且数值不一样;<br>解决方法：为不同渠道设置权威级别，如:在家里，首先得相信媳妇说的。</p><p>● <strong>数据的一致性</strong><br>例如不同来源的不同指标，实际内涵是一样的，或是同一指标内涵不一致；<br>解决方法：建立数据体系，包含但不限于指标体系、维度、单位、频度等</p><h5 id="3-1-2-数据采样">3.1.2 数据采样</h5><p><strong>1、数据不平衡(imbalance)</strong></p><p>**指数据集的类别分布不均。**比如说一个二分类问题，100个训练样本，比较理想的情况是正类、负类样本的数量相差不多;而如果正类样本有99个、负类样本仅1个，就意味着存在类不平衡。</p><p>此时预测时就算全部为正，准确率也可以达到99%，这并<strong>不能反映模型的好坏</strong>。</p><p>**注意：**面临不平衡数据集的时候，传统的机器学习模型的评价方法不能精确地衡量模型的性能。</p><p><strong>2、解决方法</strong></p><p><strong>1. 过采样(Over-Sampling)</strong></p><p>通过随机复制少数类来增加其中的实例数量，从而可增加样本中少数类的代表性。</p><p><strong>2. 欠采样(Under-Sampling)</strong><br>通过随机地消除占多数的类的样本来平衡类分布；直到多数类和少数类的实例实现平衡。</p><h5 id="3-1-3-数据集拆分">3.1.3 数据集拆分</h5><p><strong>1、机器学习中将数据划分为3份</strong></p><p>① 训练数据集(train dataset)</p><p>用来构建机器学习模型</p><p>② 验证数据集(validation dataset)</p><p>辅助构建模型，用于在构建过程中评估模型，提供无偏估计，进而调整模型参数</p><p>③ 测试数据集(test dataset)</p><p>用来评估训练好的最终模型的性能</p><p><img src="/medias/image-20200729195719556.png" alt=""></p><p><strong>2、常用拆分方法</strong></p><p><strong>1. 留出法(Hold-out)</strong></p><p>直接将数据集划分为互斥的集合，如通常选择70%数据作为训练集，30%作为测试集。需要注意的是保持划分后集合数据分布的一致性，避免划分过程中引入额外的偏差而对最终结果产生影响。</p><p><strong>2. K-折交叉验证法</strong></p><p>将数据集划分为 k 个大小相似的互斥子集，并且尽量保证每个子集数据分布的一致性。这样，就可以获取 k 组训练 - 测试集，从而进行k次训练和测试，k通常取值为10。</p><h4 id="3-2-特征工程">3.2 特征工程</h4><p><img src="/medias/image-20200729200058857.png" alt=""></p><h5 id="3-2-1-特征编码">3.2.1 特征编码</h5><p>数据集中经常会出现字符串信息，例如男女、高中低等，这类信息不能直接用于算法计算，需要将这些<strong>数据转化为数值形式</strong>进行编码，便于后期进行建模。</p><p><img src="/medias/image-20200729200430609.png" alt=""></p><p><strong>1、one-hot编码</strong></p><p>采用<strong>N位状态寄存器</strong>来对N个状态进行编码，每个状态都由他独立的寄存器位，并在任意时候只有一位有效。</p><p>√ 图中的 Elevator 和 Renovation 都是定类型数据。除去缺失值， Elevator分类有电梯和无电梯两种，因此可用01和10表示。</p><p>√ Renovation分为有精装，简装，毛坯和其它四种，可用0001/0010/0100/1000表示。</p><p><strong>2、语义编码</strong></p><p>one-hot编码无法体现数据间的语义关系，对于一些有关联的文本信息来说无法真正体现出数据关联。</p><p>√  对于这一类信息通常采用词嵌入(word embedding)的方式是比较好的选择，词嵌入信息可以编码语义信息，生成特征语义表示。目前在这一领域比较好的方法是基于 google的word2vec方法。</p><h5 id="3-2-2-特征选择">3.2.2 特征选择</h5><p><img src="/medias/image-20200729201136637.png" alt=""></p><p>◆ 过滤法(Filter)</p><p>按照发散性或相关性对各特征进行评分，设定阈值完成特征选择。</p><p>√ 互信息：指两个随机变量之间的关联程度，即给定一个随机变量后，另一个随机变量的确定性；因而互信息取值最小为0，意味着给定一个随机变量对确定一另一个随机变量没有关系，越大表示另一个变量的确定性越高。</p><p><img src="/medias/image-20200729202110064.png" alt=""></p><p>◆ 包裹法(Wrapper)</p><p>选定特定算法，然后通过不断的启发式方法来搜索特征。</p><p>◆嵌入法(Embedded):</p><p>利用正则化的思想，将部分特征属性的权重调整到 0，则这个特性相当于就是被舍弃了。常见的正则有 L1 的 Lasso， L2 的Ridge，还有一种综合 L1 和 L2 的这两个方法的 Elastic Net 方法。</p><p><img src="/medias/image-20200729201225022.png" alt=""></p><h5 id="3-2-3-特征降维">3.2.3 特征降维</h5><p>特征选择完成后，可能由于特征矩阵过大，导致计算量大、训练时间长，因此<strong>降低特征矩阵维度</strong>也是必不可少的。<br>◆ <strong>主成分分析(PCA)</strong></p><p>将原始特征空间映射到彼此正交的特征向量空间，在非满秩的情况下使用SVD分解来构建特征向量。</p><p><img src="/medias/image-20200729202538963.png" alt=""></p><p>◆ <strong>线性判别分析(LDA)</strong></p><p>给出一个标注了类别的数据集，投影到了一条直线之后，能够使得点尽量的按类别区分开。</p><p><img src="/medias/image-20200729202556707.png" alt=""></p><h5 id="3-2-4-规范化">3.2.4 规范化</h5><p>不同属性具有不同量级时会导致：</p><p>① 数量级的差异将导致量级较大的属性占据主导地位；</p><p>② 数量级的差异将导致迭代收敛速度减慢；</p><p>③ 依赖于样本距离的算法对于数据的数量级非常敏感。</p><p>◆ <strong>标准化</strong></p><p>通过减去均值然后除以方差(或标准差)，将数据按比例缩放，使之落入一个小的特定区间</p><p>x = (x - μ)/σ<br>适用于：如果数据的分布本身就服从正态分布，就可以用这个方法。</p><p>◆ <strong>区间缩放</strong></p><p>将属性缩放到一个指定的最大和最小值(通常是1-0)之间</p><p>x=(x-min)/(max-min)</p><p>◆ <strong>归一化</strong></p><p>将某一属性特征的模长转化成1。</p><img src="/medias/image-20200729203228670.png" style="float: left; zoom: 45%;"><p><br><br><br></p><h4 id="3-3-数据建模">3.3 数据建模</h4><p><img src="/medias/image-20200729203331334.png" alt=""></p><h5 id="3-3-1-机器学习算法分类">3.3.1 机器学习算法分类</h5><p><img src="/medias/image-20200729203355228.png" alt=""></p><h4 id="3-4-分类问题">3.4 分类问题</h4><p>分类问题是监督学习的一个核心问题，它从数据中学习一个分类决策函数或分类模型（分类器(classifier)），对新的输入进行输出预测，输出变量取有限个离散值。</p><p><strong>分类在我们日常生活中很常见</strong></p><p><img src="/medias/image-20200805183806785.png" alt=""></p><p><strong>核心算法</strong></p><p><strong>√</strong>  决策树、贝叶斯、SVM、逻辑回归</p><h5 id="3-4-1-决策树">3.4.1 决策树</h5><p>**决策树( decision tree)**是一个树结构，每个非叶节点表示一个特征属性，每个分支边代表这个特征属性在某个值域上的输出，每个叶节点存放一个类别。</p><p>**决策过程：**从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支直到到达叶子节点，将叶子节点存放的类别作为决策结果。</p><p>示例：假如我买了一个西瓜，它的特点是<strong>纹理清晰、根蒂硬挺</strong>，如何根据右侧决策树判断是好瓜还是坏瓜?</p><ul><li>给定训练数据，如何构建决策树呢?<ol><li><strong>特征选择</strong>：选取对训练数据具有分类能力的特征。</li><li><strong>决策树生成</strong>：在决策树各个点上按照一定方法选择特征，递归构建决策树。</li><li><strong>决策树剪枝</strong>：在已生成的树上减掉一些子树或者叶节点，从而简化分类树模型。</li></ol></li></ul><img src="/medias/image-20200805184623616.png" style="zoom: 45%;"><ul><li><p><strong>核心算法</strong></p><p><strong>ID3算法，C4.5算法及CART算法</strong></p></li></ul><p><strong>决策树特征选择</strong></p><p>决策树构建过程中的特征选择是非常重要的一步。特征选择是决定用哪个特征来划分特征空间，特征选择是要选岀对训练数据集具有分类能力的特征，这样可以提髙决策树的学习效率。</p><p><strong>信息熵</strong>：表示<strong>随机变量的不确定性，熵越大不确定性越大</strong>。<br><strong>信怠增益</strong>：信息增益 = 信息煵(前) - 信息熵(后)<br><strong>信息增益比</strong>：<strong>信息增益比 = 惩罚参数 * 信息增益</strong>。<u>特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。</u><br><strong>基尼指数</strong>：表示集合的不确定性，<strong>基尼系数越大，表示不平等程度越高</strong>。</p><img src="/medias/image-20200805184954501.png" style="zoom: 67%;"><img src="/medias/image-20200805185018283.png" style="zoom:67%;"><p><strong>决策树剪枝</strong></p><p>在生成树的过程中，如果没有**剪枝(pruning)**操作，就会生成一个队训练集完全拟合的决策树，但这是对测试集非常不友好的，泛化能力不行。因此，需要减掉一些枝叶，使得模型泛化能力更强。</p><p><strong>预剪枝</strong></p><p>通过提前停止树的构建而对树剪枝，一旦停止，节点就是叶子，该叶子持有子集中最频繁的类。</p><p>√ 定义一个<strong>高度</strong>，当决策树达到该高度时就停止生长<br>√ 达到某个<u>节点的实例具有相同的特征向量</u><br>√ 定义一个<strong>阈值</strong>(实例个数、系统性能増益等)</p><p><strong>后剪枝方法</strong>（常用）</p><p>首先<strong>构造完整的决策树</strong>，然后对那些置信度不够的结点子树用叶子结点来代替，该叶子的类标号用该结点子树中最频繁的类标记。相比于预剪枝，这种方法更常用，因为在预剪枝方法中精确地估计何时停止树增长很困难。</p><p>**理想的决策树有三种：**叶子节点数最少、叶子节点深度最小、叶子节点数最少且叶子节点深度最小。</p><img src="/medias/image-20200805191238305.png" style="zoom:80%;"><h5 id="3-4-2-贝叶斯分类">3.4.2 贝叶斯分类</h5><p>贝叶斯分类是基于贝叶斯定理和属性特征条件独立性的分类方法。</p><p>贝叶斯流派的核心：Probability theory is nothing but common sense reduced to calculation.<br>概率论只不过是把常识用数学公式表达了出来。——拉普拉斯</p><p>案例：假设春季感冒流行，你同桌打了一个喷嚏，那你同桌感冒了的概率是多少?</p><ol><li><p>计算先验概率：你同桌没有任何症状的情况下可能得感冒的概率是多少?</p></li><li><p>为每个属性计算条件概率：如果你同桌感冒了那么他会打喷嚏的概率是多少，如果他没感冒，出现打喷嚏症状的概率有多少?</p></li><li><p>计算后验概率：根据1和2求解最终问题，这才是拥叶斯思想的你该做的分析。</p></li></ol><p><img src="/medias/image-20200805200659941.png" alt=""></p><p>举个栗子：一对男女朋友，男生向女生求婚，男生的四个特点分别是不帅，性格不好，身高矮，不上进，请你判断一下女生是嫁还是不嫁?</p><p>① 估计先验概率P©</p><p>p(嫁) = 6/12(总样本数) = 1/2</p><p>② 为每个属性计算条件概率P(x~j~|c)</p><p>p(不帅嫁) = 3/6 = 1/2    p(性格不好嫁) = 1/6</p><p>p(不帅) = 5/12</p><p>③ 计算后验概率</p><p><img src="/medias/image-20200805201443208.png" alt=""></p><p>不嫁(1/3<code>*</code>1/2<code>*</code>1<code>*</code>2/3<code>*</code>1/2)  &gt; 嫁(1/2<code>*</code>1/6<code>*</code>1/6<code>*</code>1/6*1/2)</p><p><img src="/medias/image-20200805201824925.png" alt=""></p><p><strong>分析结果:不嫁!</strong></p><p>p(不师 | 不嫁) * p(性格不好 | 不嫁) * p(身高矮 | 不嫁) * p(不上进 | 不嫁) * p(不嫁)</p><p>p(不帅) * p(性格不好) * p(身高矮) * p(不上进)</p><p><strong>拉普拉斯修正</strong></p><p><img src="/medias/image-20200805202348518.png" alt=""></p><p><strong>优点：</strong><br>(1) 算法逻辑简单，易于实现<br>(2) 分类过程中时空开销小</p><p><strong>缺点：</strong><br>理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型<strong>假设属性之间相互独立</strong>，这个假设在<strong>实际应用中往往是不成立</strong>的，在<strong>属性个数比较多或者属性之间相关性较大</strong>时，分类效果不好。</p><h5 id="3-4-3-SVM分类">3.4.3 SVM分类</h5><p><img src="/medias/image-20200805202843087.png" alt=""></p><p>再之后，人们把这些球叫做  <strong>data</strong>，把棍子叫做 <strong>classifier</strong>，最大间隙 <strong>trick</strong> 叫做 <strong>optimization</strong>，拍桌子叫做 <strong>kernelling</strong>，那张纸叫做 <strong>hyperplane</strong>。</p><p><strong>支持向量机(Support Vector Machine， SVM)</strong> 是一种有监督学习方法，主要思想是建立一个最优决策超平面，使得该平面两侧距离该平面最近的两类样本之间的距离最大化，从而对分类问题提供良好的泛化能力。</p><p><img src="/medias/image-20200805203935893.png" alt=""></p><img src="/medias/image-20200805204039399.png" style="zoom:38%;"><p><strong>SVM的优点</strong><br>√ 相对于其他训练分类算法<strong>不需要过多样本</strong>，并且由于SWM引入了核函数，所以SVM可以处理高维样本。<br>√ <strong>结构风险最小</strong>。这种风险是指分类器对问题真实模型的逼近与问题真实解之间的累积误差。<br>√ <strong>非线性</strong>，是指SVM擅长应付样本数据线性不可分的情况，主要通过<strong>松弛变量(也叫惩罚变量) 和核函数技术</strong>来实现，这一部分也正是SVM的精髓所在。</p><p><strong>常用软件工具包</strong><br>LibSVM: <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">http://www.csie.ntu.edu.tw/~cjlin/libsvm/</a><br>SVM-Light: <a href="http://svmlight.joachims.org/">http://svmlight.joachims.org/</a><br>Liblinear: <a href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">http://www.csie.ntu.edu.tw/~cjlin/liblinear/</a></p><h5 id="3-4-4-逻辑回归">3.4.4 逻辑回归</h5><p><strong>logistic回归</strong>是一个分类算法，它可以处理二元分类以及多元分类。首先逻辑回归构造广义的线性回归函数，然后使用 sigmoid 函数 g(z) 将回归值映射到离散类别。<br>二项逻辑回归模型、多项逻辑回归模型</p><p><img src="/medias/image-20200805205315286.png" alt=""></p><p><strong>为什么要用 sigmoid函数?</strong><br>Sigmoid 曲线在中心附近增长速度较快，在两端增长速度较慢，取值在0-1 之间。</p><ol><li>它的输入范围是 (-∞， +∞)，而输出刚好为(0， 1)，正好满足概率分布为 (0， 1) 的要求。从贝叶斯的角度看，只要类条件概率服从指数分布，都可以推出后验概率为 sigmoid 函数形式。</li><li>他是一个单调上升的函数，具有良好的连续性，不存在不连续点。微分形式简单。</li></ol><p><strong>为什么要用对数似然损失函数?</strong></p><img src="/medias/image-20200805210237097.png" style="zoom: 40%;"><img src="/medias/image-20200805210335105.png" style="zoom:50%;"><h5 id="3-4-5-逻辑回归与最大熵模型">3.4.5 逻辑回归与最大熵模型</h5><p>熵是随机变量不确定性的度量，不确定性越大，熵值就越大。<br>德国物理学家鲁道夫·克劳修斯首次提出施的概念，用来表示任何种能量在空间中分布的均匀程度，能量分布得越均匀，熵就越大。</p><img src="/medias/image-20200808091721787.png" style="zoom:50%;"><blockquote><p>举个例子：你每次把耳机整理好，放入口袋中，下次再拿出来已经乱了让耳机线乱掉的看不见的“力”就是熵力，耳机线喜欢变成更混乱。</p></blockquote><p>数学上解决问题最漂亮的方法是最大熵模型。简单说就是保留全部的不确定性，将风险降到最小。</p><p>最大熵原理指出，对个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况<strong>不要做任何主观假设</strong>。（概率分布最均匀，预测的风险最小，不要把鸡蛋放在一个篮子里）</p><p><strong>逻辑回归是最大熵的特殊情况。</strong>（对数线性模型）</p><p><strong>最大熵模型特点</strong><br>√ 形式上看，它非常简单，非常优美。<br>√ 效果上看，唯一一种既能满足各个信息源的限制条件，又能保证平滑性的模型。<br>√ 计算量巨大，在工程上实现方法的好坏决定了模型的实用与否。</p><h5 id="3-4-6-集成学习">3.4.6 集成学习</h5><p><strong>集成学习</strong>通过将多个弱分类器集成在一起，使它们共同完成学习任务，构建一个强分类器。潜在哲<br>学思想是“<strong>三个臭皮匠赛过诸葛亮</strong>”。</p><img src="/medias/image-20200808094812114.png" style="zoom:67%;"><p>◆ <strong>理论基础</strong><br><strong>强可学习</strong>：在PAC学习框架中，一个概念，如果存在一个多项式的学习算法能够学习它，并且正确率<br>很高，那么久称这个概念是强可学习的。</p><p><strong>弱可学习</strong>：如果存在一个多项式的学习算法能够学习它，学习的正确率金币随机猜测略好，那么就称这个<br>概念是弱可学习的。</p><p><strong>Schapire</strong> 证明强可学习与弱可学习是<strong>等价</strong>的，也就是说，在PAC学习框架下，一个概念强可学习的充<br>分必要条件是这个概念弱可学习的。</p><p>◆ <strong>两类集成方法</strong></p><p><strong>Bagging(bootstrap aggregating)</strong></p><p><strong>Boosting(提升方法)</strong></p><p><strong>1) Bagging(bootstrap aggregating)</strong></p><img src="/medias/image-20200808095324837.png" style="zoom:67%;"><p>Bagging：基于数据<strong>随机重抽样</strong>的分类器构建方法。</p><ul><li>利用 bootstrap方法从整体数据集中采取有放回抽样得到 N 个数据集（如何采样?）。</li><li>在每个数据集上学习出一个模型（选择什么样的弱分类器?）。</li><li>利用N个模型的输出投票得到最后的预测结果。</li></ul><p><strong>2) Boosting</strong></p><img src="/medias/image-20200808095340194.png" style="zoom:67%;"><p>Boosting(Adaptive Boosting的简称)，基于错误提升分类器性能，通过<strong>集中关注被已有分类器分类错误的样本</strong>，构建新分类器。</p><ul><li><p>初始的分布应为等概分布。</p></li><li><p>每次循环后提高错误样本的分布概率，分错的样本在训练集中所占权重增大，使得下一次循环的基分类器能够集中力量对这些错误样本进行判断。</p></li></ul><p>严格意义上来说，这不算是一种机器学习算法，而更像是一种优化手段或者策略，它通常是结合多个简单的弱机器学习算法，去做更可靠的决策。类似于<strong>开会做决策</strong>。</p><blockquote><p><strong>Bagging与 Boosting</strong></p><p>都采用采样-学习-组合的方式，不同在于：<br>√ Bagging 中每个训练集互不相关，也就是每个基分类器互不相关，而 Boosting中训练集要在上一轮的结果上进行调整，也使得其不能并行计算。</p><p>√ Bagging 中预测函数是均匀平等的，但在 Boosting中预测函数是加权的。</p></blockquote><p><strong>代表算法：</strong></p><img src="/medias/image-20200808100517454.png" style="zoom:50%;"><p><strong>优点：</strong><br>当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多，在各大竞赛中得到了普遍应用。</p><p><strong>缺点：</strong><br>需要大量的维护工作。</p><h4 id="3-5-回归问题">3.5 回归问题</h4><h5 id="3-5-1-回归问题">3.5.1 回归问题</h5><p><strong>回归分析</strong>用于预测输入变量(自变量)和输出变量(因变量)之间的关系，特别是当输入变量的值发生变化时，输出变量值随之发生变化。直观来说回归问题等价于<strong>函数拟合</strong>，选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据。</p><img src="/medias/image-20200812183041745.png" style="zoom:50%;"><blockquote><p><strong>为什么叫回归?</strong>：达尔文表兄弟 Francis Galton发明的。Galton于1877年完成了第一次回归预测，目的是根据上一代豌豆种子(双亲)的尺寸来预测下一代豌豆种子(孩子)的尺寸。他注意到双亲高的，孩子也倾向于比平均高，但尚不及双亲，孩子的高度会向着平均身高回退(回归)。</p></blockquote><img src="/medias/image-20200812183142089.png" style="zoom:50%;"><h5 id="3-5-2-线性回归">3.5.2 线性回归</h5><p><strong>线性回归算法</strong>假设特征和结果满足线性关系。这就意味着可以将输入项分别乘以一些常量，再将结果加起来得到输出。</p><img src="/medias/image-20200812183533227.png"><h5 id="3-5-3-线性回归扩展">3.5.3 线性回归扩展</h5><p><strong>线性回归扩展算法</strong>用简单的基函数Φ(x)替换输入变量x。这样我们就把线性拟合形式扩展到了固定非线性函数的线性组合。</p><img src="/medias/image-20200812184417019.png" style="zoom:46%;"><h5 id="3-5-4-岭回归">3.5.4 岭回归</h5><p><strong>岭回归</strong>应用结构风险最小化的模型选择策略，在经验风险最小化的基础上加入正则化因子。当<strong>正则化因子</strong>选择为模型参数的<strong>二范数</strong>的时候，整个回归的方法就叫做岭回归。</p><img src="/medias/image-20200812184814045.png" style="zoom:44%;"><blockquote><p>λ越大，说明偏差就越大，原始数据对回归求取参数的作用就越小，当lamda取到个合适的值，就能在一定意义上解决过拟合的问题：原先过拟合的特别大或者特别小的参数会被约束到正常甚至很小的值，但不会为零。</p></blockquote><img src="/medias/image-20200812184848262.png" style="zoom:60%;"><h5 id="3-5-5-Lasso回归">3.5.5 Lasso回归</h5><p><strong>Lasso 回归</strong>是一种压缩估计。它通过构造一个惩罚函数得到一 个较为精炼的模型，使得它压缩一些系数，同时设定一些系数为零。因此保留了子集收缩的优点，是一种处理具有<strong>复共线性数据</strong>的<strong>有偏估计</strong>。</p><blockquote><p>Lasso 回归翻译成中文叫<strong>套索</strong>，就是拿这个东西把动物脖子套住，不要它随便跑。Lasso 回归差不多这个意思，就是让回归系数不要太大，以免造成过度拟合(overfitting) 。</p></blockquote><img src="/medias/image-20200812190035858.png" style="zoom:70%;"><h4 id="3-6-聚类问题">3.6 聚类问题</h4><h5 id="3-6-1-聚类问题">3.6.1 聚类问题</h5><p><strong>聚类问题</strong>是无监督学习的问题，算法的思想就是“物以类聚，人以群分”。聚类算法感知样本间的相似度，进行类别归纳，对新的输入进行输出预测，输出变量取有限个离散值。</p><img src="/medias/image-20200812191726911.png" style="zoom: 50%;"><p>√ 可以作为一个单独过程，用于寻找数据内在的分布结构。<br>√ 可以作为分类、稀疏表示等其他学习任务的前驱过程。</p><h5 id="3-6-2-K-means">3.6.2 K-means</h5><p>K- means(又称k-均值或k-平均)聚类算法。算法思想就是首先随机确定k个中心点作为聚类中心，然后把每个数据点分配给最邻近的中心点，分配完成后形成k个聚类，计算各个聚类的平均中心点，将其作为该聚类新的类中心点，然后重复迭代上述步骤直到分配过程不再产生变化。</p><p><strong>K- means算法流程</strong></p><blockquote><p>① 随机选择K个随机的点(称为聚类中心)。<br>② 对与数据集中的每个数据点，按照距离K个中心点的距离，将其与距离最近的中心点关联起来，与同一中心点关联的所有点聚成一类。<br>③ 计算每一组的均值，将该组所关联的中心点移动到平均值的位置。<br>④ 重复执行②-③ 步，直至中心点不再变化;</p></blockquote><p><strong>K-Means的主要优点</strong></p><blockquote><p>√ 原理比较简单，实现也是很容易，收敛速度快<br>√ 聚类效果较优<br>√ 算法的可解释度比较强<br>√ 主要需要调参的参数仅仅是簇数<strong>k</strong></p></blockquote><p><strong>K-Means的主要缺点</strong></p><blockquote><p>√ K值的选取不好把握<br>√ 不平衡数据集的聚类效果不佳<br>√ 采用迭代方法，得到的结果只是局部最优<br>√ 对噪音和异常点比较的敏感</p></blockquote><img src="/medias/image-20200812193529404.png" style="zoom: 70%;"><h5 id="3-6-3-高斯混合模型">3.6.3 高斯混合模型</h5><p><strong>高斯混合模型</strong>(Gaussian Mixed Model)指的是多个高斯分布函数的线性组合，是一种广泛使用的聚类算法，该方法使用了高斯分布作为参数模型。</p><p><strong>单高斯模型</strong>：高斯分布(Gaussian distribution)有时也被称为<strong>正态分布</strong>(normal distribution)，是一种在自然界大量的存在的、最为常见的分布形式。</p><img src="/medias/image-20200812194140068.png" style="zoom:56%;"><img src="/medias/image-20200812194234964.png" style="zoom:60%;"><p><strong>高斯混合模型</strong>：混合模型是一个可以用来表示在总体分布中含有K个子分布的概率模型，换句话说，混合模型表示了观测数据在总体中的概率分布，它是一个由K个子分布组成的混合分布。</p><img src="/medias/image-20200812194418740.png" style="zoom:56%;"><img src="/medias/image-20200812194350060.png" style="zoom:50%;"><h5 id="3-6-4-高斯混合模型求解">3.6.4 高斯混合模型求解</h5><p><strong>EM算法</strong>是一种迭代算法，1977年由 Dempster 等人总结提出，用于含有隐变量(Hidden variable)的概率模型参数的最大似然估计。</p><ul><li>基于高斯混合分布的<strong>聚类</strong></li></ul><img src="/medias/image-20200812195249767.png" style="zoom: 50%;"><img src="/medias/image-20200812195030116.png" style="zoom: 50%;"><h5 id="3-6-5-高斯混合模型与K-means">3.6.5 高斯混合模型与K- means</h5><img src="/medias/image-20200812195744585.png" style="zoom:50%;"><ul><li><p>混合高斯和K- means很相似，相似点在于两者的分类受初始值影响；两者可能限于局部最优解；两者类别的个数(k)都要靠猜测。混合高斯计算复杂度高于K-means。</p></li><li><p>K- means属于硬聚类，要么属于这类，要么属于那类，而GMM属于混合式软聚类，一个样本70%属于A，30%属于B。</p></li></ul><h5 id="3-6-6-密度聚类">3.6.6 密度聚类</h5><p><strong>密度聚类算法</strong>假设聚类结构能通过样本分布的紧密程度确定，算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果。</p><p><strong>DBSCAN算法流程</strong></p><blockquote><p>① DBSCAN通过检查数据集中每个点的Eps邻域来搜索簇，如果点p的Eps邻域包含的点多于MinPts个，则创建一个以p为核心对象的簇。<br>② 然后， DBSCAN迭代地聚集从这些核心对象直接密度可达的对象，这个过程可能涉及一些密度可达簇的合并。<br>③ 当没有新的点添加到任何簇时，该过程结束。</p></blockquote><img src="/medias/image-20200812200425530.png" style="zoom:50%;"><h5 id="3-6-7-层次聚类">3.6.7 层次聚类</h5><p><strong>层次聚类算法</strong>试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用“自底向上”的聚合策略，也可采用“自顶向下”的分拆策略。</p><p><strong>AGNES算法流程</strong></p><blockquote><p>① AGNES(Agglomerative NESting)算法最初将每个对象做为一个簇，然后这些簇根据某些准则被一步步的合并，使用单链接方法。<br>② 两个簇间的相似度由这两个不同簇中距离最近的数据点对的相似度来确定。此外当两个簇最近距离超过用户给定的阈值时聚类过程就会终止。<br>③ 聚类的合并过程反复进行直到所有的对象最终满足簇数据。</p></blockquote><img src="/medias/image-20200812200800237.png" style="zoom:50%;"><h5 id="3-6-8-谱聚类">3.6.8 谱聚类</h5><p>**谱聚类(Spectral Clustering，SC)**是一种基于图论的聚类方法，将带权无向图划分为两个或两个以上的最优子图，使子图内部尽量相似，而子图间距离尽量距离较远，以达到常见的聚类的目的。</p><p>输入：样本x，j，需要聚类的个数k</p><blockquote><ul><li>构建相似度矩阵 S，样本间 x_i 已经通过高斯相似度构建出了相似度矩阵 S，也就是邻接矩阵 W。</li><li>计算出度矩阵 D</li><li>计算出拉普拉斯矩阵 L = D - W</li><li>计算出 L 前 k 个最小的特征向量 v_1，…，v_k</li><li>将前 k 个特征向量组合成一个矩阵 V，其中第 i 列对应 v_i 列向量</li><li>该矩阵 V 的每一行对应代表 x_j 的低维度的表示 y_i</li><li>对所有 y_i 进行 k- means 聚类，聚成 k 类</li></ul></blockquote><p><strong>谱聚类的优势</strong></p><blockquote><p>√ 只需要待聚类点之间的相似度矩阵就可以做聚类了。<br>√ 对于不规则的数据(或者说是离群点)不是那么敏感，个人感觉主要体现在最小化图切割的公式中。<br>√ k- means聚类算法比较适合于凸数据集(数据集内的任意两点之间的连线都在该数据集以内，简单理解就是圆形)，而谱聚类则比较通用。</p></blockquote><p><strong>谱聚类能够识别任意形状的样本空间且收敛于全局最优解，其基本思想是利用样本数据的相似矩阵(拉普拉斯矩阵)进行特征分解后得到的特征向量进行聚类。</strong></p><h4 id="3-7-其他问题">3.7 其他问题</h4><h5 id="3-7-1-隐马尔可夫模型">3.7.1 隐马尔可夫模型</h5><p><strong>隐马尔可夫模型</strong>是一个关于时序的概率模型，描述由隐马尔可夫链随机生成观测序列的过程，属于生成模型。隐马尔可夫模型在语音识别、自然语言处理、生物信息等领域有着广泛的应用。</p><blockquote><p><strong>隐马可夫模型两个假设</strong><br>① <strong>齐次马尔可夫性假设</strong>，即假设隐藏的马尔可夫链在任意时刻 t 的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻 t 无关。<br>P(i~t~|i~t-1~，o~t-1~，…，i~1~，o~1~)=P(i~t~li~t-1~)，t=1，2，…，T<br>② <strong>观测独立性假设</strong>，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关。<br>P(o~t~|i~t~，o~t~，…，i~1~，o~1~)=P(o~t~li~t~)，t=1，2，…，T</p></blockquote><img src="/medias/image-20200812202006591.png" style="zoom:60%;"><p>隐马尔可夫模型 <strong>λ = (A， B， Π)</strong>，状态转移概率矩阵 A，初始状态概率向量Π，确定了隐藏的马尔可夫链，生成不可观测的状态序列。观测概率矩阵 B 确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。</p><p><strong>隐马可夫模型三个基本问题</strong></p><blockquote><p>① <strong>概率计算问题</strong>，给定模型 λ=(A，B，Π)和观测序列 O=(o~1~， o~2~， …，o~T~)，计算在模型 λ 下观测序列 O 出现的概率 P = (O|λ)。<br>② <strong>学习问题</strong>，已知观测序列 O=(o~1~， o~2~， …， o~T~) 估计模型 λ=(A， B， Π)参数，使得在该模型下观测序列概率 P = (O|λ)最大。<br>③ <strong>预测问题</strong>，已知模型 λ=(A，B，∏) 和观测O=(o~1~， o~2~， …， o~T~) ，求对给定观测序列条件概率P=(I|O)最大的状态序列。即给定观测序列，求最有可能的对应的状态序列。</p></blockquote><img src="/medias/image-20200812203756955.png" style="float:left;zoom:50%;"><p><br><br><br><br><br><br></p><p><strong>应用</strong></p><p><strong>词性标注、中文分词、天气预测等</strong></p><h5 id="3-7-2-CRF-条件随机场">3.7.2 CRF 条件随机场</h5><p>CRF(Conditional Random Field)条件随机场是一个序列标注模型，其优点在于为一个位置进行标注的过程中可以利用丰富的内部及上下文特征信息。</p><img src="/medias/image-20200812204649234.png" style="zoom:50%;"><p>CRF由 John Lafferty 最早在 NLP 技术领域任务中进行文本标注，有多种应用场景，如：</p><blockquote><p>√ 分词(标注字的词位信息，由字构词)<br>√ 词性标注(标注分词的词性，例如：名词，动词，助词)<br>√ 命名实体识别(识别人名，地名，机构名，商品名等具有一定内在规律的实体名词)</p></blockquote><h5 id="3-7-3-LDA-主题模型">3.7.3 LDA 主题模型</h5><p><strong>LDA 主题模型</strong>是一种文档主题生成模型，是一种非监督机器学习技术。通过模拟文档生成过程，可以用来识别大规模文档集 (document collection) 或语料库 (corpus) 中潜藏的主题信息。</p><img src="/medias/image-20200812205037681.png" style="zoom:50%;"><h5 id="3-7-4-生成模型-VS-判别模型">3.7.4 生成模型 VS 判别模型</h5><p><strong>监督学习方法</strong>可分为两大类，即生成方法与判别方法，它们所学到的模型称为生成模型与判别模型。</p><p>例子：</p><blockquote><p>例如你需要识别一种语言到底是汉语还是英语等。那么你可以有两种方法达到这个目的：<br>1、学习两种语言，你花了大量精力把汉语、英语都学会了，然后你就知道是哪种语言了。<br>2、不去学习每一种语言，你只学习汉语与英语之间的差别，然后再分类。</p></blockquote><p><strong>生成方法的特点</strong></p><blockquote><ul><li>从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。</li><li>生成方法还原出联合概率分布，而判别方法不能。</li><li>生成方法的学习收敛速度更快、即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型。</li><li>当存在隐变量时，仍然可以用生成方法学习，此时判别方法不能用。</li></ul></blockquote><p><strong>判别方法的特点</strong></p><blockquote><ul><li>判别方法寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。</li><li>判别方法利用了训练数据的类别标识信息，直接学习的是条件概率P(Y|X)或者决策函数f(X)，直接面对预测，往往学习的准确率更高。</li><li>由于直接学习条件概率P(Y|X)或者决策函数f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。</li><li>缺点是不能反映训练数据本身的特性。</li></ul></blockquote><h4 id="3-8-结果评估">3.8 结果评估</h4><p>拟合度量、查准率、查全率、F1值、PR曲线、ROC曲线</p><h5 id="3-8-1-模型选择">3.8.1 模型选择</h5><img src="/medias/image-20200812210226020.png" style="zoom:50%;"><p><strong>泛化误差</strong>：在“未来”样本上的误差。</p><p><strong>经验误差</strong>：在训练集上的误差。</p><img src="/medias/image-20200812210440702.png" style="zoom:50%;"><h5 id="3-8-2-性能评价指标——分类">3.8.2 性能评价指标——分类</h5><p><strong>准确率(Accuracy)</strong> 是指在分类中，分类正确的记录个数占总记录个数的比。<br><img src="/medias/image-20200812210758979.png" style="float:left;zoom: 36%;"></p><p><br><br></p><p><strong>召回率(Recall)</strong> 也叫查全率，是指在分类中样本中的正例有多少被预测正确了。<br>通常，准确率高时，召回率偏低；召回率高时，准确率偏低。</p><ol><li><strong>地震的预测</strong><br>对于地震的预测，我们希望的是召回率非常高，也就是说每次地震我们都希望预测出来。这个时候我们可以牺牲准确率。情愿发岀1000次警报，把10次地震都预测正确了；也不要预测100次对了8次漏了两次。</li><li><strong>嫌疑人定罪</strong><br>基于不错怪—个好人的原则，对于嫌疑人的定罪我们希望是非常准确的。及时有时候放过了一些罪犯(召回率低)，但也是值得的。</li></ol><img src="/medias/image-20200812211907811.png" style="zoom:50%;"><p><strong>准确率(Accuracy)</strong>：分类正确的样本个数占所有样本个数的比例</p><img src="/medias/image-20200812211532465.png" style="float:left;zoom: 33%;"><p><br><br></p><p><strong>平均准确率(Average per- class accuracy)</strong>：每个类别下的准确率的算术平均<br><img src="/medias/image-20200812211618026.png" style="float:left;zoom:33%;"></p><p><br><br></p><p><strong>精确率(Precision)</strong>：分类正确的正样本个数占分类器所有的正样本个数的比例<br><img src="/medias/image-20200812211655808.png" style="float:left;zoom:33%;"></p><p><br><br></p><p><strong>召回率(Recall)</strong>：分类正确的正样本个数占正样本个数的比例<br><img src="/medias/image-20200812211738354.png" style="float:left;zoom:33%;"></p><p><br><br></p><p><strong>F1- Score</strong>：精确率与召回率的调和平均值，它的值更接近于 Precision 与 Recall 中较小的值</p><img src="/medias/image-20200812211802440.png" style="float:left;zoom:33%;"><p><br><br></p><p><strong>AUC(Area under the Curve(Receiver Operating Characteristic， ROC))</strong><br><strong>ROC</strong>：纵轴：真正例率 TPR；横轴：假正例率 FPR<br><strong>AUC</strong> 是 ROC 曲线下的面积。一般来说，如果ROC是光滑的，那么基本可以判断没有太大的 overfitting，这个时候调模型可以只看 AUC，面积越大一般认为模型越好。</p><p><br><br></p><img src="/medias/image-20200812212012072.png" style="zoom:50%;"><p><br><br></p><p><strong>PR曲线</strong>：根据学习器的预测结果按正例可能性大小对样例进行排序，并逐个把样本作为正例进行预测。</p><p>√ 如果一个学习器的<strong>PR曲线</strong>包住了另一个，则可以认为A的性能优于C<br>√ 如果有交叉，如A、B，综合考虑 PR 性能引入<strong>平衡点(BEP)</strong>，基于BEP比较，A优于B</p><p><br><br></p><img src="/medias/image-20200812212505976.png" style="zoom:50%;"><p><br><br></p><img src="/medias/image-20200812212606762.png" style="zoom:40%;"><p><br><br></p><p><strong>宏平均&amp;微平均</strong><br>多分类问题中，若能得到<strong>多个混淆矩阵</strong>，例如多次训练测试的结果，多分类的两两混淆短。</p><img src="/medias/image-20200812213023222.png" style="float:left;zoom:50%;"><p><br><br></p><p><strong>对数损失</strong>(Log loss) 亦被称为逻辑回归损失(Logistic regression loss)或交叉熵损失(Cross-entropy loss)。</p><p><strong>二分类问题</strong>：y∈{0，1} 且P=Pr(y=1) 则对每个样本的对数损失为<br>L~log~ (y， p) = -logPr(ylp) = -(ylog(p)+(1-y)log(1-p))</p><p><strong>多分类问题</strong>：设 Y 为指示矩阵，即当样本的分类为 k，y~i，k~=1 设 P 为估计的概率矩阵，p~i，k~=Pr(t~i，k~=1)则对每个样本的对数损失为</p><img src="/medias/image-20200812224339654.png" style="zoom:33%;"><p><br><br></p><h5 id="3-8-3-性能评价指标——回归">3.8.3 性能评价指标——回归</h5><p><strong>平均绝对误差</strong>：平均绝对误差MAE(Mean Absolute Error)又被称为l1范数损失(l1- norm loss)<br><img src="/medias/image-20200812224619460.png" style="float:left;zoom: 33%;"></p><p><br><br></p><p><strong>平均平方误差</strong>：平均平方误差MSE( Mean Squared Error)又被称为l2范数损失(l2-norm loss)<br><img src="/medias/image-20200812224719766.png" style="float:left;zoom:33%;"></p><p><br><br></p><p><strong>均方根差RMSE</strong>：<br><strong>R Squared</strong>：是将预测值跟只使用均值的情况下相比，看能好多少。<br><img src="/medias/image-20200812224749117.png" style="float:left;zoom:33%;"></p><p><br><br></p><h5 id="3-8-4-性能评价指标——聚类">3.8.4 性能评价指标——聚类</h5><p>外部指标对数据集D={x~1~，x~2~，…x~n~}，假定通过聚类给出的簇划分为C={C~1~，C~2~，…，C~k~}，参考模型给出的簇划分为 C^<em>^={C~1~^</em>^，C~2~^<em>^，…，C~k~^</em>^)通过比对 C 和 C^*^ 来判定聚类结果的好坏。<br>Jaccard系数，FM指数，Rand指数，纯度 purity，熵entropy，互信息，<br>Adjusted Rand Index(ARI)， F-measure， Probabilistic Rand Index(PRI)。</p><p><strong>内部指标</strong>对聚类数据结构上的描述，类內距离小，类间距离大较好。</p><p><strong>DB指数( Davies-Bouldin Index，简称DBI)</strong>：衡量同一簇中数据的紧密性，越小越好。<br><strong>Dunn指数( Dunn Index简称DI)</strong>：衡量同一簇中数据的紧密性，越大越好。<br><strong>Silouette</strong>：衡量同一簇中数据的紧密性，越大越好。<br><strong>Modurity</strong>：衡量模块性，越大越好。</p><h3 id="4、课程实践">4、课程实践</h3><p>实践：鸢尾花分类</p><img src="C:\Users\hsiehchou\AppData\Roaming\Typora\typora-user-images\image-20200815092332525.png" style="zoom:50%;"><p>当数据集在原始特征中不是线性可分的时候，支持向量机采用了引入映射函数Φ(·)的策略：通过映射函数将特征空间映射为更高维的空间，在原始空间中不可分的数据在高维空间中可能变成线性可分，此时再在空间再运用SVM，因此我们就需要使用核函数。</p><p>包含150个数据，分为3类，每类50个数据，每个数据包含5个属性。0：Sepal.Length（花萼长度）；1: Sepal.Width（花萼宽度）；2：Petal.Length（花瓣长度）；3：Petal.Width（花瓣宽度）；4： 种类：Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），以及Iris<br>Virginica（维吉尼亚鸢尾）</p><pre><code class="highlight python"><span class="comment"># ！pip install matplotlib</span><span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="keyword">from</span> matplotlib <span class="keyword">import</span> colors<span class="keyword">from</span> sklearn <span class="keyword">import</span> svm<span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC<span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt<span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl<span class="comment"># *********将字符串转为整型*********</span><span class="keyword">def</span> <span class="title function_">iris_type</span>(<span class="params">s</span>):    it = {<span class="string">b'Iris-setosa'</span>:<span class="number">0</span>, <span class="string">b'Iris-versicolor'</span>:<span class="number">1</span>, <span class="string">b'Iris-virginica'</span>:<span class="number">2</span>}    <span class="keyword">return</span> it[s]<span class="keyword">def</span> <span class="title function_">show_accuracy</span>(<span class="params">a, b, tip</span>):    acc = a.ravel() == b.ravel()    <span class="built_in">print</span>(<span class="string">'%s Accuracy: %.3f'</span> %(tip, np.mean(acc)))    <span class="keyword">def</span> <span class="title function_">print_accuracy</span>(<span class="params">clf, x_train, y_train, x_test, y_test</span>):    <span class="comment"># 分别打印训练集和测试集的准确率 score(x_train, y_train):表示输出x_train, y_train在模型上的准确率</span>    <span class="built_in">print</span>(<span class="string">'training prediction: %.3f'</span> %(clf.score(x_train, y_train)))    <span class="built_in">print</span>(<span class="string">'test data prediction: %.3f'</span> %(clf.score(x_test, y_test)))    <span class="comment"># 原始结果与预测结果进行对比 predict()表示对x_train样本进行预测，返回样本类别</span>    show_accuracy(clf.predict(x_train), y_train, <span class="string">'traing data'</span>)    show_accuracy(clf.predict(x_test), y_test, <span class="string">'testing data'</span>)    <span class="comment"># 计算决策函数的值，表示x到各分割平面的距离</span>    <span class="built_in">print</span>(<span class="string">'decision_function:\n'</span>, clf.decision_function(x_train))    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">clf, x</span>):    iris_feature = <span class="string">'sepal length'</span>, <span class="string">'sepal width'</span>, <span class="string">'petal length'</span>, <span class="string">'petal width'</span>    <span class="comment"># 开始画图</span>    x1_min, x1_max = x[:, <span class="number">0</span>].<span class="built_in">min</span>(), x[:, <span class="number">0</span>].<span class="built_in">max</span>()               <span class="comment"># 第0列的范围</span>    x2_min, x2_max = x[:, <span class="number">1</span>].<span class="built_in">min</span>(), x[:, <span class="number">0</span>].<span class="built_in">max</span>()               <span class="comment"># 第1列的范围</span>    x1, x2 = np.mgrid[x1_min:x1_max:<span class="number">200j</span>, x2_min:x2_max:<span class="number">200j</span>]   <span class="comment"># 生成网格采样点</span>    grid_test = np.stack((x1.flat, x2.flat), axis=<span class="number">1</span>)            <span class="comment"># 测试点</span>    <span class="built_in">print</span>(<span class="string">'grid_test:\n'</span>, grid_test)    <span class="comment"># 输出样本到决策面的距离</span>    z = clf.decision_function(grid_test)    <span class="built_in">print</span>(<span class="string">'the distance to decision plane:\n'</span>, z)        grid_hat = clf.predict(grid_test)       <span class="comment"># 预测分类得到[0,0,...,2,2,2]</span>    <span class="built_in">print</span>(<span class="string">'grid_hat:\n'</span>, grid_hat)    grid_hat = grid_hat.reshape(x1.shape)   <span class="comment"># reshape grid_hat和x1形状一致</span>                                            <span class="comment"># 若3*3矩阵e,则e.shape()为3*3，表示3行3列</span>    cm_light = mpl.colors.ListedColormap([<span class="string">'#A0FFA0'</span>, <span class="string">'#FFA0A0'</span>, <span class="string">'#A0A0FF'</span>])    cm_dark = mpl.colors.ListedColormap([<span class="string">'g'</span>, <span class="string">'b'</span>, <span class="string">'r'</span>])    plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light)  <span class="comment"># pcolormesh(x, y, z, cmap)这里参数代入</span>                                                     <span class="comment"># x1, x2， grid_hat, cmap=cm_light绘制的是背景</span>    plt.scatter(x[:, <span class="number">0</span>],x[:, <span class="number">1</span>],c=np.squeeze(y), edgecolor=<span class="string">'k'</span>, s=<span class="number">50</span>, cmap=cm_dark) <span class="comment"># 样本点</span>    plt.scatter(x_test[:, <span class="number">0</span>], x_test[:, <span class="number">1</span>], s=<span class="number">120</span>, facecolor=<span class="string">'none'</span>, zorder=<span class="number">10</span>)     <span class="comment"># 测试点</span>    plt.xlabel(iris_feature[<span class="number">0</span>], fontsize=<span class="number">20</span>)    plt.ylabel(iris_feature[<span class="number">1</span>], fontsize=<span class="number">20</span>)    plt.xlim(x1_min, x1_max)    plt.ylim(x2_min, x2_max)    plt.title(<span class="string">'svm in iris data classification'</span>, fontsize=<span class="number">30</span>)    plt.grid()    plt.show()    <span class="keyword">def</span> <span class="title function_">classifier</span>():    clf = svm.SVC(C=<span class="number">0.5</span>,                            <span class="comment"># 误差项惩罚系数</span>                  kernel=<span class="string">'linear'</span>,                  <span class="comment"># 线性核 kernel="rbf":高斯核</span>                  decision_function_shape=<span class="string">'ovr'</span> )     <span class="comment"># 决策函数</span>    <span class="keyword">return</span> clf<span class="comment"># ******************训练模型*******************</span><span class="keyword">def</span>  <span class="title function_">train</span>(<span class="params">clf, x_train, y_train</span>):    clf.fit(x_train,          <span class="comment"># 训练集特征向量</span>            y_train.ravel())  <span class="comment"># 训练集目标值</span><span class="comment"># 1.数据准备</span><span class="comment"># 1.1 加载数据</span>data = np.loadtxt(<span class="string">'C:/Users/hsiehchou/Desktop/iris.data'</span>, <span class="comment"># 数据文件路径</span>                  dtype=<span class="built_in">float</span>,                            <span class="comment"># 数据类型</span>                  delimiter=<span class="string">','</span>,                          <span class="comment"># 数据分隔符</span>                  converters={<span class="number">4</span>:iris_type})               <span class="comment"># 将第5列使用函数iris_type进行转换</span><span class="comment"># 1.2 数据分割</span>x, y = np.split(data,       <span class="comment"># 数组数据</span>                (<span class="number">4</span>,),       <span class="comment"># 第5列开始往后为y</span>                axis=<span class="number">1</span>)     <span class="comment"># 代表纵向分割，按列分割</span>x = x[:, :<span class="number">2</span>]x_train, x_test, y_train, y_test=model_selection.train_test_split(x, <span class="comment"># 被划分的样本特征集</span>                                                                  y, <span class="comment"># 被划分的样本标签</span>                                                                  random_state=<span class="number">1</span>, <span class="comment"># 随机数种子</span>                                                                  test_size=<span class="number">0.3</span>) <span class="comment"># 测试样本占比</span><span class="comment"># print(x_train)</span><span class="comment"># print(y_train)</span><span class="comment"># 2.定义模型：SVM模型定义</span>clf=classifier()<span class="comment"># 3.训练模型</span>train(clf, x_train, y_train)<span class="comment"># 4.模型评估 </span>print_accuracy(clf, x_train, y_train, x_test, y_test)<span class="comment"># 5.模型使用</span>draw(clf, x)</code></pre><p>输出：</p><p>training prediction: 0.819<br>test data prediction: 0.778<br>traing data Accuracy: 0.819<br>testing data Accuracy: 0.778<br>decision_function:<br>[[-0.30200388  1.26702365  2.28292526]<br>[ 2.1831931  -0.19913458  1.06956422]<br>[ 2.25424706  0.79489006 -0.20587224]<br>[ 2.22927055  0.98556708 -0.22777916]<br>[ 0.95815482  2.18401419 -0.17375192]<br>[ 2.23120771  0.84075865 -0.19144453]<br>[ 2.17327158 -0.14884286  0.92795057]<br>[-0.28667175  1.11372202  2.28302495]<br>[-0.27989264  1.21274017  2.25881762]<br>[-0.29313813  1.24442795  2.2732035 ]<br>[-0.27008816  1.2272086   2.22682127]<br>[-0.25981661  2.21998499  1.20479842]<br>[-0.17071168  0.99542159  2.17180911]<br>[-0.30018876  1.25829325  2.2829419 ]<br>[-0.17539342  2.15368837  1.06772814]<br>[ 2.25702986  0.81715893 -0.22763295]<br>[-0.23988847  2.23286001  1.06656755]<br>[-0.26915223  2.23333222  1.21679709]<br>[ 2.22927055  0.98556708 -0.22777916]<br>[ 2.2530903   0.85932358 -0.2359772 ]<br>[-0.26740532  1.20784059  2.23528903]<br>[ 2.26803658  0.80468578 -0.24299359]<br>[-0.24030826  1.18556963  2.19011259]<br>[-0.25881807  1.17240759  2.23535197]<br>[-0.27273902  1.20332527  2.24866913]<br>[-0.20956348  2.19674141  1.06726512]<br>[-0.26556065  1.16490628  2.24871607]<br>[-0.22965507  1.17870942  2.17146651]<br>[ 2.25807657 -0.22526231  0.80881977]<br>[-0.27322701  2.25917947  1.17077691]<br>[-0.26638767  1.21631409  2.22685842]<br>[-0.26740532  1.20784059  2.23528903]<br>[-0.12135744  2.22922779  0.79343961]<br>[-0.2365929   1.12219635  2.21706342]<br>[-0.21558048  2.22640865  0.92573306]<br>[ 2.22344499 -0.19955645  0.88288227]<br>[ 2.22671228  0.93600592 -0.21794279]<br>[ 2.26578978 -0.24701281  0.82742467]<br>[-0.26556065  1.16490628  2.24871607]<br>[ 2.26204658  0.89725133 -0.25453765]<br>[-0.2518152   2.22343258  1.17120859]<br>[-0.27340098  1.23624732  2.22678409]<br>[-0.21624631  2.17118121  1.14723861]<br>[ 2.22874494 -0.17513313  0.8269183 ]<br>[ 2.2211989   0.87213971 -0.19151045]<br>[-0.23391072  2.21566697  1.11400955]<br>[ 2.22671228  0.93600592 -0.21794279]<br>[-0.29609931  1.25285329  2.27596663]<br>[-0.25476857  1.20746943  2.20485252]<br>[-0.29672783  1.24461331  2.28083131]<br>[-0.27578664  1.21663499  2.24864564]<br>[-0.28091389  2.25930846  1.21661886]<br>[-0.21369288  1.05233452  2.20512234]<br>[-0.27669555  1.12529292  2.27023906]<br>[-0.16942442  2.17056098  0.99533295]<br>[ 2.24933086 -0.25468768  1.0709247 ]<br>[-0.23391072  2.21566697  1.11400955]<br>[ 2.18638944  1.20994285 -0.24936796]<br>[-0.22656825  2.23557826  0.92551338]<br>[-0.27989264  1.21274017  2.25881762]<br>[ 2.24156015  0.83211053 -0.20597859]<br>[-0.28390119  1.23920595  2.25400509]<br>[ 2.24837463  0.81114157 -0.20592544]<br>[ 2.25702986  0.81715893 -0.22763295]<br>[-0.22765797  1.07419821  2.21710769]<br>[-0.18996302  2.19089984  0.99497945]<br>[-0.27357394  1.19278157  2.25408746]<br>[ 2.23355717  0.86019975 -0.2060317 ]<br>[ 2.25277813 -0.21394322  0.80875361]<br>[-0.18611572  1.10670475  2.14746524]<br>[ 2.25454797  0.88341904 -0.24307373]<br>[-0.23391072  2.21566697  1.11400955]<br>[ 2.23794605  0.91585392 -0.22774264]<br>[-0.26740532  1.20784059  2.23528903]<br>[ 2.0914977   1.20089769 -0.21820392]<br>[ 2.25962348  0.84878847 -0.24304703]<br>[-0.25213485  1.16423702  2.22696973]<br>[ 2.26725005  0.88232062 -0.25923379]<br>[-0.14201734  2.14344591  0.99568721]<br>[ 2.25731     0.95572321 -0.25455798]<br>[-0.22656825  2.23557826  0.92551338]<br>[-0.19708433  2.25161696  0.79328185]<br>[ 2.23957622  0.81769302 -0.19137855]<br>[ 2.21575566  1.0173258  -0.21798639]<br>[ 1.02668315  2.21468275 -0.21824732]<br>[ 2.27472592  0.77777882 -0.24294008]<br>[-0.21624631  2.17118121  1.14723861]<br>[-0.24730284  1.20252603  2.19004536]<br>[ 2.24156015  0.83211053 -0.20597859]<br>[-0.27273902  1.20332527  2.24866913]<br>[-0.19455078  2.17814555  1.06749683]<br>[-0.28027257  2.2623408   1.20447285]<br>[-0.28054312  1.20372124  2.26304729]<br>[-0.23391072  2.21566697  1.11400955]<br>[ 2.17896853 -0.12686338  0.8824238 ]<br>[ 2.19820639  1.04471124 -0.20619077]<br>[-0.26313706  2.23602532  1.18984329]<br>[-0.25331913  2.21599142  1.18997806]<br>[-0.28966527  1.23403227  2.27016072]<br>[-0.23157808  2.22314802  1.06680048]<br>[-0.26533811  1.22371567  2.21684157]<br>[-0.25751543  1.18608093  2.22693265]<br>[-0.27562627  2.24825903  1.21670804]<br>[-0.27273902  1.20332527  2.24866913]<br>[ 2.22671228  0.93600592 -0.21794279]]<br>grid_test:<br>[[4.3        2.        ]<br>[4.3        2.02964824]<br>[4.3        2.05929648]<br>…<br>[7.9        7.84070352]<br>[7.9        7.87035176]<br>[7.9        7.9       ]]<br>the distance to decision plane:<br>[[ 2.17689921  1.23467171 -0.25941323]<br>[ 2.18299337  1.23207323 -0.25940793]<br>[ 2.18863052  1.22933417 -0.25940262]<br>…<br>[ 2.2767579  -0.3057805   1.28707644]<br>[ 2.27757531 -0.30597655  1.28707851]<br>[ 2.27836945 -0.30616983  1.28708059]]<br>grid_hat:<br>[0. 0. 0. … 0. 0. 0.]</p><p><img src="/medias/202008150958123.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MATLAB 学习</title>
      <link href="/2020/06/19/matlab_xue_xi/"/>
      <url>/2020/06/19/matlab_xue_xi/</url>
      
        <content type="html"><![CDATA[<h3 id="第一章-MATLAB-介绍">第一章 MATLAB 介绍</h3><p>MATLAB(矩阵实验室的简称）是一种专业的计算机程序，用于工程科学的矩阵数学运算。但在以后的几年内，它逐渐发展为一种极其灵活的计算体系，用于解决各种重要的技术问题。</p><h4 id="1-1-MATLAB-的优点">1.1 MATLAB 的优点</h4><ol><li>易用性</li><li>平台独立性</li><li>预定义函数</li><li>机制独立的画图</li><li>用户图形界面</li><li>MATLAB 编译器</li></ol><h4 id="1-2-MATLAB-的缺点">1.2 MATLAB 的缺点</h4><ol><li>它是解释型语言，其执行速度要比编译型语言慢得多。</li><li>他的费用较高。</li></ol><h4 id="1-3-MATLAB-的开发环境">1.3 MATLAB 的开发环境</h4><h5 id="1-3-1-MATLAB-桌面">1.3.1 MATLAB 桌面</h5><p>在 MATLAB 桌面上可以得到和访问的窗口主要有：</p><ol><li>命令窗口（The Command Window）</li><li>命令历史窗口（The Command History Window）</li><li>启动平台（Launch Pad）</li><li>编辑调试窗口（The Edit/Debug Window）</li><li>工作台窗口和数组编辑器（Workspace Browser and Array Editor）</li><li>帮助空间窗口（Help Browser）</li><li>当前路径窗口（Current Directory Browser）</li></ol><h5 id="1-3-2-命令窗口-（The-Command-Window）">1.3.2 命令窗口 （The Command Window）</h5><pre><code class="highlight matlab">&gt;&gt; area=<span class="built_in">pi</span>*<span class="number">2.5</span>^<span class="number">2</span>area =   <span class="number">19.6350</span></code></pre><p><strong>下面两个等价</strong></p><pre><code class="highlight matlab">&gt;&gt; x1=<span class="number">1</span>+<span class="number">1</span>/<span class="number">2</span>+<span class="number">1</span>/<span class="number">3</span>+<span class="number">1</span>/<span class="number">4</span>+<span class="number">1</span>/<span class="number">5</span>+<span class="number">1</span>/<span class="number">6</span>;等价&gt;&gt; x1=<span class="number">1</span>+<span class="number">1</span>/<span class="number">2</span>+<span class="number">1</span>/<span class="number">3</span>+<span class="number">1</span>/<span class="number">4</span> ...+<span class="number">1</span>/<span class="number">5</span>+<span class="number">1</span>/<span class="number">6</span>;</code></pre><h5 id="1-3-3-历史命令窗口（The-History-Command-Window）">1.3.3 历史命令窗口（The History Command Window）</h5><p>历史命令窗口（The History CommandWindow）用于记录用户在命令窗口(The Command Windows）。</p><h5 id="1-3-4-启动平台（the-launch-pad）">1.3.4 启动平台（the launch pad）</h5><p>启动平台是一个特殊的工具，为 MATLAB 和其工具箱提供帮助、demos、其他相关文件和应用程序等参考资料。</p><h5 id="1-3-5-编辑调试器">1.3.5 编辑调试器</h5><p><strong>新建calc_area.m</strong></p><pre><code class="highlight matlab">radius=<span class="number">2.5</span>;area=<span class="built_in">pi</span>*<span class="number">2.5</span>^<span class="number">2</span>;string=[<span class="string">'the area of the circle is '</span>, num2str(area)];<span class="built_in">disp</span>(string);</code></pre><p><strong>在matlab中打开此文件，然后执行</strong></p><h5 id="1-3-6-图像窗口（Figure-Windows）">1.3.6 图像窗口（Figure Windows）</h5><pre><code class="highlight matlab">&gt;&gt; x=<span class="number">0</span>:<span class="number">0.1</span>:<span class="number">6</span>;&gt;&gt; y=<span class="built_in">sin</span>(x);&gt;&gt; <span class="built_in">plot</span>(x,y);</code></pre><p><strong>运行图：</strong><br><img src="/medias/1590581490263.png" alt="图像窗口"></p><h5 id="1-3-7-MATLAB-工作区">1.3.7 MATLAB 工作区</h5><p>像 z=10 这样的语句创建了一个变量 z，把 10 存储在其内，它保存在计算机的一段内存中，就是我们所常说的工作区。</p><p>当一个专门的命令，M 文件或函数运行时，工作区是 MATLAB所需要的所有变量和数组的集合。所有在命令窗口(The Command Windows）中执行的命令， 和所有在命令窗口(The Command Windows）执行的脚本文件(Script files）都会被分配一个普通的分配空间，所以它们能共享变量。MATLAB 函数的拥有独立的工作区，这是函数区别于脚本文件(Script files）的一个重要特征。</p><p>用 whos 命令将会产生一个在当前工作区内的所有变量和数组状况表。</p><h5 id="1-3-8-工作区浏览器">1.3.8 工作区浏览器</h5><p>当前工作区的内容也可以通过基于 GUI 的工作空间窗口检测到。工作空间窗口默认出现在 MATLAB 桌面的左上角，它提供了和 whos 命令可得到的相同的信息，并当工作区内的内容发生改变时，其内的信息也会随之更新。工作空间窗口（The workspace browser） 允许用户改变工作区内的任何一个变量的内容。</p><h5 id="1-3-9-MATLAB-帮助">1.3.9 MATLAB 帮助</h5><p>helpdesk 和 helpwin<br><img src="/medias/1590593768523.png" alt="helpdesk 和 helpwin"></p><p>lookfor acos<br><img src="/medias/1590593924920.png" alt="lookfor acos"></p><h5 id="1-3-10-一些重要的命令">1.3.10 一些重要的命令</h5><p><strong>clc</strong>——命令清空命令窗口(The Command Windows)中的内容<br><strong>clf</strong>——清空当前图像窗口中的内容<br><strong>clear</strong>——清除在工作空间窗口(The workspace brower)中变量</p><p>另一个重要的命令是 abort 命令。如果一个M文件运行时间过长，里面可能含有无限循环，而没有结束。在这种情况下，可在命令窗口内输入 control-c（简写为^c）。输入这个命令方法是光标在命令窗口内，按住控制键然后按 c。当 MATLAB 删除了 ^c，说明这个程序已经停止并回到命令行提示符状态。省略号(！)是另一个重要的特殊字符。他的特殊作用是给计算机操作系统发送一个命令。在省略号后的字符会发送给计算机并且执行，如果在计算机的命令行提示符中输入字符是一样的。</p><p>最后，你能用 diary 命令记录下在 MATLAB 中运行过程中每个线程所做的事。命令的格式如下：</p><pre><code class="highlight plaintext">diary filename</code></pre><p>当这个命令被执行后，所有在命令窗口(The Command Windows)中的输入和输出将会被记录在 diary 文件中。这是一个非常重要的工具，当 MATLAB 发生错误而中断时，利用它你可以重建重要的事件。<strong>diary off 命令中止写入diary文件，diary on 命令重新开始写入</strong>。</p><h5 id="1-3-11-MATLAB-搜索路径">1.3.11 MATLAB 搜索路径</h5><p>MATLAB包括一个特殊的命令——which命令，它能帮助我们找到正在执行的文件版本和它的路径。在检查文件名冲突方面它是非常有用的。这个命令的格式是</p><pre><code class="highlight plaintext">which filename</code></pre><p>filename 代表你所要加载的函数名。举个例子，你要加载的函数是cross.m：</p><pre><code class="highlight plaintext">&gt;&gt; which crossF:\MATLAB\toolbox\matlab\specfun\cross.m</code></pre><p>我们可以运用启动平台中的路径工具(the path tool)随时检查和修改这个路径，或者在命令窗口(The Command Windows)中输入 editpath 命令。路径工具(the path tool)</p><ol><li>addpath 增加目录到 MATLAB 搜索路径</li><li>path 显示 MATLAB 搜索路径</li><li>path2rc 增加当前目录到 MATLAB 搜索路径</li><li>rmpath 移动 MATLAB 搜索路径中的目录</li></ol><h4 id="1-4-把-MATLAB-当作便笺薄来使用">1.4 把 MATLAB 当作便笺薄来使用</h4><h3 id="第二章-MATLAB-基础">第二章 MATLAB 基础</h3><h4 id="2-1-变量和数组">2.1 变量和数组</h4><p><strong>MATLAB</strong> 程序的<strong>基本数据单元是数组</strong>。一个数组是以行和列组织起来的数据集合，并且拥有一个数组名。数组中的<strong>单个数据是可以被访问</strong>的，访问的方法是数组名后带一个括号， 括号内是这个数据所对应行标和列标。标量在 MATLAB 中也被当作数组来处理——它被看作只有一行一列的数组。</p><p>数组可以定义为<strong>向量或矩阵</strong>。</p><p>数组的大小（size）由<strong>数组的行数和列数共同决定</strong>，注意行数在前。一个数组所包含的数据多少可由<strong>行数乘列数</strong>得到。</p><p>MATLAB 的<strong>变量名必须以字母开头</strong>，<strong>后面可以跟字母，数字和下划线（_）</strong>.只有前31<br>个字符是有效的；如果超过了 31 个字符，基余的字符将被忽略。如果声明两个变量，两变量名只有第 32 个字符不同，那么 MATLAB 将它们当作同一变量对待。</p><p><strong>确保你所声明的变量名前 31 个字符是独一无二的。否则，MATLAB 将无法辨认出它们的不同。</strong></p><p>**给你的变量起一个描述性的且易于记忆的变量名。**例如，货币汇率可以exchange_rate为变量名。这种方法将使得你的程序更加明确且易于理解。</p><p>你<strong>所写的程序的开头列出一数据字典</strong>（data dictionary）十分的重要。数据字典列举了你在本程序中用到的所有变量的定义。它的定义应包括本条目的所要描述的内容和它在执行时所在的单元。当编写程序时，编定数据字典看似没有必要。但是设想一下，在过了一段时间后，你或其他人要对此程序修改，这时数据字典就显得十分的有用。</p><p><strong>给每个程序创建一个数据字典以增强程序的可维护性。</strong></p><p>在 MATLAB 语言中是<strong>区分字母大小</strong>的，也就是说，大写字母和小写字母代表的东西是不同的。</p><p><strong>在每次用到一个变量时，我们要确保变量名的大小写的精确匹配。在变量名中只使用小写字母是一个好的编程习惯。</strong></p><h4 id="2-2-MATLAB-变量的初始化">2.2 MATLAB 变量的初始化</h4><p>当变量初始化时，MATLAB 将会自动建立变量。有三种方式初始化 MATLAB 中的变量：</p><ol><li>用赋值语句初始化变量</li><li>用 input 函数从键盘输入初始化变量</li><li>从文件读取一个数据</li></ol><h5 id="2-2-1-用赋值语句初始化变量">2.2.1 用赋值语句初始化变量</h5><p>最简单的<strong>创建和初始化一个变量的方法是用赋值语句赋予变量一个或多个值</strong>。赋值语句的一般形式如下：<br>var = expression</p><p>**var 是变量名，expression 可以是一个标量、一个数组或常量、其他变量和数学运算符号（+、-）的联合。**这个表达式（expression）的值是通过一般的数学运算法则计算出来的， 然后将产生的结果存储到变量 var 中。下面是一些用赋值语句初始化的变量：<br>var=40*i;<br>var2=var/5;<br>array=[1 2 3 4];<br>x=1;<br>y=2;</p><p>第一个例子创建了一个 double 类型的标量变量，存储了一个虚数 40i。第二个例子创建了一个表达式 var2，把 var/5 的值存储于内。第三个例子创建了一个数组 array，并存储了一个 4 元素的行向量于内。最后一个例子显示了多个赋值语句可写在同一行，中间用逗号或分号隔开。注意如果在赋值语句执行时变量已经存在，那么这个变量原有的值将被覆盖。</p><p>正如第三个例子显示的，数据数组也可以初始化变量。我们可以用是括号（）和分号建立数组。所有元素按行阶排序，换句话说，每一行的值从左向右，顶部的行置于最前，底部的行置于最后。在一行内单个数值可用空格或逗号隔开，而行与行之间要与则用分号隔开， 或另起一行书写。下面的表达式都是合法的，能用于建立一个变量：</p><table><thead><tr><th style="text-align:center">数组</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:center">[3.4]</td><td style="text-align:left">这个表达式创建了1×1数组(一个标量),包含数值3.4，这时括号可以省略</td></tr><tr><td style="text-align:center">[1.0 2.0 3.0]</td><td style="text-align:left">这个表达式创建了一个 1×3 数组，一维行向量[1 2 3]</td></tr><tr><td style="text-align:center">[1.0;2.0;3.0]</td><td style="text-align:left">这个表达式创建了一个 3×1 数组，一维列向量</td></tr><tr><td style="text-align:center">[1,2,3;4,5,6]</td><td style="text-align:left">这个表达式创建了一个 2×3 数组,矩阵 <img src="/medias/1591847346041.png" width="60px"></td></tr><tr><td style="text-align:center">[1,2,3 4,5,6]</td><td style="text-align:left">这个表达式创建了一个 2×3 数组,矩阵<img src="/medias/1591847391797.png" width="60px"></td></tr><tr><td style="text-align:center">[]</td><td style="text-align:left">是个空数组，没有行，没有列(注意他与元素全为零的数组的区别)</td></tr></tbody></table><p>注意一个数组每一行元素的个数必须完全相同，每一列元素的个数也必须完全相同。像[1 2 3;4 5];这样的表达式是非法的，因为第一行有 3 个元素，第二行有只有 2 个元素.</p><p>**每一行元素的个数必须完全相同，每一列元素的个数也必须完全相同。**试图创建一个不同行(列)拥有不同数目元素的数组，在编译时将会出现错误。</p><p>当我们创建一个数组时，不是每一个元素都必须定义。如果要定义一个特殊的数组，或只有一个或几个元素没有定义，那么之前的那些元素将会自动创建，并初始化为 0。例如，如果数组 c 事先没有定义，语句 c(2,3)=5 将会创建一矩阵<img src="/medias/1591847441476.png" width="100px"></p><p>在每个赋值语句末的分号有特殊的目的：无论在何时一个表达式在赋值语句中被赋值， 分号将会中止变量值的重复。如果句末没有分号，变量值将会自动显示在命令窗口(The Command Windows)中。</p><pre><code class="highlight plaintext">&gt;&gt; e=[1 2 3;4 5 6]e =     1     2     3     4     5     6</code></pre><p>**如果在赋值语句末有分号，这种重复将会消失。**重复是一个用于检查你的工作极好的方法，但是它降低了运行速度。因此，我们在一般情况下总是禁止重复。尽管如此，重复计算的结果提供了一个强大的应急调试器。如果你不能确定一个特定的赋值语句结果是多少，这时你可以去掉这个语句后的分号，当这个语句编译时，结果会显示在命令窗口(The Command Windows)。</p><p><strong>在 MATLAB 赋值语句后加上一个分号来禁止变量值在命令窗口(The Command Windows)的重复。<strong>这将</strong>大大提高编译的速度</strong>。</p><p><strong>如果你在调试程序时需要检测一个语句的结果，可能把句后的分号去掉，这样结果将会出现在命令窗口(The Command Windows)。</strong></p><h5 id="2-2-2-用捷径表达式赋值">2.2.2 用捷径表达式赋值</h5><p>创建一个小数组用一一列举出元素的方法是比较容易的，但是当我们创建包括成千上万个元素的数组怎么办？把每一个元素列举出来则不太现实。</p><p>MATLAB 提供一种专门的捷径标记法，这种方法用克隆运算符（colon operator）适用于上述情况。克隆运算符指定一系列的数值，它指定了这个系列数的第一值，步增和最后一个值。它的一般顺序始下<br><strong>first:incr:last</strong><br>first 代表数组的每一个值，incr 代表步增量，last 代表这个数组的最后一个值。如果步增量为 1，那么步增量可省略，而变成了 first:last 格式。</p><p>例如，表达式 1:2:10 是创建一个 1×5 行向量[1 3 5 7 9]的简便方法。</p><pre><code class="highlight plaintext">&gt;&gt; x=1:2:10x =     1     3     5     7     9</code></pre><p>用克隆标记法初始化一个含有一百个元素的数组<img src="/medias/1591847553542.png" width="100px"> ，语句如下：<br>Angles = (.01:.01:1)*pi</p><p>捷径表达式可以联合转置运算符（‘）来初始化行向量，或更加复杂的矩阵。转置运算符可以在需要的情况下完成行和列的转换。因为这个表达式<br>f = [1:4]’;<br>产生一个 4 元素行向量[1 2 3 4]，然后将其转换成 4 元素的列向量<img src="/medias/1591847597056.png" width="50px"><br>相似地，表达式<br>g = 1:4;<br>h = [g’ g’]<br>将会创建一个矩阵<img src="/medias/1591847695484.png" width="80px"></p><h5 id="2-2-3-用内置函数来初始化">2.2.3 用内置函数来初始化</h5><p>数组也可以用 MATLAB 内置函数创始化。例如，函数 zeros 可以初始化任何大小的全为零的数组。用许多形式的 zeros 函数。如果这个函数的参数只是一个标量，那么 MATLAB 将会创建一个方阵，行数和列数均为这个参数。如果这个函数有两个标量参数，那么第一个参数代表行数，第二个参数代表列数。因为 size 函数所返回的一个数组的行数和列数，所以它可以联合 zeros 函数来创建一个相同大小零矩阵。下面是一些用到 zeros 函数的例子。<br>a = zeros(2);<br><img src="/medias/1591847742541.png" width="80px"></p><p>b = zeros(2,3);<br><img src="/medias/1591847794073.png" width="90px"></p><p>c = [1 2;3 4];<br><img src="/medias/1591847832861.png" width="80px"></p><p>d = zeros(size©)<br><img src="/medias/1591847880256.png" width="80px"></p><p>相似地，ones 函数产生的数组包含的元素全为1，eye 函数通常用来产生单位矩阵，只有对角线的元素为1，其他元素为0。</p><p><strong>表 2.1 列出一些用于初始化变量的函数</strong></p><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:left">作用</th></tr></thead><tbody><tr><td style="text-align:left">zeros(n)</td><td style="text-align:left">创建一个 n×n 零矩阵</td></tr><tr><td style="text-align:left">zeros(n,m)</td><td style="text-align:left">创建一个 n×m 零矩阵</td></tr><tr><td style="text-align:left">zeros(size(arr))</td><td style="text-align:left">创建一个与数组arr的零矩阵</td></tr><tr><td style="text-align:left">ones(n)</td><td style="text-align:left">创建一个n×n元素全为1矩阵</td></tr><tr><td style="text-align:left">ones(n,m)</td><td style="text-align:left">创建一个n×m元素全为1矩阵</td></tr><tr><td style="text-align:left">eye(n)</td><td style="text-align:left">创建一个n×m元素全为1矩阵</td></tr><tr><td style="text-align:left">eye(n,m)</td><td style="text-align:left">创建一个n×m的单位矩阵</td></tr><tr><td style="text-align:left">length(arr)</td><td style="text-align:left">返回一个向量的长度或二维数组中最长的那一维的长度</td></tr><tr><td style="text-align:left">size(arr)</td><td style="text-align:left">返回一个向量的长度或二维数组中最长的那一维的长度</td></tr></tbody></table><h5 id="2-2-4-用关键字-input-初始化变量">2.2.4 用关键字 input 初始化变量</h5><p>关键字 input 用来提示使用者和直接从键盘输入初始化变量。当脚本文件(Script files)时, 它可以用来提示使用者输入。input 函数在命令窗口(The Command Windows)显示提示语句，并等待用户输入一个值。例如，下面的赋值语句:<br>my_val = input(‘Enter an input value:’)</p><p>如果 input 函数中有字符’s’做为它的第二个参数，输入的数据就被当字符串，因此，语句</p><pre><code class="highlight matlab">&gt;&gt; in1 = input(<span class="string">'enter data:'</span>);enter data:<span class="number">1.23</span></code></pre><p>把数值 1.23 存储到 in1 中，而语句</p><pre><code class="highlight matlab">&gt;&gt; in2 = input(<span class="string">'enter data:'</span>,<span class="string">'s'</span>)enter data:<span class="number">1.23</span></code></pre><p>把字符串 1.23 存储到 in2 中。</p><h4 id="2-3-多维数组">2.3 多维数组</h4><p>MATLAB 的数组可能是一维或多维的。一维的数组可以形象地看作一系列的数垂直地罗列起来，用一个下标就可以调用数组中的元素（如图 a）。这样的数组适用于一个变量的函数，我们就需要两个下标来调用数组特定的函数：第一个下标选择行，第二个下标选择列。这样的数组叫做二维数组。二维数组中元素的个数取决于这个数组的行数和列数。</p><p>MATLAB 允许我们创建多维数组。这些数组的每一维对应一个下标， 和每一个单个元素都可以通过它的每一个下标被调用。在这个数组中元素的总和取决于每一维中元素的个数。<br>例如，下面两个语句创建了一个 2×3×2 数组 c</p><pre><code class="highlight matlab">&gt;&gt; c(:,:,<span class="number">1</span>)=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>];&gt;&gt; c(:,:,<span class="number">2</span>)=[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>;<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>];&gt;&gt; whos c  Name    Size      Bytes  Class     Attributes   c      <span class="number">2</span>x3x2          <span class="number">96</span>            double</code></pre><p>这个数组（2×3×2）包括 12 种元素，它的内容显示方法和其他数组的显示方法大体相同</p><pre><code class="highlight matlab">&gt;&gt; cc(:,:,<span class="number">1</span>) =     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>c(:,:,<span class="number">2</span>) =     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><h5 id="2-3-1-多维数组在内存中的存储">2.3.1 多维数组在内存中的存储</h5><p>一个有 m 行和 n 列的二维数组包括 m×n 个元素，这些元素在计算机的内存中将会占有m×n 个连续的内存空间。这些数组的元素在内存中是如何排列的呢？</p><p>MATLAB 以列主导顺序分配数组中的元素。也就是说，内存先分配第一列的元素，然后第二列，第三列，……以此类推，直到所有列都被分配完。</p><h5 id="2-3-2-用单个下标访问多标数组">2.3.2 用单个下标访问多标数组</h5><p>MATLAB 的特性之一就是它允许使用者或程序员把一个多维数看作一个一维数组，这个一维数组的长度等于多维数组的元素数。如果用一个下标访问一个多维数组，那么元素的排列顺序就是内存的分配顺序。</p><p><strong>在访问多维数组时，总是使用合适的维数。</strong></p><h4 id="2-4-子数组">2.4 子数组</h4><p>你可以选择和使用一个 MATLAB 函数的子集，好像他们是独立的数组一样。在数组名后面加括号，括号里面是所有要选择的元素的下标，这样就能选择这个函数的子集了。例如， 假设定义了一个数组 arr1 如下<br><strong>arr1 = [1.1 -2.2 3.3 -4.4 5.5]</strong><br>那么 arr1(3)为 3.3，arr1([1 4])为数组[1.1 -4.4]，arr1(1:2:5)为数组[1.1 3.3 5.5]。<br>对于一个二维数组，克隆运算符可以用于下标来选择子数组。例如，假设<br>arr2 = [1 2 3; -2 -3 -4;3 4 5]<br>将建立一个数组<img src="/medias/1591847968024.png" width="140px"></p><p>在这种定义下，子数组 arr2(1,:)为[1 2 3]，子数组 arr2(:,1:2:3)为<img src="/medias/1591848009343.png" width="80px"></p><h5 id="2-4-1-end-函数">2.4.1 end 函数</h5><p>MATLAB 中有一个特殊的函数叫做 end 函数，对于创建子数组的下标非常的有用。当用到一个函数的下标时，end 函数将会返回下标的最大值。<br>例如，假设数组 arr3 定义如下:<br><strong>arr3 = [1 2 3 4 5 6 7 8];</strong><br>那么 arr3(5:end)将会产生数组[5 6 7 8]，arr3(end)将会产生值 8。<br>end 函数返回的值一般为所要下标的最大值。如果 end 函数显示有不同的下标，那它将在一个表达式内返回不同的值。例如，假设一个 3×4 数组 arr4 的定义如下:<br><strong>arr4 = [1 2 3 4;5 6 7 8;9 10 11 12]</strong><br>那么表达式arr4(2:end,2:end)将会返回<img src="/medias/1591848070089.png" width="80px"> 。注意第一个 end 返回值为 3，第二个返回值为 4.</p><h5 id="2-4-2-子数组在左边的赋值语句的使用">2.4.2 子数组在左边的赋值语句的使用</h5><p>只要数组的形（行数和列数）和子数组的形相匹配，把子数组放于赋值语句的左边用来更新数组中的值。如果形不匹配，那么将会有错误产生。<br>例如，下面有一个 3×4 数组定义如下：</p><pre><code class="highlight matlab">&gt;&gt; arr4 = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span>;<span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]arr4 =     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><p>因为在等号左边的表达式的形（2×2）与 a 相匹配，那么下面的这个赋值语句是合法的。</p><pre><code class="highlight matlab">&gt;&gt; arr4(<span class="number">1</span>:<span class="number">2</span>,[<span class="number">1</span> <span class="number">4</span>])=[<span class="number">20</span> <span class="number">21</span>;<span class="number">22</span> <span class="number">23</span>]arr4 =    <span class="number">20</span>     <span class="number">2</span>     <span class="number">3</span>    <span class="number">21</span>    <span class="number">22</span>     <span class="number">6</span>     <span class="number">7</span>    <span class="number">23</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><p>注意数组元素（1，1），（1，4）（2，1）和（2，4）得到了更新。相对而言，两边的形不相匹配，则表达式是非法的，例如下面这个表达式。</p><pre><code class="highlight matlab">&gt;&gt;  arr5(<span class="number">1</span>:<span class="number">2</span>,[<span class="number">1</span> <span class="number">4</span>])=[<span class="number">20</span> <span class="number">21</span>]无法执行赋值，因为左侧的索引与右侧的大小不兼容。</code></pre><p><strong>对于涉及子数组的赋值语句，等号两边的形必须相匹配。否则将会产生错误。</strong></p><p>在 MATLAB 中用子数组赋值和用值直接赋值有很大的不同。如果用子数组赋值，那么只有相应的值得到更新，而其他的值保持不变。另一方面，直接赋值，则数组的原有内容全部删除并被新的值替代。<br>例如，假设用一个数组 arr4 定义如下：</p><pre><code class="highlight matlab">&gt;&gt;  arr4 = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span>;<span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]arr4 =     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><p>下面的赋值语句，只更新特定的元素：</p><pre><code class="highlight matlab">&gt;&gt; arr4(<span class="number">1</span>:<span class="number">2</span>,[<span class="number">1</span> <span class="number">4</span>]) = [<span class="number">20</span> <span class="number">21</span>;<span class="number">22</span> <span class="number">23</span>]arr4 =    <span class="number">20</span>     <span class="number">2</span>     <span class="number">3</span>    <span class="number">21</span>    <span class="number">22</span>     <span class="number">6</span>     <span class="number">7</span>    <span class="number">23</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><p>相对地，下面的赋值语句更新了数组的全部内容，并改变了数组的形</p><pre><code class="highlight matlab">&gt;&gt;  arr4 = [<span class="number">20</span> <span class="number">21</span>;<span class="number">22</span> <span class="number">23</span>]arr4 =    <span class="number">20</span>    <span class="number">21</span>    <span class="number">22</span>    <span class="number">23</span></code></pre><p><strong>确保将赋值于子数组和赋值于数组。MATLAB 将它们当作两个不同的情况来对待。</strong></p><h5 id="2-4-3-用一标量来给子数组赋值">2.4.3 用一标量来给子数组赋值</h5><p>位于赋值语句的右边的标量值总是能匹配左边数组的形。这个标量值将会被复制到左边语句中所对应的元素。例如，假设用一个数组 arr4 定义如下：</p><pre><code class="highlight matlab">&gt;&gt; arr4 = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span>;<span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]arr4 =     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><p>下面的表达式将一个值赋值于数组的 4 个元素。</p><pre><code class="highlight matlab">&gt;&gt;  arr4(<span class="number">1</span>:<span class="number">2</span>,<span class="number">1</span>:<span class="number">2</span>)=<span class="number">1</span>arr4 =     <span class="number">1</span>     <span class="number">1</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">1</span>     <span class="number">1</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span>    <span class="number">11</span>    <span class="number">12</span></code></pre><h4 id="2-5-特殊变量">2.5 特殊变量</h4><p>在 MATLAB 中有许多预先定义好的特殊变量。在 MATLAB 中这些特殊变量可以随时使用，不用初始化。一些常见的预定义值列在表 2.2。</p><p><strong>表 2.2 预定义特殊变量</strong></p><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:left">用途</th></tr></thead><tbody><tr><td style="text-align:left">pi</td><td style="text-align:left">有 15 个有效值的n</td></tr><tr><td style="text-align:left">i,j</td><td style="text-align:left">代表虚数 i(根号(-1))</td></tr><tr><td style="text-align:left">Inf</td><td style="text-align:left">这个符号代表无穷大，它一般情况下是除以 0 产生的</td></tr><tr><td style="text-align:left">NaN</td><td style="text-align:left">这个符号代表没有这个数。它一般由数学运算得到的。例如，0除以0</td></tr><tr><td style="text-align:left">clock</td><td style="text-align:left">这个特殊变量包含了当前的年，月，日，时，分，秒，是一个 6 元素行向量</td></tr><tr><td style="text-align:left">date</td><td style="text-align:left">当前的日期，使用的的字符形式，如 30-Dec-2007</td></tr><tr><td style="text-align:left">eps</td><td style="text-align:left">变量名是epsilon 的简写。它代表计算能机辨别的两数之间的最小数</td></tr><tr><td style="text-align:left">ans</td><td style="text-align:left">常用于存储表达式的结果，如果一个结果没有明确的赋值给某个变量</td></tr></tbody></table><p>这个些预定义值存储在一般的变量中，所以他们能被覆盖或改写。如果一个新值赋值于其中一个预定义变量，那么这以后的计算中新值将会替代默认值。例如，考虑下面用于计算以半径为 10 的圆的周长的语句;</p><pre><code class="highlight matlab">&gt;&gt; circl=<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">10</span> circl =   <span class="number">62.8319</span>&gt;&gt; <span class="built_in">pi</span>=<span class="number">3</span><span class="built_in">pi</span> =     <span class="number">3</span>&gt;&gt; circ2=<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">10</span>circ2 =    <span class="number">60</span></code></pre><p>在第一个语句中，pi 有默认值 3.14159…，所以周长 6.28319 是正确的结果，第二个语句重定义 pi 为 3，所以第三个语句 circ2 为 60。在程序中修改预定义值会造成一些不正确的结果，并导致一些微小而难以发现的错误。设想一下，要在1000 行的程序中找出一个像这样的错误是多么不容易。</p><p>不要重定义有意义的预定义变量。否则将后患无穷，制造成出小而难以发现的错误。</p><pre><code class="highlight matlab">&gt;&gt; c=[<span class="number">1.1000</span> <span class="number">-3.2000</span> <span class="number">3.4000</span> <span class="number">0.6000</span>;<span class="number">0.6000</span> <span class="number">1.1000</span> <span class="number">-0.6000</span> <span class="number">3.1000</span>;<span class="number">1.3000</span> <span class="number">0.6000</span> <span class="number">5.5000</span> <span class="number">0</span>]c =    <span class="number">1.1000</span>   <span class="number">-3.2000</span>    <span class="number">3.4000</span>    <span class="number">0.6000</span>    <span class="number">0.6000</span>    <span class="number">1.1000</span>   <span class="number">-0.6000</span>    <span class="number">3.1000</span>    <span class="number">1.3000</span>    <span class="number">0.6000</span>    <span class="number">5.5000</span>         <span class="number">0</span>    &gt;&gt; c(<span class="number">2</span>,:)<span class="built_in">ans</span> =    <span class="number">0.6000</span>    <span class="number">1.1000</span>   <span class="number">-0.6000</span>    <span class="number">3.1000</span>    &gt;&gt;  c(:,<span class="keyword">end</span>)<span class="built_in">ans</span> =    <span class="number">0.6000</span>    <span class="number">3.1000</span>         <span class="number">0</span>         &gt;&gt; c(<span class="number">1</span>:<span class="number">2</span>,<span class="number">2</span>:<span class="keyword">end</span>)<span class="built_in">ans</span> =   <span class="number">-3.2000</span>    <span class="number">3.4000</span>    <span class="number">0.6000</span>    <span class="number">1.1000</span>   <span class="number">-0.6000</span>    <span class="number">3.1000</span>    &gt;&gt; c(<span class="number">6</span>)<span class="built_in">ans</span> =    <span class="number">0.6000</span>    &gt;&gt;  c(<span class="number">4</span>:<span class="keyword">end</span>)<span class="built_in">ans</span> =  列 <span class="number">1</span> 至 <span class="number">7</span>   <span class="number">-3.2000</span>    <span class="number">1.1000</span>    <span class="number">0.6000</span>    <span class="number">3.4000</span>   <span class="number">-0.6000</span>    <span class="number">5.5000</span>    <span class="number">0.6000</span>  列 <span class="number">8</span> 至 <span class="number">9</span>    <span class="number">3.1000</span>         <span class="number">0</span>    &gt;&gt; c(<span class="number">1</span>:<span class="number">2</span>,<span class="number">2</span>:<span class="number">4</span>)<span class="built_in">ans</span> =   <span class="number">-3.2000</span>    <span class="number">3.4000</span>    <span class="number">0.6000</span>    <span class="number">1.1000</span>   <span class="number">-0.6000</span>    <span class="number">3.1000</span>    &gt;&gt; c([<span class="number">1</span> <span class="number">4</span>],<span class="number">2</span>)位置 <span class="number">1</span> 处的索引超出数组边界(不能超出 <span class="number">3</span>)。&gt;&gt; c([<span class="number">1</span> <span class="number">3</span>],<span class="number">2</span>)<span class="built_in">ans</span> =   <span class="number">-3.2000</span>    <span class="number">0.6000</span>    &gt;&gt; c([<span class="number">2</span> <span class="number">2</span>],[<span class="number">3</span> <span class="number">3</span>])<span class="built_in">ans</span> =   <span class="number">-0.6000</span>   <span class="number">-0.6000</span>   <span class="number">-0.6000</span>   <span class="number">-0.6000</span></code></pre><h4 id="2-6-显示输出数据">2.6 显示输出数据</h4><p>在 MATLAB 中有许多的方法显示输出数据。最简单的方法是我们已经用过的去掉语句末的分号，它将显示在命令窗口(The Command Windows)中。</p><h5 id="2-6-1-改变默认格式">2.6.1 改变默认格式</h5><p>当数据重复在命令窗口(The Command Windows)时，整数以整形形式显示，其他值将以默认格式显示。MATLAB 的默认格式是精确到小数点后四位。如果一个数太大或太小，那么将会以科学记数法的形式显示。比如，语句</p><pre><code class="highlight matlab">&gt;&gt; x = <span class="number">100.11</span>x =  <span class="number">100.1100</span>&gt;&gt; y = <span class="number">1001.1</span>y =   <span class="number">1.0011e+03</span>&gt;&gt; z = <span class="number">0.00010011</span>z =   <span class="number">1.0011e-04</span></code></pre><p>改变默认输出格式要用到 format 命令，可根据表 2.3 改变数据的输出格式</p><p><strong>表 2.3 输出显示格式</strong></p><table><thead><tr><th style="text-align:left">format 命令</th><th style="text-align:left">结果</th><th style="text-align:left">例子</th></tr></thead><tbody><tr><td style="text-align:left">format short</td><td style="text-align:left">保留小数点后 4 位（默认格式）</td><td style="text-align:left">12.3457</td></tr><tr><td style="text-align:left">format long</td><td style="text-align:left">保留小数点后 14 位</td><td style="text-align:left">12.345678901234567</td></tr><tr><td style="text-align:left">format short e</td><td style="text-align:left">带有 5 位有效数字科学记数法</td><td style="text-align:left">1.2346e+00</td></tr><tr><td style="text-align:left">format short g</td><td style="text-align:left">总共有 5 个数字，可以用科学记数法，也可不用</td><td style="text-align:left">12.346</td></tr><tr><td style="text-align:left">format long e</td><td style="text-align:left">带有 15 位有效数字科学记数法</td><td style="text-align:left">1.234567890123457e+001</td></tr><tr><td style="text-align:left">format long g</td><td style="text-align:left">总共有 5 个数字，可以用科学记数法，也可不用</td><td style="text-align:left">12.3456789012346</td></tr><tr><td style="text-align:left">format bank</td><td style="text-align:left">美元格式</td><td style="text-align:left">12.35</td></tr><tr><td style="text-align:left">format hex</td><td style="text-align:left">用 16 进制表示</td><td style="text-align:left">4028b0fcd32f707a</td></tr><tr><td style="text-align:left">format rat</td><td style="text-align:left">两个小整数的比</td><td style="text-align:left">1000/81</td></tr><tr><td style="text-align:left">format compact</td><td style="text-align:left">隐藏多余的换行符</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">format loose</td><td style="text-align:left">使用多余的换行符</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">format +</td><td style="text-align:left">只显示这个数的正负</td><td style="text-align:left">+</td></tr></tbody></table><p>所有例子都以 12．345678901234567 为例子默认的格式可以改变格式以显示更多的有效数字，用科学计数法来显示，精确到小数点后两位，显示或隐藏多余的换行符。</p><h5 id="2-6-2-disp-函数">2.6.2 disp 函数</h5><p>另一种显示数据的方法是用 disp 函数。disp 需要一个数组参数，它将值将显示在命令窗口(The Command Windows)中。如果这个数组是字符型（char），那么包含在这个数组中的字符串将会打印在命令窗口(The Command Windows)中。</p><p>此函数可联合num2str(将一个数转化为字符串)和int2str(将一个整数转化为字符串)来产生新的信息，显示在命令窗口(The Command Windows)中。例如，下面的语句将“the value of pi=3.1416”显示在命令窗口(The Command Windows)中。第一句创建了一个字符型数组，第二句用于显示这个数组。</p><pre><code class="highlight matlab">&gt;&gt; str=[<span class="string">'the value of pi='</span>num2str(<span class="built_in">pi</span>)];&gt;&gt; <span class="built_in">disp</span>(str);the value of <span class="built_in">pi</span>=<span class="number">3.1416</span></code></pre><h5 id="2-6-3-用-fprintf-函数格式化输出数据">2.6.3 用 fprintf 函数格式化输出数据</h5><p>用 fprintf 函数显示数据是一种十分简便方法。fprintf 函数显示带有相关文本的一个或多个值，允许程序员控制显示数据的方式。它在命令窗口打印一个数据的一般格式如下：<br><strong>fprint(format,data)</strong></p><p>其中 format 用于代表一个描述打印数据方式的子符串，data 代表要打印的一个或多个标量或数组。format 包括两方面的内容，一方面是打印内容的文本的提示;另一方面是打印的格式。例如，函数<br><strong>fprintf(‘The value of pi is %6.2f \n’,pi)</strong></p><p>将会打印出’The value of pi is 3.14’,后面带有一个换行符。转义序列 %6.2 代表在本函数中的第一个数据项将占有 6 个字符宽度，小数点后有 2 位小数。</p><p>fprintf 函数有一个重大的局限性，只能显示复数的实部。当我们的计算结果是复数时， 这个局限性将会产生错误。在这种情况下，最好用 disp 显示数据。</p><p><strong>表 2.4 fprintf 函数 format 字符中的特殊字符</strong></p><table><thead><tr><th style="text-align:left">format string</th><th style="text-align:left">结果</th></tr></thead><tbody><tr><td style="text-align:left">%d</td><td style="text-align:left">把值作为整数来处理</td></tr><tr><td style="text-align:left">%e</td><td style="text-align:left">用科学记数法来显示数据</td></tr><tr><td style="text-align:left">%f</td><td style="text-align:left">用于格式化浮点数，并显示这个数</td></tr><tr><td style="text-align:left">%g</td><td style="text-align:left">用科学记数格式，或浮点数格式，根据那个短，并显示之</td></tr><tr><td style="text-align:left">\n</td><td style="text-align:left">转到新的一行</td></tr></tbody></table><p>例如，下列语句计算复数 x 的值，分别用 fprintf 和 disp 显示</p><pre><code class="highlight matlab">&gt;&gt; x=<span class="number">2</span>*(<span class="number">1</span><span class="number">-2</span>*<span class="built_in">i</span>)^<span class="number">3</span>;&gt;&gt; str=[<span class="string">'disp: x = '</span> num2str(x)]; &gt;&gt; <span class="built_in">disp</span>(str);<span class="built_in">disp</span>: x = <span class="number">-22</span>+<span class="number">4</span><span class="built_in">i</span>&gt;&gt; fprintf(<span class="string">'fprintf: x = %8.4f\n'</span>,x);fprintf: x = <span class="number">-22.0000</span></code></pre><p><strong>注意 frpintf 忽略了虚部。</strong></p><p><strong>fprintf 函数只能复数的实部，所以在有复数参加或产生的计算中，可能产生错误的结果。</strong></p><h4 id="2-7-数据文件">2.7 数据文件</h4><p>有许多的方法用于加载和保存 MATLAB 的数据文件。在这里向大家介绍最简章的 save 和 load 命令。</p><p>save 命令用于保存当前 MATLAB 工作区内的数据到一个硬盘文件。这个命令的基形式如下：</p><p><strong>save filename var1 var2 var3</strong></p><p>filename 代表你要保存变量的那个文件，var1，var2 等是要保存的变量。在默认情况下，这个这个文件的扩展名为 ’mat’，我们称之为 MAT 文件。如果在 filename 后面无变量，则工作区的所有内容将会被保存。</p><p>MATLAB 用一种特殊的复杂形式来存储数据，包括了许许多多的细节，例如变量名和变量类型，数组的大小，以及所有变量值。一个在任何一个平台上创建的 MAT 文件(pc, mac, unix)在另一个平台上都可以应用。它的缺点是 MAT 文件的存储格式不能被其他程序读取。如果一个数据必须由其他程序所读取，那么必须转化为 ASCII 码，并将这些数值写到一个以 ASCII 码为编码的文件中。但是，当以 ASCII 的形式存储，像变量名和变量类型这样的信息就会丢失，产生的数据结果将会更大。</p><p>例如，假设数组 x 的定义如下<br>x=[1.23 3.14 6.28; -5.1 7.00 0];</p><p>命令“save x.dat x -ascii”将会创建一个文件 x.dat，包括数据如下<br>1.2300000e+00   3.1400000e+00   6.2800000e+00<br>-5.1000000e+00   7.0000000e+00   0.0000000e+00</p><p>用这种格式定的数据能被其他语言编写的程序或扩展页读取，所以它能帮助 MATLAB<br>程序和其他程序之间共享数据。</p><p><strong>如果数据需要在 MATLAB 和其他程序之间交换使用，那么以 ASCII 格式存储数据。如果只在 MATLAB 中使用那么，应以 mat 文件的形式存储数据。</strong></p><p>MATLAB 并不关心 ASCII 码的扩展名是什么？但是，用户最好用它的传统扩展名“dat”。</p><p><strong>以"dat"的扩展名保存 ASCII 数据文件，以区别于以"mat"为扩展名的 mat 文件。</strong></p><p>load 命令与 save 命令相反。它从硬盘文件加载数据到 MATLAB 当前工作区。这个命令的基本格式为<br>load filename</p><p>filename 代表所加载文件的文件名。如果这个文件是 mat 文件，那么所有被子加载的变量的变量名的变量类型将和原来一样。如果一个变量包含在工作区间窗口，那么这些数据将会被修复。</p><p>MATLAB 能够加载由其他程序创建的 ASCII 格式的数据文件。它首先检查所要加载的文件是 mat 文件还是 ASCII 文件。如果在 load 语句中加入-ascii 中，则强制 MATLAB 把这个文件看作 ASCII 文件。这个文件的内容将会被转化为一个 MATLAB 的数组，这个数组名就所要加载的文件名。例如，假设一个名为 x.dat 的ASCII 文件包括下列数据：<br>1.23 3.14 6.28<br>-5.1 7.00 0<br>那么“load x.dat”将会在当前工作区创建一个 2X3 数组x，包含数据值。</p><h4 id="2-8-标量运算和数组运算">2.8 标量运算和数组运算</h4><p>在 MATLAB 赋值语句中的计算，它的一般形式如下<br><strong>variable_name = expression;</strong></p><p>赋值语句计算出等号右边表达式的值，然后赋值于等号左边的变量名。注意这个等号并不是传统意义上的等号，它的意义是：存储表达式的值到左边的变量，由于这个原因，等号在这里应叫做赋值号。像<br><strong>ii = ii + 1;</strong></p><p>这样的语句在数学上是毫无意义的，但在 MATLAB 语言中，它有其固有的意义。<br>它的意义是：<strong>把变量 ii 加上 1 之后，再把值存储到变量 ii 中</strong>。</p><h5 id="2-8-1-标量运算符">2.8.1 标量运算符</h5><p>位于赋值号右边的表达式，可以包含标量，数组，括号和数学符号的任一个有效联合运算。两标量间的标准运算符号如表 2.5 所示。</p><p>当我们需要的时候，我们可以运用括号来控制运算顺序。括号内的表达式优先于括号外的表达式来计算。例如表达式 2^((8+2)/5)的计算顺序如下</p><pre><code class="highlight plaintext">2 ^ ( ( 8 + 2 ) / 5 ) = 2 ^ ( 10 / 5 )= 2 ^ 2= 4</code></pre><h5 id="2-8-2-数组运算和矩阵运算">2.8.2 数组运算和矩阵运算</h5><p>MATLAB 在数组运算中提供了两种不同类型的运算，一种是数组运算(array operations)，一种是矩阵运算(matrix)。数组运算是一种用于元素对元素的运算。也就是说，这个运算是针对两数组相对应的运算使用的。<br><img src="/medias/1591848785521.png" alt=""></p><p><strong>注意两数组的行与列必须相同，否则，MATLAB 将产生错误。</strong></p><p>数组运算可以用于数组与标量的运算。<strong>当一个数组和一个标量进行运算时，标量将会和数组中的每一元素进行运算。</strong></p><p><img src="/medias/1591848818856.png" alt=""></p><p>相对地，矩阵运算则遵守线性代数的一般规则，像矩阵的乘法。在线性代数中，c=a×b 的定义如下:</p><p><strong>表 2.5 两标量间的数学运算符</strong></p><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:center">代数形式</th><th style="text-align:center">MATLAB 形式</th></tr></thead><tbody><tr><td style="text-align:center">加号</td><td style="text-align:center"><code>A+B</code></td><td style="text-align:center"><code>A+B</code></td></tr><tr><td style="text-align:center">减号</td><td style="text-align:center"><code>A-B</code></td><td style="text-align:center"><code>A-B</code></td></tr><tr><td style="text-align:center">乘号</td><td style="text-align:center"><code>A×B</code></td><td style="text-align:center"><code>A*B</code></td></tr><tr><td style="text-align:center">除号</td><td style="text-align:center"><img src="/medias/1591849155462.png" width="28px"></td><td style="text-align:center"><code>A/B</code></td></tr><tr><td style="text-align:center">指数</td><td style="text-align:center"><img src="/medias/1591849099375.png" width="26px"></td><td style="text-align:center"><code>A^B</code></td></tr></tbody></table><p><img src="/medias/1591849257843.png" alt=""></p><p>注意，在矩阵相乘中，a 阵的列数必须等于 b 阵的行数。</p><p>MATLAB 用一个特殊的符号来区分矩阵运算和数组运算。在需要区分两者不同的时候， 把点置于符号前来指示这是一个数组运算（例如，.*）。表 2。6 给出的是一些常见的数组和矩阵运算。</p><p><strong>表 2.6 常见的数组和矩阵运算</strong></p><table><thead><tr><th style="text-align:center">运算</th><th style="text-align:center">MATLAB 形式</th><th style="text-align:left">注释</th></tr></thead><tbody><tr><td style="text-align:center">数组加法</td><td style="text-align:center">A+B</td><td style="text-align:left">数组加法和矩阵加法相同</td></tr><tr><td style="text-align:center">数组减法</td><td style="text-align:center">A-B</td><td style="text-align:left">数组减法和矩阵减法相同</td></tr><tr><td style="text-align:center">数组乘法</td><td style="text-align:center">A.*B</td><td style="text-align:left">A 和 B 的元素逐个对应相乘。两数组之间必须有相同的形，或其中一个是标量。</td></tr><tr><td style="text-align:center">矩阵乘法</td><td style="text-align:center">A*B</td><td style="text-align:left">A 和 B 的矩阵乘法。A 的列数必须和 B 的行数相同。</td></tr><tr><td style="text-align:center">数组右除法</td><td style="text-align:center">A./B</td><td style="text-align:left">A 和 B 的元素逐个对应相除：A(i,j)/B(i,j)两数组之间必须有相同的形，或其中一个是标量。</td></tr><tr><td style="text-align:center">数组左除法</td><td style="text-align:center">A.\B</td><td style="text-align:left">A 和 B 的元素逐个对应相除: B(i,j)/A(i,j)两数组之间必须有相同的形,或其中一个是标量。</td></tr><tr><td style="text-align:center">矩阵右除法</td><td style="text-align:center">A/B</td><td style="text-align:left">矩阵除法，等价于 A*inv(B), inv(B)是 B 的逆阵</td></tr><tr><td style="text-align:center">矩阵左除法</td><td style="text-align:center">A\B</td><td style="text-align:left">矩阵除法，等价于 inv(A)*B, inv(A)是 A 的逆阵</td></tr><tr><td style="text-align:center">数组指数运算</td><td style="text-align:center">A.^B</td><td style="text-align:left">AB 中的元素逐个进行如下运算 A(i,j)^B(i,j)，A(i,j)/B(i,j)两数组之间必须有相同的形，或其中一个是标量。</td></tr></tbody></table><p>初学者往往混淆数组运算和矩阵运算。在一些情况下，两者相互替换会导致非法操作，MATLAB 将会报告产生了错误。在另一些情况下，两种运算都是合法的，那么这时 MATLAB 进行错误的运算，并产生错误的结果。当我们进行方阵运算时，极易产生这样的错误。两个方阵具有相同的大小，两者之间的数组运算和矩阵运算都是合法的，但产生的结果完全不同。在这种情况下，你要万分的小心。</p><p><strong>在你的 MATLAB 代码中，仔细区分数组运算和矩阵运算。数组乘法和矩阵乘法极易混淆。</strong></p><h6 id="例-2-1-数组或矩阵加法、乘法">例 2.1 数组或矩阵加法、乘法</h6><p><img src="/medias/20200615190434407.png" alt=""></p><p><img src="/medias/20200615190528771.png" alt=""></p><h4 id="2-9-运算的优先级">2.9 运算的优先级</h4><p>许多的数学运算写入一个表达式是非常平常的事。例如，考虑初速度为 0 的匀加速运动的位移表达式<br><strong>distance = 0.5 * accel * time ^ 2</strong><br>这个表达式有二个乘法运算和一个幂运算。在这样的表达式中，知道运算的先后顺序是十分重要的。如果幂运算先于乘法运算执行，这个表达式等价于<br><strong>distance = 0.5 * accel * (time ^ 2)</strong><br>如果乘法运算先于幂运算执行，这个表达式等价于<br><strong>distance = (0.5 * accel * time) ^ 2</strong><br>这两个式子将产生不同的结果，所以我们必须清楚它们中那个是正确的。</p><p>为了使表达的值精确，MATLAB 建立了一系列的规则控制运算的层次或顺序。这些规则一般情况下遵循代数的运算法则。</p><p><strong>表 2.7 运算的优先级</strong></p><table><thead><tr><th style="text-align:left">优先级</th><th style="text-align:left">运算</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">括号里的内容先运算，从最里面的括号去运算</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">幂运算，从左向右</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left">乘除法，从左向右</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left">加减法，从左向右</td></tr></tbody></table><h5 id="例-2-2-计算">例 2.2 计算</h5><p>变量 a,b,c,d 初始化如下</p><p>a = 3; b = 2; c = 5; d = 3;</p><p>计算如下的 <strong>MATLAB</strong> 的赋值语句</p><p><img src="/medias/20200615190838299.png" alt=""></p><p>正如我们看到的，运算的顺序对一个代数表达式的最终值产生重大的影响。</p><p>将程序中的每个表达式尽量写清楚，这是十分重要的。编写的程序不仅要能够计算出所要求的值的来，在需要的时侯，还要考虑它的可维护性。你应当经常问自己“六个月后我能看得懂我现在编得程序吗？其他的程序员看到我的代码，他能迅速的理解吗？”。如果在你的心中有所疑虑，那就用更多的括号使之更加清晰。</p><p><strong>在需要的时侯用括号使用表达式更加清晰和易于理解。</strong></p><p>如果在一个表达式中用到括号，那么括号必须平衡。也就是说，左括号数与右括号数相等。如果两者数目不相同，那么将会导致错误的产生。这种错误经常在输入过程中发生，当</p><p><strong>MATLAB</strong> 编译器在执行这个命令时被发现。例如</p><p><strong>（2 + 4) / 2)</strong></p><p>在执行时将会出现一个错误。</p><h4 id="2-10-MATLAB-的内建函数">2.10 MATLAB 的内建函数</h4><h5 id="2-10-1-选择性结果">2.10.1 选择性结果</h5><p>与数学的函数不同，MATLAB 函数返回一个或多个值给调用函数。max 函数就是这样的一个例子。这个函数一般情况下返回输入向量中的最大值，但是它返回的第二个参数是输入向量中的最大值在向量中的位置。例如，语句<br><strong>maxval = max ([1 -5 6 -3])</strong><br>返回的结果为 maxval=6，但是要有两个返回值，那么这个函数包括最大所处的位置<br><strong>[maxval index] = max ([1 -5 6 -3])</strong><br>将会产生结果 maxval=6 和 index=3</p><h5 id="2-10-2-带数组输入的-MATLAB-函数的应用">2.10.2 带数组输入的 MATLAB 函数的应用</h5><p>许多 MATLAB 函数定义了一个或多个标量输入，产生一个输出。例如，语句 y=sin(x) 计算了 x 的正弦，并将结果存储到 y 变量中。如果这些函数接受了输入值构成的数组，那么MATLAB 将一一计算出每个元素所对应的值。例子，假设<br>x=[0 pi/2 3<em>pi/2 2</em>pi]<br>那么语句<br>y=sin(x)<br>将会产生 y=[0    1.0000   -1.0000   -0.0000]。</p><h5 id="2-10-3-常见的-MATLAB-函数">2.10.3 常见的 MATLAB 函数</h5><p>注意与大多数的计算语言不同，许多的 MATLAB 函数能够正确计算出复数结果。MATLAB 自动计算出正确的结果，尽管其结果可能是虚数和复数。例如，在C 和 Fortan 语言中运行函数 sqrt(-2)时将会出现运行时错误。相反地，MATLAB 将会产生虚部答案。</p><pre><code class="highlight matlab">&gt;&gt;  <span class="built_in">sqrt</span>(<span class="number">-2</span>)<span class="built_in">ans</span> =   <span class="number">0.0000</span> + <span class="number">1.4142</span><span class="built_in">i</span></code></pre><h4 id="2-11-画图入门">2.11 画图入门</h4><p>MATLAB 的扩展性和机制独立的画图功能是一个极其重要的功能。这个功能使数据画图变得十分简单。画一个数据图，首先要创建两个向量，由 x, y 构成,然后使用 plot 函数。</p><p>例如，假设我们要画出函数 y=x^2-10x+10 的图象，定义域为[0,10]。只需要 3 个语句就可以画出此图。第二句用于计算 y 值(注意我们用的是数组运算符，所以可以对 x 的元素一一运算)，最后打印出此图。<br>x = 0:1:10;<br>y = x.^2-10*x+15;<br>plot(x,y);</p><p>当执行到 plot 函时，MATLAB 调用图象窗口，并显示图象。</p><p><img src="/medias/1590936892956.png" alt="y=x^2-10x+10 的图象"></p><p>图定义域为(0，10)的 y=x^2-10x+15 的图象</p><p><strong>表 2.8 常见的 MATLAB 函数</strong></p><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">数学函数</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">angle(x)</td><td style="text-align:left">计算复数 x 的幅角</td></tr><tr><td style="text-align:left">asin(x)</td><td style="text-align:left">计算 x 的反正弦函数值</td></tr><tr><td style="text-align:left">atan(x)</td><td style="text-align:left">计算 x 的反正切函数值</td></tr><tr><td style="text-align:left">atan2(y,x)</td><td style="text-align:left">tan.^(-2)(y/x)</td></tr><tr><td style="text-align:left">cos(x)</td><td style="text-align:left">cosx</td></tr><tr><td style="text-align:left">exp(x)</td><td style="text-align:left">e^x</td></tr><tr><td style="text-align:left">log(x)</td><td style="text-align:left"><img src="/medias/1591848156167.png" width="40px"></td></tr><tr><td style="text-align:left">[value,index]=max(x)</td><td style="text-align:left">返回 x 中的最大值，和它所处的位置</td></tr><tr><td style="text-align:left">[value,index]=min(x)</td><td style="text-align:left">返回 x 中的最小值，和它所处的位置</td></tr><tr><td style="text-align:left">mod(x,y)</td><td style="text-align:left">余数</td></tr><tr><td style="text-align:left">sin(x)</td><td style="text-align:left">sinx</td></tr><tr><td style="text-align:left">sqrt(x)</td><td style="text-align:left">x 的平方根</td></tr><tr><td style="text-align:left">tan(x)</td><td style="text-align:left">tanx</td></tr><tr><td style="text-align:left">rounding(取整)函数</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">ceil(x)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">fix(x)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">round(x)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">字符转换函数</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">char(x)</td><td style="text-align:left">将矩阵中的数转化为字符，矩阵中的元素就不大于 127</td></tr><tr><td style="text-align:left">double(x)</td><td style="text-align:left">将子符串转化为矩阵</td></tr><tr><td style="text-align:left">int2str(x)</td><td style="text-align:left">将整数 x 转化为字符串形式</td></tr><tr><td style="text-align:left">num2str(x)</td><td style="text-align:left">将带小数点的数转化为一个字符型数组</td></tr><tr><td style="text-align:left">str2num(x)</td><td style="text-align:left">将字符串转化为数</td></tr></tbody></table><h5 id="2-11-1-简单的-xy-画图">2.11.1 简单的 xy 画图</h5><p>正如我们所看到的,在 MATLAB 中画图是十分容易的。只要任何一对向量的长度相同，那么它就可以就能可视化地画出来。但是这还不是最后的结果，因为它还没有标题,坐标轴标签，网格线。</p><p>给图增加标题和坐标轴标签将会用到 title, xlabel, ylable 函数。调用每个函数时将会有一个字符串，这个字符串包含了图象标题和坐标轴标签的信息。用 grid 命令可使网格线出现或消失在图象中，grid on 代表在图象中出现网格线，grid off 代表去除网格线。例如下面的语句将会产生带有标题，标签和网格线的函数图象。结果如图所示。</p><pre><code class="highlight matlab">x=<span class="number">0</span>:<span class="number">1</span>:<span class="number">10</span>;y=x.^<span class="number">2</span><span class="number">-10</span>*x+<span class="number">15</span>; <span class="built_in">plot</span>(x,y);title (<span class="string">'Plot of y=x.^2-10*x+15'</span>);xlabel (<span class="string">'x'</span>);ylabel (<span class="string">'y'</span>); grid on;</code></pre><p><img src="/medias/1590936892956.png" alt="y=x^2-10x+10 的图象"></p><h5 id="2-11-2-打印图象">2.11.2 打印图象</h5><p>一个图象一旦建立，我们就可以用 print 命令在打印机上打印出这幅图，也可以单击图象窗口的打印图标或者在文件菜单中选择打印项打印。<br>print 命令的一般形式如下：</p><p><strong>print &lt;选项&gt; &lt;文件名&gt;</strong></p><p>如果没有文件名，这个命令就会命令打印机打印当前图片。如果带有文件名，那么这个命令就会打印这个图片到指定的文件。有许多的选项指定输出到文件或打印机的格式。一个最重要的选项是-dtiff.这个选项指定输出图片的格式是标签影像档案格式（TIFF）。因为在 PC，Mac 和 UNIX 平台上的文字处理软件都支持这种格式。这就使得在文档中插入 MATLAB图象变得十分的简单。下面这个命令将会创建一个 TIFF 格式的当前图象的图片，并保存在一个叫 my_image.tif 的文件中</p><p><strong>print –dtiff my_image.tif</strong></p><p>你也可以选择图象窗口中的“file/export”选项来创建 tiff 图片。</p><h5 id="2-11-3-联合作图">2.11.3 联合作图</h5><p>在同一坐标内作出多个函数的图象的情况是十分常见的。假如，你要在同一坐标轴内作出 f(x)=sin2x 和他的微分函数的图象。它的微分式为</p><img src="/medias/1591848226907.png" width="120px"> <pre><code class="highlight matlab">x = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">100</span>:<span class="number">2</span>*<span class="built_in">pi</span>;y1 = <span class="built_in">sin</span>(<span class="number">2</span>*x);y2 = <span class="number">2</span>*<span class="built_in">cos</span>(<span class="number">2</span>*x); <span class="built_in">plot</span> (x,y1,x,y2);</code></pre><p><img src="/medias/1590987466807.png" alt="联合作图"></p><h5 id="2-11-4-线的颜色，线的形式，符号形式和图例">2.11.4 线的颜色，线的形式，符号形式和图例</h5><p>MATLAB 允许程序员选择轨迹的颜色，轨迹的形式，和符号的类型。在 X,Y 向量参数后带有这些属性的字符串的 plot 函数，可以选择这些细节。</p><p>这些属性字符串包括三个方面，第一方面指定轨迹的颜色，第二方面指定符号的类型，第三方面指定线的类型。</p><p>各种颜色，符号和线的类型将在表 2.9 中显示。</p><p><strong>表 2.9 图象的颜色，标记（符号）类型，线型</strong></p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">颜色</th><th style="text-align:center"></th><th style="text-align:center">标记类型</th><th style="text-align:center"></th><th style="text-align:center">线型</th></tr></thead><tbody><tr><td style="text-align:center">y</td><td style="text-align:center">黄色</td><td style="text-align:center">.</td><td style="text-align:center">点</td><td style="text-align:center">-</td><td style="text-align:center">实线</td></tr><tr><td style="text-align:center">m</td><td style="text-align:center">品红色</td><td style="text-align:center">o</td><td style="text-align:center">圈</td><td style="text-align:center">:</td><td style="text-align:center">点线</td></tr><tr><td style="text-align:center">c</td><td style="text-align:center">青绿色</td><td style="text-align:center">x</td><td style="text-align:center">×号</td><td style="text-align:center">-.</td><td style="text-align:center">画点线</td></tr><tr><td style="text-align:center">r</td><td style="text-align:center">红色</td><td style="text-align:center">s</td><td style="text-align:center">正方形</td><td style="text-align:center"><code>--</code></td><td style="text-align:center">虚线</td></tr><tr><td style="text-align:center">g</td><td style="text-align:center">绿色</td><td style="text-align:center">d</td><td style="text-align:center">菱形</td><td style="text-align:center"><code>&lt;none&gt;</code></td><td style="text-align:center">无</td></tr><tr><td style="text-align:center">b</td><td style="text-align:center">蓝色</td><td style="text-align:center">v</td><td style="text-align:center">倒三角</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">w</td><td style="text-align:center">白色</td><td style="text-align:center">^</td><td style="text-align:center">正三角</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">k</td><td style="text-align:center">黑色</td><td style="text-align:center">&gt;</td><td style="text-align:center">三角（向右）</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">&lt;</td><td style="text-align:center">三角(向左)</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">p</td><td style="text-align:center">五角星</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">h</td><td style="text-align:center">六线形</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"><code>&lt;none&gt;</code></td><td style="text-align:center">无</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p>这些属性字符串可以任意的混合使用。如果有多个函数，每个函数都有它自己的属性字符串。</p><p>例如，函数 y=x^2-10x+15 的图象，曲线为红色的虚线，重要的数值用蓝色的小圆圈表示。</p><pre><code class="highlight matlab">x = <span class="number">0</span>:<span class="number">1</span>:<span class="number">10</span>;y = x.^<span class="number">2</span> <span class="number">-10.</span>*x +<span class="number">15</span>; <span class="built_in">plot</span>(x,y,<span class="string">'r--'</span>,x,y,<span class="string">'bo'</span>);</code></pre><p><img src="/medias/1590991499793.png" alt="y=x^2-10x+15 的图象，曲线为红色的虚线，重要的数值用蓝色的小圆圈表示"></p><p>我们可以用 legend 来制作图例。它的基本的形式如下<br>legend(‘string1’,‘string2’,…,pos)</p><p>其中 string1, string2 等等是与轨迹标签名，而 pos 是一个整数，用来指定图例的位置。这些整数所代表的意义在表 2.10 中的列出。用 legend off 命令将能去除多余的图例。一个完整的图象例子如下，产生这个图象的语句如下所示。图在同一坐标系内， 显示了 f(x)=sin2x 和它的微分函数的图象，用黑实线代表 f(x)，用红虚线代表它的微分函数。图中有标题，坐标轴标签和网格线。</p><pre><code class="highlight matlab">x=<span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">100</span>:<span class="number">2</span>*<span class="built_in">pi</span>; y1=<span class="built_in">sin</span>(<span class="number">2</span>*x); y2=<span class="number">2</span>*<span class="built_in">cos</span>(<span class="number">2</span>*x); <span class="built_in">plot</span>(x,y1,<span class="string">'k-'</span>,x,y2,<span class="string">'b--'</span>);title(<span class="string">' Plot of f(x)=sin(2x) and its derivative'</span>); xlabel(<span class="string">'x'</span>);ylabel(<span class="string">'y'</span>); <span class="built_in">legend</span>(<span class="string">'f(x)'</span>,<span class="string">'d/dx f(x)'</span>) grid on;</code></pre><p><img src="/medias/1590991827287.png" alt="f(x)=sin(2x) 和它的微分函数的图象"></p><h5 id="2-11-5-对数尺度">2.11.5 对数尺度</h5><p>打印数据既可以用对数尺度，也可以用线性尺度。在 x,y 轴上使用这两种尺度的一种或两种可以组合形成 4 种不同的坐标系。每一种组合者有一个特定的函数。</p><ol><li>plot 函数的x,y 均用线性尺度</li><li>semilog 函数 x 轴用对数尺度，y 轴将用线性尺度</li><li>semiloge 函数 x 轴用线性尺度，y 轴用对数尺度</li><li>loglog 函数两坐标轴将会都用对数尺度。<br>这四个函数在意义上是等价的，只是坐标轴的类型不同。<br>每一个图象的例子如图 2.8 所示。</li></ol><p><img src="/medias/1590992015387.png" alt="对数尺度"></p><p><strong>表 2.10 在 legend 命令中 pos 的值</strong></p><table><thead><tr><th style="text-align:center">值</th><th style="text-align:left">意义</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:left">自动寻找最佳位置，至少不与数据冲突</td></tr><tr><td style="text-align:center">1</td><td style="text-align:left">在图象的右上角</td></tr><tr><td style="text-align:center">2</td><td style="text-align:left">在图象的左上角</td></tr><tr><td style="text-align:center">3</td><td style="text-align:left">在图象的左下角</td></tr><tr><td style="text-align:center">4</td><td style="text-align:left">在图象的右下角</td></tr><tr><td style="text-align:center">-1</td><td style="text-align:left">在图象的右边</td></tr></tbody></table><h4 id="2-12-例子">2.12 例子</h4><p>下面的例子将向大家介绍如何用 MATLAB 解决问题。</p><h5 id="例-2-3-温度转换">例 2.3 温度转换</h5><p>设计一个 MATLAB 程序，读取一个华氏温度的输入，输出开尔文温度。<br>答案：<br>华氏温度和开尔文温度的转换关系式可在物理学课本中找到。其关系式为：</p><img src="/medias/1591848284960.png" width="380px"> <p>在物理学参考书中举了一些例子，我们可以用来检验我们程序是否正确。例如</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">华氏度 <img src="/medias/1591848340502.png" width="40px"></th><th style="text-align:left">开尔文(K)</th></tr></thead><tbody><tr><td style="text-align:left">沸水的温度</td><td style="text-align:left">212</td><td style="text-align:left">373.15</td></tr><tr><td style="text-align:left">冰水混合物的温度</td><td style="text-align:left">-110</td><td style="text-align:left">194.26</td></tr></tbody></table><p>我们设计程序的步骤如下：</p><ol><li>提示用户键入华氏温度值</li><li>读取输入值</li><li>通过关系式转换为开氏温度</li><li>输出结果，结束</li></ol><p>我们将会用 input 函数输入华氏温度，用 fprintf 函数输出结果。</p><pre><code class="highlight matlab"><span class="comment">% Script file:temp_conversion.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To convert an input temperature from degrees Fahrenheit to</span><span class="comment">% an output temperature in kelvins.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========= ================</span><span class="comment">% 12/01/97 S.J.Chapman Original code</span><span class="comment">%</span><span class="comment">%Define variables:</span><span class="comment">% temp_f --Temperature in degrees Fahrenheit</span><span class="comment">% temp_k --Temperature in kelvins</span><span class="comment">% Prompt the user for the input temperature.</span>temp_f=input(<span class="string">'Enter the temperature in degrees Fahrenheit:'</span>);<span class="comment">% Converttokelvins.</span>temp_k=(<span class="number">5</span>/<span class="number">9</span>)*(temp_f<span class="number">-32</span>)+<span class="number">273.15</span>;<span class="comment">% Writeouttheresult.</span>fprintf(<span class="string">'%6.2f degrees Fahrenheit = %6.2f kelvins.\n'</span>,...temp_f,temp_k);</code></pre><p>我们输入上面的例子中的华氏温度值，以检测程序的正确性。注意用户的输入值已用黑体字标出。</p><pre><code class="highlight matlab">&gt;&gt; temp_conversionEnter the temperature in degrees Fahrenheit:<span class="number">212</span><span class="number">212.00</span> degrees Fahrenheit = <span class="number">373.15</span> kelvins.&gt;&gt; temp_conversionEnter the temperature in degrees Fahrenheit:<span class="number">-110</span><span class="number">-110.00</span> degrees Fahrenheit = <span class="number">194.26</span> kelvins.</code></pre><p>按照惯例，任何输入变量和输出变量的单位都应打印出来.</p><p><strong>当你读取和写入数据时，使用适当的单位</strong></p><h5 id="例-2-4-电子工程：负载的最大输出功率">例 2.4 电子工程：负载的最大输出功率</h5><p><img src="/medias/1591848413073.png" alt="电子工程：负载的最大输出功率题目"></p><p><img src="/medias/1591000303458.png" alt=""></p><pre><code class="highlight matlab">整个程序的代码如下：<span class="comment">% Script file:calc_power.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To calculate and plot the power supplied to a load as</span><span class="comment">% a function of the load resistance.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Descriptionofchange</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/01/98 S.J.Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% amps --Current flow to load(amps)</span><span class="comment">% pl --Power supplied to load(watts)</span><span class="comment">% rl --Resistance of the load(ohms)</span><span class="comment">% rs --Internal resistance of the power source(ohms)</span><span class="comment">% volts --Voltage of the power source(volts)</span><span class="comment">%Set the values of source voltage and internal resistance</span>volts=<span class="number">120</span>;rs=<span class="number">50</span>;<span class="comment">%Create an array of load resistances</span>rl=<span class="number">1</span>:<span class="number">1</span>:<span class="number">100</span>;<span class="comment">%Calculate the current flow for each resistance</span>amps=volts/medias/(rs+rl);<span class="comment">%Calculate the power supplied to the load</span>pl=(amps.^<span class="number">2</span>).*rl;<span class="comment">%Plot the power versus load resistance</span><span class="built_in">plot</span>(rl,pl);title(<span class="string">'Plot of power versus load resistance'</span>);xlabel(<span class="string">'Load resistance(ohms)'</span>);ylabel(<span class="string">'Power(watts)'</span>);grid on;</code></pre><p><img src="/medias/1591000448704.png" alt="运行图"></p><p>当这个程序运行时，产生的图象如上图。从这个图我们可知当负载电阻为 50Ω时， 功率最大。最大功率为 72W。</p><p>注意在本例中，用的是数组运算符.*,.^和/medias/.这些运算符将会使数组 amps 和 pl 按元素一一对应计算。</p><h5 id="例-2-5-用-C-14-确定年代">例 2.5 用 C-14 确定年代</h5><p>一个元素的放射性同位素是不稳定元素的一种特殊形态。在一段时间内，它会自然的衰变为另一种元素。衰变一种呈指数下降的过程。如果 Q0 是放射性物质在 t=0 时的初始量，那么它的质量与变量 t 的关系式为</p><img src="/medias/1591848510747.png" width="120px"> <p>其中 λ 代表衰变率。<br>因为放射性元素的衰变是以一定的速率发生的，我们可以把它当作一个时钟来测定的衰变开始的时间。如果我们知道衰变开始时物质的质量和现在放射性元素剩余的质量，我们可以根据公式(2.8)换算出衰变时间 t，即<br><img src="/medias/1591848535776.png" width="180px"></p><p>公式 2.9 在科学的许多领域有着广泛的应用。例如，考古学家可以根据C14 的衰变周期，来确定古生物距今生活的年代.现在活着的生物 C14 的含量是不变的，所以可以根据古生物 C14 的现存量来确定古生物的生存年代。已知C14 的衰变率 A 为 0.00012097/年，所以如果 C14 的剩余量可以通过测量得到，那么我们就可以根据公式 2.9 算出这个生物活在多少年之前。图 2.1 向大家展示了以时间为自变量的 C14 的剩余量函数。</p><p>编定一个程序，读取样品中 C14 剩余量的百分比，计算样品距今的年代，并打印出结果. 这个问题解决的步骤如下：</p><ol><li>提示用户输入样品中 C14 的剩余量</li><li>读取百分比</li><li>将百分比转化成分数 <img src="/medias/1591848599673.png" width="30px"></li><li>利用公式计算出距今的年数</li><li>输出结果，结束</li></ol><p>代码如下</p><pre><code class="highlight matlab"><span class="comment">% Script file:c14_date.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To calculate the age of an organic sample from the percentage</span><span class="comment">% of the original carbon 14 remaining in the sample.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/02/97 S.J.Chapman Original code</span><span class="comment">%</span><span class="comment">%Define variables:</span><span class="comment">% age --The age of the sample in years</span><span class="comment">% lamda --the radioactive decay constant for carbon-14,in units of 1/years.</span><span class="comment">% percent --The age of carbon 14 remaining at the time of the measurement</span><span class="comment">% ratio --The ratio of the carbon 14 remaining at the time of the measurement to the original amount of carbon 14.</span><span class="comment">%Set decay constant for carbon-14</span>lamda=<span class="number">0.00012097</span>;<span class="comment">%Prompt the user for the percentage of C-14 remaining.</span>percent=input(<span class="string">'Enter the percentage of carbon 14 remaining:\n'</span>);<span class="comment">%Perform calculations</span>ratio=percent/<span class="number">100</span>; <span class="comment">%Convert to fractional ratio</span>age=(<span class="number">-1.0</span>/lamda)*<span class="built_in">log</span>(ratio);<span class="comment">%Get age in years</span><span class="comment">%Tell the user about the age of the sample.</span>string=[<span class="string">'The age of the sample is '</span> num2str(age) <span class="string">'years.'</span>];<span class="built_in">disp</span>(string);</code></pre><p>我们通过计算 C14 的半周期来来测试这个程序<br>测试结果如下:</p><pre><code class="highlight plaintext">&gt;&gt; c14_dateEnter the percentage of carbon 14 remaining:50The age of the sample is 5729.9097years.</code></pre><p>在化学物理 CRC 手册(The CRC Handbook of Chemistry and Physics)中，C14 的半衰期为5730 年。</p><h4 id="2-13-调试-MATLAB-程序">2.13 调试 MATLAB 程序</h4><p>有一个古老的说法，人这一生唯一能够确定的东西是死亡和税收。我们在这里再增加一项，无论你编定多大的程序，你第一次运行时，肯定通不过！程序中的错误我们称之为 BUGS，找出并排出它们，我们称之为调试(debugging)。已知一个程序，而无法运行，我们怎样调试它呢?</p><p>在 MATLAB 中有三种类型的错误。第一种错误是语法错误。语法错误是 MATLAB 自身的错误，例如拼写错误和标点错误。当编译 M 文件时，maltab 编译器将会找出这些错误。例如，语句<br>x=(y+3)/2);<br>有一个语法错误，因为其括号不平衡。</p><p>如果这句存储在 M 文件test.m 中，当 test 编译进，将会出现下面的信息。</p><pre><code class="highlight plaintext">&gt;&gt; test??? Error: File: d:\MATLAB7\work\test.m Line: 1 Column: 10 Unbalanced or misused parentheses or brackets.</code></pre><p>第二种类型的错误是一种运行时错误。当一个非法的数学运算出现在程序的过程(例如，除以 0)，将会出现运行时错误。这些错误将会使程序返回 Inf 或 NaN，用来参与下一步的运算。导致这个程序的结果变无效。</p><p>第三种形式的错误是逻辑错误(logical error)。逻辑错误是指编译和运行都能通过，而产生了错误的结果。</p><p>在编程过程中出现的最普遍的错误是书写错误。一些书写错误可能产生无效的MATLAB 语句。这些错误产生的语法错误可能会被编译器发现。另一个书写错误发生在变量名的书写上。例如，变量中的字符可能被调换，漏写或错写。这样就会创建一个新的变量， 在前面我们已经提到，MATLAB 能够很容易地创造一个新的变量，它不会发现这个错误。书写错误也能导致逻辑错误。例如，如果变量 vel1 和 vel2 都在程序中代表速度，如果一时疏忽用其中一个替代了另一个，那么你就只能用人工检查代码找出此类错误。有的时侯程序开始时能够执行，但是运行时错误和逻辑错误可能在执行中发生。在这种情况下，可能是输入错误，也可能是逻辑结构错误。找出这类错误的第一步是检查程序的输入数据。既可以去掉输入语句后的分号，也可以加入一个多余的输出语句以证明这个输入值是不是你想要的。如果你已经排除了变量名错误和输入值错误，接着你要处理的是逻辑错误。你应该检测是否有逻辑错误，应当检查每一个赋值语句。</p><ol><li>如果一个赋值语句非常的长，把他分成许多小的赋值语句。小的语句易证明。</li><li>检查你的赋值语句中括号的放置。在赋值语句中，由于括号导致运算顺序错误是极其常见的错误。如果你对运算顺序仍有疑问，应该多加括号，使之更加清晰。</li><li>保证每个变量正确的初始化。</li><li>保证函数中用到的单位统一。例如，在三角函数中输入必须是弧度值，而不是角度值。如果你仍然得到的是错误的语句，在更多的位加上输出语句，以检查中间计算。如果你能确定错误的位置，那么你就知道在那里找到问题所在，百分九十五地在这片区域内。如果问题依然存在，那么这时你就应当把你遇到的问题解释给你的同学或老师，让他们给你检查错误。一个人看自己编写的代码找不到错误是非常常见的，而其他的人则可以迅速地找出错误的地方，而这个地方你可能已经看了一次又一次。</li></ol><p><strong>确保你在编程设计过程：</strong><br><strong>1. 初始化所有变量</strong><br><strong>2. 适当应用括号使运算顺序清晰以减少调试的工作量</strong></p><p>在 MATLAB 中有一个专门的调试器，叫做 symbolic debugger. symbolic debugger 允许用户一句一句地执行语句，检测出所有的变量值，它能让你看到所有的中间值，而不用在其中加入输出语句。</p><h4 id="2-14-总结">2.14 总结</h4><p>在本章中，向大家介绍了两种数据类型：double 和 char。我们还向大家介绍了赋值语句，数学计算，常用函数，输入输出语句和数据文件。</p><p>MATLAB 表达的运算顺序遵守一定的规则，即优先级高的先执行，优先级低的后执行。</p><p><strong>表 2.11 运算的优先级</strong></p><table><thead><tr><th style="text-align:center">优先级</th><th style="text-align:left">运算</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:left">括号里的内容先运算，从最里面的括号去运算</td></tr><tr><td style="text-align:center">2</td><td style="text-align:left">幂运算，从左向右</td></tr><tr><td style="text-align:center">3</td><td style="text-align:left">乘除法，从左向右</td></tr><tr><td style="text-align:center">4</td><td style="text-align:left">加减法，从左向右</td></tr></tbody></table><h5 id="2-14-1-好的编程习惯总结">2.14.1 好的编程习惯总结</h5><p>每一个 MATLAB 程序都应让其他熟悉 MATLAB 编程的人容易理解。所以有一个好的编程习惯十分重要，因为它能使一个程序使用很好时间。过了一个段时间，条件可能改变，程序也可能要改变以适应这些变化。修改这个程序的人可能是其他人而不是这个程序的原作者。这个程序员在修改程序之前必须先理解原程序。</p><p>编写清晰，易理解，可维护强的程序要比编写简单的程序要难得多。一个程序员必须发展这方面的能力以证明自己的工作，还有程序必须避免一些常见的错误。下面的指导意见，将有助于你养成好的编程习惯。</p><ol><li>尽可能的使用有意义的变量名，一眼就可以看懂，像 day,month,year。</li><li>给每一个程序创建一个数据字典，以提高程序的可维护性。</li><li>变量名一律用小写字母，这样可以不会因大小写不同而造成变量混淆。</li><li>在所有的 MATLAB 赋值语句的后面加上一个分号，用来禁止赋值的重复。在程序调试期间，如果你检验检某个语句的值，可去掉语句后的分号。</li><li>如果要在 MATLAB 和其他程序之间交换数据，那么就要以 ASCII 格式存储数据.如果数据只应用在此 MATLAB 中那么，应以 mat-file 格式存储数据。</li><li>以”dat”为扩展名保存 ASCII 数据以区分 MAT 文件，MAT 文件的扩展名为 mat。</li><li>用适当的括号使你的表达式清晰，易理解。</li><li>当你读取和写入数据时，使用适当的单位。</li></ol><h5 id="2-14-2-MATLAB-总结">2.14.2 MATLAB 总结</h5><p>下面的总结列举了本章出现的所有特殊符号，命令和函数，后面跟的是简短的描述。 特殊符号</p><table><thead><tr><th style="text-align:left">符号</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">[ ]</td><td style="text-align:left">数组构造器</td></tr><tr><td style="text-align:left">( )</td><td style="text-align:left">用来装载下标</td></tr><tr><td style="text-align:left">’ ’</td><td style="text-align:left">用来限制一个字符串</td></tr><tr><td style="text-align:left">,</td><td style="text-align:left">分开下标，或分开元素</td></tr><tr><td style="text-align:left">;</td><td style="text-align:left">1.防止在命令窗口的重复 <br>2.分开矩阵的行<br> 3.在一行内分开几个赋值语句</td></tr><tr><td style="text-align:left">%</td><td style="text-align:left">标志注释的开始</td></tr><tr><td style="text-align:left">:</td><td style="text-align:left">克隆运算符</td></tr><tr><td style="text-align:left">+</td><td style="text-align:left">数组和矩阵的加法</td></tr><tr><td style="text-align:left">-</td><td style="text-align:left">数组和矩阵的减法</td></tr><tr><td style="text-align:left">.*</td><td style="text-align:left">数组乘法</td></tr><tr><td style="text-align:left">*</td><td style="text-align:left">矩阵乘法</td></tr><tr><td style="text-align:left">/medias/</td><td style="text-align:left">数组右除法</td></tr><tr><td style="text-align:left">.\</td><td style="text-align:left">数组左除法</td></tr><tr><td style="text-align:left">/</td><td style="text-align:left">矩阵右除法</td></tr><tr><td style="text-align:left">\</td><td style="text-align:left">矩阵左除法</td></tr><tr><td style="text-align:left">.^</td><td style="text-align:left">数组幂运算</td></tr><tr><td style="text-align:left">’</td><td style="text-align:left">转义运算符命令和函数</td></tr><tr><td style="text-align:left">…</td><td style="text-align:left">且来表示语句太长，转到第二行写</td></tr><tr><td style="text-align:left">abs(x)</td><td style="text-align:left">计算 x 的绝对值</td></tr><tr><td style="text-align:left">acos(x)</td><td style="text-align:left">计算 x 的反余弦函数</td></tr><tr><td style="text-align:left">angle（x）</td><td style="text-align:left">计算复数 x 的幅角</td></tr><tr><td style="text-align:left">asin（x）</td><td style="text-align:left">计算 x 的反正弦函数值</td></tr><tr><td style="text-align:left">atan（x）</td><td style="text-align:left">计算 x 的反正切函数值</td></tr><tr><td style="text-align:left">atan2（y，x）</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">cos（x）cosx</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">exp（x）</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">log（x）</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">[value,index]=max（x）</td><td style="text-align:left">返回 x 中的最大值，和他所处的位置</td></tr><tr><td style="text-align:left">[value,index]=min（x）</td><td style="text-align:left">返回 x 中的最小值，和他所处的位置</td></tr><tr><td style="text-align:left">mod（x,y）余数，</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">sin（x）sinx</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">sqrt（x）</td><td style="text-align:left">x 的平方根</td></tr><tr><td style="text-align:left">tan（x）tanx</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">rounding(取整)函数</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">ceil(x)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">fix(x)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">round(x)</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">字符转换函数</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">char(x)</td><td style="text-align:left">将矩阵中的数转化为字符，矩阵中的元素就不大于 127</td></tr><tr><td style="text-align:left">double(x)</td><td style="text-align:left">将子符串转化为矩阵</td></tr><tr><td style="text-align:left">int2str(x)</td><td style="text-align:left">将整数 x 转化为字符串形式</td></tr><tr><td style="text-align:left">num2str(x)</td><td style="text-align:left">将带小数点的数转化为一个字符型数组</td></tr><tr><td style="text-align:left">str2num(x)</td><td style="text-align:left">将字符串转化为数</td></tr><tr><td style="text-align:left">format short</td><td style="text-align:left">保留小数点后 4 位（默认格式）</td></tr><tr><td style="text-align:left">format long</td><td style="text-align:left">保留小数点后 14 位</td></tr><tr><td style="text-align:left">format short e</td><td style="text-align:left">带有 5 位有效数字科学记数法</td></tr><tr><td style="text-align:left">format short g</td><td style="text-align:left">总共有 5 个数字，可以用科学记数法，也可不用</td></tr><tr><td style="text-align:left">format long e</td><td style="text-align:left">带有 15 位有效数字科学记数法</td></tr><tr><td style="text-align:left">format long g</td><td style="text-align:left">总共有 5 个数字，可以用科学记数法，也可不用</td></tr><tr><td style="text-align:left">format bank</td><td style="text-align:left">美元格式</td></tr><tr><td style="text-align:left">format hex</td><td style="text-align:left">用 16 进制表示</td></tr><tr><td style="text-align:left">format rat</td><td style="text-align:left">两个小整数的比</td></tr><tr><td style="text-align:left">format compact</td><td style="text-align:left">隐藏多余的换行符</td></tr><tr><td style="text-align:left">format loose</td><td style="text-align:left">使用多余的换行符</td></tr><tr><td style="text-align:left">format +</td><td style="text-align:left">只显示这个数的正负</td></tr><tr><td style="text-align:left">pi</td><td style="text-align:left">有 15 个有效值的π</td></tr><tr><td style="text-align:left">i,j</td><td style="text-align:left">代表虚数 i<img src="/medias/1591849393042.png" width="50px"></td></tr><tr><td style="text-align:left">Inf</td><td style="text-align:left">这个符号代表无穷大，它一般情况下是除以 0 产生的</td></tr><tr><td style="text-align:left">NaN</td><td style="text-align:left">这个符号代表没有这个数。它一般由数学运算得到的。例如，0 除以0</td></tr><tr><td style="text-align:left">clock</td><td style="text-align:left">这个特殊变量包含了当前的年，月，日，时，分，秒，是一个6 元素行向量</td></tr><tr><td style="text-align:left">date</td><td style="text-align:left">包含当前的日期，是用的字符形式</td></tr><tr><td style="text-align:left">eps</td><td style="text-align:left">变量名是 epsilon 的简写。它代表计算能机辨别的两数之间的最小数</td></tr><tr><td style="text-align:left">ans</td><td style="text-align:left">常用于存储表达式的结果，如果这个结果没有明确的赋值于某个变量</td></tr><tr><td style="text-align:left">char</td><td style="text-align:left">字符型</td></tr><tr><td style="text-align:left">plot</td><td style="text-align:left">函数的 x,y 均用线性尺度</td></tr><tr><td style="text-align:left">semilog</td><td style="text-align:left">函数 x 轴用对数尺度，y 轴将用线性尺度</td></tr><tr><td style="text-align:left">Semiloge</td><td style="text-align:left">函数 x 轴用线性尺度，y 轴用对数尺度</td></tr><tr><td style="text-align:left">loglog</td><td style="text-align:left">函数两坐标轴将会都用对数尺度</td></tr></tbody></table><h3 id="第三章-分支语句和编程设计">第三章 分支语句和编程设计</h3><p><strong>两大类控制顺序结构：</strong></p><ol><li><strong>选择结构</strong>：用于选择执行特定的语句。</li><li><strong>循环结构</strong>：用于重复执行特定部分的代码。</li></ol><h4 id="3-1-自上而下的编程方法简介">3.1 自上而下的编程方法简介</h4><p><strong>自上而下的编程方法步骤如下:</strong></p><ol><li><p><strong>清晰地陈述你所要解决的问题</strong><br>程序设计者必须和使用者讨论所需的程序，必须要对完成的任务有一个精确细致的描述。</p></li><li><p><strong>定义程序所需的输入量和程序所产生的输出量</strong><br>指定输入量和输出量，只有这样新的程序才能适应全过程计划。</p></li><li><p><strong>设计你的程序得以实现的算法</strong><br>算法是指为某个问题找到答案一步接一步的程序。在这个阶段自上而下的编程方法发挥了作用。编程设计者开始对这个问题进行逻辑划分，把它逐步分解为一个又一个子工作。这个过程叫做分解(decomposition)。如果一些子工作还是比较大，设计者还可以把他它分解成更小的块。这个过程将会继续到问题被分解成许多简单且易理解的小块为止。</p></li></ol><p>在问题被分解成小块之后，每一个小块要被进一步的求精，这个过程叫做逐步求精(stepwise refinement)。在这个过程中，设计者开始于对本小块代码总括性的描述，然后开始一步一步地定义所需的函数，越来越具体，直到他能够转化为 MATLAB 语句。</p><ol start="4"><li><p><strong>把算法转化为 MATLAB 语句</strong></p></li><li><p><strong>调试 MATLAB 程序</strong><br>首先，程序的每一部分将会被单独地检测，如果有可能的话，整个程序还要被检测一遍。在我们检测程序时，我们必须证明所有合法输入数据值都能够正常运行。用标准的输入值检测程序，看它是否产生了值。如果在一个程序中执行的算法包含了不同的分支，你必须检测每一个分支，以保证产生正确的答案。大程序在交付大众使用之前，必须经过一系列地检测。</p></li></ol><p>检测的第一步有时被称为单元检测(unit testing)。在单元检测过程中， 程序的子程序将会被独立地检测以证明它的正确性。当单元检测结束之后，这个程序将进行一系列的组合，把独立的子程序联合产生出最后的程序。程序第一步的联合通常只包括很少的子程序。通过组合这些子程序，经常用检查子程序或函数之间的联系。在一系列地组合过程中，越来越多的子程序被加了进来，直到整个程序的完成。在每一次组合的过程中，每一个错误都会被发现并在进行下一次组合之前纠正过来。<br><img src="/medias/1591864424519.png" alt="大程序典型地调试过程"></p><p><strong>程序设计的基本步骤如下</strong>:</p><ol><li>清晰地陈述出你要解决的问题。</li><li>确定程序所需地输入量和程序所产生的输出量。</li><li>为你的程序设计算法</li><li>将算法转化为 MATLAB 语句</li><li>调试 MATLAB 程序</li></ol><p><strong>遵循上面的步骤编写可靠，易理解的 MATLAB 程序。</strong></p><p>在计划阶段做好充分的准备和在编程过程使用良好的编程习惯，这样会大大降低我们调试所用的时间。好的编程习惯能减少出错的数量，也能使别人迅速地找出其中的错误。</p><h4 id="3-2-伪代码的应用">3.2 伪代码的应用</h4><p><strong>描述出你要执行的算法是非常必要的</strong>。算法的描述有一种标准形式，能让你和大家都能理解，这种描述将帮助你的内容转化为 MATLAB 代码。我们用于描述算法的标准形式叫做构造(constructs 有时也称 structure)。用这些结构描述出的算法， 我们称之为结构化算法。当在我们在 MATLAB 程序中执行这个算法时，产生的程序叫做结构化程序。</p><p>我们<strong>可以用伪代码的形式建立算法的结构</strong>。<strong>伪代码</strong>是 <strong>MATLAB 和英语的混合体</strong>。和 MATLAB 一样，它是<strong>结构化的，一行表达一个明确的意思或代码的片段，但每一行的描述用的是英语或其他人类语言</strong>。伪代码的每一行都应用普通简单且易于理解的英语或中文描述。因为修改简单灵活，所以伪代码在开发算法的过程中非常的有用。因为伪代码给编辑器或字处理器(通常用于编写 MATLAB 程序)的，而不需要其他的可视化功能。</p><p>temp_f=input(‘Enter the temperature in degrees Fahrenheit:’);<br>temp_k=(5/9)*(temp_f-32)+273.15;<br>fprintf(‘%6.2f degrees Fahrenheit = %6.2f kelvins.\n’,…<br>temp_f,temp_k);<br><strong>的伪代码如下：</strong><br>Prompt user to enter temperature in degrees Fahrenheit<br>Read temperature in degrees Fahrenheit(temp_f)<br>temp_k in kelvins ← (5/9) * (temp_f - 32) + 273.15<br>Write temperature in kelvins</p><p>注意用向左指的箭头 ← 替代等号 (=) 指出一个值将存储到对应的变量中，这样就避免了赋值号与等号的混淆。在把它们转化为 MATLAB  代码之前，伪代码将有助于你思想的组织。</p><h4 id="3-3-关系运算符和逻辑运算符">3.3 关系运算符和逻辑运算符</h4><p><strong>选择结构的运算由一个表达式控制的，这个表达式的结果只有 true(1)和 false(0)</strong>。有两种形式的运算符可以在 MATLAB 中关系得到 true/false：<strong>关系运算符和逻辑运算符</strong>。</p><p>跟 C 语言一样，<strong>MATLAB 没有布尔型和逻辑数据类型</strong>。 <strong>MATLAB 把 0 值作为结果 false，把所有的非 0 值作为结果 ture</strong>。</p><h5 id="3-3-1-关系运算符">3.3.1 关系运算符</h5><p>关系运算符是指两数值或字符操作数的运算符，这种运算将会根据两操作数的关系产生结果 true 或 false 。关系运算的基本形式如下：<br><strong>a1 op a2</strong></p><p>其中 a1 和 a2 是算术表达式，变量或字符串，op 代表表 3.1 中的关系运算符中的一个。如果两者的关系为真（true）时，那么这个运算将会返回 1 值；否则将会返回 0 值。</p><p><strong>表 3.1 关系运算符</strong></p><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">运算</th></tr></thead><tbody><tr><td style="text-align:center">==</td><td style="text-align:left">等于</td></tr><tr><td style="text-align:center">~=</td><td style="text-align:left">不等于</td></tr><tr><td style="text-align:center">&gt;</td><td style="text-align:left">大于</td></tr><tr><td style="text-align:center">&gt;=</td><td style="text-align:left">大于或等于</td></tr><tr><td style="text-align:center">&lt;</td><td style="text-align:left">小于</td></tr><tr><td style="text-align:center">&lt;=</td><td style="text-align:left">小于或等于</td></tr></tbody></table><p>下面是一些关系运算和它的结果运算结果</p><table><thead><tr><th style="text-align:left">运算</th><th style="text-align:center">结果</th></tr></thead><tbody><tr><td style="text-align:left">3 &lt; 4</td><td style="text-align:center">1</td></tr><tr><td style="text-align:left">3 &lt;= 4</td><td style="text-align:center">1</td></tr><tr><td style="text-align:left">3 == 4</td><td style="text-align:center">0</td></tr><tr><td style="text-align:left">3 &gt; 4</td><td style="text-align:center">0</td></tr><tr><td style="text-align:left">4 &lt;= 4</td><td style="text-align:center">1</td></tr><tr><td style="text-align:left">‘A’&lt;‘B’</td><td style="text-align:center">1</td></tr></tbody></table><p>最后一个运算得到的结果为 1，是因为字符之间的求值要按照子母表的顺序。<br><img src="/medias/1591867637594.png" alt="标量与数组的比较"></p><p>注意因为字符串实际上是字符的数组，关系运算符也比较两个相同长度的字符串。如果它们有不同的长度，比较运算将会产生一个错误。</p><p>等于关系运算符由两个等号组成，而赋值运算符只有一个等号。它们是完全不同的两个符号，初学者极易混淆。符号==是一个比较运算符，返回一个逻辑数，而符号=是将等号右边的表达式的值赋给左边的变量。当进行比较运算的时候，初学者经常用误用符号=。</p><p><strong>小心谨慎不要混淆了等于关系运算符（==）和赋值运算符（=）</strong>。</p><p>在运算的层次中，<strong>关系运算在所有数学运算的之后进行</strong>。所以下面两个表达式是等价的， 均产生结果 1。<br>7 + 3 &lt; 2 + 11<br>(7 + 3) &lt; (2 + 11)</p><h5 id="3-3-2-小心-和-运算符">3.3.2 小心==和~=运算符</h5><p>**等于运算符（==）**如果两变量值相同将会返回变量值 1，如果不同将返回 0。</p><p>**不等运算符（~=）**如果两变量值不同则返回 1，相则返回 0。</p><p>用这两个运算符比较两个字符串他是安全的，不会出现错误。</p><p>但对两个数字数据的比较，将可能产生异想不到的错误。两个理论上相等的数不能有一丝一毫的差别，而在计算机计算的过程中出现了近似的现象，从而可能在判断相等与不相等的过程中产生错误，这种错误叫做 round off 错误。例如，考虑下面的两个数，两者均应等于 0。</p><pre><code class="highlight plaintext">a = 0;b = sin(pi);</code></pre><p>因为这两个数在理论上相等的，所以关系式 a==b 应当返回值 1。但在事实上，MATLAB 计算所产生的结果的是</p><pre><code class="highlight matlab">&gt;&gt; a = <span class="number">0</span>;&gt;&gt; b = <span class="built_in">sin</span>(<span class="built_in">pi</span>);&gt;&gt; a == b<span class="built_in">ans</span> =     <span class="number">0</span></code></pre><p>MATLAB 报告了 a 和 b 不同因为他产生了一个 round off 错误，在计算中 sin(pi)产生了结果 1.2246×10^(-16) 而不是 0。两个理论上相等的值因为 round off 误而失之发生了细微的差别。</p><p>我们可以通过检测两数之间在一定的范围内是不是近似相等，在这个精确范围内可能会产生 round off 错误。例如测试</p><pre><code class="highlight matlab">&gt;&gt; <span class="built_in">abs</span>(a - b) &lt; <span class="number">1.0E-14</span><span class="built_in">ans</span> =     <span class="number">1</span></code></pre><p>将会产生正确的结果，不管在 a 与 b 的计算中产不产生的 round off 错误。</p><p><strong>在我们检测两数值是否相等时一定要小心，因为 round off 错误可能会使两个本来应该相等的值不相等了。这时你可以在 round off 错误的范围内它是不是近似相等。</strong></p><h5 id="3-3-3-逻辑运算">3.3.3 逻辑运算</h5><p>逻辑运算符是联系一个或二个逻辑操作数并能产生一个逻辑结果的运算符。有三个二元运算符：分别为 AND，OR 和异或运算符，还有一个一元运算符NOT。</p><p>二元逻辑运算的基本形式： l1 op l2<br>一元逻辑运算的基本形式： op l1</p><p>l1 和 l2 代表表达式或变量，op 代表表 3.2 中的逻辑运算符。如果 l1 和 l2 的逻辑运算关系<br>为 true，那么运算将会返回值 1，否则将会产生 0。</p><p><strong>表 3.2  逻辑运算符</strong></p><table><thead><tr><th style="text-align:center">…</th><th style="text-align:center">…</th></tr></thead><tbody><tr><td style="text-align:center">&amp;</td><td style="text-align:center">逻辑与</td></tr><tr><td style="text-align:center"><img src="/medias/1591869258241.png" width="16px"></td><td style="text-align:center">逻辑或</td></tr><tr><td style="text-align:center">xor</td><td style="text-align:center">逻辑与或</td></tr><tr><td style="text-align:center">~</td><td style="text-align:center">逻辑非</td></tr></tbody></table><p>运算的结果总结在真值表 3.3 中，它向我们展示每一种运算所有可能的结果。如果一个数的值不为 0，那么 MATLAB 将把看作 true，如果它为 0，则其为 false。所以 ~5 的结果为 0，~0 的结果为 1。</p><pre><code>**表 3.3 逻辑真值表**</code></pre><p><img src="/medias/1591869355713.png" alt="逻辑真值表"></p><p><img src="/medias/1591869421815.png" alt=""></p><p>在运算的顺序中，<strong>逻辑运算在所有的数学运算和关系运算之后进行</strong>。</p><p>表达式中的运算顺序如下：</p><ol><li>所有的数学运算按照前面描述的顺序的进行。</li><li>从左向右依次进行关系运算</li><li>执行所有 ~ 运算</li><li>从左向右依次进行 &amp; 运算</li><li>从左向右依次进行 | 运算和数学运算一样，括号能够改变括号的默认顺序。</li></ol><p><strong>例 3.1</strong></p><p>假设下面有三个变量被初始和一些表达式及其运算结果。<br>value1 = 1<br>value2 = 0<br>value3 = -10</p><table><thead><tr><th style="text-align:left">逻辑表达式</th><th style="text-align:center">结果</th></tr></thead><tbody><tr><td style="text-align:left">(a) ~value1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:left">(b) value1 <img src="/medias/1591869258241.png" width="16px"> value2</td><td style="text-align:center">1</td></tr><tr><td style="text-align:left">© value1 &amp; value2</td><td style="text-align:center">0</td></tr><tr><td style="text-align:left">(d) value1 &amp; value2 <img src="/medias/1591869258241.png" width="16px"> value3</td><td style="text-align:center">1</td></tr><tr><td style="text-align:left">(e) value1 &amp; (value2 <img src="/medias/1591869258241.png" width="16px"> value3)</td><td style="text-align:center">1</td></tr><tr><td style="text-align:left">(f) ~(value1 &amp; value3)</td><td style="text-align:center">0</td></tr></tbody></table><p>因为 ~ 运算在其它的逻辑运算之前进行，那么(f)中的括号是必须的。如果去掉括号的话，(f) 表达式将等价于 (~value1)&amp;value3。</p><h5 id="3-3-4-逻辑函数">3.3.4 逻辑函数</h5><p>MATLAB 中有大量的逻辑函数，在条件满足时，函数返回1。条件不满足时，返回0。这些函数和逻辑运算与关系联合在组成选择结构和循环结构。表 3.4 列出了一系列的逻辑函数。</p><p><strong>表 3.4 MATLAB 逻辑函数</strong></p><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:center">用途</th></tr></thead><tbody><tr><td style="text-align:left">ischar(a)</td><td style="text-align:center">a 是字符数组返回 1，否则返回 0</td></tr><tr><td style="text-align:left">isempty(a)</td><td style="text-align:center">a 是空数组返回 1，否则返回 0</td></tr><tr><td style="text-align:left">isinf(a)</td><td style="text-align:center">a 是无穷大，则返回 1，否则返回 0</td></tr><tr><td style="text-align:left">isnan(a)</td><td style="text-align:center">a 不是一个数则返 1，否则返回 0</td></tr><tr><td style="text-align:left">isnumeric(a)a</td><td style="text-align:center">是一个数值数组返回 1，否则返回 0</td></tr></tbody></table><h4 id="3-4-选择结构-分支语句">3.4 选择结构(分支语句)</h4><p>选择结构可以使 MATLAB 选择性执行指定区域内的代码(称之为语句块 blocks)，而跳过其他区域的代码。<strong>选择结构在 MATLAB 中有三种具体的形式:if 结构，switch 结构和 try/ catch 结构。</strong></p><h5 id="3-4-1-if-结构">3.4.1 if 结构</h5><p>if 结构的基本形式如下:<br><img src="/medias/1591871133082.png" alt=""></p><p><img src="/medias/1591871147867.png" alt=""><br>其中 control expression 控制 if 结构的运算。如果 control_expr_1 的值非 0，那么程序将会执行语句块 1(block1)，然后跳到 end 后面的第一个可执行语句继续执行。否则，程序将会检测control_expr_2 的值，。如果control_expr_2 的值非0，那么程序将会执行语句块2(block2)， 然后跳到 end 后面的第一个可执行语句继续执行。如果所有的控制表达式(control expression) 均为 0，那么程序将会执行与 else 相关的语句块。</p><p>**在一个 if 结构中，可以有任意个 elseif 语句，但 else 语句最多有一个。**只要上面每一个控制表达式均为 0，那么下一个控制表达式将会被检测。一旦其中的一个表达式的值非 0， 对应的语句块就要被执行，然后跳到 end  后面的第一个可执行语句继续执行。如果所有的控制表达式(controlexpression)均为 0，那么程序将会执行 else 语句。如果没有 else 语句，程序将会执行 end 后面的语句，而不执行 if 结构中的部分。</p><p>注意 MATLAB 在 if 结构中的关键字 end 与第二章中提到的返回已知下标最大值函数end 完全不同。MATLAB 通过 end 在 M 文件中的上下文来区分开它的两个用途。在大多数情况下，控制表达式均可以联合关系运算符和逻辑运算符。</p><p><img src="/medias/1591871837888.png" alt=""></p><p>假设我们检测某一元二次根的情况，并告诉使用者这个方程有两个复根，还是两个相等的实根和两个不相等的实根。用伪代码这个结构的形式如下:</p><pre><code class="highlight matlab"><span class="keyword">if</span> (b^<span class="number">2</span> - <span class="number">4</span>*a*c) &lt; <span class="number">0</span>    Write msg that equation has two <span class="built_in">complex</span> roots. <span class="keyword">elseif</span> (b^<span class="number">2</span> - <span class="number">4</span>*a*c) ==<span class="number">0</span>    Write msg that equation has two identical <span class="built_in">real</span> roots. <span class="keyword">else</span>    Write msg that equation has two distinct <span class="built_in">real</span> roots.<span class="keyword">end</span></code></pre><p>转化为 MATLAB 语言:</p><pre><code class="highlight matlab"><span class="keyword">if</span> (b^<span class="number">2</span> - <span class="number">4</span>*a*c) &lt; <span class="number">0</span>    <span class="built_in">disp</span>(<span class="string">'This equation has two complex roots.'</span>); <span class="keyword">elseif</span> (b^<span class="number">2</span> - <span class="number">4</span>*a*c) == <span class="number">0</span>    <span class="built_in">disp</span>(<span class="string">'This equation has two identical real roots.'</span>); <span class="keyword">else</span>    <span class="built_in">disp</span>(<span class="string">'This equation has two distinct real roots.'</span>);<span class="keyword">end</span></code></pre><p>回忆一下，判断为真时，关系运算符将会返回一个非 0 值，从而导致对应语句的执行。</p><p><strong>if 结构体经常缩进 2 到 3 个空格，以增强程序的可读性。</strong></p><p>你可以在一行内写完一个完整的 if 结构，只需把结构的每一部分后面加上分号或逗号，所以下面的两个结构是等价的:</p><pre><code class="highlight matlab"><span class="keyword">if</span> x &lt; <span class="number">0</span>    y = <span class="built_in">abs</span>(x);<span class="keyword">end</span></code></pre><p>和</p><pre><code class="highlight matlab"><span class="keyword">if</span> x &lt; <span class="number">0</span>; y = <span class="built_in">abs</span>(x); <span class="keyword">end</span></code></pre><p>但是这种方式只适用于简单的结构。</p><h5 id="3-4-2-if-结构举例">3.4.2 if 结构举例</h5><p><strong>例 3.2</strong></p><p><img src="/medias/1591872749931.png" alt="求一元二次方程的根"></p><p>我们把每一个大块分解成更小的，更细微的工作。根据判别式的值，可能有三种计算途径：</p><ol><li>读取输入的数据</li><li>计算出根</li><li>输入出根</li></ol><p>所以我们要用到有三种选项的 if 结构。产生的伪代码如下</p><pre><code class="highlight matlab">Prompt the user <span class="keyword">for</span> the coefficients a, b, and c. Read  a, b, and c discriminant ← b^<span class="number">2</span> - <span class="number">4</span>*a*c<span class="keyword">if</span> discriminat &gt; <span class="number">0</span>     x1 ← (-b + <span class="built_in">sqrt</span>(discriminant)) / (<span class="number">2</span>*a)     x1 ← (-b - <span class="built_in">sqrt</span>(discriminant)) / (<span class="number">2</span>*a)    Write msg that equation has two distinct <span class="built_in">real</span> roots.     Write out the two roots.<span class="keyword">elseif</span> discriminant == <span class="number">0</span>    x1 ← -b / (<span class="number">2</span>*a)    Write msg that equation has two identical <span class="built_in">real</span> roots.     Write out the repeated roots.<span class="keyword">else</span>    real_part   ← -b / (<span class="number">2</span>*a)     imag_part ← <span class="built_in">sqrt</span>(<span class="built_in">abs</span>(discriminant)) / (<span class="number">2</span>*a)    Write msg that equation has two <span class="built_in">complex</span> roots.     Write out the two roots.<span class="keyword">end</span></code></pre><p><strong>把算法转化为 MATLAB 语言</strong></p><pre><code class="highlight matlab"><span class="comment">% Script file: calc_roots.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program solves for the roots of a quadratic equation</span><span class="comment">% of the form a*x^2 + b*x + c = 0. It calculates the answers</span><span class="comment">% regardless of the type of roots that the equation possesses.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">%DateProgrammerDescription of change</span><span class="comment">%=================================</span><span class="comment">%12/04/98S. J. ChapmanOriginal code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% a--Coefficient of x^2 term of equation</span><span class="comment">% b--Coefficient of x term of equation</span><span class="comment">% c--Constant term of equation</span><span class="comment">% discriminant--Discriminant of the equation</span><span class="comment">% imag_part--Imag part of equation (for complex roots)</span><span class="comment">% real_part--Real part of equation (for complex roots)</span><span class="comment">% x1--First solution of equation (for real roots)</span><span class="comment">% x2--Second solution of equation (for real roots)</span><span class="comment">% Prompt the user for the coefficients of the equation </span><span class="built_in">disp</span> (<span class="string">'This program solves for the roots of a quadratic '</span>);<span class="built_in">disp</span> (<span class="string">'equation of the form A*X^2 + B*X + C = 0.'</span>);a = input(<span class="string">'Enter the coefficient A: '</span>); b = input(<span class="string">'Enter the coefficient B: '</span>); c = input(<span class="string">'Enter the coefficient C: '</span>);<span class="comment">% Calculate discriminant </span>discriminant = b^<span class="number">2</span> - <span class="number">4</span> * a * c;<span class="comment">% Solve for the roots, depending on the vlaue of the discriminant. </span><span class="keyword">if</span> discriminant &gt; <span class="number">0</span><span class="comment">% there are two real roots, so ...</span>    x1 = (-b + <span class="built_in">sqrt</span>(discriminant)) / (<span class="number">2</span>*a);     x2 = (-b - <span class="built_in">sqrt</span>(discriminant)) / (<span class="number">2</span>*a);     <span class="built_in">disp</span>(<span class="string">'This equation has two real roots:'</span>);     fprintf(<span class="string">'x1 = %f\n'</span>, x1);    fprintf(<span class="string">'x2 = %f\n'</span>, x2);<span class="keyword">elseif</span> discriminant == <span class="number">0</span> <span class="comment">% there is one repeated root, so ... </span>    x1 = ( -b ) / (<span class="number">2</span>*a);    <span class="built_in">disp</span>(<span class="string">'This equation has two identical real roots:'</span>);     fprintf(<span class="string">'x1 = x2 = %f\n'</span>, x1);<span class="keyword">else</span> <span class="comment">% there are complex roots, so ... </span>    real_part = (-b) / (<span class="number">2</span>*a);    imag_part = <span class="built_in">sqrt</span>( <span class="built_in">abs</span>(discriminant)) / (<span class="number">2</span>*a);     <span class="built_in">disp</span>(<span class="string">'This equation has complex roots:'</span>);     fprintf(<span class="string">'x1 = %f + i %f \n'</span>,real_part, imag_part);     fprintf(<span class="string">'x1 + %f - i %f \n'</span>, real_part, imag_part);<span class="keyword">end</span></code></pre><p><strong>检测这个程序</strong><br>下一步，我们必须输入实数来检测这个程序。因这个程序有三个可能的路径。所以在我们确信每一人路径都工作正常之前，必须把这三个路径检测一遍。从式子中，我们可以有用下面的方法来验证程序的正确性。<br>x^2 + 5x + 6 = 0x = -2, and x = -3<br>x^2 + 4x + 4 = 0x = -2<br>x^2 + 2x + 5 = 0x = -1 <img src="/medias/1591873746489.png" width="26px"> i2</p><p>如果输入上面三个方程的系数得到对应的结果，则说明程序是正确的。</p><pre><code class="highlight plaintext">This program solves for the roots of a quadratic equation of the form A*X^2 + B*X + C = 0.Enter the coefficient A: 1Enter the coefficient B: 5Enter the coefficient C: 6This equation has two real roots:x1 = -2.000000x2 = -3.000000This program solves for the roots of a quadratic equation of the form A*X^2 + B*X + C = 0.Enter the coefficient A: 1Enter the coefficient B: 4Enter the coefficient C: 4This equation has two identical real roots:x1 = x2 = -2.000000This program solves for the roots of a quadratic equation of the form A*X^2 + B*X + C = 0.Enter the coefficient A: 1Enter the coefficient B: 2Enter the coefficient C: 5This equation has complex roots:x1 = -1.000000 + i 2.000000 x1 + -1.000000 - i 2.000000</code></pre><p>在三种不同的情况下，程序都给出了正确的结果。</p><p><strong>例 3.3</strong><br><img src="/medias/1591874210682.png" alt=""></p><pre><code class="highlight matlab">Prompt the user <span class="keyword">for</span> the values x and yRead x and y <span class="keyword">if</span> x≥<span class="number">0</span> and y≥<span class="number">0</span>    fun ← x + y <span class="keyword">elseif</span> x≥<span class="number">0</span> and y&lt;<span class="number">0</span>    fun ← x + y^<span class="number">2</span> <span class="keyword">elseif</span> x&lt;<span class="number">0</span> and y≥<span class="number">0</span>    fun ← x^<span class="number">2</span> + y <span class="keyword">else</span>    fun ← x^<span class="number">2</span> + y^<span class="number">2</span><span class="keyword">end</span>Write out f(x,y)</code></pre><p><strong>转化为 MATLAB 语句</strong><br>最终的代码如下：</p><pre><code class="highlight matlab"><span class="comment">% Scripte file: funxy.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program solves the function f(x,y) for a</span><span class="comment">% user-specified x and y, where f(x,y) is defined as:</span><span class="comment">%        _</span><span class="comment">%        |</span><span class="comment">%        | x + y       x &gt;= 0 and y &gt;= 0</span><span class="comment">%        | x + y^2     x &gt;= 0 and y &lt; 0 </span><span class="comment">% f(x,y)=| x^2 + y     x &lt; 0 and y &gt;= 0</span><span class="comment">%        | x^2 + y^2   x &lt; 0 and y &lt; 0</span><span class="comment">%        |_</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">%   Date    Programmer  Description of change</span><span class="comment">%   =====   =========     ================</span><span class="comment">% 12/05/98  S.J.Chapman     Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% x     --First independent variable</span><span class="comment">% y     --Second independent variable</span><span class="comment">% fun   --Resulting function</span><span class="comment">% Prompt the user for the values x and y </span>x = input(<span class="string">'Enter the x coefficient: '</span>);y = input(<span class="string">'Enter the y coefficient: '</span>);<span class="comment">% Calculate the function f(x,y) based upon</span><span class="comment">% the signs of x and y. </span><span class="keyword">if</span> x&gt;=<span class="number">0</span> &amp; y&gt;=<span class="number">0</span>    fun = x + y; <span class="keyword">elseif</span> x&gt;=<span class="number">0</span> &amp; y&lt;<span class="number">0</span>    fun = x + y^<span class="number">2</span>; <span class="keyword">elseif</span> x&lt;<span class="number">0</span> &amp; y&gt;=<span class="number">0</span>     fun = x^<span class="number">2</span> + y;<span class="keyword">else</span>    fun = x^<span class="number">2</span> + y^<span class="number">2</span>;<span class="keyword">end</span><span class="comment">% Write the value of the function.</span><span class="built_in">disp</span>([<span class="string">'The vlaue of the function is '</span> num2str(fun)]);</code></pre><p><strong>检测程序</strong><br>下一步，我们必须输入实数来检测这个程序。因这个程序有四个可能的路径。所以在我们确信每一人路径都工作正常之前，必须把这四个路径检测一遍。我们分别取 4 个象限内的值(2，3)，(-2,3)，(2，-3)和(-2，-3)。我们用手工计算可得<br>f(2,3) = 2 + 3 = 5<br>f(2,-3) = 2 + (-3)^2 = 11<br>f(-2,3) = (-2)^2 + 3 = 7<br>f(-2,-3) = (-2)^2 + (-3)^2 = 13<br>当程序被编程后，运行 4 次并输入相应的值，运算结果如下:</p><pre><code class="highlight matlab">&gt;&gt; funxyEnter the x coefficient: <span class="number">2</span>Enter the y coefficient: <span class="number">3</span>The vlaue of the <span class="function"><span class="keyword">function</span> <span class="title">is</span> 5</span>&gt;&gt; funxyEnter the x coefficient: <span class="number">2</span>Enter the y coefficient: <span class="number">-3</span>The vlaue of the <span class="function"><span class="keyword">function</span> <span class="title">is</span> 11</span>&gt;&gt; funxyEnter the x coefficient: <span class="number">-2</span>Enter the y coefficient: <span class="number">3</span>The vlaue of the <span class="function"><span class="keyword">function</span> <span class="title">is</span> 7</span>&gt;&gt; funxyEnter the x coefficient: <span class="number">-2</span>Enter the y coefficient: <span class="number">-3</span>The vlaue of the <span class="function"><span class="keyword">function</span> <span class="title">is</span> 13</span></code></pre><h5 id="3-4-3-关于-if-结构使用的注意事项">3.4.3 关于 if 结构使用的注意事项</h5><p>if 结构是非常灵活的，它必须含有一个 if 语句和一个 end 语句。中间可以有任意个 elseif 语句，也可以有一个 else 语句。联合它的这些特性，我们可以创建出我们需要的各种各样的选择结构。</p><p>还有 if 语句是可以嵌套的。如果 if 结构完全是另一个 if 结构的一个语句块，我们就称两者为嵌套关系。下面是两个 if 语句的嵌套。</p><pre><code class="highlight matlab"><span class="keyword">if</span> x &gt; <span class="number">0</span>    ...    <span class="keyword">if</span> y &lt; <span class="number">0</span>        ...    <span class="keyword">end</span>    ...<span class="keyword">end</span></code></pre><p>MATLAB 翻译器经常把把已知的 end 语句和它最近的 if 语句联合在一起，所以第一个<br>end 语句和 if y&lt;0 最靠近，而第二个 end 与 if x&gt;0 最接近。对于一个编写正确的程序，它能工作正常。但如果程序员编写出错误，它将会使编译器出现混淆性错误信息提示。例如，假设我们编写一个大的程序，包括如下的一个结构:</p><pre><code class="highlight matlab">...<span class="keyword">if</span> (test1)    ...    <span class="keyword">if</span> (test2)        ...        <span class="keyword">if</span> (test3)        ...        <span class="keyword">end</span>        ...    <span class="keyword">end</span>    ...<span class="keyword">end</span></code></pre><p>这个程序包括了三个嵌套的 if 结构，在这个结构中可能有上千行的代码。现在假设第一个 end 在编辑区域突然被删除，那么 MATLAB 编译器将会自动将第二个 end 与最里面的if (test3)结构联合起来，第三个 end 将会和中间的 if(test2)联合起来。当编译器翻译到达文件结束的时候，那将发现第一个 if(test1)结构将永远没有结束，然后编译器就会产生一个错误提示信息，即缺少一个 end。但是，它不能告诉你问题发生在什么地方，这就使我们必须回过头去看整个程序，来找问题。</p><p>在大多数情况下，执行一个算法，即可以用多个 else if 语句，也可以用 if 语句的嵌套。在这种情况下，程序员可以选择他喜欢的方式。</p><p><strong>例 3.4</strong><br><strong>给出等级分数</strong><br>假设我们要编写一个程序，输入一个数值分数，输出等级分数，即是 A 级，B 级和 C 级</p><pre><code class="highlight plaintext">      grade &gt; 95A 95 2' grade &gt; 86B86 2' grade &gt; 76C76 2' grade &gt; 66D66 2' grade &gt; 0    F</code></pre><p>用两种方式写出这个程序，第一种方式用多个 elseif 语句，第二种方式用 if 的嵌套。<br>答案:<br>(a)用多个 elseif 语句</p><pre><code class="highlight matlab"><span class="keyword">if</span> grade &gt; <span class="number">95.0</span>    <span class="built_in">disp</span>(<span class="string">'The grade is A.'</span>); <span class="keyword">elseif</span> grade &gt; <span class="number">86.0</span>    <span class="built_in">disp</span>(<span class="string">'The grade is B.'</span>); <span class="keyword">elseif</span> grade &gt;<span class="number">76.0</span>    <span class="built_in">disp</span>(<span class="string">'The grade is C.'</span>); <span class="keyword">elseif</span> grade &gt; <span class="number">66.0</span>    <span class="built_in">disp</span>(<span class="string">'The grade is D.'</span>); <span class="keyword">else</span>    <span class="built_in">disp</span>(<span class="string">'The grade is F.'</span>);<span class="keyword">end</span></code></pre><p>(b)用 if 嵌套结构</p><pre><code class="highlight matlab"><span class="keyword">if</span> grade &gt; <span class="number">95.0</span>    <span class="built_in">disp</span>(<span class="string">'The grade is A.'</span>); <span class="keyword">else</span>    <span class="keyword">if</span> grade &gt; <span class="number">86.0</span>        <span class="built_in">disp</span>(<span class="string">'The grade is B.'</span>);     <span class="keyword">else</span>        <span class="keyword">if</span> grade &gt; <span class="number">76.0</span>            <span class="built_in">disp</span>(<span class="string">'The grade is C.'</span>);         <span class="keyword">else</span>            <span class="keyword">if</span> grade &gt; <span class="number">66.0</span>                <span class="built_in">disp</span>(<span class="string">'The grade is D.'</span>);             <span class="keyword">else</span>                <span class="built_in">disp</span>(<span class="string">'The grade is F.'</span>);            <span class="keyword">end</span>        <span class="keyword">end</span>    <span class="keyword">end</span><span class="keyword">end</span></code></pre><p>从上面的例子中，我们可以看到如果有多个选项的话，在一个 if 结构中用到多个 else if 语句将会比 if 的嵌套结构简单的多。</p><p><strong>对于有许多选项的选择结构来说，最好在一个 if 结构中使用多个 elseif 语句，尽量不用 if 的嵌套结构。</strong></p><h5 id="3-4-4-switch-结构">3.4.4 switch 结构</h5><p>switch 结构是另一种形式的选择结构。程序员可以根据一个单精度整形数，字符或逻辑表达式的值来选择执行特定的代码语句块。<br><img src="/medias/1591876912517.png" alt=""></p><p>如果 switch_expr 的值与case_expr_1 相符，那么第一个代码块将会被执行，然后程序将会跳到 switch 结构后的第一个语句。如果 switch_expr 的值与 case_expr_2 相符，那么第二个代码块将会被执行，然后程序将会跳到 switch 结构后的第一个语句。在这个结构中，用相同的方法来对待其他的情况。otherwise 语句块是可选的。如果它存在的话，当 switch_expr 的值与其他所有的选项都不相符时，这个语句块将会被执行。如果它不存在，且witch_expr 的值与其他所有的选项都不相符，那么这个结构中的任何一个语句块都不会被执行。这种情况下的结果可以看作没有选择结构，直接执行 MATLAB 语言。</p><p>如果说 switch_expr 有很多值可以导致相同代码的执行，那么这些值可以括在同一括号内，如下所示。如果这个 switch 表达式和表中任何一个表达式相匹配，那么这个语句块将会被执行。<br><img src="/medias/1591877065260.png" alt=""><br>switch_expr 和每一个 case_expr 既可以是数值，也可以是字符值。</p><p>注意在大多情况下只有一个语句块会被执行。当一个语句块被执行后，编译器就会跳到end 语句后的第一个语句开始执行。如果 switch 表达和多个 case 表达式相对应，那么只有他们中的第一个将会被执行。</p><p>让我们看一个简单的关于 switch 结构的例子。下面的语句用来判断 1 到 10 之间的数是奇数还是偶数。它用来说明一系列的 case 选项值的应用和 otherwise 语块的应用。</p><p>switch (value)<br>case {1, 3, 5, 7, 9},<br>disp(‘The value is odd.’);<br>case {2, 4, 6, 8, 10},<br>disp(‘The value is even.’);<br>otherwise,<br>disp(‘The value is out of range.’);<br>end</p><h5 id="3-4-5-try-catch-结构的应用">3.4.5 try/catch 结构的应用</h5><p>try/catch 结构是选择结构的一种特殊形式，用于捕捉错误。一般地，当一个 MATLAB 程序在运行时遇到了一个错误，这个程序就会中止执行。try/catch 结构修改了这个默认行为。</p><p><strong>如果一个错误发生在这个结构的 try 语句块中，那么程序将会执行 catch 语句块，程序将不会中断。它将帮助程序员控制程序中的错误，而不用使程序中断。</strong></p><p>Try/catch 结构的基本形式如下:<br><img src="/medias/1591877354008.png" alt=""></p><p><strong>当程序运行到 try/catch 语句块，在 try 语句块中的一些语句将会被执行。如果没有错误出现，catch 语句块将会被跳过。另一方面，如果错误发生在一个 try 语句块，那么程序将中止执行 try 语句块，并立即执行 catch 语句块。</strong></p><p>下面有一个包含 try/catch 结构程序。它能创建一个数组，并询问用户显示数组中的哪能一个元素。用户提供一个下标，那么这个程序将会显示对应的数组元素 try 语句块一般会在这个程序中执行，只有当 try 语句块执行出错，catch 语句块将会发生错误。</p><pre><code class="highlight matlab"><span class="comment">% Initialize array </span>a = [ <span class="number">1</span> <span class="number">-3</span> <span class="number">2</span> <span class="number">5</span>];<span class="keyword">try</span>    <span class="comment">% Try to display an element</span>    index = input(<span class="string">'Enter subscript of element to display: '</span>);     <span class="built_in">disp</span>([<span class="string">'a('</span> int2str(index) <span class="string">') = '</span> num2str(a(index))] );<span class="keyword">catch</span>    <span class="comment">% If we get here an error occurred</span>    <span class="built_in">disp</span>( [<span class="string">'Illegal subscript: '</span> int2str(index)] );<span class="keyword">end</span></code></pre><p>这个程序的执行结果如下：</p><pre><code class="highlight matlab">Enter subscript of element to display: <span class="number">3</span> a(<span class="number">3</span>) = <span class="number">2</span>Enter subscript of element to display: <span class="number">8</span> Illegal subscript: <span class="number">8</span></code></pre><h4 id="3-5-附加的画图特性">3.5 附加的画图特性</h4><p>在本节中，我们将讨论简单的二维图象(在第二章我们已有所介绍)的附加特性。这些特性将允许我们控制 x，y 轴上的值的范围，在一个坐标系内打印多个图象，或创建多个图， 或在一个图象窗口内创建多个子图像，或提供更加强大的轨迹文本字符控制。还有，我们将向大家如何创建极坐标。</p><h5 id="3-5-1-控制-x，y-轴绘图的上下限">3.5.1 控制 x，y 轴绘图的上下限</h5><p>在默认的情况下，图象的 X，Y 轴的范围宽到能显示输入值的每一个点。但是有时只显示这些数据的一部分非常有用，这时你可以应用 axis 命令/函数。</p><p>axis 命令/函数的一些形式展示在表 3.5 中。其中两个最重要的形式在表中用黑体字标出它允许程序员设定和修改坐标的上下限。所有形式的完全列表将会在 MATLAB 的在线文件中找到。</p><p>为了说明 axis 的应用，我们将画出函数 f(x)=sinx 从 -2π 加到 2π 加之间的图象，然后限定坐标的区域为0≤x≤π，0≤y≤1。</p><p><strong>表 3.5 axis 函数/命令的形式</strong></p><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:center">功能</th></tr></thead><tbody><tr><td style="text-align:left">v=axis</td><td style="text-align:center">此函数将会返回一个 4 元素行向量[xmin xmax ymin ymax]，其中 xmin xmax ymin ymax 代表 x，y 轴的上下限</td></tr><tr><td style="text-align:left">axis([xmin xmax ymin ymax])</td><td style="text-align:center">xmin xmax 设定横轴的下限及上限， ymin ymax 设定纵轴的下限及上限</td></tr><tr><td style="text-align:left">axis equal</td><td style="text-align:center">将横轴纵轴的尺度比例设成相同值</td></tr><tr><td style="text-align:left">axis square</td><td style="text-align:center">横轴及纵轴比例是 1:1</td></tr><tr><td style="text-align:left">axis normal</td><td style="text-align:center">以预设值画纵轴及横轴</td></tr><tr><td style="text-align:left">axis off</td><td style="text-align:center">将纵轴及横轴取消</td></tr><tr><td style="text-align:left">axis on</td><td style="text-align:center">这个命令打开所有的轴标签，核对符号，背景(默认情形)</td></tr></tbody></table><p>一些 MATLAB 命令似乎不能确定它是个函数还是一个命令。例如，有时 axis 它好像是命令，有时它好像是函数。有时我们把它当作命令:axis on，在其他时候，我们把他当作函数:axis([0 20 0 35])。遇到这样的情况怎么办?</p><p>一个简单的答案是 MATLAB 命令是通过函数来实现的。MALTAB 编译器无论什么时候遇到这个命令，它都能转化为相应的函数。它把命令直接当作函数来用，而不是应用命令语法。下面的两个语句是等价的：</p><pre><code class="highlight plaintext">axis on; axis ('on');</code></pre><p>无论什么时候 MATLAB遇到一个命令时，它都会转化一个函数，当命令的参数当作字符串看作相对应函数的参数。所以编译器翻译如下命令:<br><strong>garbage 1 2 3</strong><br>为<br><strong>garbage (‘1’, ‘2’, ‘3’)</strong><br>注意只有带有字符参数的函数才能当作命令。带有数字参数的函数只能被当作函数。这就是为什么 axis 有时当作命令，有时被当作函数。</p><pre><code class="highlight matlab">x=<span class="number">-2</span>*<span class="built_in">pi</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="number">2</span>*<span class="built_in">pi</span>; y=<span class="built_in">sin</span>(x);<span class="built_in">plot</span>(x,y);title(<span class="string">'Plot of sin(x) vs x'</span>);</code></pre><p>当前图象坐标轴的上下限的大小由函数 axis 得到。</p><pre><code class="highlight matlab">&gt;&gt; limits=axislimits =    <span class="number">-8</span><span class="number">8</span>  <span class="number">-1</span>  <span class="number">1</span></code></pre><p>修改坐标轴的上下限可以调用函数 axis([0 pi 0 1])。<br>当这个函数执行后，产生的图象如图 3.3（b）所示。</p><p><img src="/medias/1591878704975.png" alt="sin(x)"></p><h5 id="3-5-2-在同一坐标系内画出多个图象">3.5.2 在同一坐标系内画出多个图象</h5><p>在一般情况下，<strong>创建一个新的图象就要用到一个 plot 命令，前面的数据就会自动消失。这种行为可以通过使用 hold 命令得到修改。当 hold on 命令执行后，所有的新的图象都会叠加在原来存在的图象。hold off 命令可恢复默认情况，用新的图象来替代原来的图象。</strong></p><p>例如，在同一坐标轴内的画出 sinx 和 cosx 的图象。产生的图象如图 3.4 所示。</p><pre><code class="highlight matlab">x = -<span class="built_in">pi</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="built_in">pi</span>; y1 = <span class="built_in">sin</span>(x);y2 = <span class="built_in">cos</span>(x); <span class="built_in">plot</span>(x,y1,<span class="string">'b-'</span>); <span class="built_in">hold</span> on; <span class="built_in">plot</span>(x,y2,<span class="string">'k--'</span>); <span class="built_in">hold</span> off;<span class="built_in">legend</span> (<span class="string">'sin x'</span>,<span class="string">'cos x'</span>);</code></pre><p><img src="/medias/1591879350767.png" alt="图3.4 用hold命令在一个坐标内画出两个函数的图象"></p><h5 id="3-5-3-创建多个图象">3.5.3 创建多个图象</h5><p>MATLAB 可以创建多个图象窗口，每个窗口都有不同的数据。我们用图象数来区分这些图象窗口，图象数是一个小的正整数。第一个图象窗口称为图 1，第二个图象窗口为图 2， 依次类推。这些窗口中的一个称为当前图象窗口，所有的新的画图命令将会展示在那个窗口中。</p><p>我们用 figure 函数来选择当前窗口。这个函数的形式为“figure(n)”，其中 n 代表图象数。当这个函数被执行后，图 n 将会变为当前图象，执行所有的画图命令。如果这个图象窗口不存在，那么 MATLAB 将会自动创建。当前图象也可以用鼠标单击选择。</p><p>gcf 函数用于当于返回当前图象数。当你需要知道当前图象数时，你就把这个函数写入 M 文件中。</p><p>下面的命令用于说明图函数的应用。它将创建两个图象，第一个用来展示 e^x 的图象，第二个用来展示 e^(-x) 的图象。</p><pre><code class="highlight plaintext">figure(1);x = x:0.05:2;y1 = exp(x); plot(x,y1); figure(2);y2 = exp(-x);plot(x,y2);</code></pre><p><img src="/medias/1591879760289.png" alt=""></p><h5 id="3-5-4-子图象">3.5.4 子图象</h5><p>在一个图象窗口中有一系列的坐标系，创建出多个子图象。创建子图象要用到 subplot 命令其形式如下<br><strong>subplot(m,n,p)</strong></p><p>这个命令在当前图象窗口创建了 m×n 个子图象，按 m 行，n 列排列，并选择子图象 p 来接受当前所有画图命令。</p><p>这些子图象以从左向右从上到下编号。例如，命令 subplot(2,3,4) 将会创建 6 个子图象， 而且 subplot 4 是当前子图象。</p><p>如果 subplot 命令创建的新坐标系与原来的坐标系相冲突，那么原来的坐标系将会被自动删除。</p><p>下面的命令将会在同一窗口中创建两个子图象，每一个子图象独立地展示不同的图象。</p><pre><code class="highlight plaintext">figure(1); subplot(2,1,1); x = -pi:pi/20:pi; y = sin(x);plot(x,y); title('Subplot 1 title'); subplot(2,1,2);x = -pi:pi/20:pi; y = cos(x);plot(x,y); title('Subplot 2 title');</code></pre><p>产生的图象如图：<br><img src="/medias/1591887610689.png" alt=""></p><h5 id="3-5-5-对画线的增强控制">3.5.5 对画线的增强控制</h5><p>在第二章中，学习了如何设置画线的颜色，样式，符号形式。还可以设置其中的 4 种附加的属性。</p><table><thead><tr><th style="text-align:left">属性</th><th>说明</th></tr></thead><tbody><tr><td style="text-align:left">LineWidth</td><td>用来指定线的宽度</td></tr><tr><td style="text-align:left">MarkerEdgeColor</td><td>用来指定标识表面的颜色</td></tr><tr><td style="text-align:left">MarkerFaceColor</td><td>填充标识的颜色</td></tr><tr><td style="text-align:left">MarkerSize</td><td>指定标识的大小</td></tr></tbody></table><p>在 plot 命令中，在自变量和函数之后被指定，形式如下：</p><p><strong>plot(x,y,‘PropertyName’,value,…)</strong></p><p>例如，下面的命令将画出一个图象，轨迹的宽度为3，颜色为黑色，圆圈标识的宽度为</p><p>6，每个标识为红色边缘和绿色内核，如图 3.6。</p><pre><code class="highlight matlab"><span class="built_in">disp</span> (<span class="string">'该功能练习plot额外四个属性功能'</span>);<span class="comment">%初始化快捷式数组</span><span class="built_in">figure</span>(<span class="number">1</span>);x=<span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">15</span>:<span class="number">4</span>*<span class="built_in">pi</span>;y=<span class="built_in">exp</span>(<span class="number">2</span>*<span class="built_in">sin</span>(x));<span class="built_in">plot</span>(x,y,<span class="string">'-ko'</span>,<span class="string">'LineWidth'</span>,<span class="number">3.0</span>,<span class="string">'MarkerSize'</span>,<span class="number">6</span>,...    <span class="string">'MarkerEdgeColor'</span>,<span class="string">'r'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'g'</span>); <span class="comment">%red green</span>title(<span class="string">'exp(2*sin(x))图形'</span>);</code></pre><p><img src="/medias/20200613140236076.png" alt="说明LineWidth和Marker的属性"></p><h5 id="3-5-6-文本字符串的高级控制">3.5.6 文本字符串的高级控制</h5><p>在画图中可能要用到文本字符串(比如标题，坐标轴标签)，这些字符串可以用黑体，斜体来格式化，也包括特殊的希腊或数学符号。</p><p>文本的字体通可以通过 stream modifiers 修改。一个 stream modifier 是一个特殊的字符序列，用来告诉编译器改变它的行为。最普通的 stream modifiers 是:</p><table><thead><tr><th>-</th><th>-</th></tr></thead><tbody><tr><td>\bf</td><td>黑体</td></tr><tr><td>\it</td><td>斜体</td></tr><tr><td>\rm</td><td>恢复正常字体</td></tr><tr><td>\fontname</td><td>字体的名字</td></tr><tr><td>\fontsize</td><td>字体的大小</td></tr><tr><td>_{xxx}</td><td>xxx 做为某字符的上标</td></tr><tr><td>^{xxx}</td><td>xxx 做为某字符的下标</td></tr></tbody></table><p>一旦一个 stream modifier 插入一个文本字符串中，它持续发挥作用，直到这个字符串的结束或消失。如果一个 modifier 后在跟着一个{}，只有{}中的文本起作用。</p><p>特殊的希腊字母或数学符号也可用在文本字符串中。通过嵌入特殊的转义序列来创建这些字符。这些转义序列是支持 <em>TEX</em> 语言的特殊序列的一个子集。在表 3.6 中向大家展示一些转义序列代码的例子。所有转义序列可以在 <strong>MATLAB</strong> 在线帮助文本中找到。</p><p>如果要打印转义符\，{，}，_，或^就必须在前面加上一个反斜杠。下面的例子用于说明 stream modifier 和特殊字符的应用。</p><table><thead><tr><th>字符串</th><th>结果</th></tr></thead><tbody><tr><td><img src="/medias/20200613155732633.png" width="260px"></td><td><img src="/medias/20200613155456536.png" width="120px"></td></tr><tr><td><img src="/medias/20200613155952612.png" width="260px"></td><td><img src="/medias/20200613160252203.png" width="180px"></td></tr><tr><td><img src="/medias/20200613160058484.png" width="114px"></td><td><img src="/medias/20200613160445791.png" width="32px"></td></tr></tbody></table><p><img src="/medias/20200613163917704.png" alt="表 3.6 精选的希腊符号和数学符号"></p><h5 id="3-5-7-极坐标图象">3.5.7 极坐标图象</h5><p><strong>MATLAB</strong> 中包括一个重要的函数叫做 polar，它用于在极坐标系中画图。这个函数的基本形式如下:</p><p><strong>polar(theta,r)</strong></p><p>其是 theta 代表一个弧度角数组，r 代表一个距离数组。它用来画以角度为自变量的函数的极坐标图是非常有用的。</p><h6 id="例-3-5-心形麦克风">例 3.5 心形麦克风</h6><p><img src="/medias/20200613170639296.png" alt="心形麦克风"></p><p>代码如下：</p><pre><code class="highlight matlab"><span class="comment">% Script file: microphone.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program plots the gain pattern of a cardioid</span><span class="comment">% microphone.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/10/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% g -- Microphone gain constant</span><span class="comment">% gain -- Gain as a function of angle</span><span class="comment">% theta -- Angle from microphone axis (radians)</span><span class="comment">% Calculate gain versus angle </span>g = <span class="number">0.5</span>;theta = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="number">2</span>*<span class="built_in">pi</span>;gain = <span class="number">2</span>*g*(<span class="number">1</span>+<span class="built_in">cos</span>(theta));<span class="comment">% Plot gain</span>polar (theta,gain,<span class="string">'r-'</span>);title (<span class="string">'Gain versus angle \it\theta'</span>);</code></pre><p><img src="/medias/20200613181756132.png" alt="心形麦克风的增益图象"></p><h6 id="例-3-6-低通滤波电路">例 3.6 低通滤波电路</h6><p><img src="/medias/20200613181951589.png" alt="电器工程低通滤波电路"></p><p>代码如下：</p><pre><code class="highlight matlab"><span class="comment">% Script file: plot_filter.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program plots the amplitude and phase responses</span><span class="comment">% of a low-padd RC filter.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/29/98 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% amp   -- Amplitude response</span><span class="comment">% C     -- Capacitiance (farads)</span><span class="comment">% f -- Frequency of input signal (Hz)</span><span class="comment">% phase -- Phase response</span><span class="comment">% R     -- Resistance (ohms)</span><span class="comment">% res   -- Vo/Vi</span><span class="comment">% Initialize R &amp; C</span>R = <span class="number">16000</span>; <span class="comment">% 16 k ohms </span>C = <span class="number">1.0E-6</span>; <span class="comment">% 1 uF</span><span class="comment">% Create array of input frequencies </span>f = <span class="number">1</span>:<span class="number">2</span>:<span class="number">1000</span>;<span class="comment">% Calculate response</span>res = <span class="number">1</span> /medias/ ( <span class="number">1</span> + <span class="built_in">j</span>*<span class="number">2</span>*<span class="built_in">pi</span>*f*R*C );<span class="comment">% Calculate amplitude response </span>amp = <span class="built_in">abs</span>(res);<span class="comment">% Calculate phase response </span>phase = <span class="built_in">angle</span>(res);<span class="comment">% Create plots </span>subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>); loglog( f, amp );title(<span class="string">'Amplitude Response'</span>); xlabel(<span class="string">'Frequency (Hz)'</span>); ylabel(<span class="string">'Output/Input Ratio'</span>); grid on;subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>); semilogx( f, phase );title(<span class="string">'Phase Response'</span>); xlabel(<span class="string">'Frequency (Hz)'</span>);ylabel(<span class="string">'Output-Input Phase (rad)'</span>); grid on;</code></pre><p>得到的结果如图  所示。注意这个电路叫做低通滤波电路，是因为在低频下，电压很</p><p>少衰减，在高频下，电压衰减的很厉害。</p><p><img src="/medias/20200613182537878.png" alt=""></p><h6 id="例-3-7-热力学：理想气体定律">例 3.7 热力学：理想气体定律</h6><p>热力学：理想气体定律</p><p>理想气体是指发生在分子之间的碰撞均为弹性碰撞。你可以把理想气体中的每一个分子想象成一个刚性小弹，每次碰撞，总动能不会改变。这样的气体可以用三个变量来描述：绝对气压（<em>P</em>），体积（<em>V</em>）和绝对温度（<em>T</em>）。三者之间的关系式就是我们所熟知的理想气体定律。</p><p><em>PV=nRT</em>              (3.5)</p><p><em>P</em> 代表气压，单位为千帕，<em>V</em> 代表气体的体积，单位为升，<em>n</em> 代表分子的摩尔数，<em>T</em> 代表绝对温度，单位为开。</p><p>假设一理想气体样品在 273K 温度下，有一摩尔分子，回答相关问题。</p><p>（a）当气压从 1 到 1000 千帕变化，气体的体积将会如何变化？设置合适的坐标，画出这个气体的压力 体积图象。</p><p>（b）假设这个气体的温度上升到 373K，气体体积将会随气压如何变化。在与（a）相同的坐标系内，画出气体的压力 体积图象。轨迹用虚绿线，宽度为 2pixel。在图象上包含有一个大标题，x，y 轴的标签，还有各轨迹的图例。</p><p>答案：因为我们画的值都有一千个因子，所以一个普通线性尺度坐标不能画出有效的图象。所以，我们在画图时，用 log-log 标度。注意我们必须在相同的坐标系下，画出两个曲线，所以我们必须在画完第一个图象后加入 hold on 命令，当所有画图结束后，用上 hold off 命令。我们也必须指定轨迹的颜色，样式和宽度，并指定标签为黑体。</p><p>下面的程序创建了气压的函数 <em>V</em>(气体的体积)的图象。注意那些控制图象样式的语句， 我们已用黑体标出。</p><pre><code class="highlight matlab"><span class="comment">% Script file: ideal_gas.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">%This program plots the pressure versus volumn of an</span><span class="comment">%ideal gas.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">%  Date      Programmer   Description of change</span><span class="comment">%  ====       ========      ===================</span><span class="comment">% 07/17/00   S.J.Chapman  Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% n   --Number of atoms (mol)</span><span class="comment">% P   --Pressure (kPa)</span><span class="comment">% R   --Ideal gas constant (L kPa/mol K)</span><span class="comment">% T   --Temperature (K)</span><span class="comment">% V   --volume (L)</span><span class="comment">% Initialize nRT</span>n = <span class="number">1</span>;<span class="comment">% Moles of atoms </span>R = <span class="number">9.314</span>;<span class="comment">% Ideal gas constant </span>T = <span class="number">273</span>;<span class="comment">% Temperature (K)</span><span class="comment">% Create array of input pressures. Note that this</span><span class="comment">% array must be guite dense to catch the major</span><span class="comment">% changes in volume at low pressures. </span>P = <span class="number">1</span>:<span class="number">0.1</span>:<span class="number">1000</span>;<span class="comment">% Calculate volumes </span>V = (n * R * T) /medias/ P;<span class="comment">% Create first plot. </span><span class="built_in">figure</span>(<span class="number">1</span>);loglog(P, V, <span class="string">'r-'</span>, <span class="string">'LineWidth'</span>, <span class="number">2</span>); title(<span class="string">'\bfVolume vs Pressure in an Ideal Gas'</span>); xlabel(<span class="string">'\bfPressure (kPa)'</span>);ylabel(<span class="string">'bfVolume (L)'</span>); grid on;<span class="built_in">hold</span> on;<span class="comment">% Now increase temperature</span>T = <span class="number">373</span>;<span class="comment">% Temperature (K)</span><span class="comment">% Calculate volumes </span>V = (n * R * T) /medias/ P;<span class="comment">% Add second line to plot </span><span class="built_in">figure</span>(<span class="number">1</span>);loglog(P, V, <span class="string">'b--'</span>, <span class="string">'LineWidth'</span>, <span class="number">2</span>); <span class="built_in">hold</span> off;<span class="comment">% Add legend</span><span class="built_in">legend</span>(<span class="string">'T = 273 K'</span>, <span class="string">'T = 373 K'</span>);</code></pre><p><img src="/medias/20200613185727920.png" alt="理想气体的 V-P 图象"></p><h5 id="3-5-8-注释并保存图象">3.5.8 注释并保存图象</h5><p>一旦 <strong>MATLAB</strong> 成功创建一个图象，那么用户就可以运画图工具条上的 GUI 工具来编辑和注释这些图象。图 3.11 向大家展示了这些可用的工具，它允许我们添加直线，带箭头的线，还有文本。当工具条中的编辑按钮被选中，注释和翻译工具将会变得可用。</p><p>还有，当编辑按钮被按下，单击图象中的任何一条线或一个文本，它们将会处于可编辑状态，如果双击它们将会弹出一个属性窗口，允许我们修改这个对象的每一项属性。编辑修改后，把绿线改成了 3pixel 宽的虚线，并加上了箭头和注释。</p><p>当这个图象的编辑和注释完成后，你可以一种可修改的格式存储整个图象，方法选择图象窗口中的”file/save as”菜单项。产生的图象文件(*.fig)包含了用于重建这个图象的所有信息，也就是说在未来的任何时侯你都可以轻松的重建这个图象。</p><p><img src="/medias/20200613191725011.png" alt="应用图工具条中的纺辑工具改变了蓝线的样式并添加了注释"></p><h4 id="3-6-程序调试的进一步说明">3.6 程序调试的进一步说明</h4><p>在含有选择结构和循环结构的程序出错的概率要比只含简单的顺序结构的程序出错的概率大得多。在完成了程序设计的步骤之后，无论多大的一个程序，在第一次运行时都很难通过。假如我们创建了一个程序并调试它，只发现这个程序的输出是错误的。我们怎样找到这些错误并修改它呢?</p><p>一旦程序包含了循环和选择结构，找到错语的最好的方法是应用 <strong>MATLAB</strong> 支持的符号调试器(symbolic debugger)。这个调试器将会整合到 <strong>MATLAB</strong> 编辑器中。</p><p><strong>当一个程序执行时，我们想知道什么事情发生了。为了达到此目的，我们可以用鼠标右击你所关心的行并选择”set/clear breakpoint”选项。当一个断点被设置后，一个红色的点将会出现在行的左边。</strong></p><p><img src="/medias/20200613200439138.png" alt=""></p><p><strong>一旦这些断点被设置，在命令窗口键入 calc_roots 将会像往常一样执行这个程序。这个程序将会运行到第一个断点并在那里停止。在调试的过程中将会有一个绿色的箭头将会出现在当前行。</strong></p><p><strong>一旦到达某个断点程序员可以通过在命令窗口中键入变量名的方法检查或修改在工作区内的任一变量。当程序员对程序的这一点感到满意时，可以通过重复按 F10 一行一行调试， 也可以按 F5 运行到下一个断点。它总是能检测程序中的每一个断点中的任何一个变量的值。</strong></p><p>调试器的另处一个重要特性是可在 Breakpoints 菜单中找到。这个菜单包括两个项目： “stop if Error”和“stop if warning”。如果程序中发生了一个错误，这个错误导致了电脑死机或产生了错误信息，程序员可以打开这些选项，并执行这个程序。这个程序将会运行到错误或警告的断点并停在那儿，它允许程序员检查变量的每一个值，并帮助找出出错的原因。当一个错误被发现，程序员能用编辑器来更正这个 MALTAB 程序，并把更新的版本存到磁盘上，在调试没结束之前，它必须重复以上的动作。这个步骤将会重复下去直到这个程序没有错误出错。</p><p>现在花一定的时间来熟悉这个调试器这是值得的。</p><h4 id="3-7-总结">3.7 总结</h4><p>在本章中，向大家展示了基本的 <strong>MATLAB</strong> 选择结构，还有控制这个结构的<strong>关系运算符和逻辑运算符</strong>。这个结构的其本类型是 <strong>if 结构</strong>。这个结构<strong>非常的灵活</strong>。如果这个结构需要的话，它<strong>可以跟任意多个 elseif 语句</strong>，<strong>if 结构可以进行嵌套组成更复杂的结构</strong>。第二种选择结构是 <strong>switch 结构</strong>，它<strong>提供多项选择</strong>。第三种选择结构是 <strong>try/catch 结构</strong>。它<strong>用于跳过错误以保证程序的继续进行</strong>。</p><p>第三章向大家介绍了更多的画图方法。<strong>axis 命令允许程序员指定 X，Y 轴的取值范围</strong>。<strong>hold 命令允许程序员把后面的图象叠加到原来的图象上打印</strong>。<strong>图命令允许程序员创建和选择多个图象窗口</strong>。<strong>subplot 命令允许程序在一个图象窗中创建多个子图象</strong>。</p><p>还有，<strong>学习如何控制画图的附加功能，例如线的宽度和符号的颜色</strong>。这些属性可由指定的“propertyname”和值 Value 决定，“propertyname”和值 Value 将出现在plot 命令的数据后。运用流编辑器和转义序列将会增强对文本字符串的控制。用流字符串允许程序员指定相应的特性，例如字符的粗斜体，上下标和字体大小，字体类别。我们可以应用转义序列允许在文本中加入特殊的字符，比如说希腊字符和数学符号。</p><h5 id="3-7-1-好的编程习惯的总结">3.7.1 好的编程习惯的总结</h5><p>在有选择结构和循环结构的编程中，要遵循以下的编程指导思想。如果你长期坚持这些原则，你的代码将会有很少的错误，有了错误也易于修改，而且在以后修改程序时，也使别人易于理解。</p><ol><li><strong>在我们检测两数值是否相等时一定要小心，因为 round off 错误可能会使两个本来应该相等的值不相等了。这时你可以在 round off 错误的范围内它是不是近似相等</strong>。</li><li><strong>遵守基本编程设计步骤来编写可靠，易理解的 MATLAB 的程序</strong>。</li><li><strong>在 if 结构和 switch 语句中，语句块要缩进两个空格</strong></li></ol><h5 id="3-7-2-MATLAB-总结">3.7.2 MATLAB 总结</h5><p>下面的总结列举了本章出现的所有特殊符号，命令和函数，后面跟的是简短的描述。</p><table><thead><tr><th>-</th><th>-</th></tr></thead><tbody><tr><td>v=axis</td><td>此函数将会返回一个 4 元素行向量[xmin xmax ymin ymax]， 其中 xmin xmax ymin ymax 代表x，y 轴的上下限</td></tr><tr><td>axis([xmin xmax ymin ymax])</td><td>以 xmin xmax 设定横轴的下限及上限，以 ymin ymax 设定纵轴的下限及上限</td></tr><tr><td>axis equal</td><td>将横轴纵轴的尺度比例设成相同值</td></tr><tr><td>axis square</td><td>横轴及纵轴比例是 1:1</td></tr><tr><td>axis normal</td><td>以预设值画纵轴及横轴</td></tr><tr><td>axis off</td><td>将纵轴及横轴取消</td></tr><tr><td>axis on</td><td>这个命令打开所有的轴标签，核对符号，背景(默认情形)</td></tr></tbody></table><h3 id="第四章-循环结构">第四章 循环结构</h3><p>循环(loop)是一种 <strong>MATLAB</strong> 结构，它允许我们多次执行一系列的语句。循环结构有两种基本形式: <strong>while 循环和 for 循环</strong>。两者之间的最大不同在于代码的重复是如何控制的。在 <strong>while 循环</strong>中，<strong>代码的重复的次数是不能确定的，只要满足用户定义的条件，重复就进行下去</strong>。相对地，在 <strong>for 循环中</strong>，<strong>代码的重复次数是确定的，在循环开始之前，我们就知道代码重复的次数了</strong>。</p><h4 id="4-1-while-循环">4.1 while 循环</h4><p>只要满足一定的条件，while 循环是一个重复次数不能确定的语句块。它的基本形如下：</p><pre><code class="highlight matlab"><span class="keyword">while</span> expression...-|...|-&gt; code block..._|<span class="keyword">end</span></code></pre><p>如果 expression 的值非零(true)，程序将执行代码块(code block)，然后返回到 while 语句执行。如果 expression 的值仍然非零，那么程序将会再次执行代码。直到 expression 的值变为 0，这个重复过程结束。当程序执行到 while 语句且 expression 的值为 0 之后，程序将会执行 end 后面的第一个语句。</p><p>while 循环的伪代码为：</p><pre><code class="highlight matlab"><span class="keyword">while</span> expr.........<span class="keyword">end</span></code></pre><p>用 whlie 循环编写一个统计分析的程序。</p><h5 id="例-4-1-计算平均值和标准差">例 4.1 计算平均值和标准差</h5><p>统计分析在科学工程计算中，跟大量的数据打交道是非常平常的事，这些数据中的每一个数据都是对我们关心的一些特殊值的度量。</p><p>许多的时侯，我们并不关心某一个单个数据。我们可以通过总结得到几个重要的数据， 以此告诉我们数据的总体情况。例如，一组数据的平均数(数学期望)和标准差。平均数的定义如下:</p><img src="/medias/20200615152053161.png" style="zoom:50%;"><p>其中 x~i~  代表 <em>n</em> 个样本中的第 <em>i</em> 个样本。如果所有的输入数据都可以在一个数组中得到， 这些数据的平均数就可以通过公式(4.1)直接计算出来，或应用 <strong>MATLAB</strong> 的内建函数 mean。</p><p>标准差的定义如下:</p><img src="/medias/20200615152555036.png" style="zoom: 67%;"><p>标准差则体现随机变量取值与其期望值的偏差。标准差的值较大，则表明该随机变量的取值与其期望值的偏差较大，反之，则表明此偏差较小。如果所有的输入数据都可以在一个数组中得到，这些数据的平均数就可以通过公式(4.2)直接计算出来，或应用 <strong>MATLAB</strong> 的内建函数 std。本例的目的是要通过公式 4.1，4.2 计算平均数和标准差，介绍 while 循环的应用。我们要执行的算法是读取一个组数据，计算它们的平均数和标准差，最后输出结果。</p><p><strong>答案:</strong></p><p>程序必须能读取一系列的测量值，并能够计算出这些测量值的数学期望和标准差。在进行计算之前，我们有 while 循环来读取这些测量值。</p><p>当所有的测量值输入完毕，我们必须通过一定的方法来告诉程序没有其它的数据输入了。在这里，我们假设所有测量值均为非负数，我们用一个负数来表示数据输入完毕。当一个负数输入时，程序将停止读取输入值，并开始计算这些数据的数学期望和方差。</p><ol><li><p>陈述问题因为我们假设所有的输入数据为非负数，则合适地问题陈述为:计算一组测量数的平均数和方差，假设所有测量值为非负数;假设我们事先不知道有多少个测量数。一个负数的输入值将代表测量值输入的结束。</p></li><li><p>定义输入值和输出值这个程序的输入是未知数目的非负数。输出为这些非负数的平均数和标准差。顺便还要打印出输入数据的数据，以便于检测程序的正确性。</p></li><li><p>设计算法这个程序可分为以下三大步:</p></li></ol><pre><code class="highlight 过程">Accumulate the input dataCalculate the mean and standard deviationWrite out the mean, standard deviation, and number of points</code></pre><p>每一大步的为读取输入值。为达此目的，我们必须提示用户输入合适的值。当数据输入完毕，我们将计算出数据的个数，它们的和与平方和。这些步骤的伪代码如下所示</p><pre><code class="highlight 伪代码">Initialize n, sum_x, and sum_x2 to 0 Prompt user for first numberRead in first x while x &gt;=0n ← n+1sum_x ← sum_x + xsum_x2 ← sum_x2 + x^2 Prompt user for next number Read in next xend</code></pre><p>注意我们必须在 while 循环开始之前，我们必须读取第一个值，这样在 while 循环第一次运行中才有了检测值。</p><p>下一步，我们要计算出数学期望和标准差。这个步骤的伪代码就是公式（4.1）和(4.2) 的 <strong>MATLAB</strong> 版本。</p><pre><code class="highlight matlab">x_bar ← sum_x/n std_dev ← <span class="built_in">sqrt</span>((n*num_x2 – sum_x^<span class="number">2</span>)/(n*(n<span class="number">-1</span>)))</code></pre><p>最后我们写出输出结果:</p><pre><code class="highlight plaintext">Write out the mean value x_barWrite out the standard deviation std_dev Write out the number of input data points n</code></pre><ol start="4"><li>将伪代码转化为相应的 <strong>MATLAB</strong> 语句最终的 <strong>MATLAB</strong> 程序如下</li></ol><pre><code class="highlight matlab"><span class="comment">% Script file: stats_1.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To calculate mean and the standard deviation of</span><span class="comment">% an input data set containing an arbitrary number</span><span class="comment">% of input values.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/05/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% n -- The number of input samples</span><span class="comment">% std_dev -- The standard deviation of the input samples</span><span class="comment">% sum_x -- The sum of the input values</span><span class="comment">% sum_x2 -- The sum of the squares of the input values</span><span class="comment">% x -- An input data value</span><span class="comment">% xbar -- The average of the input samples</span><span class="comment">% Initialize sums.</span>n = <span class="number">0</span>; sum_x = <span class="number">0</span>; sum_x2 = <span class="number">0</span>;<span class="comment">% Read in first value</span>x = input(<span class="string">'Enter first value: '</span>);<span class="comment">% While Loop to read input values. </span><span class="keyword">while</span> x &gt;= <span class="number">0</span><span class="comment">% Accumulate sums. </span>n = n + <span class="number">1</span>;sum_x = sum_x + x; sum_x2 = sum_x2 + x^<span class="number">2</span>;<span class="comment">% Read in next value</span>x = input(<span class="string">'Enter next value: '</span>);<span class="keyword">end</span><span class="comment">% Calculate the mean and standard deviation </span>x_bar = sum_x / n;std_dev = <span class="built_in">sqrt</span>( (n * sum_x2 - sum_x^<span class="number">2</span>) / (n * (n<span class="number">-1</span>)) );<span class="comment">% Tell user.</span>fprintf(<span class="string">'The mean of this data set is: %f\n'</span>, x_bar); fprintf(<span class="string">'The standard deviation is: %f\n'</span>, std_dev); fprintf(<span class="string">'The number of data points is: %f\n'</span>, n);</code></pre><ol start="5"><li>检测程序为检测这个程序，我们将手工算出一组简单数据的平均数和标准差，然后与程序产生的结果进行比对。如果我们用三个输入值:3，4 和 5，那么它的平均数和标准差分别为</li></ol><img src="/medias/20200615153654748.png" style="zoom: 67%;"><p>我们把这些值输入程序后，产生的结果为</p><pre><code class="highlight plaintext">&gt;&gt; stats_1Enter first value: 3 Enter next value: 4 Enter next value: 5 Enter next value: -1The mean of this data set is: 4.000000 The standard deviation is: 1.000000 The number of data points is: 3.000000</code></pre><p>这个结果说明了程序的正确性。在这个例子中，我们并没有完全遵循设计过程。这个失误导致这个软件有一个致命的缺陷。你能指出来它吗?</p><p>我们的错误就在于我们没有检测程序所有可能的输入类型。请重看一遍程序。如果我们不输入数或者只输入一个数，那么上面的公式就会出现除以 0 的情况。这种除 0 错误将会在导致在命令窗口内出现 divide-by-zero 的警告，导致输出值为无穷大(NaN)。我们需要修改这个程序来解决这个问题，告诉用户这个问题是什么，并在适当的时侯停止。这个程序的修定版本为 stats_2。在运行运算之前，我们必须检查是否有足够多的输入值。如果没有，程序将打印出错误提示信息，并且跳出。你自己检测一下这个版本的程序。</p><pre><code class="highlight matlab"><span class="comment">% Script file: stats_2.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To calculate mean and the standard deviation of</span><span class="comment">% an input data set containing an arbitrary number</span><span class="comment">% of input values.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/05/97 S. J. Chapman Original code</span><span class="comment">% 1. 12/06/97 S. J. Chapman Correct divide-by-0 error if</span><span class="comment">% 0 or 1 input values given.</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% n -- The number of input samples</span><span class="comment">% std_dev -- The standard deviation of the input samples</span><span class="comment">% sum_x -- The sum of the input values</span><span class="comment">% sum_x2 -- The sum of the squares of the input values</span><span class="comment">% x -- An input data value</span><span class="comment">% xbar -- The average of the input samples</span><span class="comment">% Initialize sums.</span>n = <span class="number">0</span>; sum_x = <span class="number">0</span>; sum_x2 = <span class="number">0</span>;<span class="comment">% Read in first value</span>x = input(<span class="string">'Enter first value: '</span>);<span class="comment">% While Loop to read input values. </span><span class="keyword">while</span> x &gt;= <span class="number">0</span><span class="comment">% Accumulate sums. </span>n = n + <span class="number">1</span>;sum_x = sum_x + x; sum_x2 = sum_x2 + x^<span class="number">2</span>;<span class="comment">% Read in next value</span>x = input(<span class="string">'Enter next value: '</span>);<span class="keyword">end</span><span class="comment">% Check to see if we have enough input data.</span><span class="keyword">if</span> n &lt; <span class="number">2</span> <span class="comment">% Insufficient information</span><span class="built_in">disp</span>(<span class="string">'At least 2 values must be entered!'</span>); <span class="keyword">else</span> <span class="comment">% There is enough information, so calculate the mean and standard deviation</span>x_bar = sum_x / n;std_dev = <span class="built_in">sqrt</span>((n * sum_x2 - sum_x^<span class="number">2</span>) / (n * (n<span class="number">-1</span>)));<span class="comment">% Tell user.</span>fprintf(<span class="string">'The mean of this data set is: %f\n'</span>, x_bar); fprintf(<span class="string">'The standard deviation is: %f\n'</span>, std_dev); fprintf(<span class="string">'The number of data points is: %f\n'</span>, n);<span class="keyword">end</span></code></pre><p>注意平均数和标准差可以通过 <strong>MATLAB</strong> 的内建函数 mean 和 std 计算得到，输入数据存储在一个向量内，并把向量作为函数的参数。在本章章末的练习中，将会要求你用标准的 <strong>MATLAB</strong> 函数创建一个新的版本程序。</p><h4 id="4-2-for-循环">4.2 for 循环</h4><p>for 循环结构是另一种循环结构，它以指定的数目重复地执行特定的语句块。For 循环的形式如下:</p><pre><code class="highlight plaintext">for index = expr Statement 1--|... |-&gt; BodyStatement n--|end</code></pre><p>其中index 是循环变量（就是我们所熟知的循环指数），exp 是循环控制表达式。变量 index  读取的是数组 expr 的行数，然后程序执行循环体（loopbody），所以 expr 有多少列，循环体就循环多少次。expr 经常用捷径表达式的]方式，即 first:incr:last。</p><p>在 for 和 end 之前的语句我们称之为循环体。在 for 循环运转的过程中，它将被重复的执行。For 循环结构函数如下：</p><ol><li><p>在 for 循环开始之时，<strong>MATLAB</strong> 产生了控制表达式</p></li><li><p>第一次进入循环，程序把表达式的第一列赋值于循环变量 index，然后执行循环体内的语句。</p></li><li><p>在循环体的语句被执行后，程序把表达式的下一列赋值于循环变量 index，程序将再一次执行循环体语句。</p></li><li><p>只要在控制表达式中还有剩余的列，步骤 3 将会一遍一遍地重复执行。我们要举大量的例子来说明 for 循环的操作。</p></li></ol><p>第一，考虑下面的例子</p><pre><code class="highlight plaintext">for ii = 1:10Statement 1...Statement nend</code></pre><p>在这种情况下，控制表达式产生了一个 1×10 数组，所以语句 1 到n 将会被重复执行 10 次。循环系数 ii 在第一次执行的时侯是 1，第二次执行的时侯为 2，依次类推，当最后一次执行时，循环指数为 10。在第十次执行循环体之后，再也没有新的列赋值给控制表达式， 程序将会执行 end 语句后面的第一句。注意在循环体在最后一次执行后，循环系数将会一直为 10。</p><p>第二，考虑下面的例子。</p><pre><code class="highlight plaintext">for ii = 1:2:10 Statement 1...Statement nend</code></pre><p>在这种情况下，控制表达式产生了一个 1×5 数组，所以语句 1 到n 将会执行 5 次。循环指数 ii 在第一次执行时为 1，第二次执行时为 3，依此类推，最后一次执行时为 9。在第五次执行循环体之后，再也没有新的列赋值给控制表达式，程序将会执行 end 语句后面的第一句。注意在循环体在最后一次执行后，循环系数将会一直为 9。</p><p>第三，考虑下面的例子。</p><pre><code class="highlight plaintext">for ii = [5 9 7]Statement 1...Statementnend</code></pre><p>在这里，控制表达式是一个直接写出的 1×3 的数组，所以语句 1 到n 将会执行 3 次，循环指数 ii 在第一次执行时为 1，第二次执行时为 3，第三次执行时为 7。循环指数在循环结束之后一直为 7。</p><p>最后，考虑下面的例子。</p><pre><code class="highlight plaintext">for ii = [1 2 3; 4 5 6]Statement 1...Statement nend</code></pre><p><img src="/medias/20200615155819567.png" alt=""></p><pre><code class="highlight plaintext">for index = expression Statement 1...Statement nend</code></pre><h5 id="例-4-2-阶乘（factorial）函数">例 4.2 阶乘（factorial）函数</h5><p><strong>阶乘（factorial）函数</strong></p><p>为了说明 for 循环操作，我们将用 for 循环来计算阶乘函数。阶乘函数的定义如下：</p><pre><code class="highlight plaintext">N!=1N=0N!=N * (N-1) * (N-2) * ... * 3 * 2 * 1  N&gt;0</code></pre><p>计算 N 的阶乘的 <strong>MATLAB</strong> 代码为：</p><pre><code class="highlight matlab">n_factorial = <span class="number">1</span> <span class="keyword">for</span> ii = <span class="number">1</span> : nn_factorial = n_factorial * ii;<span class="keyword">end</span></code></pre><p>假设我们要计算 5 的阶乘。如果 n 为 5，for 循环控制表达式将会产生行向量[1 2 3 4 5]。这种循环将会执行 5 次，ii 值按先后顺序依次为 1，2，3，4，5。n_factorial 最终的计算结果为 1×2×3×4×5=120。</p><h5 id="例-4-3-计算-the-day-of-year">例 4.3 计算 the day of year</h5><p><strong>计算 the day of year</strong></p><p>the day of year 是指这一年已经逝去的天数（包括当天）。在平年中，它的取值范围为 1 到 365，在闰年中，它的取值范围 1 到 366。编写一个 <strong>MATLAB</strong> 程序，输入年，月，日， 输入为对应的 the of year。</p><p><strong>答案：</strong></p><p>为了确定 the day of year，程序需要计算先前月份的天数之后，然后再计算当月已经过去了多少天，在求和的过程中将会用到 for 循环。因为每一个月的天数不尽相同，所以我们要确定每一个月的正确天数。我们用 switch 结构来确定它。</p><p>在闰年时，在二月后的某一天的 the day of year 将会比平年时大 1。因为在闰年的二月份多出一个 2 月 29 号。所以为了正确地计算出 the day of year，我们必须确定那一年是闰年。在公历中，闰年是这样规定的：</p><ol><li><p>能被 400 整除的年为闰年</p></li><li><p>能被 100 整除但不能被 400 整除的年不为闰年</p></li><li><p>能被 4 整除但不能被 100 整除年为闰年</p></li><li><p>其余的年份不为闰年</p></li></ol><p>我们将用到 mod（求余）函数来确定一个数是否能被另一个数整除。如果函数的返回值为 0，则说一个数能被另一个数整除，否则，则不然。</p><p>下面是一个用于计算 the day of year 的程序。注意程序如何计算出前面月份总共的天数， 如何应用 switch 结构确定每一月的天数。</p><pre><code class="highlight matlab"><span class="comment">% Script file: doy.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program calculates the day of year corresponding</span><span class="comment">% to a specified date. It illustrates the use switch</span><span class="comment">% and for constructs.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/07/98 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% day        --Day (dd)</span><span class="comment">% day_of_year--Day of year</span><span class="comment">% ii        --Loop index</span><span class="comment">% leap_day    --Extra day for leap year</span><span class="comment">% month        --Month (mm)</span><span class="comment">% year        --Year(yyyy)</span><span class="comment">% Get day, month, and year to convert</span><span class="built_in">disp</span>(<span class="string">'This program calculates the day of year given the '</span>); <span class="built_in">disp</span>(<span class="string">'current date.'</span>);month = input(<span class="string">'Enter current month (1-12):'</span>); day = input(<span class="string">'Enter current day(1-31):'</span>);year = input(<span class="string">'Enter current year(yyyy): '</span>);<span class="comment">% Check for leap year, and add extra day if necessary </span><span class="keyword">if</span> <span class="built_in">mod</span>(year,<span class="number">400</span>) == <span class="number">0</span>leap_day = <span class="number">1</span>; <span class="comment">% Years divisible by 400 are leap years </span><span class="keyword">elseif</span> <span class="built_in">mod</span>(year,<span class="number">100</span>) == <span class="number">0</span>leap_day = <span class="number">0</span>; <span class="comment">% Other centuries are not leap years </span><span class="keyword">elseif</span> <span class="built_in">mod</span>(year,<span class="number">4</span>) == <span class="number">0</span>leap_day = <span class="number">1</span>; <span class="comment">% Otherwise every 4th year is a leap year </span><span class="keyword">else</span>leap_day = <span class="number">0</span>; <span class="comment">% Other years are not leap years </span><span class="keyword">end</span><span class="comment">% Calculate day of year by adding current day to the</span><span class="comment">% days in previous months. </span>day_of_year = day;<span class="keyword">for</span> ii = <span class="number">1</span>:month - <span class="number">1</span><span class="comment">% Add days in months from January to last month </span><span class="keyword">switch</span> (ii)<span class="keyword">case</span> {<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">10</span>,<span class="number">12</span>}day_of_year = day_of_year + <span class="number">31</span>; <span class="keyword">case</span> {<span class="number">4</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">11</span>}day_of_year = day_of_year + <span class="number">30</span>; <span class="keyword">case</span> <span class="number">2</span>day_of_year = day_of_year + <span class="number">28</span> + leap_day; <span class="keyword">end</span><span class="keyword">end</span><span class="comment">% Tell user</span>fprintf(<span class="string">'The date %2d/%2d/%4d is day of year %d.\n'</span>, month, day, year, day_of_year);</code></pre><p>我们用下面已知的结果来检测这个程序。</p><ol><li><p>1999 年不是闰年。它的 1 月 1 号对应的day of year 是 1，12 月 31 号必定对应的是 365。</p></li><li><p>2000 年是一个闰年。它的 1 月 1 号对应的 day of year 是 1，12 月 31 号必定对应的是 366。</p></li><li><p>2001 年不是闰年。它的 1 月 1 号对应的 day of year 是 30。这个程序 5 次运行后的结果分别为</p></li></ol><pre><code class="highlight plaintext">&gt;&gt; doyThis program calculates the day of year given the current date.Enter current month (1-12):1 Enter current day(1-31):1 Enter current year(yyyy): 1999The date1/ 1/1999 is day of year 1.&gt;&gt; doyThis program calculates the day of year given the current date.Enter current month (1-12):12 Enter current day(1-31):31 Enter current year(yyyy): 1999The date 12/31/1999 is day of year 365.&gt;&gt; doyThis program calculates the day of year given the current date.Enter current month (1-12):1 Enter current day(1-31):1 Enter current year(yyyy): 2000The date 1/ 1/2000 is day of year 1.&gt;&gt; doyThis program calculates the day of year given the current date.Enter current month (1-12):12 Enter current day(1-31):31 Enter current year(yyyy): 2000The date 12/31/2000 is day of year 366.&gt;&gt; doyThis program calculates the day of year given the current date.Enter current month (1-12):3 Enter current day(1-31):1 Enter current year(yyyy): 2001The date3/ 1/2001 is day of year 60.</code></pre><p>通过 5 次不同情况的检测，这个程序给出了正确的结果。</p><h5 id="例-4-4-计算平均数和标准差">例 4.4 计算平均数和标准差</h5><p><strong>统计分析</strong></p><p>执行如下算法：</p><p>输入一系列的测量数，计算它们的平均数和标准差。这些数可以是正数，负数或 0。</p><p><strong>答案：</strong></p><p>这个程序必须能够读取大量数据，并能够计算出这些测量值的平均数和标准差。这些测量值可以是正数，负数或 0。</p><p>因为我们再也不能用一个数来表示数据中止的标识了，我们要求用户给出输入值的个数，然后用 for 循环读取所有数值。</p><p>下面的就是这个修定版本的程序。它允许各种输入值，请你自己验证下面 5 个输入值的平均数和标准差：3，-1，0，1，-2。</p><pre><code class="highlight matlab"><span class="comment">% Script file: stats_3.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To calculate mean and the standard deviation of</span><span class="comment">% an input data set, where each input value can be</span><span class="comment">% positive, negative, or zero.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== ====================</span><span class="comment">% 12/08/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% ii Loop index</span><span class="comment">% n The number of input samples</span><span class="comment">% std_dev The standard deviation of the input samples</span><span class="comment">% sum_x The sum of the input values</span><span class="comment">% sum_x2 The sum of the squares of the input values</span><span class="comment">% x An input data value</span><span class="comment">% xbar The average of the input samples</span><span class="comment">% Initialize sums. </span>sum_x = <span class="number">0</span>; sum_x2 = <span class="number">0</span>;<span class="comment">% Get the number of points to input. </span>n = input(<span class="string">'Enter number of points: '</span>);<span class="comment">% Check to see if we have enough input data. </span><span class="keyword">if</span> n &lt; <span class="number">2</span> <span class="comment">% Insufficient data</span> <span class="built_in">disp</span> (<span class="string">'At least 2 values must be entered.'</span>); <span class="keyword">else</span> <span class="comment">% we will have enough data, so let's get it.</span> <span class="comment">% Loop to read input values. </span> <span class="keyword">for</span> ii = <span class="number">1</span>:n <span class="comment">% Read in next value</span>x = input(<span class="string">'Enter value: '</span>);<span class="comment">% Accumulate sums. </span>sum_x = sum_x + x; sum_x2 = sum_x2 + x^<span class="number">2</span>;<span class="keyword">end</span><span class="comment">% Now calculate statistics. </span>x_bar = sum_x / n;std_dev = <span class="built_in">sqrt</span>((n * sum_x2 - sum_x^<span class="number">2</span>) / (n * (n - <span class="number">1</span>)));<span class="comment">% Tell user.</span>fprintf(<span class="string">'The mean of this data set is: %f\n'</span>, x_bar); fprintf(<span class="string">'The standard deviation is: %f\n'</span>, std_dev);fprintf(<span class="string">'The number of data points is: %f\n'</span>, n);<span class="keyword">end</span></code></pre><p><strong>运行结果：</strong></p><pre><code class="highlight plaintext">&gt;&gt; stats_3Enter number of points: 5Enter value: 3Enter value: -1Enter value: 0Enter value: 1Enter value: -2The mean of this data set is: 0.200000The standard deviation is: 1.923538The number of data points is: 5.000000</code></pre><h5 id="4-2-1-运算的细节">4.2.1  运算的细节</h5><p>既然我们已经看了许多 for 循环的例子。在用 for 循环时，我们必须检查许多重要的细节。</p><ol><li>没有必要缩进 for 循环的循环体。即使所有语句都左对齐，<strong>MATLAB</strong> 程序也会识别出这个循环。但缩进循环体能增强代码的可读性，所以建议大家缩进循环体。</li></ol><p><strong>对于 for  循环体总是要缩进两个或更多空格，以增强程序的可读性。</strong></p><ol start="2"><li>在 for 循环中，我们不能随意修改循环指数。循环指数常被用作计算器，</li></ol><p>如果修改了它们将会导致一些奇怪而难以发现的错误。下面的一个例子将初始化一个函数的数组。但是语句“ii=5”的突然出现，导致只有 a(5)得到了初始化，它得到了本应赋给 a(1)， a(2)等等的值。</p><pre><code class="highlight plaintext">for ii = 1:10...ii = 5 ; % Error!...a(ii) = &lt;calculation&gt;end</code></pre><p><strong>在循环体中绝不修改循环指数的值。</strong></p><ol start="3"><li>我们在第二章已经学过，用赋值的方法可以扩展一个已知的数组。例如，语句</li></ol><p><strong>arr = 1:4;</strong></p><p>定义了一个数组[1 2 3 4]。如果执行语句</p><p><strong>arr(8) = 6;</strong></p><p>将会产生一个八元素数组[1 2 3 4 0 0 0 6]。不幸的是，每一次扩展数组，都要经过以下步骤:第一步，创建一个新数组。第二步，把旧数组的元素复制到新数组当中。第三步，把扩展的元素写入新数组。第四步，删除旧数组。对于大数组来说这些步骤是相当耗时的。</p><p>当一个 for 循环中存储了一个预先未定义的数组，在第一次循环执行的时侯，循环结构迫使 <strong>MATLAB</strong> 重复执行以上步骤。从另一方面说，如果在循环开始之前数组预先分配了数组的大小，那么复制就不需要了，执行代码的速度也将加快。下面代码片段向大家展示了在循环开始之前如何预先分配数组。</p><p><strong>在循环执行开始之前，总是要预先分配一个数组，这样能大大增加循环运行的速度。</strong></p><ol start="4"><li>用 for 循环和向量计算是非常常见的。例如，下面的代码片段用 for 循环计算 1 到 100  之间的所有整数的平方，平方根，立方根。</li></ol><pre><code class="highlight matlab"><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">100</span> square(ii) = ii ^<span class="number">2</span>;square_root(ii) = ii ^ (<span class="number">1</span>/<span class="number">2</span>); cube_root(ii) = ii ^ (<span class="number">1</span>/<span class="number">3</span>);<span class="keyword">end</span></code></pre><p>下面一个代码片段是用向量计算上面的问题。</p><pre><code class="highlight plaintext">ii = 1:100;square = ii .^2; square_root = ii .^ (1/2); cube_root(ii) = ii .^ (1/3);</code></pre><p>尽管两种算法得到了相同的结果，但两者并不同等价。因为 for 循环算法比向量算法慢 15 倍还多。这是由于 <strong>MATLAB</strong> 通过每一次循环时，每行都要翻译执行一次。也相当于 <strong>MATLAB</strong> 翻译执行了 300 行代码。相反，如果用向量算法，<strong>MATLAB</strong> 只需要翻译执行 4 行代码。所以用向量语句它的执行速度非常快。</p><p>向量算法的缺点是需要很大的内存，因为一些间接的数组需要创建。这经常是一小点损失，所以要比 for 循环算法好的多。</p><p>在 <strong>MATLAB</strong> 中，用向量算法代替循环的算法的过程称之为向量化(vectorization)。向量化能够改进许多的 <strong>MATLAB</strong> 程序。</p><p><strong>那种既可以用向量可以解决的问题，也可以用循环解决的问题，最好用向量解决，这是因为向量执行的速度快。</strong></p><h6 id="例-4-5-计算-1-到-10000-的之间每一个整数的平方">例 4.5 计算 1 到 10000 的之间每一个整数的平方</h6><p>比较向量算法和循环为了比较循环和向量算法执行若无事所用的时间，用两种方法编程并测试三个运算所花的时间。</p><ol><li><p>用 for 循环计算 1 到 10000 的之间每一个整数的平方，而事先不初始化平方数组。</p></li><li><p>用 for 循环计算 1 到 10000 的之间每一个整数的平方，而事先初始化平方数组。</p></li><li><p>用向量算法计算计算 1 到 10000 的之间每一个整数的平方。</p></li></ol><p><strong>答案:</strong></p><p>这个程序必须用上面提供的三种方示计算出 1 到 10000 之间的每一个整数的平方，并测试每一个种算法的时间。测试时间要用到 <strong>MATLAB</strong> 函数 tic 和 toc。tic 函数复位内建计时器， 而 toc 函数则从最后一次调用 tic 以秒开始计时。</p><p>因为在许多的计算机中它的时间钟是相当粗略的，所以有必要多运行几次以获得相应的平均数。</p><p>下面就是用三种方法编出的 <strong>MATLAB</strong> 程序。</p><pre><code class="highlight matlab"><span class="comment">% Script file: timings.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program calculates the time required to</span><span class="comment">% calculate the squares of all integers from 1 to</span><span class="comment">% 10,000 in three different ways:</span><span class="comment">% 1. Using a for loop with an uninitialized output</span><span class="comment">% array.</span><span class="comment">% 2. Using a for loop with an preallocated output</span><span class="comment">% array.</span><span class="comment">% 3. Using vectors.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/08/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% ii, jj Loop index</span><span class="comment">% average1 Average time for calculation 1</span><span class="comment">% average2 Average time for calculation 2</span><span class="comment">% average3 Average time for calculation 3</span><span class="comment">% maxcount Number of times to loop calculation</span><span class="comment">% square Array of squares</span><span class="comment">% leap_day Extra day for leap year</span><span class="comment">% month Month(mm)</span><span class="comment">% year Year(yyyy)</span><span class="comment">% Perform calculation with an uninitialized array</span><span class="comment">% "square". This calculation is done only once</span><span class="comment">% because it is so slow. </span>maxcount = <span class="number">1</span>; <span class="comment">% One repetition </span>tic; <span class="comment">% Start timer</span><span class="keyword">for</span> jj = <span class="number">1</span>:maxcountclear square <span class="comment">% Clear output array </span><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">10000</span>square(ii) = ii^<span class="number">2</span>; <span class="comment">% Calculate square</span><span class="keyword">end</span><span class="keyword">end</span>average1 = (toc)/maxcount; <span class="comment">% Calculate average time</span><span class="comment">% Perform calculation with a preallocated array</span><span class="comment">% "square". This calculation is averaged over 10</span><span class="comment">% loops.</span>maxcount = <span class="number">10</span>; <span class="comment">% One repetition </span>tic; <span class="comment">% Start timer</span><span class="keyword">for</span> jj = <span class="number">1</span>:maxcountclear square <span class="comment">% Clear output array</span>square = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">10000</span>); <span class="comment">% Preinitialize array </span><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">10000</span>square(ii) = ii^<span class="number">2</span>; <span class="comment">% Calculate square</span><span class="keyword">end</span><span class="keyword">end</span>average2 = (toc)/maxcount; <span class="comment">% Calculate average time</span><span class="comment">% Perform calculation with vectors. This calculation</span><span class="comment">% averaged over 100 executions. </span>maxcount = <span class="number">100</span>; <span class="comment">% One repetition </span>tic; <span class="comment">% Start timer</span><span class="keyword">for</span> jj = <span class="number">1</span>:maxcountclear square <span class="comment">% Clear output array </span>ii = <span class="number">1</span>:<span class="number">10000</span>; <span class="comment">% Set up vector </span>square = ii.^<span class="number">2</span>; <span class="comment">% Calculate square</span><span class="keyword">end</span>average3 = (toc)/maxcount; <span class="comment">% Calculate average time</span><span class="comment">% Display results</span>fprintf(<span class="string">'Loop / uninitialized array = %8.4f\n'</span>, average1); fprintf(<span class="string">'Loop / initialized array = %8.4f\n'</span>, average2); fprintf(<span class="string">'Vectorized = %8.4f\n'</span>, average3);</code></pre><p><strong>运行结果：</strong></p><pre><code class="highlight plaintext">&gt;&gt; timingsLoop / uninitialized array =   0.0040Loop / initialized array =   0.0003Vectorized =   0.0001</code></pre><h5 id="4-2-2-break-和-continue-语句">4.2.2 break 和 continue 语句</h5><p>有两个附加语句可以控制 while 和 for 循环: break 和 continue 语句。break 语句可以中止循环的执行和跳到 end 后面的第一句执行，而 continue 只中止本次循环，然后返回循环的顶部。如果 break 语句在循环体中执行，那么体的执行中止，然后执行循环后的第一个可执行性语句。用在 for 循环中的 break 语句的例子如下:</p><p>程序执行的结果为:</p><pre><code class="highlight matlab"><span class="comment">% test_break.m </span><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">5</span>;<span class="keyword">if</span> ii == <span class="number">3</span>;<span class="keyword">break</span>;<span class="keyword">end</span>fprintf(<span class="string">'ii = %d \n'</span>, ii);<span class="keyword">end</span><span class="built_in">disp</span>(<span class="string">'End of loop!'</span>);</code></pre><p><strong>运行结果：</strong></p><pre><code class="highlight plaintext">&gt;&gt; test_breakii = 1ii = 2End of loop!</code></pre><p>注意 break 语句在 ii 为 3 时执行，然后执行 disp(‘End of loop!’); 语句而不执行  fprintf(‘ii =   %d \n’, ii);语句。</p><p>continue 语句只中止本次循环，然后返回循环的顶部。在 for 循环中的控制变量将会更新到下一个值，循环将会继续进行。下面是一个在 for 循环中的 continue 的例子。</p><pre><code class="highlight matlab"><span class="comment">%test_continue.m </span><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">5</span>;<span class="keyword">if</span> ii == <span class="number">3</span>;<span class="keyword">continue</span>;<span class="keyword">end</span>fprintf(<span class="string">'ii = %d \n'</span>, ii);<span class="keyword">end</span><span class="built_in">disp</span>(<span class="string">'End of loop!'</span>);</code></pre><p><strong>运行结果：</strong></p><pre><code class="highlight plaintext">&gt;&gt; test_continueii = 1ii = 2ii = 4ii = 5End of loop!</code></pre><p>注意continue 语句在ii 为3 时执行，然后程序返回循环的顶部而不执行fprintf 语句。break 和 continue 语句可用在 while 循环和for 循环中。</p><h5 id="4-2-3-循环嵌套">4.2.3 循环嵌套</h5><p>一个循环完全出现在另一个循环当中，这种情况经常发生。如果一个循环完全出现在另一个循环当中，我们称这两个循环为<strong>带嵌套的循环</strong>。下面的例子用两重 for 循环嵌套来计算并写出结果。</p><pre><code class="highlight matlab"><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">3</span><span class="keyword">for</span> jj = <span class="number">1</span>:<span class="number">3</span>product = ii * jj;fprintf(<span class="string">'%d * %d = %d \n'</span>,ii,jj,product);<span class="keyword">end</span><span class="keyword">end</span></code></pre><p>在这个例子中，外部的 for 循环将把 1 赋值于循环指数 ii，然后执行内部 for 循环。内部循环的循环体将被执行 3 次，它的循环指数 ii 将会先后被赋值为 1，2，3。当完全执行完内部的循环后，外部的 for 循环将会把 2 赋值于循环指数 ii，然后内部的 for 循环将会再次执行。直到外部 for 循环执行 3 次，这个重复过程结束。产生的结果为</p><pre><code class="highlight plaintext">1 * 1 = 11 * 2 = 21 * 3 = 32 * 1 = 22 * 2 = 42 * 3 = 63 * 1 = 33 * 2 = 63 * 3 = 9</code></pre><p>注意外部 for 循环指数变量增加之前，内部 for 循环要完全执行完。</p><p>当 <strong>MATLAB</strong> 遇到一个 end 语句，它将与最内部的开放结构联合。所以第一个 end 语句与语句“for jj = 1:3”，第二个 end 语句与语句“for ii = 1:3”联合。如果在循环嵌套中一个 end 语句突然被删除，将会产生许多难以发现的错误。</p><p>如果 for 循环是嵌套的，那么它们必须含有独立的循环变量。如果它们含有相同的循环变量，那么内部循环将改变外部循环指数的值。</p><p>如果 break 或 continue 语句出现在循环嵌套的内部，那么 break 语句将会在包含它的最内部的循环起作用。</p><pre><code class="highlight matlab"><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">3</span><span class="keyword">for</span> jj = <span class="number">1</span>:<span class="number">3</span><span class="keyword">if</span> jj ==<span class="number">3</span>;<span class="keyword">break</span>;<span class="keyword">end</span>product = ii * jj;fprintf(<span class="string">'%d * %d = %d \n'</span>,ii,jj,product);<span class="keyword">end</span>fprintf(<span class="string">'End of inner loop\n'</span>);<span class="keyword">end</span>fprintf(<span class="string">'End of outer loop\n'</span>);</code></pre><p>如果内部循环指数 jj 为 3，那么 break 语句开始执行，这将导致程序跳出内部循环。程序将会打印出”End of inner loop”，外部循环指数将会增加 1，内部循环的执行重新开始。产生的输出值为:</p><pre><code class="highlight plaintext">1 * 1 = 11 * 2 = 2End of inner loop 2 * 1 = 22 * 2 = 4End of inner loop 3 * 1 = 33 * 2 = 6End of inner loop End of outer loop</code></pre><h4 id="4-3-逻辑数组与向量化">4.3 逻辑数组与向量化</h4><p>在第二章中，我们提出 <strong>MATLAB</strong> 有两个基本类型的数据类型: <strong>数字型与字符型</strong>。数字型数据包括数字，字符型数据包含字符。除这两个数据类型之外，还有第三类数据类:逻辑型。</p><p>“逻辑”数据类型在 <strong>MATLAB</strong> 中并不真实存在。其实，它是带特定逻辑属性标准数字型数据类型。逻辑型数组通过所有的关系运算符和逻辑运算符创建。它们区别于数字型的是在调用 whos 命令时，(logical)会出现在类型的后面。</p><p>例如，考虑下面的语句</p><pre><code class="highlight plaintext">a = [1 2 3; 4 5 6; 7 8 9];b = a &gt; 5;</code></pre><p><img src="/medias/20200615165559315.png" alt=""></p><pre><code class="highlight plaintext">&gt;&gt; whos  Name   Size    Bytes       Class    a     3x3     72       double array    b     3x3      9      logical arrayGrand total is 18 elements using 81 bytes</code></pre><p>我们还可以用 logical 函数给一个数组加上一个逻辑属性。例如，语句 c=logical(a)，将会把 a 值赋于 c，从而使 c 带有一定的逻辑性:</p><p>一个数组的逻辑属性可以通任何的数学运算去除。例如，如果我们在 c 数组加 0，数组的值不会改变，而它的逻辑属性将会消失</p><pre><code class="highlight plaintext">&gt;&gt; c=b+0c =000001111&gt;&gt; whosName  Size Bytes   Class  a     3×3      72double array  b 3×3  9logical array  c3×3 72double arrayGrand total is 27 elements using 153 bytes</code></pre><h5 id="4-3-1-逻辑数组的重要性">4.3.1  逻辑数组的重要性</h5><p>逻辑数组有一个重要的属性它在算术运算中能提供一个屏蔽(mask)。屏蔽(mask)是指一个数组，它从另一个数组选择所需的元素参与运算。指定的运算只在选择的元素上执行，而不执行原有的元素。</p><p>例如，假设数组 a 和b 的定义如上节所示。那么语句 a(b)=sqrt(a(b))会计算 a 中相应的元素的平方根，相应的元素是指与 b 数组中的非零元素相对应的数组 a 中的元素。其他元素保持不变。</p><pre><code class="highlight plaintext">&gt;&gt; a(b)=sqrt(a(b))a =1.00002.00003.00004.00005.00002.44952.64582.82843.0000</code></pre><p>对于一个数组的子集快速而简单，而不用循环和选择结构。</p><p>下面的语句，是用循环结构和选择结构计算上述问题。</p><pre><code class="highlight plaintext">for ii = 1:size(a,1)for jj = 1:size(a,2) if a(ii,jj) &gt; 5a(ii,jj)=sqrt(a(ii,jj));endendendb = a &gt; 5;a(b) = sqrt(a(b));</code></pre><h6 id="例-4-6-计算出大于-5000-的元素的平方根">例 4.6 计算出大于 5000 的元素的平方根</h6><p>用逻辑数数组进行屏蔽运算为了比较循环结构，选择结构与应用逻辑数组运算的快慢， 我们进行下面两个计算，并对它进行计时。</p><p>1.创建一个含 10000 个元素的数组，其值依次为 1 到 10000 之间的整数。用 for 循环和 if 结构计算大于 5000 的元素的平方根。</p><p>2.创建一个含 10000 个元素的数组，其值依次为 1 到 10000 之间的整数。用逻辑数组计算大于 5000 的元素的平方根。</p><p><strong>答案:</strong></p><p>这个程序必须创建一个含 10000 个元素的数组，其值依次为 1 到 10000 之间的整数。用两种不同的方法计算出大于 5000 的元素的平方根。</p><p>比较两种方法运行速度的 <strong>MATLAB</strong> 程序如下所示:</p><pre><code class="highlight matlab"><span class="comment">% Script file:logical1.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">%This program calculates the time required to</span><span class="comment">%calculate the square roots of all elements in</span><span class="comment">%array a whose value exceeds 5000. This is done</span><span class="comment">%in two differents ways:</span><span class="comment">%1.Using a for loop and if construct.</span><span class="comment">%2.Using a logical array.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">%Date   ProgrammerDescription of change</span><span class="comment">%====================    ============================== </span><span class="comment">% 06/01/02   S. J. ChapmanOriginal code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">%   a --Array of input values</span><span class="comment">%   b --Logical array to serve as a mask</span><span class="comment">% ii,jj --Loop index</span><span class="comment">% average1 --Average time for calculation 1</span><span class="comment">% average2 --Average time for calculation 2</span><span class="comment">% maxcount --Number of times to loop calculation</span><span class="comment">% month --Month (mm)</span><span class="comment">% year --Year (yyyy)</span><span class="comment">%</span><span class="comment">% Perform calculation using loops and branches</span>maxcount = <span class="number">1</span>; <span class="comment">% One repetition</span>tic; <span class="comment">% Start timer</span><span class="keyword">for</span> jj = <span class="number">1</span>:maxcounta = <span class="number">1</span>:<span class="number">10000</span>; <span class="comment">%Declare array a</span><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">10000</span><span class="keyword">if</span> a(ii) &gt; <span class="number">5000</span>a(ii) = <span class="built_in">sqrt</span>(a(ii));<span class="keyword">end</span><span class="keyword">end</span><span class="keyword">end</span>average1 = (toc)/maxcount;<span class="comment">% Calculate average time</span><span class="comment">%</span><span class="comment">% Perform calculation using logical arrays.</span>maxcount = <span class="number">10</span>; <span class="comment">% One repetition</span>tic; <span class="comment">% Start timer</span><span class="keyword">for</span> jj = <span class="number">1</span>:maxcounta = <span class="number">1</span>:<span class="number">10000</span>; <span class="comment">% Declare array a</span>b = a &gt; <span class="number">5000</span>; <span class="comment">% Create mask</span>a(b) = <span class="built_in">sqrt</span>(a(b)); <span class="comment">% Take square root</span><span class="keyword">end</span>average2 = (toc)/maxcount; <span class="comment">% Calculate average time</span><span class="comment">%</span><span class="comment">% Display result</span>fprintf(<span class="string">'Loop /if approach = %8.4f\n'</span>,average1);fprintf(<span class="string">'Logical array approach = %8.4f\n'</span>,average2);</code></pre><p>这个程序在 cpu 为酷睿 i5-10210U(主频为 1.6GHz)的计算机运行得到结果如下:</p><pre><code class="highlight plaintext">&gt;&gt; logical1Loop /if approach =   0.0015Logical array approach =   0.0003</code></pre><p>正如我们看到的，用逻辑数组方法速度是另一种方法的 5 倍。</p><p><strong>如果用可能的话，可用逻辑函数选择数组中的元素。如果逻辑数组进行运算，要比循环快得多。</strong></p><h5 id="4-3-2-用-if-else-结构和逻辑数组创建等式">4.3.2  用 if/else 结构和逻辑数组创建等式</h5><p>逻辑数组经常被用来替代 for 循环中的 if/else 结构。正如我们在上节所看到的，把逻辑运算当作一个屏蔽来选择数组中的某些元素进行运算。如果你要利用那些没有被选择到的元素进行运算，只需要在逻辑屏蔽上加一个非运算符(-)。例如，假设我们要计算一个二维数组中所有的大于 5 的元素的平方根，然后其余的数的平方。利用循环和选择结构的代码如下:</p><pre><code class="highlight matlab"><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="built_in">size</span>(a,<span class="number">1</span>)<span class="keyword">for</span> jj = <span class="number">1</span>:<span class="built_in">size</span>(a,<span class="number">2</span>)<span class="keyword">if</span> a(ii,jj) &gt; <span class="number">5</span>a(ii,jj) = <span class="built_in">sqrt</span>(a(ii,jj));<span class="keyword">else</span>a(ii,jj) = a(ii,jj)^<span class="number">2</span>;<span class="keyword">end</span><span class="keyword">end</span><span class="keyword">end</span></code></pre><p>用逻辑数组运算的代码如下:</p><pre><code class="highlight plaintext">b = a &gt; 5a(b) = sqrt(a(b));a(~b) = a(~b) .^2;</code></pre><p>显然用逻辑数组的方法运算速度要快得多。</p><h4 id="4-4-附加例子">4.4 附加例子</h4><h5 id="例-4-7-用最小二乘法画噪声数据的近似曲线">例 4.7 用最小二乘法画噪声数据的近似曲线</h5><p><strong>用最小二乘法画噪声数据的近似曲线</strong></p><p>下落物体将会作匀加速度运动，它的速度符合下面的公式</p><p>​                                                                          v(t) = at + v~0~           (4.3)</p><p>*v(t)*代表物体在 <em>t</em> 时刻的速度。加速度为 <em>g</em>，初速度 v~0~ 为 <em>0</em>。这个公式出现在基础物理学中，我们大家都非常的熟悉。如果我们要画出下落物体的速度时间图象，我们得到的(<em>v</em>，<em>t</em>) 测量值应当在同一条直线上。但是，学习物理的同学都知道，在实验室得到的测量值不一定是直线。为什么会这样呢?因为所有的测量都有误差。在所有测量值中都有一定的噪声。</p><p>在工程和科研方面，有许多像这个例子一样带有噪声，而我们希望得到最符合的结果。这个问题叫做线性待定问题。给出一系列带噪声的测量值(<em>x</em>，<em>y</em>)，它遵循一条直线，如何确定“最符合”这条直线的解析式呢。</p><p>如果我们确定了待定系数 <em>m</em> 和 <em>b</em>，那么我们就确定了解析式 4.4。</p><p>​                                                                           y=mx+b*              (4.4)</p><p>确定待定系数 m 和 b 的标准方法为最小二乘法。之所以称为最小二乘法，是因为根据偏差的平方和为最小的条件来选择常数 m 和 b 的。公式如下:</p><img src="/medias/20200615172252671.png" style="zoom: 50%;"><p><img src="/medias/20200615172404993.png" alt=""></p><p><strong>答案:</strong></p><ol><li>陈述问题</li></ol><p>已知有一系列含有噪声的数据(<em>x</em>，<em>y</em>)用最小二乘法计算 <em>m</em> 和 <em>b</em>。数据要求从键盘输入， 画出每一个数据点还有画出最适合的直线。</p><ol start="2"><li>定义输入输出值</li></ol><p>这个程序所需的输入值为点的个数，以及点的坐标。输出是用最小二乘法得到的斜率以及 y 上的截距。</p><ol start="3"><li>设计算法</li></ol><p>这个问题被分解为 6 个大步骤:</p><pre><code class="highlight plaintext">Get the number of input data pointsRead the input data valuesCalculate the required statisticsCalculate the slop and interceptWrite out the slop and interceptPlot the input points and the fitted line</code></pre><p>第一大步是读取输入量的个数，所以我们要用到 input 函数。下一步我们要在 for 循环中使用 input 函数读取输入量(<em>x</em>，<em>y</em>)。每一个输入值将会产生一个数组([<em>x</em>，<em>y</em>])，然后这个函数将会返回这个数组到调用程序。注意在这里应用 for 循环是合适的，因为我们事先知道循环要执行多少次。</p><p>上述步骤的伪代码如下:</p><pre><code class="highlight plaintext">Print message describing purpose of the programn_points ← input('Enter number of [x y] pairs:');for ii = 1:n_pointstemp ← ('Enter [x y] pairs:');x(ii) ← temp(1);y(ii) ← temp(2);end</code></pre><p><img src="/medias/20200615172757618.png" alt=""></p><pre><code class="highlight plaintext">Clear the vairables sum_x, sum_y, sum_x2, and sum_xyfor ii = 1:n_pointssum_x ← sum_x + x(ii)sum_y ← sum_y + y(ii)sum_x2 ← sum_x2 + x(ii)^2sum_xy ← sum_xy + x(ii) * y(ii)end</code></pre><p>下一步我们必须计算出斜率 <em>m</em> 和 <em>y</em> 轴上的载距 <em>b</em>。这一步的伪代码就是公式(4.4)和(4.5)。</p><pre><code class="highlight plaintext">x_bar ← sum_x / n_pointsy_bar ← sum_y / n_pointsslope ← (sum_xy-sum_x * y_bar)/( sum_x2 –sum_x * x_bar)y_int ← y_bar – slope * x_bar</code></pre><p>最后，我们必须写出和画出相应的结果。输入的坐标点要用圆点画出，不用连接线而用最小二乘法得到解析式对应的直线用 2pixel 的实直线画出。在此之前我们要用到 hold on 命令。画完直线之后，调用 hold off 命令。我们在图象中将会添加相应的标题，以及相应的图例。</p><ol start="4"><li>转化为 <strong>MATLAB</strong> 语句</li></ol><pre><code class="highlight matlab"><span class="comment">% Script file: lsqfit.m</span><span class="comment">% Purpose:</span><span class="comment">% To perform a leastsquares fit of an input data set</span><span class="comment">% to a straight line, and print out the resulting slope</span><span class="comment">% and intercept values. The input data for this fit</span><span class="comment">% comes from a userspecified input data file.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 01/03/99 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% ii Loop index</span><span class="comment">% n_points Number in input [x y] points</span><span class="comment">% slope Slope of the line</span><span class="comment">% sum_x Sum of all input x values</span><span class="comment">% sum_x2 Sum of all input x values squared</span><span class="comment">% sum_xy Sum of all input x*y yalues</span><span class="comment">% sum_y Sum of all input y values</span><span class="comment">% temp Variable to read user input</span><span class="comment">% x Array of x values</span><span class="comment">% x_bar Average x value</span><span class="comment">% y Array of y values</span><span class="comment">% y_bar Average y value</span><span class="comment">% y_int yaxis intercept of the line</span><span class="built_in">disp</span>(<span class="string">'This program performs a leastsquares fit of an '</span>);<span class="built_in">disp</span>(<span class="string">'input data set to a straight line.'</span>);n_points = input(<span class="string">'Enter the number of input [x y] points: '</span>);<span class="comment">% Read the input data</span><span class="keyword">for</span> ii = <span class="number">1</span>:n_pointstemp = input(<span class="string">'Enter [x y] pair: '</span>);x(ii) = temp(<span class="number">1</span>);y(ii) = temp(<span class="number">2</span>);<span class="keyword">end</span><span class="comment">% Accumulate statistics</span>sum_x = <span class="number">0</span>;sum_y = <span class="number">0</span>;sum_x2 = <span class="number">0</span>;sum_xy = <span class="number">0</span>;<span class="keyword">for</span> ii = <span class="number">1</span>:n_pointssum_x = sum_x + x(ii);sum_y = sum_y + y(ii);sum_x2 = sum_x2 + x(ii)^<span class="number">2</span>;sum_xy = sum_xy + x(ii) * y(ii);<span class="keyword">end</span><span class="comment">% Now calculate the slope and intercept.</span>x_bar = sum_x / n_points;y_bar = sum_y / n_points;slope = (sum_xy - sum_x * y_bar) / ( sum_x2 - sum_x * x_bar);y_int = y_bar - slope * x_bar;<span class="comment">% Tell user.</span><span class="built_in">disp</span>(<span class="string">'Regression coefficients for the leastsquares line:'</span>);fprintf(<span class="string">' Slope (m) = %8.3f\n'</span>, slope);fprintf(<span class="string">' Intercept (b) = %8.3f\n'</span>, y_int);fprintf(<span class="string">' No of points = %8d\n'</span>, n_points);<span class="comment">% Plot the data points as blue circles with no</span><span class="comment">% connecting lines.</span><span class="built_in">plot</span>(x,y,<span class="string">'bo'</span>);<span class="built_in">hold</span> on;<span class="comment">% Create the fitted line</span>xmin = <span class="built_in">min</span>(x);xmax = <span class="built_in">max</span>(x);ymin = slope * xmin + y_int;ymax = slope * xmax + y_int;<span class="comment">% Plot a solid red line with no markers</span><span class="built_in">plot</span>([xmin xmax],[ymin ymax],<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">2</span>);<span class="built_in">hold</span> off;<span class="comment">% Add a title and legend</span>title (<span class="string">'\bfLeastSquaresFit'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bf\ity'</span>);<span class="built_in">legend</span>(<span class="string">'Input data'</span>,<span class="string">'Fitted line'</span>);grid on</code></pre><ol start="5"><li>检测程序为了检测这个程序，我们将采用一些简单的数据，如果输入数据所对应的点都在同一条</li></ol><p>直线，那么产生的斜率和截距必定是那条直线的斜率和截距。这组数据为</p><pre><code class="highlight plaintext">[1.1 1.1][2.2 2.2][3.3 3.3][4.4 4.4][5.5 5.5][6.6 6.6][7.7 7.7]</code></pre><p>它的斜率和截距分别为 1.0 和 0.0。我们将用这些值来运行这个程序，结果如下:</p><pre><code class="highlight plaintext">&gt;&gt; lsqfitThis program performs a leastsquares fit of an input data set to a straight line.Enter the number of input [x y] points: 7Enter [x y] pair: [1.1 1.1]Enter [x y] pair: [2.2 2.2]Enter [x y] pair: [3.3 3.3]Enter [x y] pair: [4.4 4.4]Enter [x y] pair: [5.5 5.5]Enter [x y] pair: [6.6 6.6]Enter [x y] pair: [7.7 7.7]Regression coefficients for the leastsquares line: Slope (m) =    1.000 Intercept (b) =    0.000 No of points =        7</code></pre><p>图象如图</p><p><img src="/medias/20200615173633801.png" alt=""></p><p>我们将在这些值上加入一些噪声，如下所示：</p><pre><code class="highlight plaintext">[1.1 1.01][2.2 2.30][3.3 3.05][4.4 4.28][5.5 5.75][6.6 6.48][7.7 7.84]</code></pre><p>再次运行程序，所得的结果如下：</p><pre><code class="highlight plaintext">&gt;&gt; lsqfitThis program performs a leastsquares fit of an input data set to a straight line.Enter the number of input [x y] points: 7Enter [x y] pair: [1.1 1.01]Enter [x y] pair: [2.2 2.30]Enter [x y] pair: [3.3 3.05]Enter [x y] pair: [4.4 4.28]Enter [x y] pair: [5.5 5.75]Enter [x y] pair: [6.6 6.48]Enter [x y] pair: [7.7 7.84]Regression coefficients for the leastsquares line: Slope (m) =    1.024 Intercept (b) =   -0.120 No of points =        7</code></pre><p>运行结果如图：</p><p><img src="/medias/20200615174017397.png" alt=""></p><p>这个例子用到了第三章中许多画图的例子。用 hold 命令在同一坐标下，画出了多个图象。用 LineWidth 属性来改变直线的宽度。用转义序列来设标题字体。</p><h5 id="例-4-8-计算和画出抛物线">例 4.8 计算和画出抛物线</h5><p>小球的轨迹如果我们假设处于真空中，且忽略地球的曲率。在地球任意一点向空中抛出一小球将会产生类似于图 4.2（a）所示的曲线。球在时刻 t 的高度将会遵守公式(4.7)。</p><p><img src="/medias/20200615174323388.png" alt=""></p><p><img src="/medias/20200615174420156.png" alt=""></p><p><img src="/medias/20200615174512340.png" alt=""></p><pre><code class="highlight plaintext">Calculate the range of the ball for 􀈙 between 0 and 90oWrite a table of rangesDetermine the maximum range and write it outPlot the trajectories for 􀈙 between 5 and 85oPlot the maximum-range trajectory</code></pre><p>因为我们精确地知道循环重复的次数，所以在这里用 for 循环是合适的。我们现在开始定义每一个大步骤的伪代码。为了计算每一个角度小球的落地位移，我们首先应当通过公式(4.9)和(4.10)计算水平初速度和竖直初速度。然后通过 4.11 计算出小球落地的时间。最后通过 4.7 计算出落地位移。具体的伪代码如下所示。注意在用 trigonometric 函数之前，我们必须把角度转化为弧度。</p><pre><code class="highlight plaintext">Create and initialize an array to hold rangesfor ii = 1:91theta ← ii – 1;Vxo ← Vo * cos(theta * conv);Vyo ← Vo * sin(theta * conv);max_time ← -2 * Vyo / g;range(ii) ← Vxo * max_time;end</code></pre><p>下一步，写出落地的表。伪代码如下</p><pre><code class="highlight plaintext">Write headingfor ii = 1:91theta ← ii – 1;print theta and range;end</code></pre><p>我们可以用 max 函数计算最大落地位移。调用这个函数返回最大值和它的位置。伪代码如下</p><pre><code class="highlight plaintext">[maxrange index] ← max(range);Print out maximum range and angle (=index -1);</code></pre><p>我们将用 for 循环嵌套来计算和画出抛物线。。为把所有抛物线都显示在屏幕上，在第一个抛物线的语句后，加上 hold on 命令。每画一个抛物线，就要用到一个 hold on 命令。在画最后一个抛物线时要用到 hold off 命令。我们将在抛物线上取 21 个重要的点，并找了这些的位置。我们将画出这些点。伪代码如下:</p><pre><code class="highlight plaintext">for ii = 5:10:85% Get velocities and max time for this angletheta ← ii – 1;Vxo ← Vo * cos(theta * conv);Vyo ← Vo * sin(theta * conv);max_time ← -2 * Vyo / g;Initialize x and y arraysfor jj = 1:21time ← (jj – 1) * max_time / 20;x(time) ← Vxo * time;y(time) ← Vyo * time + 0.5 * g * time^2;endplot(x,y) with thin green linesSet "hold on" after first plotendAdd titles and axis labels</code></pre><p>最后，用不同的颜色且粗一点的线画出落地位移最大的抛物线。</p><pre><code class="highlight plaintext">Vxo ← Vo * cos(max_angle * conv);Vyo ← Vo * sin(max_angle * conv);max_time ← -2 * Vyo / g;Initialize x and y arraysfor jj = 1:21time ← (jj-1) * max_time / 20;x(jj) ← Vxo * time;y(jj) ← Vyo * time + 0.5 * g * time^2;endplot(x,y) with a thick red linehold off</code></pre><ol start="4"><li>转化 <strong>MATLAB</strong> 语句</li></ol><pre><code class="highlight matlab"><span class="comment">% Script file: ball.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program calculates the distance traveled by a ball</span><span class="comment">% thrown at a specified angle "theta" and a specified</span><span class="comment">% velocity "vo" from a point on the surface of the Earth,</span><span class="comment">% ignoring air friction and the Earth's curvature. It</span><span class="comment">% calculates the angle yielding maximum range, and also</span><span class="comment">% plots selected trajectories.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/10/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% conv Degrees to radians conv factor</span><span class="comment">% gravity Accel. due to gravity (m/s^2)</span><span class="comment">% ii, jj Loop index</span><span class="comment">% index Location of maximum range in array</span><span class="comment">% maxangle Angle that gives maximum range (deg)</span><span class="comment">% maxrange Maximum range (m)</span><span class="comment">% range Range for a particular angle (m)</span><span class="comment">% time Time(s)</span><span class="comment">% theta Initial angle (deg)</span><span class="comment">% traj_time Total trajectory time (s)</span><span class="comment">% vo Initial velocity (m/s)</span><span class="comment">% vxo Xcomponent of initial velocity (m/s)</span><span class="comment">% vyo Ycomponent of initial velocity (m/s)</span><span class="comment">% x Xposition of ball (m)</span><span class="comment">% y Yposition of ball (m)</span><span class="comment">% Constants</span>conv = <span class="built_in">pi</span> / <span class="number">180</span>; <span class="comment">% Degreestoradians conversion factor</span>g = <span class="number">-9.81</span>; <span class="comment">% Accel. due to gravity</span>vo = <span class="number">20</span>; <span class="comment">% Initial velocity</span><span class="comment">%Create an array to hold ranges</span>range = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">91</span>); <span class="comment">% Calculate maximum ranges</span><span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">91</span>theta = ii - <span class="number">1</span>;vxo = vo * <span class="built_in">cos</span>(theta*conv);vyo = vo * <span class="built_in">sin</span>(theta*conv);traj_time = <span class="number">-2</span> * vyo / g;range(ii) = vxo * traj_time;<span class="keyword">end</span><span class="comment">% Write out table of ranges</span>fprintf (<span class="string">'Range versus angle theta:\n'</span>);<span class="keyword">for</span> ii = <span class="number">1</span>:<span class="number">91</span>theta = ii - <span class="number">1</span>;fprintf(<span class="string">' %2d %8.4f\n'</span>,theta, range(ii));<span class="keyword">end</span><span class="comment">% Calculate the maximum range and angle</span>[maxrange index] = <span class="built_in">max</span>(range);maxangle = index - <span class="number">1</span>;fprintf (<span class="string">'\nMax range is %8.4f at %2d degrees.\n'</span>,maxrange, maxangle);<span class="comment">% Now plot the trajectories</span><span class="keyword">for</span> ii = <span class="number">5</span>:<span class="number">10</span>:<span class="number">85</span><span class="comment">% Get velocities and max time for this angle</span>theta = ii;vxo = vo * <span class="built_in">cos</span>(theta*conv);vyo = vo * <span class="built_in">sin</span>(theta*conv);traj_time = <span class="number">-2</span> * vyo / g;<span class="comment">% Calculate the (x,y) positions</span>x = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">21</span>);y = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">21</span>);<span class="keyword">for</span> jj = <span class="number">1</span>:<span class="number">21</span>time = (jj - <span class="number">1</span>) * traj_time/<span class="number">20</span>;x(jj) = vxo * time;y(jj) = vyo * time + <span class="number">0.5</span> * g * time^<span class="number">2</span>;<span class="keyword">end</span><span class="built_in">plot</span>(x,y,<span class="string">'b'</span>);<span class="keyword">if</span> ii == <span class="number">5</span><span class="built_in">hold</span> on;<span class="keyword">end</span><span class="keyword">end</span><span class="comment">% Add titles and axis lables</span>title (<span class="string">'\bfTrajectory of Ball vs Initial Angle \theta'</span>);xlabel (<span class="string">'\bf\itx \rm\bf(meters)'</span>);ylabel (<span class="string">'\bf\ity \rm\bf(meters)'</span>);axis ([<span class="number">0</span> <span class="number">45</span> <span class="number">0</span> <span class="number">25</span>]);grid on;<span class="comment">% Now plot the max range trajectory</span>vxo = vo * <span class="built_in">cos</span>(maxangle*conv);vyo = vo * <span class="built_in">sin</span>(maxangle*conv);traj_time = <span class="number">-2</span> * vyo / g;<span class="comment">% Calculate the (x,y) positions</span>x = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">21</span>);y = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">21</span>);<span class="keyword">for</span> jj = <span class="number">1</span>:<span class="number">21</span>time = (jj - <span class="number">1</span>) * traj_time/<span class="number">20</span>;x(jj) = vxo * time;y(jj) = vyo * time + <span class="number">0.5</span> * g * time^<span class="number">2</span>;<span class="keyword">end</span><span class="built_in">plot</span>(x,y,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">3.0</span>);<span class="built_in">hold</span> off</code></pre><ol start="5"><li>检测程序</li></ol><p>为了检测这个程序，我们计算手动计算了一些值，用来程序的输出结果作比较。</p><p><img src="/medias/20200615175738734.png" alt=""></p><p>当 ball 程序运行时，将 91 行含有角度和位移的结果。为了节省空间我们只打印其中的一部分。</p><p>运行结果：</p><pre><code class="highlight plaintext">&gt;&gt; ballRange versus angle theta:  0   0.0000  1   1.4230  2   2.8443  3   4.2621  4   5.6747  5   7.0805  ... 40  40.1553 41  40.3779 42  40.5514 43  40.6754 44  40.7499 45  40.7747 46  40.7499 47  40.6754 48  40.5514 49  40.3779 50  40.1553... 85   7.0805 86   5.6747 87   4.2621 88   2.8443 89   1.4230 90   0.0000 Max range is  40.7747 at 45 degrees.</code></pre><p><img src="/medias/20200615175934314.png" alt=""></p><p>This example uses several of the plotting capabilities that we introduced in Chapter 3. It uses<br>the axis command to set the range of data to display, the hold command to allow multiple plots to<br>be placed on the same axes, the LineWidth property to set the width of the line corresponding to<br>the maximum-range trajectory, and escape sequences to create the desired title and x- and y-axis<br>labels.</p><p>这个例子用到在第三章中介绍的许多画图功能。我们用 axis 命令来显示水平位移，用 hold 命令让多幅图象在同一坐标系出现。用 linewidth 属性调整曲线的宽度。用转义序列创建所需的标题以及 x，y 坐标轴的标签。</p><p>但是这个程序不是最高效的，因为许多的循环可以用向量算法代替。练习题 4.11 将要求你重写并改进 ball.m。</p><h4 id="4-5-总结">4.5 总结</h4><p>在 <strong>MATLAB</strong> 中有两种基本的循环形式，while 循环和 for 循环。while 循环中，代码的重复的次数是不能确定的，只要满足用户定义的条件，重复就进行下去。相对地，在 for 循环中，代码的重复次数是确定的，在循环开始之前，我们就知道代码重复的次数了。在两种循环中均可使用 break 语句以跳出循环。</p><h5 id="4-5-1-好的编程习惯总结">4.5.1  好的编程习惯总结</h5><p>在有选择结构和循环结构的编程中，要遵循以下的编程指导思想.如果你长期坚持这些原则，你的代码将会有很少的错误，有了错误也易于修改，而且在以后修改程序时，也使别人易于理解.</p><ol><li><p><strong>对于 for 循环体总是要缩进两个或更多空格，以增强程序的可读性。</strong></p></li><li><p><strong>在循环体中绝不修改循环指数的值。</strong></p></li><li><p><strong>在循环执行开始之前，总是要预先分配一个数组。这样能大大增加循环运行的速度</strong></p></li><li><p><strong>如果用可能的话，可用逻辑函数选择数组中的元素。如果逻辑数组进行运算，要比循环快得多。</strong></p></li></ol><h5 id="4-5-2-MATLAB-总结">4.5.2 MATLAB 总结</h5><p>下面的总结列举了本章出现的所有特殊符号，命令和函数，后面跟的是简短的描述。</p><p>break —— break 语句可以中止循环的执行和跳到 end 后面的第一句执行</p><p>continue —— continue 语句只中止本次循环，然后返回循环的顶部。</p><p>for 循环 —— 在 for 循环中，代码的重复次数是确定的</p><p>tic 函数 —— 复位内建计时器</p><p>toc 函数 —— 从最后一次调用 tic 以秒开始计时</p><p>while 循环 —— while 循环中，代码的重复的次数是不能确定的，只要满足用户定义的条件， 重复就进行下去</p><h3 id="第五章-自定义函数">第五章 自定义函数</h3><p>在第三章中，我们强调了好的编程习惯的重要性。我们进行开发的基本手段是<strong>自上而下的编程方法</strong>。在自上而下的编程方法中，它开始于对所要解决问题的精确陈述和定义输入量和输出量。下一步，我们在大面上进行算法的描述，然后把算法分解成一个一个的子问题。再然后，程序员把这一个个子问题进行再一次的分解，直到分解成简单而且能够清晰理解的伪代码。最后把伪代码转化为 <strong>MATLAB</strong> 代码。</p><p>尽管我们在前面的例子中，按照上面的步骤进行了编程。但是产生的结果在某种程度上还是受限制的。因为我们必须把每一个子问题产生的 <strong>MATLAB</strong> 代码嵌入到一个单独的大程序中。在嵌入之前我们无法对每一次子问题的代码进行独立地验证和测试。</p><p>幸运的是，<strong>MATLAB</strong> 有一个专门的机制，在建立最终的程序之前用于独立地开发与调试每一个子程序。每一个子程序都可以独立函数的形式进行编程，在这个程序中，每一个函数都能独立地检测与调试，而不受其他子程序的影响。良好的函数可以大大提高编程的效率。它的好处如下：</p><p><strong>1. 子程序的独立检测</strong></p><p><strong>每一个子程序都可以当作一个独立的单元来编写</strong>。在<strong>把子程序联合成一个的大程序之前，我们必须检测每一个子程序以保证它运转的正确性</strong>。这一步就是我们熟知的单元检测。在最后的程序建立之前，它排除了大量的问题。</p><p><strong>2. 代码的可复用性</strong></p><p>在许多的情况下，一个基本的子程序可应用在程序的许多地方。例如，在一个程序的许多地方，要求对一系列按由低到高的顺序进行排序。你可以编一个函数进行排序，然后当再次需要排序时可以调用这个函数。可重用性代码有两大好处：它<strong>大大提高了整体编程效率</strong>， 它<strong>更易于调试</strong>，因为上面的排序函数只需要调试一次。</p><p><strong>3. 远离意外副作用</strong></p><p>函数通过输入参数列表（input argument list）从程序中读取输入值，通过输出参数列表（output argument list）给程序返回结果。程序中，只有在输入参数列表中的变量才能被函数利用。函数中，只有输出参数列表中的变量才能被程序利用。这是非常重要的，因为在一个函数中的突发性编程错误只会发生错误的函数的变量。一旦一个大程序编写并发行，它还要面临的问题就是维护。程序的维护包括修补错误，修改程序以适应新或未知的环境。作维护工作的程序员在一般情况下不会是程序的原作者。如果程序编写的不好，改动一处代码就可能对程序全局产生负面影响。这种情况的发生，可能是因为变量在其他部分被重新定义或利用。如果程序员改变这个变量，可能会导致后面的程序无法使用。</p><p>好的函数的应用可以通过数据隐藏使问题最小化。在主函数中的变量在函数中是不可见的（除了在输入变量列表中的变量），在主程序中的变量不能被函数任意修改。所以在函数中改变变量或发生错误不会在程序的其他部分发生意外的副作用。</p><p><strong>把大的程序分解成函数，有很多的好处，例如，程序部分的独立检测，代码的可复用性，避免意想不到的错误。</strong></p><h4 id="5-1-matlab-函数简介">5.1 matlab 函数简介</h4><p>到目前为止，我们看到的所有的 M 文件都是脚本文件。脚本文件只是用于存储 <strong>MATLAB</strong> 语句。当一个脚本文件被执行时，和直接在命令窗口中直接键入 <strong>MATLAB</strong> 语句所产生的结果是一样的。脚本文件分享命令窗口中的工作区，所以所有的在脚本文件运行之前定义的变量都可以在脚本文件中运行，所有在脚本文件中创建的变量在脚本文件运行之后仍然存在工作区。一个脚本文件没有输入参数，也不返回结果。但是所有脚本文件可以通过存于工作区中的数据进行交互。</p><p>相对地，<strong>MATLAB</strong> 函数是一种特殊形式的 M 文件，它运行在独立的工作区。它通过输入参数列表接受输入数据，它通过输出参数列表返回结果给输出参数列表。<strong>MATLAB</strong> 函数的基本形式如下：</p><pre><code class="highlight plaintext">function [outarg1, outarg2, ...] = fname(inarg1, inarg2, ...)% H1 comment line% Other comment lines...(Executable code)...(return)</code></pre><p>function 语句标志着这个函数的开始。它指定了函数的名称和输入输出列表。输入函数列表显示在函数名后面的括号中。输出函数列表显示在等号左边的中括号中。（如果只有一个输出参数，中括号可以省略。）</p><p>输入参数列表是名字的列表，这些名字代表从调用者到函数的值。这些名字被称作形参。当函数被调用时，它们只是从调用者得来实际变量的占位符而已。相似地，输出参数列表也形参组成，当函数结束运行时，这些形参是返回到调用者的值的占位符。</p><p>在一个表达式中，调用一个函数需要用到实参列表。在命令窗口直接（或在脚本文件中， 另一个函数中）键入函数的名字就可以调用这个函数了。当调用一个函数时，第一个实参的值用在第一个形参的位置，而且其余的形参和实参都一一对应。</p><p>函数的执行从函数的顶部开始，结束于 return 语句或函数的终点。因为在函数执行到结尾就会结束，所以 return 语句在大部分的程序中没有必要使用。在输出参数列表中每一个项目都必须出现在 function 语句中的左边。当函数返回时，存储于输出函数列表的值就会返回给调用者，用于下一步的运算。</p><p>在一个函数中的初始注释行有特定的目的。在 function 语句的第一个行注释被称为 <strong>H1注释行</strong>。它应当是对本函数功能的总结。这一行的重要性在于，通过 lookfor 命令它能被搜索到并显示出来。从 <strong>H1注释行</strong>到第一个空行或第一个可执行性语句可以通过 help 命令或帮助窗口搜索到。它们则应包含如何使用这个函数的简单总结。</p><p>下面是一个自定义函数的简单例子。函数 dist2 用于计算笛卡尔坐标系中点（<em>x</em>1，<em>y</em>1）与点（<em>x</em>2，<em>y</em>2）之间的距离。(把以下代码保存成 dist2.m 文件)</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">distance</span> = <span class="title">dist2</span> <span class="params">(x1, y1, x2, y2)</span></span><span class="comment">% DIST2 Calculate the distance between two point</span><span class="comment">% Function DIST2 calculates the distance between</span><span class="comment">% two points (x1, y1) and (x2,y2) in a cartesian</span><span class="comment">% coordinate system.</span><span class="comment">%</span><span class="comment">% Calling sequence:</span><span class="comment">% res = dist2(x1, y1, x2, y2)</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% x1 --x-position of point 1</span><span class="comment">% y1 --y-position of point 1</span><span class="comment">% x2 --x-position of point 2</span><span class="comment">% y2 --y-position of point 2</span><span class="comment">% distance --Distance between points</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Pragrammer Description of change</span><span class="comment">% ======== ========== ================</span><span class="comment">% 12/15/98 S.J.Chapman Original code</span><span class="comment">%</span><span class="comment">% Calculate distance.</span>distance = <span class="built_in">sqrt</span>((x2-x1).^<span class="number">2</span> + (y2-y1).^<span class="number">2</span>);</code></pre><p>这个函数有 4 个输入参数各和 1 个输出参数。一个简单的利用这个函数的例子显示如下：</p><pre><code class="highlight matlab"><span class="comment">% Script file: test_dist2.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program test2 function dist2.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Pragrammer Description of change</span><span class="comment">% ======== ========== ================</span><span class="comment">% 12/15/98 S.J.Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% ax --x-position of point a</span><span class="comment">% ay --y-position of point a</span><span class="comment">% bx --x-position of point b</span><span class="comment">% by --x-position of point b</span><span class="comment">%</span><span class="comment">% Get input data.</span><span class="built_in">disp</span>(<span class="string">'Calculate the distance between two points:'</span>);ax = input (<span class="string">'Enter x value of point a:'</span>);ay = input (<span class="string">'Enter y value of point a:'</span>);bx = input (<span class="string">'Enter x value of point b:'</span>);by = input (<span class="string">'Enter y value of point b:'</span>);<span class="comment">% Evaluate function</span>result = dist2 (ax, ay, bx, by);<span class="comment">% Write out result.</span>fprintf(<span class="string">'The distance between points a and b is %f \n'</span>, result);</code></pre><p>当脚本文件被执行时，它的结果显示如下：</p><pre><code class="highlight matlab">&gt;&gt; test_dist2Calculate the distance between two points:Enter x value of point a:<span class="number">1</span>Enter y value of point a:<span class="number">1</span>Enter x value of point b:<span class="number">4</span>Enter y value of point b:<span class="number">5</span>The distance between points a and b is <span class="number">5.000000</span></code></pre><p>通过手动运算我们可知程序运算的结果是正确的。</p><p>函数 dist2 也支持 <strong>MATLAB</strong> 帮助子系统。如果你键入“help dist2”，将会得到的结果是：</p><pre><code class="highlight matlab">&gt;&gt; help dist2dist2 Calculate the distance between two point  Function dist2 calculates the distance between  two points (x1, y1) and (x2,y2) in a cartesian  coordinate system.   Calling sequence:  res = dist2(x1, y1, x2, y2)   Define variables:  x1 --x-position of point <span class="number">1</span>  y1 --y-position of point <span class="number">1</span>  x2 --x-position of point <span class="number">2</span>  y2 --y-position of point <span class="number">2</span>  distance --Distance between points   Record of revisions:  Date Pragrammer Description of change  ======== ========== ================  <span class="number">12</span>/<span class="number">15</span>/<span class="number">98</span> S.J.Chapman Original code   Calculate distance.</code></pre><p>相似地，键入“lookfor dist2”后将会产生如下的结果：</p><pre><code class="highlight matlab">&gt;&gt; lookfor dist2DIST2 Calculate the distance between two pointtest_dist2.m: <span class="comment">% Script file: test_dist2.m</span>&gt;&gt; lookfor distancedist2 Calculate the distance between two point</code></pre><p>为了仔细观察工作区在函数执行前后的变化，我们将在 <strong>MATLAB</strong> 调试器中加载函数 dist2 和脚本文件 test_dist2。在函数加载前，加载中，加载后设置断点（如图 5.1 所示）。 当程序中止在函数调用之前的断点，它的工作区如图 5.2(a)所示。注意工作区中只有变量 ax，ay，bx 和by。当程序中止在函数调用过程中的断点，它的工作区如图 5.2(b)所示。注意工作区中只有变量 x1，x2，y1，y2 和distance。当程序中止在函数调用后的断点，它的工作区如图 5.2©所示。注意工作区中原来的变量又重复出现，再加上函数返回的变量 result。这些图显示了 <strong>MATLAB</strong> 调用 M 文件的过程中工作区的变化。</p><p><img src="/medias/20200616161544827.png" alt="图 5.1 M 文件和函数 dist2 将会被加载到调试器，在函数调用前，调用过程中，调用后设置合适断点"></p><p><img src="/medias/20200616162050415.png" alt="图 5.2(a)"></p><p><img src="/medias/20200616163434165.png" alt="图 5.2(b)"></p><p><img src="/medias/20200616162337790.png" alt="图 5.2(c)"></p><p>图 5.2  (a)  在函数调用之前的工作区（b）函数调用过程中的工作区（c）函数调用之后的工作区</p><h4 id="5-2-在-MATLAB-中的变量传递：按值传递机制">5.2 在  MATLAB  中的变量传递：按值传递机制</h4><p>maltab 程序与它们函数之间的交互用是<strong>按值传递机制</strong>。当一个函数调用发生时，<strong>MATLAB</strong> 将会复制实参生成一个副本，然后把它们传递给函数。这次复制是非常重要的， 因为它意味着虽然函数修改了输入参数，但它并没有影响到调用者的原值。这个特性防止了因函数修改变量而导致的意想不到的严重错误。</p><p>这一特性将在下面的函数中得到说明。这个函数中有两个输入参数：a 和 b。在它的计算中，它修改了变量的值：</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">out</span> = <span class="title">sample</span><span class="params">(a, b)</span></span>fprintf(<span class="string">'In Sample: a = %f, b = %f %f\n'</span>,a,b);a = b(<span class="number">1</span>) + <span class="number">2</span>*a;b = a .* b;out = a + b(<span class="number">1</span>);fprintf(<span class="string">'In Sample: a = %f, b = %f %f \n'</span>,a,b);</code></pre><p>下面是调用这个函数的检测程序：</p><pre><code class="highlight matlab">a = <span class="number">2</span>; b = [<span class="number">6</span> <span class="number">4</span>];fprintf(<span class="string">'Before sample: a = %f, b = %f %f\n'</span>, a, b);out = sample(a, b);fprintf(<span class="string">'After sample: a = %f, b = %f %f\n'</span>,a,b);fprintf(<span class="string">'After sample: out = %f \n'</span>, out);</code></pre><p>当这个程序被执行将产生如下的结果：</p><pre><code class="highlight plaintext">&gt;&gt; test_sampleBefore sample: a = 2.000000, b = 6.000000 4.000000In Sample: a = 2.000000, b = 6.000000 4.000000In Sample: a = 10.000000, b = 60.000000 40.000000After sample: a = 2.000000, b = 6.000000 4.000000After sample: out = 70.000000</code></pre><p>注意，a 和 b 在函数 sample 内都改变了，但这些改变对调用函数中的值并没有任何的影响。</p><p>C 语言的使用者对按值传递机制比较熟悉，因为 C 应用它把标量值传递给函数。尽管 C 语言不能用按值传递机制传递数组，所以对在 C 语言函数中的形参数组进行意想不到的修改将会导致在调用程序时产生错误。<strong>MATLAB</strong> 改进了按值传递机制，既适于标量，又适应于数组（在 <strong>MATLAB</strong> 中参数传递过程中的执行要远比上面讨论中指出的要复杂的多。正如上面指出的，与按值传递相联系的复制将花去大量的时间，但是保护程序以至于不产生错误。实际上，<strong>MATLAB</strong> 用了两种方法，它先对函数的每一个参数进行分析，确定函数的那些参数进行了修改。如果函数没有修改这个参数，它将不会对此参数进行复制，而是简单地指向程序外面的外面的变量，如果函数修改了这个参数，那么这个复制就会被执行）。</p><p><img src="/medias/20200616164408737.png" alt=""></p><p><img src="/medias/20200616164714175.png" alt=""></p><pre><code class="highlight plaintext">x ← r * cos(theta * pi/180)y ← r * sin(theta * pi/180)</code></pre><p><img src="/medias/20200616164941219.png" alt=""></p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="params">[x, y]</span> = <span class="title">polar2rect</span><span class="params">(r, theta)</span></span><span class="comment">%POLAR2RECT Convert rectangular to polar coordinates</span><span class="comment">% Function POLAR2RECT accepts the polar coordinates</span><span class="comment">% (r, theta), where theta is expressed in degrees,</span><span class="comment">% and converts them into the rectangular coordinates (x, y)</span><span class="comment">%</span><span class="comment">% Calling sequence:</span><span class="comment">% [x, y] = polar2rect(r, theta)</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% r --Length of polar vector</span><span class="comment">% theta --Angle of vector in degrees</span><span class="comment">% x --x-position of point</span><span class="comment">% y --y-position of point</span><span class="comment">% </span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ====== =========== ================</span><span class="comment">% 09/19/00 S.J.Chapman Original code</span>x = r * <span class="built_in">cos</span>(theta * <span class="built_in">pi</span>/<span class="number">180</span>);y = r * <span class="built_in">sin</span>(theta * <span class="built_in">pi</span>/<span class="number">180</span>);</code></pre><p><img src="/medias/20200616165120294.png" alt=""></p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="params">[r, theta]</span> = <span class="title">rect2polar</span><span class="params">(x, y)</span></span><span class="comment">% RECT2POLAR Convert rectangular to polar coordinates</span><span class="comment">% Function RECT2POLAR accept the rectangular coordinates</span><span class="comment">% (x, y) and converts them into the polar coordinates</span><span class="comment">% (r, theta), where theta is expressed in degrees.</span><span class="comment">%</span><span class="comment">% Calling sequence:</span><span class="comment">% [r, theta] = rect2polar(x, y)</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% r     --Length of polar vector</span><span class="comment">% theta --Angle of vector in degrees</span><span class="comment">% x     --x-position of point</span><span class="comment">% y     --y-position of point</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Descriptoin of change</span><span class="comment">% ==== ========= ===============</span><span class="comment">% 09/19/00 S.J.Chapman Original code</span>r = <span class="built_in">sqrt</span>( x .^<span class="number">2</span> + y .^<span class="number">2</span>);theta = <span class="number">180</span>/<span class="built_in">pi</span> * <span class="built_in">atan2</span>(y, x);</code></pre><p><img src="/medias/20200616165330220.png" alt=""></p><pre><code class="highlight plaintext">&gt;&gt; [r, theta]=rect2polar(4,3)r =     5theta =   36.8699&gt;&gt; [r, theta]=rect2polar(-4,3)r =     5theta =  143.1301&gt;&gt; [r, theta]=rect2polar(-4,-3)r =     5theta = -143.1301&gt;&gt; [r, theta]=rect2polar(4,-3)r =     5theta =  -36.8699&gt;&gt; [x, y]= polar2rect(5,36.8699)x =    4.0000y =    3.0000&gt;&gt; [x, y]= polar2rect(5,-143.1301)x =   -4.0000y =   -3.0000&gt;&gt; [x, y]= polar2rect(5,143.1301)x =   -4.0000y =    3.0000&gt;&gt; [x, y]= polar2rect(5,-36.8699)x =    4.0000y =   -3.0000</code></pre><p>在笛卡尔坐标的四个象限内得到的结果均是正确的。</p><h5 id="例-5-2-数据排序">例 5.2 数据排序</h5><p>在许多的科研和工程应用中，随机输入一组数据并对它进行由低到高排序或由高到低进行排序是十分必要的。假设你是一个动物学家，你正在研究大量的动物，并想要鉴定这些动物最大的 5%。</p><p>解决这个问题的最直接的方法是对这些动物的大小按照降序进行排列，取其前 5%。对数据进行升序或降序排列似乎是一件非常容易的工作。毕竞，我们经常作这样的事。有一个简单的例子，把数据（10，3，6，4，9）按升序排列成（3，4，6，9，10）。我们应当怎样做呢。我们首先应当浏览整个输入数据列表（10，3，6，4，9）找出其中的最小值（3），然后浏览剩下的输入数据（10，6，4，9）并找到下一个最小值（4），然后继续重复上面的步骤，直到所有的列表中的所有数都能排完。</p><p>实际上，排序是一个非常困难的工作。当值的个数增加时，用上面简单的排序方法进行运算所消耗的时间将会迅速增加，因为每排一个数就要浏览一个遍输入值。对于大的数据集合，这个方法因太耗时，而不用。更糟糕的是，如果有大量的数据占有计算机的大部分内存我们将如何排序。开发大数据集合的高效排序技术是一个相当活跃的研究领域，它已经成为了一个新的科目。</p><p>在这个例子中，我们将尽可能简单的算法来说明排序的内容。这个最简单的算法叫做选择性排序（selection sort）。它只是对应上面描述方法的计算机执行。选择性排序的基本算法如下：</p><ol><li><p>浏览被排序数的列表，并找出其中的最小值。把最小值与排在最前面的数进行交换。如要排在最前面的数就是这个数表最小值，什么也不用做。</p></li><li><p>从这个数据列表的第二个数开始浏览找到第二个最小的数。把这个数与当前排在第二个数进行交换。如果当前排在第二位的数就是下一个最小值，那么什么也不用做。</p></li><li><p>从数据列表的第三个数开始找到第三个最小的数。把这个数与当前排在第三个数进行交换。如果当前排在第三位的数就是第三个最小值，那么什么也不用做。</p></li><li><p>重复以上步骤直至最后一位置排完。当最后一个位置排完后，排序结束。</p></li></ol><p>注意：如果我们要对 N 个数进行排序，这个排序算法要进行 N-1 次浏览才能完成排序。</p><p>这个步骤的说明如图 5.4 所示。因为有 5 个数进行排序，所以要对数据进行 4 次浏览。首先对整个数据列表进行浏览，得到最小值 3，把 3 置于第一位，故与 10 进行交换。从第二位开始浏览，得到第二个最小值 4，与 10 交换。从第三位进行浏览，得到最小值 6，6 恰在第三位上，不用交换。从第四位开始浏览，得到最小值 9，与排在第 4 位的 10 交换。排序结束。</p><p><strong>性能提示</strong></p><p><strong>选择性编程算法是一种极易理解的编程算法，但它的效率是极低的。我们绝不能用它进行大数据集合的排序(例如含有1000个元素的数组)。这个几年里，计算机专家己经发展了许多高效的排序算法。内置于 MATLAB 的 sort 和 sortrows 函数是非常高效的，在实际工作中我们应当应用这些函数。</strong></p><p><img src="/medias/20200616172732136.png" alt="图 5.4 选择性排序的一个简单例子"></p><p>我们将开发一个程序，读取从命令窗口读取一个数据集，对它进行升序排列，并出排序后的结果。这个排序将会由独立的自定义函数来完成。</p><p>答案：</p><p>这个程序必须提示使用者提供输入数据，对其进行排序，并输出排序结要。这个程序的设计过程如下：</p><ol><li><p>陈述问题我们刚才没有指定要排序的数据类型。如果数据是数字，那么问题的陈述如下。开发一个程序，它能够读取在命令窗口中输入的任意类型的数字，用独立的自定义函数对读取的值进行排序，并在命令窗口写出排序结果。</p></li><li><p>定义输入输出量这个程序的输入值是在命令窗口键入的数字值。这个程序的输出量是写在命令窗口中的排序结果。</p></li><li><p>设计算法这个问题可以分解为三大步：</p></li></ol><pre><code class="highlight plaintext">Read the input data into an arraySort the data in ascending orderWrite the sorted data</code></pre><p>第一大步是读取数据。我们必须提示使用者输入输入数据的个数，然后读取数据。因为我们知道所要读取的数的确切个数，所以可以用 for 循环主读取合适的数据。它的伪代码如下：</p><pre><code class="highlight plaintext">Prompt user for the number of data valuesRead the number of data valuesPreallocate an input arrayfor ii = 1:number of valuesPrompt for next valueRead valueend</code></pre><p>下一步，我们必须要用独立的函数对数据进行排序。我们需要对数据进行 naval-1 次浏览，每一次找出一个最小值。我们将用一个指针来寻找每一次浏览的最小值。一量最小值被找到，如果它不在列表的顶端，它就与列表顶端的元素进行交换。伪代码如下：</p><pre><code class="highlight plaintext">for ii = 1:nvals -1% Find the minimum value in a(ii) through a(nvals)iptr ← iifor jj = ii +1 to nvalsif a(jj) &lt; a(iptr)iptr ← a(iptr)endend% iptr now points to the min value, so swap a(iptr)% with a(ii) if iptr ~= ii.if ii ~= iptrtemp ← a(ii)a(ii) ← a(iptr)a(iptr) ← tempendend</code></pre><p>最后一步是输出排序结果。这个步骤的伪代码不需要重复。最终的伪代码是这三大步伪代码的联合。</p><ol start="4"><li>把伪代码转化为 <strong>MATLAB</strong> 语言选择性排序的 <strong>MATLAB</strong> 代码如下所示：</li></ol><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">out</span> = <span class="title">ssort</span><span class="params">(a)</span></span><span class="comment">% SSORT Selection sort data in ascending order</span><span class="comment">% Function SSORT sorts a numeric data set into</span><span class="comment">% ascending order. Note that the selection sort</span><span class="comment">% is relatively inefficient. DO NOT USE THIS</span><span class="comment">% FUNCTION FOR LARGE DATA SETS. Use MATLAB's</span><span class="comment">% "sort" function instead.</span><span class="comment">% Define variables:</span><span class="comment">% a     --Input array to sort</span><span class="comment">% ii    --Index variable</span><span class="comment">% iptr  --Pointer to min value</span><span class="comment">% jj    --Index variable</span><span class="comment">% nvals --Number of values in "a"</span><span class="comment">% out   --Sorted output array</span><span class="comment">% temp  --Temp variable for swapping</span><span class="comment">% Record of revisions:</span><span class="comment">% Date     Programmer       Description of change</span><span class="comment">% ====     ==========       =====================</span><span class="comment">% 12/19/98 S. J. Chapman       Original code</span><span class="comment">% Get the length of the array to sort</span>nvals = <span class="built_in">size</span>(a,<span class="number">2</span>);<span class="comment">% Sort the input array</span><span class="keyword">for</span> ii = <span class="number">1</span>:nvals<span class="number">-1</span><span class="comment">% Find the minimum value in a(ii) through a(n)</span>iptr = ii;<span class="keyword">for</span> jj = ii+<span class="number">1</span>:nvals<span class="keyword">if</span> a(jj) &lt; a(iptr)iptr = jj;<span class="keyword">end</span><span class="keyword">end</span><span class="comment">% iptr now points to the minimum value, so swap a(iptr)</span><span class="comment">% with a(ii) if ii ~= iptr.</span><span class="keyword">if</span> ii ~= iptrtemp = a(ii);a(ii) = a(iptr);a(iptr) = temp;<span class="keyword">end</span><span class="keyword">end</span><span class="comment">% Pass data back to caller</span>out = a;</code></pre><p>调用选择性排序函数的程序如下：</p><pre><code class="highlight matlab"><span class="comment">% Script file: test_ssort.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To read in an input data set, sort it into ascending</span><span class="comment">% order using the selection sort algorithm, and to</span><span class="comment">% write the sorted data to the Command window. This</span><span class="comment">% program calls function "ssort" to do the actual</span><span class="comment">% sorting.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date  Programmer  Description of change</span><span class="comment">% ====      ==========  =====================</span><span class="comment">% 12/19/98 S. J. Chapman        Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% array --Input data array</span><span class="comment">% ii --Index variable</span><span class="comment">% nvals --Numberof input values</span><span class="comment">% sorted --Sorted data array</span><span class="comment">% Prompt for the number of values in the data set</span>nvals = input(<span class="string">'Enter number of values to sort: '</span>);<span class="comment">% Preallocate array</span>array = <span class="built_in">zeros</span>(<span class="number">1</span>,nvals);<span class="comment">% Get input values</span><span class="keyword">for</span> ii = <span class="number">1</span>:nvals<span class="comment">%Prompt for next value</span>string = [<span class="string">'Enter value '</span> int2str(ii) <span class="string">': '</span>];array(ii)=input(string);<span class="keyword">end</span><span class="comment">% Now sort the data</span>sorted = ssort(array);<span class="comment">% Display the sorted result.</span>fprintf(<span class="string">'\nSorted data:\n'</span>);<span class="keyword">for</span> ii = <span class="number">1</span>:nvalsfprintf(<span class="string">' %8.4f \n'</span>,sorted(ii));<span class="keyword">end</span></code></pre><ol start="5"><li>检测程序</li></ol><p>为了检测这个程序，我们应当创建一个输入数据集，并运行这个程序。这个数据集应当包含由正负数混合组成，还有至少包括一个完全一样的值，以观察在这些情况下程序是否正常工作。</p><pre><code class="highlight plaintext">&gt;&gt; test_ssortEnter number of values to sort: 6Enter value 1: -5Enter value 2: 4Enter value 3: -2Enter value 4: 3Enter value 5: -2Enter value 6: 0Sorted data:-5.0000-2.0000-2.00000.00003.00004.0000</code></pre><p>对于我们检测的数据，程序给出了正确的结果。注意从正数到负数，还有重复值，这个程序工作正常。</p><h4 id="5-3-选择参数">5.3 选择参数</h4><p>许多的 <strong>MATLAB</strong> 函数都支持选择性输入参数和输出参数。例如，我们调用 plot 函数， 输入参数既可以少到 2 个，也可以多到 7 个参数。从另一方面说，函数 max 既支持一个输出参数，也支持两个输出参数。如果只有一个输出参数，max 将会返回函数的最大值。如果有两个输出参数将会返回数组的最大值和最大值所在的位置。如何知道一个 <strong>MATLAB</strong> 函数有几个输入输出参数呢，以及函数相应的功能呢？</p><p>在<strong>MATLAB</strong> 中有八种专门的函数用于获取关于选择性参数的信息和用于报告这些参数的错误。</p><table><thead><tr><th>-</th><th>-</th></tr></thead><tbody><tr><td>nargin</td><td>这个函数返回调用这个函数时所需要的实际输入参数的个数</td></tr><tr><td>nargout</td><td>这个函数返回调用这个函数时所需要的实际输出参数的个数</td></tr><tr><td>nargchk</td><td>如要一个函数调用被调用时参数过多或过少，那么 nargchk 函数将返回一个标准错误信息</td></tr><tr><td>error</td><td>显示错误信息，并中止函数以免它产生这个错误。如果参数错误是致命的，这个函数将会被调用</td></tr><tr><td>warning</td><td>显示警告信息并继续执行函数，如果参数错误不是致命的，执行还能继续，则这个将会被调用</td></tr><tr><td>inputname</td><td>这个函数将会返回对于特定参数个数的实际变量名</td></tr></tbody></table><p>函数 nargin 和 nargout 只用在用户自定义函数中。当他们被调用时，这些函数将会分别返回实际输入、输出参数的个数。如果一个函数在被调用时含有过多或过少的参数，函数</p><p>nargchk 将会产生一个包含标准错误的字符串。此函数的语法如下：</p><pre><code class="highlight plaintext">message = nargchk(min_args, max_args, num_args);</code></pre><p>其中 min_args 是指参数的最小个数，max_args 是指数的最大个数，num_args 是指参数的实际个数。如果参数的个数不在允许的范围，将会产生一个标准的错误信息。如果参数的个数在允许的范围之内，那么这个函数将返回一个空字符。</p><p>函数 error 是用于显示标准的错误信息和用于中止导致错误信息的自定义函数的一种标准方式。这个函数的语法是 error(‘msg’)，其中 msg 是一个包含错误信息的字符串。当 error 函数执行，它将会中止当前函数，并返回到键盘输入状态，在命令窗中显示出错误信息。如果这个信息字符中为空，error 函数将什么也不做，当前函数继续执行。如果当前函数与线程数 nargchk 工作良好，当有错误发生时，error 将产生一个信息字符串，当没有错误时，error 将产生一个空字符。</p><p>函数 warning 是用于显示函数或线程数中的警告信息的一种标准方法。此函数的语法为warning(‘msg’)，其中 msg 是指含有警告信息的字符串。当执行 warning 函数时，它将在命令窗口显示警告信息，和列出警告出现的函数和线程数。如果信息子符串为空，warning 将什么也不做。在其他情况下，函数将继续执行。</p><p>当一个函数被调用时，inputname 函数将会返回实参的名字。inputname 函数的语法为</p><pre><code class="highlight plaintext">name = inputname(argno);</code></pre><p>其中 argno 是参安息的个数。如果这个参数是一个变量，那么返回将只是变量名。如果参数是一个表达式，那么这个函数将会返回空字符。例如考虑下面的函数</p><pre><code class="highlight plaintext">function myfun(x, y, z) name = inputname(2);   disp(['The second argument is named ' name]);</code></pre><p>当这个函数被调用时，结果如下</p><pre><code class="highlight plaintext">&gt;&gt; myfun(dog,cat)   The second argument is named cat    &gt;&gt; myfun(1,2+cat)    The second argument is named</code></pre><p>函数 inputname 用来显示警告或错误信息中的参数名非常有用。</p><h5 id="例-5-3-选择性参数的应用">例 5.3 选择性参数的应用</h5><p>通过创建函数把直角坐标值（<em>x</em>，<em>y</em>）转化相应的极坐标值，我们向大家说选择性参数的应用。这个函数支持两个输入参数，<em>x</em> 和 <em>y</em>。但是，如果支持只有一个参数的情况，那么函数就假设 <em>y</em> 值为 0，并使用它进行运算。函数在一般情况下输出量为模与相角（单位为度）。但只有一个输出参数只有一个时，它只返回模。函数如下所示。</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="params">[mag, angle]</span> = <span class="title">polar_value</span><span class="params">(x, y)</span></span><span class="comment">% POLAR_VALUE Converts(x, y) to (r, theta)</span><span class="comment">% Punction POLAR_VALUE converts an input(x,y)</span><span class="comment">% va1ue into (r, theta), with theta in degrees.</span><span class="comment">% It illustrates the use of optional arguments.</span><span class="comment">% Define variables:</span><span class="comment">% angle --Angle in degrees</span><span class="comment">% msg --Error message</span><span class="comment">% mag --Magnitude</span><span class="comment">% x --Input x value</span><span class="comment">% y --Input y value(optional)</span><span class="comment">% Record Of revisions:</span><span class="comment">% Date   Programmer  Description of change</span><span class="comment">% ========   ==============    ========================</span><span class="comment">% 12/16/98   S.J.Chapman Original code</span><span class="comment">% Check for a legal number of input arquments</span>msg = nargchk(<span class="number">1</span>,<span class="number">2</span>,nargin);error(msg);<span class="comment">% If the y argument is missing, set it to 0.</span><span class="keyword">if</span> nargin &lt; <span class="number">2</span>y = <span class="number">0</span>;<span class="keyword">end</span><span class="comment">% Check for (0,0) input argument, and print out</span><span class="comment">% a warning message.</span><span class="keyword">if</span> x == <span class="number">0</span> &amp; y == <span class="number">0</span>msg = <span class="string">'Both x and y are zero: angle is meaningless!'</span>;warning(msg);<span class="keyword">end</span><span class="comment">% Now calculate the magnitude</span>mag = <span class="built_in">sqrt</span>(x .^<span class="number">2</span> + y .^<span class="number">2</span>);<span class="comment">% If the second output argument is present,calculate</span><span class="comment">% angle in degrees</span><span class="keyword">if</span> nargout == <span class="number">2</span><span class="built_in">angle</span> = <span class="built_in">atan2</span>(y,x) * <span class="number">180</span>/<span class="built_in">pi</span>;<span class="keyword">end</span></code></pre><p>我们通过在命令窗口反复调用这个函数来检测它。首先，我们用过多或过少的参数来调用这个函数。</p><pre><code class="highlight plaintext">&gt;&gt; [mag angle]=polar_value??? Error using ==&gt; polar_valueNot enough input arguments.&gt;&gt; [mag angle]=polar_value(1,-1,1)??? Error using ==&gt; polar_valueToo many input arguments.</code></pre><p>在两种情况下均产生了相应的错误信息。我们将用一个参数或两个参数调用这个函数。</p><pre><code class="highlight plaintext">&gt;&gt; [mag angle]=polar_value(1)mag =1angle =0&gt;&gt; [mag angle]=polar_value(1,-1)mag =1.4142angle =-45</code></pre><p>在这两种情况下均产生了正确的结果。我们调用这个函数使之输出有一个或两个参数。</p><pre><code class="highlight plaintext">&gt;&gt; mag = polar_value(1,-1)mag =1.4142&gt;&gt; [mag angle]=polar_value(1,-1)mag =1.4142angle =-45</code></pre><p>这个函数提供了正确的结果。最后当 x=0，y=0 时，调用这个函数。</p><pre><code class="highlight plaintext">&gt;&gt; [mag angle] = polar_value(0,0)Warning: Both x and y are zero: angle is meaningless!&gt; In polar_value at 27mag =0angle =0</code></pre><p>在这种情况下，函数显示了警告信息，但执行继续。</p><p>注意一个 <strong>MATLAB</strong> 函数将会被声明有多个输出函数，超出了实际所需要的，这是一种错误。事实上，函数没有必要调用函数 nargout 来决定是否有一个输出参数存在。例如，考虑下面的函数。</p><pre><code class="highlight plaintext">function [z1, z2] = junk(x, y)z1 = x + y;z2 = x - y;</code></pre><p>这个函数输出可以有一个或两个输出参数。</p><pre><code class="highlight plaintext">&gt;&gt; a = junk(2,1)a =3&gt;&gt; [a b] = junk(2,1)a =3b =1</code></pre><p>在一个函数中检查 nargout 的原因是为了防止无用的工作。如果我们找不到输出结果，为什么不在第一位置计算出来？程序员可以不必为无用的运算耐恼，也能加速程序的运算。</p><h4 id="5-4-用全局内存分享数据">5.4 用全局内存分享数据</h4><p>我们已经看到了，函数与程序之间交换数据是通过参数列表来完成的。当一个函数被调用时，每一个实参都会被复制，而这个复制量将会在函数中用到。</p><p>对于参数列表还有一些补充，<strong>MATLAB</strong> 函数与每一个参数或基本工作区通过全局内存交换数据。全局内存是指内存的一种特殊类型，它能够被所有的工作区访问。如果一个变量在函数中被声明全局变量，那么它将占用的是全局内存，而不是本地工作区。如果相同的变量在另一个函数中被声明为全局变量，那么这个变量所占有内存区域就是第一个函数中的相同变量。声明有全局变量的脚本文件或函数将有办法访问相同的值，所以全局变量为函数之间分享数据提供了一个方法。</p><p>全局变量的声明要用到 global 主语句，基本形式如下</p><pre><code class="highlight plaintext">global var1 var2 var3 ...</code></pre><p>其中 var1，var2，var3 等等是用全局内存的变量。为了方便，全局变量将在函数开头被声明，但是实际上没有这个必要。</p><p><strong>最是把全局变量声明在函数的开头，这样可以区别于本地变量</strong>。</p><p>每一个全局变量在函数第一次使用之前必须声明如果在本地工作区中已经被创建，那么声明为再次声明全局变量将会产生错误。为了避免这种错误，在函数中的初始注释行之后和第一个可执行性语句之前声明全局变量。</p><p><strong>在函数中的初始注释行之后和第一个可执行性语句之削声明全局变量。</strong></p><p>全局变量尤其适用于在许多函数分享大容量数据，这样全部的数据在每一次被函数调用时就不必再复制了，用全局变量在函数之间交换数据的不利一面为函数只能为特定的数据工作。通过输入数据参数交换数据的函数能用不同的参数调用它，而用全局变量进行数据交换的函数必须进行修改，以许它和不同的数据进行工作。</p><p><strong>在一个程序，你能利用全局内存，在函数之间对大规模数据进行交换</strong>。</p><h5 id="例-5-4-随机数发生器">例 5.4 随机数发生器</h5><p>随机数发生器对真实世界进行精确度量是十分重要的。对于每一个测量值来说，都有一定的测量噪声（误差）。对于系统的设计来说，这个情况必须要重要考虑，例如，真实世界中机械装置（飞机等）的运转。好的工程设计必须把他的测量误差控制在一定的范围之内， 不能因误差导致系统的不稳定。</p><p>在系统建立之前，许多的工程设计的检测是通过系统操作的模拟（simulation）来完成的。模拟包括系统动作的数学模型和符合这个模型的输入数据。如果这个模型对<strong>模拟输入数据</strong>反应正确，那么我们就能合理的证明，真实世界中的系统对真实世界中输入值有正确的反应。</p><p>提供给数学模型的<strong>模拟输入数据</strong>必须带有<strong>模拟测量噪声</strong>。模拟测量噪声是指加入理想输入值中的一系列随机数。模拟噪声一般由<strong>随机数发生器</strong>产生。</p><p><strong>随机数发生器</strong>是一个函数，当它每一次被调用时，将会返回一个不同的随机出现的数。事实上，这些数是由一个<strong>确定性算法</strong>产生的，它们只是表现为随机。但是，如果产生它们的算法足够复杂，那么应用于模拟中的这些数就足够地随机。</p><p>下面是一个简单随机数发生器的算法。它是利用大数求余的不可预知性。考虑下面的等式。</p><p><em>n</em>~i+1~ = <em>mod</em>(8121n~i~ + 28411, 134456)                                         (5.6)</p><p>假设 n~i~ 为非负整数，那么由于求余函数的关系，<em>n</em>~i+1~ 只能在 0 到 13445 之间的整数中进行取值。重复以上过程，得到的结果永远是在区间[0, 134455]中。如果我们事先不知道 8121，28411 和 134456 这三个数你很可能猜测这个顺序是由 <em>n</em> 值产生的。进一步说，它说明，所有在 0 到 13445 之间的整数出现的次序是等可能性。由于这些属性，等式（5.6）可以当一个简单的随机数发生器的基础。</p><p>现在我们用公式（5.6）设计一个随机数发生器，它的输出是一个实数，其取值范围这[0.0, 1.0]。</p><p>答案：</p><p>我们要编写一个函数，在每一次调用时，它能产生 0≤ran&lt;1.0 的随机数。随机数的产生将依赖于下面的公式。</p><img src="/medias/20200616184252386.png" style="zoom: 50%;"><p>通过公式 5.6 n~i~，在 0 到 134455 之间进行取值。公式 5.6，5.7 中产生的随机数的顺序取决于 <em>n</em>~0~的初始值(种子，seed)。我们要为用户提供一种途径，让它用于指定 <em>n</em>~0~，这样每次运行这个函数得到的随机数顺序都是不一样的。</p><ol><li>陈述问题</li></ol><p>编写一个函数 random0，使之产生一个数组，数组中包括一个或多个随机数，它的取值范围是 0≤ran&lt;1.0，它的顺序由公式 5.6 和 5.7 指定。函数应当有一个或多个输入参数(n和m)，用来指定返回数组的大小。如果它有一个参数，函数将产生一个 <em>n</em> 阶方阵; 如果有两个参数，函数将会产生一个 <em>n</em>×<em>m</em> 的数组。种子 <em>n</em>~0~ 的初始值将会由函数 seed 指定。</p><ol start="2"><li>定义输入量和输出量</li></ol><p>在这个问题中共有两个函数: seed 和random0。函数 seed 的输入是一个整数。这个函数没有输出。random0 的输入量是一个或两个整数。如果它有一个参数，函数将产生一个 n 阶方阵;如果有两个参数，函数将会产生一个 <em>n</em>×<em>m</em> 的数组。这个函数的输出是由在 0.0 和 1.0 之间的随机数组成的数组</p><ol start="3"><li>定义算法</li></ol><p>函数 random() 的伪代码如下：</p><pre><code class="highlight plaintext">function ran = random0 (n, m)Check for valid argumentsSet m ← n if not suppliedCreate output array with "zeros" functionfor ii = 1:number of rowsfor jj = 1: number of columnsISEED ← mod (8121 * ISEED + 28441, 134456)ran(ii,jj) ← ISEED /134456endend</code></pre><p>其中，ISEED 是全局变量，所以它能被所有的函数调用。函数 seed 的伪代码如下:</p><pre><code class="highlight plaintext">function seed ( new_seed)new_seed ← round( new_seed)ISEED ← abs( new_seed)</code></pre><p>当用户输入不是整数，round 函数会对其进行四舍五入。如果输入的是一个负数，abs 将会把他取正。用户事先不需知道只有正整数才是合法的种子。</p><p>ISEED 是全局变量，所以它能被所有的函数调用。</p><ol start="4"><li><p>把算法转化为 <strong>MATLAB</strong> 语句</p><p>函数 random0 的代码如下:</p></li></ol><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">ran</span> = <span class="title">random0</span><span class="params">(n,m)</span></span><span class="comment">% RANDOM0 Generate uniform random numbers in [0,1)</span><span class="comment">% Function RANDOM0 generates an array of uniform</span><span class="comment">% random numbers in the range [0,1). The usage</span><span class="comment">% is:</span><span class="comment">%</span><span class="comment">% random0(n) --Generate an n x n array</span><span class="comment">% random0(n,m) --Generate an n x m array</span><span class="comment">% Define variables:</span><span class="comment">% ii --Index variable</span><span class="comment">% ISEED --Random number seed (global)</span><span class="comment">% jj --Index variable</span><span class="comment">% m --Number of columns</span><span class="comment">% msg --Error message</span><span class="comment">% n --Number of rows</span><span class="comment">% ran --Output array</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/16/98 S. J. Chapman Original code</span><span class="comment">% Declare globl values</span><span class="keyword">global</span> ISEED <span class="comment">% Seed for random number generator</span><span class="comment">% Check for a legal number of input arguments.</span>msg = nargchk(<span class="number">1</span>,<span class="number">2</span>,nargin);error(msg);<span class="comment">% If the m argument is missing, set it to n.</span><span class="keyword">if</span> nargin &lt; <span class="number">2</span>m = n;<span class="keyword">end</span><span class="comment">% Initialize the output array</span>ran = <span class="built_in">zeros</span>(n,m);<span class="comment">% Now calculate random values</span><span class="keyword">for</span> ii = <span class="number">1</span>:n<span class="keyword">for</span> jj = <span class="number">1</span>:mISEED = <span class="built_in">mod</span>(<span class="number">8121</span>*ISEED + <span class="number">28411</span>, <span class="number">134456</span> );ran(ii,jj) = ISEED / <span class="number">134456</span>;<span class="keyword">end</span><span class="keyword">end</span></code></pre><p>函数 seed 的代码如下:</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">seed</span><span class="params">(new_seed)</span></span><span class="comment">% SEED Set new seed for function RANDOM0</span><span class="comment">% Function SEED sets a new seed for function</span><span class="comment">% RANDOM0. The new seed should be a positive</span><span class="comment">% integer.</span><span class="comment">% Define variables:</span><span class="comment">% ISEED --Random number seed (global)</span><span class="comment">% new_seed --New seed</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/16/98 S. J. Chapman Original code</span><span class="comment">% Declare globl values</span><span class="keyword">global</span> ISEED <span class="comment">% Seed for random number generator</span><span class="comment">% Check for a legal number of input arguments.</span>msg = nargchk(<span class="number">1</span>,<span class="number">1</span>,nargin);error(msg);<span class="comment">% Save seed</span>new_seed = <span class="built_in">round</span>(new_seed);ISEED = <span class="built_in">abs</span>(new_seed);</code></pre><ol start="5"><li>检测产生的 <strong>MATLAB</strong> 程序</li></ol><p><img src="/medias/20200616195128439.png" alt=""></p><pre><code class="highlight matlab">&gt;&gt; seed(<span class="number">1024</span>)&gt;&gt; random0(<span class="number">4</span>)<span class="built_in">ans</span> =    <span class="number">0.0598</span> <span class="number">1.0000</span> <span class="number">0.0905</span> <span class="number">0.2060</span>    <span class="number">0.2620</span> <span class="number">0.6432</span> <span class="number">0.6325</span> <span class="number">0.8392</span>    <span class="number">0.6278</span> <span class="number">0.5463</span> <span class="number">0.7551</span> <span class="number">0.4554</span>    <span class="number">0.3177</span> <span class="number">0.9105</span> <span class="number">0.1289</span> <span class="number">0.6230</span>&gt;&gt; random0(<span class="number">4</span>)<span class="built_in">ans</span> =    <span class="number">0.2266</span> <span class="number">0.3858</span> <span class="number">0.5876</span> <span class="number">0.7880</span>    <span class="number">0.8415</span> <span class="number">0.9287</span> <span class="number">0.9855</span> <span class="number">0.1314</span>    <span class="number">0.0982</span> <span class="number">0.6585</span> <span class="number">0.0543</span> <span class="number">0.4256</span>    <span class="number">0.2387</span> <span class="number">0.7153</span> <span class="number">0.2606</span> <span class="number">0.8922</span>&gt;&gt; seed(<span class="number">1024</span>)&gt;&gt; random0(<span class="number">4</span>)<span class="built_in">ans</span> =    <span class="number">0.0598</span> <span class="number">1.0000</span> <span class="number">0.0905</span> <span class="number">0.2060</span>    <span class="number">0.2620</span> <span class="number">0.6432</span> <span class="number">0.6325</span> <span class="number">0.8392</span>    <span class="number">0.6278</span> <span class="number">0.5463</span> <span class="number">0.7551</span> <span class="number">0.4554</span><span class="number">0.3177</span> <span class="number">0.9105</span> <span class="number">0.1289</span> <span class="number">0.6230</span>&gt;&gt; random0(<span class="number">2</span>,<span class="number">3</span>)<span class="built_in">ans</span> =    <span class="number">0.2266</span> <span class="number">0.3858</span> <span class="number">0.5876</span>    <span class="number">0.7880</span> <span class="number">0.8415</span> <span class="number">0.9287</span>&gt;&gt; arr = random0(<span class="number">1</span>,<span class="number">20000</span>);&gt;&gt; <span class="built_in">mean</span>(arr)<span class="built_in">ans</span> =<span class="number">0.5020</span>&gt;&gt; std(arr)<span class="built_in">ans</span> =<span class="number">0.2881</span>&gt;&gt; hist(arr,<span class="number">10</span>);&gt;&gt; title(<span class="string">'\bf Historygram of the Output of random0'</span>);&gt;&gt; xlabel(<span class="string">'Bin'</span>)&gt;&gt; ylabel(<span class="string">'Count'</span>)</code></pre><p>检测的结果是合理的，这些数据的平均值为 0.5020，理论值为 0.5，实际标准差为 0.2881，理论值为 0.2887 接近。柱状图如图 5.5 所示。</p><p>在 <strong>MATLAB</strong> 中，有两个产生随机数的内建函数。它们是</p><p>rand  ——    用于产生等可能的随机数</p><p>randn   ——   用于产生普通的随机数</p><p>这两个函数要远比我们创建这个随机数发生器要快得多，产生的随机数也多得多。如果你需要在你的程序中创建一些随机数，可调用它们。</p><p>调用函数 rand 和 randn 的形式如下</p><p>rand   ——    产生一个随机数</p><p>rand(n)    ——    产生一个 n×n 的随机数数组</p><p>rand(n, m)   ——   产生一个 n×m 的随机数数组</p><p><img src="/medias/20200616200025110.png" alt="图 5.5 函数 random0 得到的柱状图"></p><h4 id="5-5-在函数调用两次之间本地数据的存储">5.5 在函数调用两次之间本地数据的存储</h4><p>当一个函数执行结束，由这个函数创建的特定的工作区将会被破坏，所以在这个函数中的所有本地变量将会消失。当这个函数下一次被调用的时侯，一个新的工作区将会被创建， 而且所有本地变量的值都返回为默认。这种特性是我们所期望的，因为只有这样 <strong>MATLAB</strong> 函数才能被重复调用而不受上一次影响。</p><p>但在有些情况下，多次调用一个函数，存储一些本地变量的信息还是有用的。例如，我们想创建一个计数器，对函数调用的次数进行计数。如果每一次函数结束执行，计算器就会被破坏，那么计数不超过 1。</p><p>从 <strong>MATLAB</strong>5.1 开始，<strong>MATLAB</strong> 中就有了一个特殊的机制。这种机制允许多次调用一个函数时，保存本地变量。<strong>持久内存</strong>(persistent memory)是内存的一种类型，在函数上一次调用之后，这一步调用之前，本地变量被保存在持久内存，值不变。</p><p>持久变量应用语句声明。它的形式如下:</p><pre><code class="highlight plaintext">persistent var1 var2 var3 ...</code></pre><p>var1，var2，var3…是存储于持久内存中的变量。</p><p><strong>在两次函数调用之间有持久内存保存本地数据</strong>。</p><h5 id="例-5-5-运行平均数">例 5.5 运行平均数</h5><p>当我们键入一些变量总想得到他的统计量。<strong>MATLAB</strong> 内建函数 mean 和 std 就是进行统计数据运算的。我们对一系列的数利用这两个函数进行运算后，再键入一个新数，重新计算。这时我们就可以利用持久内存提高运算的效率。</p><p>算术平均数的定义如下:</p><img src="/medias/20200616200504459.png" style="zoom:60%;"><img src="/medias/20200616200852459.png" style="zoom: 80%;"><pre><code class="highlight plaintext">Check for a legal number of argumentsCheck for a 'reset', and reset sums if presentOtherwise, add current value to running sumsCalculate and return running average and std devif enough data is available. Return zeros if not enough data is available.</code></pre><ol start="3"><li>这些步骤的伪代码为</li></ol><pre><code class="highlight plaintext">Check for a legal number of argumentsif x == 'reset'n ← 0sum_x ← 0sum_x2 ← 0elsen ← n+1sum_x ← sum_x + xsum_x2 ← sum_x2 + x^2end% Calculate ave and sdif n == 0ave ← 0std ← 0elseif n == 1ave ← sum_xstd ← 0elseave ← sum_x / nstd ← sqrt((n*sum_x2 – sum_x^2) / (n * (n-1)))end</code></pre><ol start="4"><li>把算法转化为 <strong>MATLAB</strong> 代码</li></ol><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="params">[ave, std]</span> = <span class="title">runstats</span><span class="params">(x)</span></span><span class="comment">% RUNSTATS Generate running ave / std deviation</span><span class="comment">% Function RUNSTATS generates a running average</span><span class="comment">% and standard deviation of a data set. The</span><span class="comment">% values x must be passed to this function one</span><span class="comment">% at a time. A call to RUNSTATS with the argument</span><span class="comment">% 'reset' will reset tue running sums.</span><span class="comment">% Define variables:</span><span class="comment">% ave --Running average</span><span class="comment">% msg --Error message</span><span class="comment">% n --Number of data values</span><span class="comment">% std --Running standard deviation</span><span class="comment">% sum_x --Running sum of data values</span><span class="comment">% sum_x2 --Running sum of data values squared</span><span class="comment">% x --Input value</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/16/98 S. J. Chapman Original code</span><span class="comment">% Declare persistent values</span><span class="keyword">persistent</span> n <span class="comment">% Number of input values</span><span class="keyword">persistent</span> sum_x <span class="comment">% Running sum of values</span><span class="keyword">persistent</span> sum_x2 <span class="comment">% Running sum of values squared</span><span class="comment">% Check for a legal number of input arguments.</span>msg = nargchk(<span class="number">1</span>,<span class="number">1</span>,nargin);error(msg);<span class="comment">% If the argument is 'reset', reset the running sums.</span><span class="keyword">if</span> x == <span class="string">'reset'</span>n = <span class="number">0</span>;sum_x = <span class="number">0</span>;sum_x2 = <span class="number">0</span>;<span class="keyword">else</span>n = n + <span class="number">1</span>;sum_x = sum_x + x;sum_x2 = sum_x2 + x^<span class="number">2</span>;<span class="keyword">end</span><span class="comment">% Calculate ave and sd</span><span class="keyword">if</span> n == <span class="number">0</span>ave = <span class="number">0</span>;std = <span class="number">0</span>;<span class="keyword">elseif</span> n == <span class="number">1</span>ave = sum_x;std = <span class="number">0</span>;<span class="keyword">else</span>ave = sum_x / n;std = <span class="built_in">sqrt</span>((n*sum_x2 - sum_x^<span class="number">2</span>) / (n*(n - <span class="number">1</span>)));<span class="keyword">end</span></code></pre><ol start="5"><li>检测程序</li></ol><p>为了检测这个函数，我们必须创建一个用于复位 runstats 的脚本文件：读取输入数据， 调用 rnnstats 函数，并显示出相应的统计量。</p><p>一个合适的脚本文件显示如下：</p><pre><code class="highlight matlab"><span class="comment">% Script file: test_runstats.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To read in an input data set andn calculate the</span><span class="comment">% running statistics on the data set as the values</span><span class="comment">% are read in. The running stats will be written</span><span class="comment">% to the Command window.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/16/98 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% array --Input data array</span><span class="comment">% ave --Running average</span><span class="comment">% std --Running standard deviation</span><span class="comment">% ii --Index variable</span><span class="comment">% nvals --Number of input values</span><span class="comment">% std --Running standard deviation</span><span class="comment">% First reset running sums</span>[ave std] = runstats(<span class="string">'reset'</span>);<span class="comment">% Prompt for the number of values in the data set</span>nvals = input(<span class="string">'Enter number of values in data set: '</span>);<span class="comment">% Get input values</span><span class="keyword">for</span> ii = <span class="number">1</span>:nvals<span class="comment">% Prompt for next value</span>string = [<span class="string">'Enter value '</span> int2str(ii) <span class="string">': '</span>];x = input(string);<span class="comment">% Get running statistics</span>[ave std] = runstats(x);<span class="comment">% Display running statistics</span>fprintf(<span class="string">'Average = %8.4f; Std dev = %8.4f\n'</span>,ave, std);<span class="keyword">end</span></code></pre><p>为了检测函数，通过手动计算 5 个数得到相应的统计量，并与程序得到的结果进行比较。</p><p>如果这个 5 个数分别为：3.0, 2.0, 3.0, 4.0, 2.8</p><p>那么手动运算的结果为</p><p><img src="/medias/20200616201740469.png" alt=""></p><p>程序得到的结果为</p><pre><code class="highlight plaintext">&gt;&gt; test_runstatsEnter number of values in data set: 5Enter value 1: 3Average = 3.0000; Std dev = 0.0000Enter value 2: 2Average = 2.5000; Std dev = 0.7071Enter value 3: 3Average = 2.6667; Std dev = 0.5774Enter value 4: 4Average = 3.0000; Std dev = 0.8165Enter value 5: 2.8Average = 2.9600; Std dev = 0.7127</code></pre><p>这个运算结果与上面的手动计算相符。</p><h4 id="5-6-函数的函数（function-functions）">5.6 函数的函数（function functions）</h4><p>函数的函数(function functions)是指函数的输入参数中含有其他的函数，传递给函数的函数的变量名一般情况应用于这个函数执行的过程中。</p><p>例如，<strong>MATLAB</strong> 中有一个函数的函数叫做 fzero。这个函数用于找到传递给它的函数值为 0 时的自变量。例如，语句 fzero(‘cos’, (0, pi))，它能确定 cos 函数在区间[0, π]中何时为 0。语句 fzero(‘exp(x)-2’, [0 1])在区间[0, 1]中何时为 0。当这些语句被执行时，将产生如下的结果：</p><pre><code class="highlight plaintext">&gt;&gt; fzero('cos',[0 pi])ans =1.5708&gt;&gt; fzero('exp(x)-2',[0 1])ans = 0.6931</code></pre><p>函数的函数操作的关键字有两个专门的 maltab 函数，eval 和 feval。。函数 eval 对一个字符串进行求值，就如它在命令窗口中已经键入了一样。函数 feval 用一个特定的输入值对命名的函数进行求值。函数 eval 的形式如下：</p><pre><code class="highlight plaintext">eval(string)</code></pre><p>例如，语句 x = eval(‘sin(pi/4)’)产生的结果如下：</p><pre><code class="highlight plaintext">&gt;&gt; x = eval('sin(pi/4)')x =0.7071</code></pre><p>下面是一个例子，构建一个字符串，并用 eval 函数对其进行求值</p><pre><code class="highlight plaintext">x = 1;str = ['exp(' num2str(x) ')-1'];res = eval(str);</code></pre><p>在这种情况下，变量 str 的内容为 exp(1)-1，所以 eval 产生的结果为 1.7183。</p><p>函数 feval 对在 M 文件进行定义的命名函数进行求值，要求有指定的输入值。函数 feaval 的基本形式如下</p><p>feval(fun, value).</p><p>例如，语句 x=feval(‘sin’，pi/4)产生的结果如下</p><pre><code class="highlight plaintext">&gt;&gt; x = feval('sin',pi/4)x =0.7071</code></pre><p>更多的函数的函数将会在表 5.1 中列出。在命令窗中键入 help 函数名，了解他们的用途。</p><h5 id="例-5-6-画出所有只有一个自变量的-MATLAB-函数的图象">例 5.6 画出所有只有一个自变量的 <strong>MATLAB</strong> 函数的图象</h5><p>​             <strong>表 5.1 常见的函数的函数</strong></p><table><thead><tr><th>-</th><th>-</th></tr></thead><tbody><tr><td>fminbnd</td><td>求函数的最小值，这函数只有一个自变量</td></tr><tr><td>fzero</td><td>找出函数为 0 时的自变量的值</td></tr><tr><td>quad</td><td>在数学上组合一个函数</td></tr><tr><td>ezplot</td><td>简单易用的函数画图</td></tr><tr><td>fplot</td><td>通过函数名画出这个函数的图象</td></tr></tbody></table><p>创建一个函数的函数，它能够画出所有只有一个自变量的 <strong>MATLAB</strong> 函数的图象，自变量的范围是用户指定的始值和终值。</p><p>答案：</p><p>这个函数有两个输入参数，第一个是要画的函数的函数名，第二个是两元素向量，它指明了画图的取值范围。</p><ol><li>陈述问题</li></ol><p>创建一个函数的函数，它能够画出所有只有一个自变量的 <strong>MATLAB</strong> 函数的图象，自变量的范围由用户指定。</p><ol start="2"><li>定义输入输出函数的输入有两个</li></ol><p>(1) 包含有函数名的字符串</p><p>(2) 包含有起始值和终值的 2 元素向量函数的输出是所要画的图象</p><ol start="3"><li>设计算法这个函数可以分为 4 大步：</li></ol><p>Check for a legal number of arguments</p><p>Check that the second argument has two elements</p><p>Calculate the value of the function between the start and stop points Plot and label the function</p><p>第三四大步的伪代码如下：</p><pre><code class="highlight plaintext">n_steps ← 100step_size ← (xlim(2) – xlim(1)) / nstepsx ← xlim(1):step_size:xlim(2)y ← feval(fun, x)plot(x, y)title(['bf Plot of function ' fun ' (x)'])xlabel('\bfx;)ylabel(['bf ' fun ' (x)'])</code></pre><ol start="4"><li>把算法转化为 <strong>MATLAB</strong> 语句</li></ol><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">quickplot</span><span class="params">(fun,xlim)</span></span><span class="comment">% QUICKPLOT Generate quick plot of a function</span><span class="comment">% Function QUICKPLOT generates a quick plot</span><span class="comment">% of a function contained in a external mfile,</span><span class="comment">% between user-specified x limits.</span><span class="comment">% Define variables:</span><span class="comment">% fun --Function to plot</span><span class="comment">% msg --Error message</span><span class="comment">% n_steps --Number of steps to plot</span><span class="comment">% step_size --Step size</span><span class="comment">% x --X-values to plot</span><span class="comment">% y --Y-values to plot</span><span class="comment">% xlim --Plot x limits</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/17/98 S. J. Chapman Original code</span><span class="comment">% Check for a legal number of input arguments.</span>msg = nargchk(<span class="number">2</span>,<span class="number">2</span>,nargin);error(msg);<span class="comment">% Check the second argument to see if it has two</span><span class="comment">% elements. Note that this double test allows the</span><span class="comment">% argument to be either a row or a column vector.</span><span class="keyword">if</span> (<span class="built_in">size</span>(xlim,<span class="number">1</span>) == <span class="number">1</span> &amp; <span class="built_in">size</span>(xlim,<span class="number">2</span>) == <span class="number">2</span> ) | ...(<span class="built_in">size</span>(xlim,<span class="number">1</span>) == <span class="number">2</span> &amp; <span class="built_in">size</span>(xlim,<span class="number">2</span>) == <span class="number">1</span>)<span class="comment">% Ok --continue processing.</span>n_steps = <span class="number">100</span>;step_size = (xlim(<span class="number">2</span>) - xlim(<span class="number">1</span>)) / n_steps;x = xlim(<span class="number">1</span>):step_size:xlim(<span class="number">2</span>);y = feval(fun,x);    <span class="built_in">plot</span>(x,y);    title([<span class="string">'\bfPlot of function '</span> fun <span class="string">'(x)'</span>]);    xlabel(<span class="string">'\bfx'</span>);    ylabel([<span class="string">'\bf'</span> fun <span class="string">'(x)'</span>]);<span class="keyword">else</span><span class="comment">% Else wrong number of elements in xlim.</span>error(<span class="string">'Incorrect number of elements in xlim.'</span>);<span class="keyword">end</span></code></pre><ol start="5"><li>检测程序为了检测这个程序，我们应当用正确或错误的输入输出参数来调用这个程序。证明它能区分正确和错误的输入参数。结果如下</li></ol><pre><code class="highlight plaintext">&gt;&gt; quickplot('sin')??? Error using ==&gt; quickplotNot enough input arguments.&gt;&gt; quickplot('sin', [-2*pi 2*pi], 3)??? Error using ==&gt; quickplotToo many input arguments.&gt;&gt; quickplot('sin', -2*pi)??? Error using ==&gt; quickplotIncorrect number of elements in xlim.&gt;&gt; quickplot('sin', [-2*pi 2*pi])</code></pre><p>最后一次被调用的结果是正确的，它的图象如图 5.6 所示。</p><p><img src="/medias/20200616203935804.png" alt="图 5.6 由 quickplot 函数产生的 sinx 图象"></p><h4 id="5-7-子函数和私有函数">5.7 子函数和私有函数</h4><p>在一个单个的文件中我们可以创建多个函数。如果超过 1 个的函数出现在一个文件中， 那么最上面的那个函数为普通函数，下面的函数称为<strong>子函数</strong>或<strong>中间函数</strong>。子函数看起来和普通函数一样，但是只能被同一文件中的函数调用。</p><p>下面的例子定义了一个函数 mystats 和两个子函数 mean 和 median。函数 mystats 能被其他的 maltab 函数调用，但是子函数 mean 和 median 只能同一文件中的其他函数调用。</p><pre><code class="highlight plaintext">function [avg, med] = mystats(u)% MYSTATS Find mean and median with internal functions.% Function MYSTATS calculates the average and median% of a data set using subfunctions.n = length(u); avg = mean(u, n);med = median (u, n);function a = mean(v, n)%Subfunction to calculate average. a = sum(v) / n;function m = median(v, n)%Subfunction to calculate medianw = sort(v);if rem(n, 2) ==1m = w((n+1)/2);elsem = (w(n/2) + w(n/2 + 1))/2;end</code></pre><p>私有函数是指属于以 private 为名字的子目录中的函数。这些函数只有在父目录中才是可见的。例如，假设在 <strong>MATLAB</strong> 搜索路径中有一 testing 目录，在 testing 目录中，又有一个 private 子目录。private 中的函数只能由 testing 中的函数调用。因为对于父目录以外目标私有函数是不可见的，所以它能用其他目录中的函数重名。有了这种特性，如果你要创建自己的函数，则不必要考虑与其他目录重名。因为 <strong>MATLAB</strong> 先对私有函数查找，然后再对标准的 M 文件函数进行查找，所以它将首先找到私有函数 test.m，再找到非私有 M 文件 test.m。</p><p>在包含有你的函数的目录中，我们可以很创建你的私有目录。不要在你的搜索路径中放置你的私有目录。</p><p>在一个 M 文件中，调用一个函数，<strong>MATLAB</strong> 先检查看他是否是一个子函数。如果它不是那就检查它是不是一个私有函数。如果也不是私有函数，<strong>MATLAB</strong> 就会检它在不在标搜索路径中。</p><p>如果你有特殊的目的，<strong>MATLAB</strong> 函数只能由其他的函数调用，而绝不能由使用者调用并考虑用子函数或私有函数来隐藏它们。隐藏这些函数防止了它们偶然的使用，也能防止与其他公共函数重名时发生的冲突。</p><p><strong>用子函数或私有函数来隐藏特殊目的的函数，这些隐藏的函数只能被其他函数调用。 隐藏这些函数防止了它们偶然的使用，也能防止与其他公共函数重名时发生的冲突</strong>。</p><h4 id="5-8-总结">5.8 总结</h4><p>在第五章中，我们向大家介绍了用户自定义函数。函数是 M 文件的一种特殊类型，它通过输入参数接受数据，通过输出参数返回结果。每一个函数都有其独立的工作区。</p><p><strong>MATLAB 通过按值传递机制将参数传递给函数，这意味着 MATLAB 把每一个参数复制，并把这个拷贝传递给函数。这个复制是非常重要的，因为函数可以自由的修改输入参数， 而不会影响到程序中的实参。</strong></p><p><strong>MATLAB 函数支持改变输入输出参数的个数。函数 nargin 可以报告函数在调用过程中所需的实参个数。函数 nargout 则可以报告输出参数的个数。</strong></p><p><strong>把数据存于全局内存中，可以实现 MATLAB 函数之间数据的共享。全局变量的声明要用到 global 语句。全局变量可由所有声明它的所有函数共享。为了方便，全局变量应在 M 文件的开头声明。</strong></p><p><strong>两次调用同一函数之间，中间数据可以存储在持久内存。持久变量可能用 persistent 语句声明。</strong></p><p><strong>函数的函数是指函数的输入参数中含有其他的函数，传递给函数的函数的变量名一般情况应用于这个函数执行的过程中。</strong></p><p><strong>子函数是在一个单独文件中的附加函数，它只能被同一文件中的其他函数访问。私有函数是在 private 子目录中的函数，它们只能被父目录中的函数访问。子函数和私有函数主要用于限制 MATLAB 函数的访问。</strong></p><h5 id="5-8-1-好的编程习惯的总结">5.8.1 好的编程习惯的总结</h5><ol><li><p><strong>把大的程序分解小的，易于理解的函数</strong></p></li><li><p><strong>在 M 文件的开头声明全局变量。以区分本地变量</strong></p></li><li><p><strong>在函数中的初始注释行之后和第一个可执行性语句之前声明全局变量</strong></p></li><li><p><strong>全局变量适用大规模数据的传输</strong></p></li><li><p><strong>在两次函数调用之间有持久内存保存本地数据。</strong></p></li><li><p><strong>用子函数或私有函数来隐藏特殊目的的函数，这些隐藏的函数只能被其他函数调用。隐藏这些函数防止了它们偶然的使用，也能防止与其他公共函数重名时发生的冲突。</strong></p></li></ol><h5 id="5-8-2-MATLAB-总结">5.8.2 MATLAB 总结</h5><p>下面是对 <strong>MATLAB</strong> 函数和命令的总结，并带有简短的描述。</p><table><thead><tr><th>-</th><th>-</th></tr></thead><tbody><tr><td>nargin</td><td>这个函数返回调用这个函数时所需要的实际输入参数的个数</td></tr><tr><td>nargout</td><td>这个函数返回调用这个函数时所需要的实际输出参数的个数</td></tr><tr><td>nargchk</td><td>如要一个函数调用被调用时参数过多或过少，那么 nargchk 函数将返回一个标准错误信息</td></tr><tr><td>error</td><td>显示错误信息，并中止函数以免它产生这个错误。如果参数错误是致命的，这个函数将会被调用</td></tr><tr><td>warning</td><td>显示警告信息并继续执行函数，如果参数错误不是致命的，执行还能继续，则这个将会被调用</td></tr><tr><td>inputname</td><td>这个函数将会返回对于特定参数个数的实际变量名</td></tr><tr><td>rand</td><td>产生一个随机数</td></tr><tr><td>rand(n)</td><td>产生一个 n×n 的随机数数组</td></tr><tr><td>rand(n,m)</td><td>产生一个 n×m 的随机数数组</td></tr><tr><td>rand</td><td>用于产生等可能的随机数</td></tr><tr><td>randn</td><td>用于产生普通的随机数</td></tr></tbody></table><h3 id="第六章-复数数据、字符数据和附加画图类型">第六章 复数数据、字符数据和附加画图类型</h3><p>在第二章中，我们学习了 <strong>MATLAB</strong> 基础数据类型：double 和 char。<strong>MATLAB</strong> 还有许多的附加数据类型，在本章，我们将会了解它们中的一个。我们要讨论的附加数据类型是 <strong>MATLAB</strong> 支持的复数数据。我们也将学习如何使用 char 数据类型，以及如何把 <strong>MATLAB</strong>数组扩展为多维数组。</p><p>本章还会涉及到 <strong>MATLAB</strong> 的附加画图类型。</p><h4 id="6-1-复数数据">6.1 复数数据</h4><p><img src="/medias/20200616210254959.png" alt=""></p><p><img src="/medias/20200616210340004.png" alt=""></p><h5 id="6-1-1-复变量（complex-variables）">6.1.1  复变量（complex variables）</h5><p>复数值赋值于一个变量名，<strong>MATLAB</strong> 将自动创建一个复变量。创建复数的最简单方法是用 <strong>MATLAB</strong> 本自带的因有变量 i 或 j，它们都被预定义为 sqrt(-1) 。例如下面的语句将复数 4+3i 赋值于 c~1~。</p><pre><code class="highlight plaintext">&gt;&gt; c1 = 4 + 3*ic1 =    4.0000 + 3.0000i</code></pre><p>函数 isreal 可以判断一个数组包是实数组还是复数组。如果一个数组中的所有元素只有虚部，那么这个数组是复数组，并且 isreal(array) 将会返回一个 0。</p><h5 id="6-1-2-带有关系运算符的复数的应用">6.1.2  带有关系运算符的复数的应用</h5><p>用关系运算符==来判断两复数是否相等，或用关系运算符~=判断两复数是否不相等， 这种情况是可能的。这些运算都会产生出我们所期望的结果。例如，如果 c1=4+3i 和 c2=4-3i， 那么关系运算 c1==c2 将会产生 0，关系运算 c1~=c2 将会产生 1。</p><p>但是，比较运算符&gt;，&lt;，&lt;=或&gt;=将不会产生我们所期望的结果。当复数进行此类关系运算时，只对复数的实部进行比较。例如，如果 c1=4+i3 和 c2=4+i8，那么比较运算 c1&gt;c2 将会产生 1，尽管 c1 的模要比 c2 的模小。</p><p>如果我们需要用这些运算对两复数进行比较，我们更加关心的是两复数的模，而不只是实部。复数的模可以由 abs 固有函数计算得到（在下一节介绍，或者由公式（6.4）得到）。</p><p><img src="/medias/20200616210956249.png" alt=""></p><p>如果我们对两复数进行比较，得到的结果将更加合理。abs(c1)&gt;abs(c2)将会产生 0，因为 c1 的模大于 c2 的模。</p><p><strong>当我们应用关系运算符对复数运算时，一定要小心。关系运算符 &gt;，&lt;，&lt;= 或 &gt;= 只比较复数的实部，而不是它们的模。如果你要用这些关系运算符对一复数进行运算，比较两复数的模将更加常见。</strong></p><h5 id="6-1-3-复函数（complex-function）">6.1.3  复函数（complex function）</h5><p><strong>MATLAB</strong> 中有许多的函数支持复数的运算。这些函数可分为三大类。</p><ol><li><strong>类型转换函数</strong></li></ol><p>这些函数把数据从复数据类型转换为实数数据类型（double）。函数 real 将复数的实部转化为 double 型数据，把复数的虚部抛弃。函数 imag 把函数的虚部转化为相应的实数。</p><ol start="2"><li><strong>绝对值和幅角函数</strong></li></ol><p>这些函数把复数转化它的极坐标形式。函数 abs©用于计算复数 c 相应的绝对值，公式如下</p><p><img src="/medias/20200616211353440.png" alt=""></p><p><strong>表 6.1 常见的支持复数运算的 MATLAB 函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>conj©</td><td>计算 c 的共共枙复数。如果 c=a+bi，那么 conj©=a-bi。</td></tr><tr><td>real©</td><td>返回复数 c 的实部</td></tr><tr><td>imag©</td><td>返回复数 c 的虚部</td></tr><tr><td>isreal©</td><td>如果数组 c 中没有一个元素有虚部，函数 isreal©将返回 1。所以如果一个数组 c 是复数组成，那么~isreal©将返回 1</td></tr><tr><td>abs©</td><td>返回复数 c 模</td></tr><tr><td>angle©</td><td>返回复数 c 的幅角，等价于 atan2(imag©，real©)</td></tr></tbody></table><ol start="3"><li><strong>数学函数</strong></li></ol><p>许多的数函数都可以对复数进行运算。这些函数包括指数函数，对数函数，三角函数， 还有平方根函数。函数 sin，cos，log，sqrt 等既能对复数数据进行运算，又能对实数据进行运算。</p><p>一些支持复数运算的函数在表 6.1 中列出。</p><h6 id="例-6-1-二次方程的求解（重写）">例 6.1 二次方程的求解（重写）</h6><p>二次方程的求解（重写）</p><p>复数的价值体现在它能使运算简化。</p><p>例如，我们在例 3.2 中已解决的二次方程的求解问题，但它根据判别式用到 3 个选项的选择结构，由于复数的出现，负数的平方根的处理将不困难。所以能够大大简化我们的计算。编写一个普通的程序，解一元二次方程的根，不管是什么类型的。用复变量，而不用选择结构。</p><ol><li>陈述问题</li></ol><p>编写一个程序，解一元二次方程的根，不管有两个不同的实根，还是用两个相同的实根或两个不同复根。不需要检测判别式。</p><ol start="2"><li>定义输入输出</li></ol><p>本程序所需要方程式</p><p><img src="/medias/20200616212139706.png" alt=""></p><p>的三个系数 a，b，c。输出是这个方程式的所有根。</p><ol start="3"><li>设计算法</li></ol><p>这个程序从整体上可以分为三大步，即输入，计算，输出</p><pre><code class="highlight plaintext">Read the input data Calculate the roots Write out the roots</code></pre><p>我们现在把每一步进行逐步细化。这时判别式的值对程序的执行过程不产生影响。伪代码如下：</p><pre><code class="highlight plaintext">Prompt the user for the coefficients a, b, and c.Read a, b, and cdiscriminant ← b^2 - 4 * a * cx1 ← ( -b + sqrt(discriminant) ) / (2*a)x2 ← ( -b - sqrt(discriminant) ) / (2*a)Print 'x1 = ' , real(x1), ' + i ', imag(x1)Print 'x2 = ' , real(x2), ' + i ', imag(x2)</code></pre><ol start="4"><li>将算法转化为 <strong>MATLAB</strong> 语句</li></ol><pre><code class="highlight matlab"><span class="comment">% Script file: calc_roots2.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program solves for the roots of a quadratic equation</span><span class="comment">% of the form a*x**2 + b*x + c = 0. It calculates the answers</span><span class="comment">% regardless of the type of roots that the equation possesses.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/06/98 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% a -- Coefficient of x^2 term of equation</span><span class="comment">% b -- Coefficient of x term of equation</span><span class="comment">% c -- Constant term of equation</span><span class="comment">% discriminant -- Discriminant of the equation</span><span class="comment">% x1 -- First solution of equation</span><span class="comment">% x2 -- Second solution of equation</span><span class="comment">% Prompt the user for the coefficients of the equation</span><span class="built_in">disp</span> (<span class="string">'This program solves for the roots of a quadratic '</span>);<span class="built_in">disp</span> (<span class="string">'equation of the form A*X^2 + B*X + C = 0. '</span>);a = input (<span class="string">'Enter the coefficient A: '</span>);b = input (<span class="string">'Enter the coefficient B: '</span>);c = input (<span class="string">'Enter the coefficient C: '</span>);<span class="comment">% Calculate discriminant</span>discriminant = b^<span class="number">2</span> - <span class="number">4</span> * a * c;<span class="comment">% Solve for the roots</span>x1 = ( -b + <span class="built_in">sqrt</span>(discriminant) ) / ( <span class="number">2</span> * a );x2 = ( -b - <span class="built_in">sqrt</span>(discriminant) ) / ( <span class="number">2</span> * a );<span class="comment">% Display results</span><span class="built_in">disp</span> (<span class="string">'The roots of this equation are:'</span>);fprintf (<span class="string">'x1 = (%f) +i (%f)\n'</span>, <span class="built_in">real</span>(x1), <span class="built_in">imag</span>(x1));fprintf (<span class="string">'x2 = (%f) +i (%f)\n'</span>, <span class="built_in">real</span>(x2), <span class="built_in">imag</span>(x2));</code></pre><ol start="5"><li>检测程序下一步，我们必须输入检测来检测程序。我们要有三组数据进行检测，其判别式分别大于 0，等于 0，小于 0。根据方程式（3.1），用下面的方程式验证程序。</li></ol><p><img src="/medias/20200616212626324.png" alt=""></p><pre><code class="highlight plaintext">&gt;&gt; calc_root2This program solves for the roots of a quadraticequation of the form A*X^2 + B*X + C = 0.Enter the coefficient A: 1Enter the coefficient B: 5Enter the coefficient C: 6The roots of this equation are:x1 = (-2.000000) +i (0.000000)x2 = (-3.000000) +i (0.000000)&gt;&gt; calc_root2This program solves for the roots of a quadraticequation of the form A*X^2 + B*X + C = 0.Enter the coefficient A: 1Enter the coefficient B: 4Enter the coefficient C: 4The roots of this equation are:x1 = (-2.000000) +i (0.000000)x2 = (-2.000000) +i (0.000000)&gt;&gt; calc_root2This program solves for the roots of a quadraticequation of the form A*X^2 + B*X + C = 0.Enter the coefficient A: 1Enter the coefficient B: 2Enter the coefficient C: 5The roots of this equation are:x1 = (-1.000000) +i (2.000000)x2 = (-1.000000) +i (-2.000000)</code></pre><p>在三种不同的情况下，程序均给出了正确的结果。注意此程序与例 3.2 中的程序相比有多简单。复数数据的应用可大大简化我们的程序。</p><h5 id="6-1-4-复数数据的作图">6.1.4  复数数据的作图</h5><p>因为复数数据既包括实部又包括虚部，所以在 <strong>MATLAB</strong> 中复数数据的作图与普通实数据的作图有所区别。例如，考虑下面的函数</p><p><img src="/medias/20200616212846308.png" alt=""></p><p>如果我们用传统的 plot 命令给这个函数作图，只有实数数据被作出来，而虚部将会被忽略。下面的语句得到图象如图 6.3 所示，注意出现了警告信息：数据的虚部被忽略</p><pre><code class="highlight matlab">t = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="number">4</span>*<span class="built_in">pi</span>;y = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* (<span class="built_in">cos</span>(t) + <span class="built_in">i</span> * <span class="built_in">sin</span>(t));<span class="built_in">plot</span>(t, y);title(<span class="string">'\bfPlot of Complex Function vs Time'</span>);xlabel(<span class="string">'\bf\itt'</span>);ylabel(<span class="string">'\bf\ity(t)'</span>);</code></pre><p><img src="/medias/20200616213015318.png" alt="图 6.3 用 plot(t, y)画出的y(t)=e^(-0.2t)(cost+isint)图象"></p><p>如果函数的实部和虚部都需要的话，那么用户可以有几种选择。我们可以用下面的语句，在相同的时间轴内画出函数的图象（图 6.4）。</p><pre><code class="highlight matlab">t = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="number">4</span>*<span class="built_in">pi</span>;y = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* (<span class="built_in">cos</span>(t) + <span class="built_in">i</span> * <span class="built_in">sin</span>(t));<span class="built_in">plot</span>(t, <span class="built_in">real</span>(y),<span class="string">'b-'</span>);<span class="built_in">hold</span> on;<span class="built_in">plot</span>(t, <span class="built_in">imag</span>(y),<span class="string">'r--'</span>);title(<span class="string">'\bfPlot of Complex Function vs Time'</span>);xlabel(<span class="string">'\bf\itt'</span>);ylabel(<span class="string">'\bf\ity(t)'</span>);<span class="built_in">legend</span>(<span class="string">'real'</span>,<span class="string">'imaginary'</span>);<span class="built_in">hold</span> off;</code></pre><p><img src="/medias/20200616213449849.png" alt="图 6.4 包含了 y(t)的实部和虚部"></p><p>可选择的，函数的实部-虚部图可以被画出来。如果有一个复参数提供给 plot 函数它会自动产生一个函数的实部-虚部图。产生这类图的语句如下，产生的结果如图 6.5 所示。</p><pre><code class="highlight matlab">t = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="number">4</span>*<span class="built_in">pi</span>;y = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* (<span class="built_in">cos</span>(t) + <span class="built_in">i</span> * <span class="built_in">sin</span>(t));<span class="built_in">plot</span>(y,<span class="string">'b-'</span>);title(<span class="string">'\bfPlot of Complex Function'</span>); xlabel(<span class="string">'\bfReal Part'</span>); ylabel(<span class="string">'\bfImaginary Part'</span>);</code></pre><p><img src="/medias/20200616214015328.png" alt="图 6.5 y(t)的的实部-虚部图"></p><p>最后，我们可以画出函数的极坐标图。产生这类图语句如下，产生的结果如图图 6.6 所示。</p><pre><code class="highlight matlab">t = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">20</span>:<span class="number">4</span>*<span class="built_in">pi</span>;y = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* (<span class="built_in">cos</span>(t) + <span class="built_in">i</span> * <span class="built_in">sin</span>(t));polar(<span class="built_in">angle</span>(y),<span class="built_in">abs</span>(y));title(<span class="string">'\bfPlot of Complex Function'</span>);</code></pre><p><img src="/medias/20200616215236912.png" alt="图 6.6 y(t)的极坐标图"></p><h4 id="6-2-字符串函数（string-functions）">6.2 字符串函数（string functions）</h4><p>一个 <strong>MATLAB</strong> 字符串是一个 char 型数组。每一个字型占两个字节。当字符串被赋值于一个变量时，这个变量将被自动创建为字符变量。例如语句</p><pre><code class="highlight plaintext">str = 'This is a test';</code></pre><p>将会创建一个含有 14 个元素的数组。用 whos 命令查看它属性。</p><pre><code class="highlight plaintext">&gt;&gt; whos  Name      Size            Bytes  Class    Attributes  str       1x14               28  char</code></pre><p>一个专门的函数 ischar 常用来判断一个变量是否为字符数组。如果是的话，那么函数较会返回 1，如果不是，将会返回 0。</p><p>在下面的的小节中，我们将向大家介绍一些对字符串进行操作的函数。</p><h5 id="6-2-1-字符转换函数">6.2.1  字符转换函数</h5><p>我们可以利用 double 函数把变量从字型转化为 double 型。所以，函数 double(str)产生的结果为</p><pre><code class="highlight plaintext">&gt;&gt; x = double(str)x =    84   104   105   115    32   105   115    32    97    32   116   101   115   116</code></pre><p>我们可以利用 char 函数把 double 型数据转化为字符型数据。所以函数 char(x)产生的结果为</p><pre><code class="highlight plaintext">&gt;&gt; x = char(x)x =    'This is a test'</code></pre><h5 id="6-2-2-创建二维字符数组">6.2.2  创建二维字符数组</h5><p>我们可以创建二维字符数组，但一个数组中每一行的长度都必须相等。如果其中的一行比其他行短，那么这个字符数据将会无效，并产生一个错误。例如，下面的语句是非法的， 因为他两行的长度不同。</p><pre><code class="highlight plaintext">name = ['Stephen J. Chapman'; 'Senior Engineer'];</code></pre><p>创建二维字符数组的最简单的方法是用 char 函数。函数将会自动地寻找所有字符串中最长的那一个。</p><pre><code class="highlight plaintext">&gt;&gt; name = char('Stephen J. Chapman','Senior Engineer')name =  2×18 char 数组    'Stephen J. Chapman'    'Senior Engineer   '</code></pre><p>二维字符数组也可以用函数 strvcat，这个函数会在下一节中介绍。</p><p><strong>用 char 函数创建二维字符数组，我们就不用担心每一行的长度不相同了。</strong></p><p>我们可以应用 deblank 函数去除多余空格。例如，下面的语句去除 name 数组中第二行的多余空格，产生的结果与原来的进行比较。</p><pre><code class="highlight plaintext">&gt;&gt; line2 = name(2,:)line2 =Senior Engineer&gt;&gt; line2_trim = deblank(name(2,:))line2_trim =Senior Engineer&gt;&gt; size(line2)ans =1 18&gt;&gt; size(line2_trim)ans =1 15</code></pre><h5 id="6-2-3-字符串的连接">6.2.3  字符串的连接</h5><p>函数 strcat 水平连接两字符串，忽略所有字符串末端的空格，而字符串的空格保留。例如，下面的语句为</p><pre><code class="highlight plaintext">&gt;&gt; result = strcat('string 1 ','String 2')result =    'string 1String 2'</code></pre><p>产生的结果 string 1String 2。</p><p>函数 strvcat 用于竖直地连接两字符串，自动地把它转化为二维数组。这个函数将产生这样的结果</p><pre><code class="highlight plaintext">&gt;&gt; result = strvcat('Long String 1 ','String 2')result =  2×14 char 数组    'Long String 1 '    'String 2</code></pre><h5 id="6-2-4-字符串的比较">6.2.4  字符串的比较</h5><p>字符串与子字符串可以通过下面许多的方式进行比较。</p><ol><li><p>两个字符串，或两个字符串的部分，看两者是否相同</p></li><li><p>两个独立的字符相比较看两者是否相同</p></li><li><p>检查字符串判断每一个字符是字母，还是空格</p></li></ol><h6 id="6-2-4-1-比较两字符串，看是否相同">6.2.4.1   比较两字符串，看是否相同</h6><p>你可以利用 <strong>MATLAB</strong> 函数比较两字符串整体是否相同。它们是</p><ol><li><p>strcmp    ——    判断两字符串是否等价</p></li><li><p>strcmpi    ——   忽略大小写判断两字符串是否等价</p></li><li><p>strncmp   ——   判断两字符串前 n 个字符是否等价</p></li><li><p>strncmpi  ——   忽略大小写判断两字符串前 n 个字符是否等价</p></li></ol><p>函数 strcmp 比较字符串，包括字符串前面或后面的空格。如果两字符串完全相同，那么这个函数将返回 1。否则，返回 0。strcmpi 与 strcmp 类似，但它忽略了大小写（即“a” 与“A”看作相同的）</p><p>函数 strncmp 用来比较两字符串前 n 个字符串，包含开头的空格，如果这个 n 个字符是相同的，它们将会返回 1。否则它将会返回 0。函数 strncmpi 与它相类似，但忽略了大小写。</p><p>为了更好的理解这些函数，考虑下面的字符串</p><pre><code class="highlight plaintext">str1 = 'hello';str2 = 'Hello';str3 = 'help';</code></pre><p>字符串 str1 和 str2 不相同，但它第一个字母大小不同。所以 strcmp 将返回 0，strcmpi 将返回 1。</p><pre><code class="highlight plaintext">&gt;&gt; c = strcmp(str1,str2)c =  logical   0   &gt;&gt; c = strcmpi(str1,str2)c =  logical   1</code></pre><p>字符串 str1 和 str3 不相同，所以 strcmp 与 strcmpi 返回 0。但是 str1 和 str3 的前三个字符是相同，所以按照下面的方式调用将会返回 1。</p><pre><code class="highlight plaintext">&gt;&gt; c = strncmp(str1, str3, 2)c =  logical   1</code></pre><h6 id="6-2-4-2-判断单个字符是否相等">6.2.4.2   判断单个字符是否相等</h6><p>我们可以利用<strong>MATLAB</strong> 关系运算符对字符数组中的每一个元素进行检测，看是否相同， 但是我们要保证它们的维数是相同的，或其中一个是标量。例如，你可以用相等运算符（==） 来检测两字符串是否相匹配。</p><pre><code class="highlight plaintext">&gt;&gt; a = 'fate';&gt;&gt; b = 'cake';&gt;&gt; result = a == bresult =  1×4 logical 数组   0   1   0   1</code></pre><p>所有的关系运算符（&gt;，&gt;=，&lt;，&lt;=，==，~=）都是对字符所对应的 ASCII 值进行比较。</p><p>与 C 语言不同，<strong>MATLAB</strong> 中没有一个内建函数，对两字符串在整体进行“大于”或“小于”的关系运算。我们将会本节末创建一个类似的函数。</p><h6 id="6-2-4-3-在一字符串内对字符进行判断">6.2.4.3   在一字符串内对字符进行判断</h6><p>有两个函数可对一个字符串内的字符逐个进行分类。</p><ol><li><p>isletter       用来判断一个字符是否为字母</p></li><li><p>isspace       判断一个字符是否为空臼字符（空格，tab，换行符）</p></li></ol><p>例如，我们要创建一个字符串 mystring</p><pre><code class="highlight plaintext">mystring = 'Room 23a'</code></pre><p>函数 isletter 检测字符串中的每一个字符，将产生一个与字符串 isletter 相同长度输出向量，一个字符对应一个 1。</p><pre><code class="highlight plaintext">&gt;&gt; a = isletter(mystring)a =  1×8 logical 数组   1   1   1   1   0   0   0   1</code></pre><p>在 a 中前四个元素和最后一个元素是 1，因为它们对应的 mystring 中的字符是字母。函数 isspace 检测字符串中的每一个字符，将产生一个和字符串长度相同的输出变量，对应于空字符的向量元素为 0。</p><p>因为向量的第五个元素对应的是空格，所以向量的第五个元素的值为 1。</p><h5 id="6-2-5-在一个字符串中查找-替换字符">6.2.5  在一个字符串中查找/替换字符</h5><p><strong>MATLAB</strong> 提供了许多的函数，用来对字符串中的字符进行查找或替换。考虑字符串 test</p><pre><code class="highlight plaintext">test = 'This is a test!';</code></pre><p>函数 findstr 返回短字符串在长字符串中所有的开始位置。例如为了寻找 test 内的所有“is”</p><pre><code class="highlight plaintext">&gt;&gt; position = findstr(test,'is')position =3 6</code></pre><p>字符串“is”在 test 内出现两次，开始位置分别为 3 和 6。</p><p>函数 strmatch 是另一种匹配函数。它用来查看二维数组行开头的字符，并返回那些以指定的字符序列为开头行号。它的基本形式如下</p><pre><code class="highlight plaintext">result = strmatch(str,array);</code></pre><p>例如，我们用 strvcat 创建一个二维数组，</p><pre><code class="highlight plaintext">array = strvcat('maxarray','min value','max    value');</code></pre><p>那么下面的语句将会返回开始字符为“max”的行数。</p><pre><code class="highlight plaintext">&gt;&gt; result = strmatch('max',array)    result =    13</code></pre><p>函数 strrep 用于进行标准的查找和替换操作。它能找到一个字符串中的所有另一个字符串，并被第三个字符串替换。这个函数形式为</p><pre><code class="highlight plaintext">result = strrep(str,srch,repl)</code></pre><p>其中 str 是被检测的字符串，srch 是要查找到的字符串，repl 是用于替代的字符串，例如，</p><pre><code class="highlight plaintext">&gt;&gt; result = strrep(test,'test','pest')  result =    This is a pest!</code></pre><p>函数 strtok 返回输入字符串中第一次出现在分隔符前面的所有字符。默认的分隔符为一系列的空臼字符。strtok 的形式如下</p><p><strong>[token, remainder] = strtok(string,delim)</strong></p><p>其中 string 是输入字符串，delim 是可选择的分隔符，token 代表输入字符串中第一次出现在分隔符前面的所有字符，remainder 代表这一行的其余部分。例如</p><pre><code class="highlight plaintext">&gt;&gt; [token, remainder] = strtok('This is a test!')  token = This remainder = is a test!</code></pre><p>你可以利用函数strtok 把一个句子转换为单词。例如，下面的代码从字符数组 input_string 中分离出每一个单词，并把每一个单词独立地存储在字符数组 all_words 的每一行中。</p><pre><code class="highlight plaintext">function all_words = word(input_string)    remainder = input_string    all_words = '';    while (any(remainder))    [chopped, remainder] =    strtok(remainder); all_words = strvcat(all_words, chopped);    end</code></pre><h5 id="6-2-6-大小写转换">6.2.6  大小写转换</h5><p>函数 upper 和 lower 分别把一个字符串中所有转化大定和小写。例如</p><pre><code class="highlight plaintext">&gt;&gt; result = upper('This is test 1!')    result = THIS IS TEST 1!    &gt;&gt; result = lower('This is test 2!')    result = this is test 2!</code></pre><p>注意在大小转换时，数字和符号不受影响。</p><h5 id="6-2-7-字符串转换为数字">6.2.7  字符串转换为数字</h5><p><strong>MATLAB</strong> 把由数字组成的字符串转化为数字要用到函数 eval。例如，字符串“3.141592” 能用下面的语句把它转换为数字。</p><pre><code class="highlight plaintext">&gt;&gt; a = '3.141592';&gt;&gt; b = eval(a)b =3.1416&gt;&gt; whosName Size Bytes    Classa    1x8   16      char</code></pre><p>字符串可以用 sscanf 函数转化为数字。这个函数根据格式化转义字符转化为相应的数字。这个函数最简单的形式如下</p><pre><code class="highlight plaintext">value = sscanf(string, format)</code></pre><p>其中，string 是要转化的字符串，format 是相应的转义字符。函数 sscanf 两种最普通的转义序是“%d”，“%g”，它们分别代表输出为整数或浮点数。这个函数更多的细节我们将在第 8 章介绍。在作图中，创建一个复杂的标题或标签，它是非常有用的。</p><p>下面的例子用于说明函数 sscanf 的应用。</p><pre><code class="highlight plaintext">&gt;&gt; value1 = sscanf('3.141593','%g')value1 =3.1416&gt;&gt; value2 = sscanf('3.141593','%d')value2 =3</code></pre><h5 id="6-2-8-数字转化为字符串">6.2.8  数字转化为字符串</h5><p>​       <strong>MATLAB</strong> 中有许多的字符串/数字转换函数把数字转化为相应的字符串。我们在这里只看两个函数 num2str 和 int2str。考虑标量 x</p><pre><code class="highlight plaintext">x = 5317;</code></pre><p>在默认的情况下，<strong>MATLAB</strong> 把数 x 作为一个 1×1 的double 数组，它的值为 5317。函数 int2str（integer to string）所这个标量转化为 1×4 的字符数组，包含有字符串“5317”。</p><pre><code class="highlight plaintext">&gt;&gt; x = 5317;&gt;&gt; y = int2str(x);&gt;&gt; whosName Size Bytes  Classx  1x1   8    double y  1x4   8     char</code></pre><p>函数 num2str 为输出字符串的格式提供更多的控制。第二个可选择的参数可以对输出字符串的数字个数进行设置或指定一个实际格式。例如</p><pre><code class="highlight plaintext">&gt;&gt; p = num2str(pi,7)p =3.141593&gt;&gt; p = num2str(pi,'%10.5e')p =3.14159e+000</code></pre><p>函数 int2str 和 num2str 对作图标签是非常有用的。例如，下面的语句用 num2str 生成图象的标签。</p><pre><code class="highlight plaintext">function plotlabel(x,y)plot(x,y)str1 = num2str(min(x));str2 = num2str(max(x));out = ['Value of f from ' str1 ' to ' str2];xlabel(out);</code></pre><p>还有一些转换函数，用于把数字值从十进制转化另一种数制，例如二进制或十六进制。例如函数dec2hex 把一个十进制数转化为相应的十六进制字符串。此类的函数还有hex2num， hex2dec，bin2dec，dec2bin，base2dec，你可以通过 <strong>MATLAB</strong> 网上帮助来获取这些函数的 作用和使用方法。</p><p><strong>MATLAB</strong> 函数 mat2str 可以把一个数组转化为相应的 <strong>MATLAB</strong> 能运算字符串。这个字符串可以是 eval 函数的输入，函数 eval 对这个字符串的运算和直接在命令窗口键入效果是一样的。例如，我们定义一个数组如下</p><pre><code class="highlight plaintext">&gt;&gt; a = [1 2 3; 4 5 6]a =1 2 34 5 6</code></pre><p>函数 mat2str 运行得到的结果为</p><pre><code class="highlight plaintext">&gt;&gt; b = mat2str(a)b =[1 2 3;4 5 6]</code></pre><p>最后，<strong>MATLAB</strong> 中有一个专门的函数 sprintf 等价于函数 fprintf，唯一不同的是它的输出是一个字符串。这个函数对字符串的格式化操作的完全支持。例如，</p><pre><code class="highlight plaintext">&gt;&gt; str = sprintf('The value of pi = %8.6f',pi)str =The value of pi = 3.141593</code></pre><p>在图象中，用这些函数创建复杂的标题或标签将会非常的有用。</p><h5 id="6-2-9-总结">6.2.9 总结</h5><p>普通的 <strong>MATLAB</strong> 字符串函数总结在表 6.2 中。</p><p><strong>表 6.2 普通的 MATLAB 字符串函数</strong></p><table><thead><tr><th>类别</th><th>函数</th><th>描述普通</th></tr></thead><tbody><tr><td>普通</td><td></td><td></td></tr><tr><td></td><td>char</td><td>(1)  把数字转化为相应的字符值  (2)  把二维数组转化相应的字符串</td></tr><tr><td></td><td>double</td><td>把字符转化为相应的 double 值</td></tr><tr><td></td><td>blanks</td><td>创建一个由空格组成的字符串</td></tr><tr><td></td><td>deblanks</td><td>去除字符串末端的空格字符检测</td></tr><tr><td>字符检测</td><td></td><td></td></tr><tr><td></td><td>ischar</td><td>如果是一个字符数组，那么将会返回 1</td></tr><tr><td></td><td>isletter</td><td>如果是字母表中的字母，那么将会返回 1</td></tr><tr><td></td><td>isspace</td><td>如果是空白字符，那么将会返回 1</td></tr><tr><td>字符串操作</td><td></td><td></td></tr><tr><td></td><td>strcat</td><td>连接字符串</td></tr><tr><td></td><td>strvcat</td><td>竖直地连接字符串</td></tr><tr><td></td><td>strcmp</td><td>如果两字符串相等，那么函数将会返回 1</td></tr><tr><td></td><td>stricmp</td><td>忽略大小写如果两字符串相等，那么函数将会返回 1</td></tr><tr><td></td><td>strncmp</td><td>如果两字符串的前 n 个字母相等，那么函数将会返回 1</td></tr><tr><td></td><td>strncmpi</td><td>忽略大小，如果两字符串的前 n 个字母相同，那么数将会返回 1</td></tr><tr><td></td><td>findstr</td><td>在一个字符串中寻找另一个字符串</td></tr><tr><td></td><td>strfind</td><td>在一个字符串中寻找另一个字符串（版本 6.1 或以后的版本）</td></tr><tr><td></td><td>strjust</td><td>对齐字符串</td></tr><tr><td></td><td>strmatch</td><td>找字符串的区配</td></tr><tr><td></td><td>strrep</td><td>用一个字符串去替代另一个字符串</td></tr><tr><td></td><td>strtok</td><td>查找一字符串</td></tr><tr><td></td><td>upper</td><td>把字符串的所有字符转化为大写</td></tr><tr><td></td><td>lower</td><td>把字符串的所有字符转化为小写</td></tr><tr><td>数字转化为字符串</td><td></td><td></td></tr><tr><td></td><td>int2str</td><td>把整数转化为相应的字符串形式</td></tr><tr><td></td><td>num2str</td><td>把数字转化为相应的字符串形式</td></tr><tr><td></td><td>mat2str</td><td>把矩阵转化为相应的字符串形式</td></tr><tr><td></td><td>sprintf</td><td>对一字符串进行格式化输出</td></tr><tr><td>字符串转化为数字</td><td></td><td></td></tr><tr><td></td><td>str2double</td><td>把字符串转化相应的 double 型数据</td></tr><tr><td></td><td>str2num</td><td>把字符转化成数字</td></tr><tr><td></td><td>sscanf</td><td>从字符串中读取格式化数据</td></tr><tr><td>数制转换</td><td></td><td></td></tr><tr><td></td><td>hex2num</td><td>把 IEEE 十六进制字符型型数据转化为 double 形数据</td></tr><tr><td></td><td>hex2dec</td><td>把十六制字符串转化为相应的十进制整数</td></tr><tr><td></td><td>dec2hex</td><td>把十进制数转化为相应的十六制字符串</td></tr><tr><td></td><td>bin2dec</td><td>把二进制字符串转化为相应的十进制整数</td></tr><tr><td></td><td>base2dec</td><td>把 base B 转化为相应的十进制数据</td></tr><tr><td></td><td>dec2base</td><td>把十进制转化为相应的 base B</td></tr><tr><td></td><td>hex2num</td><td>把 IEEE 十六进制字符型型数据转化为 double 形数据</td></tr></tbody></table><h6 id="例-6-2-字符串比较函数">例 6.2 字符串比较函数</h6><p><strong>字符串比较函数</strong></p><p>在 C 语言中，函数 strcmp 根据 Ascii 码中字符顺序（我们称之为字典顺序）比较两字符， 如果第一个字符串的字典顺序在第二个字符串字典之后，函数将会产生-1，如果两字符串相同那么将会产生 0，如果第一个字符串的字典顺序在第二个字符串字典之前那么函数将会返回+1。</p><p>创建一个 <strong>MATLAB</strong> 函数 c_strcmp 用来比较两字符串，其功能与 C 语言 strcmp 中的函数功能相类似。这个函数对字符串进行比较时，应忽略末尾的空格。注意这个函数必须控制两字符串不同长的情况。</p><p>答案：</p><ol><li>陈述问题</li></ol><p>编写一个函数，比较两字符串 str1 和 str2，并返回以下结果</p><ol><li><p>-1       如果 str1 在字典顺序比 str2 的晚</p></li><li><p>0        如果两字符串的字典顺序相同</p></li></ol><p>3）+1      如果 str1 的字典顺序比 str2 的早</p><ol start="2"><li>定义输入输出量</li></ol><p>函数所需的输入量为两个字符串，str1 和 str2。这个函数的输出为-1、0 或 1。</p><ol start="3"><li>描述算法这个工程可分为以下四大步</li></ol><pre><code class="highlight plaintext">Verify input stringsPad strings to be equal lengthCompare characters from beginning to end, looking for the first differenceReturn a value based on the first difference</code></pre><p>我们将以上每一大步分解成更小的更细的小块。第一，我们必须验证传递给函数的数据是正确的。函数必须有两个参数，且这两个参数必须为字符。这一步的伪代码为</p><pre><code class="highlight plaintext">% Check for a legal number of input arguments.msg = nargchk(2, 2, nargin)error(msg)% Check to see if the arguments are stringsif either argument is not a stringerror('str1 and str2 must both be strings')else(add code here)end</code></pre><p>下一步，我们要做的是把这两个字符串具有相同的长度。最简单的方法是用 strvcat 函数把这两个字符串联合成一个二维数组。注意在这个步骤中产生字符串末端空格只是为了两字符串相等，所以这些空格可以被省略。</p><pre><code class="highlight plaintext">% Pad stringsstrings = strvcat(str1, str2)</code></pre><p>现在我们要对字符串中的每一个字符进行比较，直到我们一个不同的字符出现，并基于这种不同返回相应的值。为了达到这个止目的，其中的方法是应用关系运算符比较两个字符串，产生一个由 0 和 1 组成的数组。然后我们可以寻找第一个 1，因为它两字符串在这里出现第一次不同。这一步的伪代码如下</p><pre><code class="highlight plaintext">% Compare stringsdiff = strings(1, :) ~= strings(2, :)if sum(diff) == 0% Strings matchresult = 0else% Find first differenceival = find(diff)if strings(1, ival(1)) &gt; strings(2, ival(1))result = 1elseresult = -1endend</code></pre><ol start="4"><li>把算法转化为相应的 <strong>MATLAB</strong> 语句</li></ol><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">result</span> = <span class="title">c_strcmp</span><span class="params">(str1,str2)</span></span><span class="comment">% C_STRCMP Compare strings like C function "strcmp"</span><span class="comment">% Function C_STRCMP compares two strings, and returns</span><span class="comment">% a -1 of str1 &lt; str2, a 0 if str1 == str2, and a</span><span class="comment">% +1 if str1 &gt; str2.</span><span class="comment">% Define variables:</span><span class="comment">% diff -- Logical array of string differences</span><span class="comment">% msg -- Error message</span><span class="comment">% result -- Result of function</span><span class="comment">% str1 -- First string to compare</span><span class="comment">% str2 -- Second string to compare</span><span class="comment">% strings -- Padded array of strings</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 10/18/98 S. J. Chapman Original code</span><span class="comment">% Check for a legal number of input arguments.</span>msg = nargchk(<span class="number">2</span>,<span class="number">2</span>,nargin);error(msg);<span class="comment">% Check to see if the arguments are strings</span><span class="keyword">if</span> ~(isstr(str1) &amp; isstr(str2))error(<span class="string">'Both str1 and str2 must both be strings!'</span>)<span class="keyword">else</span><span class="comment">% Pad strings</span>strings = strvcat(str1,str2);<span class="comment">% Compare strings</span>diff = strings(<span class="number">1</span>,:) ~= strings(<span class="number">2</span>,:);<span class="keyword">if</span> sum(diff) == <span class="number">0</span><span class="comment">% Strings match, so return a zero!</span>result = <span class="number">0</span>;<span class="keyword">else</span><span class="comment">% Find first difference between strings</span>ival = <span class="built_in">find</span>(diff);        <span class="keyword">if</span> strings(<span class="number">1</span>,ival(<span class="number">1</span>)) &gt; strings(<span class="number">2</span>,ival(<span class="number">1</span>))            result = <span class="number">1</span>;        <span class="keyword">else</span>            result = <span class="number">-1</span>;        <span class="keyword">end</span><span class="keyword">end</span><span class="keyword">end</span></code></pre><ol start="5"><li>检测程序</li></ol><p>我们必须用多个字符串对程序进行检测</p><pre><code class="highlight plaintext">&gt;&gt; result = c_strcmp('String 1','String 1')result =0&gt;&gt; result = c_strcmp('String 1','String 1 ')result =0&gt;&gt; result = c_strcmp('String 1','String 2')result =-1&gt;&gt; result = c_strcmp('String 1','String 0')result =1&gt;&gt; result = c_strcmp('String 1','str')result =-1</code></pre><p>第一次检测返回 0，是因为两字符串是相同的。第二次也返回 0，因为两字符串也是相等的，只是末端空格不同，末端空格被忽略。第三次检测返回-1，因为两字符串第一次的不同出现在第 8 位上，且在这个位置上“1”&lt;“2”。第四次检测将返回 1，因为两字符串第一次的不同出现在第 8 位上，且在这个位置上，“1”&gt;“0”。第五次检测将会返回-1，因为两字符串的第一个字符就不同，在 ascii 的序列上“S”&lt;“s”。这个函数工作正常。</p><h4 id="6-3-多维数组">6.3 多维数组</h4><p>从<strong>MATLAB</strong> 5.0 版本开始支持多于二维的数组。这些多维数组用来显示多于二维的数据，或显示多个版本的二维图。例如，在一个三维空间中压力和速度的测量对于一些学科来说是非常重要的，例如空气动力学，流体力学。在这些领域中自然会用到多维数组。</p><p>多维数组是二维数组的扩展。每增加一维，它们所对应的每个元素就会多一个下角标。</p><p>我们可以轻易地创建一个多维数组。它既可以通过直接的赋值语句进行赋值，可用相同的函数进行创建（和一维二维中一样）。例如，假设你已经利用赋值语句创建了一个二维数组</p><pre><code class="highlight plaintext">&gt;&gt; a = [1 2 3 4; 5 6 7 8]a =     1     2     3     4     5     6     7     8</code></pre><p>这是一个 2×4 数组，每个元素被访问时，都应带有两个下标。这个数组可扩展为一个三维 2×4×3 数组，语句如下</p><pre><code class="highlight plaintext">&gt;&gt; a(:,:,2) = [9 10 11 12; 13 14 15 16];&gt;&gt; a(:,:,3) = [17 18 19 20; 21 22 23 24]a(:,:,1) =     1     2     3     4     5     6     7     8a(:,:,2) =     9    10    11    12    13    14    15    16a(:,:,3) =    17    18    19    20    21    22    23    24</code></pre><p>在这个多维数组中的每一个元素都可以用它的函数名加上它的三个下标进行访问，数据下标的创建可以用克隆运算符。例如，a(2,2,2)的值为</p><pre><code class="highlight plaintext">&gt;&gt; a(2,2,2)ans =    14</code></pre><p>向量 a(1,1,:)为</p><pre><code class="highlight plaintext">&gt;&gt; a(1,1,:)ans(:,:,1) =     1ans(:,:,2) =     9ans(:,:,3) =    17</code></pre><p>多维数组也可以用与其他数据相同的函数进行创建</p><pre><code class="highlight plaintext">&gt;&gt; b = ones(4,4,2)b(:,:,1) =     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1b(:,:,2) =     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1&gt;&gt; c = randn(2,2,3)c(:,:,1) =   -1.3077    0.3426   -0.4336    3.5784c(:,:,2) =    2.7694    3.0349   -1.3499    0.7254c(:,:,3) =   -0.0631   -0.2050    0.7147   -0.1241</code></pre><p>多维数组的维数可以利用 ndims 函数得到，数组的大小可通过 size 函数得到。</p><pre><code class="highlight plaintext">&gt;&gt; ndims(c)ans =     3&gt;&gt; size(c)ans =     2     2     3</code></pre><p>如果你需要多数组编写应用程序，你可以通过阅读 <strong>MATLAB</strong> user’s guide 来了解更多的多维数组函数的细节。</p><p><strong>我们可以利用多维数组来解决自然界的多变量问题，如空气动力学和流体力学。</strong></p><h4 id="6-4-关于二维作图的补充说明">6.4 关于二维作图的补充说明</h4><p>在前面的章节中，我们学习了如何创建线性图，对数图，线性-对数图和极坐标图。</p><p><strong>MATLAB</strong> 提供了许多的画图类型，用来显示你的数据。本节将向你介绍它们其中的一些操作。</p><h5 id="6-4-1-二维作图的附加类型">6.4.1  二维作图的附加类型</h5><p>除了我们已经看到图象类型，<strong>MATLAB</strong> 还支持其他的图象。实际上，在 <strong>MATLAB</strong> 帮助工作台中列出超过 20 种类型的作图。例如针头图（Stem Plots），阶梯图（stair plots），条形图(bar plots)，饼图（pie plots），罗盘图（compass plots）。在针头图中的每一个值都用一个圆圈和垂直于 x 轴的直线连接而成。在阶梯图中的每一个值都是用连续的竖直的长条线来表示，形成阶梯状效果。条形图可分成水平条形图和竖直条形图。</p><p>饼图用不同的扇区代表不同的变量。最后罗盘图是另一种极坐标图它的每一值用箭头来表示。</p><p>针头图，阶梯图，条形图，饼图，罗盘图与普通的图象差不多，它的调用方式相同。例如，下面显示的是一个针头图的代码，产生的图象如图 6.7 (a) 所示。</p><pre><code class="highlight matlab"><span class="comment">% 针头图</span>x = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span>];y = [<span class="number">2</span> <span class="number">6</span> <span class="number">8</span> <span class="number">7</span> <span class="number">8</span> <span class="number">5</span>];stem(x,y);title(<span class="string">'\bfExample of a Stem Plot'</span>); xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bf\ity'</span>); axis([<span class="number">0</span> <span class="number">7</span> <span class="number">0</span> <span class="number">10</span>]);</code></pre><p><img src="/medias/20200617104223532.png" alt="6.7 (a) 针头图"></p><p>阶梯图，针头图，条形图，罗盘图可以调用 stair，bar，barh 和 compass 命令来创建，代码类似于上面的语句。这些图象的具体细节，例如它们选择性参数，可以通过 <strong>MATLAB</strong> 在线帮助系统得到。</p><p>函数 pie 与前面其他的画图有所不同。为了创建一个饼图，程序员把数组 x 传递给函数， 函数计算出每一个元素占全部元素和的百分比。例如，如果数组 x 是[1 2 3 4]，那么pie 函数将会计算出第一个元素 1 占全部元素和的 10%，第二个元素占 20%等等。这个函数将会占这个百分比画出相应的饼图。</p><p>函数 pie 也支持选择性参数，它是 eplode。如果存在的话，explode 是一个逻辑数组，包含元素 1 和 0。如果 explode 的值为 1，那么它对应的扇区就从整体中分离出来。下面的代码将会创建出饼图 6.7 (b)。注意下面的第二个扇区分离出来的。</p><pre><code class="highlight matlab"><span class="comment">% 饼状图</span>data = [<span class="number">10</span> <span class="number">37</span> <span class="number">5</span> <span class="number">6</span> <span class="number">6</span>];explode = [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>];pie(data, explode);title(<span class="string">'\bfExample of a Pie Plot'</span>);<span class="built_in">legend</span>(<span class="string">'One'</span>,<span class="string">'Two'</span>,<span class="string">'Three'</span>,<span class="string">'Four'</span>,<span class="string">'Five'</span>);</code></pre><p><img src="/medias/20200617112443352.png" alt="6.7 (b) 饼状图"></p><p><strong>表 6.3 附加的二维作图类型</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>bar(x, y)</td><td>这个函数用于创建一个水平的条形图，x 代表第一个 X 轴的取值，y 代表对应于 Y 的取值</td></tr><tr><td>barh(x, y)</td><td>这个函数用于创建一个竖直的条形图，x 代表第一个 X 轴的取值，y 代表对应于 Y 的取值</td></tr><tr><td>compass(x, y)</td><td>这个函数用于创建一个极坐标图，它的每一个值都用箭头表示，从原点指向（x，y），注意：（x，y）是直角坐标系中的坐标</td></tr><tr><td>pie(x)  pie(x, explode)</td><td>这个函数用来创建一个饼状图，x 代表占总数的百分数。explode 用来判断是否还有剩余的百分数</td></tr><tr><td>stairs(x, y)</td><td>用来创建一个阶梯图，每一个阶梯的中心为点(x, y)</td></tr><tr><td>stem(x, y)</td><td>这个函数可以创建一个针头图，它的取值为(x,y)</td></tr></tbody></table><pre><code class="highlight matlab"><span class="comment">% 阶梯状图</span>x = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span>];y = [<span class="number">2</span> <span class="number">6</span> <span class="number">8</span> <span class="number">7</span> <span class="number">8</span> <span class="number">5</span>];stairs(x,y);title(<span class="string">'\bfExample of a Stairs Plot'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bf\ity'</span>);axis([<span class="number">0</span> <span class="number">7</span> <span class="number">0</span> <span class="number">10</span>]);</code></pre><p><img src="/medias/20200617111556210.png" alt="6.7 (c) 阶梯状图"></p><pre><code class="highlight matlab"><span class="comment">% 水平的条形图</span>x = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span>];y = [<span class="number">2</span> <span class="number">6</span> <span class="number">8</span> <span class="number">7</span> <span class="number">8</span> <span class="number">5</span>];bar(x,y);title(<span class="string">'\bfExample of a Bar Plot'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bf\ity'</span>);axis([<span class="number">0</span> <span class="number">7</span> <span class="number">0</span> <span class="number">10</span>]);</code></pre><p><img src="/medias/20200617111342662.png" alt="6.7 (d) 水平的条形图"></p><pre><code class="highlight matlab"><span class="comment">% 竖直的条形图</span>x = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span>];y = [<span class="number">2</span> <span class="number">6</span> <span class="number">8</span> <span class="number">7</span> <span class="number">8</span> <span class="number">5</span>];barh(x,y);title(<span class="string">'\bfExample of a Horizontal Bar Plot'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bf\ity'</span>);axis([<span class="number">0</span> <span class="number">7</span> <span class="number">0</span> <span class="number">10</span>]);</code></pre><p><img src="/medias/20200617113422622.png" alt="6.7 (e) 竖直的条形图"></p><pre><code class="highlight matlab">x = [<span class="number">10</span> <span class="number">2</span> <span class="number">30</span> <span class="number">14</span> <span class="number">45</span> <span class="number">60</span>];y = [<span class="number">102</span> <span class="number">60</span> <span class="number">85</span> <span class="number">47</span> <span class="number">81</span> <span class="number">45</span>];compass(x,y);title(<span class="string">'\bfExample of a Compass Plot'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bf\ity'</span>);</code></pre><p><img src="/medias/20200617112007870.png" alt="6.7 (f) 罗盘图"></p><pre><code class="highlight matlab">&gt;&gt; Z = eig(<span class="built_in">randn</span>(<span class="number">10</span>,<span class="number">10</span>));&gt;&gt; compass(Z)</code></pre><p><img src="/medias/20200617113836634.png" alt="6.7 (g) 罗盘图"></p><h5 id="6-4-2-作图函数">6.4.2  作图函数</h5><p>在前面的所有作图，我们必须创建数组，并把这些数组传递给作图函数。<strong>MATLAB</strong> 提供了两个函数可以直接作出图象，而不需要创建中间数据数组。它们是函数数 ezplot 和 fplot。</p><p>ezplot 调用函数的形式如下</p><pre><code class="highlight plaintext">ezplot( fun);ezplot( fun, [xmin xmax]); ezplot( fun, [xmin xmax], figure);</code></pre><p>其中，fun 代表一个字符串，用来表示要画的基本表达式。选择性参数[xmin，xmax]指定自变量的取值范围。如果它不存在的话，函数自变量的范围从-2n到 2n。选择性参数图来用指定图象数。</p><p>例如，下面语句打印出函数 f(x)=sinx/x，x 的取值范围在-4加 到 4加，输出图象如图 6.8 所示</p><pre><code class="highlight matlab">ezplot(<span class="string">'sin(x)/x'</span>,[<span class="number">-4</span>*<span class="built_in">pi</span> <span class="number">4</span>*<span class="built_in">pi</span>]); title(<span class="string">'Plot of sinx/x'</span>);grid on;</code></pre><p><img src="/medias/20200617114900599.png" alt="图 6.8 函数 sin(x)／x 的图象"></p><p>函数 fplot 与 ezplot 相类似，但更加精确。前两个参数与函数 ezplot 中的相同，但是函数 fplot 还有其他优点。</p><ol><li><p>函数 fplot 是适应性的，它意味着在自变量范围内函数突然变化显示更多的点。</p></li><li><p>函数 fplot 支持 <em>T~E~X</em> 命令，用来指定坐标图的标题和坐标轴标签，而函数 ezplot 则不能。</p></li></ol><p>在一般情况下，在画函数图象时，你应当使用函数 fplot。函数 ezplot 和 fplot 是第五章中“函数的函数”的具体例子。</p><p><strong>使用 fplot 函数直接打印函数，而不需创建中间数据数据</strong>。</p><h5 id="6-4-3-柱状图">6.4.3  柱状图</h5><p>柱状图用来显示一系列数据数值的分布。为了创建一个柱状图，在一系列数值中范围被平均划分，并确定某一个范围中数值的个数。并把这个数目通过函数画出图来。</p><p>标准的 <strong>MATLAB</strong> 柱状图函数应为 hist。函数的形式如下：</p><pre><code class="highlight plaintext">hist (y)hist(y, nbins)his(y, x);[n, xout] =hist(y, ...)</code></pre><p>第一个函数创建并画出一个 10 等分的柱状图，而第二种形式创建的是以 nbins 为宽度的柱状图。第三个函数允许用户用数组 x 指定柱状图中长条的中心。这个函数创建柱状图长条都是以数组中的元素为中心的。这三种形式均能创建柱状图。这个函数的最后一种形式创建了一个柱状图并返回了一个数组 xcout，在数组 n 中的每一长条的数目，而实际上并没有创建一个图象。</p><p>例如，下面的语句创建一个包含有 1000 个符合正分布的随机数数组并产生了一个取值范围 15 等分的柱状图。产生的图象如图 6.9 所示。</p><pre><code class="highlight matlab">y = <span class="built_in">randn</span>(<span class="number">10000</span>, <span class="number">1</span>);hist(y, <span class="number">15</span>);</code></pre><p><img src="/medias/20200617115351351.png" alt="图 6.9 柱状图"></p><p><strong>MATLAB</strong> 提供了函数 rose 用来创建极坐标系中的柱状图。对于研究角度的分布非常有用。你将会在章末的练习中用到。</p><h4 id="6-5-三维作图">6.5 三维作图</h4><p><strong>MATLAB</strong> 中包括了丰富的三维图象，用来显示各式各样的数据。在一般情况下，三维图象常用于显示以下两类数据。</p><ol><li><p>两个变量是同一自变量的函数，当你希望显示自变量重要性时，你可以用三维作图表示</p></li><li><p>一个变量是另外两个变量的函数</p></li></ol><h5 id="6-5-1-三维曲线作图">6.5.1 三维曲线作图</h5><p>我们可以用 plot3 函数进行三维曲线的作图。这个函数与二维 plot 函数非常相似，除了每一个点用 x，y，z 表示，而不用 x，y 表示。它的最简单的函数为</p><pre><code class="highlight plaintext">plot(x, y, z);</code></pre><p>其中 x，y，z 是等大小的数组，它们组成了这个点的 3 维坐标。函数 plot3 提供了和 plot 函数相同的线型，大小和颜色，你直接利用前面学到的知识，画出一定的图形。作为一个三维曲线的例子，考虑下面的函数</p><img src="/medias/20200617115619675.png" style="zoom:60%;"><p>这些函数表示在二维机械系统振动衰退情况，所以 <em>x</em>，<em>y</em> 代表在时刻 <em>t</em> 系统的位置。注意 <em>x</em>，<em>y</em> 有一相同的自变量 <em>t</em>。</p><p>我们可以创建一系列（x，y）并用二维函数 plot 画出（x，y）的图象，但是我们如果这样作了，时间的重要性就得不到体现。下面的语句创建了物体位置的一个二维图象，如图 6.10 (a)。这个图不可能告诉我们振动变化的快慢。</p><pre><code class="highlight matlab">t = <span class="number">0</span>:<span class="number">0.1</span>:<span class="number">10</span>;x = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* <span class="built_in">cos</span>(<span class="number">2</span>*t);y = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* <span class="built_in">sin</span>(<span class="number">2</span>*t);<span class="built_in">plot</span>(x,y);title(<span class="string">'\bfTwo-Dimensional Line Plot'</span>);xlabel(<span class="string">'\bfx'</span>);ylabel(<span class="string">'\bfy'</span>);zlabel(<span class="string">'\bfTime'</span>);axis square;grid on;</code></pre><p><img src="/medias/20200617121551518.png" alt=""></p><p>我们可以利用 plot3 函数画出时间物体位置的三维图象。下面的语句将会创造 6.11 的三维图象。</p><pre><code class="highlight matlab">t = <span class="number">0</span>:<span class="number">0.1</span>:<span class="number">10</span>;x = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* <span class="built_in">cos</span>(<span class="number">2</span>*t);y = <span class="built_in">exp</span>(<span class="number">-0.2</span>*t) .* <span class="built_in">sin</span>(<span class="number">2</span>*t);<span class="built_in">plot3</span>(x,y,t);title(<span class="string">'\bfThree-Dimensional Line Plot'</span>);xlabel(<span class="string">'\bfx'</span>);ylabel(<span class="string">'\bfy'</span>);zlabel(<span class="string">'\bfTime'</span>);axis square;grid on;</code></pre><p><img src="/medias/20200617115848907.png" alt="图 6.10 (b)"></p><p>(a) 用二维图象代表物体的位置</p><p>(b) 用三维图象来表示指定时间内的物体的位置产生的图象如图 6.10 (b) 所示。注意这个图象显示了时间的独立性。</p><h5 id="6-5-2-三维表面，网格，等高线图象">6.5.2 三维表面，网格，等高线图象</h5><p>表面，网格，等高线图象是非常简单的方法来表示两变量的函数。例如，东西（x）南北（y）点上的温度。任何两变量函数的值都能用表面，网格，或等高线图象表示。有更多作图类型出现表 6.4 中，每一个图象的例子显示在图 6.11 中。</p><p>利用其中一个函数画图，用户必须创建三个等大小的数组。这个三个数组必须包括要画的每一点的 x，y，z 值。举一个简单的例子，假设我们要 4 个点（-1，-1，1），（1，-1，2），（-1，1，1）和（1，1，0），为了画出这 4 个点，我们必须创建三个数组</p><img src="/medias/20200617121814226.png" style="zoom:67%;"><p>数组 x 包括要画得每一点的 x 值，数组 y 包括要画得每一点的 y 值，数组 z 包括要画得每一点的 z 值。这些数组被传递到画图函数。</p><p><strong>表 6.4 表面，网格，等高线图象函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>mesh(x, y, z)</td><td>这个函数创建一个三维网格图象。数组 x 包括要画得每一点的 x 值，数组 y 包括要画得每一点的 y 值，数组 z 包括要画得每一点的 z 值</td></tr><tr><td>surf(x, y, z)</td><td>这个函数创建一个三维表面图象。x，y，z 代表的意义与上式相同</td></tr><tr><td>contour(x, y, z)</td><td>这个函数创建一个三维等高线图象。x，y，z 代表的意义与上式相同</td></tr></tbody></table><p><strong>MATLAB</strong> 函数 meshgrid 使函数图象数组 x，y 的创建变得十分容易。这些函数的形式为</p><pre><code class="highlight plaintext">[x y] = meshgrid(xstart:xinc:xend, ystart:yinc:yend);</code></pre><p>xstart:xinc:xend 指定 x 值，ystart:yinc:yend 指定 y 值。</p><p>为了创建一个图象，我们要应用 meshgrid 来创建 x，y 的值，并通过函数计算（x，y） 相对应的值。最后我们调用函数 mesh，surf 或 contour 来创建图象。例如，我们考虑下面函数的网格图象。</p><img src="/medias/20200617123305773.png" style="zoom:67%;"><p>x，y 的取值分别为[-4, 4]，[-4,4]。下面语句将会创建这个图象，如图 6.11（a） 所示</p><pre><code class="highlight matlab">[x,y] = <span class="built_in">meshgrid</span>(<span class="number">-4</span>:<span class="number">0.2</span>:<span class="number">4</span>,<span class="number">-4</span>:<span class="number">0.2</span>:<span class="number">4</span>);z = <span class="built_in">exp</span>(<span class="number">-0.5</span>*(x.^<span class="number">2</span>+y.^<span class="number">2</span>));mesh(x,y,z);xlabel(<span class="string">'\bfx'</span>);ylabel(<span class="string">'\bfy'</span>);zlabel(<span class="string">'\bfz'</span>);</code></pre><p>表面，等高线图象可以类似于 mesh 函数创建。</p><p><img src="/medias/20200617123557280.png" alt=" 6.11（a）"></p><pre><code class="highlight matlab">[x,y] = <span class="built_in">meshgrid</span>(<span class="number">-4</span>:<span class="number">0.2</span>:<span class="number">4</span>,<span class="number">-4</span>:<span class="number">0.2</span>:<span class="number">4</span>);z = <span class="built_in">exp</span>(<span class="number">-0.5</span>*(x.^<span class="number">2</span>+y.^<span class="number">2</span>));surf(x,y,z);xlabel(<span class="string">'\bfx'</span>);ylabel(<span class="string">'\bfy'</span>);zlabel(<span class="string">'\bfz'</span>);</code></pre><p><img src="/medias/20200617124106383.png" alt=""></p><pre><code class="highlight matlab">[x,y] = <span class="built_in">meshgrid</span>(<span class="number">-4</span>:<span class="number">0.2</span>:<span class="number">4</span>,<span class="number">-4</span>:<span class="number">0.2</span>:<span class="number">4</span>);z = <span class="built_in">exp</span>(<span class="number">-0.5</span>*(x.^<span class="number">2</span>+y.^<span class="number">2</span>));contour(x,y,z);xlabel(<span class="string">'\bfx'</span>);ylabel(<span class="string">'\bfy'</span>);zlabel(<span class="string">'\bfz'</span>);</code></pre><p><img src="/medias/20200617124232404.png" alt=""></p><h4 id="6-6-总结">6.6 总结</h4><p><strong>MATLAB</strong> 支持复数，作为 double 数据类型的扩展。复数用 i 和 j 定义，它们都被预定义为 1 。你可以直接应用复数进行运算，但要注意关系运算符只对复数的实部进行比较， 而不对它的模进行比较。当你进行复数运算这是一个常见错误。</p><p>字符串函数是进行字符串操作。字符串是 char 型数组。这些函数允许用户对字符串进行各种各样的操作，例如连接，比较，替换，查找，大小写转换，数字与字符串之间的转换。</p><p>多维数组是指超过两维的数组。它们可用创建一维，二维数组的方法进行创建。多维数组用于解决自然界的一些问题。</p><p><strong>MATLAB</strong> 中包含了许多的二维三维的作图方法，在本章中我们向大家介绍了针头图（stem Plots），阶梯图（stair plots），条形图，饼图（pie plots），罗盘图（compass plots），三维表面，网格，等高线图象。</p><h5 id="6-6-1-好的编程习惯总结">6.6.1 好的编程习惯总结</h5><ol><li><p>用 char 函数创建二维字符数组，我们就不用担心每一行的长度不相同了。</p></li><li><p>我们可以利用多维数组来解决自然界的多变量问题，如空气动力学和流体力学。</p></li><li><p>使用 fplot 函数直接打印函数，而不需创建中间数据数据。</p></li></ol><h5 id="6-6-2-MATLAB-函数与命令总结">6.6.2 MATLAB 函数与命令总结</h5><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>char</td><td>(1) 把数字转化为相应的字符值   (2) 把二维数组转化相应的字符串</td></tr><tr><td>double</td><td>把字符转化为相应的 double 值</td></tr><tr><td>blanks</td><td>创建一个由空格组成的字符串</td></tr><tr><td>deblanks</td><td>去除字符串末端的空格</td></tr><tr><td>strcat</td><td>连接字符串</td></tr><tr><td>strvcat</td><td>竖直地连接字符串</td></tr><tr><td>strcmp</td><td>如果两字符串相等，那么函数将会返回 1</td></tr><tr><td>stricmp</td><td>忽略大小写如果两字符串相等，那么函数将会返回 1</td></tr><tr><td>strncmp</td><td>如果两字符串的前 n 个字母相等，那么函数将会返回 1</td></tr><tr><td>strncmpi</td><td>忽略大小，如果两字符串的前 n 个字母相同，那么数将会返回 1</td></tr><tr><td>findstr</td><td>在一个字符串中寻找另一个字符串</td></tr><tr><td>strfind</td><td>在一个字符串中寻找另一个字符串（版本 6。1 或以后的版本）</td></tr><tr><td>strjust</td><td>对齐字符串</td></tr><tr><td>strmatch</td><td>找字符串的区配</td></tr><tr><td>strrep</td><td>用一个字符串去替代另一个字符串</td></tr><tr><td>strtok</td><td>查找一字符串</td></tr><tr><td>upper</td><td>把字符串的所有字符转化为大写</td></tr><tr><td>lower</td><td>把字符串的所有字符转化为小写</td></tr><tr><td>int2str</td><td>把整数转化为相应的字符串形式</td></tr><tr><td>num2str</td><td>把数字转化为相应的字符串形式</td></tr><tr><td>mat2str</td><td>把矩阵转化为相应的字符串形式</td></tr><tr><td>sprintf</td><td>对一字符串进行格式化输出</td></tr><tr><td>str2double</td><td>把字符串转化相应的 double 型数据</td></tr><tr><td>str2num</td><td>把字符转化成数字</td></tr><tr><td>sscanf</td><td>从字符串中读取格式化数据</td></tr><tr><td>hex2num</td><td>把 IEEE 十六进制字符型型数据转化为 double 形数据</td></tr><tr><td>hex2dec</td><td>把十六制字符串转化为相应的十进制整数</td></tr><tr><td>dec2hex</td><td>把十进制数转化为相应的十六制字符串</td></tr><tr><td>bin2dec</td><td>把二进制字符串转化为相应的十进制整数</td></tr><tr><td>base2dec</td><td>把baseb转化为相应的 十进制数据</td></tr><tr><td>dec2dec</td><td>把十进制转化为相应的 baseb</td></tr><tr><td>bar(x, y)</td><td>这个函数用于创建一个水平的条形图，x 代表第一个 X 轴的取值，y 代表对应于 Y 的取值</td></tr><tr><td>barh(x, y)</td><td>这个函数用于创建一个竖直的条形图，x 代表第一个 X 轴的取值，y 代表对应于 Y 的取值</td></tr><tr><td>compass(x, y)</td><td>这个函数用于创建一个极坐标图，它的每一个值都用箭头表示，从原点指向（x，y），注意：（x，y）是直角坐标系中的坐标。</td></tr><tr><td>pie(x)  pie(x, explode)</td><td>这个函数用来创建一个饼状图，x 代表占总数的百分数。explode 用来判断是否还有剩余的百分数</td></tr><tr><td>stairs(x, y)</td><td>用来创建一个阶梯图，每一个阶梯的中心为点(x, y)</td></tr><tr><td>stem(x, y)</td><td>这个函数可以创建一个针头图，它的取值为(x,y)</td></tr></tbody></table><h3 id="第七章-稀疏矩阵，单元阵列，结构">第七章 稀疏矩阵，单元阵列，结构</h3><p>在本章中我们要学习三种数据类型：稀疏矩阵，单元阵列和结构。稀疏矩阵是矩阵的一种特殊形式，在这个矩阵中只对非零元素分配内存。单元阵列也是一种矩阵，它的每一个元素可以是 <strong>MATLAB</strong> 任何一种数据类型。它们广泛应用于 <strong>MATLAB</strong> 用户图象界面（GUI） 函数。最后，结构提供了一种在单个变量中存储了不同类型的数据的方法，在这个变量中的每一个数据项目都有一个独立的名字。</p><h4 id="7-1-稀疏矩阵">7.1 稀疏矩阵</h4><p>我们在第二章中已经学过了普通的 <strong>MATLAB</strong> 数组。当一个普通的数组被声明后，<strong>MATLAB</strong> 将会为每一个数组元素分配内存。例如函数 a = eye(10)要创建了 100 个元素，按10 × 10 的结构分配，对角线上的元素均为 1，其余的元素为 0。注意这些数组其中的 90 个元素为 0。这个包含有一百个元素的矩阵，只有 10 个元素包含非零值。这是稀疏矩阵或稀疏数组的一个例子。稀疏矩阵是指一个很大的矩阵，且大多数的元素为 0。</p><pre><code class="highlight plaintext">&gt;&gt; a = 2*eye(10)a =     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2     0     0     0     0     0     0     0     0     0     0     2</code></pre><p>现在假如我们要创建一个 10 × 10 的矩阵，定义如下</p><pre><code class="highlight plaintext">b =    1 0 0 0 0 0 0 0 0 0    0 2 0 0 0 0 0 0 0 0    0 0 2 0 0 0 0 0 0 0    0 0 0 1 0 0 0 0 0 0    0 0 0 0 5 0 0 0 0 0    0 0 0 0 0 1 0 0 0 0    0 0 0 0 0 0 1 0 0 0    0 0 0 0 0 0 0 1 0 0    0 0 0 0 0 0 0 0 1 0    0 0 0 0 0 0 0 0 0 1</code></pre><p>若 a，b 两矩阵相乘得到的结果为</p><pre><code class="highlight plaintext">&gt;&gt; c = a * bc =    2   000000000    0   400000000    0   040000000    0   002000000    0   0001000000    0000020000    0000002000    0000000200    0000000020    0000000002</code></pre><p>这两个稀疏矩阵相乘需要 1900 次相加和相乘，但是在大多数时侯相加和相乘的结果为0，所以我们做了许多的无用功。这个问题会随着矩阵大小的增大而变得非常的严重。例如， 假设我们要产生两个 200 × 200 的稀疏矩阵，如下所示</p><pre><code class="highlight plaintext">a = 5 * eye(200); b = 3 * eye(200);</code></pre><p>每一个矩阵有 20000 个元素，其中 19800 个元素是 0。进一步说，对这两个矩阵相乘需要 7980000 次加法和乘法。</p><p>我们可以看出对大规模稀疏矩阵进行存储和运算（其中大部分为 0）是对内存空间和 cpu资源的极大浪费。不巧的是，在现实中的许多问题都需要稀疏矩阵，我们需要一些有效的方示来解决这个问题。</p><p>大规模供电系统是现实世界中涉及到稀疏矩阵一个极好的例子。大规模供电系统可以包括上千条或更多的母线，用来产生，传输，分配电能到子电站。如果我们想知道这个系统的电压，电流和功率，我们必须首先知道每一条母线的电压。如果这个系统含有一千个母线， 这就要用到含有 1000 个未知数的联立方程组，包括一个方程，也就是说我们要创建含有1000000 个元素的矩阵。解出这个矩阵，需要上百万次的浮点运算。</p><p>但是，在这个系统中，一条母线平均只它的三条母线相连，而在这个矩阵中每一行其他的 996 个元素将为 0，所以在这个矩阵的加法和乘法运算中将会产生 0。如果在求解的过程中这些 0 可以忽略，那么这个电力系统的电压和电流计算将变得简单而高效。</p><h5 id="7-1-1-sparse-数据类型">7.1.1 sparse 数据类型</h5><p>在 <strong>MATLAB</strong> 中有一个专门的数据类型，用来对稀疏进行运算。sparse 数据类型不同于 double 数据，它在内存中只存储非零元素。实际上，sparse 数据类型只存储每一个非零元素的三个值：元素值，元素的行号和列号。尽管非零元素这三个值必须存储在这内存，但相对于存储稀疏矩阵的所有元素来说要简单高效得多。</p><p>我们用 10 × 10 的方阵来说明稀疏矩阵的应用。</p><pre><code class="highlight plaintext">&gt;&gt; a = eye(10)a =     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1     0     0     0     0     0     0     0     0     0     0     1</code></pre><p>如果这个矩阵被转化为稀疏矩阵，它的结果是</p><pre><code class="highlight plaintext">&gt;&gt;  as = sparse(a)as =   (1,1)        1   (2,2)        1   (3,3)        1   (4,4)        1   (5,5)        1   (6,6)        1   (7,7)        1   (8,8)        1   (9,9)        1  (10,10)       1</code></pre><p>注意在稀疏矩阵存储的是行列地址和这一点所对应的非零数据值。只要一个矩阵的大部分数都是 0，这种方法用来存储数据就是高效的，但是如果非零元素很多的话，那么用占用更多的空间，因为稀疏矩阵需要存储蓄地址。函数 issparse 通常用作检测一个矩阵是否为稀疏矩阵。如果这个矩阵是稀疏的，那么这个函数将会返回 1。</p><p>稀疏矩阵的优点可以通过下面的描述体现出来，考虑一个 1000 × 1000 的矩阵平均每一行只有 4 个非零元素。如果这个矩阵以全矩阵的形式储存，那么它要战胜 8000000 个字节。从另一方面说，如果它转化为一个稀疏矩阵，那么内存的使用将会迅速下降。</p><h6 id="7-1-1-1-产生稀疏矩阵">7.1.1.1   产生稀疏矩阵</h6><p><strong>MATLAB</strong> 可以通过sparse 函数把一个全矩阵转化为一个稀疏矩阵，也可以用 <strong>MATLAB</strong> 函数 speye，sprand 和 sprandn 直接产生稀疏矩阵，它们对应的全矩阵为 eye，rand，和 randn。例如，表达式 a = speye(4) 将产生一个 4 × 4 的稀疏矩阵。</p><pre><code class="highlight plaintext">&gt;&gt;  a = speye(4)a =   (1,1)        1   (2,2)        1   (3,3)        1   (4,4)        1</code></pre><p>表达式 b = full(a) 把稀疏矩阵转化相应的全矩阵。</p><pre><code class="highlight plaintext">&gt;&gt; b = full(a)b =    1000    0100    0010    0001</code></pre><h6 id="7-1-1-2-稀疏矩阵的运算">7.1.1.2   稀疏矩阵的运算</h6><p>如果一个矩阵是稀疏的，那么单个元素可以通过简单的赋值语句添加或删除，例如下面的语句产生一个 4 × 4 的稀疏矩阵，然后把其他的非零元素加入其中。</p><pre><code class="highlight plaintext">&gt;&gt; a = speye(4)a =   (1,1)        1   (2,2)        1   (3,3)        1   (4,4)        1&gt;&gt; a(2,1) = -2a =   (1,1)        1   (2,1)       -2   (2,2)        1   (3,3)        1   (4,4)        1</code></pre><p><strong>MATLAB</strong> 允许全矩阵与稀疏的混合运算。它们产生的结果可以是全矩阵也可以是稀疏矩阵，这取决于那种结果更高效。更重要的是，任何的适用全矩阵算法同样地也适合稀疏矩阵。表 7.1 列出的是一些普通的稀疏矩阵。</p><p><strong>表 7.1 普通的 MATLAB 稀疏矩阵函数</strong></p><table><thead><tr><th>类别</th><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>创建一个稀疏矩阵</td><td>speye</td><td>创建一个单位稀疏矩阵</td></tr><tr><td></td><td>sprand</td><td>创建一个稀疏矩阵，元素是符合平均分布的随机数</td></tr><tr><td></td><td>sprandn</td><td>创建一个稀疏矩阵，元素是普通的随机数</td></tr><tr><td>全矩阵和稀疏矩阵的转换函数</td><td>sparse</td><td>把一个全矩阵转化为一个稀疏矩阵</td></tr><tr><td></td><td>full</td><td>把一个稀疏矩阵转化为全矩阵</td></tr><tr><td></td><td>find</td><td>找出矩阵中非零元素和它对应的上下标</td></tr><tr><td>对稀疏矩阵进行操作的函数</td><td>nnz</td><td>非零元素的个数</td></tr><tr><td></td><td>nonzeros</td><td>返回一个向量，其中的元素为矩阵中非零元素</td></tr><tr><td></td><td>spones</td><td>用 1 代替矩阵中的非零元素</td></tr><tr><td></td><td>spalloc</td><td>一个稀疏矩阵所占的内存空间</td></tr><tr><td></td><td>issparse</td><td>如果是稀疏矩阵就返回 1</td></tr><tr><td></td><td>spfun</td><td>给矩阵中的非零元素提供函数</td></tr><tr><td></td><td>spy</td><td>用图象显示稀疏矩阵</td></tr></tbody></table><h6 id="例-7-1-用稀疏矩阵解决联立方程组">例 7.1 用稀疏矩阵解决联立方程组</h6><p><strong>用稀疏矩阵解决联立方程组</strong></p><p>为了解说明稀疏矩阵在 <strong>MATLAB</strong> 中应用，我们将用全矩阵和稀疏矩阵来解决下面的联立方程组。</p><p><img src="/medias/20200617161115854.png" alt=""></p><p>答案：</p><p>为了解决这一问题，我们将创建一个方程系数的全矩阵，并用 sparse 函数把他转化为稀疏矩阵。我们用两种方法解这个方程组，比较它们的结果和所需的内存。</p><p>代码如下：</p><pre><code class="highlight matlab"><span class="comment">% Script file: simul.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program solves a system of 8 linear equations in 8</span><span class="comment">% unknowns (a*x = b), using both full and sparse matrices.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ======== ===============</span><span class="comment">% 10/14/98 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% a --Coefficients of x (full matrix)</span><span class="comment">% as --Coefficients of x (sparse matrix)</span><span class="comment">% b --Constant coefficients (full matrix)</span><span class="comment">% bs --Constant coefficients (sparse matrix)</span><span class="comment">% x --Solution (full matrix)</span><span class="comment">% xs --Solution (sparse matrix)</span><span class="comment">% Define coefficients of the equation a*x = b for</span><span class="comment">% the full matrix solution.</span>a = [<span class="number">1.0</span> <span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">2.0</span> <span class="number">0.0</span> <span class="number">-1.0</span>; ...<span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">0.4</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span>; ...<span class="number">0.5</span> <span class="number">0.0</span> <span class="number">2.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">-1.0</span> <span class="number">0.0</span>; ...<span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">2.0</span> <span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">0.0</span>; ...<span class="number">0.0</span> <span class="number">0.0</span> <span class="number">1.0</span> <span class="number">1.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span>; ...<span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">0.0</span>; ...<span class="number">0.5</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span>; ...<span class="number">0.0</span> <span class="number">1.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">1.0</span>];b = [ <span class="number">3.0</span> <span class="number">2.0</span> <span class="number">-1.5</span> <span class="number">1.0</span> <span class="number">-2.0</span> <span class="number">1.0</span> <span class="number">1.0</span> <span class="number">1.0</span>]';<span class="comment">% Define coefficients of the equation a*x = b for</span><span class="comment">% the sparse matrix solution.</span>as = sparse(a);bs = sparse(b);<span class="comment">% Solve the system both ways</span><span class="built_in">disp</span> (<span class="string">'Full matrix solution:'</span>);x = a\b<span class="built_in">disp</span> (<span class="string">'Sparse matrix solution:'</span>);xs = as\bs<span class="comment">% Show workspace</span><span class="built_in">disp</span>(<span class="string">'Workspace contents after the solutions:'</span>)whos</code></pre><p>运行这个程序，结果如下</p><pre><code class="highlight plaintext">Full matrix solution:x =    0.5000    2.0000   -0.5000   -0.0000   -1.5000    1.0000    0.7500   -1.0000Sparse matrix solution:xs =   (1,1)       0.5000   (2,1)       2.0000   (3,1)      -0.5000   (5,1)      -1.5000   (6,1)       1.0000   (7,1)       0.7500   (8,1)      -1.0000Workspace contents after the solutions:  Name      Size            Bytes  Class     Attributes  a         8x8               512  double                as        8x8               392  double    sparse      b         8x1                64  double                bs        8x1               144  double    sparse      x         8x1                64  double                xs        8x1               128  double    sparse</code></pre><p>两种算法得到了相同的答案。注意用稀疏矩阵产生的结果不包含 <em>x</em>~4~，因为它的值为 0。注意 b 的稀疏形式占的内存空间比全矩阵形式还要大。这种情况是因为稀疏矩阵除了元素值之外必须存储它的行号和列号，所以当一个矩阵的大部分元素都是非零元素，用稀疏矩阵将降低运算效率。</p><h4 id="7-2-单元阵列-cell-array">7.2  单元阵列(cell array)</h4><p>单元阵列是 <strong>MATLAB</strong> 中特殊一种数组，它的元素被称为单元(cells)，它可以存储其它类型的 <strong>MATLAB</strong> 数组。例如，一个单元阵列的一个单元可能包含一个实数数组或字符型数组，还可能是复数组(图 7.1 所示)。</p><p>在一个编程项目中，一个单元阵列的每一个元素都是一个指针，指向其他的数据结构， 而这些数据结构可以是不同的数据类型。单元阵列为选择问题信息提供极好的方示，因为所有信息都聚集在一起，并可以通边一单个名字访问。单元阵列用大括号{}替代小括号来选择和显示单元的内容。这个不同是由于单元的内容用数据结构代替了内容。假设一单元阵列如图 7.2 所示。元素 a(1，1)是数据结构 3X3 的数字数组。a(1，1)的含义为显示这个单元的内容，它是一个数据结构。</p><p><img src="/medias/20200617185636534.png" alt=""></p><p><img src="/medias/20200617185722093.png" alt=""></p><pre><code class="highlight plaintext">&gt;&gt; a(1,1)ans =[3×3 double]</code></pre><p>相对地，a{1,1}的含义为显示这个数据结构的内容。</p><pre><code class="highlight plaintext">&gt;&gt; a{1,1}ans =    1 3 -7    2 0 6    0 5 1</code></pre><p>总起来说，标识 a{1,1}反映的是数据结构 a(1,1)内容，而标识 a(1,1)是一个数据结构。</p><p><strong>当你访问一单元阵列时，不要把()与{}混淆。它们完全不同的运算。</strong></p><h5 id="7-2-1-创建单元阵列">7.2.1  创建单元阵列</h5><p>创建单元阵列有两种方法:</p><ol><li><strong>用赋值语句</strong></li><li><strong>用函数 cell 创建</strong></li></ol><p>最简单的创建单元阵列的方法是直接把数据结构赋值于独立的单元，一次赋一个单元。但用 cell 函数创建将会更加地高效，所以我们用 cell 创建大的单元数组。</p><h6 id="7-2-1-1-用赋值语句创建单元阵列">7.2.1.1  用赋值语句创建单元阵列</h6><p>你可以用赋值语句把值赋于单元阵列的一个单元，一次赋一个单元。这里有两种赋值的方法，即内容索引(content indexing)和单元索引(cell indexing)。</p><p>内容索引要用到大括号{}，还有它们的下标，以及单元的内容。例如下面的语句创建了一个 2 × 2 的单元阵列，如图 7.2 所示。</p><pre><code class="highlight plaintext">a{1,1} = [1 3 -7; 2 0 6; 0 5 1];a{1,2} = 'This is a text string.';a{2,1} = [3+4*i -5; -10*i 3-4*i];a{2,2} = [];</code></pre><p>索引的这种类型定义了包含在一个单元中的数据结构的内容。</p><p>单元索引把存储于单元中的数据用大括号括起来，单元的下标用普通下标标记法。例如下面的语句将创建一个 2×2 的单元阵列，如图 7.2 所示。</p><pre><code class="highlight plaintext">a(1,1) ={[1 3 -7; 2 0 6;0 5 1]};a(1,2) = {'This is a text string.'};a(2,1) = {[3+4*i -5; -10*i 3-4*i]};a(2,2) = {[]};</code></pre><p>索引的这种类型创建了包含有指定值的一个数据结构，并把这个数据结构赋于一个单元。</p><p>这两种形式是完全等价的，你可以在你的程序任选其一。</p><p><strong>不要创建一个与已存在的数字数组重名的元阵列。如果得名了，MATLAB会认为你把单元阵列的内容赋值给一个普通的数组，这将会产生一个错误信息。在创建单元阵列之削， 确保同名的数字数字数组已经被删除。</strong></p><h6 id="7-2-1-2-用-cell-函数创建单元阵列">7.2.1.2   用 cell 函数创建单元阵列</h6><p>函数 cell 允许用户创建空单元阵列，并指定阵列的大小。例如，下面的语句创建一个 2×2 的空单元阵列。</p><pre><code class="highlight plaintext">a = cell(2, 2)</code></pre><p>一旦单元阵列被创立，你就可以用赋值语句对单元阵列进行赋值。</p><h5 id="7-2-2-单元创建者——大括号-的应用">7.2.2  单元创建者——大括号({})的应用</h5><p>如果在单个大括号中列出所有单元的内容，那么就定义了许多的单元，在一行中的独立单元用逗号分开，行与行之间用分号隔开。例如下面的语句创建一个 2×3 单元阵列。</p><pre><code class="highlight plaintext">b = {[1 2], 17, [2;4]; 3-4*i, 'Hello', eye(3)}</code></pre><h5 id="7-2-3-查看单元阵列的内容">7.2.3  查看单元阵列的内容</h5><p><strong>MATLAB</strong> 可以把单元阵列每一个元素的数据结构缩合在一行中显示出来。如果全部的数据结构没有被显示出来，那么显示就是一个总结。例如，单元阵列 a 和 b 显示如下</p><pre><code class="highlight plaintext">&gt;&gt; aa =    [3x3 double] [1x22 char]    [2x2 double] []&gt;&gt; bb =    [1x2 double] [ 17] [2x1 double]    [3.0000- 4.0000i] 'Hello' [3x3 double]</code></pre><p>注意 <strong>MATLAB</strong> 显示的只是数据结构，包括中括号和省略号，而不包含数据结构的内容。</p><p>如果你想要知道看到单元阵列的所有内容，要用到 celldisp 函数。这个函数显示的是每一个单元中的数据结构的内容。</p><pre><code class="highlight plaintext">&gt;&gt; celldisp(a)a{1,1} =    1 3 -7    2 0 6    0 5 1a{2,1} =    3.0000 + 4.0000i -5.0000    0 -10.0000i 3.0000 - 4.0000ia{1,2} =This is a text string.a{2,2} =[]</code></pre><p>如果要用高质量的图象显示数据结构的内容，要用到函数 cellplot。例如，函数 cellplot(b) 产生了一个图象，如图 7.3 所示。</p><p><img src="/medias/20200617211627074.png" alt="图 7.3 用函数 cellplot 显示单元阵列 b 数据结构的内容"></p><h5 id="7-2-4-对单元阵列进行扩展">7.2.4  对单元阵列进行扩展</h5><p>一个值赋值于一个单元阵列中的元素，如果这个元素现在不存在，那么这个元素就会被自动的建立，其他所需的元素也会被自动建立。例如，假设定义了一个 2 × 2 单元阵列，如图 7.1 所示。如果我们执行下面的语句</p><p>a{3, 3} = 5</p><p>单元阵列将会自动扩展为 3 × 3 单元阵列，如图 7.4 所示。</p><p><img src="/medias/20200617212155007.png" alt="图 7.4 把一个值赋值于 a(3,3)产生的结果。注意其他的空元素也是自动创建的"></p><h5 id="7-2-5-删除阵列中的元素">7.2.5  删除阵列中的元素</h5><p>如果要删除阵列中的所有元素，我们要用 clear 命令。如果要删除单元阵列中的部分元素，我们把空值赋值于这一部分元素。例如，假设 a 的定义如下</p><pre><code class="highlight plaintext">&gt;&gt; aa =    [3x3 double] [1x22 char] []    [2x2 double] [] []    [] [] [5]</code></pre><p>我们可以用下面的语句删除第三行</p><pre><code class="highlight plaintext">&gt;&gt; a(3,:)=[]a =    [3x3 double] [1x22 char] []    [2x2 double] [] []</code></pre><h5 id="7-2-6-单元阵列数据的应用">7.2.6  单元阵列数据的应用</h5><p>在一个单元阵列中，数据结构中数据可以随时用内容索引或单元索引调用。</p><p>例如假设单元阵列 c 的定义如下</p><pre><code class="highlight plaintext">c = {[1 2; 3 4],'dogs';'cats',i}</code></pre><p>存储于 c(1,1)的内容可由下面的语句调用</p><pre><code class="highlight plaintext">&gt;&gt; c{1,1}ans =    1 2    3 4</code></pre><p>同样 c(2,1)中的元素可由下面的元素调用</p><pre><code class="highlight plaintext">&gt;&gt; c{2,1}ans =cats</code></pre><p>一个单元内容的子集可由两套下标得到。例如，假设我们要得到单元 c(1,1)中的元素(1,2)。为了达到此目的，我们可以用表达式 c{1,1}(1,2)，它代表单元 c(1,1)中的元素(1,2)。</p><pre><code class="highlight plaintext">&gt;&gt; c{1,1}(1,2)ans =2</code></pre><h5 id="7-2-7-字符串单元阵列">7.2.7  字符串单元阵列</h5><p>在一个单元阵列中存储一批字符串与在标准的字符数组中存储相比是非常方便的，因为在单元阵列中每一个字符串的长度可以是不相同的，而在标准字符数组的每一行的长度都必须相等。这就意味着在单元阵列中的字符串没的必要增加多余的空格。许多的 <strong>MATLAB</strong> 用户图形界面函数均使用单元阵列，正是基于这个原因，我们将在第十章看到。</p><p>字符串单元阵列可以由两种方法创建。我们可以用方括号把独立的字符串插入到单元阵列，我们也可以函数 cellstr 把一个二维字符数组转化为相应的字符串单元阵列。</p><p>下面的例子用第一种方法创建了一个字符串单元阵列，并显示出这个阵列的结果。注意下面的每一个字符串具有不同的长度。</p><pre><code class="highlight plaintext">&gt;&gt; cellstring{1} = 'Stephen J. Chapman';&gt;&gt; cellstring{2} = 'Male';&gt;&gt; cellstring{3} = 'SSN 999-99-9999';&gt;&gt; cellstringcellstring ='Stephen J. Chapman' 'Male' 'SSN 999-99-9999'</code></pre><p>我们可以利用函数 cellstr 把一个二维字符数据转化为相应的字符串单元阵列。考虑下面的字符数组。</p><pre><code class="highlight plaintext">&gt;&gt; data = ['Line 1 ';'Additional Line']data =Line 1Additional Line</code></pre><p>相应的字符串单元阵列为</p><pre><code class="highlight plaintext">&gt;&gt; c = cellstr(data)c ='Line 1''Additional Line'</code></pre><p>我们还可以用 char 函数它转化回去</p><pre><code class="highlight plaintext">&gt;&gt; newdata = char(c)newdata =Line 1Additional Line</code></pre><h5 id="7-2-8-单元阵列的重要性">7.2.8  单元阵列的重要性</h5><p>单元阵列是非常灵活的，因为各种类型的大量数据可以存储在每一个单元中。所以，它经常当作中间 <strong>MATLAB</strong> 数据结构来用。我们必须理解它，因为在第十章中 <strong>MATLAB</strong> 图形用户界面要用到它的许多特性。</p><p>还有，单元阵列的灵活性可能使它们具有函数普通特性，这个函数是指带有输入参数和输出参数的变量个数的函数。一种特别的输入参数 varargin 可以在自定义函数中得到，这种函数支持输入参数的变量的个数。这个参数显在输入参数列表的最后一项，它返回一个单元阵列，所以一个输入实参可以包括任意数目的实参。每一个实参都变成了由 varagin 返回的单元阵列元素。如果它被应用，varagin 必须是函数中的最后一个输入参数。</p><p>例如，假设我们要编写一个函数，它可能需要任意个数的输入参数。这个函数执行如下所示</p><pre><code class="highlight plaintext">function test1(varargin)disp(['There are ' int2str(nargin) ' arguments.']);disp('The input arguments are:');disp(varargin);</code></pre><p>我们用不同的数目参数来执行这个函数，结果如下</p><pre><code class="highlight plaintext">&gt;&gt; test1There are 0 arguments.The input arguments are:&gt;&gt; test1(6)There are 1 arguments.The input arguments are:[6]&gt;&gt; test1(1,'test 1',[1 2,3 4])There are 3 arguments.The input arguments are:[1] 'test 1' [1x4 double]</code></pre><p>正如我们所看到的，参数变成了函数中的单元阵列元素。</p><p>下面是一个简单函数例子，这个函数拥有不同的参数数目。函数 plotline 任意数目的 1×2 行向量，每一个向量包含一个点(x,y)。函数把这些点连成线。注意这个函数也接受直线类型字符串，并把这些字符串转递给 plot 的函数。</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">plotline</span><span class="params">(varargin)</span></span><span class="comment">% PLOTLINE Plot points specified by [x,y] pairs.</span><span class="comment">% Function PLOTLINE accepts an arbitrary number of</span><span class="comment">% [x,y] points and plots a line connecting them.</span><span class="comment">% In addition, it can accept a line specification</span><span class="comment">% string, and pass that string on to function plot.</span><span class="comment">% Define variables:</span><span class="comment">% ii --Index variable</span><span class="comment">% jj --Index variable</span><span class="comment">% linespec --String defining plot characteristics</span><span class="comment">% msg --Error message</span><span class="comment">% varargin --Cell array containing input arguments</span><span class="comment">% x --x values to plot</span><span class="comment">% y --y values to plot</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========= =====================</span><span class="comment">% 10/20/98 S. J. Chapman Original code</span><span class="comment">% Check for a legal number of input arguments.</span><span class="comment">% We need at least 2 points to plot a line...</span>msg = nargchk(<span class="number">2</span>,Inf,nargin);error(msg);<span class="comment">% Initialize values</span>jj = <span class="number">0</span>;linespec = <span class="string">''</span>;<span class="comment">% Get the x and y values, making sure to save the line</span><span class="comment">% specification string, if one exists.</span><span class="keyword">for</span> ii = <span class="number">1</span>:nargin<span class="comment">% Is this argument an [x,y] pair or the line</span><span class="comment">% specification?</span><span class="keyword">if</span> ischar(varargin{ii})<span class="comment">% Save line specification</span>linespec = varargin{ii};<span class="keyword">else</span><span class="comment">% This is an [x,y] pair. Recover the values.</span>jj = jj + <span class="number">1</span>;x(jj) = varargin{ii}(<span class="number">1</span>);y(jj) = varargin{ii}(<span class="number">2</span>);<span class="keyword">end</span><span class="keyword">end</span><span class="comment">% Plot function.</span><span class="keyword">if</span> <span class="built_in">isempty</span>(linespec)<span class="built_in">plot</span>(x,y);<span class="keyword">else</span><span class="built_in">plot</span>(x,y,linespec);<span class="keyword">end</span></code></pre><p>我们用下面的参数调用这个函数，产生的图象如图 7.5 所示。用相同的数目的参数调用函数，看它产生的结果为什么？</p><p>plotline([0 0], [1 1], [2 4], [3 9], ‘k–’);</p><p>也有专门的输出参数，vargout，它支持不同数目的输出参数。这个参数显示在输出参数列表的最后一项。它返回一个单无阵列，所示单个输出实参支持任意数目的实参。每一个实参都是这个单无阵列的元素，存储在 varargout。如果它被应用，varargout 必须是输出参数列表中最后一项，在其它输入参数之后。存储在 varargout 中的变量数由函数 nargout 确定， 这个函数用指定于任何一个已知函数的输出实参。例如，我们要编写一函数，它返回任意数目的随机数。我们的函数可以用函数 nargout 指定输出函数的数目，并把这些数目存储在单元阵列 varargout 中。</p><p><img src="/medias/20200617214826075.png" alt="图 7.5 函数 plotline 产生的图象"></p><pre><code class="highlight plaintext">function [nvals, varargout] = test2(mult)% nvals is the number of random values returned% varargout contains the random values returnednvals = nargout - 1;for ii = 1:nargout-1varargout{ii} =randn * mult;end</code></pre><p>当这个函数被执行时，产生的结果如下</p><pre><code class="highlight plaintext">&gt;&gt; test2(4)ans =-1&gt;&gt; [a b c d] = test2(4)a =3b =-1.7303c =-6.6623d =0.5013</code></pre><p><strong>应用单元阵列varargin和 varargout创建函数，这个函数支持不同数目的输入或输出参数。</strong></p><h5 id="7-2-9-单元阵列函数总结">7.2.9  单元阵列函数总结</h5><p>支持单元阵列的一些普通函数总结在表 7.2 中。</p><p><strong>表 7.2 普通的单元阵列函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>cell</td><td>对单元阵列进行预定义</td></tr><tr><td>celldisp</td><td>显示出单元阵列的内容</td></tr><tr><td>cellplot</td><td>画出单元阵列的结构图</td></tr><tr><td>cellstr</td><td>把二维字符数组转化为相应的字符串单元阵列</td></tr><tr><td>char</td><td>把字符串单元阵列转化相应的字符数组</td></tr></tbody></table><h4 id="7-3-结构数组">7.3 结构数组</h4><p>一个数组是一个数据类型，这种数组类型有一个名字，但是在这个数组中的单个元素只能通过已知的数字进行访问。数组 arr 中的第五个元素可由 arr(5)访问。注意在这个数组中的所有元素都必须是同一类型(数字或字符)。一个单元阵列也是一种数据类型，也有一个名字，单个元素也只能通过已知的数字进行访问。但是这个单元阵列中元素的数据类型可以是不同的。相对地，一个<strong>结构</strong>也是一种数据类型，它的每一个元素都有一个名字。我们称结构中的元素为<strong>域</strong>。单个的域可以通过结构名和域名来访问，用句号隔开。</p><h5 id="7-3-1-创建结构">7.3.1 创建结构</h5><p>创建结构有两种方法</p><ol><li><p><strong>用赋值语句创建</strong></p></li><li><p><strong>用函数 struct 函数进行创建</strong></p></li></ol><h6 id="7-3-1-1-用赋值语句创建函数">7.3.1.1   用赋值语句创建函数</h6><p>你可以用赋值语句一次创建一个结构域。每一次把数据赋值于一个域，这个域就会被自动创建。例如用下面的语句创建如图 7.6 所示的结构。</p><pre><code class="highlight plaintext">&gt;&gt; student.name = 'John Doe';&gt;&gt; student.addr1 = '123 Main Street';&gt;&gt; student.city = 'Anytown';&gt;&gt; student.zip = '71211'student =name: 'John Doe'addr1: '123 Main Street'city: 'Anytown'zip: '71211'</code></pre><p>第二个 student 可以通过在结构名前加上一个下标的方式加入到这个结构中。</p><pre><code class="highlight plaintext">&gt;&gt; student(2).name = 'Jane Q. Public'student =1×2 struct array with fields:    name    addr1    city    zip</code></pre><p>Student 现在是一个 1×2 数据。注意当一个结构数据超一个元素，只有域名，而没有它的内容。在命令窗口中独立键入每一个元素，它的内容就会被列出。</p><pre><code class="highlight plaintext">&gt;&gt; student(1)ans =name: 'John Doe'addr1: '123 Main Street'city: 'Anytown'zip: '71211'&gt;&gt; student(2)ans =name: 'Jane Q. Public'addr1: []city: []zip: []</code></pre><p><img src="/medias/20200617215844914.png" alt="图 7.6 一个简单的例子。结构中每一个元素被称作域，每一个域都可以通过它的名字未访问"></p><p>注意无论结构的元素什么时间被定义，结构中的所有域都会被创建，不管它是否被初始化，没有被初始化的域将包含一个空数组，在后面我们可以用赋值语句来初始化这个域。</p><p>我们可以用 fieldnames 函数随时对结构中的域名进行恢复。这个函数可以返回一系列字符单元阵列中的域名，这个函数对结构数组的运算是非常有用的。</p><h6 id="7-3-1-2-用-struct-函数创建结构">7.3.1.2   用 struct 函数创建结构</h6><p>函数 struct 允许用户预分配一个结构数据。它的基本形式如下</p><pre><code class="highlight plaintext">structure_array = struct(fields)</code></pre><p>其中 fields 是填补结构域名的字符串数组或单元阵列。用上面的语法，函数 struct 用空矩阵初始化数组中的每一个域。</p><p>当域被定义时，我们就可以对它进行初始化，形式如下</p><pre><code class="highlight plaintext">str_array = struct('field1', var1, 'field2', val2, ...)</code></pre><p>其中参数为域名和它们的值。</p><h5 id="7-3-2-增加域到结构">7.3.2  增加域到结构</h5><p>如果一个新的域名在结构数组中的任意一个元素中被创建，那么这个域将会增加到数组的所有元素中去。例如，假设我们把一些成绩添加到 jane public 的记录中。</p><pre><code class="highlight plaintext">&gt;&gt; student(2).exams = [90 82 88]student =1x2 struct array with fields:    name    addr1    city    zip    exams</code></pre><p>如下所示，在数组的每一个记录中都有一个 exams 域。这个将会在 student(2)中进行初始化，其他同学的数组为空，除非用赋值语句给他赋值。</p><pre><code class="highlight plaintext">&gt;&gt; student(1)ans =    name: 'John Doe'    addr1: '123 Main Street'    city: 'Anytown'    zip: '71211'    exams: []&gt;&gt; student(2)ans =    name: 'Jane Q. Public'    addr1: []    city: []    zip: []    exams: [90 82 88]</code></pre><h5 id="7-3-3-删除结构中的域">7.3.3  删除结构中的域</h5><p>我们可以用 rmfield 函数删除结构数据中的域。这个函数的形式如下</p><pre><code class="highlight plaintext">struct2 = rmfield(struct_array, 'field')</code></pre><p>其中 struct_array 是一个结构数组，field 是要去除的域，stuct2 是得到的新结构的名字。例如从结构 student 中去除域名 zip，代码如下</p><pre><code class="highlight plaintext">&gt;&gt; stu2 = rmfield(student, 'zip')stu2 =    1x2 struct array with fields:    name    addr1    city    exams</code></pre><h5 id="7-3-4-结构数组中数组的应用">7.3.4  结构数组中数组的应用</h5><p>现在我们假设结构 sdudent 中已经有三个学生，所有数据如图 7.7 所示。我们如何应用结构数组中的数据呢？</p><p>我们可以在句号和域名后加数组元素名访问任意数组元素的信息。</p><pre><code class="highlight plaintext">&gt;&gt; student(2).addr1ans =P.O.Box 17&gt;&gt; student(3).examsans =65 84 81</code></pre><p>任何带一个域的独立条目可以在域名后加下标的方式进行访问，例如，第三个学生的第二个科目的成绩为</p><pre><code class="highlight plaintext">&gt;&gt; student(3).exams(2)ans =84</code></pre><p>结构数组中的域能作为支持这种数组类型任意函数的参数。例如，计算 student(2)的数据平均值，我们使用这个函数</p><pre><code class="highlight plaintext">&gt;&gt; mean(student(2).exams)ans =86.6667</code></pre><p>不幸是的，我们不能同时从多个元素中得到一个域的值。例如，语句 <a href="http://student.name">student.name</a> 是无意义的，并导致错误。如果我们想得到所有学生的名字，我们必须用到一个 for 循环。</p><pre><code class="highlight plaintext">for ii = 1:length(student)disp(student(ii).name);end</code></pre><p><img src="/medias/20200617221338097.png" alt="图 7.7 用三个元素组成的 student 数组和它所有的域"></p><p>相似地，如果我们想得到所有学生的平均成绩，我们不能用函数 mean(student.exams)，我们必须独立的访问学生的每一个成绩，并算出总成绩。</p><pre><code class="highlight plaintext">exam_list = [];for ii = 1:length(student)exam_list = [exam_list student(ii).exams];endmean(exam_list)</code></pre><h5 id="7-3-5-函数-getfield-和函数-setfield">7.3.5  函数 getfield 和函数 setfield</h5><p><strong>MATLAB</strong> 中有两个函数用来创建结构，这比用自定义函数创建要简单的多。函数 getfield 得到当前存储在域中的值，函数 setfield 在域中插入一新值。</p><p>getfield 函数的结构是</p><pre><code class="highlight plaintext">f = getfield(array,{array_index},'field',{field_index})</code></pre><p>field_index 和 array_index 是可选择性，array_index 用于创建 1×1 结构数组。调用这个函数的语句为</p><pre><code class="highlight plaintext">f = array(array_index).field(field_index);</code></pre><p>当编写程序时，尽管程序不知道结构数组中的域名，这个语句也可以应用。例如，假设我们需要编写一个程序，读取一未知数组并对它进行操作。函数可以通过调用 fieldnames 命令来确定一个结构数据的域名，然后通过函数 getfield 读取数据。为了读取第二个学生的 zip 码，函数为</p><pre><code class="highlight plaintext">&gt;&gt; zip = getfield(student,{2},'zip')zip =68888</code></pre><p>相似地，我们可以用 setfield 函数修改结构的值。形式如下</p><pre><code class="highlight plaintext">f = setfield(array,{array_index},'field',{field_index},value)</code></pre><p>f 是输出结构数组，field_index 和array_index 都是可选择性参数，array_index 用于创建1×1 结构数组。调用这个函数的语句为</p><pre><code class="highlight plaintext">array(array_index).field(field_index) = value;</code></pre><h5 id="7-3-6-对结构数组应用-size-函数">7.3.6  对结构数组应用 size 函数</h5><p>当 size 函数应用于结构数组时，它将返回这个结构数组的大小。当 size 函数应用于结构数组中的一个元素的域时它将返回这个域的大小。例如</p><pre><code class="highlight plaintext">&gt;&gt; size(student)ans =13&gt;&gt; size(student(1).name)ans =18</code></pre><h5 id="7-3-7-结构的嵌套">7.3.7  结构的嵌套</h5><p>结构数组的每一个域可是任意数据类型，包括单元阵列或结构数组。例如，下面的语句定义了一个新结构数组。它作为 student 的一个域，用来存储每一个学生所在班级的信息。</p><pre><code class="highlight plaintext">&gt;&gt; student(1).class(1).name = 'COSC 2021';&gt;&gt; student(1).class(2).name = 'PHYS 1001';&gt;&gt; student(1).class(1).instructor = 'Mr. Jones';&gt;&gt; student(1).class(2).instructor = 'Mrs. Smith';</code></pre><p>在这个语句被执行后，student(1)将由以下数据组成。注意访问嵌套结构中的数据方法。</p><pre><code class="highlight plaintext">&gt;&gt; student(1)ans =    name: 'John Doe'    addr1: '123 Main Street'    city: 'Anytown'    state: 'LA'    zip: '71211'    exams: [80 95 84]    class: [1x2 struct]&gt;&gt; student(1).classans =1x2 struct array with fields:nameinstructor&gt;&gt; student(1).class(1)ans =name: 'COSC 2021'instructor: 'Mr. Jones'&gt;&gt; student(1).class(2)ans =name: 'PHYS 1001'instructor: 'Mrs. Smith'&gt;&gt; student(1).class(2).nameans =PHYS 1001</code></pre><h5 id="7-3-8-struct-函数总结">7.3.8 struct 函数总结</h5><p>支持 struct 的普通函数总结在表 7.3 中。</p><p><strong>表 7.3 支持 struct 的函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>fieldnames</td><td>在一个字符串单元阵列中返回域名</td></tr><tr><td>getfield</td><td>从一个域中得到当前的值</td></tr><tr><td>rmfield</td><td>从一个结构中删除一个域</td></tr><tr><td>setfield</td><td>在一个域中设置一个新值</td></tr><tr><td>struct</td><td>预定义一个结构</td></tr></tbody></table><h4 id="7-4-总结">7.4 总结</h4><p>本章重点介绍了三类数据类型：稀疏矩阵，单元阵列和结构。</p><h5 id="7-4-1-好的编程习惯总结">7.4.1  好的编程习惯总结</h5><p>当你访问一单元阵列时，不要把()与{}混淆。它们完全不同的运算。</p><h5 id="7-4-2-MATLAB-函数命令总结">7.4.2 MATLAB 函数命令总结</h5><p><strong>普通的 MATLAB 稀疏矩阵函数</strong></p><table><thead><tr><th>类别</th><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>创建一个稀疏矩阵</td><td>speye</td><td>创建一个单位稀疏矩阵</td></tr><tr><td></td><td>sprand</td><td>创建一个稀疏矩阵，元素是符合平均分布的随机数</td></tr><tr><td></td><td>sprandn</td><td>创建一个稀疏矩阵，元素是普通的随机数</td></tr><tr><td>全矩阵和稀疏矩阵的转换函数</td><td>sparse</td><td>把一个全矩阵转化为一个稀疏矩阵</td></tr><tr><td></td><td>full</td><td>把一个稀疏矩阵转化为全矩阵</td></tr><tr><td></td><td>find</td><td>找出矩阵中非零元素和它对应的上下标</td></tr><tr><td>对稀疏矩阵进行操作的函数</td><td>nnz</td><td>非零元素的个数</td></tr><tr><td></td><td>nonzeros</td><td>返回一个向量，其中的元素为矩阵中非零元素</td></tr><tr><td></td><td>spones</td><td>用 1 代替矩阵中的非零元素</td></tr><tr><td></td><td>spalloc</td><td>一个稀疏矩阵所占的内存空间</td></tr><tr><td></td><td>issparse</td><td>如果是稀疏矩阵就返回 1</td></tr><tr><td></td><td>spfun</td><td>给矩阵中的非零元素提供函数</td></tr><tr><td></td><td>spy</td><td>用图象显示稀疏矩阵</td></tr></tbody></table><p><strong>普通的单元阵列函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>cell</td><td>对单元阵列进行预定义</td></tr><tr><td>celldisp</td><td>显示出单元阵列的内容</td></tr><tr><td>cellplot</td><td>画出单元阵列的结构图</td></tr><tr><td>cellstr</td><td>把二维字符数组转化为相应的字符串单元阵列</td></tr><tr><td>char</td><td>把字符串单元阵列转化相应的字符数组</td></tr></tbody></table><p><strong>支持 struct 的函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>fieldnames</td><td>在一个字符串单元阵列中返回域名</td></tr><tr><td>getfield</td><td>从一个域中得到当前的值</td></tr><tr><td>rmfield</td><td>从一个结构中删除一个域</td></tr><tr><td>setfield</td><td>在一个域中设置一个新值</td></tr><tr><td>struct</td><td>预定义一个结构</td></tr></tbody></table><h3 id="第八章-输入和输出函数">第八章 输入和输出函数</h3><p>在第二章中，我们已经学到如何用 load 和 save 命令加载和保存 <strong>MATLAB</strong> 数据，以及如何使用 fprintf 函数格式化输出数据。在本章中，我们将学习更多的关于 <strong>MATLAB</strong> 输入和输出的功能。首先，我们将会学习函数 textread，在 maltab5。3 中它是一个非常有用的函数。然后，我们将花更多的时间学习 load 和 save 命令。最后，我们将查看其他的 <strong>MATLAB</strong>I/O 选择。</p><p>熟悉 C 语言的读者对这部分数据将会十分的熟悉。但是，在 <strong>MATLAB</strong> 函数和 c 函数之间有细微的不同。</p><h4 id="8-1-函数-textread">8.1 函数 textread</h4><p>命令 textread 最早出现于 <strong>MATLAB</strong>5.3 中。它可以按列读取 ascii 文件中的元素，每一列中可能含有不同的数据类型。这函数读取其他程序生成的数据表时非常地有用。</p><p>这个命令的形式如下</p><pre><code class="highlight plaintext">[a, b, c, ...] = textread(filename, format, n)</code></pre><p>其中 filename 代表要打开的文件的名字，format 是用于每一行数据类型的字符串，n 代表要读取的行数(如果没有 n，则这个命令将读完这个文件)。格式化字符串与函数 fprintf 格式化描述的字符串相同。注意输出参数的个数必须与你读取的列数相区配。</p><p>例如，假设文件 test_input.dat 包含下列数据</p><pre><code class="highlight plaintext">James Jones O+ 3.51 22 YesSally Smith A+ 3.28 23 NO</code></pre><p>这些数据用下面的函数读取一系列的数组。</p><pre><code class="highlight plaintext">[first, last, blood, gpa, age, answer] = textread('test_input.dat','%s %s %s %f %d %s')</code></pre><p>当这个函数被编译时产生如下结果</p><pre><code class="highlight plaintext">&gt;&gt; [first, last, blood, gpa, age, answer] = textread('test_input.dat','%s %s %s %f %d%s')    first =        'James'        'Sally'    last =        'Jones'        'Smith'    blood =        'O+'        'A+'    gpa =        3.5100        3.2800    age =        22        23    answer =        'Yes'        'NO'</code></pre><p>这个函数可以通过在格式描述符前面加一个星号的方式来跳过某些所选项。例如，下面的语句只从文件只读取 first，last 和 gpa</p><pre><code class="highlight plaintext">&gt;&gt; [first, last, gpa] = textread('test_input.dat','%s %s %*s %f %*d %*s')first ='James' 'Sally'last ='Jones' 'Smith'gpa =    3.5100    3.2800</code></pre><p>函数 textread 要比 load 命令简单有效的多。load 命令假设输入文件中的所有数据都是同一类型 它不支持在不同的列上有不同的数据。此外，它把所有的数据都存储在一个数据中。相反地，函数 textread 允许每一列都有独立的变量，当和由不同类型的数据组成的列运算时，它更加的方便。</p><p>函数 textread 中有许许多多参数，它们增加了函数的灵活性。你可通过咨询 <strong>MATLAB</strong>的在线文本得到这些参数的使用细节。</p><p><strong>应用函数 text 从 ascii 文件中按行格式读取数据，这个 ascii 文件可能是其他语舌生成的， 或是由其他的应用程序生成的，例如表格。</strong></p><h4 id="8-2-关于-load-和-save-命令的进一步说明">8.2 关于 load 和 save 命令的进一步说明</h4><p>save 命令把 <strong>MATLAB</strong> 工作区数据存储到硬盘，load 命令把硬盘上的数据拷贝到工作区中。save 命令即可用特殊的二进制格式 mat-file 存储数据，也可用普通的 ascii 码格式存储数据。save 命令的形式为</p><pre><code class="highlight plaintext">save filename [list of variables] [options]</code></pre><p>如果只有 save 命令，那么当前工作区内的所有数据存储在一个名为 <strong>MATLAB</strong>.mat 的文件中。如果后面有一个文件名，那么这些数据将会存储在“filename.mat”的文件。如果后面还包括一系列的变量，那么就只存储这些特殊的变量。</p><p>支持 save 命令的参数如表 8.1 所示。</p><p><strong>表 8.1 save 命令的参数</strong></p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>-mat</td><td>以 mat 文件格式存储数据（默认）</td></tr><tr><td>-ascii</td><td>用 ascii 格式保存数据</td></tr><tr><td>-append</td><td>给已存在 matf 文件增加变量</td></tr><tr><td>-v4</td><td>也存储为 mat 文件格式，但能被 <strong>MATLAB</strong>4.0 读取</td></tr></tbody></table><p>load 命令可以加载 mat 文件或普通的 ascii 文件中的数据。load 命令的形式如下</p><pre><code class="highlight plaintext">load filename [option]</code></pre><p>如果只有 load 命令，<strong>MATLAB</strong> 将加载 <strong>MATLAB</strong>.mat 文件中的所有数据。如果还跟着一个文件名，它 load 命令将会加载这个文件中的数据。支持 load 命令的参数被列于表 8.1 中。</p><p>尽管它们的优点不是十分的明显，但是 save 和 load 命令是 <strong>MATLAB</strong> 中功能最强大， 最有用的 I/O 命令。它的优点是</p><ol><li><p>这些命令易于使用</p></li><li><p>mat 文件的平台独立。在一个支持 <strong>MATLAB</strong> 的计算机上编写的文件，在另一种支持 <strong>MATLAB</strong> 的计算机上，可以被读取。这种格式可以在 PC，Mac，许多不同版本的 Unix 上互相转换。</p></li><li><p>mat 文件高效的硬盘空间使用者，它存储数据是高精度的，在 mat 文件和 ascii 文件转化过程中会出现精度下降的情况</p></li><li><p>mat 文件存储了工作区内的每一个变量的所有信息，包括它的类属，名字和它是不是全局变量。在 I/O 其他类型数据存储格式中所有的这些信息都会丢失。例如，假设工作区包含下面信息。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt; whos Name Size Bytes Class    a 10x10 800 double (global)    ans 1x1 8 double     b 10x10 800 double     c 2x2 332 cell     string 1x16 32 char     student 1x3 2152 struct</code></pre><p>如果工作区用 save workspace.mat 命令存储，那么文件 workspace.mat 就会被自动创建。当这个文件被加载时，工作区中的所有信息都会被恢复，包括每一项的类型和一变量是否为全局变量。</p><p>这个命令的缺点是生成的 mat 文件只能由 <strong>MATLAB</strong> 调用，其他的程序不可能利用他共享数据。如要你想要与其他程序共享数据，可以应用-ascii 参数，但它有诸多的限制。</p><p><strong>表 8.2 load 命令参数</strong></p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>-mat</td><td>把文件当作 mat 文件看待（如果扩展名是 mat，此为默认格式）</td></tr><tr><td>-ascii</td><td>把文件当作 ascii 格式文件来看待（如果扩展名不为 mat，此为默认格式）</td></tr></tbody></table><p><strong>除非我们必须与非 MATLAB 程序进行数据交换，存储和加载文件时，都应用 mat 文件格式。这种格式是高效的且移植性强，它保存了所有 MATLAB 数据类型的细节</strong></p><p>save -ascii 根本不能存储单元阵列和结构数据，在保存字符串之前，它要把字符串转化相应的数字形式。load -ascii 命令只能加载空间独立的数据，这些数据每一行的元素个数都相等，<strong>MATLAB</strong> 把所有的数据都存储于一个变量中，这个变量与输出文件同名。如果你要用更高的要求（例如，保存和加载字符串，单元阵列或结构数组并与其它程序进行交换），那么你需要本章后面介绍的 I/O 命令。</p><p>如果我们要加载的文件名或变量名是字符串，那么我们要用这些命令的函数形式。例如， 下面的代码段要求用户提供一个文件名，并把当前工作区保存在那个文件中。</p><pre><code class="highlight plaintext">filename = input('Enter save file name: ','s'); save(filename)</code></pre><h4 id="8-3-MATLAB-文件过程简介">8.3 MATLAB 文件过程简介</h4><p>为了使用在 <strong>MATLAB</strong> 程序中的文件我们需要一些方法选出我们所要的文件，并从中读取或写入数据。在 <strong>MATLAB</strong> 中有一种非常灵活的读取/写入文件的方法，不管这个文件是在磁盘还是在磁带上或者是其他的存储介质。这种机制就叫做文件标识（file id）（有时可简写为 fid），当文件被打开，读取，写入或操作时，文件标识是赋值于一个文件的数。文件标识是一个正整数。两种文件标识是公开的 文件标识 1 是标准输出机制，文件标识 2 是标准错误机制（stderr）。其他的文件标识，在文件打开时创立，文件关闭时消逝。</p><p>许多的 <strong>MATLAB</strong> 语句可以控制磁盘文件的输入或输出。文件 I/O 函数被总结在表 8.3 中。</p><p><strong>表 8.3 MATLAB 输入/输出语句</strong></p><table><thead><tr><th>类别</th><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>加载/保存工作区</td><td>load</td><td>加载工作区</td></tr><tr><td></td><td>save</td><td>保存工作区</td></tr><tr><td>文件打开/关闭</td><td>fopen</td><td>打开文件</td></tr><tr><td></td><td>fclose</td><td>关闭文件</td></tr><tr><td>二进制 I/O</td><td>fread</td><td>从文件中读取二进制数据</td></tr><tr><td></td><td>fwrite</td><td>把二进制数据写入文件</td></tr><tr><td>格式化 I/O</td><td>fscanf</td><td>从文件中读取格式化数据</td></tr><tr><td></td><td>fprintf</td><td>把格式化数据写入文件</td></tr><tr><td></td><td>fgetl</td><td>读取文件的一行，忽略换行符</td></tr><tr><td></td><td>fgets</td><td>读取文件的一行，不忽略换行符</td></tr><tr><td>文件位置、状态</td><td>delete</td><td>删除文件</td></tr><tr><td></td><td>exist</td><td>检查文件是否存在</td></tr><tr><td></td><td>ferror</td><td>所需文件的 I/O 错误情况</td></tr><tr><td></td><td>feof</td><td>检测文件的结尾</td></tr><tr><td></td><td>fseek</td><td>设置文件的位置</td></tr><tr><td></td><td>ftell</td><td>检查文件的位置</td></tr><tr><td></td><td>frewind</td><td>回溯文件</td></tr><tr><td>临时情况</td><td>tempdir</td><td>得到临时目录名</td></tr><tr><td></td><td>tempname</td><td>得到临时文件名</td></tr></tbody></table><p>我们可以用 fopen 语句把文件标识传递给磁盘文件或设备，用 fclose 语句把他们从中分开。一旦一个文件用 fopen 语句得到一个文件标识，我们就可以利用 <strong>MATLAB</strong> 输入输出语句。当我们对这个文件操作完后，fclose 语句关闭并使文件标识无效。当文件打开时，函数 frewind 和 fseek 常用于改变当前文件读取和写入的位置。</p><p>在文件中读取或写入数据的方法有两种方法：像二进制数据或像格式化字符数据。由实际位样式组成的二进制数据常用于存储于计算机内存中。读取和编写二进制数据是非常高效的，但是用户不能读取存在于文件中的数据。在格式化文件中的可以转化为符串的数据可以由用户直接读取。格式化 I/O 操作比二进制 I/O 操作要慢得多，效率要低得多。在本章中， 我们将讨论两种类型的 I/O 的操作。</p><h4 id="8-4-文件的打开与关闭">8.4 文件的打开与关闭</h4><p>文件的打开与关闭函数，fopen 和 fclose 将在本节描述。</p><h5 id="8-4-1-fopen-函数">8.4.1 fopen 函数</h5><p>fopen 函数打开一个文件并对返回这个文件的文件标识数。它的基本形式如下：</p><pre><code class="highlight plaintext">fid = fopen(filename, permission)[fid, message] = fopen(filename, permission)[fid, message] = fopen(filename,permission, format)</code></pre><p>其中 filename 是要打开的文件的名字，premission 用于指定打开文件的模式，format 是一个参数字符串，用于指定文件中数据的数字格式。如果文件被成功打开，在这个语句执行之后，fid 将为一个正整数，message 将为一个空字符。如果文件打开失败，在这个语句执行之后，fid 将为 -1，message 将为解释错误出现的字符串。如果 <strong>MATLAB</strong> 要打开一个不为当前目录的文件，那么 <strong>MATLAB</strong> 将按 <strong>MATLAB</strong> 搜索路径搜索。</p><p>permisson 的字符串被列在表 8.4 中。</p><p>对于一些如 PC 一样的平台，它更重要的是区分文本文件和二进制文件。如果文件以文本格式打开，那么一个“t”就应加入到 permission 字符串中（例如“rt”或“rt+”）。</p><p><strong>表 8.4 fopen 文件 permissions</strong></p><table><thead><tr><th style="text-align:left">文件 permission</th><th>意义</th></tr></thead><tbody><tr><td style="text-align:left">‘r’</td><td>以只读格式读取文件</td></tr><tr><td style="text-align:left">‘r+’</td><td>可对文件进行读写</td></tr><tr><td style="text-align:left">‘w’</td><td>删除一个已存在文件的内容（或创建一个新文件），并以只写格式打开</td></tr><tr><td style="text-align:left">‘w+’</td><td>删除一个已存在文件的内容（或创建一个新文件），并以读写格式打开</td></tr><tr><td style="text-align:left">‘a’</td><td>打开一个已存在的文件（或创建一个新文件），并以只写文件格式打开把写入的内容增加到文件的结尾</td></tr><tr><td style="text-align:left">‘a+’</td><td>打开一个已存在的文件（或创建一个新文件），并以只写文件格式打开把写入的内容增加到文件的结尾</td></tr><tr><td style="text-align:left">‘W’</td><td>不进行自动洗带的写入数据（针对于磁带机的特殊命令）</td></tr><tr><td style="text-align:left">‘A’</td><td>不进行自动洗带的添加数据（针对于磁带机的特殊命令）</td></tr></tbody></table><p>如果是以二进制模式找开，那么“b”应加到 permission 字符串中（例如“rb”）。这实际上是不需要的，因为文件默认打开的方式是二进制模式。文本文件和二进制文件在 Unix 系统上是没有区别的，所以在这系统上，r 和 b 都不需要。</p><p>在 fopen 函数中的 format 字符串数据存储在文件中的格式。当在两计算机中传递互相矛盾的数据格式时，这个字符串才是必须的。一些可能的数字格式被总结在表 8.5 中。你可以从 <strong>MATLAB</strong> reference manual（参考手册）中得到所有可能的数字格式。</p><p>这个函数有两种提供信息的格式。函数</p><pre><code class="highlight plaintext">fids = fopen('all')</code></pre><p>返回一个行向量，这个行向量由当打开的所有文件的文件标识组成（除了 stdcut 和 stderr）。在这个向量中的元素的个数与所要打开的文件的个数相等。函数</p><pre><code class="highlight plaintext">[filename, permission, format] = fopen(fid)</code></pre><p>对于一指定文件标识的打开文件，返回它的名字，权限（permission）字符串和数字格式。</p><p>下面是一些正确应用 fopen 函数的例子。</p><h6 id="8-4-1-1-情况-1：为输入而打开——二进制文件">8.4.1.1   情况 1：为输入而打开——二进制文件</h6><p>下面的函数只为输入二进制数据而打开文件 example.dat。</p><pre><code class="highlight plaintext">fid = fopen('example.dat','r')</code></pre><p>权限（permission）字符串是“r”，它指出这个文件的打开方式为只读。这个字符串也可以是“rb”，但这是没有必要的，因为 <strong>MATLAB</strong> 默认打开的是二进制文件。</p><h6 id="8-4-1-2-情况-2：为文本输出打开——文件">8.4.1.2   情况 2：为文本输出打开——文件</h6><p>下面的函数以文本输出打开文件 outdat。</p><pre><code class="highlight plaintext">fid = fopen('outdat','wr')</code></pre><p>或</p><pre><code class="highlight plaintext">fid = fopen('outdat','at')</code></pre><p>权限字符串“wt”指定这个文件为新建文本文件。如果这个文件已存在，那旧文件就会被删除，打开新建的文件等待写入数据。如果我们要替换先前已存在的数据，那么就可以采用这个形式。</p><p>权限运算符“at”指定一个我们想要增加数据的文本文件。如果这个文件已经存在了， 那么它将会被打开，新的数据将会添加到已存在的数据中。如果我们不想替换已存在的数据， 那么就可以采用这个方式。</p><h6 id="8-4-1-3-以读写模式打开文件">8.4.1.3   以读写模式打开文件</h6><p>下面的函数打开文件 junk，可以对它进行二进制输入和输出。</p><pre><code class="highlight plaintext">fid = fopen('junk', 'r+')</code></pre><p>或</p><pre><code class="highlight plaintext">fid = fopen('junk', 'w+')</code></pre><p>每一个语句与第二个语句的不同为第一句打开已存在文件，而第二个语句则会删除已存在的文件。</p><p><strong>在使用fopen语句时，一定要注意指定合适的权限，这取决于你是要读取数据，还是要写入数据。好的编程习惯可以帮助你避免（类似于覆盖的）错误。</strong></p><p>在试图打开一个文件之后，检查错误是非常重要的。如果 fid 的值为-1，那么说明文件打开失败。你将把这个问题报告给用户，允许他们选择其他的文件或跳出程序。</p><p><strong>在文件打开操作后检查它的状态以确保它被成功打开。如果文件打开失败，提示用户解决方法。</strong></p><h5 id="8-4-2-fclose-函数">8.4.2 fclose 函数</h5><p>fclose 函数用于关闭一文件。它的形式为</p><pre><code class="highlight plaintext">status = fclose(fid) status = fclose('all')</code></pre><p>其中 fid 为文件标识，status 是操作结果，如果操作成功，status 为 0，如果操作失败，status 为 -1。</p><p>函数 status = fclose(‘all’)关闭了所有的文件，除了 stdout（fid = 1）和 stderr（fid = 0）。如果所有的文件关闭成功，status 将为 0，否则为-1。</p><h4 id="8-5-二进制-I-O-函数">8.5 二进制 I/O 函数</h4><p>二进制 I/O 函数，fwrite 和 fread，将在本节讨论。</p><h5 id="8-5-1-fwrite-函数">8.5.1 fwrite 函数</h5><p>函数 fwrite 以自定义格式把二进制数据写入一文件。它的形式为</p><pre><code class="highlight plaintext">count = fwrite(fid, array, precision) count = fwrite(fid, array, precision skip)</code></pre><p>其中 fid 是用于 fopen 打开的一个文件的文件标识，array 是写出变量的数组，count 是写入文件变量的数目。</p><img src="/medias/20200618104230986.png" style="zoom: 80%;"><p>参数 precision 字符串用于指定输出数据的格式。<strong>MATLAB</strong> 既支持平台独立的精度字符串，在所有的有 <strong>MATLAB</strong> 运行的电脑，它是相同的，也支持平台不独立的精度字符串，它们在不同类型的电脑上精度也不同。你应当只用平台独立的字符串，在本书中出现的字符串均为这种形式。</p><p><strong>表 8.6 MATLAB 精度字符串</strong></p><table><thead><tr><th>精度字符串</th><th>C/Fortan 形式</th><th>意义</th></tr></thead><tbody><tr><td>‘char’</td><td>‘char*1’</td><td>6 位字符</td></tr><tr><td>‘schar’</td><td>‘signed char’</td><td>8 位有符号字符</td></tr><tr><td>‘uchar’</td><td>‘unsigned char’</td><td>8 位无符号字符</td></tr><tr><td>‘int8’</td><td>‘integer*1’</td><td>8 位整数</td></tr><tr><td>‘int16’</td><td>‘integer*2’</td><td>16 位整数</td></tr><tr><td>‘int32’</td><td>‘integer*4’</td><td>32 位整数</td></tr><tr><td>‘int64’</td><td>‘integer*8’</td><td>64 位整数</td></tr><tr><td>‘uint8’</td><td>‘integer*1’</td><td>8 位无符号整数</td></tr><tr><td>‘uint16’</td><td>‘integer*2’</td><td>16 位无符号整数</td></tr><tr><td>‘uint32’</td><td>‘integer*4’</td><td>32 位无符号整数</td></tr><tr><td>‘uint64’</td><td>‘integer*8’</td><td>64 位无符号整数</td></tr><tr><td>‘float32’</td><td>‘real*4’</td><td>32 位浮点数</td></tr><tr><td>‘float64’</td><td>‘real*8’</td><td>64 位浮点数</td></tr><tr><td>‘bitN’</td><td></td><td>N 位带符号整数(1≤N≤64)</td></tr><tr><td>‘ubitN’</td><td></td><td>N 位无符号整数(1≤N≤64)</td></tr></tbody></table><p>台独立的精度显示在表 8.6 中。所有的这些精度都以字节为单位，除了“bitN”和“ubitN”，它以位为单位。</p><p>选择性参数 skip 指定在每一次写入输出文件之前要跳过的字节数。在替换有固定长度的值的时侯，这个参数将非常的有用。注意如果 precision 是一个像“bitN”或“ubitN”的一位格式，skip 则用位当作单位。</p><h5 id="8-5-2-fread-函数">8.5.2 fread 函数</h5><p>函数 fread 读取用用户自定义格式从一文件中读取二进制数据。它的格式如下</p><pre><code class="highlight plaintext">[array, count] = fread(fid, size, precision) [array, count] = fread(fid, size, precision, skip)</code></pre><p>其中 fid 是用于 fopen 打开的一个文件的文件标识，array 是包含有数据的数组，count是读取文件中变量的数目，size 是要读取文件中变量的数目。</p><p>参数 size 用于指定读取文件中变量的数目。这个参数有三种形式。</p><ol><li><p>n：准确地读取 n 个值。执行完相应的语句后，array 将是一个包含有 n 个值的列向量</p></li><li><p>Inf：读取文件中所有值。执行完相应的语句后，array 将是一个列向量，包含有从文件所有值。</p></li><li><p>[n，m] ：从文件中精确定地读取 nXm 个值。array 是一个 nXm 的数组。</p></li></ol><p>如果 fread 到达文件的结尾，而输入流没有足够的位数写满指定精度的数组元素，fread 就会用最后一位的数填充，或用 0 填充，直到得到全部的值。如果发生了错误，读取将直接到达最后一位。</p><p>参数 precision 和 size 在函数 fread 和函数 fwrite 中有相同的意义。</p><h5 id="例-8-1-读写二进制数据">例 8.1 读写二进制数据</h5><p>在本例中显示的脚本文件创建了一个含有 10000 个随机数的数组，以只写方式打开一个自定义文件，用 64 位浮点数格式把这个数据写入磁盘，并关闭文件。程序打开所要读取的文件，并读取数组，得到一个 100×100 的数组。它用来说明二进制 I/O 操作。</p><pre><code class="highlight matlab"><span class="comment">% Script file: binary_io.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% To illustrate the use of binary i/o functions.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 12/19/98 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% count -- Number of values read / written</span><span class="comment">% fid -- File id</span><span class="comment">% filename -- File name</span><span class="comment">% in_array -- Input array</span><span class="comment">% msg -- Open error message</span><span class="comment">% out_array -- Output array</span><span class="comment">% status -- Operation status</span><span class="comment">% Prompt for file name</span>filename = input(<span class="string">'Enter file name: '</span>,<span class="string">'s'</span>);<span class="comment">% Generate the data array</span>out_array = <span class="built_in">randn</span>(<span class="number">1</span>,<span class="number">10000</span>);<span class="comment">% Open the output file for writing.</span>[fid,msg] = fopen(filename,<span class="string">'w'</span>);<span class="comment">% Was the open successful?</span><span class="keyword">if</span> fid &gt; <span class="number">0</span><span class="comment">% Write the output data.</span>count = fwrite(fid,out_array,<span class="string">'float64'</span>);<span class="comment">% Tell user</span><span class="built_in">disp</span>([int2str(count) <span class="string">' values written...'</span>]);<span class="comment">% Close the file</span>status = fclose(fid);<span class="keyword">else</span><span class="comment">% Output file open failed. Display message.</span><span class="built_in">disp</span>(msg);<span class="keyword">end</span><span class="comment">% Now try to recover the data. Open the</span><span class="comment">% file for reading.</span>[fid,msg] = fopen(filename,<span class="string">'r'</span>);<span class="comment">% Was the open successful?</span><span class="keyword">if</span> fid &gt; <span class="number">0</span><span class="comment">% Read the input data.</span>[in_array, count] = fread(fid,[<span class="number">100</span> <span class="number">100</span>],<span class="string">'float64'</span>);<span class="comment">% Tell user</span><span class="built_in">disp</span>([int2str(count) <span class="string">' values read...'</span>]);<span class="comment">% Close the file</span>status = fclose(fid);<span class="keyword">else</span>    <span class="comment">% Input file open failed. Display message.</span>    <span class="built_in">disp</span>(msg);<span class="keyword">end</span></code></pre><p>当这个程序运行时，结果如下</p><pre><code class="highlight plaintext">&gt;&gt; binary_ioEnter file name: testfile10000 values written...10000 values read...</code></pre><p>在当前目录下，有一个 80000 字节的文件 testfile 被创建，这个文件之所以占 80000 个字节，是因为它含有 10000 个 64 位的值，每一个值占 8 个字节。</p><h4 id="8-6-格式化-I-O-函数">8.6 格式化 I/O 函数</h4><p>在本节中，我们向大家介绍格式化 I/O 函数。</p><h5 id="8-6-1-fprint-函数">8.6.1 fprint 函数</h5><p>函数 fprint 把以户自定义格式编写的格式化数据写入一个文件。它的形式为</p><pre><code class="highlight plaintext">count = fprintf(fid, format, val1, val2, ...) fprintf(format, val1, val2, ...)</code></pre><p>其中 fid 是我们要写入数据那个文件的文件标识，format 是控制数据显示的字符串。如果 fid 丢失，数据将写入到标准输出设备（命令窗口）。这些格式已经在第二章介绍过。</p><p>格式（format）字符串指定队列长度，小数精度，域宽和输出格式的其他方面。它包括文字数字字符（%）和字符序列（用于指定输出数据显示的精确格式）。一个典型的数据输出格式字符串图 8.1 所示。字符%总是标志着格式化字符串的开始，在字符%之后，这字符串应包括一个标识（flag），一个域宽，一个精度指定符和一个转换指定符。字符%，转换指定符一般会要求出在任何格式中，而标识，域宽，精度指定符是可选的。</p><img src="/medias/20200618120232274.png" style="zoom:67%;"><p>可能的转换指定符被列在表 8.7 中，可能的修改符（标识）被列在了表 8.8 中。如果我们用格式化字符串指定域宽和精度，那么小数点前的数就是域宽，域宽是所要显示的数所占的字符数。小数点后的数是精度，是指小数点后应保留的位数。</p><p>除了普通的字符和格式字符，还有转义字符常用在格式化字符串。这些特殊的字符被列在了表 8.9 中。</p><p><strong>表 8.7 函数 fprintf 的格式转换指定符</strong></p><table><thead><tr><th>指定符</th><th>描述</th></tr></thead><tbody><tr><td>%c</td><td>单个字符</td></tr><tr><td>%d</td><td>十进制表示（有符号的）</td></tr><tr><td>%e</td><td>科学记数法（用到小写的 e，例 3.1416e+00）</td></tr><tr><td>%E</td><td>科学记数法（用到大写的 e，例 3.1416E+00）</td></tr><tr><td>%f</td><td>固定点显示</td></tr><tr><td>%g</td><td>%e 和 %f 中的复杂形式，多余的零将会被舍去</td></tr><tr><td>%G</td><td>与 %g 类似，只不过要用到大写的 E</td></tr><tr><td>%o</td><td>八进制表示（无符号的）</td></tr><tr><td>%s</td><td>字符串</td></tr><tr><td>%u</td><td>十进制（无符号的）</td></tr><tr><td>%h</td><td>用十六进制表示（用小写字母 a-f 表示）</td></tr><tr><td>%H</td><td>用十六进制表示（用大写字母 A-F 表示）</td></tr></tbody></table><p><strong>表 8.8 格式标识（修改符）</strong></p><table><thead><tr><th>标识（修改符）</th><th>描述</th></tr></thead><tbody><tr><td>负号(-)</td><td>数据在域中左对齐，如果没有这个符号默认为右对齐</td></tr><tr><td>+</td><td>输出时数据带有正负号</td></tr><tr><td>0</td><td>如果数据的位数不够，用零填充前面的数</td></tr></tbody></table><p><strong>表 8.9 格式字符串的转义字符</strong></p><table><thead><tr><th>转义序列</th><th>描述</th></tr></thead><tbody><tr><td>\n</td><td>换行</td></tr><tr><td>\t</td><td>水平制表</td></tr><tr><td>\b</td><td>退后一格</td></tr><tr><td>\r</td><td>回车符，使屏幕光标移到当前行开关，下移到下一行</td></tr><tr><td>\f</td><td>跳页符号</td></tr><tr><td><code>\\</code></td><td>打印一个普通反斜杠</td></tr><tr><td><code>\</code>‘or’</td><td>打印一个省略号或单一引证</td></tr><tr><td>%%</td><td>打印一个百分号（%）</td></tr></tbody></table><h5 id="8-6-2-格式转换指定符的理解">8.6.2  格式转换指定符的理解</h5><p>理解大量的格式指定符最好的方法是用例子，现在我们看一些例子以及它们的结果。</p><h6 id="8-6-2-1-情况-1：显示十进制整数数据">8.6.2.1 情况 1：显示十进制整数数据</h6><p>显示十进制整数数据要用到%d 格式转换指定符。如果需要的话，d 可能出现在标识（flag），域宽和精度指定符之前。如果有用的话，精度指定符可以指定要显示的数据的最小数字个数，如果没有足够多的数字，那么 <strong>MATLAB</strong> 将在这个数之前添加 0。</p><table><thead><tr><th>函数</th><th>结果</th><th>评论</th></tr></thead><tbody><tr><td>fprintf(‘%d\n’,123)</td><td><img src="/medias/20200618141105367.png" style="zoom:80%;"></td><td>按需要字符的个数，显示这个数据。例如数 123， 需要三个字符</td></tr><tr><td>fprintf(‘%6d\n’,123)</td><td><img src="/medias/20200618141227986.png" style="zoom:50%;"></td><td>用 6 字符域宽显示数字。在这个域中的数是右对齐的</td></tr><tr><td>fprintf(‘%6.4d\n’,123)</td><td><img src="/medias/20200618141350370.png" style="zoom:50%;"></td><td>用 6 字符域宽显示数字，最少也要用 4 字符域宽。在这个域中的数是右对齐的</td></tr><tr><td>fprintf(‘%-6.4d\n’,123)</td><td><img src="/medias/20200618141436443.png" style="zoom:50%;"></td><td>用 6 字符域宽显示数字。最小也要用到 4 字符域宽， 在这个域中的数是左对齐的</td></tr><tr><td>fprintf(‘%+6.4d\n’,123)</td><td><img src="/medias/20200618141524490.png" style="zoom:50%;"></td><td>用 6 字符域宽显示数字，最少也要用到 4 字符域宽， 加上一个正/负号。在这个域中的数是右对齐的</td></tr></tbody></table><p>如果用格式指定符%d 显示一个非十进制数，这个指定符将会被忽略，这个数将会以科学计算法格式显示。例如</p><pre><code class="highlight plaintext">fprintf('%6d\n',123.4)</code></pre><p>将产生结果 1.234000e+002</p><h6 id="8-6-2-2-情况-2：显示浮点数数据">8.6.2.2 情况 2：显示浮点数数据</h6><p>浮点数数据的显示要用到 %e，%f，%g 格式转换指符。如果需要的话，这些格式转换指符可能出现在标识（flag），域宽和精度指定符之前。如果指定的域宽太小了，不能显示这个数，则这个域宽是无效的。否则，则应用指定的域宽。</p><table><thead><tr><th>函数</th><th>结果</th><th>评论</th></tr></thead><tbody><tr><td>fprintf(‘%f\n’,123.4)</td><td><img src="/medias/20200618152523057.png" style="zoom:60%;"></td><td>按需要字符的个数显示这个数据。%f 默认的格式是精确到小数点后 6 位</td></tr><tr><td>fprintf(‘%8.2f\n’,123.4)</td><td><img src="/medias/20200618152716457.png" style="zoom:60%;"></td><td>用 8 字符域宽显示这个数，其中两域宽用于显示小数。</td></tr><tr><td>fprintf(‘%4.2f\n’,123.4)</td><td><img src="/medias/20200618152808417.png" style="zoom:60%;"></td><td>用 6 字符域宽来显示这个数，指定的域宽因太小而被忽略。</td></tr><tr><td>fprintf(‘%10.2e\n’,123.4)</td><td><img src="/medias/20200618152913003.png" style="zoom:60%;"></td><td>以科学记数法显示数据，域宽为 10,小数点占 2 位。默认这个数是右对齐的</td></tr><tr><td>fprintf(‘%10.2E\n’,123.4)</td><td><img src="/medias/20200618152952450.png" style="zoom:60%;"></td><td>以科学记数法显示数据，域宽为 10,小数点占 2 位。默认这个数是右对齐的，只不过 E 为大写</td></tr></tbody></table><h6 id="8-6-2-3-情况-3：显示字符数据">8.6.2.3 情况 3：显示字符数据</h6><p>字符数据的显示要用到%e，%c 格式转换指符。如果需要的话，这些格式转换指符可能出现在标识（flag），域宽和精度指定符之前。如果指定的域宽太小了，不能显示这个数，则这个域宽是无效的。否则，则应用指定的域宽。</p><table><thead><tr><th>函数</th><th>结果</th><th>评论</th></tr></thead><tbody><tr><td>fprintf(‘%c\n’,‘s’)</td><td><img src="/medias/20200618161323603.png" style="zoom:50%;"></td><td>显示单个字符</td></tr><tr><td>fprintf(‘%s\n’,‘string’)</td><td><img src="/medias/20200618163324675.png" style="zoom:50%;"></td><td>显示一个字符串</td></tr><tr><td>fprintf(‘%8s\n’,‘string’)</td><td><img src="/medias/20200618163408764.png" style="zoom:50%;"></td><td>用 8 字符串域宽显示字符串，默认是右对齐格式</td></tr><tr><td>fprintf(‘%-8s\n’,‘string’)</td><td><img src="/medias/20200618163500719.png" style="zoom:50%;"></td><td>用 8 字符串域宽显示字符串，这个字符串是左对齐的</td></tr></tbody></table><h5 id="8-6-3-如何使用格式字符串">8.6.3 如何使用格式字符串</h5><p>函数 fprintf 包括一个格式字符串（在要打印出的 0 或更多的值之后）。当函数 fprintf 执行时，函数 fprintf 的输出参数列表将会按格式字符串的指示输出。这个函数从从变量的左端和格式字符的左端开始执行，并从左向右扫描，输出列表的第一个值与格式字符串中第一个格式输出符联合，等等。在输出参数列表中的值必须是相同的类型，格式必须与对应的格式描述符相对应，否则的话，意外的结果将会产生。例如，假设我们要用%c 或%d 描述符显示浮点数 123。4，这个描述符将会全部被忽略，这个数将会以科学记数的方式打印出来。</p><p><strong>保证fprintf 函数中的数据类型与格式字符串中的格式转换指定符的类型要一一对应， 否则将会产生意料之外的结果。</strong></p><p>程序从左向右读取函数 fprint 中的变量列表，它也从左向右读取相应的格式字符串。按照下面的规则，程序扫描格式字符串</p><ol><li>按从左向右的顺序扫描格式字符串。</li></ol><p>格式字符串中的第一个转换指定符与 fprint 函数输出参数列表中的第一个值相结合，依此类推。每一个格式转换指定符的类型与输出数据类型必须相同。在下面的例子中，指示符 %d 与变量 a 联合，%f 与变量 b 结合，%s 与变量 c 相结合。注意指定符类型必须与数据类型相匹配。</p><pre><code class="highlight plaintext">a = 10; b = pi; c = 'Hello';fprintf('Output: %d %f %s\n', a, b, c);</code></pre><ol start="2"><li>在函数 fprintf 运行完所有的变量之前，如果扫描还未到达格式字符串的结尾，程序再次从头开始扫描格式字符串。例如，语句</li></ol><pre><code class="highlight plaintext">a = [10 20 30 40];fprintf('Output = %4d %4d\n',a);</code></pre><p>将会产生输出</p><pre><code class="highlight plaintext">Output = 10 20Output = 30 40</code></pre><p>在打印完 a(2)后，函数到达格式字符串的结尾，它将会回字符串的开始打印 a(3)，a(4)</p><ol start="3"><li>如果函数 fprintf 在到达格式字符结束之前运行完所有的变量，格式字符串的应用停止在第一个格式指定符，而没有对应的变量，或者停止在格式字符串的末端。例如语句</li></ol><pre><code class="highlight plaintext">a = 10; b = 15; c = 20;fprintf('Output = %4d\nOutput = %4.1f\n', a, b, c);</code></pre><p>将产生输出</p><pre><code class="highlight plaintext">Output = 10Output = 15.0Output = 20Output = &gt;&gt;</code></pre><p>格式字符串的应停止在%4.1f，这是它第一次与格式转换指示符不匹配。从另一方面来说，语句</p><pre><code class="highlight plaintext">voltage = 20;fprintf('Voltage = %6.2f kv.\n', voltage);</code></pre><p>将产生输出</p><pre><code class="highlight plaintext">Voltage = 20.00 kv.</code></pre><p>因为它与格式转换字符串不匹配，所以格式的应用停止在格式字符串的结尾。</p><h6 id="例-8-2-产生一个信息表">例 8.2 产生一个信息表</h6><p>产生并打印一个数据表是说明函数 fprintf 函数就用的好方法。下面的脚本文件产生 1 到 10 中的所有整数的平方根，平方，立方，并在一个表中显示数据，并带有合适的表头。</p><pre><code class="highlight plaintext">% Script file: table.m%% Purpose:% To create a table of square roots, squares, and% cubes.%% Record of revisions:% Date Programmer Description of change% ==== ========== =====================% 12/20/98 S. J. Chapman Original code%% Define variables:% cube -- Cubes% ii -- Index variable% square -- Squares% square_roots -- Square roots% out -- Output array% Print the title of the table.fprintf(' Table of Square Roots, Squares, and Cubes\n\n');% Print column headingsfprintf(' Number Square Root Square Cube\n');fprintf(' ====== =========== ====== ====\n');% Generate the required dataii = 1:10;square_root = sqrt(ii);square = ii.^2;cube = ii.^3;% Create the output arrayout = [ii' square_root' square' cube'];% Print the datafor ii = 1:10fprintf (' %2d %11.4f %6d %8d\n',out(ii,:));end</code></pre><p>程序运行后，产生的结果为</p><pre><code class="highlight plaintext">&gt;&gt; tableTable of Square Roots, Squares, and CubesNumber Square Root Square Cube====== =========== ====== ====1 1.0000 1 12 1.4142 4 83 1.7321 9 274 2.0000 16 645 2.2361 25 1256 2.4495 36 2167 2.6458 49 3438 2.8284 64 5129 3.0000 81 72910 3.1623 100 1000</code></pre><h5 id="8-6-4-fscanf-函数">8.6.4 fscanf 函数</h5><p>函数 fscanf 可以从一个文件中按用户自定义格式读取格式化数据。形式如下：</p><p>array = fscanf(fid, format)</p><p>[array, count] = fscanf(fid, format, size)</p><p>其中 fid 是所要读取的文件的文件标识（fileid），format 是控制如何读取的格式字符串，</p><p>array 是接受数据的数组，输出参数 count 返回从文件读取的变量的个数。参数 size 指定从文件读取数据的数目。这个函数有以下三个类型。</p><ol><li><p>n        准确地读取 n 个值。执行完相应的语句后，array 将是一个包含有 n 个值的列向量</p></li><li><p>Inf      读取文件中所有值。执行完相应的语句后，array 将是一个列向量，包含有从文件所有值。</p></li><li><p>[n,m]    从文件中精确定地读取 n×m 个值。Array 是一个 n×m 的数组。</p></li></ol><p>格式字符串用于指定所要读取数据的格式。它由普通字符和格式转换指定符。函数fscanf 把文件中的数据与文件字符串的格式转换指定符进行对比。只要两者区配，fscanf 把值进行转换并把它存储在输出数组中。这个过程直到文件结束或读取的文件当数目达到了 size 数组才会结束，无论那一种情况先出现。</p><p>如果文件中的数据与格式转换指定符不匹配，fscanf 的操作就会突然中止。</p><p>fscanf 格式转换指定符基本上与 fprintf 的格式转换指定符相同。最普通的指定符被总结在表 8.10 中。</p><p>为了说明函数 fscanf 的应用，我们将试着读取文件 x.dat，在两行中包含下面的值。</p><pre><code class="highlight plaintext">10.00 20.0030.00 40.00</code></pre><ol><li>如果用下面的语句读取一文件</li></ol><pre><code class="highlight plaintext">[z, count] = fscanf(fid, '%f');</code></pre><p><img src="/medias/20200618170645806.png" alt=""></p><ol start="2"><li>如果用下面的语句读取一文件</li></ol><pre><code class="highlight plaintext">[z, count] = fscanf(fid, '%f', [2 2]);</code></pre><p><img src="/medias/20200618170801854.png" alt=""></p><ol start="3"><li>下一步，我们让我们从一文件中读取十进制小数数据。如果用下面的语句读取一文件</li></ol><pre><code class="highlight plaintext">[z, count] = fscanf(fid, '%d', Inf);</code></pre><p>z 为 10，count 的值为 1。这种情况的发生是因为 10.00 的小数点与格式转义指定符不匹配，函数 fscanf 函数停止在第一次出现不匹配时。</p><ol start="4"><li>如果用下面的语句读取一文件</li></ol><pre><code class="highlight plaintext">[z, count] = fscanf(fid, '%d.%d',[1 Inf]);</code></pre><p>z 为行向量[10 0 20 0 30 0 40 0]，count 的值为 8。这种情况的发生是因为小数点与格式</p><p>转义指定符匹配，小数点前后的数可以看作独立的整数。</p><ol start="5"><li>现在让我们文件中读取一个单独的字符，如果用下面的语句读取一文件</li></ol><pre><code class="highlight plaintext">[z, count] = fscanf(fid, '%c');</code></pre><p>变量 z 是一个包含文件中每一个字符的行向量，包括所有的空格和换行符!变量 count 等于文件中字符的个数。</p><ol start="6"><li>最后，让我们试着从文件中读取字符串，如果用下面的语句读取一文件</li></ol><pre><code class="highlight plaintext">[z, count] = fscanf(fid, '%s');</code></pre><p>z 是一个行向量，包括 20 个字符 10.0020.0030.0040.00，count 为 4。这种结果的产生是因为字符串指定符忽略空白字符，这个函数在这个文件中发现 4 个独立的字符串。</p><p><strong>表 8.10 fscanf 的格式转化指定符</strong></p><table><thead><tr><th>指定符</th><th>描述</th></tr></thead><tbody><tr><td>%c</td><td>读取一单个字符。这个字符读取的是任意类型的字符，包括空格，换行符</td></tr><tr><td>%Nc</td><td>读取 N 个字符</td></tr><tr><td>%d</td><td>读取一小数（忽略空格）</td></tr><tr><td>%e %f %g</td><td>读取一浮点数（忽略空格）</td></tr><tr><td>%i</td><td>读取一有符号数（忽略空格）</td></tr><tr><td>%a</td><td>读取一字符串。字符串可以被空格或其他类似于换行符的特殊符号隔开</td></tr></tbody></table><h5 id="8-6-5-fgetl-函数">8.6.5 fgetl 函数</h5><p>函数 fgetl 从一文件中把下一行（最后一行除外）当作字符串来读取。它的形式为</p><pre><code class="highlight plaintext">line = fgetl(fid)</code></pre><p>如果 fid 是我们所要读取的文件的标识（file id）。line 是接受数据的字符数组。如果函数 fgetl 遇到文件的结尾，line 的值为 -1。</p><h4 id="8-7-格式化和二进制-I-O-函数的比较">8.7 格式化和二进制 I/O 函数的比较</h4><p>格式化 I/O 数据产生格式化文件。格式化文件夹由可组织字符，数字等组成，并以 ASCII 文本格式。这类数据很容易辨认，因为当我们把在显示器上把他显示出来，或在打印机上打印出来。但是，为了应用格式化文件中的数据，<strong>MATLAB</strong> 程序必须把文件中的字符转化为计算机可以直接应用的中间数据格式。格式转换指定符为这次转换提供了指令。</p><p>格式化文件有以下优点：我们可以清楚地看到文件包括什么类型的数据。它还可以非常容易在不同类型的程序间进行转换。但是也有缺点程序必须作大量的工作，对文件中的字符串进行转换，转换成相应的计算机可以直接应用的中间数据格式。如果我们读取数据到其他的 <strong>MATLAB</strong> 程序，所有的这些工作都会造成效率浪费。而且一个数的计算机可以直接应用的中间数据格式要比格式化文件中的数据要大得多。例如，一个 64 位浮点数的中间数据格</p><p>式需要 8 个字节的内存。而格式化文件中的字符串表达形为士d.ddddddddddddddEee，它将需要 21 个字节。所以用字符格式存储数据是低效的且浪费磁盘空间。</p><p><strong>无格式文件</strong>（<strong>二进制文件</strong>）克服上面的缺点，它其中的数据无需转化，就可以把内存中 的数据写入磁盘。因为没有转化发生，计算机就没有时间浪费在格式化数据上。在 <strong>MATLAB</strong> 中，二进制 I/O 操作要比格式化 I/O 操作快得多，因为它中间没有转化。进一步说，数据占用的磁盘空间将更小。从另一方面来说，无格式的数据不能进行人工检查和人工翻译。还有， 它不能移植到不同类型的计算机，因为不同类型的计算机有不同中间过程来表示整数或浮点 数。</p><p>表 8.11 显示了格式化文件与无格式化文件的区别。在一般情况下，格式化文件，对于那些必须进行人工检查的数据，或对于那些必须在不同的计算机上运行的数据，是最好的选择。对于那些不需要进行人工检查的数据且在相同类型的计算机创建并运行的数据，存储最好用无格式文件。在这些环境下，无格式文件运算要快得多，占用的磁盘空间更小。</p><p><strong>对于那些必须进行人工检查的数据，或对于那些必须在不同的计算机上运行的数据，用格式化文件创建数据。对于那些不需要进行人工检查的数据且在相同类型的计算机创建并运行的数据，用无格式文件创建数据，当 I/O 速度缓慢时，用格式化文件创建数组。</strong></p><p><strong>表 8.11 格式化文件和无格式化文件的比较</strong></p><table><thead><tr><th>格式化文件</th><th>无格式化文件</th></tr></thead><tbody><tr><td>能在输出设备显示数据</td><td>不能在输出设备显示数据</td></tr><tr><td>能在不同的计算机上很容易地进行移植</td><td>不能在不同的计算机上很容易地进行移植</td></tr><tr><td>相对地，需要大量的磁盘空间</td><td>相对地，需要较少的磁盘空间</td></tr><tr><td>慢：需要大量的计算时间</td><td>慢：需要大量的计算时间</td></tr><tr><td>在进行格式化的过程中，产生截断误差或四舍五入错误</td><td>不会产生截断误差或四舍五入错误</td></tr></tbody></table><h5 id="例-8-3-格式化和二进制-I-O-文件的比较">例 8.3 格式化和二进制 I/O 文件的比较</h5><p>在这个例子中的程序比较了用格式化和二进制I/O 操作读写一个含 10000 个元素数组所花的时间。注意每一个操作运行 10 次求平均值。</p><pre><code class="highlight plaintext">% Script file: compare.m%% Purpose:% To compare binary and formatted I/O operations.% This program generates an array of 10,000 random% values and writes it to disk both as a binary and% as a formatted file.%% Record of revisions:% Date Programmer Description of change% ==== ========== =====================% 12/19/98 S. J. Chapman Original code%% Define variables:% count -- Number of values read / written% fid -- File id% in_array -- Input array% msg -- Open error message% out_array -- Output array% status -- Operation status% time -- Elapsed time in seconds%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Generate the data array.%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%out_array = randn(1,10000);%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% First, time the binary output operation.%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Reset timertic;% Loop for 10 timesfor ii = 1:10% Open the binary output file for writing.[fid,msg] = fopen('unformatted.dat','w');% Write the datacount = fwrite(fid,out_array,'float64');% Close the filestatus = fclose(fid);end% Get the average timetime = toc / 10;fprintf ('Write time for unformatted file = %6.3f\n',time);%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Next, time the formatted output operation.%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Reset timertic;% Loop for 10 timesfor ii = 1:10% Open the formatted output file for writing.[fid,msg] = fopen('formatted.dat','wt');% Write the datacount = fprintf(fid,'%23.15e\n',out_array);% Close the filestatus = fclose(fid);end% Get the average timetime = toc / 10;fprintf ('Write time for formatted file = %6.3f\n',time);%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Time the binary input operation.%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Reset timertic;% Loop for 10 timesfor ii = 1:10% Open the binary file for reading.[fid,msg] = fopen('unformatted.dat','r');% Read the data[in_array, count] = fread(fid,Inf,'float64');% Close the filestatus = fclose(fid);end% Get the average timetime = toc / 10;fprintf ('Read time for unformatted file = %6.3f\n',time);%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Time the formatted input operation.%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Reset timertic;% Loop for 10 timesfor ii = 1:10% Open the formatted file for reading.[fid,msg] = fopen('formatted.dat','rt');% Read the data[in_array, count] = fscanf(fid,'%f',Inf);% Close the filestatus = fclose(fid);end% Get the average timetime = toc / 10;fprintf ('Read time for formatted file = %6.3f\n',time)</code></pre><p>当程序在酷睿i5-10210U 1.6GHz 机器上运行，操作系统为 windows10家庭版，得到的结果为</p><pre><code class="highlight plaintext">Write time for unformatted file =  0.022Write time for formatted file =  0.026Read time for unformatted file =  0.004Read time for formatted file =  0.046</code></pre><p>写入磁盘的文件如下所示：</p><pre><code class="highlight plaintext">&gt;&gt; dir.                logical1.m       seed.m           ..               lsqfit.m         stats_3.m        ball.m           plotline.m       test_break.m     calc_roots.m     polar2rect.m     test_dist2.m     compare.m        polar_value.m    timings.m        dist2.m          quickplot.m      unformatted.dat  doy.m            random0.m        formatted.dat    rect2polar.m</code></pre><p>注意写入格式化文件数据所需的时间是无格式文件的 60 倍，记取时间是无格式文件的 75 倍。还有格式化文件的大小是无格式文件的 3 倍。得到的结果是非常清楚的，除非你真得需要格式化数据，否则二进制 I/O 操作是 <strong>MATLAB</strong> 中存储数据的一个非常好的方法。</p><h4 id="8-8-文件位置和状态函数">8.8 文件位置和状态函数</h4><p>正如我们前面所陈述的，<strong>MATLAB</strong> 文件是连续的 它们从第一条记录开始一直读到最后一条记录。但是，有时在一个程序中，我们需要多次调用一段数据或整个文件。在一个连续文件中，我们如何跳过无用的数据呢？</p><p>在打开文件之前，<strong>MATLAB</strong> 函数 exist 用于判断这个文件是否存在。一旦一个文件打开，我们就可以用函数 feof 和 ftell 判断当前数据在文件中的位置。还用两个函数帮助我们在文件中移动：frewind 和 fseek。</p><p>最后，当程序发生 I/O 错误时，<strong>MATLAB</strong> 函数 ferror 将会对这个错误进行详尽的描述。我们现在将向大家详细的介绍这 6 个函数，我们先看一下 ferror，因为它可以应用其他的函数中。</p><h5 id="8-8-1-exist-函数">8.8.1 exist 函数</h5><p>exist 函数用来检测工作区中的变量，内建函数或<strong>MATLAB</strong> 搜索路径中的文件是否存在。它的形式如下</p><pre><code class="highlight plaintext">ident = exist('item');ident = exist('item', 'kind');</code></pre><p>如果“item”存在，函数就根据它的类型返回一个值。可能的结果被显示在表 8.12 中。</p><p>函数 exist 指定所要搜索的条目（item）的类型。它的合法类型为“var”，“file”，“builtin”和“dir”。</p><p>函数 exist 是非常重要的，因为我们可以利用它判断一个文件否存在。当文件被打开时，fopen 函数中权限运算符“w”和“w+”会删除文件已有的一个文件。在程序员允许 fopen 函数删除一个文件时，它必须征得用户的同意。</p><p><strong>表 8.12 由函数 exist 的返回值</strong></p><table><thead><tr><th>值</th><th>意义</th></tr></thead><tbody><tr><td>0</td><td>没有发现条目</td></tr><tr><td>1</td><td>条目为当前工作区的一个变量</td></tr><tr><td>2</td><td>条目为 m 文件或未知类型的文件</td></tr><tr><td>3</td><td>条目是一个 MEX 文件</td></tr><tr><td>4</td><td>条目是一个 MDL 文件</td></tr><tr><td>5</td><td>条目是一个内建函数</td></tr><tr><td>6</td><td>条目是一个 p 代码文件</td></tr><tr><td>7</td><td>条目是一个目录</td></tr></tbody></table><h6 id="例-8-4-打开一个输出文件">例 8.4 打开一个输出文件</h6><p>这个程序从用户那里得到输出文件名，并检查它是否存在。如果存在，就询问用户是要把用新数据覆盖这个文件，还是要把新的数据添加到这个文件中。如果这个文件不存在，那么这个程序就会很容易地打开输出文件。</p><pre><code class="highlight plaintext">% Script file: output.m%% Purpose:% To demonstrate opening an output file properly.% This program checks for the existence of an output% file. If it exists, the program checks to see if% the old file should be deleted, or if the new data% should be appended to the old file.%% Record of revisions:% Date Programmer Description of change% ==== ========== =====================% 11/29/98 S. J. Chapman Original code%% Define variables:% fid -- File id% out_filename -- Output file name% yn -- Yes/No response% Get the output file name.out_filename = input('Enter output filename: ','s');% Check to see if the file exists.if exist(out_filename,'file')% The file existsdisp('Output file already exists.');yn = input('Keep existing file? (y/n) ','s');if yn == 'n'fid = fopen(out_filename,'wt');elsefid = fopen(out_filename,'at');endelse% File doesn't existfid = fopen(out_filename,'wt');end% Output datafprintf(fid,'%s\n',date);% Close filefclose(fid);</code></pre><p>当这个程序执行后，产生的结果为</p><pre><code class="highlight plaintext">&gt;&gt; outputEnter output filename: xxx&gt;&gt; type xxx17-Jan-2008&gt;&gt; outputEnter output filename: xxxOutput file already exists.Keep existing file? (y/n) y&gt;&gt; type xxx17-Jan-200817-Jan-2008&gt;&gt; outputEnter output filename: xxxOutput file already exists.Keep existing file? (y/n) n&gt;&gt; type xxx17-Jan-2008</code></pre><p>三种不同的情况均产生了正确的结果。</p><p><strong>未经用户同意，不要用新数据覆盖原用的文件。</strong></p><h5 id="8-8-2-函数-ferror">8.8.2  函数 ferror</h5><p>在 <strong>MATLAB</strong> 的 I/O 系统中有许多的中间数据变量，包括一些专门提示与每一个打开文件相关的错误的变量。每进行一次 I/O 操作，这些错误提示就会被更新一次。函数 ferror 得到这些错误提示变量，并把它转化为易于理解的字符信息。</p><pre><code class="highlight plaintext">message = ferror(fid) message = ferror(fid, 'clear')[message, errnum] = ferror(fid)</code></pre><p>这个函数会返回与 fid 相对应文件的大部分错误信息。它能在 I/O 操作进行后，随时被调用，用来得到错误的详细描述。如果这个文件被成功调用，产生的信息为“…”，错误数为 0。</p><p>对于特殊的文件标识，参数“clear”用于清除错误提示。</p><h5 id="8-8-3-函数-foef">8.8.3  函数 foef</h5><p>函数 feof 用于检测当前文件的位置是否是文件的结尾。它的形式如下</p><pre><code class="highlight plaintext">eofstat = feof(fid)</code></pre><p>如果是文件的结尾，那么函数返回 1，否则返回 0。</p><h5 id="8-8-4-函数-ftell">8.8.4  函数 ftell</h5><p>函数 ftell 返回 fid 对应的文件指针读/写的位置。这个位置是一个非负整数，以 byte 为单位，从文件的开头开始计数。返回值-1 代表位置询问不成功。如果这种情况发生了，我们利用 ferror 得知为什么询问不成功。函数的形式如下：</p><pre><code class="highlight plaintext">position = ftell(fid)</code></pre><h5 id="8-8-5-函数-frewind">8.8.5  函数 frewind</h5><p>函数 frewind 允许程序把文件指针复位到文件的开头，形式如下</p><pre><code class="highlight plaintext">frewind(fid)</code></pre><p>这个函数不返回任何状态信息。</p><h5 id="8-8-6-函数-fseek">8.8.6  函数 fseek</h5><p>函数 fseek 允许程序把文件指针指向文件中任意的一个位置。函数形式如</p><pre><code class="highlight plaintext">status = fseek(fid, offset, origin)</code></pre><p>函数用 offsett 和 origin 来重设 fid 对应文件的文件指针。offset 以字节为单位，带有一个正数，用于指向文件的结尾，带有一个负数，用于指向文件的开头。origin 是一个字符串， 取值为下面三个中的一个。</p><ol><li><p>“bof” 文件的开始位置</p></li><li><p>“cof” 指针中的当前位置</p></li><li><p>“eof” 文件的结束位置</p></li></ol><p>如果这个操作成功，status 的值为 0，如果操作失败 status 为-1。如果 status 为-1，用函数 ferror 判断错误出现在那里。</p><p>举一个例子，用于说明 fseek 和 ferror 的联合应用，考虑下面的语句。</p><pre><code class="highlight plaintext">[fid, msg] = fopen('x', 'r'); status = fseek(fid, -10, 'bof'); if status ~= 0msg = ferror(fid); disp(msg);end</code></pre><p>这些命令打开了一个文件，并把文件指针设置在文件开始之前的 10 个字节上面。这是不可能，所以 fseek 将会返回一个-1，用 ferror 得到对应的错误信息。当这些语句被编译时， 产生下面的错误信息。</p><pre><code class="highlight plaintext">Offset is bad - before beginning-of-file.</code></pre><h6 id="例-8-5-最小二乘法拟合直线">例 8.5 最小二乘法拟合直线</h6><p><img src="/medias/20200618212424449.png" alt=""></p><p><img src="/medias/20200618212836024.png" alt=""></p><ol><li>陈述问题</li></ol><p>用最小二乘法计算直线的截距 <em>b</em> 和斜率 <em>m</em>，输入值任意数目的（<em>x</em>，<em>y</em>）坐标对。输入值（<em>x</em>，<em>y</em>）被存储在用户自定义输入文件中。</p><ol start="2"><li>定义输入输出值</li></ol><p>程序所需的输入值是（<em>x</em>，<em>y</em>）坐标对，<em>x</em>，<em>y</em> 均为实数，每一个点都存储在磁盘文件独立的行中，输出是用最小二乘法计算出的直线的截距 <em>b</em> 和斜率 <em>m</em>。</p><ol start="3"><li>算法描述</li></ol><p>本程序可以分为以下四大步骤</p><pre><code class="highlight plaintext">Get the name of the input file and open it Accumulate the input statisticsCalculate the slope and intercept Write out the slope and intercept</code></pre><p><img src="/medias/20200618213316806.png" alt=""></p><pre><code class="highlight plaintext">Initialize n, sum_x, sum_x2, sum_y, and sum_xy to 0Prompt user for input file nameOpen file 'filename'Check for error on openif no errorREAD x, y from file 'filename'while not at end-of-filen ← n + 1sum_x ← sum_x + xsum_y ← sum_y + ysum_x2 ← sum_x2 + x^2sum_xy ← sum_xy + x*yREAD x, y from file 'filename'end(further processing)end</code></pre><p>下一步我们要用最小二乘法计算直线的截距 <em>b</em> 和斜率 <em>m</em>。我们可以根据公式（8.2）（8.3）得到。</p><pre><code class="highlight plaintext">x_bar ← sum_x / ny_bar ← sum_y / nslop ← (sum_xy - sum_x*y_bar) / (sum_x2 - sum_x*x_bar)y_int ← y_bar - slop * x_bar</code></pre><p>最后，我们要写出结果。</p><pre><code class="highlight plaintext">Write out slope 'slope' and intercept 'y_int'.</code></pre><ol start="4"><li>转化为 <strong>MATLAB</strong> 语言</li></ol><pre><code class="highlight plaintext">% Script file: lsqfit.m%% Purpose:% To perform a least-squares fit of an input data set% to a straight line, and print out the resulting slope% and intercept values. The input data for this fit% comes from a user-specified input data file.%% Record of revisions:% Date Programmer Description of change% ==== ========== =====================% 12/20/98 S. J. Chapman Original code%% Define variables:% count -- number of values read% filename -- Input file name% fid -- File id% msg -- Open error message% n -- Number of input data pairs (x,y)% slope -- Slope of the line% sum_x -- Sum of all input X values% sum_x2 -- Sum of all input X values squared% sum_xy -- Sum of all input X*Y values% sum_y -- Sum of all input Y values% x -- An input X value% x_bar -- Average X value% y -- An input Y value% y_bar -- Average Y value% y_int -- Y-axis intercept of the line% Initialize sumsn = 0; sum_x = 0; sum_y = 0; sum_x2 = 0; sum_xy = 0;% Prompt user and get the name of the input file.disp('This program performs a least-squares fit of an');disp('input data set to a straight line. Enter the name');disp('of the file containing the input (x,y) pairs: ' );filename = input(' ','s');% Open the input file[fid,msg] = fopen(filename,'rt');% Check to see if the open failed.if fid &lt; 0% There was an error--tell user.disp(msg);else% File opened successfully. Read the (x,y) pairs from% the input file. Get first (x,y) pair before the% loop starts.[in,count] = fscanf(fid,'%g %g',2);while ~feof(fid)x = in(1);y = in(2);n = n + 1; %        sum_x = sum_x + x; % Calculate        sum_y = sum_y + y; % statistics        sum_x2 = sum_x2 + x.^2; %        sum_xy = sum_xy + x * y; %        % Get next (x,y) pair        [in,count] = fscanf(fid,'%f',[1 2]);end    % Now calculate the slope and intercept.    x_bar = sum_x / n;    y_bar = sum_y / n;    slope = (sum_xy - sum_x*y_bar) / (sum_x2 - sum_x*x_bar);    y_int = y_bar - slope * x_bar;    % Tell user.    fprintf('Regression coefficients for the least-squares line:\n');    fprintf(' Slope (m) = %12.3f\n',slope);    fprintf(' Intercept (b) = %12.3f\n',y_int);    fprintf(' No of points = %12d\n',n);end</code></pre><ol start="5"><li>检测程序</li></ol><p>为了检测这个程序，我们可以用一些简单的数据集合进行检测。例如，如果输入数据所对应的点都在同一条直线，那么产生的斜率和截距必定是那条直线的斜率和截距。这组数据为</p><p>1.1  1.1</p><p>2.2  2.2</p><p>3.3  3.3</p><p>4.4  4.4</p><p>5.5  5.5</p><p>6.6  6.6</p><p>7.7  7.7</p><p>它的斜率和截距分别为 1.0 和 0.0。我们把这些值写入 input1 文件，运行这个程序，结果如下:</p><pre><code class="highlight plaintext">&gt;&gt; lsqfitThis program performs a least-squares fit of aninput data set to a straight line. Enter the nameof the file containing the input (x,y) pairs:input1.txtRegression coefficients for the least-squares line:Slope (m) = 1.000Intercept (b) = 0.000No of points = 7</code></pre><p>我们在这些测量值上加入一些噪声，数据变为</p><p>1.1 1.01</p><p>2.2 2.30</p><p>3.3 3.05</p><p>4.4 4.28</p><p>5.5 5.75</p><p>6.6 6.48</p><p>7.7 7.84</p><p>如果把这些值写入 input2 文件，运行程序，结果如下</p><pre><code class="highlight plaintext">&gt;&gt; lsqfitThis program performs a least-squares fit of aninput data set to a straight line. Enter the nameof the file containing the input (x,y) pairs:input2.txtRegression coefficients for the least-squares line:Slope (m) = 1.024Intercept (b) = -0.120No of points = 7</code></pre><p>我们用手动计算很容易就能得到上面两个程序的正确结果。第二个程序图象如图 8.2 所示。</p><p><img src="/medias/20200615173633801.png" alt="图 8.2"></p><h4 id="8-9-函数-uiimport">8.9 函数 uiimport</h4><p>函数是一种基于 GUI 的方法从一个文件或从剪贴板中获取数据。这个命令的形式如下</p><p>uiimport</p><p>structure = uiimport;</p><p>在第一种情况下，获取的数据可以直接插入当前的工作区。在第二种情况下，数据可以转化为一个结构数组。并保存在变量 structure 中。</p><p><img src="/medias/20200618220853655.png" alt="(a)"></p><p><img src="/medias/20200618220937660.png" alt="(b)"></p><p><img src="/medias/20200618221014799.png" alt="(c)"></p><p><strong>图 8.5 uiimport 的应用(a)导入向导 (b)选择一个数据文件后，创建一个或多个数组，它的内容可以被检测。©一旦一个文件被加载后，用户可以选择哪些数组要导入到 MATLAB中</strong></p><p>当我们在命令窗口中键入命令 uiimport，importwizard 将会以窗口的形式显示出来。用户可以选择获取数据的文件或剪贴板。它支持许多的不同格式，它可以读取任意应用程序保存在剪贴板是的数据。当你想要把数据导入 <strong>MATLAB</strong> 并对其进行分析时，它的灵活性将会非常地有用。</p><h4 id="8-10-总结">8.10 总结</h4><h5 id="8-10-1-好的编程习惯总结">8.10.1   好的编程习惯总结</h5><ol><li><p>除非我们必须与非 <strong>MATLAB</strong> 程序进行数据交换，存储和加载文件时，都应用 mat 文件格式。这种格式是高效的且移植性强，它保存了所有 <strong>MATLAB</strong> 数据类型的细节。</p></li><li><p>在使用 fopen 语句时，一定要注意指定合适的权限，这取决于你是要读取数据，还是要写入数据。好的编程习惯可以帮助你避免（类似于覆盖的）错误。</p></li><li><p>在文件打开操作后检查它的状态以确保它被成功打开。如果文件打开失败，提示用户解决方法。</p></li><li><p>对于那些必须进行人工检查的数据，或对于那些必须在不同的计算机上运行的数据， 用格式化文件创建数据。对于那些不需要进行人工检查的数据且在相同类型的计算机创建并运行的数据，用无格式文件创建数据，当 I/O 速度缓慢时，用格式化文件创建数组。</p></li><li><p>未经用户同意，不要用新数据覆盖原用的文件。</p></li></ol><h5 id="8-10-2-MATLAB-总结">8.10.2  MATLAB 总结</h5><p>函数与命令</p><p><strong>MATLAB 输入/输出语句</strong></p><table><thead><tr><th>类别</th><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>加载/保存工作区</td><td>load</td><td>加载工作区</td></tr><tr><td></td><td>save</td><td>保存工作区</td></tr><tr><td>文件打开/关闭</td><td>fopen</td><td>打开文件</td></tr><tr><td></td><td>fclose</td><td>关闭文件</td></tr><tr><td>二进制 I/O</td><td>fread</td><td>从文件中读取二进制数据</td></tr><tr><td></td><td>fwrite</td><td>把二进制数据写入文件</td></tr><tr><td>格式化 I/O</td><td>fscanf</td><td>从文件中读取格式化数据</td></tr><tr><td></td><td>fprintf</td><td>把格式化数据写入文件</td></tr><tr><td></td><td>fgetl</td><td>读取文件的一行，忽略换行符</td></tr><tr><td></td><td>fgets</td><td>读取文件的一行，不忽略换行符</td></tr><tr><td>文件位置、状态</td><td>delete</td><td>删除文件</td></tr><tr><td></td><td>exist</td><td>检查文件是否存在</td></tr><tr><td></td><td>ferror</td><td>所需文件的 I/O 错误情况</td></tr><tr><td></td><td>feof</td><td>检测文件的结尾</td></tr><tr><td></td><td>fseek</td><td>设置文件的位置</td></tr><tr><td></td><td>ftell</td><td>检查文件的位置</td></tr><tr><td>临时情况</td><td>frewind</td><td>回溯文件</td></tr><tr><td></td><td>tempdir</td><td>得到临时目录名</td></tr><tr><td></td><td>tempname</td><td>得到临时文件名</td></tr></tbody></table><h3 id="第九章-句柄图形">第九章 句柄图形</h3><p>句柄图形是对底层图形函数集合的总称，它实际上进行生成图形的工作。这些函数一般隐藏于 M 文件内部，但是它们非常地重要，因为程序员可以利用它对图象或图片的外观进行控制。例如，我们可以利用句柄图形只对 x 轴产生网格线，或选择曲线的颜色为枯黄色， 枯黄色 plot 命令中的标准 LineSpec 参数。还有，句柄图形可以帮助程序员为他们的程序创建用户图形界面，用户图形界面，我们将在下一章介绍。</p><p>在本章中，我们向大家介绍 <strong>MATLAB</strong> 图形系统的结构，以及如何控制图形对象的属性。</p><h4 id="9-1-MATLAB-图形系统">9.1 MATLAB 图形系统</h4><p><strong>MATLAB</strong> 图形系统是建立图形对象的等级系统之上，每一个图形对象都有一个独立的名字，这个名字叫做句柄。每一个图形对象都有它的属性，我们可以通过修改它的属性来修改物体的行为。例如，一条曲线是图形对象的一种。曲线对象有以下的属性:x 数据，y 数据， 颜色，线的类型，线宽，符号类型等等。修改其中的一个属性就会改变图象窗口中的一个图象。</p><p>由图形命令产生的每一件东西部是图形对象。例如，图形中的每一个曲线，坐标轴和字符串是独立的对象(拥有独立的名字句柄，还有形式)。所有的图象对象按<strong>子对象</strong>和<strong>父对象</strong>的形式管理，如图 9.1 所示。当一个子对象被创建时，它可能继承了父对象的许多属性。</p><p><img src="/medias/20200618222616876.png" alt="图 9.1 对象的层次结构"></p><p>在 <strong>MATLAB</strong> 中最高层次的图形对象被根对象，我们可以通过它对整个计算机屏幕进行控制。当 <strong>MATLAB</strong> 启动时，根对象会被自动创建，它一直存在到 <strong>MATLAB</strong> 关闭。与根对象相关的属性是应用于所用 <strong>MATLAB</strong> 窗口的默认属性。</p><p>在根对象下，有多个图象窗口，或只有图象。每一个图象在用于显示图象数据的计算机屏幕上都有一个独立的窗口，每一个图象都有它独立的属性。与图象相关的属性有，颜色， 图片底色，纸张大小，纸张排列方向，指针类型等。</p><p>每一个图形可包括四个对象:Uimenu 对象，Uicontrol 对象，坐标系对象和 Uicontextmenus对象。Uimenu 对象，Uicontrol 对象，和 Uicontextmenus 对象是专门地用来创建用户图形界面的对象，它们将在下一章讨论。坐标系对象是指在用于显示图象的图片中的区域。在一个图象窗口中，它可能含有一个或多个坐标系。</p><p>每一个坐标系对象可能包括曲线对象，文本对象，贴片对象，还有其他的你所需的图形对象。</p><h4 id="9-2-对象句柄">9.2 对象句柄</h4><p>每一个图象对象都有一个独一无二的名字，这个名字叫做句柄。句柄是在 <strong>MATLAB</strong> 中的一个独一无二的整数或实数，用于指定对象的身份。用于创建一个图象对象的任意命令都会自动地返回一个句柄。例如，命令</p><pre><code class="highlight plaintext">&gt;&gt;Hnd1 = figure;</code></pre><p>创建一个新的图象，并返回这个图象的句柄到变量 Hnd1。根对象句柄一般为 0，图象(图)对象的句柄一般是一个小的正整数，例如 1，2，3……而其他的图形(graphic)对象为任意的浮点数。</p><p>我们可以利用 <strong>MATLAB</strong> 函数得到图象，坐标系和其他对象的句柄。例如，函数 gcf 返回当前图象窗口的句柄，而函数 gca 则返回在当前图象窗口中的当前坐标系对象的句柄，函数 gco 返回当前选择对象的句柄。这些函数将会在后面将会被具体讨论。</p><p>为了方便，存储句柄的变量名要在小写字母后面个 H。这样就可以与普通变量(所有的小写变量，大写变量，全局变量)区分开来。</p><h4 id="9-3-对象属性的检测和更改">9.3 对象属性的检测和更改</h4><p>对象属性是一些特殊值，它可以控制对象行为的某些方面。每一个属性都有一个属性名和属性值。属性名是用大小写混合格式写成的字符串，属性名中的每一个单词的第一个字母为大写，但是 <strong>MATLAB</strong> 中的变量名的大小不与区分。</p><h5 id="9-3-1-在创建对象时改变对象的属性">9.3.1 在创建对象时改变对象的属性</h5><p>当一个对象被创建时，所有的属性都会自动初始化为默认值。包含有"propertyname(属性名)"的创建函数创建对象时，默认值会被跳过，而跳过的值在创建函数中有。例如，我们在第二章看到，线宽属性可以通过下面的 plot 命令改变。</p><pre><code class="highlight plaintext">plot(x, y, 'LineWidth', 2);</code></pre><p>录一个曲线被创建时，函数用值 2 来替代它的默认值。</p><h5 id="9-3-2-对象创建后改变对象的属性">9.3.2  对象创建后改变对象的属性</h5><p>我们可以用随时用 get 函数检测任意一个对象的属性，并用 set 函数对它进行修改。get 函数最常见的形式如下：</p><pre><code class="highlight plaintext">value = get(handle, 'PropertyName'); value = get(handle);</code></pre><p>value 是勤句柄指定对象的属性值。如果在调用函数时，只有一个句柄，那么函数将会返回一个结构，域名为这个对象的属性名，域值为属性值。</p><p>set 函数的最常用形式为</p><pre><code class="highlight plaintext">set(handle,'PropertyName1', value1, ...);</code></pre><p>在一个单个的函数中可能有多个**“<strong>propertyname</strong>"<strong>和</strong>"<strong>value</strong>”**。</p><p>例如，假设我们用下面的语句，画出函数 y(x)= x^2^ 在(0，2)中的图象</p><pre><code class="highlight matlab">x = <span class="number">0</span>:<span class="number">0.1</span>:<span class="number">2</span>;y = x .^<span class="number">2</span>;Hnd1 = <span class="built_in">plot</span>(x, y);</code></pre><p><img src="/medias/20200618224955690.png" alt="图 9.2 (a) "></p><p>图象如图 9.2 (a) 所示。这个曲线的句柄被存储在变量 Hnd1 内，我们可以利用它检测和修改这条曲线的属性。函数 get(Hnd1)在一个结构中返回这条曲线所有的属性，每一个属性名都为结构的一个元素。</p><pre><code class="highlight plaintext">&gt;&gt; result=get(Hnd1)result =    Color: [0 0 1]    EraseMode: 'normal'    LineStyle: '-'    LineWidth: 0.5000    Marker: 'none'    MarkerSize: 6    MarkerEdgeColor: 'auto'    MarkerFaceColor: 'none'    XData: [1x21 double]    YData: [1x21 double]    ZData: [1x0 double]    BeingDeleted: 'off'    ButtonDownFcn: []    Children: [0x1 double]    Clipping: 'on'    CreateFcn: []    DeleteFcn: []    BusyAction: 'queue'    HandleVisibility: 'on'    HitTest: 'on'    Interruptible: 'on'    Selected: 'off'    SelectionHighlight: 'on'    Tag: ''    Type: 'line'    UIContextMenu: []    UserData: []    Visible: 'on'    Parent: 151.0012    DisplayName: ''    XDataMode: 'manual'    XDataSource: ''    YDataSource: ''    ZDataSource: ''</code></pre><p>注意当前曲线的线宽为 0.5pixel，线型为虚线。我们能够用这些命令改变线型和线宽。</p><pre><code class="highlight plaintext">&gt;&gt;set(Hnd1,'LineWidth',4,'LineStyle','--')  ------方法已经删除</code></pre><p>产生的结果图象如 9.2 (b) 所示。</p><p><img src="C:%5CUsers%5Chsiehchou%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200618225319238.png" alt=""></p><p>函数 get 和 set 对程序员来说非常的有用，因为它们可以直接插入到 <strong>MATLAB</strong> 程序中，根据用户的输入修改图象。在下一章，我们把它用于 GUI 编程。</p><p>但对于最终的用户，他们要很容易地改变 <strong>MATLAB</strong> 对象的属性。属性编辑器是为了这个目的而设计的工具。启动属性编辑器的命令为</p><pre><code class="highlight plaintext">propedit(HandleList); propedit;</code></pre><p>这个函数第一个形式用于编辑所列出的句柄的属性，而这个函数的第二种形式用于编辑当前图象的属性。例如下面的语句创建函数 y(x)=在(0，2)x2 中的图象并打开属性编辑器， 让用户间接地改变曲线的属性。</p><pre><code class="highlight plaintext">figure(2);x = 0:0.1:2;y = x .^2;Hnd1 = plot(x, y); propedit(Hnd1);</code></pre><p>我们用这些语句调用属性编辑器，如图 9.3。属性编辑器包含了许多的窗格，用户可以根据对象的类型改变对象的属性。在例子中讨论的曲线对象，它窗格包括"Date"，“Style”， 和"Info"。"Date"窗格允许用户选择和修改所要显示的数据它可以修改 X 数据，Y 数据和 Z 数据的属性。"Style"窗格用来线型和符号属性，"Info"用来设置曲线对象的其它信息。</p><p><img src="/medias/20200618230003944.png" alt=""></p><p><img src="/medias/20200618230040265.png" alt="图 9.3 编辑曲线对象的属性编辑器"></p><p>属性编辑器可以用图象工具条上按钮调用，然后双击你所要编辑的对象。</p><h6 id="例-9-1-函数-sinc-x">例 9.1 函数 sinc(x)</h6><p>底层图形命令的应用 函数 sinc(x)的定义如下</p><p><img src="/medias/20200618232209854.png" alt=""></p><p>x 的取值从-3加 到 3加，画出这个函数的图象，用句柄图形函数画出图象，满足下面的要求</p><ol><li><p>使图象背景为粉红色</p></li><li><p>只在 y 轴上有网格线</p></li><li><p>曲线为 3point 宽，枯黄色的实线</p></li></ol><p>答案:</p><p>为了创建图象，我们需要计算 x 从-3加 到 3加 之间的函数 sincx，然后用 plot 命令画出它的图象。plot 命令这条直线的句柄。</p><p>画完直线后，我们需要修改 figure 对象的颜色和 axes 对象的网格状态，以及 line 对象的颜色与线宽。这些修改需要我们访问图对象，axes 对象，line 对象的句柄。图对象的句柄由函数 gcf 返回，axes 对象的句柄由函数 gca 返回，line 对象由 plot 函数返回。</p><p>需要修改的底层图形属性可以在 <strong>MATLAB</strong> 在线帮助工作台文件中找到，在主题"Handle Graphics Objects"目录下。它们包括当前图象的"color"属性，当前的坐标系的"YGrid"属性， 以及曲线的"LineWidth"属性和"color"属性。</p><ol><li><p>陈述问题</p><p>画出函数 sincx 的图象，x 的取值从-3加 到 3加，图象背景为粉红色，只在 y 轴上有网格线，曲线为 3point 宽，枯黄色的实线</p></li><li><p>定义的输入与输出</p><p>这个程序无输入，输出为指定的图象。</p></li><li><p>设计算法</p><p>这个问题可分为三大步</p><pre><code class="highlight plaintext">Calculate sinc(x) Plot sinc(x)Modify the required graphics object properties</code></pre></li></ol><p>这个程序的第一大步是计算 x 从-3加 到 3加 之间的函数 sincx。这个工作可以用向量化语句完成，但向量化语句在 x=0 时会产生一个 NaN，因为 0/0 没有意义。在画这个函数之前我们必须用 1.0 替换 NaN。这个步骤的伪代码为</p><pre><code class="highlight plaintext">% Calculate sinc(x)x = -3*pi:pi/10:3*piy = sin(x) /medias/ x%Find the zero value and fix it up. The zero is%located in the middle of the x array.index = fix(length(y)/2) + 1y(index) = 1</code></pre><p>下一步，我们必须画出这个函数的图象，并把所要修改的曲线的句柄存入一个变量。这个步骤的伪代码为</p><pre><code class="highlight plaintext">Hndl = plot(x, y);</code></pre><p>现在，我们必须用句柄图形修改图象背景，y 轴上的网格线，线宽和线色。图对象的句柄由函数 gcf 返回，axes 对象的句柄由函数 gca 返回，line 对象由 plot 函数返回。</p><p>粉红色背景可由 RGB 向量[1 0.8 0.8]创建，枯黄色曲线可以由 RGB 向量[1 0.5 0]创建。</p><p>伪代码如下：</p><pre><code class="highlight plaintext">set(gcf, 'Color', [1 0.8 0.8])set(gca, 'YGrid', 'on')set(Hndl, 'Color', [1 0.5 0], 'LineWidth', 3)</code></pre><ol start="4"><li>把算法转化为 <strong>MATLAB</strong> 语言</li></ol><pre><code class="highlight matlab"><span class="comment">% Script file: plotsinc.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program illustrates the use of handle graphics</span><span class="comment">% commands by creating a plot of sinc(x) from -3*pi to</span><span class="comment">% 3*pi, and modifying the characteristics of the figure,</span><span class="comment">% axes, and line using the "set" function.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 11/22/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% Hndl -- Handle of line</span><span class="comment">% x -- Independent variable</span><span class="comment">% y -- sinc(x)</span><span class="comment">% Calculate sinc(x)</span>x = <span class="number">-3</span>*<span class="built_in">pi</span>:<span class="built_in">pi</span>/<span class="number">10</span>:<span class="number">3</span>*<span class="built_in">pi</span>;y = <span class="built_in">sin</span>(x) /medias/ x;<span class="comment">% Find the zero value and fix it up. The zero is</span><span class="comment">% located in the middle of the x array.</span>index = <span class="built_in">fix</span>(<span class="built_in">length</span>(y)/<span class="number">2</span>) + <span class="number">1</span>;y(index) = <span class="number">1</span>;<span class="comment">% Plot the function.</span>Hndl = <span class="built_in">plot</span>(x,y);<span class="comment">% Now modify the figure to create a pink background,</span><span class="comment">% modify the axis to turn on y-axis grid lines, and</span><span class="comment">% modify the line to be a 2-point wide orange line.</span>set(gcf,<span class="string">'Color'</span>,[<span class="number">1</span> <span class="number">0.8</span> <span class="number">0.8</span>]);set(gca,<span class="string">'YGrid'</span>,<span class="string">'on'</span>);set(Hndl,<span class="string">'Color'</span>,[<span class="number">1</span> <span class="number">0.5</span> <span class="number">0</span>],<span class="string">'LineWidth'</span>,<span class="number">3</span>);</code></pre><ol start="5"><li>检测程序</li></ol><p>这个程序的检测是非常简单的，我们只要运行这个程序，并检查产生的图象就可以了。产生的图象如图 9.4 所示，它就是我们需要的样式。</p><p><img src="/medias/20200618233445694.png" alt="图 9.4 sincx 的图象"></p><h4 id="9-4-用-set-函数列出可能属性值">9.4 用 set 函数列出可能属性值</h4><p>函数用于提供所有可能的属性值列表。如果在调用函数 set 时，只包括属性名而不包括相应的属性值，那么函数 set 就会返回所有的合法属性值。例如，命令 set(Hnd1，<strong>“<strong>LineStyle</strong>”</strong>) 将返回所有可能的线型，大括号中是默认的线型。</p><pre><code class="highlight plaintext">&gt;&gt; set(Hndl,'LineStyle')[ {-} | -- | : | -. | none ]</code></pre><p>这个函数的合法包括和**“<strong>none</strong>”**，第一个是默认的类型。</p><pre><code class="highlight plaintext">&gt;&gt; set(Hndl,'LineWidth')A line's "LineWidth" property does not have a fixed set of property values.</code></pre><p>函数 set(Hnd1)返回一个对象的所有属性的所有可能的属性值。</p><pre><code class="highlight plaintext">&gt;&gt; set(Hndl)ans =    Color: {}    EraseMode: {4x1 cell}    LineStyle: {5x1 cell}    LineWidth: {}    Marker: {14x1 cell}    MarkerSize: {}    MarkerEdgeColor: {2x1 cell}    MarkerFaceColor: {2x1 cell}    XData: {}    YData: {}    ZData: {}    ButtonDownFcn: {}    Children: {}    Clipping: {2x1 cell}    CreateFcn: {}    DeleteFcn: {}    BusyAction: {2x1 cell}    HandleVisibility: {3x1 cell}    HitTest: {2x1 cell}    Interruptible: {2x1 cell}    Selected: {2x1 cell}    SelectionHighlight: {2x1 cell}    Tag: {}    UIContextMenu: {}    UserData: {}    Visible: {2x1 cell}    Parent: {}    DisplayName: {}    XDataMode: {2x1 cell}    XDataSource: {}    YDataSource: {}    ZDataSource: {}</code></pre><h4 id="9-5-自定义数据">9.5 自定义数据</h4><p>除了一个 GUI 对象定义的标准属性以外，程序可以定义所要控制的数据的特殊属性。程序员可以用附加属性把任意类型的数据添加到 GUI 对象中。任意数量的数据可以被存储，并应用于各种目的。</p><p>自定义数据可以用近似标准属性的形式存储。每一个数据条目都有一个名字和值。数据变量可以用函数 setappdate 存储在一个对象，并用函数 getappdata 接收。</p><p>setappdate 函数的基本形式如下:</p><pre><code class="highlight plaintext">setappdata(Hndl, 'DataName', DataValue);</code></pre><p>其中 Hndl 是数据存入的对象的句柄，**“<strong>DateName</strong>”**是这个数据的名字，而 DateValue 是赋于是这个名字的值。注意数据值可以是数字，也可以是字符串。</p><p>例如，假设我们要定义两个特殊的数据值，其中一个用于存储发在指定图象中的错误数， 另一个是用于描述最后发现的错误的字符串。这两个数据值的名字是 “ErrorCount” 和 “LastError”。我们假设 H1 为这个图象的句柄，创建这些数据条目和初始化的命令为</p><pre><code class="highlight plaintext">setappdata(Hl,'ErrorCount',0);setappdata(H1,'LastError','No error');</code></pre><p>我们可以用 getappdata 函数随时调用这些数据。getappdata 的两种形式如下</p><pre><code class="highlight plaintext">value = getappdata(Hndl, 'DataName');struct = getappdata(Hndl);</code></pre><p>其中，Hnd1 是包含有这个数据的对象句柄，"DateName"是要调用的数据的名字，如果一个 “DateName” 被指定，那么与"DateName"相关的值就会被返回。如果没有被指定，那么所有与这个对象形字相关的自定义值就会以结构的形式被返回。数据条目名就是结构元素名。</p><p>对上面的例子来说，getappdata 将会产生下面的结果</p><pre><code class="highlight plaintext">&gt;&gt; value = getappdata(Hl, 'ErrorCount')value =0&gt;&gt; value = getappdata(Hl);struct =    ErrorCount: 0    LastError: 'No error'</code></pre><p>与自定义数据相关的函数被总结在表 9.1 中。</p><p><strong>表 9.1 与自定义数据相关的函数</strong></p><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>setappdata(Hndl, ‘DataName’, DataValue)</td><td>把 DataValue 存储在对象中的’DataName’，这个对象以 Hndl 为句柄</td></tr><tr><td>value = getappdata(Hndl, ‘DataName’)<br>struct = getappdata(Hndl)</td><td>从以 Hndl 句柄的对象重新调用程序，第一种形式只读取’DataName’中的数据，第二种形式重新所有的自定义数据</td></tr><tr><td>isappdata(Hndl, ‘DataName’)</td><td>如果’DataName’在以 Hndl 为句柄的对象中有定义，那就会返回 1，否则返回 0</td></tr><tr><td>rmappdata(Hndl, ‘DataName’)</td><td>删除’DataName’，'DataName’是在以 Hndl 为句柄的对象中的自定义数据</td></tr></tbody></table><h4 id="9-6-对象查找">9.6 对象查找</h4><p>每一个新的图象在从创建开始时就有它们自已的句柄，句柄可以由创建函数返回。</p><p><strong>如果你打算修改你创建的对象的属性，那么请保存对象的句柄，为以后调用函数 get 和 set 做准备。</strong></p><p>但是我们有时不能访问句柄。假设我们由于一些原因，丢失了对象的句柄。我们如何检测和图形对象呢?<strong>MATLAB</strong> 提供了四个专门的函数，用来帮助寻找对象的句柄。</p><ol><li><p>gcf     ——    返回当前图象的句柄</p></li><li><p>gca    ——    返回当前图象中当前坐标系的句柄</p></li><li><p>gco    ——    返回当前对象的句柄</p></li><li><p>findobj  —— 寻找指定属性值的图形对象</p></li></ol><p>函数 gcf 返回当前图象的句柄。如果这个图象不存在，gcf 将会创建一个，并返回它的句柄。函数 gca 返回当前图象中当前坐标系的句柄，如果图象不存在，或当前图象中无坐标系，那么函数 gca 将创建一个坐标系，并返回它的句柄。函数 gco 的形式如下：</p><pre><code class="highlight plaintext">H_obj = gco;H_obj = gco(H_fig);</code></pre><p>其中，H_obj 是一个对象的句柄，H_fig 是一个图象的句柄。这个函数的第一种形式返回当前图象中的当前对象的句柄。它的第二种形式返回一指定图象中的当前对象的句柄。</p><p>当前对象是指用鼠标单击的最一个对象。这个对象可以是除了根对象的任意图形对象。直到鼠标在图象内发生了单击事件，在图象内才有一个当前对象。在单击事件发生之后，函数 gco 将返回一个空数组[]，不像函数 gcf 和gca，gco 如果不存在就自动创建。</p><p>一旦我们得知了一个对象的句柄，我们可以通过检测**“<strong>Type</strong>”**属性去时来确定对象的类型。“Type"属性是一个字符串，例如"图”，“line”，"text"等等。</p><pre><code class="highlight plaintext">H_obj = gco;type = get(H_obj, 'Type')</code></pre><p>查找任意一个 <strong>MATLAB</strong> 对象最简单的方法是用 findobj 函数。它的基本形式如下</p><pre><code class="highlight plaintext">Hndls = findobj('PropertyName1',value1, ...)</code></pre><p>这个命令起始于根对象，并搜索所有的对象，找出含有指定属性，指定值的对象。注意可以指定多个属性/值，findobj 只返回与之匹配的对象句柄。</p><p>例如，假设我们已经创建了图 1 和图 3。那么函数 findobj(<strong>“<strong>Type</strong>”</strong>，<strong>“<strong>图</strong>”</strong>)将会返回结果</p><pre><code class="highlight plaintext">&gt;&gt; H_fig = findobj('Type', 'figure')H_fig =    3    1</code></pre><p>函数 findobj 的这种形式非常的有用，但却比较慢，因为它必须对整个对象树进行搜索。如果你必须多次用到一对象，只调用一次函数 findobj，为了重复利用句柄，句柄应存储下来。</p><p>限定搜索对象的数目能够加快函数运行的速度。它的形式为</p><pre><code class="highlight plaintext">Hndls = findobj(SrchHndls, 'PropertyName1', value1, ...)</code></pre><p>在这里，只有数组 srchHndls 和它的子数组中的句柄，才在搜索的范围内。例如你想找到图 1 中的虚线。它的命令为</p><pre><code class="highlight plaintext">Hndls = findobj(1, 'Type', 'line', 'LineStyle', '--');</code></pre><p><strong>如果有可能的话，限定函数 findobj 的搜索范围将能加快函数的运行速度。</strong></p><h4 id="9-7-用鼠标选择对象">9.7 用鼠标选择对象</h4><p>函数 gco 将返回当前对象，当前对象是指用鼠标最后一次单击的对象。每一个对象都有一个与之相关的<strong>可选择区</strong>，在可选择区内任意一个单击都可以看作对这个对象的单击。对于细小的对象(例如线，点)来说，这种特性是非常重要的。可选择区的宽度和形状由对象的类型确定。例如，一个曲线的可选择区在离直线 5 pixel 的范围内，而一个表面，一个小块和文本对象的可选择区是包含这些对象的最小长方形。</p><p>对于一个坐标系对象来说，它的可选择区是坐标轴区域加上标题和标签的区域。但是在坐标轴内的曲线对象或其他对象有更高的优先权，你必须在单击坐标内的一点，并且不靠近直线和文本。如果单击坐标外的图象将会选择图象本身。</p><p>如果一个用户单击了两个或多个对象的所在点，例如两线的交插点将会有什么事情发 生。这取决于每一个对象<strong>堆跺顺序****(stacking order)</strong>。堆跺顺序是 <strong>MATLAB</strong> 选择对象的顺序。在一个图象中所有的"子对象"属性句柄顺序就是堆跺顺序。如果单击了两个或多个对象的所在点，在堆跺顺序的优先权高的将会被选择。</p><p>当选择图形对象时，我们有时可以调用 <strong>MATLAB</strong> 内建函数 waitforbuttonpress。这个函数的形式为</p><pre><code class="highlight plaintext">k = waitforbuttonpress</code></pre><p>当这个函数运行时，它将会暂停程序，直到任意键按下或鼠标单击事件发生后，程序才恢复运行。如果按下了鼠标键函数将会返回 0，按下任意键，函数将会 1。</p><p>函数经常用于暂停程序。当鼠标单击事件发生后，程序将会用 gco 函数恢复选择对象的句柄。</p><h5 id="例-9-2-图形对象的选择">例 9.2 图形对象的选择</h5><p>图形对象的选择</p><p>在本例中的程序可以探测图形对象的属性，并显示如何用函数 waitforbuttonpress 和 gco 选择对象。程序允许用户可以多次重复选择对象。</p><pre><code class="highlight matlab"><span class="comment">% Script file: select_object.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program illustrates the use of waitforbuttonpress</span><span class="comment">% and gco to select graphics objects. It creates a plot</span><span class="comment">% of sin(x) and cos(x), and then allows a user to select</span><span class="comment">% any object and examine its properties. The program</span><span class="comment">% terminates when a key press occurs.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description of change</span><span class="comment">% ==== ========== =====================</span><span class="comment">% 11/23/97 S. J. Chapman Original code</span><span class="comment">%</span><span class="comment">% Define variables:</span><span class="comment">% details -- Object details</span><span class="comment">% H1 -- Handle of sine line</span><span class="comment">% H2 -- Handle of cosine line</span><span class="comment">% Handle -- Handle of current object</span><span class="comment">% k -- Result of waitforbuttonpress</span><span class="comment">% type -- Object type</span><span class="comment">% x -- Independent variable</span><span class="comment">% y1 -- sin(x)</span><span class="comment">% y2 -- cos(x)</span><span class="comment">% yn -- Yes/No</span><span class="comment">% Calculate sin(x) and cos(x)</span>x = <span class="number">-3</span>*<span class="built_in">pi</span>:<span class="built_in">pi</span>/<span class="number">10</span>:<span class="number">3</span>*<span class="built_in">pi</span>;y1 = <span class="built_in">sin</span>(x);y2 = <span class="built_in">cos</span>(x);<span class="comment">% Plot the functions.</span>H1 = <span class="built_in">plot</span>(x,y1);set(H1,<span class="string">'LineWidth'</span>,<span class="number">2</span>);<span class="built_in">hold</span> on;H2 = <span class="built_in">plot</span>(x,y2);set(H2,<span class="string">'LineWidth'</span>,<span class="number">2</span>,<span class="string">'LineStyle'</span>,<span class="string">':'</span>,<span class="string">'Color'</span>,<span class="string">'r'</span>);title(<span class="string">'\bfPlot of sin \itx \rm\bf and cos \itx'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bfsin \itx \rm\bf and cos \itx'</span>);<span class="built_in">legend</span>(<span class="string">'sine'</span>,<span class="string">'cosine'</span>);<span class="built_in">hold</span> off;<span class="comment">% Now set up a loop and wait for a mouse click.</span>k = waitforbuttonpress;<span class="keyword">while</span> k == <span class="number">0</span><span class="comment">% Get the handle of the object</span>Handle = gco;<span class="comment">% Get the type of this object.</span><span class="built_in">type</span> = get(Handle,<span class="string">'Type'</span>);<span class="comment">% Display object type</span><span class="built_in">disp</span> ([<span class="string">'Object type = '</span> <span class="built_in">type</span> <span class="string">'.'</span>]);<span class="comment">% Do we display the details?</span>yn = input(<span class="string">'Do you want to display details? (y/n) '</span>,<span class="string">'s'</span>);<span class="keyword">if</span> yn == <span class="string">'y'</span>details = get(Handle);<span class="built_in">disp</span>(details);<span class="keyword">end</span><span class="comment">% Check for another mouse click</span>k = waitforbuttonpress;<span class="keyword">end</span></code></pre><p>程序运行后，得到的结果如图 9.5 所示</p><p><img src="/medias/20200619131300841.png" alt="图 9.5 sinx 和 cosx 的图象"></p><h4 id="9-8-位置和单位">9.8 位置和单位</h4><p>许多的 <strong>MATLAB</strong> 对象都包括位置(<strong>“<strong>position</strong>”</strong>)属性，它用来指定对象在计算机屏幕的位置和大小。这个属性在不同类型的对象中有细节的差别，这一点将在本节中描述。</p><h5 id="9-8-1-图象-figure-对象的位置">9.8.1  图象(figure)对象的位置</h5><p>一个图象(图)的位置(<strong>“<strong>position</strong>”</strong>)用一个 4 元素行向量指定在计算机屏幕内的位置。在这个向量中的值为[left bottom width height]，其中 left 是指图象的左边界，bottom 是指图象的底边界，width 是指图象的宽度，height 是指图象的高度。它的这些位置值的单位可以用对象的**“<strong>Units</strong>”**属性指定。例如，与当前图象的位置和单位可以用下面的语句得到。</p><pre><code class="highlight plaintext">&gt;&gt; get(gcf,'Position')ans =128 259 506 373&gt;&gt; get(gcf,'Units')ans =pixels</code></pre><p>这些信息说明当前图象窗口的左下角距屏幕右边的距离为 176pixel，距屏幕底边的距离为 204pixel。，图象的宽度为 672pixel，上下高度为 504pixel。注意这是图象的可作图区，包括边界，滚动条，菜单，还有图象的标题区。</p><p>单位(<strong>“<strong>units</strong>”</strong>)属性的默认值为像素(pixels)，但是它的属性值还可以为英尺(inches)，公分(centimeters)，点(points)，或归一化坐标(normalixed coordinates)。像素代表了屏幕像素，即在屏幕上可表示出来的最小的对象。典型的计算机屏幕最小分辨为 640×480，在屏幕的每一个位置都有超过 1000 的像素。因为像素数因机算机屏幕的不同而不同，所以指定对象的大小也会随之改变。</p><p>归一化坐标是在0 到1 范围内。在归一化坐标中，屏幕的左下角为[0,0]右上角为[1.0, 1.0]。如果对象的位置归一化坐标系的形式描述，那么不同分辨率的显示器上对象的相对位置是固定的。例如，下面的语句创建了一个图象，把图象放置在屏幕的上部，而不用考虑显示器的大小。</p><pre><code class="highlight plaintext">H = figure(1)set(H,'units', 'normalized','position',[0 .5 .5 .45])</code></pre><p><strong>如果你想把对象放置在窗口的特定位置，最好的方法是用归一化坐标，因为不用考虑显示器的大小。</strong></p><h5 id="9-8-2-坐标系对象和-uicontrol-对象的位置">9.8.2  坐标系对象和 uicontrol 对象的位置</h5><p>坐标系对象和 uicontrol 对象的位置同样可以用一个 4 元素向量表示，但它是相对于 figure 对象的位置。一般说来，所有子对象的**“<strong>position</strong>”**属性都与它的父对象相关。</p><p>默认地，坐标系对象在一图象内的位置是有归一化单位指定的，(0，0)代表图象的左下角，(1，1)代表图象的右上角。</p><h5 id="9-8-3-文本-text-对象的位置">9.8.3  文本(text)对象的位置</h5><p>与其他对象不同，文本(text)对象有一个位置属性，包含两个或三个元素。这些元素为坐标系对象中文本对象的 x，y 和 z 轴。注意都显示在坐标轴上。</p><p>放置在某一特定点的文本对象的位置可由这个对象的 HorizontalAlignment 和 VerticalAlignment 属性控制。HorizontalAlignment 的属性可以是{Left}。Center，或 Right。 VerticalAlignment 的属性值可以为 Top，cap，{Middle}，Baseline 或 Bottom。</p><p>文本对象的大小由字体大小和字符数决定，所以没有高度和宽度值与之相连。</p><h6 id="例-9-3-设置一个图象内对象的位置">例 9.3 设置一个图象内对象的位置</h6><p>正如我们前面所提到的，坐标系的位置与包含它的图象窗口的左下角有关，而文本对象的位置与坐标系的位置相关。</p><p>为了说明如何在一图象窗口中设置图形对象的位置，我们将编写一个程序，用它在单个的图象窗口内创建两个交迭的坐标系。</p><p>第一个坐标系将用来显示函数 sinx 的图象，并带有相关文本说明。第二个坐标系用来显示函数 cosx 的图象，并在坐标系的左下角有相关的文本说明。</p><p>用来创建图象的程序如下所示。注意我们用图函数来创建一个空图象，然后两个 axes 函数在图象窗口中创建两个坐标系。函数 axes 的位置可以用相对于图象窗口的归一化单位指定，所以第一个坐标系起始于(0.05,0.05)，位于图象窗口的左下角，第二坐标系起始于(0.45,0.45)，位于图象的右上角。每个坐标系都有合适的函数进行作图。</p><p>第一个坐标系中的文本对象的位置为(-加, 0)，它是曲线上的一点。当我们选择 HorizontalAlignment 的属性值为 right，那么点(-加, 0)则在文本字符串的右边。所以在最终的图象中，文本就会显示在位置点的左边(这对于新程序员来说很容易迷惑)。</p><p>在第二个坐标系中的文本对象的位置为(7.5, 0.9)，它位于坐标轴的左下方。这个字符串HorizontalAlignment 属性的默认值**“<strong>left</strong>”**，点(7.5，0.9)则在文本字符串的右边。所以在最终的图象中，文本就会显示在位置点的右边。</p><pre><code class="highlight matlab"><span class="comment">% Script file: position_object.m</span><span class="comment">%</span><span class="comment">% Purpose:</span><span class="comment">% This program illustrates the positioning of graphics</span><span class="comment">% objects. It creates a figure and then places</span><span class="comment">% two overlapping sets of axes on the figure. The first</span><span class="comment">% set fo axes is placed in the lower left corner of</span><span class="comment">% the figure. and contains a plot of sin(x), The second</span><span class="comment">% set of axes is placed in the upper right corner of the</span><span class="comment">% figure, and contains a plot of cos(x). Then two</span><span class="comment">% text strings are added to the axes, illustrating the</span><span class="comment">% positioning of text within axes.</span><span class="comment">%</span><span class="comment">% Record of revisions:</span><span class="comment">% Date Programmer Description fo change</span><span class="comment">% ===== ========== =====================</span><span class="comment">% 02/26/99 S.J.Chapman Original code</span><span class="comment">%</span><span class="comment">% Define varibles:</span><span class="comment">% H1 --Handle of sine line</span><span class="comment">% H2 --Handle of sosine line</span><span class="comment">% Ha1 --Handle of first axes</span><span class="comment">% Ha2 --Handle of second axes</span><span class="comment">% x --Independent variable</span><span class="comment">% y1 --sin(x)</span><span class="comment">% y2 --cos(x)</span><span class="comment">% Calculate sin(x) and cos(x)</span>x = <span class="number">-2</span>*<span class="built_in">pi</span>:<span class="built_in">pi</span>/<span class="number">10</span>:<span class="number">2</span>*<span class="built_in">pi</span>;y1 = <span class="built_in">sin</span>(x);y2 = <span class="built_in">cos</span>(x);<span class="comment">% Create a new figure</span><span class="built_in">figure</span>;<span class="comment">% Create the first set of axes and plot sin(x).</span><span class="comment">% Note that the position of the axes is expressed</span><span class="comment">% in normalized units.</span>Ha1 = axes(<span class="string">'Position'</span>,[<span class="number">.05</span> <span class="number">.05</span> <span class="number">.5</span> <span class="number">.5</span>]);H1 = <span class="built_in">plot</span>(x, y1);set(H1,<span class="string">'LineWidth'</span>,<span class="number">2</span>);title(<span class="string">'\bfPlot of sin \itx'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bfsin \itx'</span>);axis([<span class="number">-8</span> <span class="number">8</span> <span class="number">-1</span> <span class="number">1</span>]);<span class="comment">% Create the second set of axes and plot cos(x).</span><span class="comment">% Note that the position of the axes is expressed</span><span class="comment">% in normalized units.</span>Ha2 = axes(<span class="string">'Position'</span>,[<span class="number">.45</span> <span class="number">.45</span> <span class="number">.5</span> <span class="number">.5</span>]);H2 = <span class="built_in">plot</span>(x, y1);set(H2,<span class="string">'LineWidth'</span>,<span class="number">2</span>,<span class="string">'Color'</span>,<span class="string">'r'</span>,<span class="string">'LineStyle'</span>,<span class="string">'--'</span>);title(<span class="string">'\bfPlot of cos \itx'</span>);xlabel(<span class="string">'\bf\itx'</span>);ylabel(<span class="string">'\bfsin \itx'</span>);axis([<span class="number">-8</span> <span class="number">8</span> <span class="number">-1</span> <span class="number">1</span>]);<span class="comment">% Create a text string attached to the line on the first</span><span class="comment">% set of axes.</span>axes(Ha1);text(-<span class="built_in">pi</span>,<span class="number">0.0</span>,<span class="string">'min(x)\rightarrow'</span>,<span class="string">'HorizontalAlignment'</span>,<span class="string">'right'</span>);<span class="comment">% Create a text string in the lower left corner</span><span class="comment">% of the second set of axes.</span>axes(Ha2);text(<span class="number">-7.5</span>,<span class="number">-0.9</span>,<span class="string">'Text string 2'</span>);</code></pre><p>当这个程序执行后，产生的图象如图 9.6 所示。你就应当在你的计算机上重复地执行这人程序，所要画的对象的大小与位置，观察结果。</p><p><img src="/medias/20200619132157198.png" alt="图 9.6 程序 position_object 的结果"></p><h4 id="9-9-打印位置">9.9 打印位置</h4><p>属性**“<strong>Position</strong>"<strong>和</strong>"<strong>Units</strong>”**用来指定图象在计算机屏幕上的位置。还有其他的五个属性用于指定图象在打印纸上的位置。这些属性被总结在表 9.2 中。</p><p><strong>表 9.2 与打印相关的图象属性</strong></p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>PaperUnits</td><td>度量纸张的单位<br>[ {inches} | centimeters | normalized  | points]</td></tr><tr><td>PaperOrientation</td><td>[ {portrait} | landscape]</td></tr><tr><td>PaperPosition</td><td>位置向量，形式为[left, bottom, width, height]，单位是 PaperUnits</td></tr><tr><td>PaperSize</td><td>包含纸张大小两个元素的向量，例如[8.5 11]</td></tr><tr><td>PaperType</td><td>设置纸张的类型，注意设置这个属性会自动更新纸张的 PaperSize属性。<br>[{usletter} | uslegal | a3 | a4letter | a5 | b4 | tabloid]</td></tr></tbody></table><p>例如，我们用 landscape 模式，用归一化单位在 A4 纸上打印一个图象。我们可以设置下面的属性。</p><pre><code class="highlight plaintext">set(Hndl, 'PaperType', 'a4letter') set(Hndl, 'PaperOrientation', 'landscape') set(\Hndl, 'PaperUnits', 'normalized');</code></pre><h4 id="9-10-默认和-factory-属性">9.10 默认和 factory 属性</h4><p>当一个对象被创建时，<strong>MATLAB</strong> 就会把默认的属性值赋值于每一个对象。如果这些属性值不是你想要的，那么你必须用 set 函数选择你想要的值。如果你想更改你创建的每一个对象的一个属性，这个过程将变得非常麻烦。由于这个原因，<strong>MATLAB</strong> 允许你修改默认值本身，所以当他们被创建时，所有的对象都会继承所有正确的属性值。</p><p>当一个图形对象被创建时，<strong>MATLAB</strong> 就会通过检测对象的父对象来寻找每一个属性的默认值。如果父对象设置了默认值，那么这个值就会被应用。如果没有设置默认值，那么<strong>MATLAB</strong> 就会检测父对象的父对象，看是否有默认值。以此类推，直到根对象。在这个过程中，<strong>MATLAB</strong> 会应用第一次遇到的默认值。</p><p>默认属性可以在优先级高的图形对象中的任意一点设置。例如，默认的图的颜色在根对象中设置，而在这之后的所有图象都有一个新的默认颜色。从另一方面说，默认的坐标轴颜色可以在根对象或图象对象设置。如果坐标的默认颜色在根目录中设置，那么它将应用于所有图象的所有新坐标轴，如果默认的坐标轴颜色在图象对象中设置，它将在当前图象窗中的新坐标轴。</p><p>默认值的设置要用一个字符串，这个字符串由"Default"，对象类型和属性名组成。所以默认图象颜色可以通过属性**“<strong>DefaultFigureColor</strong>”**来设置，默认的坐标轴颜色可以通过属性</p><p>**“<strong>DefaultAxesColor</strong>”**设置。下面是设置默认值的一些例子</p><p>set(0, ‘DefaultFigureColor’, ‘y’)          黄色图象背景</p><p>set(0, ‘DefaultAxesColor’, ‘r’)         红色坐标系背景 所有图象中的坐标轴</p><p>set(gcf, ‘DefaultAxesColor’, ‘r’)      红色坐标系背景 当前图象坐标轴</p><p>set(gca, ‘DefaultLineStyle’, ‘:’)        只在当前坐标系中设置默认线型为虚线</p><p>如果你要对已存在的对象的属性进行修改，那么在用完这个属性之后，最好恢复原来的条件。如果你在一个函数中修改了一个对象的默认属性值，保存它原来的值，并在跳出这个函数之前恢复它们。例如，假充我们用归一化单位创建一系列的图象，我们可以用下面的保存和修复原来的单位。</p><pre><code class="highlight plaintext">saveunits = get(0, 'DefaultFigureUnits');set(0, 'DefaultFigureUnits', 'normalized');...&lt;MATLAB statements&gt;...set(0, 'DefaultFigureUnits', saveunits);</code></pre><p>如果你想要定制 <strong>MATLAB</strong>，每一次都有不同的默认值，那么每次当 <strong>MATLAB</strong> 启动时你必须对根对象设置默认值。最简单的方法是把默认值存入 startup.m 文件，每次 <strong>MATLAB</strong> 启动时都会自动执行。例如，假设你经常使用 A4 纸，并在图象中经常加入网格线。那么你可以把下面的语句加入到 startup.m 文件中。</p><pre><code class="highlight plaintext">set(0, 'DefaultFigurePaperType', 'a4letter');set(0, 'DefaultAxesXGrid', 'on');set(0, 'DefaultAxesYGrid', 'on');set(0, 'DefaultAxesZGrid', 'on');</code></pre><p>有三种特殊值字符串用于句柄图形:<strong>“<strong>remove</strong>”</strong>，<strong>“<strong>factory</strong>"<strong>和</strong>"<strong>default</strong>”</strong>。如果你已经为一个属性设置了默认值，那么**“<strong>remove</strong>”**值将会删除你所设置的默认值。例如，假设你设置默认的图象颜色为黄色。</p><pre><code class="highlight plaintext">set(0, 'DefaultFigureColor', 'y');</code></pre><p>调用下面的函数将会取消当前的默认值并恢复先前的默认值。</p><pre><code class="highlight plaintext">set(0, 'DefaultFigureColor', 'remove');</code></pre><p>字符串**“<strong>factory</strong>”**允许临时跳过当前的默认值，并使用原来的 <strong>MATLAB</strong> 的默认值。例如，尽管当前的默认颜色为黄色，下面的语句将会用 factory 创建下面的图象。</p><pre><code class="highlight plaintext">set(0, 'DefaultFigureColor', 'y'); figure('Color', 'factory');</code></pre><p>第三个特殊的属性值字符串是 default，这个属性值迫使 <strong>MATLAB</strong> 搜索对象层次结构，直到查到所需属性的一个默认值。如果找到，它就使用该默认值。如果查到根对象，没有找到用户定义的默认值，<strong>MATLAB</strong> 就使用 factory 默认值。它的应用说明如下</p><pre><code class="highlight plaintext">% Set default valuesset(0, 'DefaultLineColor', 'k'); % root default = blackset(gcf, 'DefaultLineColor', 'g'); % figure default = green% Create a line on the current axes. This line is green.Hndl = plot(randn(1, 10));set(Hndl, 'Color', 'default');pause(2);% Now clear the figure default and set the line color to the new% default. The line is now black.set(gcf, 'DefaultLineColor', 'remove');set(Hndl, 'Color', 'default');</code></pre><h4 id="9-11-图形对象属性">9.11 图形对象属性</h4><p>由于有成百上千的图形对象属性，我们在这里不——讨论了。我们可以通过 <strong>MATLAB</strong>帮助台得到所有属性。</p><h4 id="9-12-总结">9.12 总结</h4><ol><li><strong>如果你打算修改你创建的对象的属性，那么请保存对象的句柄，为以后调用函数get 和 set 做准备</strong></li><li><strong>如果有可能的话，限定函数 findobj 的搜索范围将能加快函数的运行速度</strong></li><li><strong>如果你想把对象放置在窗口的特定位置，最好的方法是用归一化坐标，因为不用考虑显示器的大小。</strong></li></ol><p><strong>MATLAB</strong> 总结</p><ol><li><p>gcf    ——   返回当前图象的句柄</p></li><li><p>gca   ——   返回当前图象中当前坐标系的句柄</p></li><li><p>gco   ——    返回当前对象的句柄</p></li><li><p>findobj   ——  寻找指定属性值的图形对象</p></li></ol><h3 id="第十章-用户图形界面">第十章 用户图形界面</h3><p>用户图形界面（GUI）是程序的图形化界面。一个好的 GUI 能够使程序更加容易的使用。它提供用户一个常见的界面，还提供一些控件，例如，按钮，列表框，滑块，菜单等。用户图形界面应当是易理解且操作是可以预告的，所以当用户进行某一项操作，它知道如何去做。例如，当鼠标在一个按钮上发生了单击事件，用户图形界面初始化它的操作，并在按钮的标签上对这个操作进行描述。</p><p>本章将向大家 <strong>MATLAB</strong> 用户图形界面的基本元素。本章不会对部件和 GUI 特性进行全部的描述，但是它将为你的程序提供必须的 GUI 元素。</p><h4 id="10-1-用户图形界面是如何工作的">10.1 用户图形界面是如何工作的</h4><p>用户图形界为用户提供了一个熟悉的工作环境。这个环境包括按钮，列表框，菜单，文本框等等，所有的这些控件对用户来说非常地熟悉。所以能够应用它操作应用程序，而不用直接调用操作函数。但是，对于程序员来说，GUI 比较难的，因为程序的每一个控件都必须为鼠标单击做好准备。像鼠标单击这样的输入就是我们熟知的<strong>事件</strong>，而对事件有反应的程序， 我们称之为<strong>事件驱动</strong>。</p><p>创建 <strong>MATLAB</strong> 用户图形界面必须由三个基本元素：</p><ol><li><p>组件</p><p>在 <strong>MATLAB</strong> GUI 中的每一个项目(按钮，标签，编辑框等)都是一个图形化组件组件可分为三类：<strong>图形化控件</strong>(<strong>按钮，编辑框，列表，滑动条</strong>等)，<strong>静态元素</strong>(窗口和文本字符串)，<strong>菜单和坐标系</strong>，图形化控件和静态元素由函数 uicontrol 创建，菜单由函数 uimenu 和 uicontextmenu 创建，坐标系经常用于显示图形化数据，由函数 axes 创建。</p></li><li><p>图象窗口</p><p>GUI 的每一个组件都必须安排图象窗口中。以前，我们在画数据图象时， 图象窗口会被自动创建。但我们还可以用函数 figure 来创建空图象窗口，空图象窗口经常用于放置各种类型的组件。</p></li><li><p>响应</p><p>最后，如果用户用鼠标单击或用键盘键入一些信息，那么程序就要有相应的动作。鼠标单击或键入信息是一个事件，如果<strong>MATLAB</strong> 程序运行相应的函数，那么<strong>MATLAB</strong>函数肯定会有所反应。例如，如果用户单击一按钮，这个事件必然导致相应的 <strong>MATLAB</strong> 语句执行。这些相应的语句被称为响应。只要执行 GUI 的单个图形组件，必须有一个响应。</p></li></ol><p>基本的 GUI 元素被总结在表 10.1 中，一些元素的例子被显示在图 10.中。我们将会学习这些例子，并通过它们说明 GUI 是如何工作的。</p><h4 id="10-2-创建并显示用户图形界面">10.2 创建并显示用户图形界面</h4><p>我们用工具 guide 来创建 <strong>MATLAB</strong> 用户图形界面，guide 是 GUI 集成开发环境。此工具允许程序员安排用读图形界面，选择和放置所需的 GUI 组件。一旦这些组件放置成功， 程序员就能够编辑它们的属性：名字，颜色，大小，字体，所要显示的文本等等。当 guide 保存了这个用户图形界面之后它将会自动创建一个包括有骨干函数的工作程序，程序员可以利用这些程序执行用户图形界面的执行动作。</p><p>当执行 guide 语句时，<strong>MATLAB</strong> 将会创建一个版面编辑器（layout editor），如图图 10.2所示。带有网格线的大空臼区域被称之为布局区（the layout area）。用户可以通过单击你所需要的组件创建任意的目的 <strong>MATLAB</strong> 组件，然后通过拖动它的轮廓线，把它放置在布局区内。在这个窗口的上部用一个带有许多有用工具的工具条，它允许用户分配和联合 GUI 组件，修改每一个 GUI 组件的属性，在用户图形界面中添加菜单等。</p><p>创建一个 <strong>MATLAB</strong> 用户图形界面的基本步骤为：</p><ol><li>决定这个用户图形界面需要什么样的元素，每个元素需要什么样的函数。在纸上手动粗略地画出组件的布局图。</li></ol><p><strong>表 10.1 一些基本的 GUI 组件</strong></p><table><thead><tr><th>元素</th><th>创建元素的函数</th><th>描述</th></tr></thead><tbody><tr><td>图形控件</td><td></td><td></td></tr><tr><td>按钮(pushbutton)</td><td>uicontrol</td><td>单击它将会产生一个响应</td></tr><tr><td>开关按钮(togglebutton)</td><td>uicontrol</td><td>开关按钮有两种状态“on”，“off”，每单击一次，改变一次状态。每一个单击一次产生一个响应。</td></tr><tr><td>单选按钮(radiobutton)</td><td>uicontrol</td><td>当单选按钮处于 on 状态，则圆圈中有一个点</td></tr><tr><td>复选按钮(checkbox)</td><td>uicontrol</td><td>当复选按钮处于 on 状态时，复选按钮中有一个对号</td></tr><tr><td>文本编辑框(editbox)</td><td>uicontrol</td><td>编辑框用于显示文本字符串，并允许用户修改所要显示的信息。当按下回车键后将产生响应</td></tr><tr><td>列表框(listbox)</td><td>uicontrol</td><td>列表框可显示一系文本字符串，用于可用单击或双击选择其中的一个字符串。当用户选择了其中一个字符串后，它将会有一个响应</td></tr><tr><td>下拉菜单（popup Menus）</td><td>uicontrol</td><td>下拉菜单用于显示一系列的文本字符串，当单击时将会产生响应。当下拉菜单没有点击时，只有当前选择的字符串可见</td></tr><tr><td>滑动条（slider）</td><td>uicontrol</td><td>每改变一次滑动条都会有一次响应</td></tr><tr><td>静态元素</td><td></td><td></td></tr><tr><td>框架（frame）</td><td>uicontrol</td><td>框架是一个长方形，用于联合其他控件。而它则不会产生反应</td></tr><tr><td>文本域（textfield）</td><td>uicontrol</td><td>标签是在图像窗口内某一点上的字符串</td></tr><tr><td>菜单和坐标系</td><td></td><td></td></tr><tr><td>菜单（menuitems）</td><td>Uimenu</td><td>创建一个菜单项。当鼠标在它们上单击时，它将会产生一个响应</td></tr><tr><td>右键菜单(contextmenus)</td><td>Uicontextmenu</td><td>创建一个右键菜单</td></tr><tr><td>坐标系(axes)</td><td>Axes</td><td>用来创建一个新的坐标系</td></tr></tbody></table><p><img src="/medias/20200619153259660.png" alt="图 10.1 本图显示的是 MATLAB 用户图形界面元素的例子"></p><p>按从上到下，从左向右的顺序</p><p><strong>依次为：(1)按钮(2)处于“on”状态的开关按钮。(3)在一个框架中的三个单选按钮(4)复选按钮(5)一个文本域和编辑框(6)滑动条(7)坐标系(8)列表框</strong></p><ol start="2"><li><p>调用 <strong>MATLAB</strong> 工具 guide 对图象中的控件进行布局。图象窗口的大小，排列和其中的控件布局都可以利用它进行控制。</p></li><li><p>我们可以用 <strong>MATLAB</strong> 属性编辑器(property inspector)(内置于 guide)给每一个控件起一个名字(标签)，还可以设置每一个控件的其他特性，例如颜色，显示的文本等等。</p></li><li><p>把图象保存到一个文件中。当文件被保存后，程序将会产生两个文件，文件名相同而扩展名相同。fig 文件包括你创建的用户图形界面，M 文件包含加载这个图象的代码和每个 GUI 元素的主要响应。</p></li><li><p>编写代码，执行与每一个回叫函数相关的行为。</p></li></ol><p>作为这些步骤的一个简单例子，让我们考虑一个简单的用户图形界面，它包括一个按钮和一个文本框。每单击一次按钮，文本字符串就更新一次，它用于显示用户图形界面启动后的单击总数。</p><p><img src="/medias/20200619153818881.png" alt="图 10.2"></p><p>第一步：这个用户图形界面是非常简单的。它包含一个简单的按钮和一个单个的文本域。这个按钮的响应为文本域中的当数字增加 1。这个用户图形界面的草图为图 10.3。</p><p><img src="/medias/20200619153940151.png" alt="图 10.3 控件布局草图"></p><p>第二步：对 GUI 控件进行布局，运行函数 guide。当运行 guide 执行时，它将产生如图</p><p>10.2 所示的窗口。</p><p><img src="/medias/20200619154142601.png" alt="图 10.4 guide 窗口中的用户图形界面的布局"></p><p>首先，我们必须设置布局的大小，它将生成最终用户图形界面的大小。我们可以通过拖动窗口右下角的小正方形调节布局区的大小和形状。然后点击“push botton”按钮然后拖动在布局区创建一个按钮。最后单击“text”按钮，然后拖动在布局区创建一个文本字符串。这些步骤产生的结果如图 10.4 所示。如果我们想让两个控件对齐的话，那么可以用对齐工具(Alignment Tool)达到此目的。</p><p>第三步：为了设置按钮的属性，右击按钮并选择“Inspect Properties”(编辑属性)。属性 编辑窗口如图 10.5 所示。注意这个属性编辑器列出这个按钮的所有可以得到的属性，并允许我们改变用户图形界面的属性值。属性编辑器运行得到的结果和第九章中介绍 get 和 set 函数得到的结果相同，但是属性编辑器是一种非常容易使用的形式。</p><p><img src="/medias/20200619154316777.png" alt="图 10.5 属性编辑器显示的按钮的属性。注意 string 被设置成“Click Here”，Tag 被设置成“MyFirstButton”"></p><p>对于这个按钮来说，我们可以设置它的许多属性，例如，颜色，大小，字体，文本对齐等属性。但是有两个必须设置的属性：String 属性，它包含的属性值是所要显示的文本;Tag 属性，它的属性值为按钮的名字。在这个情况下，String 被设置为‘ClickHere’，Tag 属性被设置成‘MyFirstButton’。</p><p>对于文本域来说，也有两个必须设置的属性：String 属性，它包含的属性值是所要显示的文本;Tag 属性，它的属性值为文本域的名字。回叫函数需要这个名字，并更新的它的文本域。在这个情况下，String 被设置为‘Total Click’，Tag 属性被设置成‘MyFirstText’。经过了这些步骤，布局区如图 10.6 所示。</p><p><img src="/medias/20200619154450786.png" alt="图 10.6 按钮和文本域被修改后的设计区域"></p><p>我们可以通过单击鼠标在布局编辑区的空臼点来调用属性编辑器，然后用属性编辑器检测并设置图象窗口的属性。即使不需要，设置图象窗口的名字是一个非常好的方法。当运行行程序时，在 name 属性中的字符串将会显示在用户图形界面的标题栏中。</p><p>第四步：我们以 MyFirstGUI 为名保存布局区。选择菜单项“File/Save as”，并键入名字MyFirstGUI，然后单击“save”。<strong>MATLAB</strong> 将会产生两个文件，MyFirstGUI.flg 和MyFirstGUI.m。图象文件由我们创建的用户图形界面构成。M 文件由加载图象文件和创建用户图形界面的代码组成，还包括每一个活动的用户图形界面组件的若干函数。</p><p>这时，我们已经拥有了一个完整的用户图形界面，但是它不能完成我们所要求的工作。在命令窗口内输入 MyFirstGUI，即可启动你的用户图形界面，如图 10.7 所示。如要你在这个主用户图形界面上单击这个按钮，在命令窗口中将会出现下面的信息。</p><pre><code class="highlight plaintext">MyFirstButton Callback not implemented yet.</code></pre><p><img src="/medias/20200619154716092.png" alt="图 10.7 在命令窗口中键入 MyFirstGUI，启动对应的用户图形界面"></p><p>Guide 自动创建的一部分 M 文件显示在图 10.8 中。这个文件包含函数 MyFirstGUI，还有对每一个活动的用户图形界面组件执行响应的哑元子函数，如果函数 MyFirstGUI 被调用时无参数，那么这个函数将显示出包含在文件 MyFirstGUI 中的用户图形界面。如果函数MyFirstGUI 调用时带有参数，那么函数将会假设第一个参数是子函数的名字，并用 feval 调用这个函数，把其它的参数传递给这个函数。</p><p>每一个回叫函数(call function)都控制着来自对应的用户图形界面组件的事件。如果鼠标单击事件发生在这个用户图形界面组件上，那么这个组件的回叫函数将自动被 <strong>MATLAB</strong> 调用。这个回叫函数的名字是这个用户图形界面组的 Tag 属性值加上字符串"_Callback"，所以， 回叫函数 MyFirstButton 的为 “MyFirstButton_Callback” 。</p><p>由 guide 创建的 M 文件包括了每个活动的用户图形界面组的响应。但是这些响应只是简单的显示一条消息：回叫函数还没有被执行。</p><p>第五步：现在，我们需要执行这个按钮对应的子函数。这个函数包括一个 persistent 变量，这个变量经常被用于对点击次数进行计数。当单击次数发生在这个按钮上，<strong>MATLAB</strong> 将会调用带有第一个参数 MyFirstButton_Callback 的函数 MyFirstGUI。然后函数 MyFirstGUI 将会调用函数 MyFirstButton_Callback，如图 10.9 所示。</p><p>这个函数将会对单击的次数增加 1。并创建一个新的包含有这个次数的字符串，并存储在对象文本域中 String 属性的新字符串中。在这个步骤运行的函数如下所示：</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">MyFirstButton_Callback</span><span class="params">(hObject, eventdata, handles)</span></span><span class="comment">% hObject handle to MyFirstButton (see GCBO)</span><span class="comment">% eventdata reserved - to be defined in a future version of MATLAB</span><span class="comment">% handles structure with handles and user data (see GUIDATA)</span><span class="comment">% Declare and initialize variable to store the count</span><span class="keyword">persistent</span> count<span class="keyword">if</span> <span class="built_in">isempty</span>(count)cout = <span class="number">0</span>;<span class="keyword">end</span><span class="comment">% Update count</span>count = count + <span class="number">1</span>;<span class="comment">% Create new string</span>str = sprintf(<span class="string">'Total Clicks: %d'</span>,count);<span class="comment">% Update the text field</span>set (handles.MyFirstText,<span class="string">'String'</span>,str);</code></pre><p><img src="/medias/20200619155136938.png" alt="图 10.8 MyFirstGUI 的 M 文件，是由 guide 自动创建的"></p><p>程序 MyFirstGUI 的事件运行过程。当一用户用鼠标在按钮进行单击，带有参数MyFirstButton_Callback 的函数 MyFirstGUI 就会被自动调用。函数 MyFirstGUI 将会调用子函数 MyFirstButton_Callback。这个函数用来增加次数，然后把新的次数存入用户图形界面的文本域中。</p><p>注意这个函数定义了一个持久变量 cout，并把它初始化为 0。这个函数每一次调用，cout 都会增加 1，这个函数就会创建一个含有 count 的新字符串，然后，函数更新在文本域 MyFirstText 中的字符串。</p><p>在命令窗口中键入 MyFirstGUI，运行产生的程序。当用户单击这个按钮时，<strong>MATLAB</strong> 就会自动调用带有参数 MyFirstButton_Callback 的函数 MyFirstGUI。然后函数 MyFirstGUI 就会子函数MyFirstButton_Callback。这个函数就把变量 count 加 1，并把这个值显示在文本域中。三次单击产生的用户图形界面如图图 10.10 所示。</p><p>用 guide 对一个新的用户图形界面进行布局，并用属性编辑器对每一个组件的初始属性进行设置，例如显示在组件上的文本，组件的颜色，还有回叫函数的名字。</p><p>用 guide 创建完一个用户图形界面后，人工编辑产生的函数，增加注释，描述这个函数的目的和组件，执行回叫函数的代码。</p><p><img src="/medias/20200619155440693.png" alt="图 10.9"></p><p><img src="/medias/20200619155600078.png" alt="图 10.10 在三次单击按钮之后产生的程序"></p><h5 id="10-2-1-盖头下的一瞥">10.2.1   盖头下的一瞥</h5><p>图 10.8 显示的 M 文件可以由 guide 为 MyFirstGUI 产生的。我们现在更加细致地检查这个 M 文件，以了解它是如何工作的。</p><p>首先，让我们看一下这个函数是如何声明的。注意这个函数用 vararign 来代表它的输入参数，用 varargout 代表它的输出结果。正如我们在第七章学到的，函数 varagin 能代表任意数目的输入参数，函数 varargout 能代表可变数目的输出参数。所以，用户可以用任意数目的参数调用函数 MyFirstGUI。</p><ul><li>无参数 M 文件的调用</li></ul><p>如果用户调用无参数函数 MyFirstGUI，由 nargin 返回的值将为 0。在这种情况下，程序用函数 openfig 从图象文件 MyFirstGUI。fig 中加载用户图形界面。这个函数的形式为</p><pre><code class="highlight plaintext">fig = openfig(mfilename, 'reuse');</code></pre><p>其中 mfilename 是指所要加载的图象文件的名字。第二个参数用于指定是一个拷贝运行指定的次数，或指定同时运行多个拷贝。如果这个参数是"reuse"，那么这个图象窗口只能有一个窗口在运行，如果调用带有 “reuse” 参数的函数 openfig，而且指定的图象窗口已经存了， 那么原来的窗口将会被置于屏幕的顶端并被重复利用。相反地，如果这个参数为"new"，那么这个函数的多个拷贝就可以运行。如果调用带有 “reuse” 参数的函数 openfig，那么每一次运行都会创建一个新的拷贝。默认地，用 guide 创建的用户图形界面是参数 “reuse”，所以无论在什么时侯，图象窗口只会有一个拷贝。如果你想有多个用户图形界面，你必须人工更改函数的参数。</p><p>在图象窗口被加载之后，函数将会执行下面的语句</p><pre><code class="highlight plaintext">set(fig, 'Color', get(0, 'defaultUicontrolBackgroundColor'));</code></pre><p>这个函数用于设置图象窗口的背景色，当 <strong>MATLAB</strong> 运行时，背景色就是计算机默认的背景色。这个函数把这个用户图形界面的颜色设置为计算机本地窗口的颜色。所以在 windows 操作系统上编写的用户图形界面，也可以用在 UNIX 系统的计算机上，反之亦然。在不同的操作系统下，看起来非常的自然。</p><p>下面的两个语句创建了一个结构，这个结构的元素为当前窗口中所有对象的句柄，这两个语句把这个结构当作应用程序数据来存储。</p><pre><code class="highlight plaintext">handles = guihandles(fig); guidata(fig, handles);</code></pre><p>函数 guihandles 创建了一个结构，这个结构的元素为指定窗口中所有对象的句柄。结构的每一个元素的名字与组件的 Tag 属性相同，它的值就是每一个组件的句柄。例如在 MyFirstGUI 中返回的句柄结构为</p><pre><code class="highlight plaintext">&gt;&gt; handles = guihandles(fig)handles =figure1: 99.0005MyFirstText: 3.0021MyFirstButton: 100.0007</code></pre><p>在本图中有三个用户图形界面组件 图象窗口本身，一个文本域和一个按钮。函数 guidate 把句柄结构当作应用程序数据来存储，这里我们将用函数 setappdata（在第九章有介绍）。</p><p>如果有指定一个输出参数给 MyFirstGUI，那么在这里最后的一系列语将返回这个图象句柄给这个调用者。</p><pre><code class="highlight plaintext">if nargout &gt; 0varargout{1} = fig;end</code></pre><ul><li>带有参数的 M 文件的调用</li></ul><p>如果调用带有参数的函数 MyFirstGUI，那么由 nargin 返回的值将会比 0 大。在这个种情况下，程序把第一个参数当做一个回叫函数的名字，并用 feval 执行这个函数。这个函数执行函数 naragin(1)，并把剩余的函数传递给这个函数。这种机制使子函数变为回叫函数， 而这个子函数不能直接被程序其他部分直接调用。</p><h5 id="10-2-2-一个响应子函数的结构">10.2.2   一个响应子函数的结构</h5><p>每一个调用子函数都有它的标准形式</p><p>function varargout = ComponentTag_Callback(h, eventdata, handles, varargin)</p><p>其中 ComponentTag 是产生响应的组件的名字(在 Tag 属性中的字符串)。子函数的参数</p><p>为。</p><ol><li><p>h  ——   父图象的句柄</p></li><li><p>eventdata   ——  当前不用的数组</p></li><li><p>handles  —— 由所有组件句柄构成的结构</p></li><li><p>varargin   ——  对回叫函数的增补函数。如果程序员需要的话，可以利用这个特性为回叫函数提供更多的附加信息。</p></li></ol><p>注意每一个回叫函数都用全部的权限访问 handles 结构，所以每一个回叫函数可以修改图象文件中的每一个用户图形界面组件。我们可以可以充分利用按钮的回叫函数的结构，其中按钮的回叫函数修改了在文本域中所要显示的文本。</p><pre><code class="highlight plaintext">% Update the text fieldset (handles.MyFirstText, 'String', str);</code></pre><h5 id="10-2-3-给图象增加应用程序数据">10.2.3   给图象增加应用程序数据</h5><p>应用程序需要把应用程序指定的信息存储到 handles 结构中，而不存储到全局内存和持久内存中。产生的用户图形界面将更加的耐用，因为其他 <strong>MATLAB</strong> 程序不能突然更改全局用户图形界面数据，还因为多个相同的用户图形界面之间不相互冲突。</p><p>为了增加本地数据到 handles，在用 guide 创建了用户图形界面之后，我们必须人工地修改 M 文件。程序员，在调用应用数据到 guihandles 之后和到 guide 之前，添加应用到 handles 结构。例如，为了添加鼠标单击的次数 count 到 handles 结构中，我们将修改这个程序如下：</p><pre><code class="highlight plaintext">% Generate a structrue of handles to pass to callbacks handles = guihandles(fig);% Add count to the structure. handles.count = 0;% Store the structure guidata(fig, handles);</code></pre><p>当用到这个应用数据时，那么这个应用数据将会通过 handles 结构伟递给每一个回叫函数。用到 count 值的按钮回叫函数如下所示。注意如要在结构中的任意一个信息被修改了， 那么我们必须把结构存储到guidata。</p><pre><code class="highlight matlab"><span class="function"><span class="keyword">function</span> <span class="title">varargout</span> = <span class="title">MyFirstButton_Callback</span><span class="params">(h, eventdata, handles, varargin)</span></span><span class="comment">% Update count</span>handles.count = handles.count + <span class="number">1</span>;<span class="comment">% Save the updated handles structure</span>guidata(h, handles);<span class="comment">%Create new string</span>str = sprintf(<span class="string">'Total Clicks: %d'</span>, handles.count);<span class="comment">% Update the text field</span>set (handles.MyFirstText, <span class="string">'String'</span>, str);</code></pre><p><strong>把 GUI 应用程序数据存储到 handles 结构中，以便任意的一个回叫函数都可以应用它。</strong></p><p><strong>如果你修改了 handles 结构中的任何 GUI 应用数据，确保在函数退出之削保存了调用 guidata 的结构。</strong></p><h5 id="10-2-4-一些有用的函数">10.2.4  一些有用的函数</h5><p>在设计回叫函数过程中有三种特殊函数经常被使用：gcbo，gcbf 和 findobj。虽然这些 函数在 <strong>MATLAB</strong> 6 GUIs 中的没有像以前版本那么频繁，它们还是非常有用，做为程序员， 肯定会碰到。</p><p>gcbo 函数（获得回叫对象）返回产生回叫函数的对象的句柄，gcbf 函数（获得回叫图形）返回包含该对象的图形的句柄。这些函数可以被回叫函数用来确定产生回叫的对象或图形，以便可以修改图形中的对象。</p><p>findobj 函数搜索父对象中的所有子对象，查找那些指定属性具有特定值的对象，它返回任何特征匹配的对象的句柄。findobj 最常用的格式是</p><pre><code class="highlight plaintext">Hndl = findobj(parent, ' Property', Value');</code></pre><p>其中 parent 是父对象（如图形）的句柄，Property 是要检查的属性，而 Value 是要查找的值。</p><p>例如，假设程序员要更改名称（tag）为“Button1”的按钮的文字，该程序可能先查找这个按钮，然后用下面的语句替换该文字：</p><pre><code class="highlight plaintext">Hndl = findobj(gcbf, 'Tag', 'Button1'); set (Hndl, 'String', 'New text');</code></pre><h4 id="10-3-对象属性">10.3 对象属性</h4><p>每个 GUI 对象都包含一系列可以自定义该对象的扩展属性，各种类型的对象（如图形、坐标轴，uicontrols 控件等）之间只有轻微的差别，所有类型的对象的所有属性都可以通过帮助浏览器在线找到它们的介绍文档，但是图形对象和 uicontrols 控件的一些较重要属性在表 10.2 和表 10.3 中粗略列出。</p><p>对象的属性值可以通过使用对象检查器或者是使用 get 和 set 函数进行修改，虽然对象检查器在 GUI 设计过程中可以很方便的修改属性，我们必须在程序运行过程中使用 set 和 get 函数动态地修改属性值，例如在回叫函数中进行修改。</p><p><strong>表 10.2 图形的重要属性</strong></p><table><thead><tr><th>属性</th><th>描述</th></tr></thead><tbody><tr><td>SelectionType</td><td>设定鼠标在图形上的最后一次击键时选择的类型。单击返回“normal”，双击返回“open”。还有一些附加选项，请查阅 <strong>MATLAB</strong> 在线文档</td></tr><tr><td>Tag</td><td>图形的名称，可以用来选中定位图形</td></tr><tr><td>Units</td><td>用来描述图形位置的单位，可选的值为“inches”、“centimeters”、 “normalized” ，“points”、“pixels”或 “characters”。默认为“pixels”</td></tr><tr><td>Visible</td><td>设定图形是否可见，可选值为“on”或“off”</td></tr><tr><td>WindowStyle</td><td>设定图形风格是普通的还是模式的（参阅对话框的讨论），可选的值为 “normal” 或 “modal”</td></tr></tbody></table><p><strong>表 10.3 uicontrol 控件的重要属性</strong></p><table><thead><tr><th>属性</th><th>描述</th></tr></thead><tbody><tr><td>BackgroundColor</td><td>设定对象的背景颜色。值要么是预定义的颜色如“r”、“g”或“b”，要么是一个有 3 个元素的向量，这 3 个元素分别代表红、绿和蓝，范围从 0-1 之间。比如洋红色为[1 0 1]</td></tr><tr><td>Callback</td><td>设定对象被键盘或文本输入激活时被叫函数的名称和参数</td></tr><tr><td>Enable</td><td>设定对象是否可选，如果不能，则对鼠标或键盘输入没有响应。可选值为“on”或“off”</td></tr><tr><td>FontAngle</td><td>设定在对象上显示的字符串的角度，可选值为“normal”，“italic”和 “oblique”</td></tr><tr><td>FontName</td><td>设定对象上显示的字符串的字体名称</td></tr><tr><td>FontSize</td><td>设定对象上显示的字符串的字号大小。默认是单位是 points</td></tr><tr><td>FontWeight</td><td>设定对象上显示的字符串的字体粗细，可选值为 “light” 、“normal” 、“demi” 和 “bold”</td></tr><tr><td>ForegroundColor</td><td>设定对象的前景色</td></tr><tr><td>HorizontalAlignment</td><td>设定对象中的字符串的水平对齐情况，可选值为“left”、“center”和 “right”</td></tr><tr><td>Max</td><td>设定对象 value 属性的最大值</td></tr><tr><td>Min</td><td>设定对象 value 属性的最小值</td></tr><tr><td>Parent</td><td>包含本对象的图形的句柄</td></tr><tr><td>Position</td><td>设定图形在屏幕上的位置，单位为“units”。这个值接受一个 4 元素的向量，前 2 个元素表示对象相对于图形在左下角的 x 和 y 坐标。而后 2 个元素则表示对象的宽和高</td></tr><tr><td>Tag</td><td>对象的名称，可以用来选中定位对象</td></tr><tr><td>TooltipString</td><td>设定鼠标光标指到该对象时显示的帮助文本</td></tr><tr><td>Units</td><td>来描述图形位置的单位，可选的值为“inches”、“centimeters”、 “normalized”，“points”、“pixels”或“characters”。默认为“pixels”</td></tr><tr><td>Value</td><td>uicontrol 控件的当前值。对开关按钮、复选按钮和单选按钮来说，选中时，这个值为 max，没有选中时值为 min。对其它控件来说有不同的意义</td></tr><tr><td>Visible</td><td>设定对象是否可见。可选值为“on”或“off”</td></tr></tbody></table><h4 id="10-4-图形用户界面组件">10.4 图形用户界面组件</h4><p>本节概述了常见图形用户界面组件的基本特性，讨论了如何创建和使用每种组件，同时也讨论了每种组件能产生的事件类型。本节讨论的组件有：</p><ul><li><p>文本域</p></li><li><p>编辑框</p></li><li><p>框架</p></li><li><p>按钮</p></li><li><p>开关按钮</p></li><li><p>复选按钮</p></li><li><p>单选按钮</p></li><li><p>下拉菜单</p></li><li><p>列表框</p></li><li><p>滑动条</p></li></ul><h5 id="10-4-1-文本域-Text-Fields">10.4.1   文本域(Text Fields)</h5><p>文本域是显示文本的图形对象，可以通过设定文本域的水平对齐属性改变显示文本时的对齐方式，创建时默认是水平居中。文本域是通过创建风格为“edit”的 uicontrol 控件来创建的。可以通过使用版面编辑器中的文本域工具）把文本域添加到 GUI 中。</p><p>文本域并不产生回叫，不过文本域中显示的文本可以在回叫函数中通过设定 String 属性来更改，如 10.2 节所示。</p><h5 id="10-4-2-编辑框-Edit-Boxes">10.4.2   编辑框(Edit Boxes)</h5><p>编辑框是允许用户输入文本的图形对象，当用户在文本框中输完文本后按回车 Enter 时会产生回叫。文本域是通过创建风格为“edit”的 uicontrol 控件来创建的。可以通过使用版面编辑器中的编辑框工具  ）把编辑框添加到 GUI 中。</p><p>如图 10.11a 所示，该图是一个简单的 GUI，包含了名为“EditBox”的编辑框和名为“TextBox”的文本域各一个。当用户在编辑框中输入字符串后，它将自动调用 EditBox_Callback 函数，如图 10.11b 所示。这个函数使用 handles 结构定位编辑框获得用户的输入内容，然后再定位文本域并把字符串在文本域中显示出来。图 10.12 显示了 GUI 启动之后用户刚刚在编辑框中输入“Hello”后的情况。</p><p><img src="/medias/20200619163026295.png" alt="（a）"></p><pre><code class="highlight plaintext">function EditBox_Callback(hObject, eventdata, handles)% Find the value typed into the edit boxstr = get ( handles.EditBox,'String');% Place the value into the text fieldset (handles.TextBox,'String', str);</code></pre><p>​               图10.11 (a)只有一个编辑框和文本域的布局(b) GUI 的回叫函数</p><p><img src="/medias/20200619163425639.png" alt="图10.12(a)由程序test_edit产生的 GUI(b)用户输入Hello并回车后的GUI"></p><h5 id="10-4-3-框架-Frames">10.4.3   框架(Frames)</h5><p>框架是在 GUI 界面上显示一个矩形框，你可以把逻辑上相联系的对象用框架框起来。如图 10.1 所示，框架可以把一组单选按钮组合起来。</p><p>框架是通过创建风格为“frame”的 uicontrol 控件来创建的。可以通过使用版面编辑器中的框架工具）把框架添加到 GUI 中。框架不会产生回叫。</p><h5 id="10-4-2-按钮-Pushbuttons">10.4.2   按钮(Pushbuttons)</h5><p>按钮是当用户在其上面单击时能触发特定行为的一种组件。当用户用鼠标在其单击时， 按钮会产生回叫。按钮是通过创建风格为“pushbutton”的 uicontrol 控件来创建的。可以通过使用版面编辑器中的按钮工具）把按钮添加到 GUI 中。</p><p>图 10.10 中的 MyFirstGUI 函数演示了如何使用按钮</p><h5 id="10-4-3-开关按钮-Toggle-Buttons">10.4.3   开关按钮(Toggle Buttons)</h5><p>开关按钮是有两种状态的一类按钮：on（被按下去）和 off（没有被按下去）。当鼠标单时，开关按钮在两种状态之间切换，并且每次都产生回叫。当开关按钮为 on（被按下去） 时，“Value”属性的值被设为 max（通常是 1），当为 off（没有被按下去）时，“Value”属性的值被设为 min（通常是 0）。</p><p>开关按钮是通过创建风格为“Togglebutton”的 uicontrol 控件来创建的。可以通过使用版面编辑器中的开关按钮工具）把开关按钮添加到 GUI 中。</p><p>图 10.13 (a) 是一个含有开关按钮（名为“ToggleButton”）和文本域（名为“TextBox”）的简单 GUI。当用户在开关按钮上单击时，将自动调用 ToggleButton_Callback 函数（如10.13 (b) 所示）。这个函数使用 handles 结构定位开关按钮并从“Value”属性获得按钮的状态， 然后再定位文本域并把按钮状态在文本域中显示出来。图 10.14 显示了 GUI 启动之后用户刚刚在开关按钮上单击后的情况。</p><p><img src="/medias/20200619163839214.png" alt="图 10.13 (a)"></p><pre><code class="highlight plaintext">% (b)function ToggleButton_Callback(hObject, eventdata, handles)% Find the state of the toggle buttonstate = get(handles.ToggleButton,'Value');% Place the value into the text fieldif state == 0set(handles.TextBox,'String','Off');elseset(handles.TextBox,'String','On');end</code></pre><p><strong>图 10.13 (a)含有一个开关按钮和文本域的简单 GUI 布局 (b)本 GUI 的回叫函数</strong></p><p><img src="/medias/20200619164112901.png" alt="图10.14(a)由程序test_toggle产生的当开关按钮为off时的GUI(b)开关按钮为on时的GUI"></p><h5 id="10-4-6-复选和单选按钮-Checkboxes-and-Radio-Buttons">10.4.6 复选和单选按钮(Checkboxes and Radio Buttons)</h5><p>复选和单选按钮在本质上是与开关按钮一样的，除了它们的外观不同之外。与开关按钮一样，复选与单选按钮有两种状态：on 和off。当鼠标单击时，按钮会在两种状态之间切换， 每次产生回叫。当按钮状态为 on 时，复选或单选按钮的“Value”被设为 max（通常为 1），当按钮状态为 off 时，“Value”值被设为 min（通常为 0）。复选与单选按钮的形状如图 10.1所示。</p><p>复选按钮是通过创建风格为“checkbox”的 uicontrol 控件来创建的，而单选按钮则是通过创建风格为 “radiobutton” 的 uicontrol 控件来创建的。可以通过使用版面编辑器中的复选</p><p>按钮工具把复选按钮添加到 GUI 中，可以通过使用版面编辑器中的单选按钮工具把单选按钮添加到 GUI 中。</p><p>复选按钮通常用来作为“开/关”选择，而单选按钮通常用在一组排它性选项中选一。</p><p>图 10.15(a)演示了如何用单选按钮创建一组排它性选项。这个图形的 GUI 创建了三个单选按钮，标为“Option 1”、“Option 2”和“Option 3”，每个单选按钮拥有独自的参数，使用相同的回叫函数。</p><p>相应的回叫函数如图 10.15 (b) 所示。当用户单击一个单选按钮时，相应的回叫函数被执行，函数在文本框中显示当前选项同，选中相应在的单选按钮，并把其它单选按钮设为未选状态。</p><p>注意 GUI 使用框架把单选按钮组合到一起，使它们看起来更像是一组。图 10.6 显示了“Option 2”被选中后的情况。</p><p><img src="/medias/20200619164415903.png" alt="图 10.15(a)"></p><pre><code class="highlight plaintext">% (b)% --- Executes on button press in radiobutton1.function radiobutton1_Callback(hObject, eventdata, handles)set (handles.Label1,'String','Option 1');set (handles.radiobutton1,'Value',1);set (handles.radiobutton2,'Value',0);set (handles.radiobutton3,'Value',0);% --- Executes on button press in radiobutton2.function radiobutton2_Callback(hObject, eventdata, handles)set (handles.Label1,'String','Option 2');set (handles.radiobutton1,'Value',0);set (handles.radiobutton2,'Value',1);set (handles.radiobutton3,'Value',0);% --- Executes on button press in radiobutton3.function radiobutton3_Callback(hObject, eventdata, handles)set (handles.Label1,'String','Option 3');set (handles.radiobutton1,'Value',0);set (handles.radiobutton2,'Value',0);set (handles.radiobutton3,'Value',1);</code></pre><p><img src="/medias/20200619164552859.png" alt="图 10.15 (c)"></p><h5 id="10-4-7-下拉菜单-Popup-Menus">10.4.7 下拉菜单(Popup Menus)</h5><p>下拉菜单允许用户选择一组排它性列表选项中的一项。用户可以选择的列表选项是由一个字符串胞数组指定的。“Value”属性的值指示了当前哪个字符串被选中。下拉菜单可以通过版面编辑器上的下拉菜单工具）添加到 GUI 中。</p><p>图 10.17 (a) 是一个使用下拉菜单的例子。图形中的 GUI 创建了有五个选项的下拉菜单， 依次标为“Option 1”、“Option 2”……</p><p>相应的回叫函数如图 10.17 (b) 所示。回叫函数通过检查菜单“Value”参数的值取得当前选中项，然后在文本域中显示含有“Value”值的文字。</p><p><img src="/medias/20200619164720683.png" alt="图 10.17 (a)"></p><pre><code class="highlight plaintext">% (b)% --- Executes on selection change in Popup1.function Popup1_Callback(hObject, eventdata, handles)% Find the value of the popup menuvalue = get(handles.Popup1,'Value');% Place the value into the text fieldstr = ['Option ' num2str(value)];set (handles.Label1,'String',str);</code></pre><p><strong>图 10.17(a)含有下拉菜单和用未显示当前选择的项的文本域GUI布局 (b)本GUI的回叫函数</strong></p><p><img src="/medias/20200619164925084.png" alt="图10.18由程序test_popup产生的GUI"></p><h5 id="10-4-8-列表框-List-Boxes">10.4.8 列表框(List Boxes)</h5><p>列表框可以显示多行文本并允许用户选择其中一行或多行的图形对象，如果文本的行数比刚好填满列表框还要多，则将会在列表框中出现滑动条以便用户可以上下滚动列表项。用户能够选择的文本行由一字符串胞数组指定，“Value”属性的值指示了当前哪些字符串被选中。</p><p>列表框由风格属性为“listbox”的 uicontrol 创建，用户可以使用版面编辑器中的列表框工具把它添加到 GUI 中。</p><p>列表框可以用来从几个可能选项中选项其中的一项。在平常的 GUI 使用中，在列表框中单击选择某项并不产生动作，而是要等到某些外部触发器（如按钮）来产生动作。不过， 鼠标双击通常立即产生动作。可以通过设置图形对象的 SelectionType 属性的不同使单击与双击事件有差异：单击设置为“normal”，双击设置为“open”。</p><p>有时也允许列表框多选。如果 max 属性值与 min 属性值的差大于 1，那么就允许多选， 否则则仅允许单选。</p><p>图 10.19(a) 是列表框仅允许单选的例子。图形中的 GUI 创建了有八个选项的列表框，这八项分别标为“Option 1”、“Option 2”……“Option 8”。此外，GUI 创建了一个按钮用来完成选择并显示选项。列表框和按钮都会产生回叫。</p><p>相应的回叫函数如图 10.19(b) 所示。如果列表框中的项被选中，则函数 ListBox1_Callback 将会被执行，这个函数会检查产生回叫的图形（使用 gcbf 函数），看看选择动作是单击还是双击，如果是单击，则什么也不做，双击则取得列表框中的选中值，然后在文本域中显示适当的文字。</p><p>如果是按钮被选中，则执行 Button1_Callback 函数，取得列表框中的选中值，然后在文本域中显示适当的文字。程序 test_listbox 创建的 GUI 如图 10.20 所示。</p><p>在本章练习中，你将会被要求修改本例，使得列表框可以复选。</p><p><img src="/medias/20200619165159929.png" alt="图 10.19(a)"></p><pre><code class="highlight plaintext">% (b)% --- Executes on button press in Button1.function Button1_Callback(hObject, eventdata, handles)% Find the value of the popup menuvalue = get (handles.Listbox1,'Value');%Update text lablestr = ['Option ' num2str(value)];set (handles.Label1,'String',str);% --- Executes on selection change in Listbox1.function Listbox1_Callback(hObject, eventdata, handles)% if this was a double click,update the label.selectiontype = get(gcbf,'SelectionType');if selectiontype(1) == 'o'    % Find the value of the popup menu    value = get(handles.Listbox1,'Value');    %Update text label    str = ['Option ' num2str(value)];    set(handles.Label1,'String',str);end</code></pre><p><strong>图 10.19 (a)放置列表框、按钮和文本域的界面 (b)本 GUI 的回叫函数，注意单击选择和双击选择都能引发回叫</strong></p><p><img src="/medias/20200619165321305.png" alt="图10.20程序test_listbox产生的GUI"></p><h5 id="10-4-9-滑动条-Sliders">10.4.9 滑动条(Sliders)</h5><p>滑动条是允许用户通过用鼠标移动滑块来在最大值和最小值之间选择一个值的一种图形对象。设置到“Value”中的值在 min 和 max 之间，具体取决于滑块的位置。</p><p>滑动条是由风格为“slider”的 uicontrol 控件创建的。可以通过版面编辑器中的滑动条工具把滑动条添加到 GUI 中。</p><p>图 10.21(a) 是版面放置了一个滑动条和一个文本域的情况，滑动条的“min”（最小值）属性设为 0，“max”（最大值）属性设为 10。当用户拖动滑块时，将自己调用 Slider1_Callback函数（如图 10.21(b) 所示），这个函数从滑动条的“Value”属性取得当前值并把它显示在文本域中。图 10.22 滑块在 max 和 min 范围内某个值的情况。</p><p><img src="/medias/20200619165506876.png" alt="图 10.21(a) "></p><pre><code class="highlight plaintext">% (b)% --- Executes on slider movement.function Slider1_Callback(hObject, eventdata, handles)% Find the value of the slidervalue = get(handles.Slider1,'Value');% Place the value in the text fieldstr = sprintf('%.2f',value);set (handles.Label1,'String',str);</code></pre><p><strong>图10.21(a)带有滑动条和文本域的简单界面 (b)本GUI的回叫函数</strong></p><p><img src="/medias/20200619165650356.png" alt="图10.22由程序test_slider产生的GUI"></p><h6 id="例-10-1-温度转换">例 10.1 温度转换</h6><p><img src="/medias/20200619165842443.png" alt=""></p><p><img src="/medias/20200619165910759.png" alt="图 10.23 温度转换 GUI 界面布局"></p><p>第二步是创建函数把华氏温度转换成摄氏温度。函数 to_c 把华氏温度转换成摄氏温度，它必须以下面的公式计算</p><p><img src="/medias/20200619170020719.png" alt=""></p><p>这个函数的代码是：</p><pre><code class="highlight plaintext">function deg_c = to_c(deg_f)% Convert degrees Fahrenheit to degrees C.deg_c = (5/9) * (deg_f - 32);</code></pre><p>函数 to_f 把摄氏温度转成成华氏温度，用下在的公式计算</p><img src="/medias/20200619170107656.png" style="zoom:70%;"><p>这个函数的代码如下：</p><pre><code class="highlight plaintext">function deg_f = to_f(deg_c)% Convert degrees Celsius to degrees Fahrenheitdeg_f = (9/5) * deg_c + 32;</code></pre><p>最后，我们必须编写回叫函数把它绑在一起。这些函数必须能对三个按钮作出反应。（注意我们既要难对用户在编辑框的输入做出更新，也要以一致的格式来显示数据，同时，如果用户输入的值落在允许范围之外，还必须能够更正它。）</p><p>这里还有另外一个因素要考虑：我们在编辑框中输入的值是字符串 strings，但我们要以数字来对待它。如果用户在编辑框输入 100，则实际上得到的是字符串“100”，并不是数字 100。回叫函数必须把字符串转换成数字，以便用来计算。这种转换用 str2num 函数来完成， 它把字符串转换成数字。</p><p>同时，</p><p>回叫函数必须限制用户输入的值在有效范围之内，即 0-100ºC 和 32-212ºF 之间。</p><p>回叫函数如图下：</p><pre><code class="highlight plaintext">%  温度转换 GUI 的回叫函数function Edit1_Callback(hObject, eventdata, handles)% Update all temperature valuedeg_f = str2num(get(hObject,'String'));deg_f = max([32 deg_f]);deg_f = min([212 deg_f]);deg_c = to_c(deg_f);% Now update the fieldsset (handles.Edit1,'String',sprintf('%.1f',deg_f));set (handles.Edit2,'String',sprintf('%.1f',deg_c));set (handles.Slider1,'Value',deg_c);function Edit2_Callback(hObject, eventdata, handles)% Update all temperature valuedeg_c = str2num(get(hObject,'String'));deg_c = max([0 deg_c]);deg_c = min([100 deg_c]);deg_f = to_f(deg_c);% Now update the fieldsset (handles.Edit1,'String',sprintf('%.1f',deg_f));set (handles.Edit2,'String',sprintf('%.1f',deg_c));set (handles.Slider1,'Value',deg_c);% --- Executes on slider movement.function Slider1_Callback(hObject, eventdata, handles)% Update all temperature valuesdeg_c = get(hObject,'Value');deg_f = to_f(deg_c);% Now update the fieldsset (handles.Edit1,'String',sprintf('%.1f',deg_f));set (handles.Edit2,'String',sprintf('%.1f',deg_c));set (handles.Slider1,'Value',deg_c);</code></pre><h4 id="10-5-对话框">10.5 对话框</h4><p>对话框是一种通常用来显示信息或从用户处获得输入的特殊图形，对话框通常用来显示出错、提供警告、提问问题或获取输入。它们也用来选取文件或打印机属性。</p><p>对话框可以是有模式的或无模式的。模式对话框在它消失之间不允许程序中的其它窗口被访问，而无模式对对话框则不存在这些限制。模式对话框典型的应用是用来显示错误或警告，而这些信息通常是需要引起重视，不可忽略的。默认地，大多数对话框是无模式的。</p><p><strong>MATLAB</strong> 包含了很多类型的对话框，大多数对话框已经在表 10.4 中列出。这里我们只讨论其中的几种，关于其它对对话框的内容请参阅 <strong>MATLAB</strong> 在线文档。</p><p><strong>表 10.4 挑选的对话框</strong></p><table><thead><tr><th>属性</th><th>描述</th></tr></thead><tbody><tr><td>dialog</td><td>创建一个通用对话框</td></tr><tr><td>errordlg</td><td>在对话框中显示错误信息，用户必须点击 OK（确定）按钮才能继续</td></tr><tr><td>helpdlg</td><td>在对话框中显示帮助信息，用户必须点击 OK（确定）按钮才能继续</td></tr><tr><td>inputdlg</td><td>显示需要输入数据，并接受输入的数据</td></tr><tr><td>printdlg</td><td>显示打印机选择对话框</td></tr><tr><td>questdlg</td><td>提问。这种对话框可以包含二到三个按钮，默认是 Yes（是），No（否）和 Cancel（取消）</td></tr><tr><td>uigetfile</td><td>显示打开文件对话框。这类对话框允许用户选择要打开的文件，但并不打开文件</td></tr><tr><td>uiputfile</td><td>显示保存文件对话框。这类对话框允许用户选择要保存的文件，但并不保存文件</td></tr><tr><td>uisetcolor</td><td>显示颜色选择对话框</td></tr><tr><td>uisetfont</td><td>显示字体选择对话框</td></tr><tr><td>warndlg</td><td>在对话框中显示警告信息，用户必须点击 OK（确定）按钮才能继续</td></tr></tbody></table><h5 id="10-5-1-错误和警告对话框">10.5.1 错误和警告对话框</h5><p>​        错误与警告对话框有相似的调用参数与行为，实际上，这两种对话框仅仅是显示的图标不同而已。最常见的调用格式如下：</p><pre><code class="highlight plaintext">errordlg(error_string,box_title,create_mode); warndlg(warning_string,box_title,create_mode);</code></pre><p>其中 error_string 或 warning_string 就是要显示给用户的信息，box_title 是对话框的标题，create_mode 可以是“modal”或“non_modal”，这取决于你要何种对话框。</p><p>例如，下面的语句创建一个用户无法忽略的模式对话框，这个语句产生的对话框如图10.25 所示。</p><p>errordlg(‘Invalid ipnut values!’,‘Error Dialog Box’,‘modal’);</p><p><img src="/medias/20200619173654765.png" alt="图 10.25 错误对话框"></p><h5 id="10-5-2-输入对话框">10.5.2   输入对话框</h5><p>输入对话框提示用户输入程序需要的一个或多个值，可以用下面格式创建：</p><pre><code class="highlight plaintext">answer = inputdlg(prompt) answer = inputdlg(prompt, title)answer = inputdlg(prompt, title, line_no)answer = inputdlg(prompt, title, line_no, default_answer)</code></pre><p>这里的 prompt 是一个字符串数组，数组的每个元素就是要求用户回答的问题，title 指定对话框的标题，line_no 限定用户输入的行数，最后，default_answer 是一个胞数组 包含了具体某个问题用户没有回答时的默认答案。注意有多少个问题，就必须提供多少个默认答案。</p><p>当用户单击对话框上的 OK 按钮时，答案将在字符串胞数组的形式保存到变量 answer 中。</p><p>作为输入对话框的例子，假设我们要用输入对话框允许用户指定图形的位置，下面的代码将能做到：</p><pre><code class="highlight plaintext">prompt{1} = 'Starting x position:'; prompt{2} = 'Starting x position:'; prompt{3} = 'Starting x position:'; prompt{4} = 'Starting x position:'; title = 'Set Figure Position'; default_ans = {'50', '50', '180', '100'};default = inputdlg(prompt,title,1,default_ans);</code></pre><p>结果如图 10.26 所示:</p><p><img src="/medias/20200619180501095.png" alt="图 10.26 输入对话框"></p><h5 id="10-5-3-打开与保存对话框">10.5.3   打开与保存对话框</h5><p>uigetfile 和uisetfile 对话框是设计用来允许用户交互地选择要打开或保存的文件，这些对话框返回文件名及路径，但并不实际读取或保存它。程序员负责写额外的代码。</p><p>这两个对话框的形式如下：</p><pre><code class="highlight plaintext">[filename, pathname] = uigetfile(filter_spec, title); [filename, pathname] = uisetfile(filter_spec, title);</code></pre><p>参数 filter_spec 是指定在对话框中显示的文件类型的字符串，如“<em>.m”、“</em>.mat”等等。参数 title 指定对话框的标题。对话框执行后，filename 包含了所选择的文件名，而 pathname 包含了文件的路径。如果取消对话框，则 filename 被设为 0。</p><p>下面的脚本文件演示了如何使用这些对话框，它提示用户输入 MAT 文件名，读取文件的内容，图 10.27 是在 Windows Xp 系统中运行的结果（不同的操作系统显示的界面会有不同）。</p><pre><code class="highlight plaintext">[filename, pathname] = uigetfile('*.mat', 'Load MAT File'); if filename ~= 0load([pathname filename]);end</code></pre><p><img src="/medias/20200619180724611.png" alt="图 10.27 Windows xp 系统下 uigetfile 的打开文件对话框"></p><p><strong>在基于GUI编程中，使用对话框来提供信息或要求输入数据，如果信息紧迫且不可忽略，则把对话框设为模式对话框。</strong></p><h4 id="10-6-菜单">10.6 菜单</h4><p>菜单也可以添加到 <strong>MATLAB</strong> 的 GUI 中。使用菜单可使 GUI 显示界面上没有附加组件用户即可选择行动。</p><p><strong>MATLAB</strong> 中有两种菜单：在图形界面顶部的菜单栏下拉的<strong>标准菜单</strong>与在某对象上右击的弹出的<strong>上下文菜单</strong>。本节我们将学习如何创建这两类菜单。</p><p>标准菜单是由 uimenu 对象创建的，菜单中的每一项及子菜单都是一个独立的 uimenu 对象，这些 uimenu 对象与 uicontrol 对象相似，有许多相同的属性，例如 Parent，Callback，Enable 等等，一些 uimenu 较重要的属性在表 10.5 中列出。</p><p><strong>表 10.5 重要的 uimenu 属性</strong></p><table><thead><tr><th>属性</th><th>描述</th></tr></thead><tbody><tr><td>Accelerator</td><td>指定键盘上某个字符与该菜单项相当，用户可以使用键盘组合键 CTRL + key 激活该项</td></tr><tr><td>Callback</td><td>设定该菜单项激活时调用的函数的名称与参数。如果该项是一个子菜单，则该函数在子菜单显示之前执行;如果该项没有子菜单，则该函数在鼠标释放时执行</td></tr><tr><td>Checked</td><td>如果该项为 on，则在该项左边会有一个选择标记，这种属性可以用来指示菜单项在两种状态之间转换在情况，可选值为“on” 和“off”</td></tr><tr><td>Enable</td><td>设定该菜单项是否可选，如果不能，则不会对任意鼠标单击与键盘加速键做出响应，可选值为“on”或“off”</td></tr><tr><td>Label</td><td>设定在菜单项上显示的文本，可以用“&amp;”符号指定本项的键盘助记键盘并在菜单上显示出来。例如，字符串“&amp;File”将在菜单上显示“File”并对F 键作出响应</td></tr><tr><td>Parent</td><td>本菜单项的父对象的句柄。父对象可以是一个图形或另一个菜单项</td></tr><tr><td>Position</td><td>设定菜单项在菜单栏或菜单上的位置，1 代表在顶级菜单中的最右边或在子菜单中的最上边</td></tr><tr><td>Separator</td><td>如果属性为“on”，则在这项上画一条分隔线，可选的值为“on”或“off”</td></tr><tr><td>Tag</td><td>菜单项的名称，可用来定位菜单项</td></tr><tr><td>Visible</td><td>设定本菜单项是否可见，可选值为“on”或“off”</td></tr></tbody></table><p>每个菜单项都是都隶属于某个父对象，而图形本身是一个最顶端的菜单。所有的隶属于同一父对象的 uimenus 显示在相同的菜单上，各项叠起来形成一个树形子菜单。图 10.28 （a） 显示了运行中的一个典型<strong>MATLAB</strong> 菜单，而图10.28 （b） 显示了组成该菜单的各项之间的关系。</p><p><img src="/medias/20200619181515189.png" alt="图 10.28 （a）"></p><p>​                   <img src="/medias/20200619181639681.png" alt="图10.28 （b）"></p><p><img src="/medias/20200619181808974.png" alt="图 10.28 (c)"></p><p><strong>图10.28(a)典型的菜单结构 (b)创建菜单的 uimenu 项之间的关系 ©菜单编辑器中的结构</strong></p><p><strong>MATLAB</strong> 使用菜单编辑器创建菜单，可以通过上界面编辑器向导顶端图标打开。</p><p>图 10.28c 显示了产生菜单上各项的结构。附加属性在表 10.5 中列出。菜单编辑器可以用属性编辑器设置（propedit）。</p><p>顶级上下文菜单由 uicontextmenu 对象创建，上下文菜单中的下一级菜单项则由 uimenu 对象创建，上下文菜单基本上与标准菜单相同，除了可以隶属于任何对象（坐标轴，线条， 文本，图形等等）外。表 10.6 列出了 uicontextmenu 一些重要的属性。</p><h5 id="10-6-1-禁用默认菜单">10.6.1   禁用默认菜单</h5><p>每个 <strong>MATLAB</strong> 图形默认都会出现一组标准菜单，如果你要删除这些菜单并创建自己的菜单，首先就必须把默认菜单关闭掉，是否显示默认菜单是由图形的 Menubar 的属性控制的。或选值为“figure”和“none”。如果设为“figuire”，那么将显示菜单，如果设为“none”，默认菜单将会抑制。创建 GUIs 时你可以使用属性编辑器来设置。</p><p><strong>表 10.6 uicontextmenu 几个重要属性</strong></p><table><thead><tr><th>属性</th><th>属性</th></tr></thead><tbody><tr><td>Callback</td><td>设定上下文菜单激活时调用的函数的名称和参数。在菜单显示之前执行</td></tr><tr><td>Parent</td><td>上下文菜单的父对象的句柄</td></tr><tr><td>Tag</td><td>上下文菜单的名称，可以用来定位它</td></tr><tr><td>Visible</td><td>设定上下文菜单是否可见。这个属性会被自动设置，通常不需要修改</td></tr></tbody></table><h5 id="10-6-2-创建自定义菜单">10.6.2   创建自定义菜单</h5><p>为 GUI 创建自定义标准菜单基本上分三步处理：</p><ol><li><p>第一，在菜单编辑器中创建一个新的菜单结构。使用菜单编辑器定义结构，给每个菜单项填上 Label 标签和独一的 Tag 名称，同时也可以为菜单项手动创建回叫字符串，这需要些技巧  为菜单项创建回叫的最好办法是对 uicontrol 自动创建的回叫进行研究，并把它当成例子学习。uimenu 回叫字符串的正确形式如下：MyGui(‘MenuItemTag_Callback’, gcbo, [], guidata(gcbo));</p><p>这里你要把 MyGui 替换成你自己的 GUI 名称，把 MenuItemTag 设为菜单项的名称。</p></li><li><p>第二，使用属性编辑器（propedit）编辑每个菜单项的属性，最重要的几个需要设置的是 Callback，Label 和 Tag，这些都可以通过菜单编辑器进行设置，因此通常并不需要属性编辑器。当然，如果你要设置表 10.5 中列出的其它属性，就必须使用属性编辑器了。</p></li><li><p>第三，为菜单项编写代码实际回叫函数所必须完成的功能。你必须为菜单项手动创建回叫函数。</p></li></ol><p>在本章节末尾，将以一个例子演示创建菜单的过程。</p><p><strong>与GUI对象不同，MATLAB 并不自动为菜单项创建回叫字符串与存根，必须手动完成。</strong></p><p><strong>菜单项的属性中只有Label，Tag，Callback，Checked 和 Separator 等属性可以在菜单编辑器中设置，如果要设置其它属性，就必须使用图形中的属性编辑器，选择正确的菜单项进行编辑。</strong></p><h5 id="10-6-3-加速键与键盘助记键">10.6.3   加速键与键盘助记键</h5><p><strong>MATLAB</strong> 菜单支持键盘加速键与助记键。加速键是“CTRL+key”组合键，不需要先打开菜单就能使某菜单项执行。例如，加速键“o”可能分配给菜单中的“File/Open（文件/ 打开）”，如果这样，键盘组合键“CTRL+o”将会使“File/Open”项的回叫函数执行。</p><p>有一些组合键盘为操作系统所保留，因操作系统（PC 或 UNIX）而异，查阅 <strong>MATLAB</strong>在线文档，看看哪些组合键适合你的计算机。</p><p>加速键在 uimenu 对象的 Accelerator 属性中设定。</p><p>键盘助记键仅是一个字母，在菜单被打开后敲击该字母就会执行该菜单项。分配菜单项的助记键被加以下划线。如果是顶级菜单，则必须按住键盘的 ALT 键再同时按下该字母， 一旦顶级菜单已经打开，则只需敲击该字母就能执行该项。</p><p>图 10.29 演示了键盘助记键的使用。File（文件）菜单使用 ALT+f 打开，一旦菜单打开，只需敲“x”即可执行 Exit（退出）项。</p><p>助记键是通过在 Label 属性中的目标字母前面加上“&amp;”字符来定义的。“&amp;”不会被显示出来，后面是字符会被加以下划线，它就成了助记键。例如，图 10.29 中的 Exit（退出） 菜单项的 Label 属性值是“E&amp;xit”。</p><p><img src="/medias/20200619190824198.png" alt="图 10.29 通过 ALT+f 打开显示的菜单，要退出只需单击&quot;x&quot;即可"></p><h5 id="10-6-4-创建上下文菜单">10.6.4   创建上下文菜单</h5><p>上下文菜单与创建普通菜单的方式相同，除了顶级菜单项是一个 uicontextmenu 外。uicontextmenu 的父对象必须是一个图形。但上下文菜单也可以与任何图象对象绑定起来并对鼠标右键做出响应。上下文菜单通过在菜单编辑器选择“Context Menu”项来创建。一旦上下文菜单创建后，就可以在它下面创建任意数量的菜单项。</p><p>要把上下文菜单与特定对象绑定起来，你必须把对象的 UiContextMenu 属性设置成uicontextmenu 的句柄。这通常通过属性编辑器来完成，但也可以使用下面的 set 命令来做。假如 Hcm 是一个上下文菜单的句柄，下面的语句将把这个菜单与用 plot 命令创建的线条绑定起来。</p><pre><code class="highlight plaintext">H1 = plot(x,y);   set (H1, 'UIContextMenu',Hcm);</code></pre><p>在下面的例子中，我们创建一个上下文菜单，并把它与一个图对象联合起来。</p><h6 id="例-10-2-绘制数据点">例 10.2 绘制数据点</h6><p>编写程序，打开用户指定的数据文件，然后把文件中数据绘点画线。程序必须包含一个文件（File）菜单，有打开（Open）和退出（Exit）项，还必须包含一个绑定到线条上的上下文菜单，菜单的内容可以改变线条的风格。假设文件的数据是以（x，y）对的形式出现， 每行一对。</p><p>解决方案：</p><p>本程序必须包含一个有打开（Open）和退出（Exit）菜单项的标准菜单和一个用来绘制数据的坐标轴，也必须包含一个用来设定不同线条风格的上下文菜单，还必须把上下文菜单绑定到描绘的线条中，上下文菜单项中应该包含实线、虚线、点线和虚点线等风格。</p><p>创建本程序的第一步是使用向导创建所需要的 GUI，本例中界面只有一组坐标轴（见图10.30(a)）。然后，我们用菜单编辑器创建文件菜单，这个菜单包含了 Open（打开）和 Exit（退出）项，如图 10.30(b)。注意我们必须使用菜单编辑器设置 Label，Tag 和每个菜单项的 callback 字符串。还必须为 File（文件）指定助记键“F”，为 Open（打开）指定“O”及为 Exit（退出）指定“x”，并在 Exit 与 Open 之间设置分隔符，如图 10.30 所示。</p><p><img src="/medias/20200619183120815.png" alt="图10.30(C:/Users/hsiehchou/Desktop/MATLAB学习/20200619183120815.png)"></p><p><img src="/medias/20200619183156094.png" alt="图 10.30(C:/Users/hsiehchou/Desktop/MATLAB学习/20200619183156094.png)"></p><p><strong>图10.30(a) plot_line的界面 (b) 菜单编辑器中的文件菜单</strong></p><p><img src="/medias/20200619183255146.png" alt="图10.30 (C:/Users/hsiehchou/Desktop/MATLAB学习/20200619183255146.png)菜单编辑器中的上下文菜单"></p><p>下一步，我们采用菜单编辑器创建上下文菜单。这个菜单以 uicontextmenu 对象开始， 带有四个选项（如图 10.30c），同样，我们设置各项的 Label，Tag 和 callback 字符串。</p><p>到这里，我们把 GUI 保存为 plot_line.fig，plot_line.m 将被自动创建。然而，每项哑元回叫函数不会被自动创建，必须手工完成。</p><p>GUI 创建后，必须为菜单建立六个回叫函数。最难的回叫函数是 File/Open 菜单项的函数，这个回叫函数必须提示用户输入文件名（使用 uigetfile 对话框），打开文件，读取数据，把它保存到 x 和 y 数组中，最后关闭文件。接着，绘制线条，以应用程序数据保存线条句柄以便后面我们可以修改线条风格。最后，回叫函数必须把上下文菜单联结在一起。mFileOpen_Callback 函数如图 10.31 所示。注意函数使用对话框告知用户文件打开出错。</p><p>剩下的回叫函数相当简单，mFileExit_Callback 函数仅仅是关闭图形，线条风格函数仅仅设置线条风格。当用户鼠标在线条上面右击时，上下文菜单会弹出。如果用户从弹出的菜单选择一项，相应的回叫函数将使用保存的线条句柄更改属性。这五个函数如图 10.32 所示。</p><p>程序最终如图 10.33。在你自己的电脑上实践，确保它正确运行。</p><pre><code class="highlight matlab"><span class="comment">% ------File/Open 回叫函数----------------------</span><span class="function"><span class="keyword">function</span> <span class="title">mFileOpen_Callback</span><span class="params">(hObject, eventdata, handles)</span></span><span class="comment">% Get the file to open</span>[filename, pathname] = uigetfile(<span class="string">'*.dat'</span>,<span class="string">'Load Data'</span>); <span class="comment">%%%%获取文件名</span><span class="keyword">if</span> filename ~= <span class="number">0</span>    <span class="comment">% Open the input file</span>    filename = [pathname filename];    [fid, msg] = fopen(filename, <span class="string">'rt'</span>); <span class="comment">%%%%打开文件</span>    <span class="comment">% Check to see of the open failed.</span>    <span class="keyword">if</span> fid &lt; <span class="number">0</span>        <span class="comment">% There was an error -- tell user.</span>        str = [<span class="string">'File'</span> filename <span class="string">' could not be opened.'</span>];        title = <span class="string">'File Open Failed'</span>;        errordlg(str, title,<span class="string">'modal'</span>); <span class="comment">%%%%打开文件失败时的错误信息</span>    <span class="keyword">else</span>        <span class="comment">% File opened successfully, Read the (x,y) pairs from</span>        <span class="comment">% the input file. Get first (x,y) pair before the</span>        <span class="comment">% loop starts.</span>        [in, count] = fscanf(fid, <span class="string">'%g'</span>, <span class="number">2</span>); <span class="comment">%%%%打开文件失败时的错误信息</span>        ii = <span class="number">0</span>;        <span class="keyword">while</span> ~feof(fid)            ii = ii + <span class="number">1</span>;            x(ii) = in(<span class="number">1</span>);            y(ii) = in(<span class="number">2</span>);            <span class="comment">%Get next (x,y) pair</span>        [in, count] = fscanf(fid, <span class="string">'%g'</span>, <span class="number">2</span>);<span class="comment">%%%%读取数据</span>        <span class="keyword">end</span>        <span class="comment">% Data read in. Close file. fclose(fid);</span>        <span class="comment">% Now plot the data.</span>        hline = <span class="built_in">plot</span>(x,y,<span class="string">'LineWidth'</span>,<span class="number">3</span>); <span class="comment">%%%%绘线条</span>        xlabel(<span class="string">'x'</span>);        ylabel(<span class="string">'y'</span>); grid on;        <span class="comment">% Associate the context menu with line</span>        set(hline,<span class="string">'Uicontextmenu'</span>, handles.ContextMenu1); <span class="comment">%%%%设置上下文菜单</span>        <span class="comment">%Save the line's handle as application data</span>        handles.hline = hline;<span class="comment">%%%%把句柄保存为应用程序数据</span>        guidata(gcbf, handles);    <span class="keyword">end</span><span class="keyword">end</span></code></pre><pre><code class="highlight matlab"><span class="comment">% ---------------plot_line 中的其它函--------------</span><span class="function"><span class="keyword">function</span> <span class="title">mFileExit_Callback</span><span class="params">(hObject, eventdata, handles)</span></span>close(gcbf);<span class="comment">% hObject handle to mFileExit (see GCBO)</span><span class="comment">% eventdata reserved - to be defined in a future version of MATLAB</span><span class="comment">% handles structure with handles and user data (see GUIDATA)</span><span class="function"><span class="keyword">function</span> <span class="title">LineSolid_Callback</span><span class="params">(hObject,eventdata,handles)</span></span>set(handles.hline,<span class="string">'LineStyle'</span>,<span class="string">'-'</span>);<span class="function"><span class="keyword">function</span> <span class="title">LineDashed_Callback</span><span class="params">(hObject,eventdata,handles)</span></span>set(handles.hline,<span class="string">'LineStyle'</span>,<span class="string">'--'</span>);<span class="function"><span class="keyword">function</span> <span class="title">LineDotted_Callback</span><span class="params">(hObject,eventdata,handles)</span></span>set(handles.hline,<span class="string">'LineStyle'</span>,<span class="string">':'</span>);<span class="function"><span class="keyword">function</span> <span class="title">LineDashDot_Callback</span><span class="params">(hObject,eventdata,handles)</span></span>set(handles.hline,<span class="string">'LineStyle'</span>,<span class="string">'-.'</span>);<span class="comment">% ----------------------------------------</span></code></pre><p><img src="/medias/20200619183802792.png" alt="图10.33 plot_line产生的GUI"></p><h4 id="10-7-创建高效-GUIs-的技巧">10.7  创建高效 GUIs 的技巧</h4><p>本节列出一些创建高效图形用户界面（GUI）的技巧。</p><h5 id="10-7-1-工具提示">10.7.1   工具提示</h5><p><strong>MATLAB</strong> 从 5.2 版本开始支持工具提示 即当鼠标在某对象上面停留一小会儿后弹出的一个小帮助窗口，它是 uicontrol GUI 对象中的一个属性，通常用来对 GUI 上的对象提供快速帮助。</p><p>工具提示通过在对象的 TooltipString 属性中设置你想要显示的内容来定义。在本章末练习中，你会被要求创建工具提示。</p><p><strong>对</strong> <strong>GUI</strong> <strong>组件设置工具提示，为用户提供关于该组件功能的有用线索。</strong></p><h5 id="10-7-2-伪代码（p-码，pcode）">10.7.2   伪代码（p 码，pcode）</h5><p>在程序执行过程中第一次执行函数时，<strong>MATLAB</strong> 把函数编译（或解析）成称为 pcode（伪代码的简称）的中间代码，然后执行它的运行时解析程序中执行伪代码。一旦函数被编译，它就留中 <strong>MATLAB</strong> 的内存中，能够被重复执行而无需重新编译。不过，当 <strong>MATLAB</strong> 下次执行时，函数又得重新编译。</p><p>这种初期编译带来的开销（不利因素）相对较小，不过随着函数越来越大，这种开销变得越来越重要。由于定义 GUI 的函数通常相当大，基于 GUI 的程序编译开销与其它类型的程序相比也相对较大。换句话说，由于初期编译，GUI 程序运行得更慢。</p><p>幸运的是，我们可以避免这种开销：把 <strong>MATLAB</strong> 函数及脚本文件编译成伪代码，保存的伪代码文件可以在将来立即执行。执行伪代码文件节省了初期编译时间，使程序运行得更快。</p><p><strong>MATLAB</strong> 采用 pcode 命令创建伪代码文件，这个命令采用下面的形式之一：</p><pre><code class="highlight plaintext">pcode fun1.m fun2.m fun3.m ... pcode *.m</code></pre><p>第一种形式编译给定名称的文件，第二种形式编译当前目录下所有的 M 文件。编译结果以“p”保存。例如，你编译了文件 foo.m，那么输出将保存在 foo.p 文件中。</p><p>如果同一函数既存在于 M 文件中也存在于 p 文件中，<strong>MATLAB</strong> 将自动执行 p 文件中的版本，这是由于该版本更快。然而，如果你修改了 M 文件，你一定要记得重新编译，否则程序将仍然执行旧代码。</p><p>把文件编译成伪代码也有其它优点。在伪代码的形式把发布给其他人可以保护你在源代码上的投资。它们可以自由执行，但别人就没那么容易重建文件得到你的（设计）理念。</p><p><strong>一旦程序工作正常，用 pcode 命令预编译 M 文件，以便提高程序运行速度。</strong></p><p><strong>如果更改了已经编译成伪代码的</strong> <strong>M</strong> <strong>文件，记得要重新编译。否则，你仍然是那些老的、没有修改的代码。</strong></p><h5 id="10-7-3-附加提高">10.7.3   附加提高</h5><p>基于 GUI 的程序可能比我们在本章所简单介绍的更复杂。作为本章使用过的 Callback属性的附加内容，uicontrols 支持三种类型的回叫：CreateFcn，DeleteFcn 和 ButtonDownFcn。<strong>MATLAB</strong> 图形同样支持三种重要类型的回叫：WindowButtonDownFcn WindowButtonMotionFcn 和 WindowButtonUpFcn。</p><p><strong>CreateFcn</strong> 属性定义了对象创建时自动调用的回叫。这种属性允许程序员在程序运行期间对象创建时自定义该对象。由于这种回叫在对象完成定义之前执行，程序员必须在对象创建之前指定描述对象根属性的函数。例如，下面的语句将会使得 function_name 函数在每次</p><p>uicontrol 对象创建之前执行。函数将会在 <strong>MATLAB</strong> 创建对象的属性之后被调用，因此它们</p><p>（对象的属性）在函数执行之前都是可用的。</p><pre><code class="highlight plaintext">Sset(0,'DefaultUicontrolCreateFcn',    'function_name')</code></pre><p><strong>DeleteFcn</strong> 属性定义了对象被销毁时自动调用的函数，它在对象的属性被销毁之前执行，所以它们（对象的属性）在函数执行之前仍可用。这个回叫使程序员有机会去做一些自定义的清理工作。</p><p><strong>ButtonDownFcn</strong> 属性定义了当鼠标在 uicontrol 周围 5-pixel 内按按钮时自动调用的回叫。如果鼠标按钮按在 uicontrol 上，执行 Callback 函数，否则，如果是在边界附近，则执行 ButtonDownFcn。如果 uicontrol 不可用，此时即使鼠标击在控件上，也会执行ButtonDownFcn。</p><p><strong>WindowButtonDownFcn</strong>、<strong>WindowButtonMotionFcn</strong> 和 <strong>WindowButtonUpFcn</strong> 等图形级的回叫函数允许程序员实现动画或拖放等特性，这是由于这些函数可以检测鼠标按下后的初始、中间和最终位置。这些函数跳出本书讨论的范围，但是值得学习知道。参阅 <strong>MATLAB</strong> 用户文档《创建图形用户界面》一卷获得这些回叫函数的描述。</p><h6 id="例-10-3-创建柱状图">例 10.3 创建柱状图</h6><p>编写程序，打开用户指定的数据文件，按文件中的数据计算柱状图。程序应该能计算文件中数据的平均差，中位差和标准差。程序必须包含文件菜单（含打开和退出项），还必须提供用户更改图形柱数的方法。</p><p>选择另一种颜色替换图形和文本标签的背景色，为菜单项设置键盘加速键，在适当的地方添加工具提示。</p><p>解决方案：</p><p>本程序应包含带有打开和退出项的标准菜单、一个用来绘制柱状图的坐标轴，六个文本域，其中三个用来显示平均差、中位差和标准差，三个用来做为标签。程序还必须包含一个标签和一个编辑框，用来让用户更改柱状图中的柱数。</p><p>我们选取淡蓝色[0.6 1.0 1.0]作为 GUI 的背景色，为了达到目的，应在设计时在属性编辑器中把这个代表颜色的向量加进图形的“Color”属性和文本标签的“BackgroundColor” 属性。</p><p>第一步，使用向导 guide 设计 GUI（如图 10.34a 所示），然后，用属性编辑器编辑界面中的文本域和编辑框。必须为这些控件设置独一的名称，以便在后面的回叫函数中定位。下一步，使用菜单编辑器创建文件菜单（如图 10.34b）。最后，把 GUI 保存为 histGUI，向导会自动创建 histGUI.fig 和histGUI.m。</p><p>histGUI.m 保存后，必须编辑它，在句柄结构中添进表示柱状图的柱数的应用程序数</p><pre><code class="highlight plaintext">% Choose default command line output for histGUI handles.output = hObject;% Add the number of bins to this structrue. handles.nbins = str2num(get(handles.NBins,'String'));% Update handles structure guidata(hObject, handles);</code></pre><p><img src="C:/Users/hsiehchou/Desktop/MATLAB%E5%AD%A6%E4%B9%A0/20200619184256516.png" alt=""></p><p><img src="/medias/20200619184337794.png" alt="图10.34(C:/Users/hsiehchou/Desktop/MATLAB学习/20200619184337794.png)菜单编辑器中的文件菜单"></p><p>接着，为“文件/打开”、“文件/退出”菜单项和“柱数”编辑框创建回叫函数。只有最后一个函数才会自动创建菜单项的回叫必须手工添加。</p><p>“文件/打开”回叫函数提示用户选择文件，然后从文件中读取数据，计算并显示柱状图，更新统计文本域。注意文件中的数据也必须保存到 handles 结构中，以便用户更改柱数时可以重新计算。处理这些的步骤的函数如下：</p><pre><code class="highlight plaintext">function mFileOpen_Callback(hObject,eventdata, handles)% Get file name[filename, path] = uigetfile('*.dat;*.abc', 'Load Data File');if filename ~= 0% Read data    x = textread([path filename],'%f');    % Save in handles structure     handles.x = x;    guidata(gcbf, handles);    % Create histogram     hist(handles.x, handles.nbins);    % Set axis labels     xlabel('\bfValue');     ylabel('\bfCount');    % Calculate statistics     ave = mean(x);    med = median(x);     sd = std(x);    n = length(x);    % Update fields    set (handles.MeanData,'String',sprintf('%7.2f',ave));    set (handles.MedianData,'String', sprintf('%7.2f',med));     set (handles.StdDevData,'String', sprintf('%7.2f',sd));    set (handles.TitleString,'String',['Histogram (N = ' int2str(n) ')']);end</code></pre><p>“文件/退出”很简单，仅是关闭图形而已。</p><pre><code class="highlight plaintext">function mFileExit_Callback(hObject, evendata, handles) close(gcbf);</code></pre><p>NBins 的回叫函数必须读取输入的数字，取最接近的整数，然后又把它显示在编辑框中，并重新计算和显示柱状图。注意柱数必须重新保存到 handles 结构中，以便用户打开新的数据文件时可以使用。实现这些步骤的回叫函数如下：</p><pre><code class="highlight plaintext">function NBins_Callback(hObject, eventdata, handles)% Get number of bins, round to integer,and update fieldnbins = str2num(get(gcbo,'String'));nbins = round(nbins); if nbins &lt; 1nbins = 1;endset (handles.NBins, 'String', int2str(nbins));% sprintf('nbins = %d' nbins);% Save in handles structrue handles.nbins = nbins; guidata(gcbf, handles);% Re-display data, if availableif handles.nbins &gt; 0 &amp; ~isempty(handles.x)    % Create histogram     hist(handles.x, handles.nbins);end</code></pre><p>程序最终如图 10.35 所示，试验该程序能否正确运行。</p><p><img src="/medias/20200619184654191.png" alt="图 10.35 histGUI 程序产生的 GUI(C:/Users/hsiehchou/Desktop/MATLAB学习/20200619184654191.png)"></p><h4 id="10-8-总结">10.8  总结</h4><p>本章我们学习了如何创建 <strong>MATLAB</strong> 图形用户界面，一个 GUI 的三个基本部分是<strong>组件</strong></p><p>（uicontrols，uimenus 和uicontextmenus），包含它们的<strong>图形</strong>和以鼠标及键盘作出响应实现动作的<strong>回叫</strong>。</p><p>标准 GUI 组件由 uicontrol 创建，它包括文本域，编辑框，框架，按钮，形状按钮，复选框，单选按钮，下拉菜单，列表框和滑动条。由 uimenu 和 uicontextmenu 创建的标准 GUI 组件是标准菜单和上下文菜单。</p><p>所有的这些组件都可以使用向导 guide（GUI 开发环境工具）放置到图形上。一旦 GUI 布局完成，用户必须用属性编辑器编辑对象属性，然后为每个 GUI 对象编写实现其动作的回叫函数。</p><p>对话框是用来显示信息或从用户处获取输入的特殊图形。对话框通常用来显示错误，提供警告，询问问题或获取用户输入。它们也用来选择文件与打印机属性。</p><p>对话框有有模式与无模式之分。模式对话框在它消失之前不允许用户访问应用程序的其它窗口，而无模式对话框没有这个限制。模式对话框习惯上用来显示需要用户急切注意、不可忽略的警告或错误信息。</p><p>菜单也可以添加到 <strong>MATLAB</strong> 的 GUI 中。菜单可以使界面没有太多组件又可以实现动作。菜单在处理那些不会经常用到的选项而又不想把 GUI 堆得乱七八糟时非常有用。菜单采用菜单编辑器来创建，对每个菜单项，用户必须使用菜单编辑器设置其 Label 标签、Tag 名称和回叫字符串。与 GUI 组件不同，guide 不会自动为菜单项创建回叫字符串，用户要完全负责定义回叫字符串和实现其函数体。</p><p>加速键与键盘助记键可以用来加快窗体操作。</p><h5 id="10-8-1-好的编程习惯总结">10.8.1   好的编程习惯总结</h5><p>当使用 <strong>MATLAB</strong> 的 GUI 时，应该遵循下面的指导语：</p><ol><li><p>用 guide 对一个新的用户图形界面进行布局，并用属性编辑器对每一个组件的初始属性进行设置，例如显示在组件上的文本，组件的颜色，还有回叫函数的名字。</p></li><li><p>用 guide 创建完一个用户图形界面后，人工编辑产生的函数，增加注释，描述这个函数的目的和组件，执行回叫函数的代码。</p></li><li><p>把GUI 应用程序数据存储到handles 结构中，以便任意的一个回叫函数都可以应用它。</p></li><li><p>如果你修改了 handles 结构中的任何 GUI 应用数据，确保在函数退出之前保存了调用guidata 的结构。</p></li><li><p>在基于 GUI 编程中，使用对话框来提供信息或要求输入数据，如果信息紧迫且不可忽略，则把对话框设为模式对话框。</p></li><li><p>对 GUI 组件设置工具提示，为用户提供关于该组件功能的有用线索。</p></li><li><p>一旦程序工作正常，用 pcode 命令预编译 M 文件，以便提高程序运行速度。</p></li></ol><h5 id="10-8-2-MATLAB-总结">10.8.2  MATLAB 总结</h5><p>下面的总结列出了本章中讨论到的 <strong>MATLAB</strong> 命令与函数，还有它们的简要介绍。同时， 请参阅表 10.2，10.3，10.5 和 10.6 等图形对象属性总结。</p><p><strong>命令与函数</strong></p><table><thead><tr><th>-</th><th>-</th></tr></thead><tbody><tr><td>axes</td><td>创建一组坐标轴的函数</td></tr><tr><td>dialog</td><td>创建一个通用对话框</td></tr><tr><td>errordlg</td><td>显示错误信息</td></tr><tr><td>helpdlg</td><td>显示帮助信息</td></tr><tr><td>findobj</td><td>查找一个或多个属性匹配的 GUI 对象</td></tr><tr><td>gcbf</td><td>取得回叫图形</td></tr><tr><td>gcbo</td><td>取得回叫对象</td></tr><tr><td>guidata</td><td>保存图形中的 GUI 应用程序数据</td></tr><tr><td>guihandles</td><td>从保存在图形中的应用程序数据中取得 handles 结构</td></tr><tr><td>guide</td><td>GUI 开发环境工具</td></tr><tr><td>inputdlg</td><td>从用户处获取输入数据的对话框</td></tr><tr><td>printdlg</td><td>打印对话框</td></tr><tr><td>questdlg</td><td>询问问题的对话框</td></tr><tr><td>uicontrol</td><td>创建 GUI 对象的函数</td></tr><tr><td>uicontextmenu</td><td>创建上下文菜单的函数</td></tr><tr><td>uigetfile</td><td>获取输入文件的对话框</td></tr><tr><td>uimenu</td><td>创建标准菜单、或者在标准菜单或上下文菜单中创建菜单项的函数</td></tr><tr><td>uiputfile</td><td>选择输出文件对话框</td></tr><tr><td>uisetcolor</td><td>显示颜色选择对话框</td></tr><tr><td>uisetfont</td><td>显示字体选择对话框</td></tr><tr><td>warndlg</td><td>显示警告对话框</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Matlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第六章 Python机器学习</title>
      <link href="/2020/06/07/di_liu_zhang_python_ji_qi_xue_xi/"/>
      <url>/2020/06/07/di_liu_zhang_python_ji_qi_xue_xi/</url>
      
        <content type="html"><![CDATA[<h2 id="第六章-Python-机器学习">第六章 Python 机器学习</h2><h3 id="1、机器学习基础">1、机器学习基础</h3><h4 id="1-1-机器学习分类">1.1 机器学习分类</h4><h5 id="1-1-1-机器学习定义">1.1.1 机器学习定义</h5><ol><li>机器学习 (Machine Learning, ML) 是一门综合性非常强的多领域<code>交叉学科</code>，涉及线性代数、概率论、统计学、算法复杂度理论等多门学科。</li><li>机器学习根据已知<code>数据</code>来不断<code>学习和积累经验</code>，然后<code>总结出规律并尝试预测未知数据的属性</code>。机器学习可利用数据或经验等不断<code>改善自身的性能</code>。</li><li>机器学习是目前<code>弱人工智能</code>的核心，其应用十分广泛，如计算机视觉、自然语言处理、生物特征识别、搜索引擎、垃圾邮件过滤、推荐系统、广告投放、信用评价、欺诈检测、股票交易和医疗诊断等应用。</li></ol><h5 id="1-1-2-机器学习分类">1.1.2 机器学习分类</h5><ol><li><p>可以定义为：机器学习是从<code>数据</code>中自动分析获得<code>模型</code>，并利用模型对未知数据进行<code>预测</code>。可分为：</p></li><li><p>监督学习（supervised learning）<br>1）监督学习：主要特点是要在训练模型时提供给学习系统<code>训练样本以及样本对应的类别标签</code>，因此又称为有导师学习。例：学生从老师那里获取知识、信息，老师提供对错指示、告知最终答案的学习过程。<br>2）典型的监督学习方法：决策树、支持向量机（SVM）、监督式神经网络等分类算法和线性回归等回归算法。<br>3）监督学习目标：利用一组带有<code>标签</code>的数据，学习从<code>输入到输出的映射</code>，然后将这种映射关系<code>应用到未知数据</code>上，达到分类（输出是<code>离散</code>的）或回归（输出是<code>连续</code>的）的目的。<br>4）监督学习（supervised learning）<br>•目标值：类别——分类问题。<br>•目标值：连续型的数据——回归问题。<br>5）示例<br>➢预测明天的气温是多少度？<br>➢预测明天天气是晴、阴或雨？<br>➢人的年龄预测？<br>➢人脸识别？</p></li><li><p>无监督学习（unsupervised learning）<br>1）无监督学习：主要特点是训练时<code>只提供</code>给学习系统<code>训练样本</code>，而没有样本对应的类别标签信息。例：没有老师的情况下，学生从书本或网络自学的过程。<br>2）无监督学习中，训练数据包含一组输入向量而<code>没有相应的目标值</code>。这类算法的目标可能是发现原始数据中<code>相似样本的组合（称作聚类）</code>，或者确定<code>数据的分布（称作密度估计）</code>，或者把数据从高维空间投影到低维空间（称作<code>降维</code>）以便进行可视化。<br>3）典型的无监督学习方法：聚类学习、自组织神经网络学习。</p></li><li><p>半监督学习（semi-supervised learning）<br>1）半监督学习方式下，训练数据有<code>部分被标识</code>，<code>部分没有被标识</code>，这种模型首先需要学习数据的内在结构，以便合理的组织数据来进行预测。算法上，包括一些对常用监督式学习算法的延伸，这些算法首先试图<code>对未标识数据进行建模</code>，在此基础上<code>再对标识的数据进行预测</code>。<br>2）例：给学生很多未分类的书本与少量的清单，清单上说明哪些书属于同一类别，要求对其他所有书本进行分类。</p></li><li><p>强化学习（reinforcement learning，增强学习）<br>1）强化学习：主要特点是通过试错来发现最优行为策略而不是带有标签的样本学习。<br>2）主要包含四个元素，agent，环境状态，行动，奖励, 强化学习的目标就是获得最多的累计奖励。<br>3）例：小孩学走路、下棋 （包括下围棋和象棋）、机器人、自动驾驶等。</p></li></ol><h4 id="1-2-监督学习-分类">1.2 监督学习-分类</h4><h5 id="1-2-1-分类学习">1.2.1 分类学习</h5><ol><li><p>输入：一组有<code>标签</code>的训练数据(也称观察和评估)，标签表明了这些数据（观察）的所署类别。</p></li><li><p>输出：分类模型根据这些训练数据，训练自己的<code>模型参数</code>，学习出一个适合这组数据的<code>分类器</code>，当有新数据（非训练数据）需要进行类别判断，就可以将这组新数据作为输入送给学习好的分类器进行判断。</p></li><li><p>数据集<br>1）训练集(training set):顾名思义用来训练模型的<code>已标注数据</code>，用来建立模型，发现规律。<br>2）测试集(testing set):也是<code>已标注数据</code>，通常做法是将<code>标注隐藏</code>，输送给训练好的模型，通过结果与真实标注进行对比，<code>评估模型</code>的学习能力。</p></li><li><p>训练集/测试集划分方法<br>根据已有标注数据，随机选出一部分数据（70%）作为训练数据，余下的作为测试数据，此外还有交叉验证法等用来评估分类模型。</p></li><li><p>分类学习评价标准<br>1）精确率：针对预测结果而言，也称查全率，是所有样本中<code>被识别为A类</code>的样本数量与<code>实际属于A类</code>的样本数量的比值。以二分类为例，它表示的是<code>预测为正</code>的样本中有多少是<code>真正的正</code>样本。那么就有两种可能：一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)。精确率P=TP/(TP+FP)<br>2）召回率：针对原样本而言，它表示的是样本中的正例有多少被预测正确。那也有两种可能：一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(TN)。召回率P=TP/(TP+TN)</p></li><li><p>分类学习评价标准——例：<br>•假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本。<br>•TP: 将正类预测为正类数40；TN: 将正类预测为负类数20；FP: 将负类预测为正类数10；FN: 将负类预测为负类数30。<br>•准确率（accuracy）=预测对的/所有=(TP+FN)/(TP+FN+FP+TN)=(40+30)/100=70%<br>•精确率（precision）=TP/(TP+FP)=40/(40+10)=80%<br>•召回率（recall）=TP/(TP+TN)=40/(40+20)=66.7%</p></li><li><p>分类学习应用<br>•金融：贷款是否批准进行评估。<br>•医疗诊断：判断一个肿瘤是恶性还是良性。<br>•欺诈检测：判断一笔银行的交易是否涉嫌欺诈。<br>•网页分类：判断网页的所属类别，财经或者是娱乐？<br>•垃圾邮件分类：判定邮件是否为垃圾邮件。</p></li></ol><h5 id="1-2-2-分类学习常用算法">1.2.2 分类学习常用算法</h5><ol><li><p>K近邻分类器(KNN)<br>KNN：通过计算待分类数据点，与已有数据集中的所有数据点的距离。取距离最小的前K个点，根据“少数服从多数“的原则，将这个数据点划分为出现次数最多的那个类别。<br><img src="/medias/1591458262946.png" alt="K近邻分类器(KNN)"></p></li><li><p>决策树<br>1）决策树是一种树形结构的分类器，通过顺序询问分类点的属性决定分类点最终的类别。<br>2）通常根据特征的信息增益或其他指标，构建一颗决策树。<br>3）在分类时，只需要按照决策树中的结点依次进行判断，即可得到样本所属类别。<br><img src="/medias/1591458315138.png" alt="判定是否去相亲的决策树"></p></li><li><p>朴素贝叶斯<br>1）朴素贝叶斯分类器是一个以贝叶斯定理为基础的多分类的分类器。<br>2）对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。<br>$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$</p></li></ol><h4 id="1-3-监督学习-回归分析">1.3 监督学习-回归分析</h4><h5 id="1-3-1-回归分析">1.3.1 回归分析</h5><ol><li><p>回归：统计学分析数据的方法，目的在于了解两个或多个<code>变数间是否相关</code>、研究其<code>相关方向与强度</code>，并建立<code>数学模型</code>以便<code>观察特定变数</code>来<code>预测</code>研究者感兴趣的<code>变数</code>。</p></li><li><p>回归分析可以帮助人们了解在<code>自变量变化时因变量的变化量</code>。一般来说，通过回归分析我们可以由给出的自变量估计因变量的条件期望。</p></li><li><p>回归分析应用：回归方法适合对一些带有时序信息的数据进行预测或者趋势拟合，常用在金融及其他涉及时间序列分析的领域：<br>1）股票趋势预测<br>2）交通流量预测<br>3）房价预测</p></li></ol><h5 id="1-3-2-回归分析方法">1.3.2 回归分析方法</h5><ol><li>线性回归<br>线性回归 (Linear Regression) 是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，其使用形如 y=wx+b 的<code>线性模型</code>拟合数据输入和输出之间的映射关系。</li></ol><p><img src="/medias/1591458735099.png" alt="线性回归"></p><ol start="2"><li><p>线性回归——实际用途<br>1）利用数据拟合<code>模型进行预测</code>：如果目标是预测或者映射，线性回归可以用来对观测数据集的 y 和 X 的值拟合出一个预测模型。当完成这样一个模型以后，对于一个新增的 X 值，在没有给定与它相配对的 y 的情况下，可以用这个拟合过的模型预测出一个 y 值。<br>2）相关性分析<code>去除冗余</code>：给定一个变量 y 和一些变量 $X_1-X_n$，这些变量有可能与 y 相关，线性回归分析可以用来量化 y 与 $X_i$  之间相关性的强度，评估出与 y 不相关的 $X_i$ ，并识别出哪些 $X_i$ 的子集包含了关于 y 的冗余信息。</p></li><li><p>房价与房屋尺寸关系的线性拟合<br>1）背景：我们可以根据已知的房屋成交价和房屋的尺寸进行线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行成交价格的预测。<br>2）目标：对房屋成交信息建立回归方程，并依据回归方程对房屋价格进行预测。</p></li></ol><p><img src="/medias/1591458884615.png" alt="房价与房屋尺寸关系的线性拟合图"></p><ol start="4"><li><p>非线性拟合：多项式回归<br>1）多项式回归(Polynomial Regression)是研究一个因变量与一个或多个自变量间多项式的回归分析方法。<br>2）如果自变量只有一个时，称为一元多项式回归；如果自变量有多个时，称为多元多项式回归。</p></li><li><p>什么时候用多项式回归<br>1）在一元回归分析中，如果依变量 y 与自变量 x 的关系为<code>非线性的</code>，但是又找不到适当的函数曲线来拟合，则可以采用一元多项式回归。<br>2）多项式回归的最大优点就是可以<code>通过增加x的高次项对实测点进行逼近</code>，直至满意为止。<br>3）事实上，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，因为任一函数都可以分段用多项式来逼近。</p></li></ol><h3 id="2、Scikit-learn-库">2、Scikit-learn 库</h3><h4 id="2-1-Sklearn-库概述">2.1 Sklearn 库概述</h4><h5 id="2-1-1-Scikit-learn-库概述">2.1.1 Scikit-learn 库概述</h5><ol><li>Scikit-learn 项目最早由数据科学家 David Cournapeau 在2007年发起，使用需要 NumPy 和 SciPy 等其他库的支持，是 Python 中专门针对机器学习应用而发展起来的一款开源扩展库。</li><li>和其他众多的开源项目一样，Scikit-learn 目前主要由社区成员自发进行维护。</li><li>Scikit-learn 相比其他开源项目显得更为保守，主要体现在：一是Scikit-learn 从来不做除机器学习领域之外的其他扩展，二是 Scikit-learn 从来不采用未经广泛验证的算法。</li><li><a href="http://scikit-learn.org/stable/index.html">http://scikit-learn.org/stable/index.html</a></li></ol><p><img src="/medias/1591459169266.png" alt="Scikit-learn 库"></p><h5 id="2-1-2-Scikit-learn-库数据集">2.1.2 Scikit-learn 库数据集</h5><p>在机器学习中，经常需要使用各种各样的数据集，Scikit-learn 库提供了一些常用的数据集：</p><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">数据集名称</th><th style="text-align:left">调研方式</th><th style="text-align:left">数据描述</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">鸢尾花数据集</td><td style="text-align:left">Load_iris()</td><td style="text-align:left">用于多分类任务的数据集</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">波士顿房价数据集</td><td style="text-align:left">Load_boston()</td><td style="text-align:left">用于回归任务的经典数据集</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left">糖尿病数据集</td><td style="text-align:left">Load_diabetes()</td><td style="text-align:left">用于回归任务的经典数据集</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left">手写数字数据集</td><td style="text-align:left">Load_digits()</td><td style="text-align:left">用于多分类任务的数据集</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left">乳腺癌数据集</td><td style="text-align:left">Load_breast_cancer()</td><td style="text-align:left">经典的用于二分类任务的数据集</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left">体能训练数据集</td><td style="text-align:left">Load_linnerud()</td><td style="text-align:left">经典的用于多变量回归任务的数据集</td></tr></tbody></table><h5 id="2-1-3-Scikit-learn-库功能">2.1.3 Scikit-learn 库功能</h5><ol><li><p>分类<br>1）分类是指识别给定对象的所属类别，属于监督学习的范畴，最常见的应用场景包括垃圾邮件检测和图像识别等。<br>2）目前 Scikit-learn 已经实现的算法包括：支持向量机（SVM），最近邻，逻辑回归，随机森林，决策树以及多层感知器（MLP）神经网络等。</p></li><li><p>回归<br>1）回归是指预测与给定对象相关联的连续值属性，最常见的应用场景包括预测药物反应和预测股票价格等。<br>2）目前 Scikit-learn 已经实现的算法包括：支持向量回归(SVR)，脊回归，Lasso 回归，弹性网络（Elastic Net），最小角回归（LARS），贝叶斯回归，以及各种不同的鲁棒回归算法等。<br>3）回归算法几乎涵盖了所有开发者的需求范围，而且更重要的是，Scikit-learn 还针对每种算法都提供了简单明了的用例参考。</p></li><li><p>聚类<br>1）聚类是指自动识别具有相似属性的给定对象，并将其分组为集合，属于无监督学习的范畴。<br>2）最常见的应用场景包括顾客细分和试验结果分组。目前 Scikit-learn 已经实现的算法包括：K-均值聚类，谱聚类，均值偏移，分层聚类，DBSCAN 聚类等。</p></li><li><p>数据降维<br>数据降维是指使用主成分分析（PCA）、非负矩阵分解（NMF）或特征选择等降维技术来减少要考虑的随机变量的个数，其主要应用场景包括可视化处理和效率提升。</p></li><li><p>模型选择<br>模型选择是指对于给定参数和模型的比较、验证和选择，其主要目的是通过参数调整来提升精度。目前 Scikitlearn 实现的模块包括：格点搜索，交叉验证和各种针对预测误差评估的度量函数。</p></li><li><p>数据预处理<br>1）数据预处理是指数据的特征提取和归一化，是机器学习过程中的第一个也是最重要的一个环节。<br>2）归一化是指将输入数据转换为具有零均值和单位权方差的新变量，但因为大多数时候都做不到精确等于零，因此会设置一个可接受的范围，一般都要求落在 0-1 之间。<br>3）特征提取是指将文本或图像数据转换为可用于机器学习的数字变量。</p></li></ol><p><img src="/medias/1591459683330.png" alt="Scikit-learn 库功能"></p><h4 id="2-2-Sklearn-库分类算法">2.2 Sklearn 库分类算法</h4><h5 id="2-2-1-Scikit-learn-库分类算法">2.2.1 Scikit-learn 库分类算法</h5><ol><li>K近邻分类器(KNN)<br>KNN：通过计算待分类数据点，与已有数据集中的所有数据点的距离。取距离最小的前 K 个点，根据“少数服从多数“的原则，将这个数据点划分为出现次数最多的那个类别。</li></ol><p><strong>K近邻算法</strong></p><p><img src="/medias/1591459969667.png" alt="K近邻分类器(KNN)"></p><ol start="2"><li>Sklearn 中的 k 邻分类器<br>在 sklearn 库中，可以使用 sklearn.neighbors.KNeighborsClassifier 创建一个 K 近邻分类器，主要参数有：<br>1）n_neighbors：用于指定分类器中K的大小(默认值为5)。<br>2）Weights：设置选中的K个点对分类结果影响的权重（默认值为平均权重”uniform”，可以选择“distance”代表越近的点权重越高，或者传入自己编写的以距离为参数的权重计算函数）。<br>3）algorithm：设置用于计算临近点的方法 （ 选项中有ball_tree、kd_tree 和 brute，分别代表不同的寻找邻居的优化算法，默认值为 auto，根据训练数据自动选择）。<br><strong>k值的选择</strong><br>①如果 k 值较小，就相当于用较小邻域中的训练实例进行预测，极端情况下 k=1，测试实例只和最接近的一个样本有关，训练误差很小(0)，但是如果这个样本恰好是噪声，预测就会出错。也就是说，如果k值过小，容易产生过拟合，误差过大。<br>②如果 k 值较大，就相当于用很大邻域中的训练实例进行预测，相当于和估计数据不相近的样本也参与了，造成模型偏差过大。极端情况是 k=n，测试实例的结果是训练数据集中实例最多的类，这样会产生欠拟合。<br>③在应用中，一般选择较小 k 并且 k 是奇数。通常采用交叉验证的方法来选取合适的 k 值，或者 k 一般低于训练样本数的平方根。<br><strong>Sklearn 中的 k 邻分类器——示例</strong></li></ol><pre><code class="highlight plaintext">from sklearn.neighbors import KNeighborsClassifier# 创建一组数据X和它对应的标签yX=[[0],[1],[2],[3],[4],[5]]y=[0,0,0,1,1,1]# 使用最近的3个邻居作为分类的依据，得到分类器neigh = KNeighborsClassifier(n_neighbors=3)# 将训练数据 X 和标签 y 送入分类器进行学习neigh.fit(X, y)# 调用 predict() 函数，对未知分类样本 [1.1]分类，可以直接并将需要分类的数据构造为数组形式作为参数传入，得到分类标签作为返回值print(neigh.predict([[1.4]]))print(neigh.predict([[2.4]]))print(neigh.predict([[2.5]]))print(neigh.predict([[2.6]]))</code></pre><p><strong>运行结果</strong><br>[0]<br>[0]<br>[0]<br>[1]</p><ol start="3"><li>决策树<br>1）决策树是一种树形结构的分类器，通过顺序询问分类点的属性决定分类点最终的类别。<br>2）通常根据特征的信息增益或其他指标，构建一颗决策树。<br>3）在分类时，只需要按照决策树中的结点依次进行判断，即可得到样本所属类别。</li></ol><p><img src="/medias/1591460354838.png" alt="判定是否去相亲的决策树"><br><strong>Sklearn中的决策树</strong><br>在 sklearn 库中 ， 可以使用sklearn.tree.DecisionTreeClassifier 创建一个决策树用于分类，其主要参数有：<br>1）criterion ：用于选择属性的准则，可以传入 “gini” 代表基尼系数，或者 “entropy”  代表信息增益。<br>2）max_features ：表示在决策树结点进行分裂时，从多少个特征中选择最优特征。可以设定固定数目、百分比或其他标准，默认值是所有特征个数。</p><p><strong>Sklearn中的决策树算法示例</strong></p><pre><code class="highlight plaintext">from sklearn import datasets # 导入方法类iris = datasets.load_iris() # 加载 iris 数据集iris_feature = iris.data # 特征数据iris_target = iris.target # 分类数据from sklearn.model_selection import train_test_splitfeature_train, feature_test, target_train, target_test = train_test_split(iris_feature, iris_target, test_size=0.33, random_state=42)from sklearn.tree import DecisionTreeClassifierdt_model = DecisionTreeClassifier() # 所以参数均置为默认状态dt_model.fit(feature_train,target_train) # 使用训练集训练模型predict_results = dt_model.predict(feature_test) # 使用模型对测试集进行预测print('predict_results:', predict_results)print('target_test:', target_test)# 通过scikit-learn中提供的评估计算方法查看预测结果的准确度from sklearn.metrics import accuracy_scoreprint(accuracy_score(predict_results, target_test))</code></pre><p><strong>运行结果</strong></p><p>predict_results: [1 0 2 1 1 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1<br>0 0 0 2 1 1 0 0 1 1 2 1 2]<br>target_test: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1<br>0 0 0 2 1 1 0 0 1 2 2 1 2]<br>0.96</p><ol start="4"><li>Sklearn 中的朴素贝叶斯<br>•在 sklearn 库中，实现了三个朴素贝叶斯分类器，如下表所示</li></ol><table><thead><tr><th style="text-align:left">分类器</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">naive_bayes.GussianNB</td><td style="text-align:left">高斯朴素贝叶斯</td></tr><tr><td style="text-align:left">naive_bayes.MultinomialNB</td><td style="text-align:left">针对多项式模型的斯朴素贝叶斯分类器</td></tr><tr><td style="text-align:left">naive_bayes.BernoulliNB</td><td style="text-align:left">针对多元伯努利模型的斯朴素贝叶斯分类器</td></tr></tbody></table><p>区别在于假设某一特征的所有属于某个类别的观测值符合特定分布，如，分类问题的特征包括人的身高，身高符合高斯分布，这类问题适合高斯朴素贝叶斯</p><p><strong>Sklearn中的朴素贝叶斯算法示例</strong></p><pre><code class="highlight plaintext">import numpy as npfrom sklearn.naive_bayes import GaussianNBX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])Y = np.array([1, 1, 1, 2, 2, 2])#使用默认参数，创建一个高斯朴素贝叶斯分类器，并将该分类器赋给变量clf = GaussianNB(priors=None)clf.fit(X, Y)print(clf.predict([[-0.8, -1]]))</code></pre><p><strong>运行结果</strong><br>[1]</p><h4 id="2-3-Sklearn-库回归算法">2.3 Sklearn 库回归算法</h4><h5 id="2-3-1-Scikit-learn-库回归算法">2.3.1 Scikit-learn 库回归算法</h5><ol><li><p>Sklearn 中的回归算法<br>•线性回归函数包括：普通线性回归函数（LinearRegression），岭回归（Ridge）， Lasso回归（Lasso）。<br>•非线性回归函数，如多项式回归（Polynomial Features）通过<br>sklearn.preprocessing 子模块进行调用</p></li><li><p>Sklearn 中的线性回归：房价与房屋尺寸线性拟合<br>•技术路线：sklearn.linear_model.LinearRegression<br>•调用 sklearn.linear_model.LinearRegression() 所需参数：<br>1）fit_intercept : 布尔型参数，表示是否计算该模型截距。可选参数；<br>2）normalize : 布尔型参数，若为 True，则X在回归前进行归一化。可选参数。默认值为 False；<br>3）copy_X : 布尔型参数，若为True，则X将被复制；否则将被覆盖。 可选参数。默认值为 True；<br>4）n_jobs : 整型参数，表示用于计算的作业数量；若为 -1，则用所有的 CPU。可选参数。默认值为 1；</p></li></ol><h5 id="2-3-2-Sklearn中的线性回归：房价与房屋尺寸线性拟合">2.3.2 Sklearn中的线性回归：房价与房屋尺寸线性拟合</h5><pre><code class="highlight plaintext">import matplotlib.pyplot as pltimport numpy as npfrom sklearn import linear_model# 读取数据集datasets_X = []#房屋面积datasets_Y = []#房屋价格fr = open('prices.txt','r') lines = fr.readlines()for line in lines:items = line.strip().split(',')datasets_X.append(int(items[0])) # 注意加上类型转换datasets_Y.append(int(items[1]))# 将 datasets_X 转换为二维数组，以符合 linear.fit 函数的参数要求datasets_X = np.array(datasets_X).reshape([-1,1])datasets_Y = np.array(datasets_Y)# 以数据datasets_X的最大值和最小值为范围，建立等差数列，方便后续画图。 minX = min(datasets_X)maxX = max(datasets_X)X = np.arange(minX,maxX).reshape([-1,1])linear = linear_model.LinearRegression() linear.fit(datasets_X, datasets_Y)# 图像中显示plt.scatter(datasets_X, datasets_Y, color = 'red',label='origin data')plt.plot(X, linear.predict(X), color = 'blue',label='linear regression prediction') plt.legend()  #使label生效plt.xlabel('Area')plt.ylabel('Price')plt.show()</code></pre><h3 id="3、线性回归预测实战">3、线性回归预测实战</h3><h4 id="3-1-线性回归原理">3.1 线性回归原理</h4><h5 id="3-1-1-“回归”的由来">3.1.1 “回归”的由来</h5><ol><li><p>“回归” 是由高尔顿在研究人类遗传问题时提出来的。</p></li><li><p>为研究父代与子代身高的关系，高尔顿搜集了 1078 对父亲及其儿子的身高数据并进行了深入分析，发现了回归效应:</p></li><li><p>当父亲高于平均身高时，他们的儿子身高比他更高的概率要小于比他更矮的概率；父亲矮于平均身高时，他们的儿子身高比他更矮的概率要小于比他更高的概率。</p></li><li><p>即这两种身高父亲的儿子的身高，有向他们父辈的平均身高回归的趋势，解释为：大自然约束使人类身高分布相对稳定而非两极分化，就是所谓的“回归效应”。</p></li></ol><h5 id="3-1-2-回归分析概念">3.1.2 回归分析概念</h5><ol><li>回归分析法：指将具有相关关系的两个变量之间的数量关系进行测定，通过建立一个数学表达式进行统计估计和预测的统计研究方法。</li><li>自变量：一般把作为估测依据的变量叫做自变量</li><li>因变量： 待估测的变量</li><li>回归方程：反映自变量和因变量之间联系的数学表达式</li><li>回归模型：某一类回归方程的总称</li></ol><h5 id="3-1-3-回归分析步骤">3.1.3 回归分析步骤</h5><p><img src="/medias/1591461605573.png" alt="回归分析步骤"></p><h4 id="3-2-线性回归模型原理">3.2 线性回归模型原理</h4><p><img src="/medias/1591461655296.png" alt="线性回归模型"><br><img src="/medias/1591461668594.png" alt="线性回归模型"><br><img src="/medias/1591461678967.png" alt="线性回归模型"></p><h4 id="3-3-预测儿童身高实战">3.3 预测儿童身高实战</h4><h5 id="3-3-1-线性回归预测实战">3.3.1 线性回归预测实战</h5><ol><li><p>线性回归预测儿童身高<br>•假定一个人的身高只受年龄、性别、父母身高、祖父母身高和外祖父母身高这几个因素的影响，并假定大致符合线性关系。<br>•在其他条件不变的情况下，随着年龄的增长，会越来越高；<br>•同样，对于其他条件都相同的儿童，其父母身高较高的话，儿童也会略高一些。<br>•假定到18岁后身高会长期保持固定而不再变化（不考虑年龄太大之后会稍微变矮一点的情况）。<br>•根据给定<code>训练数据和对应标签</code>，线性拟合出儿童身高模型，预测测试数据儿童身高。</p></li><li><p>线性回归预测儿童身高<br>•训练数据：每行表示一个样本，包含信息为：儿童年龄，性别（0女1田）、父亲、母亲、祖父、祖母、外祖父、和外祖母的身高。<br>[[1, 0, 180, 165, 175, 165, 170, 165],<br>[3, 0, 180, 165, 175, 165, 173, 165],<br>[4, 0, 180, 165, 175, 165, 170, 165],<br>[6, 0, 180, 165, 175, 165, 170, 165],<br>[8, 1, 180, 165, 175, 167, 170, 165],<br>[10, 0, 180, 166, 175, 165, 170, 165],<br>[11, 0, 180, 165, 175, 165, 170, 165],<br>[12, 0, 180, 165, 175, 165, 170, 165],<br>[13, 1, 180, 165, 175, 165, 170, 165],<br>[14, 0, 180, 165, 175, 165, 170, 165],<br>[17, 0, 170, 165, 175, 165, 170, 165]]<br>• 对应标签数据：儿童身高<br>[60, 90, 100, 110, 130, 140, 150, 164, 160, 163, 168]</p></li><li><p>线性回归预测儿童身高<br>1）导入扩展库</p></li></ol><pre><code class="highlight plaintext">import copyimport numpy as npfrom sklearn import linear_model</code></pre><p>2）训练数据准备</p><pre><code class="highlight plaintext">x = np.array([[1, 0, 180, 165, 175, 165, 170, 165],[3, 0, 180, 165, 175, 165, 173, 165],[4, 0, 180, 165, 175, 165, 170, 165],[6, 0, 180, 165, 175, 165, 170, 165],[8, 1, 180, 165, 175, 167, 170, 165],[10, 0, 180, 166, 175, 165, 170, 165],[11, 0, 180, 165, 175, 165, 170, 165],[12, 0, 180, 165, 175, 165, 170, 165],[13, 1, 180, 165, 175, 165, 170, 165],[14, 0, 180, 165, 175, 165, 170, 165],[17, 0, 170, 165, 175, 165, 170, 165]])y = np.array([60, 90, 100, 110, 130, 140, 150, 164, 160, 163, 168])</code></pre><p>3）创建线性回归模型，得出拟合直线</p><pre><code class="highlight plaintext"># 创建线性回归模型lr = linear_model.LinearRegression() # 根据已知数据拟合最佳直线lr.fit(x, y)</code></pre><p>4）待预测数据准备</p><pre><code class="highlight plaintext">xs = np.array([[10, 0, 180, 165, 175, 165, 170, 165],[17, 1, 173, 153, 175, 161, 170, 161],[34, 0, 170, 165, 170, 165, 170, 165]])</code></pre><p>5）预测并输出结果</p><pre><code class="highlight plaintext">for item in xs:# 为不改变原始数据，进行深复制，并假设超过18岁以后就不再长高了# 对于18岁以后的年龄，返回18岁时的身高item1 = copy.deepcopy(item)if item1[0] &gt; 18:item1[0] = 18print(item, ':', lr.predict(item1.reshape(1,-1)))</code></pre><p><strong>运行结果</strong><br>[ 10   0 180 165 175 165 170 165] : [140.56153846]<br>[ 17   1 173 153 175 161 170 161] : [158.41]<br>[ 34   0 170 165 170 165 170 165] : [176.03076923]</p><h3 id="4、贝叶斯分类实战">4、贝叶斯分类实战</h3><h4 id="4-1-分类基本概念">4.1 分类基本概念</h4><h5 id="4-1-1-什么是分类">4.1.1 什么是分类</h5><p><strong>超市物品分类</strong></p><p><img src="/medias/1591462398944.png" alt="超市物品分类"></p><p><strong>垃圾分类</strong></p><p><img src="/medias/1591462403300.png" alt="垃圾分类"></p><p><strong>生活信息分类</strong></p><p><img src="/medias/1591462408292.png" alt="生活信息分类"></p><h5 id="4-1-2-分类在数据挖掘中的定义">4.1.2 分类在数据挖掘中的定义</h5><p>•分类就是把一些新的数据项<code>映射到给定类别</code>的中的某一个类别。<br>•分类属于<code>有监督学习</code>(supervised learning)，与之相对于的是无监督学习<br>(unsupervised learning)，比如聚类。<br>•分类与聚类的最大区别在于，分类数据中的一部分的<code>类别是已知</code>的，而聚类数据的<code>类别未知</code>。</p><h5 id="4-1-3-分类问题">4.1.3 分类问题</h5><p><strong>动物分类问题</strong><br>根据现有的知识，我们得到了一些关于哺乳动物和鸟类的信息，我们能否对新发现的物种，比如动物A，动物B进行分类？</p><table><thead><tr><th style="text-align:left">动物种类</th><th style="text-align:left">体型</th><th style="text-align:left">翅膀数量</th><th style="text-align:left">脚的只数</th><th style="text-align:left">是否产蛋</th><th style="text-align:left">是否有毛</th><th style="text-align:left">类别</th></tr></thead><tbody><tr><td style="text-align:left">狗</td><td style="text-align:left">中</td><td style="text-align:left">0</td><td style="text-align:left">4</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">哺乳动物</td></tr><tr><td style="text-align:left">猪</td><td style="text-align:left">大</td><td style="text-align:left">0</td><td style="text-align:left">4</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">哺乳动物</td></tr><tr><td style="text-align:left">牛</td><td style="text-align:left">大</td><td style="text-align:left">0</td><td style="text-align:left">4</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">哺乳动物</td></tr><tr><td style="text-align:left">麻雀</td><td style="text-align:left">小</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">是</td><td style="text-align:left">鸟类</td></tr><tr><td style="text-align:left">天鹅</td><td style="text-align:left">中</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">是</td><td style="text-align:left">鸟类</td></tr><tr><td style="text-align:left">大雁</td><td style="text-align:left">中</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">是</td><td style="text-align:left">鸟类</td></tr><tr><td style="text-align:left">动物A</td><td style="text-align:left">大</td><td style="text-align:left">0</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">无</td><td style="text-align:left">?</td></tr><tr><td style="text-align:left">动物B</td><td style="text-align:left">中</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">?</td></tr></tbody></table><h5 id="4-1-4-分类的流程">4.1.4 分类的流程</h5><ol><li>步骤一：将样本转化为等维的数据特征（<code>特征提取</code>）。所有样本必须具有相同数量的特征。兼顾特征的全面性和独立性。</li><li>步骤二：选择与类别相关的特征（<code>特征选择</code>）。比如，绿色代表与类别非常相关，黑色代表部分相关，浅蓝色代表完全无关。</li><li>步骤三：建立分类模型或分类器。</li><li>分类器通常可以看作一个函数，它把特征映射到类的空间上。</li><li>$$f(x_{i1},  x_{i2}, x_{i3}, …,x_{in})→y_i$$</li></ol><table><thead><tr><th style="text-align:left">动物种类</th><th style="text-align:left">体型</th><th style="text-align:left">翅膀数量</th><th style="text-align:left">脚的只数</th><th style="text-align:left">是否产蛋</th><th style="text-align:left">是否有毛</th><th style="text-align:left">类别</th></tr></thead><tbody><tr><td style="text-align:left">狗</td><td style="text-align:left">中</td><td style="text-align:left">0</td><td style="text-align:left">4</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">哺乳动物</td></tr><tr><td style="text-align:left">猪</td><td style="text-align:left">大</td><td style="text-align:left">0</td><td style="text-align:left">4</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">哺乳动物</td></tr><tr><td style="text-align:left">牛</td><td style="text-align:left">大</td><td style="text-align:left">0</td><td style="text-align:left">4</td><td style="text-align:left">否</td><td style="text-align:left">是</td><td style="text-align:left">哺乳动物</td></tr><tr><td style="text-align:left">麻雀</td><td style="text-align:left">小</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">是</td><td style="text-align:left">鸟类</td></tr><tr><td style="text-align:left">天鹅</td><td style="text-align:left">中</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">是</td><td style="text-align:left">鸟类</td></tr><tr><td style="text-align:left">大雁</td><td style="text-align:left">中</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">是</td><td style="text-align:left">是</td><td style="text-align:left">鸟类</td></tr></tbody></table><h5 id="4-1-5-分类的方法">4.1.5 分类的方法</h5><p>1）常用分类算法主要包括相似函数，关联规则分类算法，K近邻分类算法，决策树分类算法，贝叶斯分类算法和基于模糊逻辑，遗传算法，粗糙集和神经网络的分类算法。<br>2）分类算法有很多种，都有各自的优缺点和应用范围，本课程我们以贝叶斯分类算法为例。</p><h4 id="4-2-贝叶斯分类概述">4.2 贝叶斯分类概述</h4><ol><li><p>背景<br>1）贝叶斯分类基于<code>贝叶斯</code>定理，贝叶斯定理是由 18 世纪概率论和决策论的研究者 Thomas Bayes 发明的，故用其名字命名为贝叶斯定理。<br>2）通过对分类算法的比较研究发现，朴素贝叶斯分类法可以与决策树和经过挑选的神经网络分类器相媲美。用于大型数据库，贝叶斯分类法也具有很高准确率和速度。</p></li><li><p>先验概率与后验概率<br>1）先验概率：由<code>以往</code>的数据分析得到的概率；<br>2）后验概率：<code>得到信息之后</code>重新加以修正的概率。</p></li><li><p>贝叶斯理论<br>1）简单的说，<code>贝叶斯定理是基于假设的先验概率</code>、给定假设下观察到不同数据的概率，提供了一种计算后验概率的方法。<br>2）在人工智能领域，贝叶斯方法是一种非常具有代表性的<code>不确定性知识表示和推理方法</code>。</p></li><li><p>贝叶斯定理<br>1）P(A)  是 A 的<code>先验概率或边缘概率</code>。之所以称为“先验”是因为它不考虑任何B方面的因素。<br>2）P(A|B) 是已知 B 发生后 A 的<code>条件概率</code>，也由于得自 B 的取值而被称作 A 的<code>后验概率</code>。<br>3）P(B|A ) 是已知 A 发生后 B 的<code>条件概率</code>，也由于得自 A 的取值而被称作B的<code>后验概率</code>。<br>4）P(B)是B的<code>先验概率或边缘概率</code>，也作标准化常量（normalized constant）。<br>$$P(A|B)=P(A)\frac{P(B|A)}{P(B)}$$<br>贝叶斯公式提供了从先验概率 P(A)、P(B) 和 P(B|A) 计算后验概率 P(A|B) 的方法。</p></li><li><p>朴素贝叶斯<br>假设待分类项的各个属性相互独立的情况下构造的分类算法就是朴素贝叶斯算法。</p></li></ol><p><strong>基本思想</strong><br>给定的待分类项 X{a1,a2，…,an}，求解在此项出现条件下各个类别 $y_i$ 出现的概率，哪个 P($y_i$|X) 最大，就把此待分类项归属哪个类别。</p><ol start="6"><li>四种贝叶斯分类器<br>1）Naïve Bayes：朴素贝叶斯，假定各特征变量 x 是相互独立的。<br>2）TAN：对朴素贝叶斯进行了扩展，允许各特征变量所对应的节点构成一棵树。<br>3）BAN：对 TAN 扩展，允许各特征变量所对应的节点间关系构成一个图，而不止是树。<br>4）GBN：一种无约束的贝叶斯网络分类器。</li></ol><p><img src="/medias/1591463598040.png" alt="四种贝叶斯分类器"></p><ol start="7"><li>贝叶斯分类流程<br>1）准备阶段：主要是依据具体情况<code>确定特征属性</code>，并且对特征属性进行适当划分。然后就是对一部分待分类项进行人工划分，以确定训练样本。<code>输入是所有的待分类项，输出是特征属性和训练样本</code>。<br>2）分类器训练阶段：计算每个类别在训练样本中出现频率以及每个特征属性划分对每个类别的条件概率估计。<code>输入是特征属性和训练样本，输出是分类器</code>。<br>3）应用阶段：使用分类器对待分类项进行分类，其<code>输入是分类器和待分类项，输出是待分类项与类别的映射关系</code>。</li></ol><p><img src="/medias/1591463645577.png" alt="贝叶斯分类流程"></p><h4 id="4-3-垃圾邮件分类实战">4.3 垃圾邮件分类实战</h4><p>训练数据：<br>垃圾邮件（0.txt至150.txt），其中 0-127 为垃圾邮件，128 至 150 为正常邮件，151 至 156 为测试邮件。</p><p><img src="/medias/1591463717009.png" alt="垃圾邮件分类"></p><h5 id="4-3-1-问题分析">4.3.1 问题分析</h5><p>①读取全部训练集，<code>删除其中的干扰字符</code>，例如【】*。、，等等，然后<code>分词</code>，再删除<code>长度为 1</code>的单个字，这样的单个字对于文本分类没有贡献，剩下的词汇认为是有效词汇。</p><p>②统计全部训练集中每个<code>有效词汇的出现次数</code>，截取出现次数最多的<code>前N个</code>。</p><p>③根据第 1 步预处理后的垃圾邮件和非垃圾邮件内容生成特征向量，统计第 2 步中得到的N个词语分别在该邮件中的出现频率。</p><p>④根据第 3 步中得到特征向量和已知邮件分类创建并训练朴素贝叶斯模型。</p><p>⑤读取测试邮件，参考第 1 步，对邮件文本进行预处理，提取特征向量。</p><p>⑥使用第 4 步中训练好的模型，根据第 5 步提取的特征向量对邮件进行分类。</p><h5 id="4-3-2-垃圾邮件分类实战">4.3.2 垃圾邮件分类实战</h5><ol><li>导入扩展库</li></ol><pre><code class="highlight plaintext">from re import subfrom collections import Counter from itertools import chainfrom numpy import arrayfrom jieba import cutfrom sklearn.naive_bayes import MultinomialNB</code></pre><ol start="2"><li>获取文件中所有词</li></ol><pre><code class="highlight plaintext">def getWordsFromFile(txtFile):words = []with open(txtFile, encoding='utf8') as fp:for line in fp:line = line.strip()line = sub(r'[.【】0-9、—。，！~\*]', '', line) line = cut(line)line = filter(lambda word: len(word)&gt;1, line)words.extend(line)return words</code></pre><ol start="3"><li>获得全部训练集中出现次数最多的词</li></ol><pre><code class="highlight plaintext">allWords = []def getTopNWords(topN):txtFiles = [str(i)+'.txt' for i in range(151)]for txtFile in txtFiles:allWords.append(getWordsFromFile(txtFile)) freq = Counter(chain(*allWords))return [w[0] for w in freq.most_common(topN)]topWords = getTopNWords(600)</code></pre><ol start="4"><li>获取特征向量、创建模型训练</li></ol><pre><code class="highlight plaintext">vectors = []for words in allWords:temp = list(map(lambda x: words.count(x), topWords))vectors.append(temp) vectors = array(vectors) labels = array([1]*127 + [0]*24)model = MultinomialNB() model.fit(vectors, labels)</code></pre><ol start="5"><li>预测未知邮件，进行分类，看是否为垃圾邮件</li></ol><pre><code class="highlight plaintext">def predict(txtFile):words = getWordsFromFile(txtFile)currentVector = array(tuple(map(lambda x: words.count(x),topWords)))result = model.predict(currentVector.reshape(1, -1))[0] return '垃圾邮件' if result==1 else '正常邮件'for mail in ('%d.txt'%i for i in range(151, 156)):print(mail, predict(mail), sep=':')</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第五章 Python 数据可视化</title>
      <link href="/2020/06/06/di_wu_zhang_python_shu_ju_ke_shi_hua/"/>
      <url>/2020/06/06/di_wu_zhang_python_shu_ju_ke_shi_hua/</url>
      
        <content type="html"><![CDATA[<h2 id="第五章-Python-数据可视化">第五章 Python 数据可视化</h2><h3 id="1、Matplotlib-基础">1、Matplotlib 基础</h3><h4 id="1-1-Matplotlib-库介绍">1.1 Matplotlib 库介绍</h4><ol><li><p>Matplotlib 是 Python 最著名的绘图库，它提供了一整套和 Matlab 相似的命令 API，十分适合交互式地进行制图。而且也可以方便地将它作为绘图控件，嵌入 GUI 应用程序中。</p></li><li><p>Matplotlib 库由各种可视化类构成，内部结构复杂。</p></li><li><p>Matplotlib.pyplot 是绘制各类可视化图形的命令字库，相当于快捷方式。</p></li><li><p>Matplotlib 文档相当完备，并且 Gallery 页面中有上百幅缩略图，打开之后都有源代码。因此如果你需要绘制某种类型的图，只需要在这个页面中浏览、复制、 粘贴一下，基本上通过修改数据和设置都能搞定。</p></li></ol><h5 id="1-1-1-Matplotlib-库效果">1.1.1 Matplotlib 库效果</h5><p><a href="https://matplotlib.org/gallery/index.html">https://matplotlib.org/gallery/index.html</a></p><p><img src="/medias/1591439857009.png" alt="Matplotlib 库"></p><h5 id="1-1-2-Matplotlib-库-Gallery-示例">1.1.2 Matplotlib 库 Gallery 示例</h5><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as pltN = 5menMeans = (20, 35, 30, 35, 27)womenMeans = (25, 32, 34, 20, 25)menStd = (2, 3, 4, 1, 2)womenStd = (3, 5, 2, 3, 3)ind = np.arange(N)    # the x locations for the groups width = 0.35       # the width of the barsp1 = plt.bar(ind, menMeans, width, yerr=menStd) p2 = plt.bar(ind, womenMeans, width,bottom=menMeans, yerr=womenStd)plt.ylabel('Scores')plt.title('Scores by group and gender')plt.xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))plt.yticks(np.arange(0, 81, 10))plt.legend((p1[0], p2[0]), ('Men', 'Women'))plt.show()</code></pre><p><img src="/medias/1591439822693.png" alt="Gallery 示例"><br>或者新版本代码</p><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as pltlabels = ['G1', 'G2', 'G3', 'G4', 'G5']men_means = [20, 35, 30, 35, 27]women_means = [25, 32, 34, 20, 25]men_std = [2, 3, 4, 1, 2]women_std = [3, 5, 2, 3, 3]width = 0.35 # the width of the bars: can also be len(x) sequencefig, ax = plt.subplots()ax.bar(labels, men_means, width, yerr=men_std, label='Men')ax.bar(labels, women_means, width, yerr=women_std, bottom=men_means,       label='Women')ax.set_ylabel('Scores')ax.set_title('Scores by group and gender')ax.legend()plt.show()</code></pre><p><img src="/medias/1591439831012.png" alt="Gallery 示例"></p><h4 id="1-2-Matplotlib-快速绘图">1.2 Matplotlib 快速绘图</h4><h5 id="1-2-1-快速绘图">1.2.1 快速绘图</h5><ol><li><p>matplotlib 中的快速绘图的函数库可以通过如下语句载入：<br><strong>import matplotlib.pyplot as plt</strong></p></li><li><p>接下来调用 figure 创建一个绘图对象，并且使它成为当前的绘图对象：<br><strong>plt.figure(figsize=(8,4))</strong></p></li><li><p>通过 figsize 参数可以指定绘图对象的宽度和高度，单位为英寸； dpi 参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为 80 。</p></li><li><p>也可以不创建绘图对象直接调用接下来的 plot 函数直接绘图，matplotlib 会自动创建一个绘图对象。</p></li><li><p>在使用 Jupyter Notebook 环境绘图时，需要先运行 Jupyter Notebook 的魔术命令 <code>%matplotlib inline</code>。这条命令的作用是将 Matplotlib 绘制的图形嵌入在当前页面中。而在桌面环境中绘图时，不需要添加此命令，而是在全部绘图代码之后追加<code>plt.show()</code>。<br><strong>%matplotlib inline</strong></p></li><li><p>如果需要同时绘制多幅图表的话，可以是给 figure 传递一个整数参数指定图标的序号，如果所指定序号的绘图对象已经存在的话，将不创建新的对象，而只是让它成为当前绘图对象。</p></li><li><p>plot 函数的调用方式很灵活，使用关键字参数指定各种属性：<br>➢label: 给所绘制的曲线一个名字 ， 此名字在图示 (legend) 中显示 。 只要在字符串前后添加 “$” 符号 ， matplotlib 就会使用其内嵌的latex 引擎绘制的数学公式；<br>➢color: 指定曲线的颜色；<br>➢linewidth: 指定曲线的宽度；<br>➢参数 <code>b -- </code>指定曲线的颜色和线型</p></li><li><p>可通过一系列函数设置绘图对象的各个属性：<br>➢xlabel/ylabel：设置 X 轴/Y轴 的文字<br>➢title：设置图表的标题<br>➢ylim：设置Y轴的范围<br>➢legend：图例图示<br>➢plt.show ()：显示出创建的所有绘图对象</p></li></ol><pre><code class="highlight plaintext">plt.xlabel("Time(s)") plt.ylabel("Volt") plt.title("PyPlot First Example") plt.ylim(-1.2,1.2) plt.legend()</code></pre><ol start="9"><li>可以调用 plt. savefig ()  将当前的 Figure 对象保存成图像文件 ， 图像格式由图像文件的扩展名决定<br><strong>plt.savefig(“test.png”,dpi=120)</strong></li></ol><h5 id="1-2-2-快速绘图示例">1.2.2 快速绘图示例</h5><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as plt x = np.linspace(0, 10, 500)y = np.sin(x)z = np.cos(x**2) plt.figure(figsize=(8,6))plt.plot(x,y,label="$sin(x)$",color="red",linewidth=2) plt.plot(x,z,"b--",label="$cos(x^2)$")plt.xlabel("Time(s)") plt.ylabel("Volt") plt.title("PyPlot First Example") plt.ylim(-1.2,1.2) plt.legend() plt.show()#plt.savefig("test.png",dpi=120)</code></pre><p><img src="/medias/1591440532131.png" alt="快速绘图示例"></p><h4 id="1-3-Matplotlib-库使用初探">1.3 Matplotlib 库使用初探</h4><ol><li>pyplot 的基础图标函数如下</li></ol><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">plt.plot(x,y,fmt,…)</td><td style="text-align:left">绘制一个坐标图</td></tr><tr><td style="text-align:left">plt.boxplot(data, notch, position)</td><td style="text-align:left">绘制一个箱形图</td></tr><tr><td style="text-align:left">plt.bar(left, height, width, bottom)</td><td style="text-align:left">绘制一个柱状图</td></tr><tr><td style="text-align:left">plt.barh(width, bottom, left, height)</td><td style="text-align:left">绘制一个横向条形图</td></tr><tr><td style="text-align:left">plt.polar(theta, r)</td><td style="text-align:left">绘制极坐标图</td></tr><tr><td style="text-align:left">plt.pie(data, explode)</td><td style="text-align:left">绘制饼状图</td></tr><tr><td style="text-align:left">plt.psd(x, NFFT=256, pad_to, Fs)</td><td style="text-align:left">绘制功率谱密度图</td></tr><tr><td style="text-align:left">plt.cohere(x, y, NFFT=256, Fs)</td><td style="text-align:left">绘制X-Y的相关性函数</td></tr><tr><td style="text-align:left">plt.scatter(x, y)</td><td style="text-align:left">绘制散点图，其中，x和y长度相同</td></tr><tr><td style="text-align:left">plt.step(x, y, where)</td><td style="text-align:left">绘制步阶图</td></tr><tr><td style="text-align:left">plt.hist(x, bins, normed)</td><td style="text-align:left">绘制直方图</td></tr><tr><td style="text-align:left">plt.contour(X, Y, Z, N)</td><td style="text-align:left">绘制等值图</td></tr><tr><td style="text-align:left">plt.vlines()</td><td style="text-align:left">绘制垂直图</td></tr><tr><td style="text-align:left">plt.stem(x, y, linefmt, markerfmt)</td><td style="text-align:left">绘制柴火图</td></tr><tr><td style="text-align:left">plt.plot_date()</td><td style="text-align:left">绘制数据日期</td></tr></tbody></table><ol start="2"><li><p>pyplot 的绘图区域<br>1）可以用子图来将图样（plot）放在均匀的坐标网格中。<br>2）plt.subplot(nrows, ncols, plot_number)。<br>3）用 subplot 函数的时候，需要指明网格的行列数量，以及你希望将图样放在哪一个网格区域中。</p></li><li><p>pyplot的绘图区域示例</p></li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.subplot(2,1,1)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(2,1,1)',ha='center',va='center',size=24,alpha=.5)plt.subplot(2,1,2)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(2,1,2)',ha='center',va='center',size=24,alpha=.5)# plt.savefig('./medias/figures/subplot-horizontal.png', dpi=64) plt.show()</code></pre><p><img src="/medias/1591440988040.png" alt="pyplot的绘图区域示例"></p><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.subplot(1,2,1)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(1,2,1)',ha='center',va='center',size=24,alpha=.5)plt.subplot(1,2,2)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(1,2,2)',ha='center',va='center',size=24,alpha=.5)# plt.savefig('./medias/figures/subplot-horizontal.png', dpi=64) plt.show()</code></pre><p><img src="/medias/1591441076189.png" alt="pyplot的绘图区域示例"></p><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.subplot(2,2,1)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(2,2,1)',ha='center',va='center',size=24,alpha=.5)plt.subplot(2,2,2)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(2,2,2)',ha='center',va='center',size=24,alpha=.5)plt.subplot(2,2,3)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(2,2,3)',ha='center',va='center',size=24,alpha=.5)plt.subplot(2,2,4)plt.xticks([]), plt.yticks([])plt.text(0.5,0.5, 'subplot(2,2,4)',ha='center',va='center',size=24,alpha=.5)# plt.savefig('./medias/figures/subplot-horizontal.png', dpi=64) plt.show()</code></pre><p><img src="/medias/1591441165908.png" alt="pyplot的绘图区域示例"></p><h3 id="2、折线图、散点图实战">2、折线图、散点图实战</h3><h4 id="2-1-折线图实战">2.1 折线图实战</h4><h5 id="2-1-1-折线图">2.1.1 折线图</h5><ol><li>折线图通常用来表示数据随时间或有序类别变化的趋势。</li><li>最简单的折线图示例。</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltdata=[1,2,3,4,5,4,2,4,6,7] # 随意创建的数据plt.plot(data) # 引用matplotlib库中的pyplot模块绘图plt.show()</code></pre><p><img src="/medias/1591442728046.png" alt="折线图"></p><ol start="3"><li><p>折线图通常用来表示数据随时间或有序类别变化的趋势。</p></li><li><p>plot() 函数的第一个参数表示横坐标数据</p></li><li><p>第二个参数表示纵坐标数据</p></li><li><p>第三个参数表示颜色、线型和标记样式</p></li><li><p>颜色常用的值有（r/g/b/c/m/y/k/w）</p></li><li><p>线型常用的值有（-/–/:/-.）</p></li><li><p>标记样式常用的值有（/medias/,/o/v/^/s/*/D/d/x/&lt;/&gt;/h/H/1/2/3/4/_/|）</p></li><li><p>绘制多条曲线、曲线颜色、线型、标记等参数设置</p></li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltimport matplotlib.font_manager as fmyy=[1,2,3,4,5,3,1,2,7,8] #随便创建的数据xx=[3,5,4,1,9,3,2,5,6,3]zz=[2,2,4,7,4,8,2,4,5,6]plt.plot(yy, color='r', linewidth=5, linestyle=':', label='Data 1') plt.plot(xx, color='g', linewidth=2, linestyle='--', label='Data 2') plt.plot(zz,color='b', linewidth=0.5, linestyle='-', label='Data 3') plt.legend(loc=2) plt.xlabel('X轴名称', fontproperties='simhei')plt.ylabel('Y轴名称', fontproperties='simhei')plt.title('折线图美化示例', fontproperties='simhei')plt.ylim(0,10)</code></pre><p><img src="/medias/1591443248270.png" alt="绘制多条曲线、曲线颜色、线型、标记等参数"></p><h5 id="2-1-2-折线图实战一">2.1.2 折线图实战一</h5><p>已知王府井某小吃店 2018 年每个月份的营业额如下表所示。请使用matplotlib 扩展库编写 Python 程序绘制折线图对该小吃店全年营业额进行可视化，并使用红色点划线连接每个月份的数据，并在每个月份的数据处使用三角形标记。</p><table><thead><tr><th style="text-align:left">月份</th><th style="text-align:left">1</th><th style="text-align:left">2</th><th style="text-align:left">3</th><th style="text-align:left">4</th><th style="text-align:left">5</th><th style="text-align:left">6</th><th style="text-align:left">7</th><th style="text-align:left">8</th><th style="text-align:left">9</th><th style="text-align:left">10</th><th style="text-align:left">11</th><th style="text-align:left">12</th></tr></thead><tbody><tr><td style="text-align:left">营业额（万元）</td><td style="text-align:left">5.2</td><td style="text-align:left">7.7</td><td style="text-align:left">5.8</td><td style="text-align:left">5.7</td><td style="text-align:left">7.3</td><td style="text-align:left">9.2</td><td style="text-align:left">18.7</td><td style="text-align:left">14.6</td><td style="text-align:left">20.5</td><td style="text-align:left">17.0</td><td style="text-align:left">9.8</td><td style="text-align:left">6.9</td></tr></tbody></table><p><strong>小吃店营业额折线图</strong></p><pre><code class="highlight plaintext">import matplotlib.pyplot as pltmonth = list(range(1,13))money = [5.2, 2.7, 5.8, 5.7, 7.3, 9.2,18.7, 15.6, 20.5, 18.0, 7.8, 6.9]plt.plot(month, money, 'b-.^')plt.xlabel('月份', fontproperties='simhei', fontsize=14)plt.ylabel('营业额（万元）', fontproperties='simhei', fontsize=14)plt.title('小吃店2018年营业额变化趋势图', fontproperties='simhei', fontsize=18)plt.tight_layout()   # 紧缩四周空白，扩大绘图区域可用面积plt.show()</code></pre><p><img src="/medias/1591443587731.png" alt="小吃店营业额折线图"></p><h4 id="2-2-散点图实战">2.2 散点图实战</h4><h5 id="2-2-1-散点图方法">2.2.1 散点图方法</h5><ol><li>在 matplotlib 中使用函数  matplotlib.pyplot.scatter  绘制散点图。</li></ol><pre><code class="highlight plaintext">matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None,  vmax=None, alpha=None, linewidths=None, verts=None, edgecolors=None, hold=None, data=None, **kwargs)</code></pre><ol start="2"><li>常用参数有：x,y 组成了散点的坐标；s 为散点的面积；c 为散点的颜色（默认为蓝色 ‘b’）；marker 为散点的标记；alpha 为散点的透明度（0 与 1 之间的数，0 为完全透明， 1 为完全不透明）; linewidths 为散点边缘的线宽；如果 marker 为 None，则使用 verts 的值构建散点标记；edgecolors 为散点边缘颜色。</li></ol><h5 id="2-2-2-绘制普通散点图">2.2.2 绘制普通散点图</h5><pre><code class="highlight plaintext">import matplotlib import matplotlib.pyplot as plt import numpy as np# 10个点N = 10x = np.random.rand(N)y = np.random.rand(N)plt.scatter(x, y)plt.show()</code></pre><p><img src="/medias/1591443956266.png" alt="普通散点图"></p><h5 id="2-2-3-更改散点大小">2.2.3 更改散点大小</h5><pre><code class="highlight plaintext">import matplotlib import matplotlib.pyplot as plt import numpy as np# 10个点N = 10x = np.random.rand(N) y = np.random.rand(N)# 每个点随机大小s = (30*np.random.rand(N))**2 plt.scatter(x, y, s=s)plt.show()</code></pre><p><img src="/medias/1591444012764.png" alt="更改散点大小"></p><h5 id="2-2-4-更改散点颜色、透明度">2.2.4 更改散点颜色、透明度</h5><pre><code class="highlight plaintext">import matplotlib import matplotlib.pyplot as plt import numpy as np# 10个点N = 10x = np.random.rand(N)y = np.random.rand(N)# 每个点随机大小s = (30*np.random.rand(N))**2# 随机颜色c = np.random.rand(N)plt.scatter(x, y, s=s, c=c, alpha=0.5) plt.show()</code></pre><p><img src="/medias/1591444069805.png" alt="更改散点颜色、透明度"></p><h5 id="2-2-5-更改散点形状">2.2.5 更改散点形状</h5><pre><code class="highlight plaintext">import matplotlib.pyplot as pltimport numpy as np# 10个点N = 10x = np.random.rand(N)y = np.random.rand(N)s = (30*np.random.rand(N))**2c = np.random.rand(N)plt.scatter(x, y, s=s, c=c, marker='^', alpha=0.5)plt.show()</code></pre><p><img src="/medias/1591444111716.png" alt="更改散点形状"></p><h5 id="2-2-6-一张图绘制两组数据的散点图">2.2.6 一张图绘制两组数据的散点图</h5><pre><code class="highlight plaintext">import matplotlib.pyplot as plt import numpy as np# 10个点N = 10x1 = np.random.rand(N) y1 = np.random.rand(N) x2 = np.random.rand(N) y2 = np.random.rand(N)plt.scatter(x1, y1, marker='o') plt.scatter(x2, y2, marker='^') plt.show()</code></pre><p><img src="/medias/1591444187747.png" alt="一张图绘制两组数据的散点图"></p><h5 id="2-2-7-为散点图增加图例">2.2.7 为散点图增加图例</h5><pre><code class="highlight plaintext">import matplotlib.pyplot as plt import numpy as np# 10个点N = 10x1 = np.random.rand(N) y1 = np.random.rand(N) x2 = np.random.rand(N) y2 = np.random.rand(N)plt.scatter(x1, y1, marker='o', label="circle") plt.scatter(x2, y2, marker='^', label="triangle")plt.legend(loc='best')plt.show()</code></pre><p><img src="/medias/1591444271870.png" alt="为散点图增加图例"></p><h3 id="3、柱状图、饼状图实战">3、柱状图、饼状图实战</h3><h4 id="3-1-柱状图实战">3.1 柱状图实战</h4><h5 id="3-1-1-柱状图">3.1.1 柱状图</h5><ol><li><p>使用 Matplotlib 提供的 bar() 函数来绘制柱状图。</p></li><li><p>与前面介绍的 plot() 函数类似，程序每次调用 bar() 函数时都会生成一组柱状图， 如果希望生成多组柱状图，则可通过多次调用 bar() 函数来实现。</p></li><li><p>只要将 bar() 函数理解透彻，我们就能绘制各种类型的柱状图。</p></li></ol><h5 id="3-1-2-柱状图-绘图方法-bar">3.1.2 柱状图 绘图方法 bar()</h5><pre><code class="highlight plaintext">bar(x, height, width=0.8, *, align='center', **kwargs)</code></pre><ol><li>主要参数：<br>1）x：包含所有柱子的下标的列表。<br>2）height：y 轴的数值序列，也是柱状图的高度，一般就是我们需要展示的数据。<br>3）width：为柱状图的宽度，一般这是为 0.8 即可。<br>4）align：柱子对齐方式，有两个可选值：center 和 edge。center 表示每根柱子是根据下标来对齐,  edge 则表示每根柱子全部以下标为起点，然后显示到下标的右边。如果不指定该参数，默认值是 center。</li><li>可选参数：<br>1）color：每根柱子呈现的颜色，可指定一个固定值或者一个列表。<br>2）edgecolor：每根柱子边框的颜色。<br>3）linewidth：每根柱子的边框宽度。如果没有设置该参数，默认无边框。<br>4）tick_label：每根柱子上显示的标签，默认无标签。<br>5）xerr：每根柱子顶部在横轴方向的线段长度。<br>6）yerr：每根柱子顶端在纵轴方向的线段长度。<br>7）ecolor：设置 xerr 和 yerr 的线段的颜色，可以指定一个固定值或者一个列表。</li></ol><h5 id="3-1-3-柱状图实战：利用-pandas-快速绘制">3.1.3 柱状图实战：利用 pandas 快速绘制</h5><p>某商场2018年各部门每个月的业绩如下表所示（单位：万元）。编写程序绘制柱状图可视化各部门的业绩，可以借助于 pandas 的DataFrame 结构快速绘制图形，并要求坐标轴、标题和图例以中文形式显示。</p><table><thead><tr><th style="text-align:left">月份</th><th style="text-align:left">1</th><th style="text-align:left">2</th><th style="text-align:left">3</th><th style="text-align:left">4</th><th style="text-align:left">5</th><th style="text-align:left">6</th><th style="text-align:left">7</th><th style="text-align:left">8</th><th style="text-align:left">9</th><th style="text-align:left">10</th><th style="text-align:left">11</th><th style="text-align:left">12</th></tr></thead><tbody><tr><td style="text-align:left">男装</td><td style="text-align:left">51</td><td style="text-align:left">32</td><td style="text-align:left">58</td><td style="text-align:left">57</td><td style="text-align:left">30</td><td style="text-align:left">46</td><td style="text-align:left">38</td><td style="text-align:left">38</td><td style="text-align:left">40</td><td style="text-align:left">53</td><td style="text-align:left">58</td><td style="text-align:left">50</td></tr><tr><td style="text-align:left">女装</td><td style="text-align:left">70</td><td style="text-align:left">30</td><td style="text-align:left">48</td><td style="text-align:left">73</td><td style="text-align:left">82</td><td style="text-align:left">80</td><td style="text-align:left">43</td><td style="text-align:left">25</td><td style="text-align:left">30</td><td style="text-align:left">49</td><td style="text-align:left">79</td><td style="text-align:left">60</td></tr><tr><td style="text-align:left">餐饮</td><td style="text-align:left">60</td><td style="text-align:left">40</td><td style="text-align:left">46</td><td style="text-align:left">50</td><td style="text-align:left">57</td><td style="text-align:left">76</td><td style="text-align:left">70</td><td style="text-align:left">33</td><td style="text-align:left">70</td><td style="text-align:left">61</td><td style="text-align:left">49</td><td style="text-align:left">45</td></tr><tr><td style="text-align:left">化妆品</td><td style="text-align:left">110</td><td style="text-align:left">75</td><td style="text-align:left">130</td><td style="text-align:left">80</td><td style="text-align:left">83</td><td style="text-align:left">95</td><td style="text-align:left">87</td><td style="text-align:left">89</td><td style="text-align:left">96</td><td style="text-align:left">88</td><td style="text-align:left">86</td><td style="text-align:left">89</td></tr><tr><td style="text-align:left">金银首饰</td><td style="text-align:left">143</td><td style="text-align:left">100</td><td style="text-align:left">89</td><td style="text-align:left">90</td><td style="text-align:left">78</td><td style="text-align:left">129</td><td style="text-align:left">100</td><td style="text-align:left">97</td><td style="text-align:left">108</td><td style="text-align:left">152</td><td style="text-align:left">96</td><td style="text-align:left">87</td></tr></tbody></table><pre><code class="highlight plaintext">import pandas as pdimport matplotlib.pyplot as pltimport matplotlib.font_manager as fmdata = pd.DataFrame({'月份': [1,2,3,4,5,6,7,8,9,10,11,12],'男装': [51,32,58,57,30,46,38,38,40,53,58,50], '女装': [70,30,48,73,82,80,43,25,30,49,79,60], '餐饮': [60,40,46,50,57,76,70,33,70,61,49,45],'化妆品': [110,75,130,80,83,95,87,89,96,88,86,89],'金银首饰': [143,100,89,90,78,129,100,97,108,152,96,87]})data.plot(x='月份', kind='bar')#绘制柱状图，指定月份数据作为x轴plt.xlabel('月份', fontproperties='simhei') # 设置x、y轴标签和字体plt.ylabel('营业额（万元）', fontproperties='simhei')myfont = fm.FontProperties(fname=r'STKAITI.ttf') plt.legend(prop=myfont)plt.show()</code></pre><p><img src="/medias/Figure_1.png" alt="各部门每个月的业绩柱状图"></p><h5 id="3-1-4-柱状图实战：使用-matplotlib-绘制">3.1.4 柱状图实战：使用 matplotlib 绘制</h5><ol><li>简单柱状图</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as plt  num_list = [1.5,0.6,7.8,6]  plt.bar(range(len(num_list)), num_list)  plt.show()</code></pre><p><img src="/medias/1591445577900.png" alt="简单柱状图"></p><p><strong>设置标签</strong></p><pre><code class="highlight plaintext">import matplotlib.pyplot as plt  name_list = ['Monday','Tuesday','Friday','Sunday']num_list = [1.5,0.6,7.8,6]  plt.bar(range(len(num_list)), num_list, color='rgb', tick_label=name_list)  plt.show()</code></pre><p><img src="/medias/1591445668808.png" alt="柱状图设置标签"></p><ol start="2"><li>条形柱状图</li></ol><p><strong>设置标签</strong></p><pre><code class="highlight plaintext">import matplotlib.pyplot as plt  name_list = ['Monday','Tuesday','Friday','Sunday']  num_list = [1.5,0.6,7.8,6]  plt.barh(range(len(num_list)), num_list,color='rgb',tick_label=name_list)  plt.show()</code></pre><p><img src="/medias/1591446055626.png" alt="条形柱状图设置标签"></p><h5 id="3-1-5-柱状图实战：使用-matplotlib-绘制">3.1.5 柱状图实战：使用 matplotlib 绘制</h5><ol><li>堆叠柱状图</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltname_list = ['Monday','Tuesday','Friday','Sunday']  num_list = [1.5,0.6,7.8,6]  num_list1 = [1,2,3,1]  plt.bar(range(len(num_list)), num_list, label='boy', fc = 'y')  plt.bar(range(len(num_list)), num_list1, bottom=num_list, label='girl', tick_label = name_list, fc = 'r')  plt.legend()  plt.show()</code></pre><p><img src="/medias/1591446154977.png" alt="堆叠柱状图"></p><ol start="2"><li>并列柱状图</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltname_list = ['Monday','Tuesday','Friday','Sunday']num_list = [1.5,0.6,7.8,6]  num_list1 = [1,2,3,1]  x =list(range(len(num_list)))  total_width, n = 0.8, 2  width = total_width / n  plt.bar(x, num_list, width=width, label='boy',fc = 'y')  for i in range(len(x)):  x[i] = x[i] + width  plt.bar(x, num_list1, width=width, label='girl', tick_label = name_list, fc = 'r') plt.legend()  plt.show()</code></pre><p><img src="/medias/1591446298354.png" alt="并列柱状图"></p><h4 id="3-2-饼状图实战">3.2 饼状图实战</h4><h5 id="3-2-1-饼状图">3.2.1 饼状图</h5><ol><li><p>概念：<br>1）饼状图显示一个系列中各项的大小与各项总和的比例。<br>2）饼状图可自动根据数据的百分比画饼。</p></li><li><p>绘制饼状图的基本语法<br>1）创建数组 x 的饼图，每个楔形的面积由 x/sum(x) 决定；<br>2）若 sum(x)&lt;1，则 x 数组不会被标准化，x 值即为楔形区域面积占比。注意，该种情况会出现 1-sum(x) 的空楔形。<br>3）若 sum(x)&gt;1，则由 x[i]/sum(x) 算出每一个楔形占比，饼图 360° 区域均被填充。<br><img src="/medias/1591446413658.png" alt="饼状图"></p></li></ol><h5 id="3-2-2-饼状图绘图方法-pie">3.2.2 饼状图绘图方法 pie()</h5><pre><code class="highlight plaintext">pie(x, explode=None, labels=None, colors=None, autopct=None, pctdistance=0.6, shadow=False, labeldistance=1.1, startangle=None, radius=None, counterclock=True, wedgeprops=None, textprops=None, center=(0,0),frame=False, rotatelabels=False, hold=None, data=None)</code></pre><p><strong>参数详解</strong><br>1）x：(创建饼状图的数据，每一块) 的比例，如果 sum(x) &gt;1 会使用 sum(x) 归一化。</p><p>2）explode：(每一块)离开中心距离，一个 list 或数组。</p><p>3）labels：list, optional, default:None；为每个楔形添加标签。</p><p>4）color：array-like, optional, default:None；若无，则用 currently active cycle 中的颜色添加。</p><p>5）autopct：控制饼图内百分比设置，可以使用 format 字符串或者format function：可以是整数(‘%d%%’)、浮点数(%1.3f%%‘)、字符串(’%s%%')、函数。</p><p>6）label distance：float, optional, default:1.1；label 标记的绘制位置，相对于半径的比例，默认值为 1.1，如 &lt;1 则绘制在饼图内侧。</p><p>7）pctdistance：float, optional, default:0.6；类似于 labeldistance，指定 autopct 的位置刻度，默认值为0.6。</p><p>8）shadow：bool, optional, default:False；为饼状图画阴影(True)。</p><p>9）startangle : float, optional, default: None；起始绘制角度，默认图是从 x 轴正方向逆时针画起，如设定=90则从 y 轴正方向画起。</p><p>10）radius : float, optional, default: None；饼图的半径，若为None时，则默认为 1。</p><p>11）counterclock : bool, optional, default: True；指定分数方向，逆时针 (True) 或顺时针。</p><p>12）wedgeprops : dict, optional, default: None；描述楔形边界线宽度值，参数形式’‘wedgeprops = {‘linewidth’: 3}’'楔形边界线宽度为 3。</p><p>13）textprops : dict, optional, default: None；传递给文本对象的字典参数。</p><p>14）center :  list of float, optional, default: (0, 0)；图标的中心为，默认(0,0)，也可以是两个标量的序列(sequence  of 2 scalars)。</p><h5 id="3-2-3-饼状图实战">3.2.3 饼状图实战</h5><ol><li>简单饼状图</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as plt# 用来正常显示中文标签plt.rcParams['font.sans-serif']=['SimHei']labels = 'A','B','C','D'sizes = [10,20,30,40]plt.pie(sizes,labels=labels)plt.title("饼状图实战")plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591447406454.png" alt="简单饼状图"></p><ol start="2"><li>explode : 一块饼图离开中心距离，默认值为（0,0），就是不离开中心。</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签labels = 'A','B','C','D'sizes = [10,20,30,40]explode = (0,0,0.1,0)  #将第三块分离出来plt.pie(sizes, labels=labels, explode=explode) # 增加explode参数plt.title("饼状图实战")plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591447385887.png" alt="一块饼图离开中心距离"></p><ol start="3"><li>colors：数组，可选参数，默认为：None；用来标注每块饼图的 matplotlib 颜色。</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei']labels = 'A','B','C','D'sizes = [10,20,30,40]explode = (0,0,0.1,0)colors = ['r','g','y','b'] #自定义颜色列表plt.pie(sizes, labels=labels, explode=explode, colors=colors)plt.title("饼状图实战")plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591447360661.png" alt="标注每块饼图的 matplotlib 颜色"></p><ol start="4"><li>autopct：控制饼图内百分比设置,可以使用 format 字符串或者format function。<br>‘%1.1f’：指小数点后保留一位有效数值。</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei']labels = 'A','B','C','D'sizes = [10,20,30,40] explode = (0,0,0.1,0)colors = ['r','g','y','b'] #自定义颜色列表#plt.pie(sizes,labels=labels,explode=explode,colors=colors, autopct='%1.1f') #保留一位小数plt.pie(sizes,labels=labels,explode=explode,colors=colors, autopct='%1.2f%%')  #保留两位小数，增加百分号plt.title("饼状图实战")plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591447572772.png" alt="饼图内百分比设置"></p><ol start="5"><li>x：每一块饼图的比例，为必填项，如果 sum(x)&gt;1，会将多出的部分进行均分；如为必填项，如果 sum(x)&lt;1，1-sum(x) 的部分空出；</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei']labels = 'A','B','C','D'# sizes = [0.1,0.2,0.3,0.4]  # sum(x) == 1# sizes = [0.1,0.2,0.3,0.9]  # sum(x) &gt; 1sizes = [0.1,0.2,0.3,0.2]  # sum(x) &lt; 1explode = (0,0,0.1,0)colors = ['r','g','y','b'] #自定义颜色列表plt.pie(sizes,labels=labels,explode=explode,colors=colors, autopct='%1.1f')  #保留一位小数plt.title("饼状图实战")plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591447644747.png" alt="每一块饼图的比例"></p><ol start="6"><li>添加图例，plt.legend( )</li></ol><pre><code class="highlight plaintext">import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei']labels = 'A','B','C','D'sizes = [0.1,0.2,0.3,0.4]  # sum(x) == 1explode = (0,0,0.1,0)plt.pie(sizes,labels=labels,explode=explode, autopct='%1.1f')plt.legend(loc="upper right", fontsize=10, bbox_to_anchor=(1.1,1.05), borderaxespad=0.3) # bbox_to_anchor=[0.5, 0.5]   # 外边距 上边 右边# borderaxespad = 0.3图例的内边距plt.title("饼状图实战")plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591447788057.png" alt="添加图例"></p><h5 id="3-2-4-饼状图实战二：学生成绩分布饼状图">3.2.4 饼状图实战二：学生成绩分布饼状图</h5><p>已知某高校某班级的操作系统、高等数学、英语和 Python 课程考试成绩如下表所示，要求利用 matplotlib 库绘制饼状图显示该班级每门课的成绩中优（85分以上）、及格（60-84分）、不及格（60分以下）的学生占比。</p><table><thead><tr><th style="text-align:left">课程/学生</th><th style="text-align:left">1</th><th style="text-align:left">2</th><th style="text-align:left">3</th><th style="text-align:left">4</th><th style="text-align:left">5</th><th style="text-align:left">6</th><th style="text-align:left">7</th><th style="text-align:left">8</th><th style="text-align:left">9</th><th style="text-align:left">10</th><th style="text-align:left">11</th><th style="text-align:left">12</th><th style="text-align:left">13</th><th style="text-align:left">14</th><th style="text-align:left">15</th><th style="text-align:left">16</th></tr></thead><tbody><tr><td style="text-align:left">操作系统</td><td style="text-align:left">89</td><td style="text-align:left">70</td><td style="text-align:left">49</td><td style="text-align:left">87</td><td style="text-align:left">92</td><td style="text-align:left">84</td><td style="text-align:left">73</td><td style="text-align:left">71</td><td style="text-align:left">78</td><td style="text-align:left">81</td><td style="text-align:left">90</td><td style="text-align:left">37</td><td style="text-align:left">77</td><td style="text-align:left">82</td><td style="text-align:left">75</td><td style="text-align:left">90</td></tr><tr><td style="text-align:left">高等数学</td><td style="text-align:left">70</td><td style="text-align:left">74</td><td style="text-align:left">80</td><td style="text-align:left">60</td><td style="text-align:left">50</td><td style="text-align:left">87</td><td style="text-align:left">68</td><td style="text-align:left">77</td><td style="text-align:left">95</td><td style="text-align:left">80</td><td style="text-align:left">79</td><td style="text-align:left">74</td><td style="text-align:left">69</td><td style="text-align:left">64</td><td style="text-align:left">82</td><td style="text-align:left">81</td></tr><tr><td style="text-align:left">英语</td><td style="text-align:left">83</td><td style="text-align:left">87</td><td style="text-align:left">69</td><td style="text-align:left">55</td><td style="text-align:left">80</td><td style="text-align:left">89</td><td style="text-align:left">96</td><td style="text-align:left">81</td><td style="text-align:left">83</td><td style="text-align:left">90</td><td style="text-align:left">54</td><td style="text-align:left">70</td><td style="text-align:left">79</td><td style="text-align:left">66</td><td style="text-align:left">85</td><td style="text-align:left">82</td></tr><tr><td style="text-align:left">Python</td><td style="text-align:left">90</td><td style="text-align:left">60</td><td style="text-align:left">82</td><td style="text-align:left">79</td><td style="text-align:left">88</td><td style="text-align:left">92</td><td style="text-align:left">85</td><td style="text-align:left">87</td><td style="text-align:left">89</td><td style="text-align:left">71</td><td style="text-align:left">45</td><td style="text-align:left">50</td><td style="text-align:left">80</td><td style="text-align:left">81</td><td style="text-align:left">87</td><td style="text-align:left">93</td></tr></tbody></table><pre><code class="highlight plaintext">from itertools import groupbyimport matplotlib.pyplot as pltplt.rcParams['font.sans-serif'] = ['simhei']# 每门课程的成绩用字典存储scores = {'操作系统':[89,70,49,87,92,84,73,62,78,81,90,65,77,82,81,79,80],'高等数学':[70,74,80,60,50,87,68,77,95,80,79,74,69,64,82,81], '英语':[83,87,69,55,80,89,96,81,83,90,54,70,79,66,85,82],'Python编程':[90,60,82,79,88,92,85,87,89,71,45,50,80,81,87,93]}# 自定义分组函数，在下面的groupby()函数中使用def splitScore(score):    if score&gt;=85:        return '优'    elif score&gt;=70:        return '良'    elif score&gt;=60:        return '及格'     else:        return '不及格'# 统计每门课程中优、及格、不及格的人数# ratios的格式为{'课程名称':{'优':3, '及格':5, '不及格':1},...} ratios = dict()for subject, subjectScore in scores.items():    ratios[subject] = {}    # groupby()函数需要对原始分数进行排序才能正确分类    for category, num in groupby(sorted(subjectScore), splitScore):        ratios[subject][category] = len(tuple(num))# 创建4个子图fig, axs = plt.subplots(2,2) axs.shape = 1,4# 依次在4个子图中绘制每门课程的饼状图for index, subjectData in enumerate(ratios.items()):    # 选择子图    plt.sca(axs[0][index])    subjectName, subjectRatio = subjectData    plt.pie(list(subjectRatio.values()), # 每个扇形对应的书        labels=list(subjectRatio.keys()),  # 每个扇形的标签        autopct='%1.1f%%')    # 百分比显示格式    plt.xlabel(subjectName)plt.gca().set_aspect('equal') plt.text(1,-1.2,'By hsiehchou')plt.show()</code></pre><p><img src="/medias/1591448519409.png" alt="学生成绩分布饼状图"></p><h3 id="4、雷达图、三维实战">4、雷达图、三维实战</h3><h4 id="4-1-雷达图实战">4.1 雷达图实战</h4><h5 id="4-1-1-雷达图">4.1.1 雷达图</h5><ol><li><p>雷达图（Radar Chart），又蜘蛛网图（Spider Chart），可以很好刻画出某些指标的横向或纵向的对比关系。</p></li><li><p>雷达图常用于对多项指标的全面分析。比如：HR 想要比较两个应聘者的综合素质，用雷达图分别画出来，就可以进行直观的比较。</p></li><li><p>python 中用 matplotlib 模块绘制雷达图需要用到极坐标系。<br><img src="/medias/1591448640196.png" alt="雷达图"></p></li></ol><h5 id="4-1-2-雷达图之极坐标系">4.1.2 雷达图之极坐标系</h5><ol><li><p>在平面内取一个定点 O，叫<code>极点</code>，引一条射线 Ox，叫做<code>极轴</code>，再选定一个长度单位和角度的正方向（通常取逆时针方向）。对于平面内任何一点 M，用 ρ 表示线段 OM 的长度（有时也用 r 表示），θ 表示从 Ox 到 OM 的角度，ρ 叫做点 M 的<code>极径</code>，θ 叫做点 M 的<code>极角</code>，有序数对 (ρ,θ) 就叫点 M 的<code>极坐标</code>，这样建立的坐标系叫做<code>极坐标系</code>。</p></li><li><p>通常情况下，M 的极径坐标单位为 1（长度单位），极角坐标单位为 °。<br><img src="/medias/1591448745576.png" alt="雷达图之极坐标系"></p></li></ol><h5 id="4-1-3-雷达图之-polar-函数">4.1.3 雷达图之 polar 函数</h5><pre><code class="highlight plaintext">polar(theta, r, **kwargs)</code></pre><p><strong>1. 主要参数：</strong><br>➢theta：指极角θ。<br>➢r：指极径。</p><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as pltplt.polar(0.25*np.pi, 20, 'ro', lw=2) plt.ylim(0,50)    #设置极轴的上下限plt.show()</code></pre><p><img src="/medias/1591448807308.png" alt="雷达图之 polar 函数"></p><p><strong>注：</strong><br>0.25*np.pi=45°：极角<br>20：极径<br>’ro’：绘极坐标形状为红色圆点<br>lw=2：极坐标图形宽度为 2</p><p><strong>2. 如果绘制多个极角和极轴</strong></p><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as plttheta = np.array([0.25,0.5,0.75,1,1.25,1.5,1.75,2]) r = [75,60,50,70,50,85,45,70]plt.polar(theta*np.pi, r, 'ro', lw=2)plt.ylim(0,100)plt.show()</code></pre><p><img src="/medias/1591448900309.png" alt="绘制多个极角和极轴"></p><p><strong>注：</strong><br>theta：定义了一个 ndarray 数组存储多个数据<br>r：定义了一个数组存放极轴的长度，也叫极径</p><ol start="3"><li><p>则在图中绘制出多个点:（0.25<em>π，75）,（0.5</em>π， 60）,（0.75<em>π，50）,（1.0</em>π，70）等。</p></li><li><p>绘制完极坐标点后，把每个点用线连起来，就是雷达图了。</p></li><li><p>只需要把图形绘制样式修改为 ‘ro-’ 即可.</p></li></ol><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as plttheta = np.array([0.25,0.5,0.75,1,1.25,1.5,1.75,2]) r = [75,60,50,70,50,85,45,70]plt.polar(theta*np.pi, r, 'ro-', lw=2)plt.ylim(0,100)plt.show()</code></pre><p><img src="/medias/1591449048767.png" alt="极坐标点之间的连线"></p><p><strong>注：</strong><br>’ro-’：其中-表示极坐标点之间的连线</p><ol start="6"><li>闭合曲线：多构造一个极坐标点，和第一个点重叠。</li></ol><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as plttheta = np.array([0.25,0.5,0.75,1,1.25,1.5,1.75,2,0.25]) r = [75,60,50,70,50,85,45,70,75]plt.polar(theta*np.pi, r, 'ro-', lw=2)plt.ylim(0,100)plt.show()</code></pre><p><img src="/medias/1591449141208.png" alt="闭合曲线"></p><p><strong>注：</strong><br>最后一个极坐标点与第一个参数相同：(0.25, 75)</p><ol start="7"><li>fill() 函数填充雷达图。</li></ol><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as plttheta =  np.array([0.25,0.5,0.75,1,1.25,1.5,1.75,2,0.25])r = [75,60,50,70,50,85,45,70,75]plt.polar(theta*np.pi, r, 'ro-', lw=2)plt.fill(theta*np.pi, r, facecolor='r', alpha=0.25) #填充plt.ylim(0,100)plt.show()</code></pre><p><img src="/medias/1591449248638.png" alt="填充雷达图"></p><h5 id="4-1-4-实战：学生课程成绩雷达图">4.1.4 实战：学生课程成绩雷达图</h5><p>一般来说，大学的学位证只能证明学生达到该学习阶段的最低要求，并不能体现学生的综合能力以及擅长的学科与领域，因此用人单位在招聘时往往还需要借助于成绩单进行综合考察。如果把每个学生的专业核心课成绩绘制成雷达图印在学位证书上，就可让用人单位非常直观地了解学生综合能力。编写程序，根据某学生的部分专业核心课程和成绩清单绘制雷达图。</p><table><thead><tr><th style="text-align:left">科目</th><th style="text-align:left">C++</th><th style="text-align:left">Python</th><th style="text-align:left">高等数学</th><th style="text-align:left">大学英语</th><th style="text-align:left">软件工程</th><th style="text-align:left">组成原理</th><th style="text-align:left">操作系统</th><th style="text-align:left">网络工程</th></tr></thead><tbody><tr><td style="text-align:left">成绩</td><td style="text-align:left">82</td><td style="text-align:left">95</td><td style="text-align:left">72</td><td style="text-align:left">85</td><td style="text-align:left">45</td><td style="text-align:left">58</td><td style="text-align:left">65</td><td style="text-align:left">86</td></tr></tbody></table><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as plt# 某学生的课程与成绩courses = ['C++', 'Python', '高等数学', '大学英语', '软件工程', '组成原理', '操作系统', '网络工程'] scores = [82, 95, 72, 85, 45, 58, 65, 86]dataLength = len(scores)     # 数据长度# angles 数组把圆周等分为 dataLength 份angles = np.linspace(0,    # 数组第一个数据2*np.pi,  # 数组最后一个数据dataLength,  # 数组中数据数量endpoint=False)  # 不包含终点scores.append(scores[0])angles = np.append(angles, angles[0]) # 闭合# 绘制雷达图plt.polar(angles,  # 设置角度scores,    # 设置各角度上的数据 'rv--',    # 设置颜色、线型和端点符号 linewidth=2)  # 设置线宽# 设置角度网格标签plt.thetagrids(angles*180/np.pi, courses, fontproperties='simhei') # 填充雷达图内部plt.fill(angles, scores, facecolor='r', alpha=0.5)plt.show()</code></pre><p><img src="/medias/1591449650714.png" alt="学生课程成绩雷达图"></p><h4 id="4-2-三维图实战">4.2 三维图实战</h4><h5 id="4-2-1-三维图概述">4.2.1 三维图概述</h5><ol><li><p>matplotlib 支持一些基础的三维图表绘制，比如曲面图散点图和柱状图，需要使用 mpl_toolkits 模块。</p></li><li><p>如果要绘制三维图形，首先需要使用下面的语句导入相应的对象：<br>➢<strong>from mpl_toolkits.mplot3d import Axes3D</strong></p></li><li><p>然后使用下面的两种方式之一声明要创建三维子图：<br>➢<strong>ax = fig.gca(projection=‘3d’)</strong><br>➢<strong>ax = plt.subplot(111, projection=‘3d’)</strong></p></li><li><p>接下来就可以使用 ax 的 plot() 方法绘制三维曲线、plot_surface() 方法绘制三维曲面、 scatter() 方法绘制三维散点图或 bar3d() 方法绘制三维柱状图了。</p></li></ol><h5 id="4-2-2-三维曲面绘制方法-p3d-Axes3D-plot-surface">4.2.2 三维曲面绘制方法:  p3d.Axes3D. plot_surface()</h5><ol><li>在绘制三维图形时，至少需要指定x、y、z三个坐标轴的数据，然后再根据不同的图形类型指定额外的参数设置图形的属性。</li></ol><pre><code class="highlight plaintext">plot_surface(X, Y, Z, *args, **kwargs)</code></pre><ol start="2"><li>常用参数：<br>➢rstride 和 cstride 分别控制 x 和 y 两个方向的步长，这决定了曲面上每个面片的大小；<br>➢color 用来指定面片的颜色；<br>➢cmap 用来指定面片的颜色映射表。</li></ol><h5 id="4-2-3-三维散点图绘制方法：p3d-Axes3D-scatter">4.2.3 三维散点图绘制方法：p3d.Axes3D.scatter()</h5><pre><code class="highlight plaintext">p3d.Axes3D.scatter (xs, ys, zs=0, zdir='z', s=20, c=None, depthshade=True, *args,  **kwargs)</code></pre><p><strong>常用参数</strong><br>➢xs、ys、zs 分别用来指定散点符号的 x、y、z 坐标，如果同时为标量则指定一个三点符号的坐标，如果同时为等长数组则指定一系列散点符号的坐标。<br>➢s 用来指定散点符号的大小，可以是标量或与 xs 等长的数组。</p><h5 id="4-2-4-三维柱状图绘制方法：p3d-Axes3D-bar3d">4.2.4 三维柱状图绘制方法：p3d.Axes3D. bar3d()</h5><pre><code class="highlight plaintext">p3d.Axes3D. bar3d(x, y, z, dx, dy, dz, color=None, zsort='average', *args, **kwargs)</code></pre><p><strong>常用参数</strong><br>➢x、y、z 分别用来指定每个柱底面的坐标，如果这三个参数都是标量则指定一个柱的底面坐标，如果是三个等长的数组则指定多个柱的底面坐标。<br>➢dx、dy、dz 分别用来指定柱在三个坐标轴上的跨度，即 x 方向的宽度、y 方向的厚度和 z 方向的高度。<br>➢color 用来指定柱的表面颜色。</p><h5 id="4-2-5-三维曲线图实战">4.2.5 三维曲线图实战</h5><ol><li>生成测试数据 x、y、z，然后绘制三维曲线，并设置图例的字体和字号。</li></ol><pre><code class="highlight plaintext">import numpy as npimport matplotlib as mplfrom mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as pltimport matplotlib.font_manager as fm# 绘制三维图形fig = plt.figure()ax = fig.gca(projection='3d')# 生成测试数据theta = np.linspace(-4 * np.pi, 4 * np.pi, 100) z = np.linspace(-4, 4, 100)*0.3r = z**4 + 1x = r * np.sin(theta)y = r * np.cos(theta)# 绘制三维曲线，设置标签ax.plot(x, y, z, 'bv-', label='参数曲线')# 设置图例字体、字号，显示图例font = fm.FontProperties(fname=r'C:\Users\hsiehchou\.spyder-py3\STKAITI.ttf')mpl.rcParams['legend.fontsize'] = 10ax.legend(prop=font)plt.show()</code></pre><p><img src="/medias/1591450502805.png" alt="三维曲线"></p><ol start="2"><li>生成测试数据 x、y、z，然后绘制三维曲线，并设置图例的字体和字号。</li></ol><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as pltimport mpl_toolkits.mplot3d# 生成测试数据，在x和y方向分布生成-2到2之间的20个数# 步长使用虚数，虚部表示点的个数，并且包含endx, y = np.mgrid[-2:2:20j, -2:2:20j]z = 50 * np.sin(x+y*2)# 创建三维图形ax = plt.subplot(111, projection='3d')# 绘制三维曲面ax.plot_surface(x,y,z, rstride=3, cstride=2, cmap=plt.cm.coolwarm)# 设置坐标轴标签ax.set_xlabel('X')ax.set_ylabel('Y')ax.set_zlabel('Z')# 设置图形标题ax.set_title('三维曲面', fontproperties='simhei', fontsize=24)plt.show()</code></pre><p><img src="/medias/1591450640439.png" alt="三维曲面"></p><ol start="3"><li>生成测试数据，绘制三维柱状图，设置每个柱的颜色随机，且宽度和厚度都为 1。</li></ol><pre><code class="highlight plaintext">import numpy as npimport matplotlib.pyplot as pltimport mpl_toolkits.mplot3dx = np.random.randint(0, 40, 10)y = np.random.randint(0, 40, 10)z = 80*abs(np.sin(x+y))ax = plt.subplot(projection='3d')for xx, yy, zz in zip(x, y, z):color = np.random.random(3)ax.bar3d(xx, yy, 0, dx=1, dy=1, dz=zz, color=color)ax.set_xlabel('X') ax.set_ylabel('Y') ax.set_zlabel('Z') plt.show()</code></pre><p><img src="/medias/1591450739894.png" alt="三维柱状图"></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第四章 Python 数据处理</title>
      <link href="/2020/06/04/di_si_zhang_python_shu_ju_chu_li/"/>
      <url>/2020/06/04/di_si_zhang_python_shu_ju_chu_li/</url>
      
        <content type="html"><![CDATA[<h2 id="第四章-Python-数据处理">第四章 Python 数据处理</h2><h3 id="1、numpy-数组操作">1、numpy 数组操作</h3><h4 id="1-1-numpy-库概述">1.1 numpy 库概述</h4><h5 id="1-1-1-引言">1.1.1 引言</h5><ol><li>Python 中用列表(list)保存一组值，可用来当作数组使用，由于列表的元素可以是任何对象，因此列表中所保存的是对象的指针。为保存一个简单的[1,2,3]，需要有 3 个指针和三个整数对象。对于数值运算来说这种结构显然<strong>比较浪费内存和CPU计算时间</strong>。</li><li>此外 Python 还提供了一个 array 模块，array 对象和列表不同，它直接保存数值，和 C 语言的一维数组比较类似。但是由于它<strong>不支持多维</strong>，也没有各种运算函数，因此也不适合做数值运算。</li><li>numpy 的诞生弥补了这些不足，numpy 提供 <strong>ndarray（N-dimensional array object</strong>）对象：ndarray 是存储单一数据类型的多维数组。</li></ol><h5 id="1-1-2-numpy（Numerical-Python的简称）">1.1.2 numpy（Numerical Python的简称）</h5><p>是高性能科学计算和数据分析的基础包，支持维度数组与矩阵运算。包括：</p><ol><li>一个强大的 N 维数组对象 ndarray，具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。</li><li>用于对整组数据进行快速运算的标准数学函数（无需编写循环）。</li><li>用于读写磁盘数据的工具以及用于操作内存映射文件的工具。</li><li>线性代数、随机数生成以及傅里叶变换等功能。</li><li>用于集成由 C、C++、Fortran 等语言编写的代码的工具。</li></ol><h5 id="1-1-3-numpy-库提供了大量的库函数和操作">1.1.3 numpy 库提供了大量的库函数和操作</h5><p>可以帮助程序员轻松地进行数值计算。这类数值计算广泛用于以下任务：</p><ol><li>机器学习模型：在编写机器学习算法时，需要对矩阵进行各种数值计算。例如矩阵乘法、加法等。使用 numpy 库可进行<strong>简单</strong>(在编写代码方面)和<strong>快速</strong>(在速度方面)计算。numpy 数组用于存储训练数据和机器学习模型的参数。</li><li>图像处理和计算机图形学：计算机中的图像表示为多维数字数组，numpy 提供了一些优秀的库函数来快速处理图像。例如，镜像图像、按特定角度旋转图像等。</li><li>数学任务：numpy 可进行数值积分、微分、内插、外推等操作。numpy 库形成了一种基于 Python 的 MATLAB 的快速替代。</li></ol><h4 id="1-2-numpy-库安装">1.2 numpy 库安装</h4><h5 id="1-2-1-使用已有的发行版本">1.2.1 使用已有的发行版本</h5><ol><li>对于许多用户，尤其是 Windows 用户，最简单的方法是下载Python  发行版，包含所有的关键包（包括 numpy，SciPy，matplotlib 以及 Python 核心自带的其它包）：</li><li><strong>Anaconda</strong>: 免费 Python 发行版，用于进行大规模数据处理、预测分析，和科学计算，致力于简化包的管理和部署。支持 Linux, Windows 和 Mac 系统。（推荐）</li><li>Enthought Canopy: 提供了免费和商业发行版。持 Linux, Windows 和 Mac 系统。</li><li>WinPython: 免费的 Python 发行版，包含科学计算包与 Spyder IDE。支持 Windows。</li><li>Pyzo: 基于 Anaconda 的免费发行版本及 IEP 的交互开发环境，超轻量级。 支持Linux, Windows 和 Mac 系统。</li></ol><h5 id="1-2-2-使用-pip-安装">1.2.2 使用 pip 安装</h5><ol><li>安装 numpy 最简单的方法就是使用 pip 工具：</li></ol><pre><code class="highlight plaintext">python -m pip install --user numpy</code></pre><ol start="2"><li><code>--user</code> 选项可以设置只安装在当前的用户下，而不是写入到系统目录。</li></ol><h4 id="1-3-ndarray-概述">1.3 ndarray 概述</h4><ol><li>N 维数组对象 ndarray 是用于存放<strong>同类型元素</strong>的多维数组。</li><li>ndarray 中的每个元素在内存中都有<strong>相同存储大小</strong>的区域。</li><li>ndarray 中的每个元素是数据类型对象的对象 （ 称为 dtype）。</li><li>与 Python 中的其他容器对象一样，可以通过对数组进行索引或切片。</li><li>可通过 ndarray 的方法和属性来访问和修改 ndarray 的内容 。</li></ol><h4 id="1-4-ndarray-之创建数组">1.4 ndarray 之创建数组</h4><h5 id="1-4-1-创建-ndarray：创建数组最简单的办法就是使用-array-函数。">1.4.1 创建 ndarray：创建数组最简单的办法就是使用 array 函数。</h5><p>它接受一切序列型的对象，然后产生一个含有传入数据的 numpy 数组。其中，嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组。</p><pre><code class="highlight plaintext">numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0)</code></pre><table><thead><tr><th style="text-align:left">名称</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">object</td><td style="text-align:left">数组或嵌套的数列</td></tr><tr><td style="text-align:left">dtype</td><td style="text-align:left">数组元素的数据类型，可选</td></tr><tr><td style="text-align:left">copy</td><td style="text-align:left">对象是否需要复制，可选</td></tr><tr><td style="text-align:left">order</td><td style="text-align:left">创建数组的样式，C 为行方向，F 为列方向，A 为任意方向（默认）</td></tr><tr><td style="text-align:left">subok</td><td style="text-align:left">默认返回一个与基类类型一致的数组</td></tr><tr><td style="text-align:left">ndmin</td><td style="text-align:left">指定生成数组的最小维度</td></tr></tbody></table><pre><code class="highlight plaintext">&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; a = [1, 2, 3, 4]   # 创建简单的列表&gt;&gt;&gt; b = np.array(a)    # 将列表转换为数组&gt;&gt;&gt; barray([1, 2, 3, 4])&gt;&gt;&gt; c = np.array([[1,  2],  [3,  4]]) &gt;&gt;&gt;c[[1, 2] [3, 4]]</code></pre><h5 id="1-4-2-除了np-array之外，还有一些函数也可以新建数组：">1.4.2 除了np.array之外，还有一些函数也可以新建数组：</h5><ol><li>zeros 和 ones 分别可以创建指定长度或者形状的全 0 或全 1 数组</li><li>empty 可以创建一个没有任何具体值的数组</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; np.zeros(3)  # 全 0 一维数组array([ 0.,  0.,  0.])&gt;&gt;&gt; np.ones(3)   # 全 1 一维数组array([ 1.,  1.,  1.])&gt;&gt;&gt; np.zeros((3,3))   # 全 0 二维数组，3 行 3 列array([[ 0.,  0.,  0.],    [ 0.,  0.,  0.],    [ 0.,  0.,  0.]])&gt;&gt;&gt; np.zeros((3,1))   # 全 0 二维数组，3 行 1 列array([[ 0.],    [ 0.],    [ 0.]])&gt;&gt;&gt; np.zeros((1,3))  # 全 0 二维数组，1 行 3 列array([[ 0.,  0.,  0.]]) &gt;&gt;&gt; np.ones((3,3))   # 全 1 二维数组，3 行 3 列array([[ 1.,  1.,  1.],    [ 1.,  1.,  1.],    [ 1.,  1.,  1.]])&gt;&gt;&gt; np.ones((1,3))     # 全 1 二维数组，1 行 3 列array([[ 1.,  1.,  1.]]) &gt;&gt;&gt; np.identity(3)     # 单位矩阵，3 行 3 列array([[ 1.,  0.,  0.],    [ 0.,  1.,  0.],    [ 0.,  0.,  1.]])</code></pre><h5 id="1-4-3-创建随机数组">1.4.3 创建随机数组</h5><ol><li><strong>均匀分布</strong></li></ol><ol><li>np.random.rand(10, 10) 创建指定形状(示例为10行10列)的数组(范围在0至1之间)</li><li>np.random.uniform(0, 100)  创建指定范围内的一个数</li><li>np.random.randint(0, 100)  创建指定范围内的一个整数</li></ol><ol start="2"><li><strong>正态分布</strong></li></ol><ol><li>np.random.normal(1.75, 0.1, (2, 3))     给定均值/标准差/维度的正态分布</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; np.random.randint(0, 50, 5) # 随机数组，5个0到50之间的数字array([13, 47, 31, 26,  9])&gt;&gt;&gt; np.random.randint(0, 50, (3,5)) # 3行5列，共15个随机整数，都介于[0,50]array([[44, 34, 35, 28, 18],    [24, 24, 26,  4, 21],    [30, 40,  1, 24, 17]])&gt;&gt;&gt; np.random.rand(10)  # 10个介于[0,1)的随机数array([ 0.58193552,  0.11106142,  0.13848858,  0.61148304,  0.72031503,0.12807841,  0.49999167,  0.24124012,  0.15236595,  0.54568207])&gt;&gt;&gt; np.random.standard_normal(5) # 从标准正态分布中随机采样5个数字array([2.82669067, 0.9773194, -0.72595951, -0.11343254, 0.74813065])</code></pre><h5 id="1-4-4-查看数组属性的用法">1.4.4 查看数组属性的用法</h5><table><thead><tr><th style="text-align:left">用法</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">b.size</td><td style="text-align:left">数组元素个数</td></tr><tr><td style="text-align:left">b.shape</td><td style="text-align:left">数组形状</td></tr><tr><td style="text-align:left">b.ndim</td><td style="text-align:left">数组维度</td></tr><tr><td style="text-align:left">b.dtype</td><td style="text-align:left">数组元素类型</td></tr><tr><td style="text-align:left">b.Itemsize</td><td style="text-align:left">数组元素字节大小</td></tr></tbody></table><h5 id="1-4-5-查看数组属性的用法">1.4.5 查看数组属性的用法</h5><pre><code class="highlight plaintext">import numpy as npx = np.array([(1,2,3),(4,5,6)]) print(x)print(x.size)print(x.ndim)print(x.shape)print(x.itemsize)print(x.dtype,'\n')y = x.reshape(3,2)print(y,'\n')print(y.shape)</code></pre><h4 id="1-5-数组和标量之间的运算">1.5 数组和标量之间的运算</h4><p>数组很重要，因为它可以使我们不用编写循环即可对数据执行批量运算。这通常叫做<strong>矢量化</strong>（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级。同样，数组与标量的算术运算也会将那个标量值传播到各个元素。</p><pre><code class="highlight plaintext">&gt;&gt;&gt; arr = np.array([[1., 2., 3.], [4., 5., 6.]]) &gt;&gt;&gt; arrarray([[1., 2., 3.],&gt;&gt;&gt; 1 / arr array([[1., 0.5, 0.33333333],       [0.25, 0.2, 0.16666667]])&gt;&gt;&gt; arr - arr array([[0., 0., 0.],    [0., 0., 0.]])&gt;&gt;&gt; arr * arr array([[ 1.,  4.,  9.],        [16., 25., 36.]])&gt;&gt;&gt; arr ** 0.5array([[1., 1.41421356, 1.73205081],        [2., 2.23606798, 2.44948974]])</code></pre><h4 id="1-6-基本的索引和切片">1.6 基本的索引和切片</h4><ol><li>选取数据子集或的单个元素的方式有很多。</li><li>一维数组很简单，从表面上看，它们跟 Python 列表的功能差不多。</li><li>一维数组跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，数组视图上的任何修改都会直接反映到原始数组上。</li><li>将一个标量值赋值给一个切片时，该值会自动传播到整个选区。</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; arr = np.arange(10)&gt;&gt;&gt; arrarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) &gt;&gt;&gt; arr[5]5&gt;&gt;&gt; arr[5:8]array([5, 6, 7])&gt;&gt;&gt; arr[5:8] = 12&gt;&gt;&gt; arrarray([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9]) &gt;&gt;&gt; arr_slice = arr[5:8]&gt;&gt;&gt; arr_slice[1] = 12345&gt;&gt;&gt; arrarray([ 0, 1,  2,  3,  4, 12, 12345, 12,  8,  9]) &gt;&gt;&gt; arr_slice[:] = 64&gt;&gt;&gt; arrarray([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])</code></pre><ol start="5"><li>在二维数组中，各索引位置上的元素不再是标量而是一维数组。</li><li>可以对各个元素进行递归访问，但是这样有点麻烦。</li><li>还有一种方式是传入一个以逗号隔开的索引列表来选取单个元素。</li><li>在多维数组中，如果省略了后面的索引，则返回对象会是一个维度低一点的 ndarray。</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])&gt;&gt;&gt; arr3darray([[[ 1,  2,  3],    [ 4,  5,  6]],    [[ 7,  8,  9],    [10, 11, 12]]])&gt;&gt;&gt; arr3d[0] array([[1, 2, 3],    [4, 5, 6]])&gt;&gt;&gt; arr3d[0][1]     array([4, 5, 6])</code></pre><h4 id="1-7-数学和统计方法">1.7 数学和统计方法</h4><ol><li><strong>基本数组统计方法</strong><br>可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算。</li></ol><table><thead><tr><th style="text-align:left">方法</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">sum</td><td style="text-align:left">对数组中全部或某轴向的元素求和。零长度的数组的sum 为 0</td></tr><tr><td style="text-align:left">mean</td><td style="text-align:left">算术平均数。零长度的数组的 mean 为 NaN。</td></tr><tr><td style="text-align:left">std, var</td><td style="text-align:left">分别为标准差和方差，自由度可调（默认为n）</td></tr><tr><td style="text-align:left">min, max</td><td style="text-align:left">最大值和最小值</td></tr><tr><td style="text-align:left">argmin, argmax</td><td style="text-align:left">分别为最大和最小元素的索引</td></tr><tr><td style="text-align:left">cumsum</td><td style="text-align:left">所有元素的累加</td></tr><tr><td style="text-align:left">cumprod</td><td style="text-align:left">所有元素的累积</td></tr></tbody></table><ol start="2"><li><strong>sum、mean 以及标准差 std</strong> 等聚合计算既可以当做数组的实例方法调用，也可以当做顶级 numpy 函数使用。</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; arr = np.random.randn(5, 4) # 5行4列正态分布的数据&gt;&gt;&gt; arr.mean()-0.022341797127577216 &gt;&gt;&gt; np.mean(arr)-0.022341797127577216 &gt;&gt;&gt; arr.sum()-0.44683594255154435</code></pre><ol start="3"><li><strong>mean 和 sum</strong> 这类的函数可以接受一个 axis 参数（用于计算该轴向上的统计值）。</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; arr.mean(axis=1)array([-0.11320162, -0.032351  , -0.24522299,  0.13275031,  0.14631631]) &gt;&gt;&gt; arr.sum(0)array([-1.71093252,  3.4431099 , -1.78081725, -0.39819607])</code></pre><pre><code class="highlight plaintext"># 数学和统计方法import numpy as nparr = np.random.randn(5, 4) # 正态分布的数据print(arr, '\n')print(arr.mean(), '\n')print(np.mean(arr), '\n')print(arr.sum(), '\n')print(arr.mean(axis = 0), '\n') # 按列print(arr.mean(axis = 1), '\n') # 按行print(arr.sum(0), '\n')print(arr.sum(1), '\n')b = np.array(arr[0])print(arr[0])print(b.mean())</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">[[-0.80010107  1.07708638 -1.35612627 -0.0968496 ] [ 1.19282733 -0.76803973  0.96541953 -0.92755397] [ 0.1632381   0.20535389 -0.40766701 -1.59165831] [ 0.82877811  2.36588387  1.93749325 -0.59130029] [ 2.00014605 -2.02632033  0.98467712 -0.12523931]] 0.15150238691579443 0.15150238691579443 3.0300477383158886 [ 0.6769777   0.17079282  0.42475933 -0.6665203 ] [-0.29399764  0.11566329 -0.40768333  1.13521373  0.20831588] [ 3.38488852  0.85396408  2.12379663 -3.33260149] [-1.17599056  0.46265316 -1.63073333  4.54085494  0.83326354] [-0.80010107  1.07708638 -1.35612627 -0.0968496 ]-0.29399764052791716</code></pre><ol start="4"><li><p><strong>cumsum</strong><br>按照所给定的轴参数返回元素的梯形累计和，axis=0，按照行累加。axis=1，按照列累加。</p></li><li><p><strong>cumprod</strong><br>按照所给定的轴参数返回元素的梯形累计乘积，axis=0，按照行累积。 axis=1，按照列累积。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; arr = np.array([[0, 1 ,2], [3, 4, 5], [6, 7, 8]]) &gt;&gt;&gt; arr.cumsum(0)array([[ 0,  1,  2],[ 3,  5,  7],[ 9, 12, 15]], dtype=int32)&gt;&gt;&gt; arr.cumprod(1)array([[  0,   0,   0],    [  3,  12,  60],    [  6,  42, 336]], dtype=int32)</code></pre><h3 id="2、numpy-矩阵操作">2、numpy 矩阵操作</h3><h4 id="2-1-numpy-矩阵库-Matrix">2.1 numpy 矩阵库(Matrix)</h4><ol><li><p>NumPy 中包含了一个矩阵库 numpy.matlib，该模块中的函数返回的是一个矩阵，而不是 ndarray 对象。</p></li><li><p>一个𝑚x𝑛的矩阵是一个由 𝑚行（row）𝑛 列（column）元素排列成的矩形阵列。</p></li><li><p>矩阵里的元素可以是数字、符号或数学式。以下是一个由6个数字元素构成的2行3列的矩阵：$\begin{bmatrix}1 &amp; 9 &amp; -13\20 &amp; 5 &amp; -6 \end{bmatrix} $</p></li><li><p>NumPy 和 Matlab 不一样 ， 对于多维数组的运算 ， 缺省情况下并不使用矩阵运算 ，如果你希望对数组进行矩阵运算的话 ， 可以调用ndarry对象相应的函数</p></li></ol><h4 id="2-2-numpy矩阵生成">2.2 numpy矩阵生成</h4><ol><li><strong>常规方式生成</strong></li></ol><pre><code class="highlight plaintext">import numpy as npx = np.matrix([[1,2,3], [4,5,6]])y = np.matrix([1,2,3,4,5,6])# x[0,0]返回行下标和列下标都为0的元素# 注意，对于矩阵x来说，x[0,0]和x[0][0]的含义不一样print(x, y, x[0,0],x[0][0],sep='\n\n')</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">[[1 2 3] [4 5 6]][[1 2 3 4 5 6]]1[[1 2 3]]</code></pre><ol start="2"><li><strong>matlib.empty()</strong><br><strong>numpy.matlib.empty(shape, dtype, order)</strong></li></ol><p>➢<strong>shape</strong>: 定义新矩阵形状的整数或整数元组<br>➢<strong>Dtype</strong>: 可选，数据类型<br>➢<strong>order</strong>: C（行序优先） 或者 F（列序优先）</p><pre><code class="highlight plaintext">import numpy.matlib import numpy as npprint (np.matlib.empty((1,2))) # 填充为随机数据</code></pre><p><strong>运行结果</strong><br>[[-6.04134793e-125  1.10846539e-274]]</p><ol start="3"><li><p><strong>numpy.matlib.zeros()</strong></p></li><li><p><strong>numpy.matlib.ones()</strong><br>➢numpy.matlib.zeros() 函数创建一个以 0 填充的矩阵。<br>➢numpy.matlib.ones() 函数创建一个以 1 填充的矩阵。</p></li></ol><pre><code class="highlight plaintext">import numpy.matlib import numpy as np print (np.matlib.zeros((2,2))) print (np.matlib.ones((2,2)))</code></pre><p><strong>运行结果</strong><br>[[0. 0.]<br>[0. 0.]]<br>[[1. 1.]<br>[1. 1.]]</p><ol start="5"><li><strong>numpy.matlib.eye()</strong><br>numpy.matlib.eye() 函数返回一个矩阵，对角线元素为 1，其他位置为零。</li></ol><p><strong>numpy.matlib.eye(n, M, k, dtype)</strong><br>➢<strong>n</strong>: 返回矩阵的行数<br>➢<strong>M</strong>: 返回矩阵的列数，默认为 n<br>➢<strong>k</strong>: 对角线的索引<br>➢<strong>dtype</strong>: 数据类型</p><pre><code class="highlight plaintext">import numpy.matlib import numpy as np print (np.matlib.eye(n =  3, M =  4, k =  0, dtype =  int))</code></pre><p><strong>运行结果</strong><br>[[1 0 0 0]<br>[0 1 0 0]<br>[0 0 1 0]]</p><ol start="6"><li><strong>numpy.matlib.identity():返回给定大小的单位矩阵</strong><br>单位矩阵是个方阵，从左上角到右下角的对角线（称为主对角线）上的元素均为 1，除此以外全都为 0。</li></ol><p>$$I_1=[1]，I_2=\begin{bmatrix}1 &amp; 0\0 &amp;1\end{bmatrix}，I_3=\begin{bmatrix}1 &amp; 0 &amp; 0\0 &amp; 1 &amp; 0\0 &amp; 0 &amp; 1\end{bmatrix}，…，$$</p><p>$$I_n=\begin{bmatrix}1 &amp; 0 &amp; … &amp; 0\ 0 &amp; 1 &amp; … &amp; 0\. &amp; . &amp; . &amp; .\. &amp; . &amp; . &amp; .\ . &amp; . &amp; . &amp; . \0 &amp; 0 &amp; … &amp; 1  \end{bmatrix}$$</p><pre><code class="highlight plaintext">import numpy.matlib import numpy as np # 大小为4，类型为整型print (np.matlib.identity(4, dtype = int))</code></pre><p><strong>运行结果</strong><br>[[1 0 0 0]<br>[0 1 0 0]<br>[0 0 1 0]<br>[0 0 0 1]]</p><ol start="7"><li><strong>numpy.matlib.rand()</strong><br>numpy.matlib.rand()   函数创建一个给定大小的矩阵，数据是随机填充的。</li></ol><pre><code class="highlight plaintext">import numpy.matlib import numpy as np print (np.matlib.rand(4,4))</code></pre><p><strong>运行结果</strong><br>[[0.32525881 0.19282243 0.63614484 0.19132335]<br>[0.89759542 0.2546368  0.129491   0.87191412]<br>[0.71666597 0.48077184 0.80972151 0.30165613]<br>[0.34678005 0.39324507 0.8171954  0.53549778]]</p><h4 id="2-3-numpy矩阵常用操作">2.3 numpy矩阵常用操作</h4><h5 id="2-3-1-矩阵与二维数组相互转换">2.3.1 <strong>矩阵与二维数组相互转换</strong></h5><p>矩阵总是二维的，而 ndarray 是一个 n 维数组。 两个对象都是可互换的。</p><pre><code class="highlight plaintext">import numpy.matlib import numpy as np  i = np.matrix('1,2;3,4') print(i)j = np.asarray(i) print(j)k = np.asmatrix (j)  print (k)</code></pre><p><strong>运行结果</strong><br>[[1 2]<br>[3 4]]<br>[[1 2]<br>[3 4]]<br>[[1 2]<br>[3 4]]</p><h5 id="2-3-2-矩阵转置">2.3.2 矩阵转置</h5><pre><code class="highlight plaintext">import numpy as npx = np.matrix([[1,2,3], [4,5,6]]) y = np.matrix([1,2,3,4,5,6]) print(x.T, y.T, sep='\n\n')</code></pre><p><strong>运行结果</strong><br>[[1 4]<br>[2 5]<br>[3 6]]</p><p>[[1]<br>[2]<br>[3]<br>[4]<br>[5]<br>[6]]</p><h5 id="2-3-3-查看矩阵特征">2.3.3 查看矩阵特征</h5><pre><code class="highlight plaintext">import numpy as npx = np.matrix([[1,2,3], [4,5,6]]) print(x.mean(), end='\n====\n') # 所有元素平均值print(x.mean(axis=0), end='\n====\n')   # 纵向平均值print(x.mean(axis=0).shape, end='\n====\n')print(x.mean(axis=1), end='\n====\n')  # 横向平均值print(x.sum(), end='\n====\n')  # 所有元素之和   print(x.max(axis=1), end='\n====\n')  # 横向最大值print(x.argmax(axis=1), end='\n====\n') # 横向最大值的下标print(x.diagonal(), end='\n====\n')  # 对角线元素</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">3.5====[[2.5 3.5 4.5]]====(1, 3)====[[2.] [5.]]====21====[[3] [6]]====[[2] [2]]====[[1 5]]====</code></pre><h5 id="2-3-4-矩阵乘法">2.3.4 矩阵乘法</h5><p>$A=\left(a_{ij}\right)^{m,p}<em>{i,j=1}，B=\left(b</em>{ij}\right)^{p,n}<em>{i,j=1}，C=\left(c</em>{ij}\right)^{m,n}<em>{i,j=1}，c</em>{ij}=\sum\limits_{k=1}^p{a_{ik}b_{kj}}$</p><pre><code class="highlight plaintext">import numpy as npx = np.matrix([[1,2,3], [4,5,6]]) y = np.matrix([[1,2], [3,4], [5,6]]) print(x*y)</code></pre><p><strong>运行结果</strong><br>[[22 28]<br>[49 64]]</p><h4 id="2-4-矩阵运算">2.4 矩阵运算</h4><ol><li><p>numpy.linalg 中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西</p></li><li><p>它们跟 MATLAB 和 R 等语言所使用的是相同的行业标准级Fortran库</p></li><li><p>常用的 numpy.linalg 函数：</p></li></ol><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">diag</td><td style="text-align:left">以一维数组的形式返回方阵的对角线（或非对角线）元素，或将一维数组转换为方阵（非对角线元素为0）</td></tr><tr><td style="text-align:left">dot</td><td style="text-align:left">矩阵乘法</td></tr><tr><td style="text-align:left">trace</td><td style="text-align:left">计算对角线元素的和</td></tr><tr><td style="text-align:left">det</td><td style="text-align:left">计算矩阵行列式</td></tr><tr><td style="text-align:left">eig</td><td style="text-align:left">计算方阵的特征值和特征向量</td></tr><tr><td style="text-align:left">inv</td><td style="text-align:left">计算方阵的逆</td></tr><tr><td style="text-align:left">svd</td><td style="text-align:left">计算奇异值分解（SVD）</td></tr><tr><td style="text-align:left">solve</td><td style="text-align:left">解线性方程组Ax=b，其中A为一个方阵</td></tr><tr><td style="text-align:left">lstsq</td><td style="text-align:left">计算Ax=b的最小二乘解</td></tr></tbody></table><h5 id="2-4-1-numpy-dot-——两个数组的点积，即元素对应相乘">2.4.1 numpy.dot()——两个数组的点积，即元素对应相乘</h5><ol><li><p>对于两个一维的数组，计算的是这两个数组对应下标元素的乘积和(数学上称之为内积)。</p></li><li><p>对于二维数组，计算的是两个数组的矩阵乘积。</p></li><li><p>对于多维数组，它的通用计算公式如下，即结果数组中的每个元素都是：数组 a 的最后一维上的所有元素与数组 b 的倒数第二位上的所有元素的乘积和：<br><strong>dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])</strong></p></li></ol><p><strong>numpy.dot(a, b, out=None)</strong><br>➢<strong>a</strong> : ndarray 数组<br>➢<strong>b</strong> : ndarray 数组<br>➢<strong>out</strong> : ndarray, 可选，用来保存 dot() 的计算结果</p><h5 id="2-4-2-numpy-dot-示例">2.4.2 numpy.dot()示例</h5><p><strong>计算式为：[[1<em>11+2</em>13, 1<em>12+2</em>14],[3<em>11+4</em>13, 3<em>12+4</em>14]]</strong></p><pre><code class="highlight plaintext">import numpy.matlib import numpy as npa = np.array([[1,2],[3,4]])b = np.array([[11,12],[13,14]]) print(np.dot(a,b))</code></pre><p><strong>运行结果</strong><br>[[37 40]<br>[85 92]]</p><h5 id="2-4-3-numpy-vdot-——返回两个向量的点积">2.4.3 numpy.vdot()——返回两个向量的点积</h5><p>如果第一个参数是复数，那么它的共轭复数会用于计算。如果参数是多维数组，它会被展开。</p><p><strong>计算式为：1<em>11 + 2</em>12 + 3<em>13 + 4</em>14 = 130</strong></p><pre><code class="highlight plaintext">import numpy as np a = np.array([[1,2],[3,4]]) b = np.array([[11,12],[13,14]]) # vdot 将数组展开计算内积print (np.vdot(a,b))</code></pre><p><strong>运行结果</strong><br>130</p><h5 id="2-4-4-numpy-linalg-inv-——计算逆矩阵">2.4.4 numpy.linalg.inv()——计算逆矩阵</h5><p>逆矩阵（inverse matrix）：设 A 是数域上的一个 n 阶矩阵，若在相同数域上存在另一个 n 阶矩阵 B，使得： AB=BA=E ，则我们称 B 是 A 的逆矩阵，而 A 则被称为可逆矩阵。注：E 为单位矩阵。</p><pre><code class="highlight plaintext">import numpy as np x = np.array([[1,2],[3,4]]) y = np.linalg.inv(x) print (x)print (y)print (np.dot(x,y))</code></pre><p><strong>运行结果</strong><br>[[1 2]<br>[3 4]]<br>[[-2.   1. ]<br>[ 1.5 -0.5]]<br>[[1.00000000e+00 1.11022302e-16]<br>[0.00000000e+00 1.00000000e+00]]</p><h5 id="2-4-5-numpy-linalg-solve-——求矩阵形式的线性方程的解">2.4.5 numpy.linalg.solve()——求矩阵形式的线性方程的解</h5><p>线性方程组<br>$$\begin{cases}<br>a_{11}x_1&amp;+&amp;a_{12}x_2&amp;+&amp;\cdots&amp;+a_{1n}x_n&amp;=&amp;b_1\<br>a_{21}x_1&amp;+&amp;a_{22}x_2&amp;+&amp;\cdots&amp;+a_{2n}x_n&amp;=&amp;b_2&amp;\<br>&amp;&amp;&amp;&amp;\vdots\<br>a_{n1}x_1&amp;+&amp;a_{n2}x_2&amp;+&amp;\cdots&amp;+a_{nn}x_n&amp;=&amp;b_n&amp;<br>\end{cases}$$</p><p>可以写作矩阵相乘的形式 ax=b。<br>其中，a 为 n×n 的矩阵，x 和 b 为 m×1 的矩阵。</p><h5 id="2-4-6-numpy-linalg-solve-示例">2.4.6 numpy.linalg.solve()示例</h5><p>$$\begin{cases}<br>x+y+z=6\<br>2y+5z=-4\<br>2x+5y-z=27<br>\end{cases} $$</p><p>转换成 $\begin{bmatrix}1 &amp; 1 &amp; 1\0 &amp; 2 &amp; 5\2 &amp; 5 &amp; -1\end{bmatrix}\begin{bmatrix}x\y\z \end{bmatrix}=\begin{bmatrix}6\-4\27 \end{bmatrix}$</p><pre><code class="highlight plaintext">import numpy as npa = np.array([[1,1,1], [0,2,5],[2,5,-1]])   # 系数矩阵b = np.array([6,-4,27])  # 系数矩阵x = np.linalg.solve(a, b)  # 求解print(x)print(np.dot(a, x))    # 验证</code></pre><p><strong>运行结果</strong><br>[ 5.  3. -2.]<br>[ 6. -4. 27.]</p><h3 id="3、pandas-数据结构">3、pandas 数据结构</h3><h4 id="3-1-引言">3.1 引言</h4><ol><li><p>Pandas 是<strong>基于 NumPy</strong> 的一种工具 ， 该工具是为了<strong>解决数据分析任务</strong>而创建的。</p></li><li><p>Pandas 纳入了大量库和一些<strong>标准的数据模型</strong> ，提供了高效地操作大型数据集所需的工具。</p></li><li><p>Pandas 提供了大量能使我们<strong>快速便捷地处理数据的函数和方法</strong>。</p></li><li><p>Pandas 是 Python 的一个数据分析包 ，最初于 2008 年 4 月开发 ，2009 年底开源 ，目前由 PyData 开发团队继续开发和维护。</p></li></ol><p>5.Pandas 最初被作为金融数据分析工具而开发出来，也为时间序列分析提供了很好的支持。</p><h4 id="3-2-pandas库介绍">3.2 pandas库介绍</h4><ol><li><p><strong>pandas</strong> 是 python 第三方库，提供高性能易用数据类型和分析工具。</p></li><li><p><strong>pandas</strong> 基于 numpy 实现，常与 numpy 和 matplotlib 一同使用。</p></li><li><p><strong>pandas</strong> 中有两大核心数据结构：<strong>Series</strong> （一维数据） 和 <strong>DataFrame</strong>（多特征数据，既有行索引，又有列索引）。</p></li></ol><p><img src="/medias/1591420106630.png" alt="Series"></p><p><img src="/medias/1591420115214.png" alt="DataFrame"></p><ol start="4"><li><p><strong>Series</strong><br>1）一维数组，与 Numpy 中的一维 array 类似 。<br>2）Series、numpy 中的一维 array 与 Python 基本的数据结构 List 也很相近， 其区别是： List 中的元素可以是不同的数据类型，而 array 和 Series 中则只允许存储相同的数据类型。<br>3）Series可以更有效的使用内存 ， 提高运算效率。</p></li><li><p><strong>Time-Series</strong>：以时间为索引的Series。</p></li><li><p><strong>DataFrame</strong>：带标签且大小可变的二维表格型数据结构，可以将 DataFrame 理解为 Series 的容器。</p></li><li><p><strong>Panel</strong>：三维的数组，可以理解为DataFrame的容器。</p></li></ol><h4 id="3-3-Series">3.3 Series</h4><ol><li><p>Series 是一种类似于一维数组的对象，它由一维数组（各种 numpy 数据类型）以及一组与之相关的数据标签（即索引）组成。</p></li><li><p>Series 创建函数：<br><strong>pandas.Series( data, index, dtype, copy)</strong></p></li></ol><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>data</code></td><td style="text-align:left">数据采取各种形式，如：<code>adarray</code>，<code>list</code>，<code>constants</code></td></tr><tr><td style="text-align:left"><code>index</code></td><td style="text-align:left">索引值必须是唯一的和散列的，与数据的长度相同。默认 <code>np.arange(n)</code> 如果没有索引被传递。</td></tr><tr><td style="text-align:left"><code>dtype</code></td><td style="text-align:left"><code>dtype</code> 用于数据类型，如果没有，将推断数据类型</td></tr><tr><td style="text-align:left"><code>copy</code></td><td style="text-align:left">复制数据，默认为 <code>false</code></td></tr></tbody></table><ol start="3"><li>Series 的创建：<br>1）使用 Python 数组创建<br>2）使用 numpy 数组创建<br>3）使用 python 字典创建<br><strong>注意</strong><br>与字典不同的是：<strong>Series允许索引重复</strong></li></ol><pre><code class="highlight plaintext">import pandas as pdimport numpy as nppd.Series([11, 12], index=["北京", "上海"])</code></pre><p><strong>运行结果</strong><br>北京    11<br>上海    12<br>dtype: int64</p><pre><code class="highlight plaintext">pd.Series(np.arange(3,6))</code></pre><p><strong>运行结果</strong><br>0    3<br>1    4<br>2    5<br>dtype: int32</p><pre><code class="highlight plaintext">pd.Series({"北京": 11, "上海": 12, "深圳": 14})</code></pre><p><strong>运行结果</strong><br>北京    11<br>上海    12<br>深圳    14<br>dtype: int64</p><ol start="4"><li><p>Series 的字符串表现形式为：<strong>索引在左边，值在右边</strong>。</p></li><li><p>如果没有为数据指定索引，则自动创建一个 0 到 N-1（N 为数据的长度）的整数型索引。</p></li><li><p>可以通过 Series 的 values 和 index 属性获取其数组表示形式和索引对象。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; obj = pd.Series([4, 7, -5, 3]) &gt;&gt;&gt; obj.valuesarray([ 4,  7, -5,  3], dtype=int64) &gt;&gt;&gt; obj.indexRangeIndex(start=0, stop=4, step=1)&gt;&gt;&gt; obj[2]-5&gt;&gt;&gt; obj[1] = 8 &gt;&gt;&gt; obj[[0, 1, 3]]0    41    83    3dtype: int64</code></pre><ol start="7"><li><p>通常希望所创建的 Series 带有一个可以对各个数据点进行标记的索引。</p></li><li><p>与普通 NumPy 数组相比，可以通过索引的方式选取 Series 中的单个或一组值。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; obj2=pd.Series([4,2,-5,3],index=['a', 'b', 'c', 'd'])&gt;&gt;&gt; obj2a    4b    2c   -5d    3dtype: int64&gt;&gt;&gt; obj2['a']4&gt;&gt;&gt; obj2['d'] = 6 &gt;&gt;&gt; obj2a    4b    2c   -5d    6dtype: int64&gt;&gt;&gt; obj2[['a','b','d']]a    4b    2d    6dtype: int64</code></pre><ol start="9"><li>Series 中很重要的一个功能是：它会在算术运算中自动对齐不同索引的数据。</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; obj2 = pd.Series({"Ohio": 35000, "Oregon": 16000, "Texas": 71000, "Utah": 5000})&gt;&gt;&gt; obj3 = pd.Series({"California": np.nan, "Ohio": 35000, "Oregon": 16000, "Texas": 71000})&gt;&gt;&gt; obj2 + obj3California         NaNOhio           70000.0Oregon         32000.0Texas         142000.0Utah               NaNdtype: float64</code></pre><ol start="10"><li><p>Series 对象本身及其索引都有一个 name 属性</p></li><li><p>Series 的索引可以通过赋值的方式就地修改</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; obj3.name= 'population' &gt;&gt;&gt; obj3.index.name = 'state' &gt;&gt;&gt; obj3stateCalifornia        NaNOhio          35000.0Oregon        16000.0Texas         71000.0Name: population, dtype: float64&gt;&gt;&gt; obj = pd.Series([4, 7, -5, 3])&gt;&gt;&gt; obj.index = ['Bob', 'Steve', 'Jeff', 'Ryan'] &gt;&gt;&gt; objBob      4Steve    7Jeff    -5Ryan     3dtype: int64</code></pre><h4 id="3-4-DataFrame">3.4 DataFrame</h4><h5 id="3-4-1-DataFrame介绍">3.4.1 DataFrame介绍</h5><ol><li>DataFrame 是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。</li><li>DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共用同一个索引）。</li><li>跟其他类似的数据结构相比（如 R 语言的 data.frame），DataFrame 中面向行和面向列的操作基本上是平衡的。</li><li>DataFrame 中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。</li></ol><h5 id="3-4-2-DataFrame特点">3.4.2 DataFrame特点</h5><ol><li>潜在的列是不同的类型</li><li>大小可变</li><li>标记轴( ( 行和列) )</li><li>可以对行和列执行算术运算</li></ol><h5 id="3-4-3-DataFrame示例">3.4.3 DataFrame示例</h5><p>学生数据<br><img src="/medias/1591421808705.png" alt="学生数据"></p><h5 id="3-4-4-DataFrame构造函数">3.4.4 DataFrame构造函数</h5><p><strong>pandas.DataFrame( data, index, columns, dtype, copy)</strong></p><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><code>data</code></td><td style="text-align:left">数据采取各种形式，如：<code>ndarray</code>, <code>series</code>, <code>map</code>, <code>lists</code>, <code>dict</code>, <code>constant</code> 和另一个 <code>DataFrame</code></td></tr><tr><td style="text-align:left"><code>index</code></td><td style="text-align:left">对于行标签，要用于结果帧的索引是可选缺省值 <code>np.arrange(n)</code>，如果没有传递索引值</td></tr><tr><td style="text-align:left"><code>columns</code></td><td style="text-align:left">对于列标签，可选的默认语法是—— <code>np.arange(n)</code>。这只有在没有索引传递的情况下才是这样</td></tr><tr><td style="text-align:left"><code>dtype</code></td><td style="text-align:left">每列的数据类型</td></tr><tr><td style="text-align:left"><code>copy</code></td><td style="text-align:left">如果默认值为 <code>False</code>，则此命令（或任何它）用于复制数据</td></tr></tbody></table><h5 id="3-4-5-DataFrame">3.4.5 DataFrame</h5><ol><li>创建一个空的 DataFrame：函数不指定参数返回空 DataFrame</li></ol><pre><code class="highlight plaintext"># 创建一个空的DataFrame import pandas as pddf = pd.DataFrame() print(df)</code></pre><p><strong>运行结果</strong><br>Empty DataFrame<br>Columns: []<br>Index: []</p><ol start="2"><li>从列表创建 DataFrame</li></ol><pre><code class="highlight plaintext"># 从单个列表创建DataFramedata = [1,2,3,4]df = pd.DataFrame(data) print(df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">   00  11  22  33  4</code></pre><pre><code class="highlight plaintext"># 从嵌套列表创建DataFrame、并指定数据类型data = [['Alex',10],['Bob',12],['Clarke',13]]df = pd.DataFrame(data,columns=['Name','Age'],dtype=float) print(df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">     Name   Age0    Alex  10.01     Bob  12.02  Clarke  13.0</code></pre><ol start="3"><li><p>由等长列表或 numpy 数组组成的字典创建 DataFrame。</p></li><li><p>DataFrame 结果会自动加上索引（跟 Series 一样），且全部会被有序排列。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'year': [2000 , 2001, 2002, 2001, 2002], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}&gt;&gt;&gt; frame = pd.DataFrame(data)&gt;&gt;&gt; frame</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">stateyearpop0Ohio20001.51Ohio20011.72Ohio20023.63Nevada20012.44Nevada20022.9</code></pre><ol start="5"><li><p>如果指定了列顺序，则 DataFrame 的列就会按照指定顺序进行排列。</p></li><li><p>跟原 Series 一样，如果传入的列在数据中找不到，就会产生 NAN 值。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; pd.DataFrame(data, columns=['year', 'state', 'pop'])</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">yearstatepop02000Ohio1.512001Ohio1.722002Ohio3.632001Nevada2.442002Nevada2.9</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five'])&gt;&gt;&gt; frame2</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        yearstatepop  debtone    2000Ohio1.5  NaNtwo    2001Ohio1.7  NaNthree2002Ohio3.6  NaNfour2001Nevada2.4  NaNfive2002Nevada2.9  NaN</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2.columns</code></pre><p><strong>运行结果</strong><br>Index([‘year’, ‘state’, ‘pop’, ‘debt’], dtype=‘object’)</p><ol start="7"><li><p>通过类似字典标记的方式或属性的方式，可以将 DataFrame 的列获取为一个 Series。</p></li><li><p>返回的 Series 拥有原 DataFrame 相同的索引，且其 name 属性也已经被相应地设置好了。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2['state']</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">one        Ohiotwo        Ohiothree      Ohiofour     Nevadafive     NevadaName: state, dtype: object</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2['year']</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">one      2000two      2001three    2002four     2001five     2002Name: year, dtype: int64</code></pre><ol start="9"><li><p>列可以通过赋值的方式进行修改。</p></li><li><p>例如，给那个空的“delt”列赋上一个标量值或一组值。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2['debt'] = 16.5 &gt;&gt;&gt; frame2</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">    yearstatepop debtone    2000Ohio1.5 16.5two    2001Ohio1.7 16.5three2002Ohio3.6  16.5four2001Nevada2.4  16.5five2002Nevada2.9  16.5</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2['debt'] = np.arange(5.) &gt;&gt;&gt; frame2</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">    yearstatepop  debtone    2000Ohio1.5  0.0two    2001Ohio1.7  1.0three2002Ohio3.6  2.0four2001Nevada2.4  3.0five2002Nevada2.9 4.0</code></pre><ol start="11"><li><p>将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。</p></li><li><p>如果赋值的是一个 Series，就会精确匹配 DataFrame 的索引，所有空位都将被填上缺失值。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five']) &gt;&gt;&gt; frame2['debt'] = val&gt;&gt;&gt; frame2</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        yearstatepop debtone    2000Ohio1.5 NaNtwo    2001Ohio1.7 -1.2three2002Ohio3.6 NaNfour2001Nevada2.4 -1.5five2002Nevada2.9 -1.7</code></pre><ol start="13"><li><p>为不存在的列赋值会创建出一个新列</p></li><li><p>关键字 del 用于删除列</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2['eastern'] = frame2.state == 'Ohio' &gt;&gt;&gt; frame2</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        yearstatepop  debteasternone 2000Ohio1.5  NaN    Truetwo    2001Ohio1.7 -1.2 Truethree2002Ohio3.6  NaN    Truefour2001Nevada2.4 -1.5 Falsefive2002Nevada2.9 -1.7 False</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; del frame2['eastern']&gt;&gt;&gt; frame2.columns</code></pre><p><strong>运行结果</strong><br>Index([‘year’, ‘state’, ‘pop’, ‘debt’], dtype=‘object’)</p><ol start="15"><li><p>将嵌套字典（也就是字典的字典）传给 DataFrame，它就会被解释为：外层字典的键作为列，内层键则作为行索引。</p></li><li><p>也可以对上述结果进行转置。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; pop = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}&gt;&gt;&gt; frame3 = pd.DataFrame(pop)&gt;&gt;&gt; frame3</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">    NevadaOhio2001 2.4    1.72002 2.9    3.62000 NaN    1.5</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; frame3.T</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">    200120022000Nevada2.4    2.9    NaNOhio1.7    3.6    1.5</code></pre><ol start="17"><li>如果设置了 DataFrame 的 index 和 columns 的 name 属性，则这些信息也会被显示出来。</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; frame3.index.name = 'year' &gt;&gt;&gt; frame3.columns.name = 'state' &gt;&gt;&gt; frame3</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">stateNevadaOhioyear20012.4    1.720022.9    3.62000NaN    1.5</code></pre><ol start="18"><li><p>跟 Series 一样，values 属性也会以二维 ndarray 的形式返回 DataFrame 中的数据。</p></li><li><p>如果 DataFrame 各列的数据类型不同，则数组的数据类型就会选用能兼容所有列的数据类型。</p></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; frame3.values</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">array([[2.4, 1.7],       [2.9, 3.6],       [nan, 1.5]])</code></pre><pre><code class="highlight plaintext">&gt;&gt;&gt; frame2.values</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">array([[2000, 'Ohio', 1.5, nan],       [2001, 'Ohio', 1.7, -1.2],       [2002, 'Ohio', 3.6, nan],       [2001, 'Nevada', 2.4, -1.5],       [2002, 'Nevada', 2.9, -1.7]], dtype=object)</code></pre><h3 id="4、pandas-常用方法">4、pandas 常用方法</h3><h4 id="4-1-数据读取与写入">4.1 数据读取与写入</h4><ol><li><p>Pandas 支持常用的文本格式数据(csv、json、html、剪贴板)、二进制数据(excel、hdf5 格式、Feather 格式、Parquet 格式、Msgpack、 Stata、SAS、pkl)、SQL 数据(SQL、谷歌 BigQuery 云数据)等。</p></li><li><p>一般情况下 ， 读取文件的方法以 pd.read_ 开头， 而写入文件的方法以 pd.to_ 开头。</p></li><li><p>示例1</p></li></ol><pre><code class="highlight plaintext"># 示例1，读入剪贴板数据，写入csv，转换为json、html、excel等格式import pandas as pdimport numpy as npfrom pandas import Series, DataFrame# 粘贴板内容#ABC# x14p# y25q# z36r# 从粘贴板读取数据df1 = pd.read_clipboard()# 把数据放入到粘贴板中，数据可以直接粘贴到 excel 文件中df1.to_clipboard()# 读写 csv 文件，可以取消 indexdf1.to_csv('df1.csv')df1.to_csv('df1_noIndex.csv', index = False)# 转化为 json 格式df1.to_json('df1.json')# 转化为 html 格式df1.to_html('df1.html')# 转换为 excel 格式df1.to_excel('df1.xlsx')</code></pre><table><thead><tr><th style="text-align:left">数据类型</th><th style="text-align:left">描述符</th><th style="text-align:left">读方法</th><th style="text-align:left">写方法</th></tr></thead><tbody><tr><td style="text-align:left">text</td><td style="text-align:left">CSV</td><td style="text-align:left"><code>read_csv</code></td><td style="text-align:left"><code>to_csv</code></td></tr><tr><td style="text-align:left">text</td><td style="text-align:left">JSON</td><td style="text-align:left"><code>read_json</code></td><td style="text-align:left"><code>to_json</code></td></tr><tr><td style="text-align:left">text</td><td style="text-align:left">HTML</td><td style="text-align:left"><code>read_csv</code></td><td style="text-align:left"><code>to_csv</code></td></tr><tr><td style="text-align:left">text</td><td style="text-align:left">剪切板</td><td style="text-align:left"><code>read_clipboard</code></td><td style="text-align:left"><code>to_clipboard</code></td></tr><tr><td style="text-align:left">二进制</td><td style="text-align:left">Excel</td><td style="text-align:left"><code>read_excel</code></td><td style="text-align:left"><code>to_excel</code></td></tr><tr><td style="text-align:left">二进制</td><td style="text-align:left">HDF5</td><td style="text-align:left"><code>read_hdf</code></td><td style="text-align:left"><code>to_hdf</code></td></tr><tr><td style="text-align:left">二进制</td><td style="text-align:left">PKL</td><td style="text-align:left"><code>read_pickle</code></td><td style="text-align:left"><code>to_pickle</code></td></tr><tr><td style="text-align:left">SQL</td><td style="text-align:left">SQL</td><td style="text-align:left"><code>read_sql</code></td><td style="text-align:left"><code>to_sql</code></td></tr></tbody></table><p><strong>数据读取函数read_csv示例</strong></p><ol><li><p>read_csv（）</p></li><li><p>自定义索引：可以指定 csv 文件中的一列来使用 index_col 定制索引</p></li><li><p>dtype：数据类型转换</p></li><li><p>skiprows：跳过指定的行数</p></li><li><p>示例2</p></li></ol><pre><code class="highlight plaintext"># 示例 2-1 read_csvdf=pd.read_csv('temp.csv') print(df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">   S.No    Name  Agw       City  Salary0     1     Tom   28    Toronto   200001     2     Lee   32   HongKong    30002     3  Steven   43   Bay Area    83003     4     Ram   38  Hyderabad    3900</code></pre><pre><code class="highlight plaintext"># 示例 2-2  自定义索引：可以指定 csv 文件中的一列来使用 index_col 指定索引df = pd.read_csv("temp.csv", index_col=['S.No']) print(df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        Name  Agw       City  SalaryS.No                                1        Tom   28    Toronto   200002        Lee   32   HongKong    30003     Steven   43   Bay Area    83004        Ram   38  Hyderabad    3900</code></pre><pre><code class="highlight plaintext"># 示例 2-3 转换器 dtypedf = pd.read_csv("temp.csv", dtype={'Salary': np.float64}) print(df) print(df.dtypes)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">   S.No    Name  Agw       City   Salary0     1     Tom   28    Toronto  20000.01     2     Lee   32   HongKong   3000.02     3  Steven   43   Bay Area   8300.03     4     Ram   38  Hyderabad   3900.0S.No        int64Name       objectAgw         int64City       objectSalary    float64dtype: object</code></pre><pre><code class="highlight plaintext"># 示例 2-4  使用 names参数指定标题名称df=pd.read_csv("temp.csv", names=['a', 'b', 'c','d','e']) print(df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">      a       b    c          d       e0  S.No    Name  Agw       City  Salary1     1     Tom   28    Toronto   200002     2     Lee   32   HongKong    30003     3  Steven   43   Bay Area    83004     4     Ram   38  Hyderabad    3900</code></pre><p>观察可以看到，标题名称附加了自定义名称，但文件中的标题还没有被消除。现在使用header参数来删除它。如果标题不是第一行，则将行号传递给标题，这将跳过前面的行。</p><pre><code class="highlight plaintext"># 示例 2-5消除文件中的标题df=pd.read_csv("temp.csv", names=['a', 'b', 'c','d','e'], header=0) print(df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">   a       b   c          d      e0  1     Tom  28    Toronto  200001  2     Lee  32   HongKong   30002  3  Steven  43   Bay Area   83003  4     Ram  38  Hyderabad   3900</code></pre><pre><code class="highlight plaintext"># 示例 2-6 skiprows跳过指定的行数df=pd.read_csv("temp.csv", skiprows=2) print (df)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">   2     Lee  32   HongKong  30000  3  Steven  43   Bay Area  83001  4     Ram  38  Hyderabad  3900</code></pre><h4 id="4-2-描述性统计方法">4.2 描述性统计方法</h4><ol><li><p>Pandas 提供了几个统计和描述性方法，方便你从宏观的角度去了解数据集，例如count() 用于统计非空数据的数量。</p></li><li><p>除了统计类的方法，Pandas 还 提供了很多计算类的方法，比如 sum() 用于计算数值数据的总和；mean() 用 于 计 算 数 值 数 据 的 平 均 值 ；median() 用于计算数值数据的算术中值。</p></li></ol><table><thead><tr><th style="text-align:left">函数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">count()</td><td style="text-align:left">非空观测数量</td></tr><tr><td style="text-align:left">sum()</td><td style="text-align:left">所有值之和</td></tr><tr><td style="text-align:left">mean()</td><td style="text-align:left">所有值的平均值</td></tr><tr><td style="text-align:left">median()</td><td style="text-align:left">所有值的中位数</td></tr><tr><td style="text-align:left">mode()</td><td style="text-align:left">值的模值</td></tr><tr><td style="text-align:left">std()</td><td style="text-align:left">值的标准偏差</td></tr><tr><td style="text-align:left">min()</td><td style="text-align:left">所有值中的最小值</td></tr><tr><td style="text-align:left">max()</td><td style="text-align:left">所有值中的最大值</td></tr><tr><td style="text-align:left">abs()</td><td style="text-align:left">绝对值</td></tr><tr><td style="text-align:left">prod()</td><td style="text-align:left">数组元素的乘积</td></tr><tr><td style="text-align:left">cumsum()</td><td style="text-align:left">累计总和</td></tr><tr><td style="text-align:left">cumprod()</td><td style="text-align:left">累计乘积</td></tr></tbody></table><p><strong>描述性统计方法示例</strong><br><strong>sum()</strong>：求和；<br><strong>mean()</strong> ：求中值；<br><strong>std()</strong>：求标准差；<br><strong>describe()</strong>：描述性统计信息摘要。</p><pre><code class="highlight plaintext"># 示例3 描述统计方法import pandas as pdimport numpy as np# Create a Dictionary of seriesd = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Minsu','Jack','Lee','David','Gasper','Betina','Andres']),'Age':pd.Series([25,26,25,23,30,29,23,34,40,30,51,46]),'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8,3.78,2.98,4.80,4.10,3.65])}#Create a DataFramedf = pd.DataFrame(d)print(df, '\n')print("\n列求和")print(df.sum(), '\n')  # 列求和， 默认axis=0.print("\n行求和")print(df.sum(1), '\n')   # 行求和，axis=1print("\n求均值")print(df.mean(), '\n')   # 求均值print("\n标准差")print(df.std(), '\n')    # 标准差# include参数是用于传递关于什么列需要考虑用于总结的必要信息的参数，获取值列表，默认情况下是“数字值”。# object - 汇总字符串列；# number - 汇总数字列；# all - 将所有列汇总在一起（不应将其作为列表值传递）。print("\n统计信息摘要")print(df.describe(include=['number']))    # 统计信息摘要</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">      Name   Age  Rating0      Tom   25    4.231    James   26    3.242    Ricky   25    3.983      Vin   23    2.564    Steve   30    3.205    Minsu   29    4.606     Jack   23    3.807      Lee   34    3.788    David   40    2.989   Gasper   30    4.8010  Betina   51    4.1011  Andres   46    3.65 列求和Name      TomJamesRickyVinSteveMinsuJackLeeDavidGasperBe...Age                                                     382Rating                                                44.92dtype: object 行求和0     29.231     29.242     28.983     25.564     33.205     33.606     26.807     37.788     42.989     34.8010    55.1011    49.65dtype: float64 求均值Age       31.833333Rating     3.743333dtype: float64 标准差Age       9.232682Rating    0.661628dtype: float64 统计信息摘要             Age     Ratingcount  12.000000  12.000000mean   31.833333   3.743333std     9.232682   0.661628min    23.000000   2.56000025%    25.000000   3.23000050%    29.500000   3.79000075%    35.500000   4.132500max    51.000000   4.800000</code></pre><h4 id="4-3-迭代与遍历">4.3 迭代与遍历</h4><ol><li><p>pandas 对象之间的基本迭代的行为取决于类型。当迭代一个系列时，它被视为数组式，基本迭代产生这些值。其他数据结构，如：DataFrame，遵循类似惯例迭代对象的键。</p></li><li><p>简而言之，基本迭代(对于 i 在对象中)产生：<br>➢Series - 值<br>➢DataFrame - 列标签</p></li><li><p>要遍历数据帧(DataFrame)中的行，可以使用以下函数：<br>➢iteritems() - 迭代(key，value)对<br>➢iterrows() - 将行迭代为(索引，系列)对<br>➢itertuples() - 以 namedtuples 的形式迭代行</p></li></ol><h5 id="4-3-1-迭代-DataFrame">4.3.1 迭代 DataFrame</h5><pre><code class="highlight plaintext"># 迭代 DataFrameimport pandas as pdimport numpy as npN=5df = pd.DataFrame({    'D': pd.date_range(start='2019-01-01',periods=N,freq='M'),     'x': np.linspace(0,stop=N-1,num=N),    'y': np.random.rand(N),    'z': np.random.choice(['Low','Medium','High'],N).tolist(),})print(df,'\n')for col in df:    print(col)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">           D    x         y       z0 2019-01-31  0.0  0.088484    High1 2019-02-28  1.0  0.763299    High2 2019-03-31  2.0  0.918397    High3 2019-04-30  3.0  0.785687  Medium4 2019-05-31  4.0  0.821885     Low Dxyz</code></pre><h5 id="4-3-2-遍历Dataframe-示例">4.3.2 遍历Dataframe 示例</h5><ol><li>iteritems()：将索引和值作为键和列值迭代为 Series 对象。</li><li>iterrows()：返回迭代器，产生每个索引值以及包含每行数据的序列。</li><li>itertuples()：方法将为 DataFrame 中的每一行返回一个产生一个命名元组的迭代器。元组的第一个元素将是行的相应索引值，而剩余的值是行值。</li></ol><pre><code class="highlight plaintext"># 遍历 iteritems()将每个列作为名称，将索引和值作为键和列值迭代为Series对象df = pd.DataFrame(np.random.randn(4,3), columns=['col1','col2','col3'])print(df, '\n')print("\niteritems---------")for key,value in df.iteritems():      print (key,value)# iterrows()返回迭代数器，产生每个索引值以及包含每行数据的序列print("\niterrows---------")for row_index,row in df.iterrows():        print (row_index,row) # itertuples()方法将为 DataFrame 中的每一行返回一个产生一个命名元组的迭代器。元组的第一个元素将是行的相应索引值，而剩余的值是行值print("\nitertuples---------")for row in df.itertuples():        print (row)</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">       col1      col2      col30  0.769239 -0.321667  0.2299701 -0.414440 -0.686365 -1.8045742 -0.625321 -0.410545 -0.2668783  0.942061 -0.429502 -0.191403 iteritems---------col1 0    0.7692391   -0.4144402   -0.6253213    0.942061Name: col1, dtype: float64col2 0   -0.3216671   -0.6863652   -0.4105453   -0.429502Name: col2, dtype: float64col3 0    0.2299701   -1.8045742   -0.2668783   -0.191403Name: col3, dtype: float64iterrows---------0 col1    0.769239col2   -0.321667col3    0.229970Name: 0, dtype: float641 col1   -0.414440col2   -0.686365col3   -1.804574Name: 1, dtype: float642 col1   -0.625321col2   -0.410545col3   -0.266878Name: 2, dtype: float643 col1    0.942061col2   -0.429502col3   -0.191403Name: 3, dtype: float64itertuples---------Pandas(Index=0, col1=0.7692393725888382, col2=-0.3216667049027107, col3=0.22996991034224118)Pandas(Index=1, col1=-0.41444004324475786, col2=-0.6863646340873751, col3=-1.8045739966582113)Pandas(Index=2, col1=-0.625321480205094, col2=-0.4105445003436983, col3=-0.2668784127256191)Pandas(Index=3, col1=0.9420608482646933, col2=-0.4295015650195585, col3=-0.191402644416027)​</code></pre><h4 id="4-4-排序">4.4 排序</h4><ol><li><p>按索引排序：使用 sort_index() 方法，通过传递 axis 参数和排序顺序，可以对 DataFrame 进行排序。 默认情况下，按照升序对行标签进行排序。</p></li><li><p>按数值排序：sort_values() 是按值排序的方法。它接受一个 by 参数，它将使用要与其排序值的 DataFrame 的列名称。</p></li><li><p>排序顺序：通过将布尔值传递给升序参数 ascending，可以控制排序顺序。</p></li><li><p>按行或列排序：通过设置 axis 参数为 0 或 1 ，为 0 时逐行排序，为 1 时逐列排序，默认为 0。</p></li></ol><p><strong>排序示例</strong></p><pre><code class="highlight plaintext">print("\n待排序------")unsorted_df = pd.DataFrame(np.random.rand(10,2),index=[1,4,6,2,3,5,9,8,0,7],columns = ['A','B'])print(unsorted_df,'\n')print("\n按索引排序------")sorted_df=unsorted_df.sort_index(ascending = True)  #按索引排序print (sorted_df,'\n')print("\n按'B'列的值进行排序------")sorted_df = unsorted_df.sort_values(by='B') # 按'B'列的值进行排序print (sorted_df,'\n')</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">待排序------          A         B1  0.301330  0.3036824  0.955318  0.0358096  0.254245  0.7982252  0.408592  0.4705273  0.885707  0.1312585  0.135931  0.8597959  0.934681  0.2183918  0.992487  0.4160870  0.221823  0.4683667  0.414039  0.531079 按索引排序------          A         B0  0.221823  0.4683661  0.301330  0.3036822  0.408592  0.4705273  0.885707  0.1312584  0.955318  0.0358095  0.135931  0.8597956  0.254245  0.7982257  0.414039  0.5310798  0.992487  0.4160879  0.934681  0.218391 按'B'列的值进行排序------          A         B4  0.955318  0.0358093  0.885707  0.1312589  0.934681  0.2183911  0.301330  0.3036828  0.992487  0.4160870  0.221823  0.4683662  0.408592  0.4705277  0.414039  0.5310796  0.254245  0.7982255  0.135931  0.859795</code></pre><h4 id="4-5-缺失值处理">4.5 缺失值处理</h4><ol><li><p>缺失值主要是指数据丢失的现象，也就是数据集中的某一块数据不存在。</p></li><li><p>除了原始数据集就已经存在缺失值以外，当我们用到索引对齐（reindex()，选择等）方法时，也容易人为导致缺失值的产生。</p></li><li><p><strong>缺失值处理</strong>包括：<br>➢ 缺失值标记<br>➢ 缺失值填充<br>➢ 缺失值插值</p></li><li><p>Pandas 为了更方便地<strong>检测缺失值</strong>，将不同类型数据的缺失均采用 NaN 标记。这里的 NaN 代表 Not a Number ，它仅仅是作为一个标记。</p></li><li><p>Pandas 中用于<strong>标记缺失值主要用到两个方法</strong>，分别是：isnull () 和 notnull ()，顾名思义就是「是缺失值」和「不是缺失值」。默认会返回布尔值用于判断。</p></li></ol><pre><code class="highlight plaintext"># 使用reindex()人为生成缺失值df = pd.DataFrame(np.random.rand(4, 3), index=['a', 'c', 'e', 'f'],columns=['one', 'two', 'three'])print('原始：\n', df,'\n')df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g'])print('reindex后：\n', df,'\n')print(df['one'].isnull(),'\n')  # 缺失值标记print (df['one'].notnull(),'\n')</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">原始：         one       two     threea  0.051237  0.164315  0.632927c  0.459356  0.435970  0.615046e  0.420776  0.668942  0.680803f  0.086104  0.409684  0.162472 reindex后：         one       two     threea  0.051237  0.164315  0.632927b       NaN       NaN       NaNc  0.459356  0.435970  0.615046d       NaN       NaN       NaNe  0.420776  0.668942  0.680803f  0.086104  0.409684  0.162472g       NaN       NaN       NaN a    Falseb     Truec    Falsed     Truee    Falsef    Falseg     TrueName: one, dtype: bool a     Trueb    Falsec     Trued    Falsee     Truef     Trueg    FalseName: one, dtype: bool</code></pre><ol start="6"><li>Pandas 提供了各种方法来<strong>清除缺失的值</strong>。fillna() 函数可以通过几种方法用非空数据“填充” NaN 值。<br>1）用标量值替换 NaN<br><strong>print (df.fillna(0))</strong></li></ol><pre><code class="highlight plaintext"># 用标量填充print("NaN replaced with '0'：")print(df.fillna(0))</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">NaN replaced with '0'：        one       two     threea  0.051237  0.164315  0.632927b  0.000000  0.000000  0.000000c  0.459356  0.435970  0.615046d  0.000000  0.000000  0.000000e  0.420776  0.668942  0.680803f  0.086104  0.409684  0.162472g  0.000000  0.000000  0.000000</code></pre><p>2）向前填充：pad/fill<br><strong>print(df.fillna(method='pad’))</strong></p><pre><code class="highlight plaintext"># 向前填充print(df.fillna(method='pad'))</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        one       two     threea  0.051237  0.164315  0.632927b  0.051237  0.164315  0.632927c  0.459356  0.435970  0.615046d  0.459356  0.435970  0.615046e  0.420776  0.668942  0.680803f  0.086104  0.409684  0.162472g  0.086104  0.409684  0.162472</code></pre><p>3）向后填充：bfill/backfill<br><strong>print(df.fillna(method=‘backfill’))</strong></p><pre><code class="highlight plaintext"># 向后填充print (df.fillna(method='backfill'))</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        one       two     threea  0.051237  0.164315  0.632927b  0.459356  0.435970  0.615046c  0.459356  0.435970  0.615046d  0.420776  0.668942  0.680803e  0.420776  0.668942  0.680803f  0.086104  0.409684  0.162472g       NaN       NaN       NaN</code></pre><ol start="7"><li><strong>丢弃缺少的值</strong>：如果只想排除缺少的值，则使用 dropna 函数和 axis 参数。默认情况下，axis=0，如果行内的任何值是 NaN，那么整个行被删除。<br>1）丢弃含 NaN 值的行<br><strong>print(df.dropna())</strong><br>2）丢弃含 NaN 值的列<br><strong>print (df.dropna(axis=1))</strong></li></ol><pre><code class="highlight plaintext">df = pd.DataFrame(np.random.rand(4, 3), index=['a', 'c', 'e', 'f'], columns=['one', 'two', 'three'])df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g'])print(df,'\n')print(df.dropna()) # 丢弃含 NaN 值的行print (df.dropna(axis=1)) # 丢弃含 NaN 值的列</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">        one       two     threea  0.430961  0.718700  0.023831b       NaN       NaN       NaNc  0.560938  0.816387  0.409205d       NaN       NaN       NaNe  0.945503  0.838175  0.707113f  0.987987  0.275285  0.532072g       NaN       NaN       NaN         one       two     threea  0.430961  0.718700  0.023831c  0.560938  0.816387  0.409205e  0.945503  0.838175  0.707113f  0.987987  0.275285  0.532072Empty DataFrameColumns: []Index: [a, b, c, d, e, f, g]</code></pre><ol start="8"><li><strong>替换缺失（或通用）值</strong>：用一些具体的值取代一个通用的值或缺失值。用标量替换 NaN 和使用 fillna() 函数等效。</li></ol><pre><code class="highlight plaintext"># 替换通用数据或者缺失值df = pd.DataFrame({'one':[10,20,30,40,50,2000],'two':[1000,0,30,40,50,60]}) print(df,'\n')print(df.replace({1000:10,2000:60}))</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第三章 Python 编程进阶</title>
      <link href="/2020/06/02/di_san_zhang_python_bian_cheng_jin_jie/"/>
      <url>/2020/06/02/di_san_zhang_python_bian_cheng_jin_jie/</url>
      
        <content type="html"><![CDATA[<h2 id="第三章-Python-编程进阶"><strong>第三章 Python 编程进阶</strong></h2><h3 id="1、输入输出与文件操作"><strong>1、输入输出与文件操作</strong></h3><ol><li><strong>输入输出</strong><br><strong>基本输入、输出</strong></li><li><strong>文件操作</strong><br><strong>文件编码、基本操作</strong></li></ol><h4 id="1-1-输入"><strong>1.1 输入</strong></h4><ol><li><strong>Python 提供了 input() 内置函数从标准输入读入一行文本。</strong></li><li><strong>input() 函数也可以接收一个 Python 表达式作为输入，并将运算结果返回。</strong></li><li><strong>input() 函数的返回值永远是字符串，当我们需要返回 int 型时需要使用int(input()) 。</strong></li></ol><p><strong>eval() 函数用来执行一个字符串表达式，并返回表达式的值。</strong></p><pre><code class="highlight plaintext">str = input("请输入：")print("你输入的内容是：", str)sum = input("请输入算术表达式：")sum = eval(sum)print(sum)</code></pre><p><strong>请输入：Python编程学习</strong><br><strong>你输入的内容是： Python编程学习</strong><br><strong>请输入算术表达式：2+5</strong><br><strong>7</strong></p><h4 id="1-2-输出"><strong>1.2 输出</strong></h4><ol><li><strong>用 print() 在括号中加上字符串，就可以向屏幕上输出指定的文字。比如：输出“hello world”，用代码实现如下：</strong><br><strong>print(“hello world”)</strong></li><li><strong>print() 函数也可以接受多个字符串，用逗号“,”隔开，就可以连成一串输出：</strong><br><strong>print(‘The quick brown fox’, ‘jumps over’, ‘the lazy dog!’)</strong></li><li><strong>print() 会依次打印每个字符串，遇到逗号","会输出一个空格，因此，输出的字符串是这样拼起来的：</strong></li></ol><pre><code class="highlight plaintext">print('The quick brown fox', 'jumps over', 'the lazy dog!')</code></pre><p><strong>The quick brown fox jumps over the lazy dog!</strong></p><ol start="4"><li><p><strong>print()也可以打印整数，或者计算结果：</strong><br><strong>print(300)   # 输出300</strong><br><strong>print(100+200)  # 输出300</strong></p></li><li><p><strong>print()函数也可以接受多个字符串，用逗号“,”隔开，就可以连成一串输出：</strong></p></li></ol><pre><code class="highlight plaintext">print('100+200=', 100+200)</code></pre><p><strong>100+200= 300</strong></p><p><strong>对于100 + 200，Python解释器自动计算出结果300，但是，'100 + 200 ='是字符串而非数学公式，Python把它视为字符串。</strong></p><h4 id="1-3-格式化输出"><strong>1.3 格式化输出</strong></h4><h5 id="1-3-1-整数的输出"><strong>1.3.1  整数的输出</strong></h5><p><strong>1）%o ---- oct 八进制</strong><br><strong>2）%d ---- dec 十进制</strong><br><strong>3）%x ---- hex 十六进制</strong></p><pre><code class="highlight plaintext">print('%o' % 20)print('%d' % 20)print('%x' % 20)</code></pre><p><strong>24</strong><br><strong>20</strong><br><strong>14</strong></p><h5 id="1-3-2-浮点数的输出"><strong>1.3.2  浮点数的输出</strong></h5><p><strong>1）</strong></p><pre><code class="highlight plaintext">print('%f' % 1.11)     # 默认保留6位小数print('%.1f' % 1.11)   # 取1位小数print('%e' % 1.11)     # 默认6位小数，用科学计数法print('%.3e' % 1.11)   # 取3位小数，用科学计数法print('%g' % 1111.1111)    # 默认6位有效数字print('%.7g' % 1111.1111)  # 取7位有效数字print('%.2g' % 1111.1111)  # 取2位有效数字，自动转换为科学计数法1.1e+03</code></pre><p><strong>1.110000</strong><br><strong>1.1</strong><br><strong>1.110000e+00</strong><br><strong>1.110e+00</strong><br><strong>1111.11</strong><br><strong>1111.111</strong><br><strong>1.1e+03</strong></p><p><strong>2）</strong><br><strong>round(number[, ndigits])</strong></p><p><strong><code>number</code> ---- 这是一个数字表达式。</strong><br><strong><code>ndigits</code> ---- 表示从小数点到最后四舍五入的位数。默认值为 0。</strong><br><strong>：该方法返回 x 的小数点舍入为 n 位数后的值。</strong><br><strong><br></strong></p><ol><li><strong>round()函数只有一个参数，不指定位数时，返回一个整数，而且是最靠近的整数，类似于四舍五入。</strong></li><li><strong>当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则。</strong></li><li><strong>但是碰到.5的情况时，如果要取舍的位数前的小数是奇数，则直接舍弃，如果是偶数则向上取舍。</strong></li></ol><pre><code class="highlight plaintext">round(1.1125) # 四舍五入，不指定位数，取整round(1.1135,3) # 取3位小数，由于3为奇数，则向下“舍”round(1.1125,3) # 取3位小数，由于2为偶数，则向上“入”round(2.675, 2) # 取2们有效小数</code></pre><p><strong>1</strong><br><strong>1.113</strong><br><strong>1.113</strong><br><strong>2.67</strong></p><p><strong>round(2.675, 2) 的结果，结果应该是2.68的，但它偏偏是2.67，为什么？这跟浮点数的精度有关。在机器中浮点数不一定能精确表达，换算成一串1和 0 后可能是无限位数的，机器已经做出了截断处理。因此在机器中保存的2.675这个数字就比实际数字要小那么一点点。这一点点就导致了它离2.67要更近一点点，所以保留两位小数时就近似到了2.67。</strong></p><h5 id="1-3-3-字符串输出"><strong>1.3.3 字符串输出</strong></h5><ol><li><strong>%s</strong></li><li><strong>%10s —— 右对齐，占位符10位</strong></li><li><strong>%.2s —— 截取2位字符串</strong></li></ol><pre><code class="highlight plaintext">print('%s' % 'hello world') # 字符串输出print('%20s' % 'hello world') # 右对齐，取20位，不够则补位print('%-20s' % 'hello world') # 左对齐，取20位，不够则补位print('%.2s' % 'hello world') # 取2位print('%10.2s' % 'hello world') # 右对齐，取2位print('%-10.2s' % 'hello world') # 左对齐，取2位</code></pre><p><strong>结果：</strong></p><pre><code class="highlight plaintext">hello world         hello worldhello world         he        hehe</code></pre><h3 id="2、文件"><strong>2、文件</strong></h3><h4 id="2-1-文件编码"><strong>2.1 文件编码</strong></h4><h5 id="2-1-1-ASCII-码"><strong>2.1.1 ASCII 码</strong></h5><ol><li><strong>ASCII(American Standard Code for Information Interchange)，是一种的编码。</strong></li><li><strong>ASCII 码使用指定的 7 位或 8 位二进制数组合来表示 128 或 256 种可能的字符。</strong></li><li><strong>英语中，用 128 个符号编码便可以表示全部，但是用来表示其他语言，128 个符号是不够。欧洲国家就决定，利用字节中闲置的最高位编入新的符号。欧洲国家编码体系，可以表示最多 256 个符号。</strong></li><li><strong>汉字多达 10 万左右，一个字节只能表示 256 种符号，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312，使用两个字节表示一个汉字。</strong></li></ol><h5 id="2-1-2-Unicode"><strong>2.1.2 Unicode</strong></h5><ol><li><strong>Unicode 码扩展自 ASCII 字元集</strong></li><li><strong>Unicode 是计算机科学领域里的一项业界标准，包括字符集、编码方案等。</strong></li><li><strong>Unicode 通常用表示一个字符，原有的英文编码从单字节变成双字节，只需要把高字节全部填为 0 就可以。</strong></li><li><strong>跨语言、跨平台进行文本转换和处理。</strong></li><li><strong>对每种语言中字符设定统一且唯一的二进制编码。</strong></li><li><strong>每个英文字母前都必然有二到三个字节是 0，这对于存储来说是极大的浪费。</strong></li></ol><h5 id="2-1-3-UTF-8（8-bit-Unicode-Transformation-Format）"><strong>2.1.3 UTF-8（8-bit Unicode Transformation Format）</strong></h5><ol><li><strong>可变长度的Unicode的实现方式。</strong></li><li><strong>使用 1~4 个字节表示一个符号，根据不同的符号而变化字节长度。</strong></li></ol><h4 id="2-2-文件类型"><strong>2.2 文件类型</strong></h4><h5 id="2-2-1-文本文件"><strong>2.2.1 文本文件</strong></h5><p><strong>以 ASCII 码方式存储的文件</strong></p><h5 id="2-2-2-二进制文件"><strong>2.2.2 二进制文件</strong></h5><p><strong>直接由比特 0 和比特 1 组成，没有统一字符编码</strong></p><h4 id="2-3-文件操作"><strong>2.3 文件操作</strong></h4><h5 id="2-3-1-打开文件"><strong>2.3.1 打开文件</strong></h5><p><strong>建立磁盘上的文件与程序中的对象相关联</strong></p><ol><li><strong>Python 通过解释器内置的 open() 函数打开一个文件，并实现该文件与一个程序变量的关联，open() 函数格式如下：</strong></li></ol><pre><code class="highlight plaintext">&lt;变量名&gt;=open(&lt;文件名&gt;,&lt;打开模式&gt;)</code></pre><ol start="2"><li><strong>open() 函数有两个参数：文件名和打开模式。</strong></li><li><strong>文件名可以是文件的实际名字，也可以是包含完整路径的名字。</strong></li><li><strong>文件打开模式：只读，写入，追加等。这个参数是非强制的，默认文件访问模式为只读 ®。</strong></li><li><strong>open() 函数提供 7 种基本的打开模式</strong></li></ol><table><thead><tr><th style="text-align:center"><strong>模式</strong></th><th style="text-align:left"><strong>说明</strong></th></tr></thead><tbody><tr><td style="text-align:center"><strong>r</strong></td><td style="text-align:left"><strong>读模式（默认模式，可省略），如果文件不存在，抛出异常</strong></td></tr><tr><td style="text-align:center"><strong>w</strong></td><td style="text-align:left"><strong>写模式，如果文件已存在，先清空原有内容；如果文件不存在，创建新文件</strong></td></tr><tr><td style="text-align:center"><strong>x</strong></td><td style="text-align:left"><strong>写模式，创建新文件，如果文件已存在则抛出异常</strong></td></tr><tr><td style="text-align:center"><strong>a</strong></td><td style="text-align:left"><strong>追加模式，不覆盖文件中原有内容</strong></td></tr><tr><td style="text-align:center"><strong>b</strong></td><td style="text-align:left"><strong>二进制模式（可与 r、w、x 或 a 模式组合使用）</strong></td></tr><tr><td style="text-align:center"><strong>t</strong></td><td style="text-align:left"><strong>文本模式（默认模式，可省略）</strong></td></tr><tr><td style="text-align:center"><strong>+</strong></td><td style="text-align:left"><strong>读、写模式（可与其他模式组合使用）</strong></td></tr></tbody></table><ol start="6"><li><strong>读写模式</strong></li></ol><table><thead><tr><th style="text-align:center"><strong>模式</strong></th><th style="text-align:center"><strong>r</strong></th><th style="text-align:center"><strong>r+</strong></th><th style="text-align:center"><strong>w</strong></th><th style="text-align:center"><strong>w+</strong></th><th style="text-align:center"><strong>a</strong></th><th style="text-align:center"><strong>a+</strong></th></tr></thead><tbody><tr><td style="text-align:center"><strong>读</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"></td><td style="text-align:center"><strong>+</strong></td></tr><tr><td style="text-align:center"><strong>写</strong></td><td style="text-align:center"></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td></tr><tr><td style="text-align:center"><strong>创建</strong></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td></tr><tr><td style="text-align:center"><strong>覆盖</strong></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"><strong>指针在开始</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center"><strong>指针在结尾</strong></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"><strong>+</strong></td><td style="text-align:center"><strong>+</strong></td></tr></tbody></table><h5 id="2-3-2-文件操作"><strong>2.3.2 文件操作</strong></h5><ol><li><strong>读取</strong></li></ol><p><strong>根据打开方式不同可以对文件进行相应的读写操作，Python提供4个常用的文件内容读取方法。</strong></p><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>含义</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>&lt;file&gt;.readall()</code></strong></td><td style="text-align:left"><strong>读入整个文件内容，返回一个字符串或字节流</strong></td></tr><tr><td style="text-align:left"><strong><code>&lt;file&gt;.read(size = -1)</code></strong></td><td style="text-align:left"><strong>从文件中读入整个文件内容，如果给出参数，读入前size长度的字符串或字节流</strong></td></tr><tr><td style="text-align:left"><strong><code>&lt;file&gt;.readline(size = -1)</code></strong></td><td style="text-align:left"><strong>从文件中读入一行内容，如果给出参数，读入前  size 长度的字符串或字节流</strong></td></tr><tr><td style="text-align:left"><strong><code>&lt;file&gt;.readlines(hint = -1)</code></strong></td><td style="text-align:left"><strong>从文件中读入所有行，以每行为元素形成一个列表，如果给出参数，读入 hint 行</strong></td></tr></tbody></table><ol start="2"><li><strong>写入</strong></li></ol><p><strong>Python 提供 3 个与文件内容写入有关的方法</strong></p><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>含义</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>&lt;file&gt;. write(s) </code></strong></td><td style="text-align:left"><strong>向文件写入一个字符串或字节流</strong></td></tr><tr><td style="text-align:left"><strong><code>&lt;file&gt;. writelines(lines) </code></strong></td><td style="text-align:left"><strong>将一个元素为字符串的列表写入文件</strong></td></tr><tr><td style="text-align:left"><strong><code>&lt;file&gt;. seek(offset) </code></strong></td><td style="text-align:left"><strong>0：文件开头；1：当前位置；2：文件结尾</strong></td></tr></tbody></table><ol start="3"><li><p><strong>定位</strong></p></li><li><p><strong>其他：追加、计算等</strong></p></li><li><p><strong>上下文管理语句with</strong><br><strong>在实际开发中，读写文件应优先考虑使用上下文管理语句with。关键字with可以自动管理资源，不论因为什么原因跳出with块，总能保证文件被正确关闭。除了用于文件操作，with关键字还可以用于数据库连接、网络连接或类似场合。用于文件内容读写时，with语句的语法形式如下：</strong></p></li></ol><pre><code class="highlight plaintext">with open(filename, mode, encoding) as fp:# 这里写通过文件对象 fp 读写文件内容的语句块</code></pre><ol start="6"><li><strong>文件操作示例</strong><br><strong>编写程序将电话簿 teleAddressBook.txt 和电子邮件 emailAddressBook.txt 合并为一个完整的 addressBook.txt</strong></li></ol><hr><table><thead><tr><th style="text-align:left"><strong>姓名</strong></th><th style="text-align:left"><strong>电话号码</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>张伟</strong></td><td style="text-align:left"><strong>1534098751</strong></td></tr><tr><td style="text-align:left"><strong>王伟</strong></td><td style="text-align:left"><strong>1520878752</strong></td></tr><tr><td style="text-align:left"><strong>王芳</strong></td><td style="text-align:left"><strong>1520658753</strong></td></tr><tr><td style="text-align:left"><strong>李娜</strong></td><td style="text-align:left"><strong>1523098754</strong></td></tr><tr><td style="text-align:left"><strong>刘伟</strong></td><td style="text-align:left"><strong>1596098755</strong></td></tr></tbody></table><p><strong>emailAddressBook.txt</strong></p><table><thead><tr><th style="text-align:left"><strong>姓名</strong></th><th style="text-align:left"><strong>邮箱</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>张伟</strong></td><td style="text-align:left"><strong><a href="mailto:1534098751@qq.com">1534098751@qq.com</a></strong></td></tr><tr><td style="text-align:left"><strong>王伟</strong></td><td style="text-align:left"><strong><a href="mailto:1520878752@qq.com">1520878752@qq.com</a></strong></td></tr><tr><td style="text-align:left"><strong>王芳</strong></td><td style="text-align:left"><strong><a href="mailto:1520658753@qq.com">1520658753@qq.com</a></strong></td></tr><tr><td style="text-align:left"><strong>李伟</strong></td><td style="text-align:left"><strong><a href="mailto:1520098754@qq.com">1520098754@qq.com</a></strong></td></tr></tbody></table><p><strong>addressBook.txt</strong></p><table><thead><tr><th style="text-align:left"><strong>姓名</strong></th><th style="text-align:left"><strong>电话</strong></th><th style="text-align:left"><strong>邮箱</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>张伟</strong></td><td style="text-align:left"><strong>1534098751</strong></td><td style="text-align:left"><strong><a href="mailto:1534098751@qq.com">1534098751@qq.com</a></strong></td></tr><tr><td style="text-align:left"><strong>王伟</strong></td><td style="text-align:left"><strong>1520878752</strong></td><td style="text-align:left"><strong><a href="mailto:1520878752@qq.com">1520878752@qq.com</a></strong></td></tr><tr><td style="text-align:left"><strong>王芳</strong></td><td style="text-align:left"><strong>1520658753</strong></td><td style="text-align:left"><strong><a href="mailto:1520658753@qq.com">1520658753@qq.com</a></strong></td></tr><tr><td style="text-align:left"><strong>李娜</strong></td><td style="text-align:left"><strong>1523098754</strong></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>刘伟</strong></td><td style="text-align:left"><strong>1596098755</strong></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>李伟</strong></td><td style="text-align:left"></td><td style="text-align:left"><strong><a href="mailto:1520098754@qq.com">1520098754@qq.com</a></strong></td></tr></tbody></table><ol start="7"><li><strong>文件操作示例代码</strong></li></ol><pre><code class="highlight plaintext">with open('teleAddressBook.txt', 'rt') as ftele1:with open('emailAddressBook.txt', 'rt') as ftele2:ftele1.readline() # 跳过第一行ftele2.readline()lines1=ftele1.readlines()lines2=ftele2.readlines()# 建立空表用于存储姓名，电话，emaillist1_name=[]list1_tele=[]list2_name=[]list2_email=[]for line in lines1: # 获取第一个文本中的姓名和电话信息elements=line.split()list1_name.append(elements[0])list1_tele.append(elements[1])for line in lines2: # 获取第二个文本中的姓名和邮件信息elements=line.split()list2_name.append(elements[0])list2_email.append(elements[1])# 生成新的数据lines=[]lines.append('姓名\t电话\t\t邮箱\n')# 遍历列表1for i in range(len(list1_name)):s=''# 查看列表1中的名字是否在列表2中if list1_name[i] in list2_name:j=list2_name.index(list1_name[i])s='\t'.join([list1_name[i], list1_tele[i], list2_email[j]])s+='\n'else:s='\t'.join([list1_name[i], list1_tele[i], str('   ----   ')])s+='\n'lines.append(s)for i in range(len(list2_name)):s=''if list2_name[i] not in list1_name:s='\t'.join([list2_name[i], str('   ----   '), list2_email[i]])s+='\n'lines.append(s)# 写入文件ftele3=open('addressbook', 'w')ftele3.writelines(lines)# 关闭文件ftele3.close()ftele1.close()ftele2.close()print('新的通讯录已合成')</code></pre><h5 id="2-3-3-关闭文件"><strong>2.3.3 关闭文件</strong></h5><ol><li><strong>切断文件与程序的联系</strong></li><li><strong>写入磁盘，并释放文件缓冲区</strong></li></ol><h3 id="3、Excel-文件操作实例"><strong>3、Excel 文件操作实例</strong></h3><h4 id="3-1-Excel文件格式说明"><strong>3.1 Excel文件格式说明</strong></h4><ol><li><strong>一个 Excel 电子表格文档称为一个工作簿（workbook），一个工作簿保存在扩展名为 .xlsx 的文件中。</strong></li><li><strong>每个工作簿可以包含多个表（Sheet）。</strong></li><li><strong>用户当前查看的表（或关闭 Excel 前最后查看的表），称为活动表。</strong></li><li><strong>每个表都有一些列（地址是从 A 开始的字母）和一些行（地址是从1开始的数字）。</strong></li><li><strong>在特定行和列的方格称为单元格（cell）。</strong></li><li><strong>每个单元格都包含一个数字或文本值。</strong></li></ol><h4 id="3-2-openpyxl-库"><strong>3.2 openpyxl 库</strong></h4><h5 id="3-2-1-openpyxl-库特点"><strong>3.2.1 openpyxl 库特点</strong></h5><ol><li><strong>用于读取/写入 Excel 2010 xlsx/xlsm/xltx/xltm 文件的 Python 库。</strong></li><li><strong>使用 getter/setter 模式。你可以随时读取某个单元格的内容，并根据其内容进行相应的修改，openpyxl 会帮你记住每个单元格的状态。</strong></li><li><strong>虽然它支持修改已有文件，但由于其所支持的功能有限，读入文件时会忽略掉它所不支持的内容，再写入时，这些内容就丢失了。</strong></li></ol><h5 id="3-2-2-openpyxl-库缺点"><strong>3.2.2 openpyxl 库缺点</strong></h5><ol><li><strong>不支持 07 版本之前的 XLS 格式。</strong></li><li><strong>不支持 Excel 中的公式。</strong></li></ol><h5 id="3-2-3-openpyxl-库常用操作"><strong>3.2.3 openpyxl 库常用操作</strong></h5><ol><li><p><strong>安装 openpyxl 库</strong></p></li><li><p><strong>导入 openpyxl 库</strong></p></li><li><p><strong>用 openpyxl 库打开 Excel 文档</strong></p></li><li><p><strong>从工作簿中取得工作表</strong></p></li><li><p><strong>从表中取得行和列</strong><br><strong>可以将 Worksheet 对象切片，取得 Excel 表格中一行、一列或一个矩形区域中的所有 Cell 对象，然后可以循环遍历这个切片中的所有单元格。</strong></p></li><li><p><strong>新建工作簿：新建工作簿不需要在系统中创建新文件，在内存中操作即可。</strong></p></li></ol><pre><code class="highlight plaintext">from openpyxl import Workbook# 工作簿实例化wb = Workbook()</code></pre><ol start="7"><li><strong>从工作簿激活工作表</strong></li></ol><pre><code class="highlight plaintext"># 激活获取工作表，此方法调用 _active_sheet_index方法，默认索引为0，即第一个工作表ws = wb.active</code></pre><ol start="8"><li><strong>也可用 create_sheet() 方法创建工作表。</strong></li></ol><pre><code class="highlight plaintext"># 默认在最后添加工作表ws1 = wb.create_sheet()# 在指定位置添加工作表，位置0，即第一个ws2 = wb.create_sheet(0)</code></pre><ol start="9"><li><strong>可以通过工作表名称获取工作表，以下两种方式效果相同。</strong></li></ol><pre><code class="highlight plaintext">ws3 = wb["New Title"]ws4 = wb.get_sheet_by_name("New Title")</code></pre><ol start="10"><li><strong>通过 get_sheet_names() 获取工作簿所有工作表的名称，返回值为 list 类型。</strong></li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; print(wb.get_sheet_names())['Sheet2', 'New Title', 'Sheet1']</code></pre><ol start="11"><li><strong>获取单元格</strong></li></ol><pre><code class="highlight plaintext">c = ws['A4'] # 利用坐标获取单元格，若单元格不存在，则被创建。ws['A4'] = 4 # 对单元格的值直接赋值。# 也可通过以下两种方式获取单元格，效果相同。c = ws.cell('A4')# 指定行和列获取，从 1 开始，不从 0 开始。d = ws.cell(row = 4, column = 1)</code></pre><ol start="12"><li><strong>利用切片方式获取指定区域的单元格</strong></li></ol><pre><code class="highlight plaintext">cell_range = ws['A1':'C2']</code></pre><ol start="13"><li><strong>获取单元格后，写数据</strong></li></ol><pre><code class="highlight plaintext">c = ws.cell('A4’)c.value = 'hello, world'</code></pre><ol start="14"><li><strong>对实例化的工作簿调用 openpyxl.workbook.Workbook.save() 进行保存</strong></li></ol><pre><code class="highlight plaintext">wb.save('sample.xlsx')</code></pre><h4 id="3-3-Excel-文件-人口普查数据-处理实例"><strong>3.3 Excel 文件(人口普查数据)处理实例</strong></h4><h5 id="3-3-1-问题描述"><strong>3.3.1 问题描述</strong></h5><p><strong>处理2010年美国人口普查数据文件 censuspopdata.xlsx，Excle 文件中只有一张表，名为 ‘Population by Census Tract’。每一行都保存了一个普查区的数据。列分别是普查区的编号(A)，州的简称(B)，县的名称©，普查区的人口(D)。</strong></p><h5 id="3-3-2-题目要求"><strong>3.3.2 题目要求</strong></h5><ol><li><strong>编写程序，从人口普查 Excel 文件中读取数据，并计算出每个县的人口统计值。</strong></li><li><strong>题目要求以字典嵌套字典方式存储统计信息，最外层字典的键是州，州里的键是县，县里的键是 pop 和人口普查区数量。</strong><br><strong>dict = { ‘州’:{ ‘县1’: {‘pop’:9000, ‘人口普查区’：2}， }， }</strong></li></ol><h5 id="3-3-3-求解步骤"><strong>3.3.3 求解步骤</strong></h5><ol><li><strong>从 Excel 电子表格中读取数据。</strong></li><li><strong>计算每个县中普查区的数目。</strong></li><li><strong>计算每个县的总人口。</strong></li><li><strong>打印结果。</strong></li></ol><h5 id="3-3-4-待处理-Excel-文件"><strong>3.3.4  待处理 Excel 文件</strong></h5><table><thead><tr><th style="text-align:center"><strong>普查区编号</strong></th><th style="text-align:center"><strong>州(state)</strong></th><th style="text-align:center"><strong>乡/县(country)</strong></th><th style="text-align:center"><strong>POP2010</strong></th></tr></thead><tbody><tr><td style="text-align:center"><strong>01001020100</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>1912</strong></td></tr><tr><td style="text-align:center"><strong>01001020200</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>2170</strong></td></tr><tr><td style="text-align:center"><strong>01001020300</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>3373</strong></td></tr><tr><td style="text-align:center"><strong>01001020400</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>4386</strong></td></tr><tr><td style="text-align:center"><strong>01001020500</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>10766</strong></td></tr><tr><td style="text-align:center"><strong>01001020600</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>3668</strong></td></tr><tr><td style="text-align:center"><strong>01001020700</strong></td><td style="text-align:center"><strong>AL</strong></td><td style="text-align:center"><strong>Autauge</strong></td><td style="text-align:center"><strong>2891</strong></td></tr></tbody></table><h5 id="3-3-5-实例代码"><strong>3.3.5 实例代码</strong></h5><pre><code class="highlight plaintext">import openpyxl, pprintprint('Opening workbook...')wb = openpyxl.load_workbook('censuspopdata.xlsx')sheet = wb.get_sheet_by_name('Population by Census Tract') # 获取人口统计Sheet工作表countryData = {} # 定义统计结果保存字典print('Reading rows...')for row in range(2, sheet.max_row+1):# 从 Excel 文件第二行开始读取数据，至最后一行。前闭后开，不包括 max_row+1 行state = sheet['B' + str(row)].value # 读取州名country = sheet['C' + str(row)].value # 读取县名pop = sheet['D' + str(row)].value # 读取人口数量值countryData.setdefault(state, {})countryData[state].setdefault(country, {'tracts': 0, 'pop': 0})countryData[state][country]['tracts'] += 1 # 该县的人口普查次数+1countryData[state][country]['pop'] += int(pop) # 该县所有普查次区人口数量相加print('Writing results...')resultFile = open('census2010.py', 'w')resultFile.write('allData = ' + pprint.pformat(countryData))# pprint 生成一个字符串，格式化好的、有效的python代码resultFile.close()print('Done.')</code></pre><p><strong>运行结果</strong></p><pre><code class="highlight plaintext">allData = {'AK':{'Aleutians East':{'pop': 3141, 'tracts': 1}, 'Aleutians West':{'pop': 5561, 'tracts': 2}, 'Anchorage':{'pop': 291826, 'tracts': 55},'Bethel':{'pop': 17013, 'tracts': 3},'Bristol Bay':{'pop': 997, 'tracts': 1},'Denali':{'pop': 1826, 'tracts': 1},'Dillingham':{'pop': 4847, 'tracts': 2},'Fairbanks North Star':{'pop': 97581, 'tracts': 19},'Haines':{'pop': 2508, 'tracts': 1},'Hoonah-Angoon':{'pop': 2150, 'tracts': 2},'Juneau':{'pop': 31275, 'tracts': 6},'Kenai Peninsula':{'pop': 55400, 'tracts': 13},'Ketchikan Gateway':{'pop': 13477, 'tracts': 4},'Kodiak Island':{'pop': 13592, 'tracts': 5},'Lake and Peninsula':{'pop': 1631, 'tracts': 1},'Matanuska-Susitna':{'pop': 88995, 'tracts': 24},'Nome':{'pop': 9492, 'tracts': 2},'North Slope':{'pop': 9430, 'tracts': 3},</code></pre><h3 id="4、自然语言处理实战"><strong>4、自然语言处理实战</strong></h3><h4 id="4-1-中文分词介绍"><strong>4.1 中文分词介绍</strong></h4><h5 id="4-1-1-中文分词特点"><strong>4.1.1 中文分词特点</strong></h5><ol><li><strong>词是最小的能够独立活动的有意义的语言成分。</strong></li><li><strong>汉语是以字为单位，不像西方语言，词与词之间没有空格之类的标志指示词的边界。</strong></li><li><strong>分词问题为中文文本处理的基础性工作，分词的好坏对后续中文信息处理其关键作用。</strong></li></ol><h5 id="4-1-2-中文分词难点"><strong>4.1.2 中文分词难点</strong></h5><ol><li><p><strong>分词规范，词的定义还不明确 (《统计自然语言处理》宗成庆)</strong></p></li><li><p><strong>歧义切分问题，交集型切分问题，多义组合型切分歧义等</strong><br><strong>结婚的和尚未结婚的 =&gt;</strong><br><strong>结婚／的／和／尚未／结婚／的</strong><br><strong>结婚／的／和尚／未／结婚／的</strong></p></li><li><p><strong>未登录词问题有两种解释：</strong><br><strong>一是已有的词表中没有收录的词。</strong><br><strong>二是已有的训练语料中未曾出现过的词，一些网络新词，自造词一般都属于这些词。</strong></p></li></ol><h5 id="4-1-3-中文分词方法"><strong>4.1.3 中文分词方法</strong></h5><ol><li><strong>基于字典、词库匹配的分词方法(基于规则)</strong><br><strong>将待分的字符串与一个充分大的机器词典中的词条进行匹配。常用的有：正向最大匹配，逆向最大匹配，最少切分法。实际应用中，将机械分词作为初分手段，利用语言信息提高切分准确率。</strong></li><li><strong>基于词频度统计的分词方法（基于统计）</strong><br><strong>相邻的字同时出现的次数越多，越有可能构成一个词语，对语料中的字组频度进行统计，基于词的频度统计的分词方法是一种全切分方法。jieba是基于统计的分词方法。</strong></li><li><strong>基于知识理解的分词方法</strong><br><strong>该方法主要基于句法、语法分析，并结合语义分析，通过对上下文内容所提供信息的分析对词进行定界。由于汉语语言知识的笼统、复杂性，目前还处在试验阶段。</strong></li></ol><h4 id="4-2-jieba-扩展库"><strong>4.2 jieba 扩展库</strong></h4><h5 id="4-2-1-jieba-是-Python-中一个重要的第三方中文分词函数库"><strong>4.2.1 jieba 是 Python 中一个重要的第三方中文分词函数库</strong></h5><ol><li><strong>jieba分词，，有集成的python库，简单易用。</strong></li><li><strong>安装：</strong><br><strong>1）全自动安装： easy_install jieba 或者 pip install jieba / pip3 install jieba</strong><br><strong>2）半自动安装：先下载 <a href="https://pypi.python.org/pypi/jieba/">https://pypi.python.org/pypi/jieba/</a> ，解压后运行 python <a href="http://setup.py">setup.py</a> install</strong><br><strong>3）手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录</strong><br><strong>4）通过 import jieba 来引用</strong></li></ol><h5 id="4-2-2-jieba-实现原理"><strong>4.2.2 jieba 实现原理</strong></h5><ol><li><strong>基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)。</strong><br><strong>例如：句子“抗日战争”生成的 DAG 中{0:[0,1,3]} 这样一个简单的 DAG，就是表示 0 位置开始，在 0,1,3 位置都是词，就是说 0~0，0~1，0~3 即 “抗”，“抗日”，“抗日战争”这三个词在dict.txt中是词。</strong></li><li><strong>采用了动态规划查找最大概率路径，找出基于词频的最大切分组合。</strong><br><strong>根据动态规划查找最大概率路径的基本思路就是对句子从右往左反向计算最大概率，…依次类推， 最后得到最大概率路径，得到最大概率的切分组合。</strong></li><li><strong>对于未登录词，采用了基于汉字成词能力的隐马尔科夫模型（HMM）模型，使用了 Viterbi 算法（一种最优路径算法）。</strong></li></ol><h5 id="4-2-3-jieba-是-Python-中一个重要的第三方中文分词函数库"><strong>4.2.3 jieba 是 Python 中一个重要的第三方中文分词函数库</strong></h5><ol><li><p><strong>第三方库，需要安装</strong></p></li><li><p><strong>安装成功提示</strong><br><strong>Successfully installed jieba-0.39</strong></p></li><li><p><strong>也可离线下载安装</strong><br><strong>个人推荐离线安装，因为网速，anaconda安装容易失败，我试了很多次了。</strong><br><strong>下载地址：<a href="https://pypi.org/project/jieba/#files%EF%BC%89">https://pypi.org/project/jieba/#files）</a></strong></p></li></ol><h5 id="4-2-4-jieba-支持三种分词模式"><strong>4.2.4 jieba 支持三种分词模式</strong></h5><ol><li><strong>精确模式：试图将句子最精确地切开，适合文本分析。</strong></li><li><strong>全模式：把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义。</strong></li><li><strong>搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。</strong></li><li><strong>支持繁体分词</strong></li><li><strong>支持自定义词典</strong></li><li><strong>MIT 授权协议（开源软件授权协议）</strong></li></ol><h5 id="4-2-5-jieba-常用函数"><strong>4.2.5 jieba 常用函数</strong></h5><ol><li><strong>jieba.cut ：</strong><br><strong>方法接受三个输入参数:</strong><br><strong>1）需要分词的字符串。</strong><br><strong>2）cut_all 参数用来控制是否采用全模式。</strong><br><strong>3）HMM 参数用来控制是否使用 HMM 模型。</strong></li><li><strong>jieba.cut_for_search ：</strong><br><strong>方法接受两个参数：</strong><br><strong>1）需要分词的字符串。</strong><br><strong>2）是否使用 HMM 模型。</strong><br><strong>该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细。</strong></li><li><strong>jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者</strong></li></ol><h4 id="4-3-jieba-扩展库示例"><strong>4.3 jieba 扩展库示例</strong></h4><h5 id="4-3-1-jieba-三种分词模式的区别"><strong>4.3.1 jieba 三种分词模式的区别</strong></h5><pre><code class="highlight plaintext">import jieba'''cut 方法有两个参数1）第一个参数是我们想分词的字符串2）第二个参数cut_all是用来控制是否采用全局模式'''# 全模式word_list = jieba.cut("今天天气真好。亲爱的，我们去远足吧！", cut_all=True)print("全模式：","|".join(word_list))# 精确模式，默认就是精确模式word_list = jieba.cut("今天天气真好。亲爱的，我们去远足吧！", cut_all=False)print("精确模式：","|".join(word_list))# 搜索引擎模式word_list = jieba.cut_for_search("今天天气真好。亲爱的，我们去远足吧！")print("搜索引擎模式：","|".join(word_list))</code></pre><p><strong>全模式： 今天|今天天气|天天|天气|真好|。|亲爱|的|，|我们|去|远足|吧|！</strong><br><strong>精确模式： 今天天气|真|好|。|亲爱|的|，|我们|去|远足|吧|！</strong><br><strong>搜索引擎模式： 今天|天天|天气|今天天气|真|好|。|亲爱|的|，|我们|去|远足|吧|！</strong></p><h5 id="4-3-2-TF-IDF-释义"><strong>4.3.2 TF-IDF 释义</strong></h5><ol><li><strong>TF-IDF（term frequency–inverse document frequency）是一种用于的常用加权技术。</strong></li><li><strong>TF意思是词频，指关键词在文中出现的次数除以全文总字数。</strong></li><li><strong>IDF意思是逆文本频率指数，反映关键词的普遍程度——当一个词越普遍（即有大量文档包含这个词）时，其IDF值越低；反之，则IDF值越高。</strong></li></ol><p><strong>TF-IDF=TF×IDF</strong><br><strong>$词频(TF)=\frac{某个词在文章中的出现次数}{文章的总词数}\times逆文档频率(IDF)=log(\frac{语料库的文档数}{包含该词的文档数+1})$</strong></p><h5 id="4-3-3-可以看出"><strong>4.3.3 可以看出</strong></h5><ol><li><strong>当一个词在文档频率越高并且新鲜度高（即普遍度低），其TF-IDF值越高。</strong></li><li><strong>TF-IDF兼顾词频与新鲜度，过滤一些常见词，保留能提供更多信息的重要词。</strong></li></ol><h5 id="4-3-4-基于TF-IDF算法的关键词抽取"><strong>4.3.4 基于TF-IDF算法的关键词抽取</strong></h5><pre><code class="highlight plaintext">import jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())</code></pre><ol><li><strong>sentence：待提取的文本。</strong></li><li><strong>topK：返回几个 TF/IDF 权重最大的关键词，默认值为 20。</strong></li><li><strong>withWeight：是否一并返回关键词权重值，默认值为 False。</strong></li><li><strong>allowPOS：词性过滤，为空表示不过滤，若提供则仅返回符合词性要求的关键词。</strong></li></ol><h5 id="4-3-5-基于TF-IDF算法的关键词抽取示例"><strong>4.3.5 基于TF-IDF算法的关键词抽取示例</strong></h5><pre><code class="highlight plaintext">import jieba.analysef = open("十九大报告节选.txt", "rb")sentence = f.read()keywords = jieba.analyse.extract_tags(sentence, topK=15, withWeight=True, allowPOS=('n','nr','ns'))for item in keywords:    print(item[0],item[1])</code></pre><p><strong>allowPOS词性过滤：n表示名词、nr表示人名、ns表示地名</strong></p><h5 id="4-3-6-基于TF-IDF算法的关键词抽取示例运行结果"><strong>4.3.6 基于TF-IDF算法的关键词抽取示例运行结果</strong></h5><p><strong>十九大报告节选.txt 在目录C:\Users\用户名.spyder-py3下</strong></p><p><strong>（原始文档）</strong><br><strong>中国共产党第十九次全国代表大会，是在全面建成小康社会决胜阶段、中国特色社会主义进入新时代的关键时期召开的一次十分重要的大会。</strong></p><p><strong>大会的主题是：不忘初心，牢记使命，高举中国特色社会主义伟大旗帜，决胜全面建成小康社会，夺取新时代中国特色社会主义伟大胜利，为实现中华民族伟大复兴的中国梦不懈奋斗。</strong></p><p><strong>不忘初心，方得始终。中国共产党人的初心和使命，就是为中国人民谋幸福，为中华民族谋复兴。这个初心和使命是激励中国共产党人不断前进的根本动力。全党同志一定要永远与人民同呼吸、共命运、心连心，永远把人民对美好生活的向往作为奋斗目标，以永不懈怠的精神状态和一往无前的奋斗姿态，继续朝着实现中华民族伟大复兴的宏伟目标奋勇前进。</strong></p><p><strong>当前，国内外形势正在发生深刻复杂变化，我国发展仍处于重要战略机遇期，前景十分光明，挑战也十分严峻。全党同志一定要登高望远、居安思危，勇于变革、勇于创新，永不僵化、永不停滞，团结带领全国各族人民决胜全面建成小康社会，奋力夺取新时代中国特色社会主义伟大胜利。</strong></p><p><strong>初心 1.056602437712</strong><br><strong>小康社会 0.6097804820220001</strong><br><strong>特色 0.5239102226336</strong><br><strong>全党同志 0.512082614532</strong><br><strong>社会主义 0.50983069314</strong><br><strong>中国 0.3632784823992</strong><br><strong>全面 0.33744171159299996</strong><br><strong>时代 0.3303798174336</strong><br><strong>人民 0.3125617860198</strong><br><strong>大会 0.2465050141716</strong><br><strong>共命运 0.228315420044</strong><br><strong>机遇期 0.222561778594</strong><br><strong>伟大旗帜 0.214452476432</strong><br><strong>方得 0.1954708653386</strong><br><strong>牢记 0.18611115603679998</strong></p><h4 id="4-4-统计《三国演义》小说词频前20的词语"><strong>4.4 统计《三国演义》小说词频前20的词语</strong></h4><p><strong>源代码</strong></p><pre><code class="highlight plaintext">import jiebaf = open(".\三国演义.txt", "rb")txt = f.read()words = jieba.lcut(txt)counts = {}for word in words:    if len(word) == 1: # 排除单个字的分词结果        continue    else:        counts[word] = counts.get(word, 0) + 1items = list(counts.items())items.sort(key = lambda items: items[1], reverse = True)for i in range(20):    word, count = items[i]    print("{0:&lt;10}{1:&gt;5}".format(word, count))</code></pre><p><strong>曹操          940</strong><br><strong>孔明          828</strong><br><strong>将军          762</strong><br><strong>却说          648</strong><br><strong>玄德          568</strong><br><strong>关公          508</strong><br><strong>丞相          489</strong><br><strong>二人          465</strong><br><strong>不可          436</strong><br><strong>荆州          420</strong><br><strong>玄德曰         385</strong><br><strong>孔明曰         385</strong><br><strong>不能          383</strong><br><strong>如此          376</strong><br><strong>张飞          350</strong><br><strong>商议          344</strong><br><strong>如何          337</strong><br><strong>主公          328</strong><br><strong>军士          311</strong></p><h4 id="4-5-统计《三国演义》分词后，词频数前50中，三国人物出现次数"><strong>4.5 统计《三国演义》分词后，词频数前50中，三国人物出现次数</strong></h4><p><strong>源代码</strong></p><pre><code class="highlight plaintext">import jiebaf = open(".\三国演义.txt", "rb")txt = f.read()words = jieba.lcut(txt)counts = {}for word in words:    if len(word) == 1: # 排除单个字的分词结果        continue    elif word == "诸葛亮" or word == "孔明曰":        rword = "孔明"    elif word == "关公" or word == "云长":        rword = "关羽"    elif word == "玄德" or word == "玄德曰":        rword = "刘备"        elif word == "孟德" or word == "丞相":        rword = "曹操"        else:        rword = word        counts[word] = counts.get(word, 0) + 1        personlist = ["孔明","曹操","张飞","刘备","关羽","孙权","吕布","鲁肃","周瑜","赵云","马超","姜维","魏延","庞统","董卓","袁绍","孟获","陆逊","孙尚香","孙坚","孙策","司马懿","曹丕","张辽"]        items = list(counts.items())items.sort(key = lambda items: items[1], reverse = True)for i in range(50):    word, count = items[i]    if personlist.count(word) &gt; 0:        print("{0:&lt;10}{1:&gt;5}".format(word, count))</code></pre><p><strong>曹操          940</strong><br><strong>孔明          828</strong><br><strong>张飞          350</strong><br><strong>吕布          302</strong><br><strong>刘备          278</strong><br><strong>孙权          266</strong><br><strong>赵云          257</strong><br><strong>司马懿         222</strong><br><strong>周瑜          218</strong><br><strong>袁绍          191</strong><br><strong>马超          185</strong><br><strong>魏延          177</strong></p><h3 id="5、图像处理实战"><strong>5、图像处理实战</strong></h3><h4 id="5-1-Pillow-扩展库"><strong>5.1 Pillow 扩展库</strong></h4><h5 id="5-1-1-Pillow扩展库概述"><strong>5.1.1 Pillow扩展库概述</strong></h5><ol><li><strong>PIL（Python Imaging Library）是Python常用的图像处理库，功能非常强大，API 简单易用。</strong></li><li><strong>但 PIL 仅支持到 Python 2.7，加上年久失修。</strong></li><li><strong>一群志愿者在 PIL 的基础上创建了PIL的兼容版本，名字叫 Pillow，支持最新 Python 3.x，并加入许多新特性。</strong></li><li><strong>Pillow 提供了广泛的文件格式支持，强大的图像处理能力，主要包括图像储存、图像显示、格式转换以及基本的图像处理操作等。</strong></li></ol><h5 id="5-1-2-Pillow-扩展库主要功能"><strong>5.1.2 Pillow 扩展库主要功能</strong></h5><ol><li><p><strong>图像归档</strong><br><strong>对图像进行批处理、生成图像预览、图像格式转换等。</strong></p></li><li><p><strong>图像处理</strong><br><strong>图像基本处理、像素处理、颜色处理。</strong></p></li></ol><h5 id="5-1-3-Pillow-扩展库主要操作"><strong>5.1.3 Pillow 扩展库主要操作</strong></h5><ol><li><p><strong>在 PIL 中，任何一个图像文件都可以用 Image 对象表示。</strong></p></li><li><p><strong>Image 类的图像读取和创建方法</strong></p></li></ol><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>Image.open(filename)</strong></td><td style="text-align:left"><strong>根据参数加载图像文件</strong></td></tr><tr><td style="text-align:left"><strong>Image.new(mode, size, color)</strong></td><td style="text-align:left"><strong>根据给定参数创建一个新的图像</strong></td></tr><tr><td style="text-align:left"><strong>Image.open(StringIO.StringIO(buffer)</strong></td><td style="text-align:left"><strong>从字符串中获取图像</strong></td></tr><tr><td style="text-align:left"><strong>Image.frombytes(mode, size, data)</strong></td><td style="text-align:left"><strong>根据像素点data创建图像</strong></td></tr><tr><td style="text-align:left"><strong>Image.verify()</strong></td><td style="text-align:left"><strong>对图像文件完整性进行检查，返回异常</strong></td></tr></tbody></table><ol start="3"><li><strong>Image 类有 4 个处理图片的常用属性</strong></li></ol><table><thead><tr><th style="text-align:left"><strong>属性</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>Image.format</strong></td><td style="text-align:left"><strong>标识图像格式或来源，如果图像不是从文件读取，值是None</strong></td></tr><tr><td style="text-align:left"><strong>Image.mode</strong></td><td style="text-align:left"><strong>图像的色彩模式，“L”灰度图像、“RGB”真彩色图像、“CMYK”出版图像</strong></td></tr><tr><td style="text-align:left"><strong>Image.size</strong></td><td style="text-align:left"><strong>图像宽度和高度，单位是像素(px)，返回值是二元元组(tuple)</strong></td></tr><tr><td style="text-align:left"><strong>Image.palette</strong></td><td style="text-align:left"><strong>调色板属性，返回一个ImagePalette类型</strong></td></tr></tbody></table><ol start="4"><li><strong>Image 类的图像转换和保存方法</strong></li></ol><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>Image.save(filename,format)</strong></td><td style="text-align:left"><strong>将图像保存为filename文件名，format是图片格式</strong></td></tr><tr><td style="text-align:left"><strong>Image.convert(mode)</strong></td><td style="text-align:left"><strong>使用不同的参数，转换图像为新的模式</strong></td></tr><tr><td style="text-align:left"><strong>Image.thumbnail(size)</strong></td><td style="text-align:left"><strong>创建图像的缩略图，size是缩略图尺寸的二元元组</strong></td></tr></tbody></table><p><strong>生成图像的缩略图，其中（128，128）是缩略图的尺寸</strong></p><pre><code class="highlight plaintext">from PIL import Imageim = Image.open("\img0.jpg") im.thumbnail((128, 128)) im.save("img0TN", "JPEG")</code></pre><ol start="5"><li><strong>Image 类能够对每个像素点或者一幅 RGB 图像的每个通道单独进行操作，split() 方法能够将 RGB 图像各颜色通道提取出来，merge() 方法能够将各独立通道再合成一幅新的图像。</strong></li></ol><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>Image.point(func)</strong></td><td style="text-align:left"><strong>根据函数 func 功能对每个元素进行运算，返回图像副本</strong></td></tr><tr><td style="text-align:left"><strong>Image.split()</strong></td><td style="text-align:left"><strong>提取 RGB 图像的每个颜色通道，返回图像副本</strong></td></tr><tr><td style="text-align:left"><strong>Image.merge(mode,bands)</strong></td><td style="text-align:left"><strong>合并通道，采用 mode 色彩，bands 是新色的色彩通道</strong></td></tr><tr><td style="text-align:left"><strong>Image.blend(img1, img2, alpha)</strong></td><td style="text-align:left"><em><em>将两幅图片 img1 和 img2 按照如下公式插值后生成新的图像： img1 * (1.0 - alpha) + img2</em> alpha</em>*</td></tr></tbody></table><ol start="6"><li><strong>颜色变换</strong></li></ol><pre><code class="highlight plaintext">from PIL import Imageim = Image.open('img1.jpg')r,g,b = im.split()om = Image.merge("RGB", (b, g, r)) om.save('img1BGR.jpg')</code></pre><ol start="7"><li><strong>通道颜色变换</strong></li></ol><pre><code class="highlight plaintext">from PIL import Imageim = Image.open('img1.jpg')r,g,b = im.split() # 获得RGB通道数据newr = g.point(lambda i: i*0.9)newg = g.point(lambda i: i&lt;200) # 选择g通道值低于200的像素点newb = b.point(lambda i: i)om = Image.merge(im.mode, (newr, newg, b)) # 将3个通道合成新图像om.save('img1Merge.jpg')</code></pre><ol start="8"><li><strong>PIL 库的 ImageFilter 提供的过滤图像方法</strong></li></ol><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>ImageFilter.BLUR</strong></td><td style="text-align:left"><strong>图像的模糊效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.CONTOUR</strong></td><td style="text-align:left"><strong>图像的轮廓效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.DETAIL</strong></td><td style="text-align:left"><strong>图像的细节效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.EDGE_ENHANCE</strong></td><td style="text-align:left"><strong>图像的边界加强效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.EDGE_ENHANCE_MORE</strong></td><td style="text-align:left"><strong>图像的阈值边界加强效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.EMBOSS</strong></td><td style="text-align:left"><strong>图像的浮雕效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.FIND_EDGES</strong></td><td style="text-align:left"><strong>图像的边界效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.SMOOTH</strong></td><td style="text-align:left"><strong>图像的平滑效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.SMOOTH_MORE</strong></td><td style="text-align:left"><strong>图像的阈值平滑效果</strong></td></tr><tr><td style="text-align:left"><strong>ImageFilter.SHARPEN</strong></td><td style="text-align:left"><strong>图像的锐化效果</strong></td></tr></tbody></table><ol start="9"><li></li></ol><p><strong>生成图像模糊效果：套用滤镜</strong></p><pre><code class="highlight plaintext">from PIL import Imagefrom PIL import ImageFilterim = Image.open("img1.jpg")om = im.filter(ImageFilter.BLUR) # 为图片使用模糊滤镜om.save('img1_blur.jpg')</code></pre><ol start="10"><li><strong>PIL 库的 ImageEnhance 类提供了更高级的图像增强需求，提供调整色彩度、亮度、对比度、锐化等功能。</strong></li></ol><table><thead><tr><th style="text-align:left"><strong>方法</strong></th><th style="text-align:left"><strong>描述</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>ImageEnhance.enhance(factor)</strong></td><td style="text-align:left"><strong>对选择属性的数值增强factor倍</strong></td></tr><tr><td style="text-align:left"><strong>ImageEnhance.Color(im)</strong></td><td style="text-align:left"><strong>调整图像的颜色平衡</strong></td></tr><tr><td style="text-align:left"><strong>ImageEnhance.Contrast(im)</strong></td><td style="text-align:left"><strong>调整图像的对比度</strong></td></tr><tr><td style="text-align:left"><strong>ImageEnhance.Brightness(im)</strong></td><td style="text-align:left"><strong>调整图像的亮度</strong></td></tr><tr><td style="text-align:left"><strong>ImageEnhance.Sharpness(im)</strong></td><td style="text-align:left"><strong>调整图像的锐度</strong></td></tr></tbody></table><ol start="11"><li><strong>高级图像增强示例</strong></li></ol><pre><code class="highlight plaintext">from PIL import Imagefrom PIL import ImageEnhanceim = Image.open("img1.jpg")# 调整图像对比度om = ImageEnhance.Contrast(im) # 图像对比度增强3倍om.enhance(3).save('img1_EnContras t.jpg’)</code></pre><h4 id="5-2-验证码生成实战"><strong>5.2 验证码生成实战</strong></h4><h5 id="5-2-1-题目要求"><strong>5.2.1 题目要求</strong></h5><p><strong>利用 PIL 的 ImageDraw 提供的绘图方法生成如下图的验证码，要求字母随机、填充颜色随机。</strong></p><h5 id="5-2-2-思路"><strong>5.2.2 思路</strong></h5><ol><li><strong>使用库 PIL、random</strong></li><li><strong>画布：随机填充色</strong></li><li><strong>字母：指定字体（注意路径）、模糊滤镜 BLUR</strong></li></ol><h5 id="5-2-3-验证码生成实战代码"><strong>5.2.3 验证码生成实战代码</strong></h5><pre><code class="highlight plaintext">from PIL import Image, ImageDraw, ImageFont, ImageFilterimport random# 随机字母（65-90表示26个大写英文字母）def rndChar():    return chr(random.randint(65, 90))# 随机颜色1（验证码背景颜色）def rndColor():    return (random.randint(64, 255), random.randint(64, 255), random.randint(64, 255))    # 随机颜色2（文字颜色）def rndColor2():    return (random.randint(32, 127), random.randint(32, 127), random.randint(32, 127))    # 240*60width = 60 * 4height = 60image = Image.new('RGB', (width, height), (255, 255, 255))# 创建 Font 对象font = ImageFont.truetype('ARIALN.TTF', 36)# 创建 Draw 对象draw = ImageDraw.Draw(image)# 填充每个像素for x in range(width):    for y in range(height):        draw.point((x, y), fill=rndColor())# 输出文字for t in range(4):    draw.text((60 * t + 10, 10), rndChar(), font=font, fill=rndColor2())# 模糊image = image.filter(ImageFilter.BLUR)image.save('code.jpg', 'jpeg')</code></pre><p><strong><img src="/medias/1591338787052.png" alt="验证码生成"></strong></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何阅读一本书</title>
      <link href="/2020/05/12/ru_he_yue_du_yi_ben_shu_du_shu/"/>
      <url>/2020/05/12/ru_he_yue_du_yi_ben_shu_du_shu/</url>
      
        <content type="html"><![CDATA[<h2 id="第一篇-阅读的层次">第一篇 阅读的层次</h2><h3 id="第一章-阅读的活力与艺术">第一章  阅读的活力与艺术</h3><h4 id="1-1-主动的阅读">1.1 主动的阅读</h4><p>阅读可以是一件多少主动的事。</p><p>阅读越主动，效果越好。</p><h4 id="1-2-阅读的目标：为获得资讯而读，以及为求得理解而读">1.2  阅读的目标：为获得资讯而读，以及为求得理解而读</h4><h4 id="1-3-阅读就是学习：指导型的学习，以及自我发现型的学习之间的差异">1.3 阅读就是学习：指导型的学习，以及自我发现型的学习之间的差异</h4><p>只有<strong>真正学习到的人才是主动的学习者</strong>。</p><p><strong>在阅读与倾听时我们必须要思考，就像我们在研究时一定要思考。</strong></p><p>**思考只是主动阅读的一部分。**一个人还必须运用他的感觉与想像力。一个人必须观察，记忆，在看不到的地方运用想像力。这就是在非辅助型的学习中经常想要强调的任务，而在被教导型的阅读，或倾听学习中被遗忘或忽略的过程。</p><p>阅读的艺术包括了所有<strong>非辅助型自我发现学习的技巧</strong>：<strong>敏锐的观察、灵敏可靠的记忆、想像的空间，<strong>再者当然就是</strong>训练有素的分析、省思能力</strong>。这么说的理由在于：<strong>阅读也就是一种发现虽然那是经过帮助，而不是未经帮助的一个过程</strong>。</p><h4 id="1-4-老师的出席与缺席">1.4 老师的出席与缺席</h4><p>如果你问一本书一个问题，你就必须自己回答这个问题。在这样的情况下，这本书就跟自然或世界一样。当你提出问题时，只有等你自己作了思考与分析之后，才会在书本上找到答案。</p><p>对我们这些已经不在学校的人来说，当我们试着要读一本既非主修也非选修的书籍时，也就是我们的成人教育要完全依赖书籍本身的时候，我们就不能再有老师的帮助了。因此，如果我们打算继续学习与发现，我们就要懂得如何让书本来教导我们。</p><h3 id="第二章-阅读的层次">第二章  阅读的层次</h3><p><strong>四种层次的阅读</strong></p><h4 id="2-1-第一种层次的阅读-基础阅读-elementary-reading">2.1 第一种层次的阅读-----基础阅读 (elementary reading)</h4><p>这个阅读层次的学习通常是在小学时完成的。<strong>在这个层次的阅读中，要问读者的问题是：”这个句子在说什么？”</strong></p><h4 id="2-2-第二种层次的阅读-检视阅读-inspectional-reading">2.2 第二种层次的阅读-----检视阅读 (inspectional reading)</h4><p>检视阅读是系统化略读 (skimming systematically)的一门艺术。在这个层次的阅读上，你的目标是从表面去观察这本书，学习到光是书的表象所教给你的一切。在<strong>这个层次要问的典型问题就是：”这本书在谈什么？”<strong>这是个表象的问题。还有些类似的问题是：</strong>“这本书的架构如何？”<strong>或是：</strong>“这本书包含哪些部分？”</strong></p><p>用检视阅读读完一本书之后，无论你用了多短的时间，你都该回答得出这样的问题：＂这是哪一类的书——小说、历史，还是科学论文？”</p><h4 id="2-3-第三种层次的阅读-分析阅读-analytical-reading">2.3 第三种层次的阅读-----分析阅读(analytical reading)</h4><p><strong>分析阅读</strong>就是<strong>全盘的阅读、完整的阅读，或是说优质的阅读</strong>——你能做到的最好的阅读方式。我们要在这里强调的是，<strong>分析阅读永远是一种专注的活动</strong>。<strong>在这个层次的阅读中，读者会紧抓住一本书——这个比喻蛮恰当的——一直要读到这本书成为他自己为止</strong>。<strong>分析阅读就是要咀嚼与消化一本书</strong>。</p><p>如果你的目标只是获得资讯或消遣，就完全没有必要用到分析阅读。分析阅读就是特别在追寻理解的。</p><h4 id="2-4-第四种层次的阅读-主题阅读-syntopical-reading">2.4 第四种层次的阅读-----主题阅读(syntopical reading)</h4><p>主题阅读是所有阅读中最复杂也最系统化的阅读。<strong>主题阅读是最主动、也最花力气的一种阅读</strong>。主题阅读不是个轻松的阅读艺术，规则也并不广为人知。虽然如此，<strong>主题阅读却可能是所有阅读活动中最有收获的</strong>。就是因为<strong>你会获益良多</strong>，所以<strong>绝对值得你努力学习如何做到这样的阅读</strong>。</p><h3 id="第三章-阅读的第一个层次：基础阅读">第三章  阅读的第一个层次：基础阅读</h3><h4 id="3-1-学习阅读的阶段">3.1 学习阅读的阶段</h4><p>1）<strong>第一个阶段</strong>，称为“<strong>阅读准备阶段</strong>” (reading readiness)。</p><p>2）<strong>第二个阶段</strong>，<strong>孩子会学习读一些简单的读物</strong>。这个阶段要结束时，小学生应该就能自己阅读简单的书，而且很喜欢阅读了。</p><p>3）<strong>第三个阶段</strong>，<strong>特征是快速建立字汇的能力</strong>，所用的方法是从上下文所提供的线索，＂揭发”不熟悉的字眼。</p><p>4）<strong>第四个阶段</strong>，<strong>特征是精练与增进前面所学的技巧</strong>。最重要的是，学生开始能消化他的阅读经验——从一本书所提出来的一个观点转化到另一个观点，在同一个主题上，对不同的作者所提出来的观点作比较。这是阅读的成熟阶段，应该是一个青少年就该达到的境界，也是终其一生都该持续下去的。</p><h4 id="3-2-阅读的阶段与层次">3.2 阅读的阶段与层次</h4><ol><li><p>基础阅读的<strong>第一个阶段，阅读准备阶段</strong>——相当于学前教育或幼稚园的学习经验。</p></li><li><p>基础阅读的<strong>第二阶段，认字</strong>——相当于一年级学生典型的学习经验（尽管相当多正常的孩子在某方面来说并非都很“经典”。</p></li><li><p>基础阅读的<strong>第三个阶段，字汇的增长及对课文的运用</strong>——通常是（但非全面性，就算正常孩子也一样）在四年级结束时就学会的方法。</p></li><li><p>基础阅读的<strong>第四个阶段</strong>，也就是最后一个阶段，到这个时期，学生要从小学或初中毕业了。</p></li></ol><p>只有当一个孩子精通了基础阅读的四个阶段，才是他准备好往更高层次的阅读迈进的时候。只有当他能自己阅读时，才能够自已开始学习。也只有这样，他才能变成一个真正优秀的阅读者。</p><h4 id="3-3-更高层次的阅读与高等教育">3.3 更高层次的阅读与高等教育</h4><p>一个优秀的大学，就算什么也没贡献，也该培育出能进行主题阅读的读者。大学的文凭应该代表着一般大学毕业生的阅读水平．不但能够阅读任何一种普通的资料，还能针对任何一种主题做个人的研究（这就是在所有阅读中，主题阅读能让你做到的事）。然而，通常大学生要在毕业以后，再读三四年的时间才能达到这样的程度，并且还不见得一定达到。</p><h4 id="3-4-阅读与民主教育的理念">3.4 阅读与民主教育的理念</h4><p>无限制的受教育机会是一个社会能提供给人民最有价值的服务——或说得正确一点，只有当一个人的自我期许，能力与需要受限制时，教育机会才会受到限制。</p><p>我们一定要比一个人人识字的国家更进一步。我们的国人应该变成一个个真正”有能力”的阅读者，能够真正认知”有能力”这个字眼中的涵义。达不到这样的境界，我们就无法应付未来世界的需求。</p><h3 id="第四章-阅读的第二个层次：检视阅读">第四章  阅读的第二个层次：检视阅读</h3><p><strong>检视阅读，才算是真正进入阅读的层次。</strong></p><h4 id="4-1-检视阅读一：有系统的略读或粗读">4.1 检视阅读一：有系统的略读或粗读</h4><p><strong>略读或粗读是检视阅读的第一个子层次</strong>。你脑中的<strong>目标是要发现这本书值不值得多花时间仔细阅读</strong>。其次，就算你决定了不再多花时间仔细阅读这本书，略读也能告诉你许多跟这本书有关的事。</p><p><strong>略读如何去做的一些建议</strong></p><ol><li><p><strong>先看书名页，然后如果有序就先看序</strong><br>要很快地看过去。 特别注意副标题，或其他的相关说明或宗旨，或是作者写作本书的特殊角度。在完成这个步骤之前，你对这本书的主题已经有概念了。 如果你愿意，你会暂停一下，在你脑海中将这本书归类为某个特定的类型。而在那个类型中，已经包含了哪些书。</p></li><li><p><strong>研究目录页，对这本书的基本架构做概括性的理解</strong><br>这就像是在出发旅行之前，要先看一下地图一样。很惊讶的是，除非是真的要用到那本书了，许多人连目录页是看都不看一眼的。<br>通常，一本书，特别是一些论说性的书都会有目录，但是有时小说或诗集也会写上一整页的纲要目录，分卷分章之后再加许多小节的副标，以说明题旨。目录纲要还是很有价值的，在你开始阅读整本书之前，你应该先仔细阅读目录才对。</p></li><li><p><strong>如果书中附有索引，也要检阅一下</strong><br>索引快速评估一下这本书涵盖了哪些议题的范围，以及所提到的书籍种类与作者等等。如果你发现列举出来的哪一条词汇很重要， 至少要看一下引用到这个词目的某几页内文。你所阅读的段落很可能就是个要点——这本书的关键点——或是关系到作者意图与态度的新方法。</p></li><li><p><strong>如果那是本包着书衣的新书，不妨读一下出版者的介绍</strong><br>作者尽力将书中的主旨正确地摘要出来，已经不是稀奇的事了。</p></li><li><p><strong>从一本书的目录开始挑几个看来跟主题息息相关的篇章来看</strong><br>如果这些篇章在开头或结尾有摘要说明（很多会有），就要仔细地阅读这些说明。</p></li><li><p><strong>把书打开来，东翻翻西翻翻，念个一两段，有时候连续读几页，但不要太多</strong><br>就用这样的方法<strong>把全书翻过一遍，随时寻找主要论点的讯号</strong>，<strong>留意主题的基本脉动</strong>。最重要的是，<strong>不要忽略最后的两三页</strong>。就算最后有后记，一本书最后结尾的两三页也还是不可忽视的。很少有作者能拒绝这样的诱惑，而不是结尾几页将自己认为既新又重要的观点重新整理一遍的。虽然有时候作者自己的看法不一定正确，但你不应该错过这个部分。</p></li></ol><p>附带一提的是，这是一种非常主动的阅读。<strong>一个人如果不够灵活，不能够集中精神来阅读，就没法进行检视阅读。</strong></p><p><strong>问题：</strong><br>有多少次你在看一本好书的时候，翻了好几页，脑海却陷人了白日梦的状态中，等清醒过来，竟完全不明白自己刚看的那几页在说些什么？</p><p><strong>解决方法：</strong><br>你可以<strong>把自己想成是一个侦探，在找寻一本书的主题或思想的线索</strong>。<strong>随时保持敏感，就很容易让一切状况清楚</strong>。留意我们所提出的建议，会帮助你保持这样的态度。你会很惊讶地发现自己节省了更多时间，高兴自己掌握了更多重点，然后轻松地发现原来阅读是比想像中还更要简单的一件事。</p><h4 id="4-2-检视阅读二：粗浅的阅读">4.2 检视阅读二：粗浅的阅读</h4><p><strong>什么叫对的方向？</strong><br>答案是一个很重要又有帮助的阅读规则，但却经常被忽略。</p><p>这个规则很简单：<strong>头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或思索。</strong></p><p><strong>只注意你能理解的部分，不要为一些没法立即了解的东西而停顿</strong>。<strong>继续读下去，略过那些不懂的部分，很快你会读到你看得懂的地方</strong>。<strong>集中精神在这个部分。继续这样读下去。将全书读完，不要被一个看不懂的章节、注解、评论或参考资料阻挠或泄气</strong>。如果你让自已被困住了，如果你容许自已被某个顽固的段落绑住了，你就是被打败了。在大多数情况里，你一旦和它纠缠，就很难脱困而出。在读第二遍的时候，你对那个地方的了解可能会多一些，但是在那之前，你必须至少将这本书先从头到尾读一遍才行。</p><p>你从头到尾读了一遍之后的了解——就算只有50%或更少——能帮助你在后来重读第一次略过的部分时，增进理解。能帮助你在后来重读第一次略过的部分时，增进理解。就算你不重读，对一本难度很高的书了解了一半，也比什么都不了解来得要好些——如果你让自己在一碰上困难的地方就停住，最后就可能对这本书真的一无所知了。</p><p>这个规则也适用于论说性的作品。事实上，第一次看这样一本书的时候要粗浅阅读的这个规则，在你违反的时候正可以不证自明。</p><p>如果你坚持要了解每一页的意义，才肯再往下读，那你一定读不了多少。</p><h4 id="4-3-阅读的速度">4.3 阅读的速度</h4><p>检视阅读是一种在有限的时间当中，充分了解一本书的艺术。检视阅读的两个方式都需要快速地阅读。一个熟练的检视阅读者想要读一本书时，不论碰到多难读或多长的书，都能够很快地运用这两种方式读完。</p><p>一个很好的速读课程应该要教你不同的阅读速度，而<strong>不是一味求快</strong>，而<strong>忽略了你目前能掌握的程度</strong>。应该是<strong>依照读物的性质与复杂程度，而让你用不同的速度来阅读。</strong></p><p>我们的重点真的很简单。许多书其实是连略读都不值得的，另外一些书只需要快速读过就行了。有少数的书需要用某种速度，通常是相当慢的速度，才能完个理解。<strong>一个只需要快速阅读的书却用很慢的速度来读</strong>，就是在浪费时间，这时<strong>速读的技巧就能帮你解决问题</strong>。但这只是阅读问题中的一种而已。要了解一本难读的书，其间的障碍，非一般所谓生理或心理障碍所能比拟甚或涵盖。</p><p>所谓阅读速度，理想上来说，<strong>不只是要能读得快，还要能用不同的速度来阅读</strong>——<strong>要知道什么时候用什么样的速度是恰当的</strong>。<strong>检视阅读是一种训练有素的快速阅读</strong>，但这不只是因为你读的速度快——虽然你真的读得很快而是因为在检视阅读时，<strong>你只读书中的一小部分，而且是用不同的方式来读，不一样的目标来读</strong>。</p><p><strong>分析阅读通常比检视阅读来得慢一些</strong>，但就算你拿到一本书要做分析阅读，也不该用同样的速度读完全书。每一本书，不论是多么难读的书，在无关紧要的间隙部分就可以读快一点。而一本好书，总会包含一些比较困难，应该慢慢阅读的内容。</p><h4 id="4-4-逗留与倒退">4.4 逗留与倒退</h4><p>许多人会从最初学会阅读之后，多年一直使用“半出声"(sub-vocalize)的方式来阅读。此外，拍摄下来的眼睛在活动时的影片，显示年轻或未受过训练的阅读者，在阅读一行字的时候会在五六个地方发生“逗留”(fixate)现象。（眼睛在移动时看不见，只有停下来时才能看见。）因此，他们在读这一行字的时候，只能间隔着看到一个个单字或最多两三个字的组合。更糟的是，这些不熟练的阅读者在每看过两三行后，眼睛就自然地“倒退”(regress)到原点——也就是说，他们又会倒退到先前读过的句子与那一行去了。</p><p>许多人在阅读时会“逗留”会“倒退”，因而使他们的速度慢下来的习惯。</p><p>要矫正眼睛逗留于一点的工具有很多种，有些很复杂又很昂贵。无论如何，任何复杂的工具其实都比不上你的一双手来得有用，<strong>你可以利用双手训练自己的眼睛，跟着章节段落移动得越来越快</strong>。你可以自己做这样的训练：<strong>将大拇指与食指、中指合并在一起，用这个“指针”顺着一行一行的字移动下去，速度要比你眼睛感觉的还要快一点</strong>。<strong>强迫自己的眼睛跟着手部的动作移动</strong>。一旦你的眼睛能跟着手移动时，你就能读到那些字句了。继续练习下去，继续增快手的动作，等到你发觉以前，你的速度已经可以比以前快两三倍了。</p><h4 id="4-5-理解的问题">4.5 理解的问题</h4><p><strong>一个优秀的阅读者就是读得很主动，很专心。</strong></p><p>专心并不一定等于理解力——如果大家对“理解力”并没有误解的话。理解力，是比回答书本内容一些简单问题还要多一点的东西。那种有限的理解力，不过是小学生回答”这是在说什么？”之类问题的程度而已。一个读者要能够正确地回答许多更进一步的问题，才表示有更高一层的理解力，而这是速读课程所不要求的东西，也几乎没有人指导要如何回答这类的问题。</p><p>速读的问题就出在理解力上。事实上，这里所谓的理解力是超越基础阅读层次以上的理解力，也是造成问题的根源。大多数的速读课程都没有包括这方面的指导。因此，有一点值得在这里强调的是，本书之所以想要改进的．正是这一种阅读的理解力。没有经过分析阅读，你就没法理解一本书。正如我们前面所言，分析阅读，是想要理解（或了解）一本书的基本要件。</p><h4 id="4-6-检视阅读的摘要">4.6 检视阅读的摘要</h4><p><strong>阅读的速度并非只有单一的一种，重点在如何读出不同的速度感，知道在阅读某种读物时该用什么样的速度</strong>。超快的速读法是引人怀疑的一种成就，那只是表现你在阅读一种根本不值得读的读物。更好的秘方是：**在阅读一本书的时候，慢不该慢到不值得，快不该快到有损于满足与理解。**不论怎么说，阅读的速度，不论是快还是慢，只不过是阅读问题一个微小的部分而已。</p><p>当你并<strong>不清楚手边的一本书是否值得细心阅读时</strong>（经常发生这种情况），<strong>必须先略读一下</strong>。一般来说，<strong>就算你想要仔细阅读的书也要先略读一下，从基本架构上先找到一些想法。</strong></p><p>最后，<strong>在第一次阅读一本难读的书时，不要企图了解每一个字句</strong>。这是最最重要的一个规则。<strong>这也是检视阅读的基本概念。<strong>不要害怕，或是担忧自己似乎读得很肤浅。就算是</strong>最难读的书也快快地读一遍</strong>。当你再读第二次时，你就已经准备好要读这本书了。</p><h3 id="第五章-如何做一个自我要求的读者">第五章 如何做一个自我要求的读者</h3><p><strong>在阅读的时候想要保持清醒，或昏昏入睡，主要看你的阅读目标是什么</strong>。如果你的<strong>阅读目标是获得利益</strong>——<strong>不论是心灵或精神上的成长</strong>——<strong>你就得保持清醒</strong>。这也意味着<strong>在阅读时要尽可能地保持主动</strong>，同时还<strong>要做一番努力</strong>——而这番努力是<strong>会有回馈</strong>的。</p><h4 id="5-1-主动的阅读基础：一个阅读者要提出的四个基本问题">5.1 主动的阅读基础：一个阅读者要提出的四个基本问题</h4><p><strong>主动阅读的核心</strong>：你在阅读时要<strong>提出问题</strong>来——<strong>在阅读的过程中，你自己必须尝试去回答的问题。</strong></p><ol><li><p><strong>整体来说，这本书到底在谈些什么？</strong><br>你一定要<strong>想办法找出这本书的主题</strong>，作者<strong>如何依次发展这个主题，如何逐步从核心主题分解出从打属的关键议题来</strong>。</p></li><li><p><strong>作者细部说了什么，怎么说的？</strong><br>你一定要想办法<strong>找出主要的想法、声明与论点</strong>。这些<strong>组合成作者想要传达的特殊讯息</strong>。</p></li><li><p><strong>这本书说得有道理吗？是全部有道理，还是部分有道理？</strong><br>除非你能回答前两个问题，否则你没法回答这个问题。在你<strong>判断这本书是否有道理之前</strong>，你必须先<strong>了解整本书在说些什么才行</strong>。然而，等你了解了一本书，如果你又读得很认真的话，你会觉得有责任为这本书做个自己的判断。光是知道作者的想法是不够的。</p></li><li><p><strong>这本书跟你有什么关系？</strong><br>如果这本书给了你一些资讯，你一定要问问这些资讯有什么意义。为什么这位作者会认为知道这件事很重要？你真的有必要去了解吗？如果这本书不只提供了资讯，还启发了你，就更有必要找出其他相关的、更深的含意或建议，以获得更多的启示。</p></li></ol><p>任何一种超越基础阅读的阅读层次，<strong>核心就在你要努力提出问题</strong>（然后尽你可能地找出答案）。这是绝不可或忘的原则。这也是有自我要求的阅读者，与没有自我要求的阅读者之间，有天壤之别的原因。后者提不出问题——当然也得不到答案。</p><h4 id="5-2-如何让一本书真正属于你自己">5.2 如何让一本书真正属于你自己</h4><p>要真正完全拥有一本书，必须把这本书变成你自己的一部分才行，而要让你成为书的一部分最好的方法——书成为你的一部分和你成为书的一部分是同一件事——就是要去写下来。</p><p><strong>为什么对阅读来说，在书上做笔记是不可或缺的事？</strong><br><strong>第一，那会让你保持清醒——不只是不昏睡，还是非常清醒。</strong><br>**其次，阅读，如果是主动的，就是一种思考，而思考倾向于用语言表达出来——不管是用讲的还是写的。**一个人如果说他知道他在想些什么，却说不出来，通常是他其实并不知道自己在想些什么。<br><strong>第三，将你的感想写下来，能帮助你记住作者的思想。</strong></p><p>阅读一本书应该像是你与作者之间的对话。有关这个主题，他知道的应该比你还多，否则你根本用不着去跟这本书打交道了。但是了解是一种双向沟通的过程，学生必须向自己提问题，也要向老师提问题。一旦他了解老师的说法后，还要能够跟老师争辩。在书上做笔记，其实就是在表达你跟作者之间相异或相同的观点。这是你对作者所能付出的最高的敬意。</p><h4 id="5-3-做笔记的多种方法">5.3 做笔记的多种方法</h4><ol><li><p><strong>画底线</strong>——在主要的重点，或<strong>重要又有力量的句子下画线</strong></p></li><li><p><strong>在画底线处的栏外再加画一道线</strong>——把你已经<strong>画线的部分再强调一遍</strong>，或是某一段很重要，但要画底线太长了，便在这一整段外加上一个记号</p></li><li><p><strong>在空白处做星号或其他符号</strong>——要<strong>慎用</strong>，<strong>只用来强调书中十来个最重要的声明或段落</strong>即可。你可能想要将<strong>做过这样记号的地方每页折一个角，或是夹一张书签</strong>。这样你随时从书架上拿起这本书，打开你做记号的地方，就能唤醒你的记忆</p></li><li><p><strong>在空白处编号</strong>——作者的某个论点发展出一连串的重要陈述时，可以<strong>做顺序编号</strong></p></li><li><p><strong>在空白处记下其他的页码</strong>——强调作者在书中其他部分也有过同样的论点，或相关的要点，或是与此处观点不同的地方。这样做能让散布全书的想法统一集中起来。许多读者会用 Cf 这样的记号，表示比较或参照的意思</p></li><li><p><strong>将关键字或句子圈出来</strong>——这跟画底线是同样的功能。</p></li><li><p><strong>在书页的空白处做笔记</strong>——在阅读某一章节时，你可能会有些问题（或答案），在空白处记下来，这样可以帮你回想起你的问题或答案。你也可以将复杂的论点简化说明在书页的空白处。或是记下全书所有主要论点的发展顺序。书中最后一页可以用来作为个人的索引页，将作者的主要观点依序记下来。</p></li></ol><p><strong>书前的空白页最好是用来记载你的思想</strong>。 你读完一本书，在最后的空白页写下个人的索引后，再翻回前面的空白页，试着将全书的大纲写出来，用不着一页或一个重点一个重点地写（你已经在书后的空白页做过这件事了），试着将全书的整体架构写出来，列出基本的大纲与前后篇章秩序。</p><h4 id="5-4-三种做笔记的方法">5.4 三种做笔记的方法</h4><h5 id="5-4-1-结构笔记-structural-note-making">5.4.1 结构笔记(structural note-making)</h5><p>用检视阅读来读一本书时，可能没有太多时间来做笔记。检视阅读，就像我们前面所说过的，所花的时间永远有限。虽然如此，你在这个层次阅读时，还是会提出一些重要的问题，而且最好是在你记忆犹新时，将答案也记下来——只是有时候不见得能做得到。</p><p><strong>在检视阅读中，要回答的问题是：</strong><br><strong>第一，这是什么样的一本书？</strong><br><strong>第二，整本书在谈的是什么？</strong><br><strong>第三，作者是借着怎样的整体架构，来发展他的观点或陈述他对这个主题的理解？</strong></p><p>**你应该做下笔记，把这些问题的答案写下来。**尤其如果你知道终有一天，或许是几天或几个月之后，你会重新拿起这本书做分析阅读时，就更该将问题与答案先写下来。要做这些笔记最好的地方是目录页，或是书名页，这些是我们前面所提的笔记方式中没有用到的页数。</p><p>在这里要注意的是，这些笔记主要的重点是全书的架构，而不是内容——至少不是细节。因此我们称这样的笔记为<strong>结构笔记(structural note-making)</strong>。</p><h5 id="5-4-2-概念笔记-conceptual-note-making">5.4.2 概念笔记(conceptual note-making)</h5><p>在检视阅读的过程中，特别是又长又难读的书，你有可能掌握作者对这个主题所要表达的一些想法。但是通常你做不到这一点。 而除非你真的再仔细读一遍全书，否则就不该对这本书立论的精确与否、有道理与否遽下结论。 之后，等你做分析阅读时，关于这本书准确性与意义的问题，你就要提出答案了。<strong>在这个层次的阅读里，你做的笔记就不再是跟结构有关，而是跟概念有关了</strong>。这些概念是作者的观点，而<strong>当你读得越深越广时，便也会出现你自己的观点了</strong>。</p><p><strong>结构笔记</strong>与**概念笔记(conceptual note-making)**是截然不同的。而当你同时在读好几本书，在做主题阅读——就同一个主题，阅读许多不同的书时，你要做的又是什么样的笔记呢？同样的，这样的笔记也应该是概念性的。你在书中空自处所记下的页码不只是本书的页码，也会有其他几本书的页码。</p><h5 id="5-4-3-辩证笔记-dialectical-note-making">5.4.3 辩证笔记(dialectical note making)</h5><p>对一个已经熟练同时读好几本相同主题书籍的专业阅读者来说，还有一个更高层次的记笔记的方法。那就是针对一场讨论情境的笔记——这场讨论是由许多作者所共同参与的，而且他们可能根本没有觉察自己的参与。我们喜欢称这样的笔记为<strong>辩证笔记(dialecticalnote making)</strong>。因为<strong>这是从好多本书中摘要出来的</strong>，而不是一本，因而<strong>通常需要用单独的一张纸来记载</strong>。这时，我们会再用上概念的结构——就一个单一主题，把所有相关的陈述和疑问顺序而列。</p><h4 id="5-5-培养阅读的习惯">5.5 培养阅读的习惯</h4><p><strong>要养成习惯，除了不断地运作练习之外，别无他法。</strong></p><p><strong>在你养成习惯的前后，最大的差异就在于阅读能力与速度的不同</strong>。经过练习后，同一件事，你会做得比刚开始时要好很多。这也就是俗话说的<strong>熟能生巧</strong>。<strong>一开始你做不好的事，慢慢就会得心应手</strong>，像是自然天生一样。你好像生来就会做这件事，就跟你走路或吃饭一样自然。这也是为什么说习惯是第二天性的道理。</p><h4 id="5-6-由许多规则中养成一个习惯">5.6 由许多规则中养成一个习惯</h4><p><strong>一定要学会忘掉那些分开的步骤，才能表现出整体的动作，而每一个单一的步骤都还要确实表现得很好。</strong> 但是，为了<strong>要忘掉这些单一的动作</strong>，一开始你<strong>必须先分别学会每一个单一的动作</strong>。只有这样，你<strong>才能将所有的动作连结起来。</strong></p><p>阅读就跟滑雪一样，除非你对每一个步骤都很熟练之后，你才能将所有不同的步骤连结起来，变成一个复杂却和谐的动作。你无法压缩其中不同的部分，好让不同的步骤立刻紧密连结起来。你在做这件事时，每一个分开来的步骤都需要你全神贯注地去做。<strong>在你分别练习过这些分开来的步骤后</strong>，你不但<strong>能放下你的注意力</strong>，<strong>很有效地将每个步骤做好</strong>，还<strong>能将所有的动作结合起来，表现出一个整体的顺畅行动</strong>。</p><p><strong>一个人只要学习过一种复杂的技巧，就会知道要学习一项新技巧，一开始的复杂过程是不足为惧的</strong>。也知道他用不着担心这些个别的行动，因为只有<strong>当他精通这些个别的行动时，才能完成一个整体的行动</strong>。</p><p>规则的多样化，意味着要养成一个习惯的复杂度，而非表示要形成许多个不同的习惯。在到达一个程度时，每个分开的动作自然会压缩、连结起来，变成一个完整的动作。当<strong>所有相关动作都能相当自然地做出来时，你就已经养成做这件事的习惯了</strong>。然后你就能想一下如何读一本以前你觉得对自己来说很困难的书。<strong>一开始时，学习者只会注意到自己与那些分开来的动作。等所有分开的动作不再分离，渐渐融为一体时，学习者便能将注意力转移到目标上，而他也具备了要达成目标的能力了</strong>。</p><p>要学习做一个很好的阅读者并不容易。而且不单单只是阅读．还是分析式的阅读。</p><h2 id="第二篇-阅读的第三个层次：分析阅读">第二篇 阅读的第三个层次：分析阅读</h2><h3 id="第六章-一本书的分类">第六章 一本书的分类</h3><p>当我们提到读书的时候，所说明的<strong>阅读规则也同样适用于其他比较易于阅读的资料</strong>。虽然这些规则程度不尽相当，应用在后者身上时，有时候作用不尽相同，但是<strong>只要你拥有这些技巧，懂得应用，总可以比较轻松。</strong></p><h4 id="6-1-书籍分类的重要性（规则一：分类）">6.1 书籍分类的重要性（规则一：分类）</h4><p><strong>分析阅读的第一个规则可以这么说：</strong></p><p><strong>规则一：</strong><br><strong>你一定要知道自己在读的是哪一类书，而且要越早知道越好。最好早在你开始阅读之前就先知道。</strong></p><p>一开始时，你要**先检视这本书用检视阅读先浏览一遍。**你读读书名、副标题、目录，然后最少要看看作者的序言、摘要介绍及索引。如果这本书有书衣，要看看出版者的宣传文案。这些都是作者在向你传递讯号，让你知道风朝哪个方向吹。如果你不肯停、看、听，那也不是他的错。</p><h4 id="6-2-从一本书的书名中你能学到什么">6.2 从一本书的书名中你能学到什么</h4><p>如果读者忽略了这一切，却答不出“这是－本什么样的书”的问题，那他只该责怪自己了。事实上，他只会变得越来越困惑。如果他不能回答这个问题，如果他从没问过自己这个问题，他根本就不可能回答随之而来的，关于这本书的其他问题。</p><p>阅读书名很重要，但还不够。除非你能在心中有一个分类的标准，否则世上再清楚的书名，再详尽的目录、前言，对你也没什么帮助。</p><p><strong>只有当你自己心中有一个分类的标准，你才能做明智的判断。<strong>换句话说，如果</strong>你想简单明白地运用这个规则，那就必须先使这个规则更简单明白一些</strong>。只有当你在不同的书籍之间能找出区别，并且定出一些合理又经得起时间考验的分类时，这个规则才会更简单明白一些。</p><p>我们要确定的是一个基本的分类原则，这个原则适用于所有的论说性作品。这也就是用来区分理论性与实用性作品的原则。</p><h4 id="6-3-实用性vs-理论性作品">6.3 实用性vs.理论性作品</h4><p><strong>实用是与某种有效的做法有关，不管是立即或长程的功效。而理论所关注的却是去明白或了解某件事。</strong></p><p>知识可以用在许多方面，不只是控制自然，发明有用的机器或工具，还可以指导人类的行为，在多种技术领域中校正人类的运作技巧。这里我们要举的例子是纯科学与应用科学的区别，或是像通常非常粗糙的那种说法，也就是科学与科技之间的区别。</p><p><strong>要让知识变成实用，就要有操作的规则。<strong>我们一定要超越</strong> ”知道这是怎么回事”，进而明白“如果我们想做些什么，应该怎么利用它”</strong>。概括来说，这也就是知与行的区别。理论性的作品是在教你这是什么，实用性的作品在教你如何去做你想要做的事，或你认为应该做的事。</p><p><strong>任何一本指南类的书都是实用的。任何一本书告诉你要该做什么，或如何去做，都是实用的书。</strong></p><p>所有<strong>说明某种艺术的学习技巧</strong>，<strong>任何一个领域的实用手册</strong>，像是工程、医药或烹任，或<strong>所有便于分类为“教导性"</strong>(moral)<strong>的深奥论述</strong>，如经济、伦理或政治问题的书，<strong>都是实用的书。</strong></p><p>严格来说，<strong>任何一本教我们如何生活，该做什么，不该做什么，同时说明做了会有什么奖赏，不做会有什么惩罚的伦理的书</strong>，不论我们是否同意他的结论，<strong>都得认定这是一本实用的书。</strong></p><p>实用书所用到的典型陈述，是某件事应该做完（或做到）；这样做（或制造）某个东西是对的；这样做会比那样做的结果好；这样选择要比那样好，等等。相反的，理论型的作品却常常说”是“，没有“应该”或“应当”之类的字眼。那是在表示某件事是真实的，这些就是事实，不会说怎样换一个样子更好，或者按照这个方法会让事情变得更好等等。</p><p>照传统的分法，理论性的作品会被分类为<strong>历史、科学和哲学</strong>等等。</p><p><strong>历史</strong>就是<strong>纪事</strong>(Chronotopic)。</p><p><strong>科学</strong>则不会太在意过去的事，它所面对的是可能发生在任何时间、地点的事。科学家寻求的是<strong>定律或通则</strong>。</p><p>如果一本理论的书所强调的内容，超乎你日常、例行、正常生活的经验，那就是<strong>科学</strong>的书。否则就是一本<strong>哲学</strong>的书。</p><h3 id="第七章-透视一本书">第七章 透视一本书</h3><h4 id="7-0-规则二：简单描述整本书的内容、规则三：列举重要篇章，说明怎么组成一个整体的架构">7.0 规则二：简单描述整本书的内容、规则三：列举重要篇章，说明怎么组成一个整体的架构</h4><p>每一本书的封面之下都有一套自己的骨架。作为一个分析阅读的读者，你的责任就是要找出这个骨架。</p><p>知道<strong>掌握一本书的架构是绝对需要的</strong>，这能带引你发现阅读任何一本书的第二及第三个规则。 我们说的是“任何一本书”。这些规则适用于诗集，也适用于科学书籍．或任何一种论说性作品。当然，根据书本的不同这些规则在应用时会各不相同。</p><p><strong>分析阅读的第二个规则是：</strong><br><strong>使用一个单一的句子，或最多几句话（一小段文字）来叙述整本书的内容。</strong></p><p>从某一方面来说，每一本书都有一个“干什么”的主题，整本书就是针对这个主题而展开。如果你知道了，就明白了这是什么样的书。我们也可以揣测－个作者想要干什么．想要做什么。<strong>找出一本书在干什么，也就是在发现这本书的主题或重点。</strong></p><p>对于“整体内容”这件事，光是一个模糊的认知是不够的，你必须要确切清楚地了解才行。只有一个方法能知道你是否成功了。你必须能用几句话，告诉你自己，或别人，这整本书在说的是什么。不要满足于“感觉上的整体”，自己却说不出口。</p><p><strong>第三个规则可以说成是：</strong><br><strong>将书中重要篇章列举出来，说明它们如何按照顺序组成一个整体的架构。</strong></p><p>一本好书，就像一栋好房子，每个部分都要很有秩序地排列起来。每个重要部分都要有一定的独立性。就像我们看到的，每个单一部分有自己的室内架构，装潢的方式也可能跟其他部分不同。但是却一定要跟其他部分连接起来这是与功能相关——否则这个部分便无法对整体的智能架构作出任何贡献了。</p><h4 id="7-1-结构与规划：叙述整本书的大意">7.1 结构与规划：叙述整本书的大意</h4><p>首先，一位作者，特别是好的作者，会经常想要帮助你整理出他书中的重点。尽管如此，当你要求读者择要说出一本书的重点时，大多数人都会一脸茫然。一个原因是今天的人们普遍不会用简明的语言表达自己，另一个原因，则是他们忽视了阅读的这一条规则。当然，这也说明太多读者根本就不注意作者的前言，也不注意书名，才会有这样的结果。</p><p>其次，是要小心，不要把我们提供给你的那些书的重点摘要，当作是它们绝对又惟一的说明。一本书的整体精神可以有各种不同的诠释，没有哪一种一定对。当然，某些诠释因为够精简、准确、容易理解，就是比另一些诠释好。不过，也有些南辕北辙的诠释，不是高明得不相上下，就是烂得不相上下。</p><h4 id="7-2-驾驭复杂的内容：为一本书拟大纲的技巧">7.2 驾驭复杂的内容：为一本书拟大纲的技巧</h4><p>我们可以依照第三个规则，将内容大纲排列如下：<br>(1)  作者将全书分成五个部分，<strong>第一部分谈的是什么，第二部分谈的是什么，第三部分谈的是别的事，第四部分则是另外的观点，第五部分又是另一些事。</strong></p><p>(2)  <strong>第一个主要的部分又分成三个段落，第一段落为X，第二段落为Y，第三段落为Z。</strong></p><p>(3)  在<strong>第一部分的第一阶段，作者有四个重点，第一个重点是A，第二个重点是B，第三个重点是C，第四个重点是D</strong>等等。</p><p>一本书的生命也是有限的，就算不死，也跟所有人造的东西一样是不完美的。 因为没有一本书是完美的，所以也不值得为任何一本书写出一个完美的纲要。你只要尽力而为就行了。</p><h4 id="7-3-阅读与写作的互惠技巧">7.3 阅读与写作的互惠技巧</h4><p>一个作品应该有整体感，清楚明白，前后连贯。如果这本书有整体的精神，那我们就一定要找出来。如果全书是清楚明白又前后一贯的，我们就要找出其间的纲要区隔，与重点的秩序来当作回报。所谓文章的清楚明白，就是跟纲要的区隔是否清楚有关，所谓文章的前后一贯，就是能把不同的重点条理有序地排列出来。</p><p><strong>规则二和规则三这两个规则不但可以用来阅读一整本论说性的书，也可以用来阅读其中某个特别重要的部分</strong>。如果书中某个部分是一个相当独立又复杂的整体，那么就要分辨出这部分的整体性与复杂性，才能读得明白。 传达知识的书，与文学作品、戏剧、小说之间，有很大的差异。 前者的各个部分可以是独立的，后者却不能。如果一个人说他把那本小说已经”读到够多，能掌握主题了”，那他一定根本不知道自己在说些什么。</p><h4 id="7-4-发现作者的意图（规则四：找出作者要问的问题）">7.4 发现作者的意图（规则四：找出作者要问的问题）</h4><p><strong>第四个规则可以说是：</strong><br><strong>找出作者要问的问题。</strong></p><p>如果主要的问题很复杂，又分成很多部分，你还要能说出次要的问题是什 么。你应该不只是有办法完全掌握住所有相关的问题，还要能明智地将这些问题整合出顺序来。哪一个是主要的，哪个是次要的？哪个问题要先回答，哪些是后来才要回答的？</p><p>从某方面来说，你可以看出这个规则是在重复一些事情，这些事情在你掌握一本书的整体精神和重要部分的时候已经做过了。然而，这个规则的确可以帮你做好这些事。换句话说，遵守规则四，能让你和遵守前两条规则产生前后呼应的效果。</p><p><strong>如何找出作者的问题？</strong><br>某件事存在吗？是什么样的事？发生的原因是什么？或是在什么样的情况下存在？或为什么会有这件事的存在？这件事的目的是什么？造成的影响是什么？特性及特征是什么？与其他类似事件，或不相同事件的关联是什么？这件事是如何进行的？以上这些都是<strong>理论性的问题</strong>。</p><p>有哪些结果可以选择？应该采取什么样的手段才能获得某种结果？要达到某个目的，应该采取哪些行动？以什么顺序？在这些条件下，什么事是对的，或怎样才会更好，而不是更糟？在什么样的条件下，这样做会比那样做好一些？以上这些都是<strong>实用的问题</strong>。</p><h4 id="7-5-分析阅读的第一个阶段">7.5 分析阅读的第一个阶段</h4><p>阅读的前四个规则是分析阅读的规则。如果在运用之前能先做好检视阅读，会更能帮助你运用这些规则。这前四个规则是有整体性，有同一个目标的。这四个规则在一起，能提供读者对一本书架构的认识。当你运用这四个规则来阅读一本书，或任何又长又难读的书时，你就完成了分析阅读的第一个阶段。</p><p><strong>真正实际的读者是一次就完成所有的阶段。</strong></p><h4 id="7-6-总结">7.6 总结</h4><p>分析阅读的第一阶段，或，找出一本书在谈些什么的四个规则：<br>(1)<strong>依照书本的种类与主题作分类。</strong><br>(2)<strong>用最简短的句子说出整本书在谈些什么。</strong><br>(3)<strong>按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出。</strong><br>(4) <strong>找出作者在问的问题，或作者想要解决的问题。</strong></p><h3 id="第八章-与作者找出共通的词义">第八章 与作者找出共通的词义</h3><p>如果你运用了前一章结尾时所谈到的前四个规则，你就完成了分析阅读的第一个阶段。</p><p>现在进行第二个阶段。这也包括了四个阅读规则。</p><p><strong>第一个规则——称为“找出共通的词义”</strong></p><p>在任何一个成功的商业谈判中，双方找出共同的词义，也就是达成共识(coming to terms)，通常是最后一个阶段。</p><p>但是在用<strong>分析阅读阅读一本书时，找出共通的词义却是第一个步骤。<strong>除非读者与作者能找出共通的词义，否则想要把知识从一方传递到另一方是不可能的事。因为</strong>词义(term)是可供沟通的知识的基本要素</strong>。</p><h4 id="8-1-单字vs-词义">8.1 单字vs.词义</h4><p>词义和单字(word)不同——至少，不是一个没有任何进一步定义的单字。如果词义跟单字完全相同，你只需要找出书中重要的单字，就能跟作者达成共识了。但是一个单字可能有很多的意义，特别是一个重要的单字。如果一个作者用了一个单字是这个意义，而读者却读成其他的意义，那这个单字就在他们之间擦身而过，他们双方没有达成共识。</p><p><strong>沟通是一个人努力想要跟别人</strong>（也可能是动物或机器）<strong>分享他的知识、判断与情绪</strong>。只有当双方对一些事情达成共识，譬如彼此对一些资讯或知识都有分享，沟通才算成功。</p><p>只要模糊地带还存在，就表示作者和读者之间对这些单字的意义还没有共识。为了要达成完全的沟通，最重要的是双方必须要使用意义相同的单字——简单来说，就是，<strong>找出共通的词义达成共识</strong>。双方找出共通的词义时，沟通就完成了，两颗心也奇迹似地拥有了相同的想法。</p><p>词义可以定义为没有模糊地带的字。当一个单字使用得没有模糊意义的时候，就是一个词义了。字典中充满了单字。就这些单字都有许多意义这一点而言，它们几乎都意义模糊。当某个时间，作者与读者同时在使用同一个单字，并采取惟一相同的意义时，在那种毫无模糊地带的状态中，他们就是找出共通的词义了。</p><p>可以将达成共识看作是一种<strong>使用文字的技巧，以达到沟通知识</strong>的目的。</p><p>必须<strong>抓住书中重要的单字．搞清楚作者是如何使用这个单字的</strong>。不过我们可以说得更精确又优雅一些。</p><h4 id="8-2-规则五：找出重要单字，透过它们与作者达成共识">8.2 规则五：找出重要单字，透过它们与作者达成共识</h4><p><strong>第一部分：</strong> <strong>找出重要单字</strong>，那些举足轻重的单字。</p><p><strong>第二部分：</strong> <strong>确认这些单字在使用时的最精确的意义</strong>。</p><p>这是分析阅读第二阶段的第一个规则，目标是<strong>诠释内容与讯息</strong>。</p><p><strong>第一个步骤</strong>是<strong>处理语言的问题</strong>。<br><strong>第二个步骤</strong>是<strong>超越语言，处理语言背后的思想涵义</strong>。</p><p>因为语言并不是完美的传递知识的媒介，因而在沟通时也会有形成障碍的作用。追求具备诠释能力的阅读，规则就在克服这些障碍。身为读者，我们应该从我们这一边来努力打通障碍。两个心灵想透过语言来接触，需要作者与读者双方都愿意共同努力才行。就像教学，除非被教的学生产生<strong>呼应的活力</strong>，否则光靠老师是行不通的。</p><p>语言与思想的问题——特别是单字与词义之间的差异——是非常重要的。因此我们宁愿冒着重复的风险，也要确定这个重点被充分了解。这个重点就是，一个单字可能代表许多不同的词义，而一个词义可以用许多不同的单字来解释。</p><h4 id="8-3-找出关键字">8.3 找出关键字</h4><p>如果你不想办法了解这些关键字所出现的那些段落的意思，你就没法指出哪些字是关键字了。如果你了解那些段落的意思，当然会知道其中哪几个字是非常重要的。如果你并不完全了解那些段落的意思，很可能是因为你并不清楚作者是如何使用一些特定的字眼。如果你把觉得有困扰的字圈出来，很可能就找出了作者有特定用法的那些字了。</p><p>从一个读者的角度来看，<strong>最重要的字就是那些让你头痛的字</strong>。这些字很可能对作者来说也很重要。不过，有时也并非如此。</p><p>也很可能，对作者来说很重要的字．对你却不是问题——因为你已经了解了这些字。在这种状况下，你与作者就是已经找出共通的词义，达成共识了。只有那些还未达成共识的地方，还需要你的努力。</p><h4 id="8-4-专门用语及特殊字汇">8.4 专门用语及特殊字汇</h4><p><strong>第一个，也是最明显的信号是，作者开诚布公地强调某些特定的字，而不是其他的字</strong>。他会用很多方法来做这件事。他会用不同的字体来区分，如加括号，斜体字等记号以提醒你。他也会明白地讨论这些字眼不同的意义．并指出他是如何在书中使用这些不同的字义，以引起你对这些字的注意。或是他会借着这个字来命名另外一个东西的定义，来强调这个字。</p><p>每一个知识领域都有独特的专门用语(technical vocabulary)。</p><p>如果你知道这是什么种类的书，整本书在谈的主题是什么，有哪些重要的部分，将大大帮助你把专门用语从一般用语中区分出来。作者的书名、章节的标题、前言，在这方面也都会有些帮助。</p><p>某些知识领域有一套完整的专门用语，在一本这种主题的书中找出重要的单字，相形之下就很容易了。就积极面来说．只要熟悉一下那个领域，你就能找出这些专门的单字；就消极面来说，你只要看到不是平常惯见的单字，就会知道那些字一定是专门用语。</p><p><strong>另外一个线索是，作者与其他作者争执的某个用语就是重要的字</strong>。当你发现一位作者告诉你某个特定的字曾经被其他人如何使用，而他为什么选择不同的用法时，你就可以知道这个字对他来说意义非凡。</p><p>**大多数人都习惯于没有主动的阅读。**没有主动的阅读或是毫无要求的阅读，最大的问题就在读者对字句毫不用心，结果自然无法跟作者达成共识了。</p><h4 id="8-5-找出字义">8.5 找出字义</h4><p><strong>你一定要利用上下文自己已经了解的所有字句，来推敲出你所不了解的那个字的意义。</strong></p><p>如果一个定义里的每个字都还需要去定义时，那没有任何一个东西可以被定义了。</p><p>事实上，本书之所以能给你带来新的洞察力或启发，就是因为其中有一些你不能一读即懂的字句。如果你不能自己努力去了解这些字，那就不可能学会我们所谈的这种阅读方法。你也不可能作到自己阅读一本书的时候，从不太了解进展到逐渐了解的境界。</p><p>一个单字是可以代表许多不同词义的。记住这件事的一个方法，是区分作者的用语(vocabulary)与专业术语(terminology) 之间的不同。</p><p>另外还有一些更复杂的情况。首先，<strong>一个可以有许多不同意义的字，在使用的时候可以只用其中一个意义，也可以把多重意义合起来用</strong>。让我们再用“阅读”来当例子。在本书某些地方，我们用来指阅读任何一种书籍。在另一些地方，我们指的是教导性的阅读，而非娱乐性的阅读。还有一些其他地方，我们指的更是启发性的阅读，而非只是获得资讯。</p><p>为了确定你跟我们对于阅读这件事达成了共识，我们用类似“启发性的阅读”的句子来代替“阅读”这两个字。为了更确定清楚，我们又用了类似“如何运用你的心智来阅读一本书，也就是如何让自己从不太理解到逐渐理解的一个过程”的长句子来说明一个词义，这个词义也就是本书最强调的一种阅读。但这个词义却分别用了一个字、一个片语及一个长句子来作说明。</p><p><strong>如果因为练习分析阅读而引发你的兴趣，你可以利用这种阅读多读一点和这些主题相关的书。在阅读这些书时，你会获得更多的好处，因为你是在阅读的经验中，提出了自己的问题而去找这些书的。</strong></p><p>你也可能并不想再研究下去。就算你不想，只<strong>要你肯花一点精神，在读一本书的时候，找出重要的关键字，确认每个字不同意义的转换，并与作者找出共通的词义．你对一本书的理解力就会大大增加了</strong>。很少有一些习惯上的小小改变，会产生如此宏大的效果。</p><h3 id="第九章-判断作者的主旨">第九章 判断作者的主旨</h3><p>书里的提案，也就是主旨，也是一种声明。 那是作者在表达他对某件事的判断。他断言某件他认为是真的事，或否定某件他判断是假的事。他坚持这个或那个是事实。 这样的提案，是一种知识的声明，而不是意图的声明。作者的意图可能在前言的一开头就告诉我们了。就一部论说性的作品来说．通常他会承诺要指导我们做某件事。为了确定他有没有澄守这些承诺．我们就一定要找出他的**主旨(propositions)**才行。</p><h4 id="9-0-规则六：与句子及提案有关、规则七：与各种论述-arguments-有关">9.0 规则六：与句子及提案有关、规则七：与各种论述(arguments)有关</h4><p><strong>分析阅读的第六个规则，是与句子及提案有关的规则。</strong></p><p>第七个规则与第六个规则是息息相关的。一位作者可能借着事件、事实或知识，诚实地表达自己的想法。通常我们也是抱着对作者的信任感来阅读的。但是除非我们对作者的个性极端感兴趣，否则只是知道他的观点并不能满足我们。<strong>作者的主旨如果没有理论的支持，就只是在抒发个人想法罢了</strong>。如果是这本书、这个主题让我们感兴趣，而不是作者本身，那么我们不只想要知道作者的主张是什么，还想知道<strong>为什么他认为我们该被说服，以接受这样的观点</strong>。</p><p><strong>因此，第七个规则与各种论述(arguments)有关。</strong></p><p>一种说法总是受到许多理由、许多方法的支持。有时候我们可以强力主张真实，有时候则顶多谈谈某件事的可能。但不论哪种论点都要包含一些用某种方式表达的陈述。</p><p>我们说明**这些规则的顺序，都是有文法与逻辑的根据的。**我们从共识谈到主旨，再谈到论点，表达的方法是从字（与词）到一个句子，再到一连串的句子（或段落）来作说明。我们从最简单的组合谈到复杂的组合。当然，一本书含有意义的最小单位就是”字”。但是如果说一本书就是一连串字的组合，没有错，却并不恰当。书中也经常把一组组的字，或是一组组的句子来当单位。－个主动的读者，不只会注意到字，也会注意到句子与段落。 除此之外，没有其他方法可以发现一个作者的共识、主旨与论点。</p><p>我们把分析阅读谈到这里时——<strong>目的是在诠释作者的意图</strong>——似乎和第一个阶段的发展方向背道而驰——<strong>第一阶段的目的是掌握结构大纲</strong>。我们原先从将一本书当作是个整体，谈到书中的主要部分，再谈到次要的部分。</p><p>因此，这两个过程，掌握大纲与诠释意图，在主旨与论述的层次中互相交集了。你<strong>将一本书的各个部分细分出来</strong>，就可以<strong>找出主旨与论述</strong>。然后你再仔细<strong>分析一个论述由哪些主旨，甚至词义而构成</strong>。等这两个步骤你都完成时，就可以说是真的了解一本书的内容了。</p><h4 id="9-1-句子与主旨">9.1 句子与主旨</h4><p>句子与段落是文法的单位、语言的单位。主旨与论述是逻辑的单位，也就是思想与知识的单位。</p><p>让我们说明句子与主旨之间的关系。并不是一本书中的每一句话都在谈论主旨。有时候，一些句子在表达的是疑问。他们提出的是问题，而不是答案。<strong>主旨则是这些问题的答案</strong>。**主旨所声明的是知识或观点。**这也是为什么我们说表达这种声明的句子是叙述句(declarative)，而提出问题的句子是疑问句(interrogative)。其他有些句子则在表达希望或企图。这些句子可能会让我们了解一些作者的意图，却并不传达他想要仔细推敲的知识。</p><p>并不是每一个叙述句都能当作是在表达一个主旨。这么说至少有两个理由。第一个是<strong>事实上，字都有歧义，可以用在许多不同的句子中</strong>。因此，如果字所表达的意思改变了，很可能同样的句子却在阐述不同的主旨。</p><p><strong>当一个简单的句子使用的字都毫无歧义时，通常在表达的是一个单一的主旨</strong>。但就算用字没有歧义，一个复合句也可能表达一个或两个主旨。一个复合句其实是一些句子的组合，其间用一些字如 “与”、“如果……就”或“不但…而且”来作连接。</p><p>不只是一个单一的句子可以表达出不同的主旨，不管是有歧义的句子或复合句都可以，而且同一个主旨也能用两个或更多不同的句子来说明。如果你能抓住我们在字里行间所用的同义字，你就会知道我们在说：“教与学的功能是互相连贯的”与“传授知识与接受知识是息息相关的过程”这两句话时，所谈的是同一件事。</p><p>你应该注意一个句子中字的排列顺序，与彼此之间的关系。对一个阅读者来说，有一些文法的知识是必要的。除非你能越过语言的表象，看出其中的意义，否则你就无法处理有关词义、主旨与论述思想的要素——的问题。只要文字、句子与段落是不透明的、未解析的，他们就是沟通的障碍，而不是媒介。你阅读了一些字，却没有获得知识。</p><h4 id="9-2-谈规则（规则五、规则六、规则七）">9.2 谈规则（规则五、规则六、规则七）</h4><p><strong>第五个规则是：</strong> <strong>找出关键字，与作者达成共识</strong>。</p><p><strong>第六个规则是：</strong> <strong>将一本书中最重要的句子圈出来，找出其中的主旨</strong>。</p><p><strong>第七个规则是：</strong> <strong>从相关文句的关联中，设法架构出一本书的基本论述</strong>。</p><h4 id="9-3-找出关键句">9.3 找出关键句</h4><p>一本书中真正的关键句中只有少数的几句话，并不是说你就可以忽略其他的句子。当然，你应该要了解每一个句子。而大多数的句子，就像大多数的文字一样，对你来说都是亳无困难的。我们在谈速读时提到过，在读这些句子时可以相当快地读过去。</p><p><strong>从一个读者的观点来看，<strong>对你</strong>重要的句子就是一些需要花一点努力来诠释的句子</strong>，因为你第一眼看到这些句子时并不能完全理解。你对这些句子的理解，只及于知道其中还有更多需要理解的事。这些句子你会读得比较慢也更仔细一点。这些句子对作者来说也许并不是最重要的，但也很可能就是，因为<strong>当你碰到作者认为最重要的地方时，应该会特别吃力</strong>。用不着说，<strong>你在读这些部分时应该特别仔细才好。</strong></p><p>最重要的句子就是在整个论述中，阐述作者判断的部分。一本书中通常包含了一个以上或一连串的论述。作者会解释为什么他现在有这样的观点，或为什么他认为这样的情况会导致严重的后果。他也可能会讨论他要使用的一些字眼。他会批评别人的作品。他会尽量加入各种相关与支持的论点。但<strong>他沟通的主要核心是他所下的肯定与否定的判断</strong>，<strong>以及他为什么会这么做的理由</strong>。因此，<strong>要掌握住重点，就要从文章中看出浮现出来的重要句子。</strong></p><p>有些作者会帮助你这么做。他们会在这些字句底下划线。他们不是告诉你说这些是重点，就是用不同的印刷字体将主要的句子凸显出来。当然，如果你阅读时昏昏沉沉的，这些都帮不上忙了。我们碰到过许多读者或学生，根本不注意这些已经弄得非常清楚的记号。他们只是一路读下去，而不肯停下来仔细地观察这些重要的句子。</p><p>阅读的一部分本质就是被困惑，而且知道自己被困惑。怀疑是智慧的开始，从书本上学习跟从大自然学习是一样的。如果你对一篇文章连一个问题也提不出来，那么你就不可能期望一本书能给你一些你原本就没有的视野。</p><p><strong>另一个找出关键句的线索是</strong>——<strong>找出组成关键句的文字来。</strong></p><p><strong>如果你已经将重要的字圈出来了，它一定会引导你看到值得注意的句子</strong>。因此在诠释阅读法中，第一个步骤是为第二个步骤作准备的。反之亦然。 很可能你是因为对某些句子感到困惑，而将一些字作上记号的。事实上，虽然我们在说明这些规则时都固定了前后的顺序，但你却不一定要依照这个顺序来阅读。词义组成了主旨，主旨中又包含了词汇。如果你知道这个字要表达的意思，你就能抓住这句话中的主旨了**。如果你了解了一句话要说明的主旨，你也就是掌握了其中词义的意思。**</p><p><strong>接下来的是更进一步找出最主要的主旨的线索。<strong>这些主旨一定在一本书最主要的论述中——不是前提就是结论。因此，如果你能</strong>依照顺序找出这些前后相关的句子——找出有始有终的顺序</strong>，你<strong>可能就已经找到那些重要的关键句子了</strong>。</p><p>我们所说的顺序，要有始有终。任何一种论述的表达，都需要花点时间。你可以一口气说完一句话，但你要表达一段论述的时候却总要有些停顿。你要先说一件事，然后说另一件事．接下来再说另一件事。一个论述是从某处开始，经过某处，再到达某处的。那是思想的演变移转。可能开始时就是结论，然后再慢慢地将理由说出来。也可能是先说出证据与理由，再带引你达到结论。</p><p>许多人认为他们知道如何阅读，因为他们能用不同的速度来阅读。但是他们经常在错误的地方暂停，慢慢阅读。他们会为了一个自己感兴趣的句子而暂停，却不会为了感到困扰的句子而暂停。事实上，在阅读非当代作品时，这是最大的障碍。</p><h4 id="9-4-找出主旨">9.4 找出主旨</h4><p><strong>当你发现一段话里所使用的文字的意义时，你就和作者找到了共识</strong>。同样的，<strong>诠释过组成句子的每个字，特别是关键字之后，你就会发现主旨。</strong></p><p>在找出文字所表达的意思与句子所阐述的主旨之间，只有两个不同之处。一个是后者所牵涉的内容比较多。就像你要用周边的其他字来解释一个特殊的字一样，你也要借助前后相关的句子来了解那个问题句。在两种情况中，都是从你了解的部分，进展到逐渐了解你原来不懂的部分。</p><p><strong>另一个不同是书复杂的句子通常要说明的不只一个主旨</strong>。除非你能分析出所有不同，或相关的主旨，否则你还是没有办法完全诠释一个重要的句子。要熟练地做到这一点，就需要常常练习。<strong>试着在本书中找出一些复杂的句子，用你自己的话将其中的主旨写出来。</strong></p><p>“用你自己的话来说“，是测验你懂不懂一个句子的主旨的最佳方法。如果要求你针对作者所写的某个句子作解释，而你只会重复他的话或在前后顺序上作一些小小的改变，你最好怀疑自己是否真的了解了这句话。</p><p>如果你想要确定自己是否吸收了主旨，而不只是生吞活剥了字句，最好是用这种翻译来测试一下。就算你的测验失败了，你还是会发现自己的理解不及在哪里。</p><h4 id="9-5-找出论述">9.5 找出论述</h4><p>指导我们阅读的第七个规则的逻辑单位，是“论述”——一系列先后有序，其中某些还带有提出例证与理由作用的主旨。如同”意思”之于文字，“主旨”之于句子，“论述“这个逻辑单位也不会只限定于某种写作单位里。一个论述可能用一个复杂的句子就能说明。可能用一个段落中的某一组句子来说明。可能等于一个段落，但又有可能等于好几个段落。</p><p>另外还有一个困难点。在任何一本书中都有许多段落根本没有任何论述——就连一部分也没有。这些段落可能是一些说明证据细节，或者如何收集证据的句子。</p><p><strong>第七个规则可以有另一个公式：</strong></p><p><strong>如果可以，找出书中说明重要论述的段落。但是，如果这个论述井没有这样表达出来，你就要去架构出来。你要从这一段或那一段中挑选句子出来，然后整理出前后顺序的主旨，以及其组成的论述。</strong></p><p>等你找到主要的句子时，架构一些段落就变得很容易了。有很多方法可试。你可以用一张纸，写下构成一个论述的所有主旨。通常更好的方法是，就像我们已经建议过的，在书的空白处作上编号，再加上其他记号，把一些应该排序而读的句子标示出来。</p><p><strong>在阅读的过程中你能让大脑不断地活动，能跟作者达成共识，找到他的主旨，那么你就能看出他的论述是什么了</strong>。而这也就是人类头脑的自然本能。</p><p><strong>进一步应用这个阅读规则：</strong></p><p><strong>首先</strong>，要记住<strong>所有的论述都包含了一些声明</strong>。其中有些是你为什么该接受作者这个论述的理由。如果你先找到结论，就去看看理由是什么。如果你先看到理由，就找找看这些理由带引你到什么样的结论上。</p><p><strong>其次</strong>，要<strong>区别出两种论述的不同之处</strong>。 一种是以一个或多个特殊的事实证明某种共通的概念，另一种是以连串的通则来证明更进一步的共通概念。前者是归纳法，后者是演绎法。但是这些名词并不重要。重点作如何区分二者的能力。</p><p><strong>第三</strong>，找出作者认为哪些事情是<strong>假设</strong>，哪些是能<strong>证实</strong>的或有根据的，以及哪些是不需要证实的<strong>自明之理</strong>。</p><p>换句话说，每个论述都要有开端。基本上。有两种开始的方法或地方：一种是<strong>作者与读者都同意的假设</strong>，－种是<strong>不论作者或读者都无法否认的自明之理</strong>。在第一种状况中，<strong>只要彼此认同，这个假设可以是任何东西</strong>。第二个情况就需要<strong>多一点的说明了</strong>。</p><h4 id="9-6-找出解答（规则八：找出作者的解答）">9.6 找出解答（规则八：找出作者的解答）</h4><p>在你想发现一本书到底在谈些什么的最后一个步骤是：<strong>找出作者在书中想要解决的主要问题</strong>（如果你回想下，这在第四个规则中已经谈过了）。现在，你已经跟作者有了共识，抓到他的主旨与论述了，你就该检视一下你收集到的是什么资料，并提出一些更进一步的问题来。作者想要解决的问题哪些解决了？为了解决问题，他是否又提出了新问题？无论是新问题或旧问题，哪些是他知道自己还没有解决的？</p><p>诠释作品的阅读技巧的最后一部分就是：<br><strong>规则八，找出作者的解答。</strong></p><p>你在应用这个规则及其他三个规则来诠释作品时，你可以很清楚地感觉到自己已经开始在了解这本书了。如果你开始读一本超越你能力的书——也就是能教导你的书——你就有一段长路要走了。更重要的是，你现在已经能用分析阅读读完一本书了。这第三个，也是最后一个阶段的工作很容易。你的心灵及眼睛都已经打开来了，而你的嘴闭上了。做到这一点时，你已经在伴随作者而行了。从现在开始，你可以有机会与作者辩论，表达你自己的想法。</p><h4 id="9-7-分析阅读的第二个阶段">9.7 分析阅读的第二个阶段</h4><p>分析阅读的第二个阶段，或找出一本书到底在说什么的规则（诠释一本书的内容）：<br>(5)   <strong>诠释作者使用的关键字，与作者达成共识。</strong><br>(6)   <strong>从最重要的句子中抓出作者的重要主旨。</strong><br>(7)   <strong>找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。</strong><br>(8)   <strong>确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，确定哪些是作者认为自已无法解决的问题。</strong></p><h3 id="第十章-公正地评断一本书">第十章 公正地评断一本书</h3><p>读者需要还作者一个深思熟虑的评断。</p><p>一本好书值得主动地阅读。主动的阅读不会为了已经了解一本书在说些什么而停顿下来，必须能评论，提出批评，才算真正完成了这件事。没有自我期许的读者没法达到这个要求，也不可能作到分析或诠释一本书。</p><h4 id="10-1-受教是一种美德">10.1 受教是一种美德</h4><p>受教的美德——这是一种长久以来一直受到误解的美德。受教通常与卑躬屈膝混为一谈。一个人如果被动又顺从，可能就会被误解为他是受教的人。相反的，受教或是能学习是一种极为主动的美德。一个人如果不能自动自发地运用独立的判断力，他根本就不可能学习到任何东西。<strong>或许他可以受训练，却不能受教</strong>。因此，<strong>最能学习的读者，也就是最能批评的读者</strong>。这样的读者在最后终于能对一本书提出回应，对于作者所讨论的问题，会努力整理出自己的想法。</p><p>光是努力，并不足以称得上受教。<strong>读者必须懂得如何评断一本书，就像他必须懂得如何才能了解一本书的内容</strong>。 这第三组的阅读规则，也就是引导读者在最后一个阶段训练自己受教的能力。</p><h4 id="10-2-修辞的作用">10.2 修辞的作用</h4><p>我们经常发现教学与受教之间的关系是互惠的，而一个作者能深思熟虑地写作的技巧，和一个读者能深思熟虑地掌握这本书的技巧之间，也有同样的互惠关系。</p><p>最后阶段的一些规则，则超越理解的范畴，要作出评论。于是，这就涉及修辞。</p><p>如果我们在说话，我们不只希望别人了解我们，也希望别人能同意我们的话。 如果我们沟通的目的是很认真的，我们就希望能说服或劝导对方——更精确地说，说服对方接受我们的理论，劝导对方最终受到我们的行为与感觉的影响。在作这样的沟通时，接受的一方如果也想同样认真，那就不但要有回应，还要做一个负责的倾听者。你对自己所听到的要有回应，还要注意到对方背后的意图。同时，你还要能有自己的主见。当你有自己的主见时，那就是你的主张，不是作者的主张了。如果你不靠自己，只想依赖别人为你作判断，那你就是在做奴隶，不是自由的人了。思想教育之受推崇．正因如此。</p><p>站在叙述者或作者的角度来看，<strong>修辞就是要知道如何去说服对方</strong>。因为这也是最终的目标，所有其他的沟通行为也必须做到这个程度才行。相对的，在读者或听者的立场，修辞的技巧是知道当别人想要说服我们时，我们该如何反应。同样的，文法及逻辑的技巧能让我们了解对方在说什么．并准备作出评论。</p><h4 id="10-3-暂缓评论的重要性（规则九：暂缓评论）">10.3 暂缓评论的重要性（规则九：暂缓评论）</h4><p>除非你听清楚了，也确定自己了解了，否则就不要回话。除非你真的很满意自已完成的前两个阅读阶段，否则不会感觉到可以很自由地表达自己的想法。只有<strong>当你做到这些事时，你才有批评的权力，也有责任这么做。</strong></p><p><strong>第九个规则：</strong></p><p>在你说出“我同意"，"我不同意”，或“我暂缓评论”之前，你一定要能肯定地说：“我了解了。”上述三种意见代表了所有的评论立场。我们希望你不要弄错了．以为所谓评论就是要不同意对方的说法。这是非常普遍的误解。同意对方说法，与不同意对方说法都一样要花心力来作判断的。同意或不同意都有可能对，也都有可能不对。毫无理解便同意只是愚蠢，还不清楚便不同意也是无礼。</p><p><strong>暂缓评论也是评论的一种方式。那是一种有些东西还未表达的立场。你在说的是．无论如何．你还没有被说服。</strong></p><p>你可能会怀疑，这些不过是普通常识，为什么要大费周章地说明？<strong>有两个理由。</strong><br><strong>第一点，<strong>前面已经说过，<strong>许多人会将评论与不同意混为一谈</strong>（就算是“建设性”的批评也是不同意）。<br>其</strong>次，<strong>虽然这些规则看起来很有理，<strong>在我们的经验中却发现很少有人能真正运用</strong>。这就是古人说的</strong>光说不练的道理</strong>。</p><p>当然，说出“我不懂”也是个很重要的评断，但这只能在你尽过最大努力之后，因为书而不是你自己的理由才能说这样的话。如果你已经尽力，却仍然无法理解，可能是这本书真的不能理解。对一本书，尤其是一本好书来说，这样的假设是有利的。在阅读一本好书时，无法理解这本书通常是读者的错。</p><h4 id="10-4-避免争强好辩的重要性（规则十：避免争强好辩）">10.4 避免争强好辩的重要性（规则十：避免争强好辩）</h4><p>评论式阅读的第二个规则的道理，与第一个一样清楚，但需要更详尽的说明与解释。</p><p><strong>规则十：</strong></p><p>**当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论。**如果你知道或怀疑自己是错的，就没有必要去赢得那场争辩。事实上，你赢得争辩可能真的会在世上名噪一时，但长程来说，诚实才是更好的策略。</p><p>在与作者——活着或死了的老师——对话中，真正的好处是他能从中学到什么；如果他知道所谓的赢只在于增进知识，而不是将对方打败，他就会明自争强好辩是毫无益处的。我们并不是说读者不可以极端反对或专门挑作者的毛病，我们要说的只是：就像他反对一样，他也要有同意的心理准备。不论要同意还是反对，他该顾虑的都只有一点——事实，关于这件事的真理是什么。</p><p>这里要求的不只是诚实。读者看到什么应该承认是不必说的。当必须同意作者的观点，而不是反对的，也不要有难过的感觉。如果有这样的感觉，他就是个积习己深的好辩者。就这第二个规则而言，这样的读者是情绪化的，而不是理性的。</p><h4 id="10-5-化解争议（规则十一：化解争议）">10.5 化解争议（规则十一：化解争议）</h4><p>大部分争论形式——只要排除误解，增加知识就能解决这些争论。</p><p>一个人在与别人对话时，就算有不同的意见，最后还是有希望达成共识。他应该准备好改变自己的想法，才能改变别人的想法。他永远要先想到自己可能误解了，或是在某一个问题上有盲点。在争论之中，一个人绝不能忘了这是教导别人，也是自己受教的一个机会。</p><p><strong>第三个规则要如何应用在读者与作者的对话中呢？这个规则要怎样转述成阅读的规则呢？</strong><br>当读者发现自己与书中某些观点不合时，就要运用到这个规则了。这个规则要求他先确定这个不同的意见不是出于误解。再假设这个读者非常注意，除非自己真的了解，而且确实毫无疑问，否则不会轻易提出评断的规则，那么，接下来呢？</p><p>接下来，这个规则要求他就真正的知识与个人的意见作出区别。还要相信就知识而言，这个争议的议题是可以解决的。如果他继续进一步追究这个问题，作者的观点就会指引他，改变他的想法。如果这样的状况没有发生，就表示他的论点可能是正确的，至少在象征意义上，他也有能力指导作者。至少他可以希望如果作者还活着，还能出席的话，作者也可能改变想法。</p><p>如果一个作者的主旨没有理论基础，就可以看作是作者个人的意见。一个读者如果不能区别出知识的理论说明与个人观点的阐述，那他就无法从阅读中学到东西。他感兴趣的顶多只是作者个人，把这本书当作是个人传记来读而已。当然，这样的读者无所谓同意或不同意，他不是在评断这本书，而是作者本身。</p><p>如果读者基本的兴趣是书籍本身，而不是作者本身，对于自己有责任评论这件事就要认真地对待。在这一点上，读者要就真正的知识与他个人观点以及作者个人观点之不同之处，作出区分。因此，除了表达赞成或反对的意见之外，读者还要作更多的努力。他必须为自己的观点找出理由来。当然，如果他赞同作者的观点、就是他与作者分享同样的理论。但是如果他不赞同，他一定要有这么做的理论基础。否则他就只是把知识当作个人观点来看待了。</p><p><strong>规则十一：</strong></p><p><strong>尊重知识与个人观点的不同，在作任何评断之前，都要找出理论基础。</strong></p><h4 id="10-6-总结">10.6 总结</h4><p>这三个规则在一起所说明的是批评式阅读的条件，而在这样的阅读中，读者应该能够与作者“辩论”。</p><p><strong>第一：<strong>要求</strong>读者先完整地了解一本书，不要急着开始批评。</strong><br><strong>第二：<strong>恳请</strong>读者不要争强好辩或盲目反对。</strong><br><strong>第三：</strong> <strong>将知识上的不同意见看作是大体上可以解决的问题。</strong></p><p>这个规则再进一步的话，就是要求读者要为自己不同的意见找到理论基础，这样这个议题才不只是被说出来，而且会解释清楚。只有这祥，才有希望解决这个问题。</p><h3 id="第十一章-赞同或反对作者">第十一章 赞同或反对作者</h3><p>当读者不只是盲目地跟从作者的论点，还能和作者的论点针锋相对时，他最后才能提出同意或反对的有意义的评论。</p><p>同意或反对所代表的意义值得我们进一步讨论。一位读者与作者达成共识后，掌握住他的主旨与论述，便是与作者心意相通了。事实上，<strong>诠释一本书的过程是透过言语的媒介，达到心及上的沟通。读懂一本书可以解释为作者与读者之间的一种认同。</strong> 他们同慈用这样的说法来说明一种想法。因为这样的认同，读者便能透过作者所用的语言，看出他想要表达的想法。</p><p><strong>当你透过对一本书的诠释理解，与作者达成了共识之后，才可以决定同意他的论点，或是不同意他的立场。</strong></p><h4 id="11-1-偏见与公正">11.1 偏见与公正</h4><p><strong>第一点，<strong>因为</strong>人有理性的一面，又有动物的一面，所以在争辩时就要注意你会带进去的情绪，或是在当场引发的脾气。否则你的争论会流于情绪化，而不是在说理了</strong>。当你的情绪很强烈时，你可能会认为自已很有道理。</p><p>**第二点，<strong>你</strong>要把自己的前提或假设摊出来。<strong>你要知道你的偏见是什么——这也是</strong>你的预先评断。**否则你就不容易接受对手也有不同假设的权利。<strong>一场好的辩论是不会为假设而争吵的。</strong></p><p>**第三点，**也是最后一点，派别之争几乎难以避免地会造成一些盲点，要化解这些盲点，<strong>应尽力尝试不偏不倚。<strong>当然，争论而不想有派别之分是不可能的事。但是</strong>在争论时应该多一点理性的光，少一点激情的热，每个参与辩论的人至少都该从对方的立场来看想</strong>。如果你不能用同理心来阅读一本书，你的反对意见会更像是争吵，而不是文明的意见交流。</p><p>理想上，这三种心态是明智与有益的对话中必要的条件。这三种要件显然也适用在阅读上——那种作者与读者之间的对话上。对一个愿意采取理性争论方式的读者来说，每个建议对他都是金玉良言。</p><p>我们仍然相信，作者与读者的对话及批评式的阅读，是可以相当有纪律的。因此，我们要介绍一套比较容易遵守，可以取代这三种规则的替代方法。这套方法指出四种站在对立角度来评论一本书之道。我们希望即使读者想要提出这四种评论时，也不会陷入情绪化或偏见的状态中。</p><p><strong>以下是这四点的摘要说明</strong><br>(1)  你的<strong>知识不足</strong>(uninformed)。<br>(2)  你的<strong>知识有错误</strong>(misinformed)。<br>(3)  你<strong>不合逻辑</strong>——你的推论无<strong>法令人信服</strong>。<br>(4)  你的<strong>分析不够完</strong>整。</p><p>无论如何，这确实是一位读者在不同意时．基本上可以作出的重点声明。这四个声明多少有点独立性。只用其中一点，不会妨害到其他重点的运用。每个重点或全部的重点都可以用上，因为这些重点是不会互相排斥的。</p><p>读者不能任意使用这些评论，除非他确定能证明这位作者是知识不足、知识有误或不合逻辑。一本书不可能所有的内容都是知识不足或知识有误。一本书也不可能全部都不合逻辑。而要作这样评论的读者，除了要能精确地指认作者的问题之外，还要能进一步证明自己的论点才行。他要为自己所说的话提出理由来。</p><h4 id="11-2-判断作者的论点是否正确">11.2 判断作者的论点是否正确</h4><p>(1)  **说一位作者知识不足，就是在说他缺少某些与他想要解决的问题相关的知识。**在这里要注意的是，除非这些知识确实相关，否则就没有理由作这样的评论。<strong>要支持你的论点，你就要能阐述出作者所缺乏的知识，并告诉他这些知识如何与这个问题有关，如果他拥有这些知识会如何让他下一个不同的结论。</strong></p><p>(2)  **说一位作者的知识错误，就是说他的理念不正确。**这样的错误可能来自缺乏知识，但也可能远不只于此。不论是哪一种，他的论点就是与事实相反。作者所说的事实或可能的事实，其实都是错的，而且是不可能的。这样的作者是在主张他自己其实并没有拥有的知识，当然，<strong>除非这样的缺点影响到作者的结论，否则并没必要指出来</strong>。<strong>要作这个评论，你必须要能说明事实，或是能采取比作者更有可能性的相反立场来支持你的论点</strong>。</p><p>前两点的批评是互相有关联的。**知识不足，就可能造成我们所说的知识错误。**此外，任何人的某种知识错误，也就是在那方面知识不足。不过，这两种不足在消极与积极面上的影响，还是有差别的。缺乏相关的知识，就不太可能解决某个特定的问题，或支持某一种结论。错误的知识却会引导出错误的结论，与站不住脚的解答。这两个评论合在一起，<strong>指出的是作者的前提有缺陷。<strong>他</strong>需要充实知识。他的证据与论点无论在质与量上都还不够好。</strong></p><p>(3)  **说一位作者是不合逻辑的，就是说他的推论荒谬。**一般来说，荒谬有两种形态。**一种是缺乏连贯，也就是结论冒出来了，却跟前面所说的理论连不起来。另一种是事件变化的前后不一致，也就是作者所说的两件事是前后矛盾的。**要批评这两种问题，读者一定要能例举精确的证据，而那是作者的论点中所欠缺的使人信服的力量。只要当主要的结论受到这些荒谬推论的影响时，这个缺点才要特别地提出来。一本书中比较无关的部分如果缺乏信服力，也还说得过去。</p><p>第三个批评点与前两个是互相关联的。当然，有时候作者可能没法照他自己所提的证据或原则得出结论。这样他的推论就不够完整。但是这里我们主要关心的还是一个作者的理论根据很好，导出来的结论却很差的情况。发现作者的论点没有说服人的力量，是因为前提不正确或证据不足，虽然很有趣，但却一点也不重要。</p><p>如果一个人设定了很完整的前提，结论却问题百出，那从某个角度而言，就是他的知识有错误。不过，到底这些错误的论述来自推论有毛病的问题，还是因为一些其他的缺点，特别像是相关知识不足等等，这两者之间的差异倒是值得我们细细推敲的。</p><h4 id="11-3-判断作者论述的完整性">11.3 判断作者论述的完整性</h4><p><strong>前面三个批评点，是与作者的声明与论述有关的。</strong></p><p>第四个批评点。这是在讨论<strong>作者是否实际完成了他的计划——也就是对于他的工作能否交待的满意度</strong>。</p><p>在开始之前，我们必须先澄清一件事。如果你说你读懂了，而你却找不出证据来支持前面任何一个批评点的话，这时你就有义务要同意作者的任何论点。这时你完全没有自主权。你没有什么神圣的权利可以决定同意或不同意。</p><p>如果你不能用相关证据显示作者是知识不足、知识有误，或不合逻辑，你就不能反对他。</p><p>**前面三个批评点与作者的共识、主旨与论述有关。**这些是作者开始写作时要用来解决问题的要素。第四点——这本书是否完整了——与整本书的架构有关。</p><p>(4)  说一位作者的分析是不完整的，就是说他并没有解决他一开始提出来的所有问题，或是他并没有尽可能善用他手边的资料，或是他并没有看出其间的含意与纵横交错的关系，或是他没法让自己的想法与众不同。但这还不够去说一本书是不完整的。任何人都可以这样评论一本书。人是有限的，他们所做的任何工作也都是有限的，不完整的。因此，作这样的评论是毫无意义的。<strong>除非读者能精确地指出书中的问题点——不论是来自他自己的努力求知，或是靠其他的书帮忙——才能作这样的批评。</strong></p><p>严格来说，第四点并不能作为不同意一个作者的根据。我们只能就作者的成就是有限的这一点而站在对立面上。然而，当读者找不出任何理由提出其他批评点而同意一本书的部分理论时，或许会因为这第四点，关于一本书是不完整的论点，而暂缓评论整本书。站在读者的立场，暂缓评论一本书就是表示作者并没有完全解决他提出的问题。</p><p>阅读同样领域的书，可以用这四种评论的标准来作比较。如果一本书能比另一本书说出较多的事实，错误也较少，就比较好一点。但如果我们想要借读书来增进知识，显然一本能对主题作最完整叙述的书是最好的。唯有比较每位作者在分析论点时的完整性，才是真正有深度的比较。比较每本书里有效而且突出的论点有多少，就可以当作评断其完整性的参考了。这时你会发现能与作者找出共同的词义是多么有用了。<strong>突出的词义越多，突出的论述也就越多。</strong></p><p>在拟大纲的最后阶段，就是要知道作者想要解决的问题是什么。诠释一本书的最后阶段，就是要知道作者解决了哪些问题，还有哪些问题尚未解决。批评一本书的最后阶段，就是要检视作者论述的完整性。这跟全书大纲，作者是否把问题说明清楚，也跟诠释一本书，衡量他多么完满地解决了问题都有关。</p><h4 id="11-4-分析阅读的三阶段">11.4 分析阅读的三阶段</h4><p><strong>所有的规则按适当的次序，用合宜的标题写出来：</strong></p><p>一、<strong>分析阅读的第一阶段：找出一本书在谈些什么的规则</strong><br>(1)依照书的<strong>种类与主题</strong>来<strong>分类</strong>。<br>(2)使用<strong>最简短的文字说明整本书在谈些什么</strong>。<br>(3) 将<strong>主要部分按顺序与关联性列举出来</strong>。<strong>将全书的大纲列举出来</strong>，井<strong>将各个部分的大纲也列出来</strong>。<br>(4) 确定作者<strong>想要解决的问题</strong>。</p><p>二、<strong>分析阅读的第二阶段：诠释一本书的内容规则</strong><br>(5)诠释作者的<strong>关键字</strong>，与他<strong>达成共识</strong>。<br>(6)由<strong>最重要的句子</strong>中，<strong>抓住作者的</strong>重要主旨。<br>(7)知道作者的<strong>论述是什么</strong>，从内容中<strong>找出相关的句子</strong>，再<strong>重新架构</strong>出来。<br>(8)确定作者已经<strong>解决了哪些问题</strong>，<strong>还有哪些是没解决的</strong>。再<strong>判断哪些是作者知道他没解决的问题</strong>。</p><p>三、<strong>分析阅读的第三阶段：像是沟通知识一样地评论一本书的规则</strong><br>A.   <strong>智慧礼节的一般规则</strong><br>(9)    除非你已经完成大纲架构，也能诠释整本书了，否则<strong>不要轻易批评</strong>。（在你说出：“我读懂了！”之前，不要说你同意、不同意或暂缓评论。）<br>(10)<strong>不要争强好胜</strong>，非辩到底不可。<br>(11)在<strong>说出评论之前</strong>，你要<strong>能证明自己区别得出真正的知识与个人观点的不同</strong>。</p><p>B.   <strong>批评观点的特别标准</strong><br>(12)证明作者的<strong>知识不足</strong>。<br>(13)证明作者的<strong>知识错误</strong>。<br>(14)证明作者<strong>不合逻辑</strong>。<br>(15)证明作者的<strong>分析与理由是不完整的</strong>。</p><p>**注意：**关于最后这四点，前三点是表示不同意见的准则，如果你无法提出相关的佐证，就必须同意作者的说法，或至少一部分说法。你只能因为最后一点理由，对这本书暂缓评论。</p><p>如果你是为了追求知识而阅读，除非你能判断作者所提出的事实的意义，或者应该具备的意义，否则称不上有头脑的阅读。作者所提出的事实，很少没经过有意无意的诠释。尤其如果你读的是文摘类的作品，那都是根据某种意义，或某种诠释原则而过滤过的事实。如果你阅读的是启发性的作品，这个问题更是没有终了的时刻。在学习的任何一个阶段，你都要回顾一下这个问题：<strong>“这究竟有没有意义？”</strong></p><p>我们已经提过的这四个问题，总结了身为读者应尽的义务。前三个，与人类语言的沟通天性有关。如果沟通并不复杂，就用不着做出大纲来。如果语言是完美的沟通媒介，而不是有点不透明，就用不着诠释彼此的想法了。如果错误与无知不会局限真实或知识，我们也根本用 不着批评了。第四个问题区别了讯息(information)与理解(under­standing)之间的差异。如果你阅读的读物是以传递讯息为主，你就要自己更进一步，找出其中的启发性来。即使你被自己阅读的东西所启发了，你也还要继续往前探索其中的意义。</p><p>分析阅读的规则是一个理想化的阅读。这些规则只是衡量阅读层次的理想标准。你是个好读者，也就能达到你应该达到的阅读层次。</p><h4 id="11-5-小结">11.5 小结</h4><p>当我们说某人读书“读得很好"(Well-read)时，我们心中应该要有这些标准来作衡量的依据。太多时候，我们是用这样的句子来形容一个人阅读的量，而非阅读的质。<strong>一个读得很广泛，却读不精的人，与其值得赞美，不如值得同情。</strong></p><p>伟大的作者经常也是伟大的读者，但这并不是说他们阅读所有的书。他们精通自己所阅读的书，他们的程度就可以跟作者相匹敌。他们有权被称作权威人士。在这种状况下，很自然地，一个好学生通常会变成老师，而一位好的读者也会变成作者。</p><p>运用本书所提供的规则，<strong>仔细地阅读一本书</strong>，而不是浮面地阅读大量的书，就是一个好读者能达到的理想境界了。当然，许多书都值得精读。但有<strong>更多的书只要浏览一下</strong>就行了。<strong>要成为一个好读者，就要懂得依照一本书的特质，运用不同的阅读技巧来阅读。</strong></p><h3 id="第十二章-辅助阅读">第十二章 辅助阅读</h3><p>除了书籍本身之外，任何辅助阅读我们都可以称作是外在的阅读。所谓“内在阅读"(intrinsic reading)，意思是指阅读书籍的本身，与所有其他的书都是不相关的。而“外在阅读"(extrinsic reading)指的是我们借助其他一些书籍来阅读一本书。</p><p>一直将焦点集中在身为读者的基本工作上——<strong>拿起一本书来研究，运用自己的头脑来努力，不用其他的帮助</strong>。但是如果一直这样做下去，可能就错了。外在阅读可以帮上这个忙。有时候还非要借助外在阅读，才能完全理解一本书呢！</p><p>在理解与批评一本书的过程中，内在与外在的阅读通常会混在一起。在诠释、批评与做大纲时，我们都难免受到过去经验的影响。在阅读这本书之前，我们一定也读过其他的书。没有人是从分析阅读开始阅读第一本书的。我们可能不会充分对照其他书籍或自己生活里的经验，但是我们免不了会把某一位作者对某件事的声明与结论，拿来跟我们所知的，许多不同来源的经验作比较。这也就是俗话说的，我们不应该，也不可能完全孤立地阅读一本书。</p><p>整体来说，在你找寻外力帮助之前，最好能自己一个人阅读。如果你经常这么做，最后你会发现越来越不需要外界的助力了。</p><p>外在的辅助来源可以分成四个部分。<br><strong>第一，相关经验。</strong><br><strong>第二，其他的书。</strong><br><strong>第三，导论与摘要。</strong><br><strong>第四，工具书。</strong></p><p>根据一般的阅读常识来说，<strong>你依照内在阅读的规则尽力将一本书读完之后，却还是有一部分不懂或全部都不懂时，就应该要找外在的帮助了。</strong></p><h4 id="12-1-相关经验的角色">12.1 相关经验的角色</h4><p><strong>特殊经验</strong>则需要<strong>主动地寻找</strong>，只有当一个人碰到困难时才会用得上。特殊经验的最佳例子就是在实验室中进行的实验，但也不一定需要有实验室。</p><p><strong>一般经验</strong>并不一定要每个人都有才叫一般。一般(Common)与全体(Universal)是有点差别的。</p><p>这两种经验主要是跟不同的书籍有关。</p><p>一般经验在一方面与阅读小说有关，另一方面与阅读哲学书籍有关。判断一本小说的写实性，完全要依赖一样，我们从自己的生活体验来看这本书是真实或不够真实。</p><p>特殊经验主要是与阅读科学性作品有关。要理解与判断一本科学作品所归纳的论点，你就必须了解科学家所作的实验报告与证明。有时候科学家在形容一个实验时栩栩如生，你读起来一点困难也没有。有时说明图表会帮助你了解这些像是奇迹般的描述。</p><p>阅读历史作品，同时与一般经验及特殊经验都有关。这是因为历史掺杂着虚构与科学的部分。</p><p>要怎样才能知道你是否适当地运用自己的经验，来帮助你读懂一本书呢？问问你自己：在你觉得自己了解了的某一点上，能不能举出一个实例来？<strong>在你不太确定自己有没有掌握一本书时，不妨这样测验一下你自己。</strong></p><h4 id="12-2-其他的书可以当作阅读时的外在助力">12.2 其他的书可以当作阅读时的外在助力</h4><p>我们的建议尤其适用于所谓巨著。一般人总是抱着热忱想要阅读巨著，但是当他绝望地感觉到自已无法理解这本书时，热忱很快便消退了。其中一个原因，当然是因为一般人根本不知道要如何好好地阅读一本书。但还不只如此，还有另一个原因：他们认为自己应该能够读懂自己所挑选的第一本书，用不着再读其他相关的著作。</p><p>许多伟大的作品不只是互相有关联，而且在写作时还有特定的先后顺序，这都是不该忽略的事。后人的作品总是受到前人的影响。如果你先读前一位的作品，他可能会帮助你了解后人的作品。 <strong>阅读彼此相关的书籍，依照写作的时间顺序来读，对你了解最后写的作品有很大帮助。这就是外在辅助阅读的基本常识与规则。</strong></p><p>**外在辅助阅读的主要功用在于延伸与一本书相关的内容脉络。**我们说过文章的脉络有助于诠释字义与句子，找出共识与主旨。就像一整本书的脉络是由各个部分贯穿起来一样，相关的书籍也能提供一个大型的网路脉络，以帮助你诠释你正在阅读的书。</p><p>我们经常会发现，一本伟大的著作总会有很长的对话部分。伟大的作者也是伟大的读者，想要了解他们，不妨读一读他们在读的书。身为读者，他们也是在与作者对话，就像我们在跟我们所阅读的书进行对话一样。只不过我们可能没写过其他的书。</p><p>想要加入这样的谈话，我们一定要读与巨著相关的著作，而且要依照写作前后的年表来阅读。有关这些书的对话是有时间顺序的。时间顺序是最基本的，千万不要忽略了。阅读的顺序可以是从现代到过去，也可以从过去到现代。虽然从过去读到现代的作品因为顺其自然而有一定的好处，不过年代的角度也可以倒过来观察。</p><p>顺便提醒一下，比起科学与小说类的书，阅读历史与哲学的书时，比较需要阅读相关的书籍。尤其是阅读哲学书时更重要，因为哲学家互相都是彼此了不起的读者。在小说与戏剧中，这就比较不重要了。如果真是好作品，可以单独阅读。当然一些文评家并不想限制自己这么做。</p><h4 id="12-3-如何运用导读与摘要">12.3 如何运用导读与摘要</h4><p>第三种外在的<strong>辅助阅读包括导读(commentary)与摘要(ab­stract)</strong>。这里要强调的是，<strong>在运用这些资料时要特别聪明，也就是要尽量少用</strong>。这么说有两个理由。</p><p><strong>第一，</strong> <strong>一本书的导读并不一定都是对的</strong>。当然这些导读的用处很大，但却并不像我们希望的那样经常有用。</p><p><strong>第二，</strong> <strong>就算他们写对了，可能也不完整</strong>。因此，你可能在书中发现一些重点，而那些导读者却没有发现到。阅读这类导读，尤其是自以为是的导读，会限制你对一本书的理解，就算你的理解是对的。</p><p><strong>一些关于如何使用导读的建议</strong></p><p>事实上，这已经很相当于<strong>外在阅读的基本规则</strong>。内在阅读的规则是在阅读一本书之前，你要先看作者的序与前言。相反地，外在的阅读规则是除非你看完了一本书，否则不要看某个人的导读。这个规则尤其适用于一些学者或评论家的导言。要正确地运用这些导读，必须<strong>先尽力读完一本书</strong>，然后还有些问题在干扰着你时，你才<strong>运用这些导读来解答问题</strong>。<strong>如果你先读了这些导读，可能会让你对这本书产生曲解。你会只想看那些学者或批评家提出的重点，而无法看到可能同样重要的其他论点。</strong></p><p>如果是用这样的方法阅读，附带读一些这类的导读书籍是很有趣的事。你已经读过全书，也都了解了。而那位导读者也读过这本书，甚至可能读了好几次，他对这本书有自己的理解。你接近他的作品时，基本上是与他站在同一个水平上的。然而如果你在阅读全书之前，先看了他的导读手册，你就隶属于他了。</p><p>**要特别注意的是，**你必须读完全书之后，才能看这类诠释或导读手册，而不是在之前看。如果你已经看过全书，知道这些导读如果有错，是错在哪里，那么这样的导读就不会对你造成伤害。但是如果你完全依赖这样的书，根本没读过原书，你的麻烦就大了。</p><p>**还有一个重点，**如果你养成了依赖导读的习惯，当你找不到这类书时，你会完全不知所措。你可能可以借着导读来了解某一本作品，但一般而言，你不会是个好读者。</p><p>这里所说的外在阅读的规则也适用于摘录或情节摘要之类的作品。他们有两种相关的用途，也只有这两种。</p><p><strong>第一，<strong>如果你</strong>已经读过一本书，这些摘要能唤醒你的记忆</strong>。理想上，<strong>在分析阅读时，你就该自己作这样的摘要</strong>。</p><p>**第二，**在主题阅读时，**摘要的用处很大，**你可以因此知道某些特定的议题是与你的主题密切相关的。<strong>摘要绝不能代替真正的阅读，但有时却能告诉你，你想不想或需不需要读这本书。</strong></p><h4 id="12-4-如何运用工具书">12.4 如何运用工具书</h4><p>工具书的类型有许多种。下面是我们认为最主要的两种：<strong>字典与百科全书</strong>。 无论如何，对于其他类型的工具书，我们也还是有很多话要说的。</p><p>虽然这是事实，但可能很多人不了解，那就是在你能运用工具书之前，你自己已经具备了很多知识：尤其是你必须有四种基本的知识。因此，工具书对矫正无知的功能是有限的。那并不能帮助文盲，也不能代替你思考。</p><p>**要善用工具书，**首先你必须有一些想法，不管是多模糊的想法，那就是你想要知道些什么？你的无知就像是被光圈围绕着的黑暗。你一定要能将光线带进黑暗之中才行。而除非光圈围绕着黑暗，否则你是无法这么做的。换句话说，你一定要能对工具书问一个明智的问题。否则如果你只是彷惶迷失在无知的黑幕中，工具书也帮不上你的忙。</p><p>**其次，**你一定要知道在哪里找到你要找的答案。你要知道自己问的是哪一类的问题，而哪一类的工具书是回答这类问题的。没有一本工具书能回答所有的问题，无论过去或现在，所有的工具书都是针对特定问题而来的。尤其是，事实上，<strong>在你能有效运用工具书之前，你必须要对主要类型的工具书有一个全盘的了解。</strong></p><p>在工具书对你发挥功用之前，你还必须有第三种知识。你必须要知道这本书是怎么组织的。在阅读工具书时也一样，要看完编辑说明如何使用这本书之后，才开始阅读内容。</p><p>当然，<strong>工具书并不能回</strong>答所有的问题。</p><p><strong>要明智地运用工具书的第四个条件就是：</strong><br>**你必须知道你想要找的是什么，在哪一种工具书中能找到这样的东西。**你也要知道如何在工具书中找到你要的资料，还要能确定该书的编者或作者知道哪个答案。在你使用工具书之前，这些都是你应该清楚知道的事。对一无所知的人来说，工具书可说是毫无用处。工具书并不是茫然无知的指南。</p><h4 id="12-5-如何使用字典">12.5 如何使用字典</h4><p>字典是一种工具书，以上所说的工具书问题在使用时都要考虑进去。</p><p>不论<strong>字典</strong>是如何编辑的，<strong>主要目的还是教育的工具</strong>。</p><p><strong>阅读任何一本书的第一个规则是</strong>：<strong>知道这是一本什么样的书。</strong></p><p><strong>从四个方面来看待文字：</strong></p><p>(1)  <strong>文字是物质的——可以写成字，也可以说出声音</strong>。因此，在拼字与发音上必须统一，虽然这种统一常被特例变化所破坏，但并不像你某些老师所说的那样重要。</p><p>(2)  <strong>文字是语言的一部分</strong>。在一个较复杂的句子或段落的结构中，文字扮演了文法上的角色。同一个字可以有多种不同的用法，随着不同的谈话内容而转变意义，特别是在语音变化不明显的英文中更是如此。</p><p>(3)  <strong>文字是符号——这些符号是有意义的，不只一种意义，而是很多种意义</strong>。这些意义在许多方面是互相关联的。 有时候会细微地变化成另一种意义，有时候一个字会有一两组完全不相干的意义。 因为意义上的相通，不同的字也可能互相连接起来——就像同义字，不同的字却有同样的意义。或是反义字，不同的字之间有相反或对比的意义。</p><p>(4)  <strong>文字是约定俗成的——这是人类创造的符号</strong>。 这也是为什么每个字都有历史．都有历经变化的文化背景。从文字的字根、字首、字尾，到词句的来源，我们可以看出文字的历史。</p><p>字典是一种完美的自修工具书，因为它告诉你要注意什么，如何诠释不同的缩写字，以及上面所说的四种有关文字符号的知识。任何人不善读一本字典开头时所作的解释以及所列的缩写符号，那用不好字典就只能怪他自己了。</p><h4 id="12-6-如何使用百科全书">12.6 如何使用百科全书</h4><p>百科全书和一般光提供讯息的书不同，它所能提供的理解取决于你对这些相关事实之间的关系的了解。</p><p>使用百科全书，读者必须要依赖编者的帮忙与建议。任何一本好的百科全书都有引言，指导读者如何有效地运用这本书，你一定要照着这些指示阅读。通常，这些引言都会要使用者在翻开字母排列的内容之前，先查证一下索引。</p><p>字典是关于文字的，而百科全书是关于事实的。</p><p>(1)  <strong>事实是一种说法(proposition)——说明一个事实时，会用一组文字来表达</strong>。为了全盘地了解知识，你必须知道事实的意义——这个意义又如何影响到你在找寻的真理。如果你知道的只是事实本身，表示你了解的并不多。</p><p>(2)  <strong>事实是一种“真实”的说法(“True” proposition)——事实不是观点</strong>。当有人说：”事实上……”的时候，表示他在说的是一般人同意的事。由于百科全书必须只报导事实，不掺杂观点（除了上述的方法），因而也限制了记载的范围。它不能处理一些未达成共识的主题——如果真的要处理这些问题，只能列举人们各种不同的说法。</p><p>(3)  <strong>事实是真相的反映</strong>——事实可能是</p><ol><li>一个资讯；</li><li>不受怀疑的推论。</li></ol><p>不管是哪一种，都代表着事情的真相。因此，事实如果只是对真相提出一点揣测，那就称不上是观念或概念，以及理论。同样地，对真相的解释（或部分解释），除非众所公认是正确的，否则就不能算是事实。</p><p>(4)  <strong>事实是某种程度上的约定俗成——我们说事实会改变</strong>。我们的意思是，某个时代的事实，到了另一个时代却不是事实了。但既然事实代表 ”真实” ，当然是小会变的。因为真实．严格来说是不会变的，事实也不会变。不过所有我们认为是真实的主旨．并不一定都是真实的。我们一定要承认的是，任何我们认为是真实的主旨，都可能被更有包容力或更正确的观察与调查证明是错的。与科学有关的事实更是如此。</p><p>事实——在某种程度上——也受到文化的影响。</p><p>如果你记住前面有关事实的叙述，一本好的百科全书会回答你有关事实的所有问题。将百科全书当作是辅助阅读的艺术，也就是能对事实提出适当问题的艺术。就跟字典一样，我们只是帮你提出问题来，百科全书会提供答案的。</p><p>还要记得一点，百科全书不是追求知识最理想的途径。你可能会从其中条理分明的知识中．获得启发，但就算是在最重要的问题上，百科全书的启发性也是有限的。理解需要很多相关条件，在百科全书中却找不到这样的东西。</p><h2 id="第三篇-阅读不同读物的方法">第三篇 阅读不同读物的方法</h2><h3 id="第十三章-如何阅读实用型的书">第十三章 如何阅读实用型的书</h3><p><strong>越通用的规则就越少</strong>，这算是一个好处。而<strong>越通用的规则，也越容易理解——容易学会与使用这些规则</strong>。但是，说实在的，当你置身错复杂的实际情况，想要援用一些规则的时候你也会发现越通用的规则离题越远。</p><p>我们前面谈过分析阅读的规则，一般来说是适用于论说性的作品也就是说任何一种传达知识的书。但是你不能只用一般通用的方法来读任何一本书。你可能读这本书那本书，或是任何一种特殊主题的书,可能是历史、数学、政治论文或科学研究，或是哲学及神学理论，因此，在运用以下这些规则时，你一定要有弹性，并能随时调整。幸运的是，当你开始运用这些规则时你会慢慢感觉到这些规则是如何在不同的读物上发挥作用。</p><p>要特别提醒的是，在第十一章结尾时所说明的十五个阅读规则并不适用于阅读小说或诗集。</p><p>这四个问题与任何本书都有关，不论是虚构或非虚构，不论是诗、历史、科学或哲学。</p><h4 id="13-1-两种实用性的书">13.1 两种实用性的书</h4><p>关于实用性的书有一件事要牢记在心：<strong>任何实用性的书都不能解决该书所关心的实际问题</strong>。一本理论性的作品可以解决自己提出的问题。但是<strong>实际的问题却只能靠行动来解决。</strong></p><p>你必须自已进行有活力的阅读过程，不只是读这本书，还要读很多其他的书。这也是为什么老话说：<strong>只有行动能解决问题</strong>。<strong>行动只能在现世发生，而不是在书本中发生。</strong></p><p><strong>读者一定要能加上一点自己的想法，才能运用在实际的状况中</strong>。他要能<strong>更了解实际状况</strong>，<strong>更有判断力</strong>，知道如何将规则应用在这样的状况中。</p><p>**任何书里包含了规则——原理、准则或任何一种一般的指导你都要认定是一本实用性的书。**规则底下的原理通常都很科学，换言之，属于理论性的知识。规则与原理的结合，就是事物的理论。因此，我们谈造桥的理论，也谈打桥牌的理论。我们的意思是，<strong>理论性的原则会归纳出出色的行事规则</strong>。</p><p><strong>实用性的书因此可分为两种类型：</strong></p><ol><li><strong>说明规则</strong>的实用性的书</li><li><strong>阐述形成规则</strong>的原理的实用性的书</li></ol><p>不管是在什么领域中，谈规则的书都可以立刻认出来是实用性的。一本谈实用原理的书，乍看之下会以为是理论性的书。</p><p>在阅读一本以规则为主的书时，要找寻的主旨当然是那些规则。阐述这些规则通常是用命令句，而不是叙述句。</p><p>无论是叙述句或命令句，你总是能认出一个规则来，因为它在建议你某件事是值得做的，而且一定会有收获。</p><p>**无法让一本实用的书被实用地阅读，就是失败的阅读。**如果在原理中能找到可以理解的规则，那么也就可以在由原理引导出来的规则或建议的行动中，找到实用原理的意义。</p><p>行为规则要谈得上是真理，有两种情况：</p><ol><li><strong>真的有效</strong></li><li><strong>是这样做能带引你到正确的结果，达到你的期望</strong></li></ol><p>如果你不认同仔细、头脑清楚地阅读是件值得做的事情，那么纵使本书的规则真的有效，这本书对你来说还是没什么实用性。</p><p>在评断一本理论性的书时，读者必须观察他自己与作者之间的原理与假设的一致性或差异性。<strong>在评断一本实用性的书时，所有的事都与结果及目标有关。</strong></p><h4 id="13-2-说服的角色">13.2 说服的角色</h4><p>当你在阅读任何一种实用书时，一定要问你自己两个主要的问题。<br><strong>第一、作者的目的是什么？</strong><br><strong>第二、他建议用什么方法达到这个目的？</strong></p><p>对作品最终的评断是<strong>你是否接受他的结论，与他提议的方法。</strong></p><p>实用书的特性，<strong>一个人必须要被说服，以采取特定的思想与行动</strong>。<strong>实际的思考与行动除了需要理智以外，情感也是重要的因素</strong>。没有人可以没有受到感动，却认真采取实际评论或行动的。</p><p>一个人如果真正读懂了一本实用的书，他知道这本书的基本共识、主旨、论述是什么，就能觉察出作者的雄辩。但是，一个读者如果完全不接受所有内容的诉求，那就不必阅读实用性的书了。</p><h4 id="13-3-赞同实用书之后">13.3 赞同实用书之后</h4><p>在读一本书时要提出的四个问题，到了读实用性的书时有了一点变化。</p><p><strong>第一个问题：这本书是在谈些什么？</strong><br>读任何书都得想办法找出一个<strong>作者的问题是什么</strong>（规则四涵盖这一点），不过在读实用性的书时，格外是一个决定性的关键。你一定要了解作者的目的是什么。换句话说，一定要知道他想解决的问题是什么。你一定要知道他想要做些什么——因为，在实用性的书中，知道<strong>他要做的是什么</strong>，就等于是知道<strong>他想要你做的是什么</strong>。这当然是非常重要的事了。</p><p><strong>第二个问题：回答关于这本书的意义或内容。</strong><br>你仍然要能够找出<strong>作者的共识、主旨与论述</strong>。规则八要你说出哪些是作者已经解决的问题，哪些是还没有解决的问题。你要发现并了解作者所建议的、达到他目标的方法。换句话说，在阅读实用性书时，如果规则四调整为：<strong>＂找出作者想要你做什么。”<strong>规则八就该调整为：</strong>”了解他要你这么做的目的。”</strong></p><p><strong>第三个问题：内容真实吗？</strong><br>在理论性作品中，当你根据自己的知识来比较作者对事物的描绘与说明时，这个问题的答案便出来了。如果这本书所描述的大致与你个人的体验相似时，你就必须承认那是真实的，或至少部分是真实的。实用性的书，虽然也会与真实作比较，但最主要的却是你能不能接受作者的宗旨——他最终的目标，加上他建议的达成目标的方法——这<strong>要看你认为追求的是什么，以及什么才是最好的追求方法而定。</strong></p><p><strong>第四个问题：这本书与我何干？</strong><br>(1)   <strong>同意分析阅读是值得做的。</strong><br>(2)   <strong>接受这些阅读规则，当作是达到目标的基本要件</strong>，你会像我们现在所说的一样，开始照着阅读起来。<br>如果你没有这么做，可能并不是你偷懒或太累了，而是你并不真的同意(1)或(2)。</p><p>某些作者提出的结论是很通用或一般性的——可供所有的人类使用——另外一些作者的结论却只有少数人能运用。如果结论是通用的——譬如像本书，所谈的是使所有人都能阅读得更好，而不是只有少数人——那么我们所讨论的便适用于每位读者。</p><p>心理问题会影响我们阅读实用性的作品。</p><h3 id="第十四章-如何阅读想像文学">第十四章 如何阅读想像文学</h3><p>阅读想像文学的问题比阅读论说性作品的问题更为困难。然而，比起阅读科学、哲学、政治、经济与历史，一般人却似乎更广泛地拥有阅读文学的技巧。</p><p><strong>如何阅读想像文学的建议</strong><br><strong>开始</strong>，<strong>从否定的说法谈起</strong>，而不建立一些规则。<br><strong>其次</strong>，用<strong>类推的方法</strong>，简短地<strong>将阅读非小说的规则转化为阅读小说</strong>的规则。<br><strong>最后</strong>，<strong>阅读特殊形态的想像文学时所发生的问题</strong>，像是小说、戏剧与抒情诗。</p><h4 id="14-1-读想像文学的“不要”">14.1 读想像文学的“不要”</h4><p>为了要用否定的形态来作说明，一开始就有必要掌握论说性作品与文学作品的差异。</p><p><strong>论说性作品要传达的是知识</strong>——在<strong>读者经验中曾经有过或没有过的知识</strong>。<br><strong>想像文学是在阐述一个经验本身</strong>——那是<strong>读者只能借着阅读才能拥有或分享的经验</strong>如果成功了，就<strong>带给读者一种享受</strong>。</p><p>我们都是运用判断与推论，也就是理智，才能理解事情。这并不是说我们在思考时用不上想像力，或我们的感官经验完全独立于理性的洞察与反应之外。</p><p>有关想像文学的事实，带引出我们要建议的否定的指令：<strong>不要抗拒想像文学带给你的影响力</strong>。</p><p>阅读一部<strong>伟大的文学作品</strong>的规则应该<strong>以达成某种深沉的经验为目标</strong>。这些规则应该尽可能去除我们体验这种深刻感受的阻碍。</p><p><strong>在想像文学中，不要去找共识、主旨或论述</strong>。</p><p>最后一个否定的指令：<strong>不要用适用于传递知识的，与真理一致的标准来批评小说</strong>。</p><p>这是真的吗？我们也有这样的感觉吗？ 我们是不是总是这样想，却从来没有意识到？以前或许很模糊的事，现在是不是却很明显了？作者的理论或说明虽然可能很复杂，是不是却比我们过去对这个观念的混淆来得清楚，也简单多了？</p><p>如果我们能很肯定地回答上述问题，我们与作者之间的沟通便算是建立起来了。当我们了解，也不反对作者的观点时，我们一定要说：”<strong>这确实是我们共通的观念。我们测验过你的理论，发现是正确的</strong>。”</p><h4 id="14-2-阅读想像文学的一般规则">14.2 阅读想像文学的一般规则</h4><p><strong>阅读论说性作品的三组规则</strong><br>**第一组：**找出作品的如整体及部分结构<br>**第二组：**定义与诠释书中的共识、主旨与论述<br>**第三组：**评论作者的学说，以赞同或反对的意见完成我们对他的作品的理解</p><p>称这三组规则为<strong>架构性、诠释性与评论性</strong>的。</p><p>首先，我们可以将架构性的规则——拟大纲的规则——改变为适合阅读小说的规则：<br>(1)  你必须<strong>将想像文学作品分类</strong>。抒情诗在叙述故事时，基本上是<strong>以表达个人情绪的经验为主</strong>。<br>(2)  你要能<strong>抓住整本书的大意</strong>。你能不能<strong>掌握</strong>这一点，要看你<strong>能不能用一两句话来说明整本书的大意</strong>。<br>(3)  你不仅要能将<strong>整本书简化为大意</strong>，还要能<strong>发现整本书各个部分是如何架构</strong>起来的。</p><p><strong>阅读小说时候的诠释规则是什么？</strong><br>(1)  小说的要素是插曲、事件、角色与他们的思想、言语、感觉及行动。<br>(2)  <strong>共识与主旨有关</strong>。小说的要素与整个表现的场景或背景有关。<br>(3)  如果说论说性作品中有任何活动，那就是<strong>论述的发展</strong>。由证据与理由到结构的一个逻辑性的演变。</p><p>任何经验都有时间顺序，无论多么短暂飘渺的经验都是如此。</p><p><strong>小说的阅读批评规则是什么？</strong><br><strong>在论说性作品中</strong>的规则是：<strong>在你还不了解一本书之前，不要评论一本书——不要说你同意或反对这个论点</strong>。</p><p><strong>小说的阅读批评</strong>的规则是：<strong>在你衷心感激作者试着为你创造的经验之前，不要批评一本想像的作品</strong>。</p><p>你不只要能说明你自已为什么喜欢或不喜欢，还要能<strong>表达出</strong>这本书中<strong>哪些地方是好的</strong>，<strong>哪些是不好的</strong>，并<strong>说明理由</strong>才行。</p><p>你会慢慢<strong>建立起批评的标准</strong>，你也会发现许多跟你有同样品味的人与你一起分享你的论点。你还可能会发现一件我们相信如此的事：<strong>懂得阅读方法的人，文学品味都很高</strong>。</p><h3 id="第十五章-阅读故事、戏剧与诗的一些建议">第十五章 阅读故事、戏剧与诗的一些建议</h3><p><strong>三个问题：</strong><br>第一，<strong>这整本书的内容是在谈些什么？</strong><br>第二，<strong>内容的细节是什么？是如何表现出来的？</strong><br>第三，<strong>这本书说的是真实的吗？全部真实或部分真实？</strong></p><p>要回答第一个问题，就是你<strong>能说出关于一个故事、戏剧或诗的情节大意，并要能广泛地包括故事或抒情诗中的动作与变化。</strong><br>要回答第二个问题，你就<strong>要能辨识剧中所有不同的角色，并用你自己的话重新叙述过发生在他们身上的关键事件。</strong><br>要回答第三个问题，就是你**能合理地评断一本书的真实性。**这像一个故事吗？这本书能满足你的心灵与理智吗？你欣赏这本书带来的美吗？不管是哪一种观点，你能说出理由吗？</p><p>第四个问题是：<strong>这本书与我何关？</strong><br>在想像文学作品中，这个问题与阅读诗与故事毫无关系。严格说起来，在你读好了——也就是分析好了小说、戏剧或诗之后，是用不着采取什么行动的。在你采取类似的分析阅读，回答前面三个问题之后，你身为读者的责任就算尽到了。</p><p>不过，阅读故事与小说的主要目的并不是要采取实际的行动。想像文学可以引导出行动，但却并非必要，因为它们属于纯艺术的领域。</p><p>如果你受到一本书的影响，而走出户外进行任何行动时，要问问你自己，那本书是否包含了激励你的宣言，让你产生行动力？这是想像文学本身就拥有的自主权。<strong>要把这些文学作品读通，你惟一要做的事就是去感受与体验</strong>。</p><h4 id="15-1-如何阅读故事书">15.1 如何阅读故事书</h4><p>第一个建议是：<strong>快读，并且全心全意地读。</strong></p><p>要达到这个理想，最接近的方法就是<strong>将阅读一篇好故事</strong>的<strong>时间压缩到合理的长度</strong>。否则你可能会忘了其间发生的事情，也会漏掉一些完整的情节，最后不知道自己在读的是什么了。</p><p>建议是<strong>要读得很快，而且全神投入</strong>。</p><p>让<strong>角色进人你的心灵</strong>之中，<strong>相信</strong>其中<strong>发生的事件</strong>，就算有疑惑也不要怀疑。在你了解一个角色为什么要做这件事之前，不要心存疑虑。尽量<strong>试着活在他的世界</strong>里，而不是你的世界，这样他所做的事就很容易理解了。除非你真的尽力”活在”这样的虚构世界中，否则不要任意批评这个世界。</p><p>阅读每一本书时要提出的问题——<strong>这整本书在谈些什么？</strong><br>除非你能很快读完，否则你没法看到整个故事的大要。如果你不专心一致地读，你也会漏掉其中的细节。</p><p>故事就像我们的人生一样，在生命中，我们不可能期望了解每一件发生在我们身上的事，或把一生全都看清楚。但是，<strong>当我们回顾过去时，我们便了解为什么了</strong>。所以，读者在阅读小说时，全部看完之后再<strong>回顾一下</strong>，就会了解事件的关联与活动的前后顺序了。</p><p>所有这些都回到同一个重点：<strong>你一定要读完一本小说之后，才能谈你是否把这个故事读通了</strong>。在阅读一本小说时，在第一页之前， 到最后一页之后，你对那些角色会发生些什么事所产生的想像，跟下一个阅读的人没什么两样。</p><p>对人类而言，小说或虚构的故事似乎是不可或缺的。为什么？<br>其中一个理由是：<strong>小说能满足我们潜意识或意识中许多的需要</strong>。如果只是<strong>触及意识的层面</strong>，像<strong>论说性作品</strong>一样，当然是很重要的。但<strong>小说</strong>一样也很重要，因为它<strong>触及潜意识的层面</strong>。</p><h4 id="15-2-关于史诗的重点">15.2 关于史诗的重点</h4><p>阅读任何一部重要的史诗对读者来说都有额外的要求——<strong>要求你集中注意力，全心参与并运用想像力</strong>。阅读史诗所要求的努力确实是不简单的。</p><p>好的阅读我们该说是<strong>分析阅读能让我们收获良多</strong>，而阅读史诗，至少就像阅读其他小说作品一样，能让我们的<strong>心灵更上层楼</strong>。不幸的是，如果读者不能善用阅读技巧来阅读这些史诗，将会一无所获。</p><h4 id="15-3-如何阅读戏剧">15.3 如何阅读戏剧</h4><p>如果你没有<strong>将剧本搬上心灵的舞台演出过</strong>，或许你还不能算是读过剧本了。就算你读得再好，也只是读了一部分而已。</p><p><strong>把剧本大声地读出来</strong>倒经常是不错的方法。<strong>要慢慢读，就像是听众在听你说话一样，还是带着感情读也就是说要让那些句子对你别有深意。<strong>这个简单的建议会帮助你解决许多问题。只有</strong>当这样做之后还有问题，才要找注解来帮助你阅读</strong>。</p><h4 id="15-4-关于悲剧的重点">15.4 关于悲剧的重点</h4><p>第一，<strong>记住悲剧的精髓在时间，或是说缺乏时间</strong>。<br>对我们来说很容易看出来该做些什么，但我们能在有限的时间中看清楚一切吗？在阅读希腊悲剧时，你要一直把这个问题放在心中。</p><p>第二，我们确实知道在希腊的戏剧中，所有的悲剧演员都穿一种高出地面几英寸的靴子（他们也戴面具）。<br>因此你要记得，在读旁白的部分时，你要想像这些台词是跟你一般身高的人所说出来的话，而在读悲剧人物的台词时，你要想像这是出自一个大人物的口中，他们不只是在形象上，在实际身高上也高出你一截。</p><h4 id="15-5-如何阅读抒情诗-Lyric-Poetry">15.5 如何阅读抒情诗(Lyric Poetry)</h4><p>最简单的有关诗的定义，就是诗人所写的东西。</p><p>无论我们心中如何激荡着原始的诗情，但是诗仍是由<strong>文字组成的</strong>，而且是以条理分明，精巧熟练的方式所组合出来的。</p><p><strong>两个观念：</strong><br><strong>第一</strong>，抒情诗，任何现代诗，只要你<strong>肯拿起来读</strong>，你会发现并不像你想的要花那么大的功夫。<br><strong>其次</strong>，那绝对是值得你花时间与精力去做的事。</p><p>一首好诗可以<strong>用心研读，一读再读</strong>，并在你一生当中<strong>不断地想起这首诗</strong>。你会在诗中<strong>不断地找到新点子、新的乐趣与启示</strong>，对你自己及这个世界<strong>产生新的想法</strong>。</p><p>阅读抒情诗的<strong>第一个规则</strong>是：<strong>不论你觉得自己懂不懂，都要一口气读完，不要停</strong>。</p><p>任何一首诗都有个<strong>整体大意</strong>。除非我们一次读完，否则无法理解大意是什么，也很难发现诗中<strong>隐藏的基本感觉与经验</strong>是什么。尤其是在一首诗中，中心思想绝不会在第一行或第一段中出现的。那是整首诗的意念，而不是在某一个部分里面。</p><p>阅读抒情诗的<strong>第二个规则</strong>是：<strong>重读一遍——大声读出来</strong>。<br><strong>大声朗诵诗句</strong>，会发现似乎说出来的字句<strong>可以帮助你更了解这首诗</strong>。**如果你朗诵出来，比较不容易略过那些不了解的字句，你的耳朵会抗议你的眼睛所忽略的地方。**诗中的节奏或是有押韵的地方，能帮助你把该强调的地方突显出来，增加你对这首诗的了解。最后，你会对这首诗打开心灵，让它对你的心灵发生作用一如它应有的作用。</p><p>如果一个人觉得自己不能读诗，只要能遵守前面这两个规则来读，就会发现比较容易一些了。一旦你掌握住一首诗的大意时，就算是很模糊的大意，你也可以开始提出问题来。</p><p><strong>只要一个人愿意努力，几乎任何人都能读任何诗</strong>。你发现任何有关作者生活与时代的资讯，只要是确实的都有帮助。要了解一首诗，一定要去读它——<strong>一遍又一遍地读</strong>。</p><h3 id="第十六章-如何阅读历史书">第十六章 如何阅读历史书</h3><h4 id="16-1-难以捉摸的史实">16.1 难以捉摸的史实</h4><p>一件历史的”事实”——虽然我们感觉很相信这两个字代表的意义，但却是世上<strong>最难以捉摸的</strong>。当然，某一种历史事实是可以很确定的。（比如一些重大事件的历史事件的记载，时间是应该不会错的。）</p><h4 id="16-2-历史的理论">16.2 历史的理论</h4><p>当然，一个好的历史学家是不会编造过去的。他认为自己对某些观念、事实，或精准的陈述责无旁贷。不过，有一点不能忘记的是，历史学家一定要编纂一些事情。他不是在许多事件中找出一个共通的模式，就是要套上一个模式。他也总不免要指出事件发生的原因及行为的动机。</p><p>如果我们真的想要了解一个事件或时期的历史，就很有必要多看一些相关的论著。如果我们所感兴趣的事件对我们又有特殊意义的话，就更值得这么做了。我们认为每一种历史的写作都必定是从某个观点出发的。为了追求真相，我们必须从更多不同的角度来观察才行。</p><h4 id="16-3-历史中的普遍性">16.3 历史中的普遍性</h4><p><strong>阅读历史的两个要点是：</strong><br><strong>第一</strong>，对你感兴趣的事件或时期，尽可能阅读一种以上的历史书。<br><strong>第二</strong>，阅读历史时，不只要关心在过去某个时间、地点真正发生了什么事，还要读懂在任何时空之中，尤其是现在，人们为什么会有如此这般行动的原因。</p><h4 id="16-4-阅读历史书要提出的问题">16.4 阅读历史书要提出的问题</h4><p>在阅读历史时，我们也要像阅读论说性作品一样，提出基本的问题。<br><strong>第一个问题</strong>：每一本历史书都有一个<strong>特殊而且有限定范围</strong>的<strong>主题</strong>。通常读者很容易就看出这样的主题，不过，不见得会仔细到看出作者为自己所设定的范围。</p><p><strong>第二个问题</strong>：历史书在说一个故事，而这个故事当然是发生在一个特定的时间里。一般的纲要架构因此决定下来了，用不着我们去搜寻。</p><p>历史告诉我们人类过去所做的事，也经常引导我们作改变，尝试表现出更好的自我。历史会建议一些<strong>可行性</strong>，因为那是以前的人已经做过的事。既然是做过的事，就可能再做一次——或是可以<strong>避免再做</strong>。</p><h4 id="16-5-如何阅读传记与自传">16.5 如何阅读传记与自传</h4><p>传记是一个<strong>真人的故事</strong>。这种作品一直以来就是有混合的传统，因此也保持着混杂的特性。</p><p>读者也要问同样的问题——<strong>作者的目的是什么</strong>？他所谓<strong>真实包含哪些条件</strong>？——这也是在读任何一本书时都要提出的问题。</p><p>我们要记得，没有任何文字是自己写出来的——我们所阅读到的文字都是由人所组织撰写出来的。</p><p>自传揭露了多少有关作者的秘密，我们都用不着花上一堆时间来研究作者并未言明的秘密。当然，如果你想知道一个人的一生，你就该尽可能去阅读你能找到的资料，包括他对自己一生的描述（如果他写过）。对于任何自传都要有一点<strong>怀疑心</strong>，同时别忘了，在你还不了解一本书之前，<strong>不要妄下论断</strong>。</p><p>传记是有<strong>启发性</strong>的。那是生命的故事，通常是成功者一生的故事——也可以当作我们<strong>生活的指引</strong>。</p><h4 id="16-6-如何阅读关于当前的事件">16.6 如何阅读关于当前的事件</h4><p>在阅读时，<strong>四个基本问题是一定要提出来</strong>的。</p><p>所谓当前发生的事件，也就是跟“新闻”这两个字很类似。</p><p>阅读当代作品时，我们不会有时空的隔阂，因此我们除了要厘清作者心中的过滤器之外，也要弄清楚自己的想法才行。</p><p>读者要<strong>擦亮眼睛</strong>(Caveat lector)!要搞清楚他们的利益考虑，阅读任何东西都要小心翼翼。</p><h4 id="16-7-关于文摘的注意事项">16.7 关于文摘的注意事项</h4><p>当我们尽心阅读这些摘要，就像他们在之前的尽心阅读以帮助我们作摘要一样，他们的功能对我们才会真正有帮助。</p><p><strong>越是浓缩过的摘要，筛选得越厉害</strong>。内容被浓缩得越多，我们对浓缩者的特质就更要有所了解。毕竟，在经过专业浓缩过的句子中，读者更要能读出言外之意才行。<strong>阅读文摘</strong>，有时是<strong>最困难又自我要求最多</strong>的一种阅读方式。</p><h3 id="第十七章-如何阅读科学与数学">第十七章 如何阅读科学与数学</h3><p><strong>限定讨论两种形式的书：</strong><br>一种是在我们传统中，<strong>伟大的科学与数学</strong>的<strong>经典之作</strong>。另一种则是<strong>现代科普著作</strong>。</p><h4 id="17-1-了解科学这一门行业">17.1 了解科学这一门行业</h4><p>我们毫不迟疑地要推荐你<strong>最少要阅读一些伟大的科学经典巨著</strong>。事实上，你真的没有借口不阅读这样的书。其中没有一本真的很难读，就算牛顿的《自然哲学的数学原理》(Mathematical Principles of Natural Philosophy)，<strong>只要你真的肯努力，也是可以读得通的</strong>。</p><p>你要做的就是<strong>运用阅读论说性作品的规则</strong>，而且要很<strong>清楚地知道作者想要解决的问题是什么</strong>。这个分析阅读的规则<strong>适用于任何论说性的作品</strong>，尤其<strong>适用于科学与数学的作品</strong>。</p><p>要<strong>跟上科学发展的脚步</strong>，<strong>找出</strong>事实、假定、原理与证据之间的<strong>相互关联</strong>，就是<strong>参与了人类理性的活动</strong>，而那可能是人类最成功的领域。也许，光这一点就能印证有关科学历史研究的价值了。此外，这样的研究还能在<strong>某种程度</strong>上<strong>消除一些对科学的谬误</strong>。</p><h4 id="17-2-阅读科学经典名著的建议">17.2 阅读科学经典名著的建议</h4><p>所谓科学作品，就是在某个研究领域中，经过实验或自然观察得来的结果，所写成的研究报告或结论。叙述科学的问题总要尽量描述出正确的现象，<strong>找出不同现象之间的互动关系</strong>。</p><p>伟大的科学作品，尽管最初的假设不免个人偏见，但<strong>不会有夸大或宣传</strong>。你要注意作者最初的假设，放在心上，然后把他的假设与经过论证之后的结论作个区别。一个越“客观”的科学作者，越会明白地要求你接受这个、接受那个假设。<strong>科学的客观不在于没有最初的偏见，而在于坦白承认</strong>。</p><p>在科学作品中，<strong>主要的词汇</strong>通常都是<strong>一些不常见的或科技的用语</strong>。这些用语很容易找出来，你也<strong>可以经由这些用语找到主旨</strong>。主旨通常都是很一般性的。</p><p>在阅读科学作品时，似乎有两个主要的难题。<br>一个是有关论述的问题。<strong>科学基本上是归纳法</strong>，基本的论述也就是经由研究查证，建立出来的一个通则——可能是经由实验所创造出来的一个案例，也可能是长期观察所收集到的一连串案例。还有另外一些论述是<strong>运用演绎法来推论的</strong>。这样的论述是<strong>借着其他已经证明过的理论，再推论出来的</strong>。在讲求证据这一点上，科学与哲学其实差异不大。不过<strong>归纳法是科学的特质</strong>。</p><p>出现第一个困难的原因是：为了了解科学中归纳法的论点，你就必须<strong>了解科学家引以为理论基础的证据</strong>。如果这本书不能启发一个人时，读者只有一个解决办法，就是自己<strong>亲身体验以获得必要的特殊经验</strong>。他可能要亲眼看到实验的过程，或是去观察与操作书中所提到的相同的实验仪器。他也可能要去博物馆观察标本与模型。</p><p>任何人想要了解科学的历史**，除了阅读经典作品外，还要能自己做实验**，以熟悉书中所谈到的关系重大的实验。</p><p>这并不是说你一定要依序完成所有的实验才能开始阅读这本书。不过在当时他所提出来的方法仍是革命性的，他所构思的化学元素大体上我们仍然沿用至今。因此阅读这本书的重点是：<strong>你用不着读完所有的细节才能获得启发</strong>。譬如他的前言<strong>便强调了科学方法的重要，便深具启发性</strong>。</p><h4 id="17-3-面对数学的问题">17.3 面对数学的问题</h4><p>数学其实是一种语言，我们可以像学习自己的语言一样学习它。在学习自己的语言时，我们要学两次：<strong>第一次是学习如何说话</strong> <strong>，第二次是学习如何阅读</strong>。幸运的是，数学只需要学一次，因为它完全是书写的语言。</p><p><strong>学习新的书写语言，牵涉到基础阅读的问题</strong>。当第一次接受阅读指导时，我们的问题在要学习认出每一页中出现的特定符号，还要记得这些符号之间的关系。如果我们被一个句子的句法搞昏头时，也得从<strong>基础的层次来解决</strong>。只有当我们解决了这些问题时，我们的阅读能力才能更上层楼。</p><p>任何一种语言都是一种沟通的媒介，借着语言人们能彼此了解共同的主题。</p><p><strong>基本几何学的命题有两种：</strong><br>(1)   有关<strong>作图问题</strong>的叙述。<br>(2)   有关<strong>几何图形与各相关部分之间</strong>的关系的定理。作图的问题必须着手去做，定理的问题就得去证明。</p><p>作图很明显地与公设(postulate)相似，两者都声称几何的运作是可以执行出来的。在公设的案例中，这个可能性是<strong>假定</strong>(assumed)出来的。在命题的案例中，那是要证明(proved)出来的。当然，<strong>要这样证明，需要用到公设</strong>。</p><p>命题要确定的不是假设是否为真，也不是结论是否为真——除非假设为真的时候。而除非命题得到证明，否则我们就无法确认假设和结论的关系是否为真。命题所证明的，纯粹是这种关系是否为真。别无其他。</p><p>我们只是针对一个<strong>真正有范围限制的问题，作出真正逻辑的解释</strong>。在解释的清晰与问题范围有限制的特质之中，有一种特别的吸引力。</p><h4 id="17-4-掌握科学作品中的数学问题">17.4 掌握科学作品中的数学问题</h4><p>我们所关心的是在科学作品中有<strong>相当多的数学问题</strong>，而这也是一个主要的阅读障碍。关于这一点有几件事要说明如下。</p><p>第一，你<strong>至少可以把一些比你想像的基础程度的数学读得更明白</strong>。<br>我们已经建议你从欧几里得开始，我们确定你只要花几个晚上把《几何原理》读好，就能<strong>克服对数学的恐惧心理</strong>。读完欧几里得之后，你可以进一步，看看其他经典级的希腊数学大师的作品——阿基米德(Archimedes)、阿波罗尼乌斯(Apollonius)、尼科马科斯(Nicomachus)。这些书并不真的很难，而且你可以<strong>跳着略读</strong>。</p><p>第二，如果你阅读数学书的企图是<strong>要了解数学本身</strong>，当然你<strong>要读数学</strong>，<strong>从头读到尾——手上还要拿枝笔</strong>，这会比阅读任何其他的书还需要<strong>在书页空白处写些笔记</strong>。但是你的企图可能并非如此，而是只想<strong>读一本有数学在内的科学书</strong>，这样<strong>跳着略读反而是比较聪明</strong>的。</p><p>以牛顿的《自然哲学的数学原理》为例，<strong>先看定理的说明，再看看结论，掌握一下这是如何证明出来的。</strong> <strong>读读引理</strong> (lemmas)及<strong>系理</strong>(corollaries)的<strong>说明</strong>，再<strong>读</strong>所谓<strong>旁注</strong> (scholiums)（基本上这是讨论命题与整个问题之间的关系）。这么做了之后，你会<strong>看到整本书的全貌</strong>，也会发现牛顿是<strong>如何架构这个系统</strong>的——哪个先哪个后，各个部分又如何密切呼应起来。用这样的方法读这本书，觉得困难就<strong>不要看图表（<strong>许多读者是这么做的），<strong>只挑你感兴趣的内容</strong>来看，但要</strong>确定没错过牛顿所强调的重点</strong>。其中一个重点出现在第三卷的结尾，名称是“<strong>宇宙系统</strong>”，牛顿称之为<strong>一般的旁注</strong>，不但<strong>总结了前人的重点</strong>，也<strong>提出</strong>了一个物理学上几乎所有<strong>后人都会思考的伟大问题</strong>。</p><p>科学作品中经常会包括数学，主要因为我们前面说过数学精确、清晰与范围限定的特质。有时候你能读懂一些东西，却用不着深入数学的领域，像牛顿的书就是个例子。奇怪的是，就算数学对你来说可怕得不得了，但是一点也没有数学有时造成的麻烦还可能更大呢！</p><p>当然，并不是所有的科学经典作品都用上了数学，或是一定要用数学。只要你记住，<strong>你的责任不是成为这个主题的专家，而是要去了解相关的问题，在阅读时就会轻松许多</strong>。</p><h4 id="17-5-关于科普书的重点">17.5 关于科普书的重点</h4><p>从某一方面而言，关于阅读科普书，我们没有什么更多的话要说了。就定义上来说，这些书——不论是书或文章——都是为广泛的大众而写的，而不只是为专家写的。因此，如果你已经读了一些科学的经典名作，这类流行书对你来说就毫无问题了。<br>这是因为这些书虽然与科学有关，但一般来说，读者都已经<strong>避免了阅读原创性科学巨著的两个难题</strong>。<br>第一，<strong>他们只谈论一点相关的实验内容</strong>（他们只报告出实验的结果）。<br>第二，<strong>内容只包括一点数学</strong>（除非是以数学为主的畅销书）。</p><p><strong>阅读科普书绝对比阅读故事书要困难得多</strong>。就算是一篇三页没有实验报告，没有图表，也没有数学方程式需要读者去计算的有关DNA的文章，<strong>阅读的时候如果你不全神贯注，就是没法理解</strong>。因此，在阅读这种作品时<strong>所需要的主动性比其他的书还要多</strong>。</p><ol><li>要<strong>确认主题</strong>。</li><li>要<strong>发现整体与部分之间的关系</strong>。</li><li>要<strong>与作者达成共识</strong>。</li><li>要<strong>找出主旨与论述</strong>。</li><li><strong>在评估或衡量意义之前</strong>，要能<strong>完全了解这本书</strong>才行。</li></ol><p>现在这些规则对你来说应该都很熟悉了。但是在这里运用起来更有作用。</p><p><strong>短文通常都是在传递资讯</strong>，你阅读的时候用<strong>不着太多主动的思考</strong>。你要做的<strong>只是去了解</strong>，<strong>明白作者所说的话</strong>，除此之外大多数情况就<strong>用不着花太大的力气</strong>了。</p><p>如果我们想要<strong>了解我们存活的这个年代</strong>，我们就该<strong>了解一下数学是什么，数学家是如何运用数学，如何思考的</strong>。</p><h3 id="第十八章-如何阅读哲学书">第十八章 如何阅读哲学书</h3><p><strong>为什么孩子天生就有的心态，我们却要努力去发展呢？</strong><br>在我们成长的过程中，不知是什么原因，成人便失去了孩提时代原本就有的好奇心。或许是因为学校教育使头脑僵化了——死背的学习负荷是主因，尽管其中有大部分或许是必要的。另一个更可能的原因是父母的错。就算有答案，我们也常告诉孩子说没有答案，或是要他们不要再问问题了。碰到那些看来回答不了的问题时，我们觉得困窘，便想用这样的方法掩盖我们的不自在。所有这些都在打击一个孩子的好奇心。他可能会以为问问题是很不礼貌的行为。人类的好问从来没有被扼杀过，但却很快地降格为大部分大学牛所提的问题他们就像接下来要变成的成人一样，只会问一些资讯而已。</p><p>对这个问题我们没有解决方案，当然也不会自以为是，认为我们能告诉你如何回答孩子们所提出来的深刻问题。但是我们要提醒你一件很重要的事，<strong>就是最伟大的哲学家所提出来的深刻问题，正是孩子们所提出的问题。能够保留孩子看世界的眼光，又能成熟地了解到保留这些问题的意义，确实是非常稀有的能力——拥有这种能力的人也才可能对我们的思想有重大的贡献</strong>。</p><p>我们并不一定要像孩子般地思考，才能了解存在的问题。孩子们其实并不了解，也没法了解这样的问题——就算真有人能了解的话。但是我们一定要能够<strong>用赤子之心来看世界，怀疑孩子们怀疑的问题，问他们提出的问题</strong>。成人复杂的生活阻碍了寻找真理的途径。<strong>伟大的哲学家</strong>总能<strong>厘清生活中的复杂</strong>，看出简单的差别——只要经由他们说明过，原先困难无比的事就变得很简单了。<strong>如果我们要学习他们，提问题的时候就一定也要有孩子气的单纯——而回答时却成熟而睿智</strong>。</p><h4 id="18-1-哲学家提出的问题">18.1 哲学家提出的问题</h4><p>这些哲学家所提出的“孩子气的单纯”问题，到底是些什么问题？我们写下来的时候，这些问题看起来并不简单，因为要回答起来是很困难的。不过，由于这些问题都很根本也很基础，所以乍听之下很简单。</p><p>一个哲学家想要<strong>探索存在的特质与存在的领域</strong>时，这些就是他们会提出来的典型问题。因为是问题，并不难说明或理解，但要回答，却难上加难——事实上困难到即使是近代的哲学家，也无法作出满意的解答。</p><p>哲学家会提的<strong>另一组问题不是存在，而是跟改变或形成有关</strong>。根据我们的经验，我们会毫不迟疑地指出某些事物是存在的，但是我们也会说所有这些事物都是会改变的。它们存在过，却又消失了。当它们存在时，大多数都会从一个地方移动到另一个地方，其中有许多包括了质与量上的改变：它们会变大或变小，变重或变轻，或是像成熟的苹果与过老的牛排，颜色会有改变。</p><p><strong>哲学并不只限于理论性的问题而已</strong>。以善与恶为例。孩子特别关心好跟坏之间的差别，如果他们弄错了，可能还会挨打。但是直到我们成人之后，对这两者之间的差异也不会停止关心。在善与恶之间，是否有普遍被认可的区别？无论在任何情况中，是否某些事永远是好的，某些事永远是坏的？或是就像哈姆雷特引用蒙田的话：“<strong>没有所谓好跟坏，端看你怎么去想它</strong>。”当然，善与恶跟对与错并不相同。这两组词句所谈的似乎是两种不同的事。尤其是，就算我们会觉得凡是对的事情就是善的，但我们可能不觉得凡是错的事情就一定是恶的。</p><p>我们所讨论的两种问题，<strong>区分出两种主要不同的哲学领域</strong>。<br>第一组，<strong>关于存在与变化的问题，与这个世界上存在与发生的事有关。这类问题在哲学领域中属于理论或思辩型的部分</strong>。<br>第二组，<strong>关于善与恶，好与坏的问题，和我们应该做或探寻的事有关，我们称这是隶属于哲学中实用的部分，更正确来说该是规范 (normative)的哲学</strong>。<br><strong>哲学规范的书基本上关心的是所有人都应该追求的目标</strong>——像过好生活，或组织一个好社会，他们就应该运用什么方法来达成目的的这一点上，却仅仅只会提供一些<strong>最普遍的共识</strong>。</p><p>哲学家提出来的问题，也有助于哲学两大领域中次分类的区分。</p><ol><li>如果<strong>思辩或理论型</strong>的哲学主要在<strong>探讨存在</strong>的问题，那就<strong>属于形上学</strong>。</li><li>如果<strong>问题与变化有关</strong>——关于特质与种类的演变，变化的条件与原因——就是<strong>属于自然哲学</strong>的。</li><li>如果主要<strong>探讨的是知识的问题</strong>——关于我们的认知，人类知识的起因、范围与限制，确定与不确定的问题——那就属于认识论(epistemology)的部分，也称作<strong>知识论</strong>。</li><li>就<strong>理论与规范哲学</strong>的区分而言，如果是<strong>关于如何过好生活，个人行为中善与恶的标准</strong>，这都与伦理学有关，也就是<strong>理论哲学的领域；<strong>如果是</strong>关于良好的社会，个人与群体之间的行为问题</strong>，则是政治学或政治哲学的范畴，也就是<strong>规范哲学的领域</strong>。</li></ol><h4 id="18-2-现代哲学与传承">18.2 现代哲学与传承</h4><p>为了说明简要，<strong>让我们把世上存在及发生了什么事，或人类该做该追求的问题</strong>当作“<strong>第一顺位问题</strong>”。我们要认知这样的问题。<br>然后是“<strong>第二顺位问题</strong>”：<strong>关于我们在第一顺位问题中的知识，我们在回答第一顺位问题时的思考模式，我们如何用语言将思想表达出来等问题</strong>。</p><p><strong>区别出第一顺位与第二顺位问题</strong>是有帮助的。因为那会<strong>帮助</strong>我们<strong>理解近年来的哲学界发生了什么变化</strong>。当前主要的专业哲学家不再相信第一顺位的问题是哲学家可以解决的问题。目前大多数专业哲学家将心力投注在第二顺位的问题上，<strong>经常提出来的是如何用言语表达思想的问题</strong>。</p><p>问题在于今天大家几乎全然放弃了第一顺位的疑问，也就是对门外汉读者来说最可能感兴趣的那些问题。事实上，今天的哲学，就像当前的科学或数学一样，已经<strong>不再为门外汉写作</strong>了。第二顺位的问题，几乎可以顾名思义，都是些诉求比较窄的问题，而专业的哲学家，就像科学家一样，他们<strong>惟一关心的只有其他专家的意见</strong>。</p><p>这使得现代哲学作品对一个非哲学家来说格外难读——就像科学书对非科学家来说一样的困难。只要是关于第二顺位的哲学作品，我们都无法指导你如何去阅读。不过，还是有一些你可以读的哲学作品， 我们相信也是你该读的书。这些作品提出的问题是我们所说的第一顺位问题。毫无意外的，这些书主要也是为门外汉而写的，而不是专业哲学家写给专业同行看的。</p><p>上溯至1930年或稍晚一点，哲学书是为一般读者而写作的。哲学家希望同行会读他们的书，但也希望一般有知识的读者也能读。因为他们所提的问题，想要回答的问题都是与一般人切身相关的，因此他们认为一般人也该知道他们的思想。</p><h4 id="18-3-哲学的方法">18.3 哲学的方法</h4><p>至少就提出与回答第一顺位问题的哲学而言，了解哲学方法的立足点是很重要的。假设你是一个哲学家，你对我们刚才提的那些孩子气的单纯问题感到很头痛——像任何事物存在的特质，或是改变的特质与成因等问题。那你该怎么做？</p><p>如果你的问题是科学的，你会知道要如何回答。你该进行某种特定的研究，或许是发展一种实验，以检验你的回答，或是广泛地观察各种现象以求证。如果你的问题是关于历史的，你会知道也要做一些研究，当然是不同的研究。但是要找出普遍存在的特质，却没有实验方法可循。而要找出改变是什么，事情为什么会改变，既没有特殊的现象可供你观察，更没有文献记载可以寻找阅读。你惟一能做的是思考问题本身，简单来说，<strong>哲学就是一种思考，别无他物</strong>。</p><p>当然，你并不是在茫然空想。<strong>真正好的哲学并不是“纯“思维——脱离现实经验的思考</strong>。观念是不能任意拼凑的。回答哲学问题，有严格的检验，以确认答案是否合乎逻辑。但这样的检验纯粹是来自一般的经验——你身而为人就有的经验，而不是哲学家才有的经验。你透过人类共同经验而对“改变”这种现象的了解，并不比任何人差——有关你的一切，都是会改变的。只要改变的经验持续下去，你就可以像个伟大的哲学家一样，思考有关改变的特质与起因。而他们之所以与你不同，就在他们的思想极为续密：他们能整理出所有可能问到的最尖锐的问题，然后再仔细清楚地找出答案来。他们用什么方法找出答案来呢？不是观察探索，也不是寻找比一般人更多的经验，而是<strong>比一般人更深刻地思考这个问题</strong>。</p><p>当我们在阅读一本哲学书时，所感兴趣的是哲学的问题，而不是科学或历史的问题。在这里我们要冒着重复的风险再说一次，我们要强调的是，<strong>要回答哲学的问题，除了思考以外，别无他法</strong>。如果我们能建造一架望远镜或显微镜，来检验所谓存在的特质，我们当然该这么做，但是不可能有这种工具的。</p><h4 id="18-4-哲学的风格">18.4 哲学的风格</h4><p>虽然哲学的方法只有一种，但是在西方传统中，伟大的哲学家们至少采用过五种论述的风格。研究或阅读哲学的人应该能区别出其间的不同之处，以及各种风格的优劣。</p><p>(1) 哲学对话：第一种<strong>哲学的论说形式</strong>，虽然并不是很有效，但首次出现在柏拉图的《对话录》(Dialogues)中。<br>这种<strong>风格是对话的，甚至口语的</strong>，一群人跟苏格拉底讨论一些主题（或是后来一些对话讨论中，是和一个名叫“雅典陌生人"[the  Athenian Stranger]的人来进行的）。通常在一阵忙乱的探索讨论之后，苏格拉底会开始<strong>提出一连串的问题，然后针对主题加以说明</strong>。在柏拉图这样的大师手中，这样的风格是启发性的，的确能引领读者自己去发现事情。这样的风格再加上苏格拉底的故事的高度戏剧性 或是说高度的喜剧性——就变得极有力量。<br>柏拉图却一声不响地做到了。怀特海有一次强调，全部西方哲学，不过是“柏拉图的注脚”。后来的希腊人自己也说：“无论我想到什么，都会碰到柏拉图的影子。“无论如何，不要误会了这些说法。柏拉图自已显然并没有哲学系统或教条——<strong>若不是没有教条，我们也没法单纯地保持对话，提出问题。因为柏拉图，以及在他之前的苏格拉底，已经把后来的哲学家认为该讨论的所有重要问题，几乎都整理、提问过了</strong>。</p><p>(2)  <strong>哲学论文或散文</strong>：亚里士多德是柏拉图最好的学生，他在柏拉图门下学习了二十年。据说他也写了对话录，却完全没有遗留下来。所遗留下来的是一些针对不同的主题，异常难懂的散文或论文。</p><p>(3)  <strong>面对异议</strong>：中世纪发展的哲学风格，以圣托马斯·阿奎那的《神学大全》为极致，兼有前述两者的风貌。我们说过，哲学中不断提到的问题大部分是柏拉图提出的；我们应该也谈到，苏格拉底在对话过程中问的是那种小孩子才会问的简单又深刻的问题。而亚里士多德，我们也说过，他会<strong>指出其他哲学家的不同意见，并作出回应</strong>。</p><p>在阿奎那的作品中，最重要的是，他能明确指<strong>陈各种冲突，将不同的观点都说明出来，然后再面对所有不同的意见，提出自己的解决方案</strong>。从对立与冲突中，让真理逐渐浮现，这是中世纪非常盛行的想法。在阿奎那的时代，哲学家接受这样的方式，事实上是因为他们随时要准备当众，或在公开的论争中为自己的观点作辩护——这些场合通常群聚着学生和其他利害相关的人。中世纪的文化多半以口述方式流传，部分原因可能是当时书籍很少，又很难获得。一个主张要被接受，被当作是真理，就要能接受公开讨论的测试。<strong>哲学家不再是孤独的思考者，而是要在智力的市场上，接受对手的挑战</strong>。因此，《神学大全》中便渗透了这种<strong>辩论与讨论的精神</strong>。</p><p>(4)  <strong>哲学系统化</strong>：在17世纪，第四种哲学论说形式又发展出来了。这是两位著名的哲学家，笛卡尔与斯宾诺莎所发展出来的。他们着迷于数学如何组织出一个人对自然的知识，因此他们想<strong>用类似数学组织的方式，将哲学本身整理出来</strong>。</p><p>斯宾诺莎将这样的概念发展到更深的层次。他的《伦理学》(Eth­ics)是用严格的数学方式来表现的，其中有命题、证明、系理、引理、旁注等等。然而，关于形上学或伦理道德的问题，用数学的方法来解析不能让人十分满意，数学的方法还是比较适合几何或其他的数学问题，而不适合用在哲学问题上。当你阅读<strong>斯宾诺莎</strong>的时候，可以像你在阅读牛顿的时候那样<strong>略过很多地方</strong>，在阅读<strong>康德或亚里士多德</strong>时，你什么也不能略过，因为他们的理论是<strong>一直连续下来</strong>的。读<strong>柏拉图时也不能省略</strong>，你漏掉一点就像看一幕戏或读一首诗时，<strong>错过了其中一部分</strong>，这样<strong>整个作品就不完整了</strong>。</p><p>(5)  <strong>格言形式</strong>：还有另一种哲学论说形式值得一提，只不过没有前面四种那么重要。这就是<strong>格言的形式</strong>，是由尼采在他的书《查拉图斯特拉如是说》(Thus Spake Zarathustra)中所采用的，一些现代的法国哲学家也运用这样的方式。</p><p>上个世纪这样的风格之所以受到欢迎，可能是因为西方的读者对东方的哲学作品特别感兴趣，而那些作品就多是用格言的形式写作的。这样的形式可能也来自帕斯卡尔的《沉思录》(Pensees)。当然，帕斯卡尔并不想让自己的作品就以这样简短如谜的句子面世，但是在他想要以文章形式写出来之前，他就已经去世了。</p><p>用<strong>格言的形式来解说哲学</strong>，最大的好处在于<strong>有启发性</strong>。这会给读者一个印象，就像在这些简短的句子中还有言外之意，他必须自己<strong>运用思考来理解</strong>——他<strong>要能够自己找出各种陈述之间的关联，以及不同论辩的立足点</strong>。同样地，这样的形式也有<strong>很大的缺点</strong>，因为<strong>这样的形式完全没法论说</strong>。作者就像个撞了就跑的司机，他碰触到一个主题，谈到有关的真理与洞见，然后就跑到另一个主题上，却并没有为自己所说的话作适当的辩解。因此，格言的形式对喜欢诗词的人来说是很有意思的，但对严肃的哲学家来说却是很头痛的，因为他们希望能跟随着作者的思想，对他作出评论。</p><p>也就是说，所有伟大的哲学作品都不出这五种写作形式，当然，有时哲学家会尝试一种以上的写作方式。不论过去或现在，<strong>哲学论文或散文都可能是最普遍的形式</strong>，从最高超最困难的作品，像康德的书，到最普遍的哲学论文都包括在其中。对话形式是出了名的难写，而几何形式是既难读又难写。格言形式对哲学家来说是绝对不能满意的。而托马斯形式则是现代较少采用的一种方式。或许这也是现代读者不喜欢的一种方式，只是很可惜这样的方式却有很多的好处。</p><h4 id="18-5-阅读哲学的提示">18.5 阅读哲学的提示</h4><p>到目前为止，读者应该很清楚在阅读任何哲学作品时，最重要的就是要<strong>发现问题</strong>，或是<strong>找到书中想要回答的问题</strong>。这些问题可能详细说明出来了，也可能隐藏在其中。不管是哪一种，你都要试着找出来。</p><p>作者会如何回答这些问题，<strong>完全受他的中心思想与原则的控制</strong>。在这一方面作者可能也会说明出来，但不一定每本书都如此。我们前面已经引述过巴兹尔·威利的话，要<strong>找出作者隐藏起来、并未言明的假设</strong>，是多么困难——也多么重要的事情。这适用于每一种作品。运用在哲学书上尤其有力。</p><p>伟大的哲学家在他的作品背后，都有<strong>自己特定的中心思想与原则</strong>。你可以很容易就看出他是否清楚地写在你读的那本书里。但是他也可能不这么做，保留起来在下一本书里再说明白。也可能他永远都不会明讲，但是在每本书里都有点到。</p><p><strong>哲学所询问的不只是现象之间的联系</strong>，更要<strong>追寻潜藏在其中的最终原因与条件</strong>。要回答这些问题，<strong>只有清楚的论述与分析，才能让我们感到满意</strong>。</p><p>**读者最要花力气的就是作者的词义与基本主旨。**虽然哲学家跟科学家一样，有一些专门的技术用语，但他们表达思想的词句通常来自日常用语，只是用在很特殊的意义上。读者需要特别注意这一点。如果他不能克服自己，总是想将一个熟悉的字看作一般意义的想法，最后他会让整本书变成胡说八道又毫无意义。</p><p><strong>哲学讨论的基本词义就像科学作品一样，当然是抽象的</strong>。其实，任何具有共通性的知识，除了抽象的词义外，无从表达。</p><p><strong>哲学作品</strong>几乎没有不陈述一些作者认为不证自明的主旨。这种主旨都<strong>直接来自经验</strong>，而不是由其他主旨证明而来。</p><p>因此要了解并测验一位哲学家的主要原则，你用不着借重经由方法调查而获得的特殊经验，这种额外的助力。他诉求的是你<strong>自己的普通常识</strong>，<strong>以及对你自己所生存的这个世界的日常观察</strong>。</p><h4 id="18-6-厘清你的思绪">18.6 厘清你的思绪</h4><p>一本好的哲学理论的书，就像是好的科学论文，不会有滔滔雄辩或宣传八股的文字。</p><p>哲学家彼此意见往往不合这一点，不应该是你的困扰。这有<strong>两个原因</strong>。<br>第一，<strong>如果这些不同的意见一直存在，可能就指出一个没有解决或不能解决的大问题</strong>。知道真正的奥秘所在是件好事。<br>第二，<strong>哲学家意见合不合其实并不重要，你的责任只是要厘清自己的思路</strong>。就哲学家透过他们的作品而进行的长程对话，你一定要能判断什么成立，什么不成立才行。如果你把一本哲学书读懂了——意思是也读懂了其他讨论相同主题的书——你就可以有评论的立场了。</p><h4 id="18-7-关于神学的重点">18.7 关于神学的重点</h4><p>神学有两种类型，<strong>自然神学</strong>(natural theology)与<strong>教义神学</strong>(dogmatic theology)。</p><p><strong>自然神学是哲学的一支，也是形而上学的最后一部分</strong>。譬如你提出一个问题，因果关系是否永无止境？每件事是否都有起因？如果你的答案是肯定的，你可能会陷入一种永无止境的循环当中。因此，你可能要设定某个不因任何事物而发生的原始起因的别称。亚里士多德称这种没有起因的原因是“不动的原动者"(unmoved mover)。你可以另外命名甚至可以说那不过是上帝的别称——但是重点在，你要<strong>透过不需要外力支援的——自然进行的思考，达成这番认知</strong>。</p><p>教义神学与哲学则不同，因为教义神学的首要原则就是某个宗教的教徒所信奉的经文。教义神学永远依赖教义与宣扬教义的宗教权威人士。如果你没有这样的信仰，也不属于某个教派，想要把教义神学的书读好，你就得拿出读数学的精神来读。但是你得永远记住，在有关信仰的文章中，信仰不是一种假设。对有信仰的人来说，那是一种确定的知识，而不是一种实验性的观点。</p><p>一般来说，在面对教义神学的书时，他们会犯一两个错。<br>第一个错是<strong>拒绝接受——即使是暂时的接受——作者首要原则的经文</strong>。<br>第二个错是<strong>认为既然整本书的首要原则是教义的，依据这些教义而来的论述，这些教义所支持的推论，以及所导引出来的结论，都必然也都是属于教义的</strong>。</p><p>一个<strong>没有信仰的读者</strong>在阅读这样的书时，他要做的就是<strong>接受首要原则是成立的，然后用阅读任何一本好的论说性作品都该有的精神来阅读</strong>。至于一个<strong>有信仰的读者</strong>在阅读与自己信仰有关的书籍时，要<strong>面对的则是另一些困难</strong>了。这些问题并不只限于阅读神学才出现。</p><h4 id="18-8-如何阅读“经书”">18.8 如何阅读“经书”</h4><p>有一种很有趣的书，一种阅读方式，是我们还没提到的。我们用“经书"(canonical)来称呼这种书，如果传统一点，我们可能会称作“圣书" (sacred)或“神书"(holy)。但是今天这样的称呼除了在某些这类书上还用得着之外，已经不适用于所有这类书籍了。</p><p>任何一个机构——教会、政党或社会——在其他的功能之外，如果<br>(1) 有<strong>教育的功能</strong><br>(2) 有<strong>一套要教育的课本</strong>(a body of doctrine to teach)<br>(3) 有<strong>一群虔诚又顺服的成员</strong>，那么属于这类组织的成员在阅读的时候都会<strong>必恭必敬</strong>。<br>他们不会——也不能——质疑这些对他们而言就是“经书”的书籍的权威与正确的阅读方法。信仰使得这些信徒根本不会发现“神圣的“经书中的错误，更别提要找出其中道理不通的地方。</p><p><strong>一个忠诚的读者在阅读经书时，有义务要从中找到意义，并能从其他的”事实”中举证其真实性</strong>。如果他自己不能这么做，他就有义务去找能做到的人。这个人可能是牧师或祭司，或是党派中的上级指导者，或是他的教授。在任何状况中，他都必须接受对方提供给他的解决之道。他的阅读基本上是没有自由可言的。相对地，他也会获得阅读其他书所没有的一种满足感当作回报。</p><h3 id="第十九章-如何阅读社会科学">第十九章 如何阅读社会科学</h3><p>社会科学的观念与术语几乎渗透了所有我们今天在阅读的作品中。</p><p>譬如像现代的新闻记者，不再限定自己只报导事实。只有在报纸头版出现，简短的“<strong>谁——发生了什么事——为什么发生——何时何地发生</strong>“新闻提要，才是以事实为主。一般来说，记者都会将事实加上诠释评论、分析，再成为新闻报导。这些诠释与评论都是来自社会科学的观念与术语。</p><p>这些观念与术语也影响到当代许多书籍与文章，甚至可以用社会评论来作一个归类。我们也看到许多文学作品是以这类的主题来写作的：种族问题、犯罪、执法、贫穷、教育、福利、战争与和平、好政府与坏政府。这类文学作品便是向社会科学借用了思想意识与语言。</p><p>社会科学作品并不只限定于非小说类。仍然有一大批重要的当代作家所写的是社会科学的小说。</p><p>此外，无论是任何社会、经济或政治的问题，几乎全都有专家在作研究。这些专家不是自己作研究，就是由直接面对这些问题的官方单位邀请来做。在社会科学专家的协助下，这些问题有系统地阐释出来， 并要想办法解决这些问题。</p><p>社会科学的成长与普及，最重要的因素是在高中与大专教育中引进了社会科学。</p><h4 id="19-1-什么是社会科学？">19.1 什么是社会科学？</h4><p><strong>究竟社会科学是什么呢？</strong><br>有一个方法可以找出答案，就是去看看大学中将哪些学科与训练课程安排在这样的科系之下。社会科学的部门中通常包括了人类学、经济学、政治学与社会学。</p><p><strong>为什么没有包括法律、教育、商业、社会服务与公共行政呢？所有这些学科也都是运用社会科学的概念与方法才发展出来的啊？</strong><br>对于这个问题，最常见的回答是：后面这些学科的目的，在于训练大学校园以外的专业工作者，而前面所提的那些学科却是比较专注于追求人类社会的系统知识，通常是在大学校园中进行的。</p><p><strong>那么心理学呢？</strong><br>一些划分严格的社会科学家会将心理学排除在社会科学之外，因为他们认为心理学所谈的是个人的特质问题，而社会科学关心的却是文化、制度与环境因素。一些区分比较没那么严格的学者，则认为生理心理学应该归类为生物科学，而不论是正常或变态心理学则该隶属于社会科学，因为个<strong>人与社会整体是不可分割</strong>的。</p><p><strong>那么行为科学呢？他们在社会科学中担任什么样的角色？</strong><br>依照原始的用法，行为科学中包括了社会学、人类学、行为生物学、经济学、地理学、法律、心理学、精神病学与政治科学。<strong>行为科学特别强调对可观察可测量的行为作系统化的研究，以获得可被证实的发现</strong>。近年来，行为科学几乎跟社会科学变成同义词了，但许多讲究传统的人反对这样的用法。</p><p>诸如<strong>人类学、经济学、政治学、社会学的学科，都是组成社会科学的核心</strong>，几乎所有的社会科学家都会将这些学科归纳进来。</p><h4 id="19-2-阅读社会科学的容易处">19.2 阅读社会科学的容易处</h4><p>绝大部分社会科学看起来都像是非常容易阅读的作品。这些作品的内容<strong>通常取材自读者所熟悉的经验——在这方面</strong>，<strong>社会科学就跟诗与哲学一样——论说的方式也经常是叙述式的</strong>，这对读过小说与历史的读者来说都很熟悉。</p><p><strong>我们都已经很熟悉社会科学的术语，而且经常在使用</strong>。诸如文化（比较文化、反文化、次文化）、集团、疏离、地位、输入／输出、下层结构、伦理、行为、共识等很多这样的术语，几乎是现代人交谈与阅读时经常会出现的字眼。</p><p>想想”社会”，这是一个多么变色龙的词，前面不知可以加上多少形容词，但它总是在表达一种人民群居生活，而非离群索居的广阔定义。我们听到过失序的社会、不健全的社会、沉默的社会、贪婪的社会、富裕的社会……，我们可以从英文字典中第一个字母找起，最后找到“发酵的"(zymotic)社会这样的形容词——这是指持续动荡的社会，就跟我们所处的社会一样。</p><p>把“社会“看作是形容词，同样有许多熟悉的意义。像社会力量、社会压力、社会承诺，当然还有无所不在的社会问题。在阅读或写作杜会科学时，最后一种是<strong>特别容易出现的题材</strong>。</p><p>社会学家在写作时所用的术语及隐喻，加上字里行间充满深刻的情感，让我们误以为这是很容易阅读的。书中所引用的资料对读者来说是很熟悉的，的确，那是他们天天读到或听到的字眼。此外，读者的态度与感觉也都跟着这些问题的发展紧密联系在一起。<strong>对于社会科学所讨论的问题，我们都会有很强烈的意见。</strong></p><h4 id="19-3-阅读社会科学的困难处">19.3 阅读社会科学的困难处</h4><p>说来矛盾，我们前面所说的让社会科学看来很容易阅读的因素，却也是让社会科学不容易阅读的因素。譬如我们前面所提到的最后一个因素你身为一个读者，要对作者的观点投人一些看法。许多读者担心，<strong>如果承认自己与作者意见不合，而且客观地质疑自己阅读的作品，是一种对自己投入不忠的行为</strong>。但是，只要你是<strong>用分析阅读来阅读，这样的态度是必要的</strong>。我们所谈的阅读规则中已经指出了这样的态度，至少在做大纲架构及诠释作品的规则中指出过。如果你要回答阅读任何作品都该提出的头两个问题，你一定要先检查一下你自己的意见是什么。<strong>如果你拒绝倾听一位作者所说的话，你就无法了解这本书了。</strong></p><p>**社会科学中熟悉的术语及观点，同时也造成了理解上的障碍。**许多社会科学家自己很清楚这个问题。他们非常反对在一般新闻报导或其他类型的写作中，任意引用杜会科学的术语及观点。如果在你阅读的作品中，作者将一个自己都不太清楚的词句当作是关键字，那你一定也会跟着摸不着头脑的。</p><p>让我们把这个观点再说明清楚一点。我们要先把社会科学与自然科学——物理、化学等——区分出来。我们已经知道，**科学作品（指的是后面那种“科学")的作者会把假设与证明说得十分清楚，同时也确定读者很容易与他达成共识，并找到书中的主旨。<strong>因为在阅读任何论说性作品时，与作者达成共识并找到主旨是最重要的一部分，科学家的作法等于是帮你做了这部分的工作。不过你还是会发现用数学形式表现的作品很难阅读，如果你没法</strong>牢牢掌握住论述、实验，以及对结论的观察基础，**你会发现很难对这本书下评论——也就是回答”这是真实的吗？”“这本书与我何干？”的问题。然而，有一点很重要的是，<strong>阅读科学作品要比阅读任何其他论说性作品都来得容易</strong>。</p><p>换句话说，<strong>自然科学的作者必须做的是“把他的用语规定出来”</strong>——这也就是说，他告诉你，在他的论述中有哪些基本的词义，而他会如何运用。这样的说明通常会出现在书的一开头，可能是解释、假设、公理等等。<strong>在阅读自然科学的作品时，你也不会与作者争辩他的使用规则。你接受这些规则，开始阅读。</strong></p><p><strong>在自然科学中已经很普遍的用语说明，在社会科学中却仍然不太普遍</strong></p><ol><li>一个理由是——<strong>社会科学并不能数学化</strong></li><li>另一个理由是——<strong>在社会或行为科学中，要说明用语比较困难</strong></li></ol><p>阅读社会科学作品最困难的地方在于：<strong>事实上，在这个领域中的作品是混杂的，而不是纯粹的论说性作品</strong>。太多社会科学的作品混杂了科学、哲学与历史，甚至为了加强效果，通常还会带点虚构的色彩。</p><p>你还记得**分析阅读的第一个步骤是回答这个问题：这是本什么样的书？**如果是小说，这个问题相当容易回答。如果是科学或哲学作品，也不难。就算是形式混杂的历史，一般来说读者也会知道自己在读的是历史。但是组成社会科学的不同要素——有时是这种，有时是那种，有时又是另一种模式使我们在阅读任何有关社会科学的作品时，很难回答这个问题。事实上，这就跟要给社会科学下定义是同样困难的事。</p><p>不过，<strong>分析阅读的读者还是得想办法回答这个问题</strong>。这不只是他要做的第一件工作，也是最重要的工作。如果他能够<strong>说出他所阅读的这本书是由哪些要素组成的，他就能更进一步理解这本书了</strong>。</p><h4 id="19-4-阅读社会科学作品">19.4 阅读社会科学作品</h4><p><strong>在阅读社会科学时，关于一个主题通常要读好几本书，而不会只读一本书。<strong>这不只是因为社会科学是个新领域，只有少数经典作品，还因为我们</strong>在阅读社会科学时，主要的着眼点在一个特殊的事件或问题上，而非一个特殊的作者或一本书</strong>。<strong>基本上，在这些领域中，并没有什么权威的著作，因此我们必须读很多本相关的书。<strong>而社会科学家本身也有一个现象，就是</strong>为了要能跟得上时代，他们必须不断地推陈出新，重新修订他们的作品，新作品取代旧作品，过时的论述也不断被淘汰了</strong>。</p><p><strong>分析阅读的规则并不适用于就一个主题同时阅读很多本书的情况</strong>。分析阅读适用于阅读个别的书籍。当然吗如果你想要善用这些规则，就要仔细地研究观察。接下来要介绍的新的阅读规则，则需要我们 通过第三层次的阅读（分析阅读），才能进入这第四层次的阅读（主题阅读）。<strong>我们现在就准备要讨论第四层次的阅读。因为社会科学作品有这样的特质，所以必须要用这样的阅读。</strong></p><p><strong>如何阅读实用性作品，这与其他的阅读完全不同，因为读者有特定的义务，也就是如果他同意作者的观点，就要采取行动</strong>。然后我们讨论小说与诗，提出和阅读论说性作品不同的问题。最后，我们讨论的是三种理论性的论说作品科学与数学、哲学、社会科学。<strong>社会科学放在最后，是因为这样的书需要用上主题阅读。</strong></p><h2 id="第四篇-阅读的最终目标">第四篇 阅读的最终目标</h2><h3 id="第二十章-阅读的第四个层次：主题阅读">第二十章 阅读的第四个层次：主题阅读</h3><p>我们在前面提到过，<strong>在讨论某个特定的主题时，牵涉到的往往不只是一本书</strong>。我们也一再非正式地提醒过，甚至其他领域中相关的作者与书籍，都与这个特定的主题有关。</p><p><strong>在作主题阅读时：</strong></p><ol><li>第一个要求就是知道：<strong>对一个特定的问题来说，所牵涉的绝对不是一本书而已</strong>。</li><li>第二个要求则是：<strong>要知道就总的来说，应该读的是哪些书？</strong></li></ol><p>第二个要求比第一个要求还难做到。</p><p>我们在检验这个句子：”与<strong>同一个主题</strong>相关两本以上的书"时，困难就出现了。我们所说的“同一个主题”是什么意思？如果这个主题是单一的历史时期或事件，就很清楚了，但是在其他的领域中，就很难作这样清楚的区分。</p><p>你可能料到小说有这种情况。因为作品的特性，小说沟通问题的方法跟论说性作品不同。但是，论说性作品也有同样的问题。</p><p>譬如说你对“爱”这个概念很感兴趣，想要阅读相关的读物。因为关于爱的作品很广泛，你要整理出一个相关书目来阅读是有点困难的。假设你向专家求教，到一个完备的图书馆中寻找书目，还对照一位优秀学者所写的论文，终于把书目弄出来了。再假设你进一步舍弃诗人和小说家谈的这个主题，只想从论说性的作品中找答案（在后面我们会说明为什么这样的做法是明智的）。现在你开始依照书目来阅读这些书了。你发现什么？</p><p>面对如此庞大的相关资料，我们要<strong>如何决定我们要研究的主题是什么呢</strong>？我们能确定这中间只有一个单一的主题吗？就像这个问题本身的困难，在我们找到答案之前，我们能说我们已经确认了“<strong>同一个主题</strong>”吗？</p><p>你只不过读了一小部分有关爱的论说性作品，这些问题就会浮现在你脑海中，其实还有更多其他的问题会出现。无论如何，我们已经说到重点了。<strong>在做主题阅读时，会出现一种很矛盾的现象。虽然这个层次的阅读被定义为就同一个主题，阅读两种以上的书，意思也是指在阅读开始之前，这个主题就已经被确认了</strong>，但是换个角度来说，<strong>这个主题也是跟着阅读走的，而不是事前就能定出来的</strong>。以爱这个例子来说，在你决定自己要读些什么之前，你可能已经读了好几百本相关的著作了。等你都读完之后，你会发现有一半的书其实跟主题根本无关。</p><h4 id="20-1-在主题阅读中，检视阅读所扮演的角色">20.1 在主题阅读中，检视阅读所扮演的角色</h4><p>我们已经说过很多次，<strong>阅读的层次是渐进累积的</strong>。<strong>较高层次的阅读中也包括了前面的，或较低层次的阅读</strong>。在主题阅读中，我们就要说明这一点。</p><p>你可能还记得，在解说检视阅读与分析阅读的关系时，我们指出在检视阅读中的两个步骤——<strong>第一个是浏览，第二个是粗浅地阅读</strong>——也就是<strong>分析阅读的前两个步骤</strong>。</p><p><strong>浏览</strong>能帮助你准备做分析阅读的第一个步骤：<strong>你能确定自己在读的是什么主题，能说明这是什么样的书，并拟出大纲架构。</strong><br><strong>粗浅的阅读</strong>对分析阅读的第一步骤也有帮助。基本上这是进入第二步骤的准备动作。在第二个步骤中，你<strong>要能够与作者达成共识，说明他的主旨，跟随他的论述，才能够诠释整本书的内容</strong>。</p><p>同样的，<strong>检视阅读与分析阅读也可以当作是进人主题阅读的前置作业或准备动作</strong>。事实上，在这个阶段，<strong>检视阅读已经是读者在阅读时主要的工具或手段了</strong>。</p><p>举例来说，你有上百本的参考书目，看起来全是与爱有关的主题。如果你全部用<strong>分析阅读来阅读</strong>，你不只会很<strong>清楚</strong>你在<strong>研究的主题是什么——主题阅读中的“同一主题"——你还会知道你所阅读的书中，那些跟主题无关，是你不需要的书</strong>。但是要用分析阅读将一百本书读完，会花上你十年的时间。就算你能全心投注在这个研究上，仍然要花上好几个月的时间。再加上我们前面谈过的主题阅读中会出现的矛盾问题，显然必要有一些捷径。</p><p>这个捷径是要靠你的<strong>检视阅读技巧来建立</strong>的。你收集好书目之后，要做的第一件事是检视书单上所有的书。<strong>在做检视阅读之前，绝不要用分析阅读来阅读</strong>。<strong>检视阅读</strong>不会让你明白有关主题的所有错综复杂的内容，或是作者所有的洞察力，但却<strong>具有两种基本的功能</strong>。<strong>第一，它会让你对自己想要研究的主题有个清晰的概念，这样接下来你针对某几本书做分析阅读时，会大有助益。其次，它会简化你的书目到一个合理的程度。</strong></p><p><strong>对学生，尤其是研究生来说，我们很难想到还有比这更管用的方式。只要他们肯照着做，一定会有帮助。<strong>根据我们的经验，在研究生程度的学生中，确实有些人能做到主动的阅读与分析阅读。这对他们来说还不够，他们或许不是完美的读者，但是至少他们知道要如何掌握一本书的重点，能明确地说出书中的要点，并把这些观点纳入他们研究主题的一部分。但是他们的努力有一大半是浪费掉了，因为他们不知道要</strong>如何才能比别人读得快一点</strong>。他们阅读每一本书或每一篇文章都花上同样的时间与努力，结果他们该花精神好好阅读的书却没有读好，倒把时间花在那些不太值得注意的书上了。</p><p>能够<strong>熟练检视阅读的读者，不但能在心中将书籍分类，而且能对内容有一个粗浅的了解。<strong>他也会</strong>用非常短的时间就发现，这本书谈的内容对他研究的主题到底重不重要</strong>。这时他可能还不清楚哪些资料才是最重要的这可能要等到读下本书的时候才能发现。但是有两件事至少他已经知道其中之一。那就是他不是发现这本书必须回头再读一次，以获得启发，便是知道不论这本书多有趣又多丰富，却毫无启发性，因此不值得重新再读。</p><p>这个忠告通常会被忽略是有原因的。我们说过，**在分析阅读中，技巧熟练的阅读者可以同时用上许多技巧，而初学者却必须把步骤分开来。**同样的，<strong>主题阅读的准备工作——先检视书目上所有的书，在开始做分析阅读之前先检视一遍——可以在做分析阅读时一并进行</strong>。但我们不相信任何读者能做到这一点，就算技巧再熟练也不行。这也是许多年轻研究生所犯的毛病。他们自以为两个步骤可以融合为一个，结果阅读任何书都用同样的速度，对某些特殊的作品来说不是太快就是太慢，但无论如何，对他们阅读的大部分书来说，这样的方法都是不对的。</p><p><strong>一旦你检视过，确定某些书跟你研究的主题相关后，你就可以开始做主题阅读了</strong>。要注意的是，我们并没有像你以为的说：“开始做分析阅读”。当然，你需要研读每一本书，再组合起跟你主题相关的资料，你在做分析阅读时就已经学会了这些技巧。但是绝不要忘了，<strong>分析阅读的技巧只适用于单一的作品，主要的目标是要了解这本书</strong>。而我们会看到，主题阅读的目标却大不相同。</p><h4 id="20-2-主题阅读的五个步骤">20.2 主题阅读的五个步骤</h4><p>现在我们准备好要说明如何做主题阅读了。我们的假设是：<strong>你已经检视了相当多的书，你至少对其中一些书在谈些什么有点概念了，而且你也有想要研究的主题了。接下来你该怎么办？</strong></p><p>在<strong>主题阅读中一共有五个步骤</strong>。这些步骤我们不该称之为规则——虽然也许我们会因为只要漏掉其中一个步骤，主题阅读就会变得很困难，甚至读不下去了。我们会简略地介绍一下这些步骤的顺序，不过这些步骤彼此之间还是可以互相取代的。</p><p><strong>主题阅读步骤一：找到相关的章节</strong>。<br>当然，我们假设你已经学会分析阅读了，如果你愿意，你能把所有相关的书都看透彻了。但是你可能会把阅读单本的书放在第一顺位，而把自己的主题放在其次。事实上，这个顺序应该颠倒过来，<strong>在主题阅读中，你及你关心的主题才是基本的重点，而不是你阅读的书。</strong></p><p>在你已经<strong>确定哪些书是相关的之后</strong>，<strong>主题阅读的第一个步骤就是把这些书整体检视阅读一遍</strong>。你的<strong>目标是找出书中与你的主题极为相关的章节</strong>。你选择的书不太可能全本都与你的主题或问题相关。就算是如此，也一定是少数，你应该很快地把这本书读完。你不该忘了，你的阅读是别有用心的——也就是说，<strong>你是为了要解决自己的问题才阅读——而不是为了这本书本身的目的而阅读。</strong></p><p>看起来，这个步骤似乎与前面所说的，为了发现这本书是否与你主题相关的检视阅读当同一件事来进行。许多状况的确可以这么做。但是如果你认为永远都可以这么做的话，可能就不太聪明了。记住，<strong>第一步的检视阅读是要集中焦点在你要进一步做主题阅读的主题上</strong>。我们说过，除非你已经检阅过书单上大部分的书，否则你无法完全理解这个问题。因此，<strong>在确认哪些是相关的书籍的同时，还要确认哪些是相关的章节，其实是很危险的做法</strong>。除非你的技巧已经很熟练，而且对你要研究的主题已经很清楚了，否则你<strong>最好是将两部分分开来做</strong>。</p><p><strong>在主题阅读中，能够把你所阅读的第一批书，与你后来针对这个主题阅读的许多本书的差别区分出来，是很重要的事</strong>。对后来的这些书来说，你可能对自己的主题已经有了很清楚的概念，这时就可以把两种检视阅读合并在一起。但是<strong>在一开始时．却要明显地区分出来，否则你在找相关章节时会犯下严重的错误，到后来要更正这些错误时义要花上很多的时间与精力</strong>。</p><p>总之，<strong>要记得你最主要的工作不是理解整本书的内容，而是找出这本书对你的主题有什么帮助，而这可能与作者本身的写作目的相去甚远</strong>。在这个阶段的过程中，这并不重要。作者可能是在无意之间帮你解决了问题。我们已经说过，<strong>在主题阅读中，是书在服务你，而不是你在服务书</strong>。因此，<strong>主题阅读是最主动的一种阅读法</strong>。当然，<strong>分析阅读也需要主动的阅读方式</strong>。但是你<strong>在分析阅读一本书时，你就像是把书当作主人，供他使唤</strong>。而你<strong>在做主题阅读时，却一定要做书的主人</strong>。</p><p><strong>主题阅读步骤二：带引作者与你达成共识。</strong><br><strong>在诠释阅读中</strong>（分析阅读的第二步骤），<strong>第一个规则是要你与作者达成共识，也就是要能找出关键字，发现他是如何使用这些字的。<strong>但是现在你</strong>面对的是许多不同的作者</strong>，他们不可能每个人都使用同样的字眼，或相同的共识。在这时候就是要<strong>由你来建立起共识，带引你的作者们与你达成共识，而不是你跟着他们走</strong>。</p><p><strong>在主题阅读中</strong>，这可能是<strong>最困难的一个步骤</strong>。<strong>真正的困难在于要强迫作者使用你的语言，而不是使用他的语言</strong>。这跟我们一般的阅读习惯都不相同。我们也指出过很多次，我们假设：我们想要用分析阅读来阅读的作者，是比我们优秀的人。尤其如果这是一本伟大的著作时，就更可能如此。无论我们在了解他的过程中花了多少力气，我们都会倾向于接受他的词义与他安排的主题结构。但<strong>在主题阅读中，如果我们接受任何一位作者所提出来的词汇</strong>(terminology)，<strong>我们很快就会迷失</strong>。<strong>我们可能会了解他的书，却无法了解别人的书。我们也很难找到与自己感兴趣的主题的资料</strong>。</p><p>我们不只要<strong>能够坚决拒绝接受任何一位作者的词汇</strong>，还得<strong>愿意面对可能没有任何一位作者的词汇对我们来说是有用的事实</strong>。</p><p><strong>简单来说，主题阅读是一种大量的翻译工作</strong>。我们并不是将一种语言翻成另一种语言，像法语翻成英语，但是我们要将一种共通的词汇加诸在许多作者身上，无论他们所使用的是不是相同的语言，或是不是关心我们想解决的问题，是否创造了理想的词汇供我们使用。</p><p>这就是说，<strong>在进行主题阅读时，我们要建立一组词汇，首先帮助我们了解所有的作者，而不是其中一两个作者；其次帮助我们解决我们的问题</strong>。这一点认识会带我们进入第三个步骤。</p><p><strong>主题阅读步骤三：厘清问题。</strong><br><strong>诠释阅读的第二个规则是要我们找出作者的关键句子。<strong>然后</strong>从中逐步了解作者的主旨</strong>。主旨是由词义组成的，在主题阅读中，当然我们也要做同样的工作。最好的方法是<strong>先列出一些可以把我们的问题说得比较明白的问题，然后让那些作者来回答这些问题</strong>。</p><p>事实上，有时候我们<strong>必须接受作者可能一个问题也回答不了</strong>。在这样的状况中，我们<strong>必须要将他视为是对这个问题保持沉默，或是尚未作出决定</strong>。但是就算他并没有很清楚地讨论这个问题，有时我们也可以在他书中找到间接的回答。我们会得出这么一个结论：<strong>如果他考虑到这个问题的话，那就会如何如何回答这个问题</strong>。在这里<strong>需要一点自我约束</strong>。我们<strong>不能把思想强加在作者脑海中，也不能把话语放进他们的口中</strong>。但是我们也<strong>不能完全依赖他们对这个问题的解说</strong>。如果我们真的能靠其中任何一位作者来解释这个问题，或许我们根本就没有问题要解决。</p><p>我们说过要把问题照秩序排列出来，好帮助我们在研究时使用。当然，这个秩序是跟主题有关的，不过还是有一般的方向可循。第一个问题通常<strong>跟我们在研究的概念或现象的存在或特质有关</strong>。如果一位作者说这种现象的确存在，或这种概念有一种特质，那么对于他的书我们就要提出更进一步的问题了。这个问题可能跟<strong>这个现象是如何被发现，或这个概念是如何表现出来的有关</strong>。最后一部分的问题则是<strong>与回答前面问题所产生的影响有关。</strong></p><p>我们不该期望所有的作者都用同一种方法来回答我们的问题。如果他们这么做了，我们就又没有问题要解决了。那个问题会被一致的意见解决了。正因为每个作者都不相同，因此我们要再面对主题阅读的下一个步骤。</p><p><strong>主题阅读步骤四：界定议题。</strong><br>如果一个问题很清楚，如果我们也确定各个作者会用不同的方式来回答——不论赞成或反对——那么这个议题就被定义出来了。这是介于用这种方法回答问题的作者，和用另外一种（可能是相反的）方法来回答问题的作者之间的议题。</p><p>如果检验过后，所有的作者提供的答案只有正反两面的意见，那么这个问题算是简单的问题。通常，<strong>对一个问题会有超过两种以上的答案</strong>。在<strong>这种情况</strong>下，我们就要<strong>找出不同意见彼此之间的关联，再根据作者的观点来作分类。</strong></p><p><strong>当两个作者对同一个问题有相当的了解，所作的回答却完全相反或矛盾时，这才是一个真正有参与的议题</strong>。但是这样的现象并不像我们希望的那样经常发生。通常，<strong>答案之不同固然来自于各人对这个主题有不同的观点，但也有很多情况是来自于对问题本身的认知不同</strong>。所以<strong>在做主题阅读的读者，要尽可能地确保议题是大家所共同参与的</strong>。有时候这会迫使他在列出问题的时候，小心不采取任何一位作者明自采用的方法。</p><p>我们要处理的问题．<strong>可能会出现很多种不同的议题，不过通常都可以分门别类</strong>。譬如像考虑到某种概念的特质的问题，就会出现一堆相关的议题。<strong>许多议题绕着一组相互关联密切的问题打转</strong>，就会<strong>形成这个主题的争议</strong>。这样的争议可能很复杂，这时主题阅读的读者就要将所有争议的前后关系整理清楚——尽管没有任何作者做这件事。厘清争议，同时将相关议题整理出来之后，我们便要进入主题阅读的最后一个步骤。</p><p><strong>主题阅读步骤五：分析讨论。</strong><br>到目前为止，我们已经检验过作品，找出相关的章节，设定了一个不偏不倚的共识，适用于所有被检视过的作者，再设定出一整套的问题，其中大部分都能在作者的说明中找到答案。然后就不同的答案界定并安排出议题。接下来该怎么做呢?</p><p>前面四个步骤与分析阅读的前两组规则是互相辉映的。这些规则应用在任何一本书中，都会要我们<strong>回答一个问题：这本书在说些什么？是如何说明的？<strong>在</strong>主题阅读中</strong>，对于与我们的问题相关的讨论，我们<strong>也要回答类似的问题</strong>。在<strong>只阅读一本书的分析阅读</strong>中，剩下<strong>还有两个问题要回答：这是真实的吗？这与我何干？<strong>而在</strong>主题阅读</strong>中，我们对于讨论<strong>也要准备回答同样的问题</strong>。</p><p>因此，就可以发现的真理而言，就我们可以找到的问题答案而言，与其说是立足于任何一组主旨或主张上，不如说是<strong>立足于顺序清楚的讨论的本身</strong>。因此，为了要让我们的头脑接受这样的真相——也让别人接受我们要多做一点工作，不只是问问题与回答问题而已。我们要依照特定的顺序来提问题，也要能够辨认为什么是这个顺序。我们必须说明这些问题的不同答案，并说明原因。我们也<strong>一定要能够从我们检视过的书中找出支持我们把答案如此分类的根据</strong>。只有<strong>当我们做到这一切时</strong>，我们<strong>才能号称针对我们问题的讨论作了分析，也才能号称真正了解了问题</strong>。</p><p>事实上，我们所做的可能超过这些。<strong>对一个问题完整地分析过后</strong>，<strong>将来其他人对同一个问题要作研究时</strong>，我们的<strong>分析讨论就会提供他一个很好的研究基础</strong>。那会<strong>清除一些障碍，理出一条路，让一个原创性的思考者能突破困境</strong>。如果没有这个分析的工作，就没法做到这一点，因为这个问题的各个层面就无法显现出来。</p><h4 id="20-3-客观的必要性">20.3 客观的必要性</h4><p>**要完整地分析一个问题或某个主题，得指出这个讨论中的主要议题，或是一些基本的知性反对立场。**这并不是说在所有的讨论中，反对的意见总是占主导的。相反，<strong>同意或反对的意见总是互相并存的</strong>。也就是说，在大多数的议题中，正反两面的意见总是有几个，甚至许多作者在支持。在一个争议性的立场上，我们很少看到一个孤零零的支持者或反对者。</p><p>换句话说，<strong>主题阅读的目的，并不是给阅读过程中发展出来的问题提供最终答案，也不是给这个计划开始时候的问题提供最终解答</strong>。当我们要给这样的主题阅读写一份读者报告的时候，这个道理特别清楚。如果这份报告就任何所界定并分析过的重要议题，想要主张或证明某一种观点的真实或虚假，都会太过教条，失去对话的意义。如果这么做，主题阅读就不再是主题阅读，而只是讨论过程中的另一个声音，失去了疏离与客观性。</p><p>我们要说的是我们在<strong>追求理解的过程中，可以而且应该多贡献一种不同的形式</strong>。而<strong>这样的形式必须是绝对客观又公正的</strong>。<strong>主题阅读所追求的这种特质</strong>，可以用这句话来作总结：＂<strong>辩证的客观。</strong>”</p><p>简单来说，<strong>主题阅读就是要能面面俱到，而自己井不预设立场</strong>。当然，这是个严格的理想，一般人是没法做到的。而<strong>绝对的客观也不是人类所能做到的事</strong>。他可能可以做到不预设立场，毫无偏见地呈现出任何观点，对不同的意见也保持中立。但是<strong>采取中立比面面俱到要容易多了</strong>。在这一方面，主题阅读的读者注定会失败的。一个议题有各种不同的观点，不可能巨细靡遗地全都列出来。虽然如此，<strong>读者还是要努力一试</strong>。</p><p>虽然我们说<strong>保持中立要比面面俱到容易一些，但还是没那么容易</strong>。**主题阅读的读者必须抗拒一些诱惑，厘清自己的思绪。**对于某些冲突性的观点避免作出明白的真伪判断，并不能保证就能做到完全的公正客观。偏见可能会以各种微妙的方式进入你的脑海中——可能是总结论述的方式，可能是因为强调与忽略的比重，可能是某个问题的语气或评论的色彩，甚至可能因为对某些关键问题的不同答案的排列顺序。</p><p>要<strong>避免这样的危险</strong>，谨慎的<strong>主题阅读的读者可以采取一个明显的手段</strong>，<strong>尽量多加利用</strong>。那就是他要<strong>不断回头参阅诸多作者的原文，重新再阅读相关的章节</strong>。并且，<strong>当他要让更多的人能应用他的研究结果时，他必须照原作者的原文来引用他的观点或论述</strong>。虽然看起来有点矛盾，但这并不影响我们前面所说的，在分析问题时必须先建立一套中立的词汇。这样的中立语言还是必要的，而且在总结一个作者的论述时，一定要用这套中立的语言，而不是作者的语言。但是伴随着总结，<strong>一定要有仔细引用的作者原文，以免对文意有所扭曲，这样阅读者才能自己判断你对作者所作的诠释是否正确。</strong></p><p><strong>主题阅读的读者必须能够坚决地避免这个问题，才不会偏离公正客观的立场</strong>。要达到这样的理想，必须要能不偏不倚地<strong>在各种相对立的问题中保持平衡</strong>，<strong>放下一切偏见</strong>，<strong>反省自己是否有过与不及的倾向</strong>。在最后的分析中，一份主题阅读的书面报告是否达到对话形式的客观，虽然也可以由读者来判断，但只有写这份报告的人才真正明白自己是否达到这些要求。</p><h4 id="20-4-主题阅读的练习实例：进步论">20.4 主题阅读的练习实例：进步论</h4><p>在主题阅读中，要包括小说、戏剧与诗是很困难的，原因有很多个。<br>第一，<strong>故事的精髓在情节，而非对某个议题所秉持的立场</strong>。一般来说，要将小说作者的观点列入议题的某一方时需要作很多很广泛的努力。要花的努力很多，得到的结果却可能是半信半疑的，因此通常最好放弃在这方面的努力。</p><p>可以检验进步这个概念的其他许多作品，一如常见的情况，显得一片混乱。面对这样的问题，我们前面说过，就是要建立起一套中立的语句。这是一个很复杂的工作，下面的例子可以帮助我们说明这是如何进行的。</p><p>所谓“进步”一词，不同的作者有许多不同的用法。这些不同的用法，大部分显示的只是意义的轻重不同，因而可以用分析的方法来处理。但是有些作者也用这个词来指出历史上某种特定的变化，而这种变化不是改善的变化。既然大多数作者都用“进步”来指出历史上某种为了促进人类朝向更美好生活的变化，并且既然往更改善的状态的变化是这个概念的基础，那么同样的字眼就不能适用于两种相反的概念了。因此，本例我们取大多数人的用法，那些主张历史上“非关改善的进展"(non-meliorative advance)的作者，就只好划为少数派了。我们这么说的目的是，在讨论这些少数作者的观点时，<strong>就算他们自己运用了“进步”这样的字眼，我们也不能将他们纳入“进步”的概念中</strong>。</p><p>我们前面说过，<strong>主题阅读的第三步是厘清问题</strong>。在“进步”的例子中，我们对这个问题一开始的直觉，经过检验之后，证明是正确的。第一个要问的问题，也是各个作者被认为提供各种不同答案的问题，是“历史上真的有‘进步’这回事吗？”说历史的演变整体是朝向改善人类的生存条件，的确是事实吗？基本上，对这个问题有三种不同的回答：(1)是(2)否(3)不知道。然而，回答“是“可以用许多不同的方式来表达，回答“否”也有好几种说法，而说“不知道”也至少有三种方式。</p><p><strong>对这个基本问题所产生的各式各样相互牵连的答案，构成我们所谓关于进步的一般性争议</strong>。所谓一般性，是因为我们研究的每个作者，只要对这个主题有话要说，就会在这个主题所界定的各个议题上选边站。但是对于进步还有一种特殊的争论，参与这种议题的，都是一些主张进步论的作者——这些作者主张进步确实发生。身为进步论的作者，他们全都强调进步是一种历史的事实，而所有的议题都应该和进步的本质或特质相关。这里的议题其实只有三种，只是个别讨论起来都很复杂。<br>这三个议题我们可以用问题的形式来说明：<br>(1)  进步是必要的？还是要取决于其他事件?<br>(2)  进步会一直无止境地持续下去？还是会走到终点或高原期而消失?<br>(3)  进步是人类的天性，还是养成的习惯——来自人类动物的本能，或只是外在环境的影响？</p><p>最后，就<strong>进步发生的面向</strong>而言，还有一些次要议题，不过，这些议题仍然只限于在主张进步论的作者之间。有六个面向是某些作者认为会发生，另外有些作者虽然多少会反对其中一两个的发生，但不会全部反对（因为他们在定义上就是肯定进步发生的作者）。这六个面向是：<br>(1)  <strong>知识的进步</strong><br>(2)  <strong>技术的进步</strong><br>(3)  <strong>经济的进步</strong><br>(4)  <strong>政治的进步</strong><br>(5)  <strong>道德的进步</strong><br>(6)  <strong>艺术的进步</strong><br>关于最后一项有些特殊的争议。因为在我们的观点里，没有一位作者坚信在这个面向中真的有进步，甚至有些作者否认这个面向有进步。</p><p>我们列举出“进步”的分析架构，只是要让你明白，在这个主题中包含了多少的议题，与对这些讨论的分析——换句话说，这也是主题阅读的第四及第五个步骤。<strong>主题阅读的读者必须做类似的工作才行</strong>，当然，<strong>他用不着非得就自己的研究写一本厚厚的书不可</strong>。</p><h4 id="20-5-如何应用主题工具书">20.5 如何应用主题工具书</h4><p>如果你仔细阅读过本章，你会注意到，虽然我们花了不少时间谈这件事，但我们并没有解决主题阅读中的矛盾问题。这个<strong>矛盾</strong>可以说明如下：<strong>除非你知道要读些什么书，你没法使用主题阅读。但是除非你能做主题阅读，否则你不知道该读些什么书。<strong>换句话说，这可以算是</strong>主题阅读中的根本问题</strong>。也就是说，<strong>如果你不知道从何开始，你就没法做主题阅读</strong>。就算你对如何开始有粗浅的概念，你花在寻找相关书籍与篇章的时间，远超过其他步骤所需时间的总和。</p><p>当然，至少理论上有一种方法可以解决这个矛盾的问题。理论上来说，你可以对我们传统中的主要经典作品有一番完整的认识，对每本书所讨论的各种观念都有相当的认知。如果你是这样的人，就根本用不着任何人帮忙，我们在主题阅读上也没法再多教给你什么了。</p><p>从另一个角度来看，就算你本身没有这样的知识，你还是<strong>可以找有这种知识的人帮忙</strong>。但<strong>你要认清一点，就算你能找到这样的人，他的建议最后对你来说，在帮助的同时，几乎也都会变成障碍</strong>。如果那个主题<strong>正好是他做过特殊研究</strong>的，对他来说就很难只告诉你哪<strong>些章节是重要相关</strong>的，而不告诉你该如何读这些书——而这一点很可能就造成你的<strong>阻碍</strong>。但是<strong>如果他并没有针对这个主题做过特殊的研究，他知道的也许还没有你多</strong>——尽管你们双方都觉得应该比你多。</p><p>因此，你需要的是一本工具书，能告诉你在广泛的资料当中，到哪里去找与你感兴趣的主题相关的章节，而用不着花时间教你如何读这些章节——也就是对这些章节的意义与影响不抱持偏见。</p><p>当然，<strong>主题工具书</strong>有一个主要的缺点。这仍然是一套书目的索引（尽管是很大的一套），至于这套书没有包含的其他作品里什么地方可以找到你要的东西，则<strong>只有一些粗略的指引</strong>。不过，<strong>不管你要做哪一类主题阅读，这套书至少总能帮助你知道从何处着手</strong>。同时，<strong>在这整套名著中的书，不论是关于哪个主题，也都是你真的想要阅读的书</strong>。因此，<strong>主题工具书</strong>能帮助成熟的学者，或刚开始研究特定问题的初学者<strong>节省许多基本的研究工具</strong>，<strong>能让他很快进人重点，开始做独立的思考</strong>。因为他<strong>已经知道前人的思想是什么了。</strong></p><p>主题工具书对这种研究型的读者很有帮助，而且对初学者更有助益。主题工具书能从三方面帮助刚开始做研究的人：<strong>启动阅读，建议阅读，指导阅读</strong>。</p><p><strong>在启动阅读方面</strong>，主题工具书能帮助我们在面对传统经典作品时，克服最初的困难。这些作品都有点吸引力，我们都很想读这些书，但往往做不到。我们听到很多建议，要我们从不同的角度来阅读这样的书，而且有不同的阅读进度，从简单的作品开始读，再进展到困难的作品。但是所有这类阅读计划都是要读完整本书，或是至少要读完其中的大部分内容。就一般的经验来说，这样的解决方案很少能达到预期的效果。</p><p>对于这类经典巨著，使用主题阅读再加上主题工具书的帮助，就会产生完全不同的解决方案。<strong>主题工具书可以帮读者就他们感兴趣的主题，启动他对一些经典著作的阅读</strong>——在这些主题上，<strong>先阅读来自大量不同作者的一些比较短的章节</strong>。这可以<strong>帮助我们在读完这些经典著作之前，先读进去</strong>。</p><p>使用主题阅读来阅读经典名著，再加上主题工具书的帮助，还能提供我们许多建议。<strong>读者一开始阅读是对某个主题特别感兴趣，但是会逐渐激发出对其他主题的兴趣。而一旦你开始研究某位作者，就很难不去探索他的上下文</strong>。就在你明白过来之前，这本书你已经读了一大半了。</p><p>最后，主题阅读加上主题工具书，还能从<strong>三种不同的方向指导关系</strong>。事实上这是这个层次的阅读最有利的地方。</p><p><strong>第一，读者阅读的章节所涉及的主题，能够给他一个诠释这些章节的方向。<strong>但这并不是告诉他这些章节是什么意思，因为一个章节可能从好几个或许多个方向与主题相关。而读者的责任就是要</strong>找出这个章节与主题真正相关的地方在哪里</strong>。要学习这一点，需要拥有很重要的阅读技巧。</p><p><strong>第二，针对同一个主题，从许多不同的作者与书籍中收集出来的章节，能帮助读者强化对各个章节的诠释能力。<strong>有时候我们从同一本书中依照顺序来阅读的章节，以及</strong>挑出来比对阅读的章节，相互对照之下可以让我们更了解其中的含意</strong>。有时候从不同书中摘出来的章节是互相冲突的，但是当你读到彼此冲突的论点时，就会更明白其中的意义了。有时候从一个作者的书中摘出来的章节，由另一个作者的书的某个章节作补充或评论，实际上可以帮助读者对第二位作者有更多的了解。</p><p>**第三，如果主题阅读运用在许多不同的主题上，当你发现同一个章节被主题工具书引述在许多不同主题之下的时候，这件事情本身就很有指导阅读的效果。**随着读者针对不同的主题要对这些章节进行多少不同的诠释，他会发现这些章节含有丰富的意义。<strong>这种多重诠释的技巧，不只是阅读技巧中的基本练习，同时也会训练我们的头脑面对任何含义丰富的章节时，能习惯性地作出适当的调整。</strong></p><p>因为我们相信，<strong>对想做这个层次的阅读的读者来说，无论他是资深的学者或初学者，主题工具书都很有帮助，因此我们称这一阅读层次为主题阅读</strong>。我们希望读者能原谅我们一点点的自我耽溺。为了回报您的宽容，我们要指出很重要的一点。</p><p><strong>主题阅读</strong>可以说有<strong>两种</strong>：</p><ol><li>一种是<strong>单独使用的主题阅读</strong></li><li>一种是<strong>与主题工具一起并用</strong><br><strong>后一种可以当作是构成前一种阅读计划的一部分</strong>，一开始<strong>由这里着手</strong>，是<strong>最聪明的做法</strong>。 而前一种主题阅读所应用的范围要比后一种广义许多。</li></ol><h4 id="20-6-构成主题阅读的原则">20.6 构成主题阅读的原则</h4><p>当然，我们对所有这些指控都不同意，我们要依序回答这些指控。让我们一次谈一个。<br>**第一，是关于词汇的问题。**否认一个概念可以用不同的词汇来说明，就像否认一种语言可以翻译成另一种语言。当然，这样的否认是刻意制造出来的。譬如最近我们阅读（《古兰经》的一个新译本，前言一开始便说要翻译（《古兰经》是不可能的事。但是因为译者接着又解释他是如何完成的，所以我们只能假设他的意思是：要翻译这样一本被众人视为神圣的典籍，是一件极为困难的事。我们也同意。<strong>不过困难并不代表做不到。</strong></p><p>事实上，所谓作者本身的词汇是神圣不可侵犯的说法，其实只是在说要将一种说法翻译成另一种说法是非常困难的。这一点我们也同意。但是，<strong>同样的，困难并非不可能做到。</strong></p><p>**其次．谈到作者各自区隔与独立的特性。**这就像说有一天亚里士多德走进我们办公室（当然穿着长袍），身边跟着一位又懂现代英语又懂古希腊语的翻译，而我们却无法听懂他讲什么，他也无法听懂我们讲什么一样。我们不相信有这回事。毫无疑问，亚里士多德对他看到的许多事一定觉得很讶异，但我们确信在十分钟之内，只要我们想，我们就能跟他一起讨论某个我们共同关心的问题。<strong>对于一些特定的概念一定会发生困难，但是只要我们能够发现，就能解决。</strong></p><p>如果这是可行的（我们不认为任何人会否认），那么让一本书经由翻译——也就是主题阅读的读者——与另一本书的作者”谈话“，并不是不可能的事。当然，这需要很谨慎，而且你要把双方的语言——也就是两本书的内容——了解得越透彻越好。<strong>这些问题并非不能克服，如果你觉得无法克服只是在自欺欺人。</strong></p><p>**最后，谈到风格的问题。**我们认为，这就像是说人与人之间无法作理性的沟通，而只能作情绪上的沟通——就像你跟宠物沟通的层次。</p><p>如果你用很愤怒的腔调对你的狗说：“我爱你！＂它会吓得缩成团，并不知道你在说什么。有谁能说：人与人之间的语言沟通，除了语气与姿势外就没有其他的东西？说话的语气是很重要的——尤其当沟通的主要内容是情绪关系的时候；而当我们只能听（或者看？）的时候，肢体语言中可能就有些要告诉我们的事情。但是人类的沟通，不只这此东西。如果你问一个人出口在哪里？他告诉你沿着B走廊就会看到。这时他用的是什么语气并不重要。他可能对也可能错，可能说实话也可能撒谎，但是重点在你沿着B走廊走，很快就能找到出口了。你知道他说的是什么，也照着做了，这跟他如何说这句话一点关系也没有。</p><p>只要<strong>相信翻译是可行的</strong>（因为人类一直在做这件事），<strong>书与书之间就能彼此对谈</strong>（因为人类也一直在这么做）。<strong>只要愿意这么做，人与人之间也有理性客观的沟通能力</strong>（因为我们能彼此互相学习），所以我们相信主题阅读是可行的。</p><h4 id="20-7-主题阅读精华摘要">20.7 主题阅读精华摘要</h4><p>我们已经谈完主题阅读了。让我们将这个层次的阅读的每个步骤列举出来。<br>我们说过，在主题阅读中有两个阶段。<br><strong>一个是准备阶段，另一个是主题阅读本身</strong>。让我们复习一下这些不同的步骤：</p><p><strong>一、观察研究范围：主题阅读的准备阶段</strong><br>(1)  <strong>针对你要研究的主题，设计一份试验性的书目。<strong>你可以参考图书馆目录、专家的建议与书中的书目索引。<br>(2)  <strong>浏览这份书目上所有的书</strong>，<strong>确定哪些与你的主题相关</strong>，并</strong>就你的主题建立起清楚的概念</strong>。</p><p><strong>二、主题阅读：阅读所有第一阶段收集到的书籍</strong><br>(1)  <strong>浏览所有在第一阶段被认定与你主题相关的书，找出最相关的章节。</strong><br>(2)  <strong>根据主题创造出一套中立的词汇，带引作者与你达成共识</strong>——无论作者是否实际用到这些词汇，所有的作者，或至少绝大部分的作者都可以用这套词汇来诠释。<br>(3)  <strong>建立一个中立的主旨，列出一连串的问题无论作者是否明白谈过这些问题</strong>，所有的作者，或者<strong>至少大多数的作者都要能解读为针对这些问题提供了他们的回答。</strong><br>(4)  **界定主要及次要的议题。<strong>然后</strong>将作者针对各个问题的不同意见整理陈列在各个议题之旁。**你要记住，各个作者之间或之中，不见得一定存在着某个议题。有时候，你需要针对一些不是作者主要关心范围的事情，把他的观点解读，才能建构出这种议题。<br>(5)  <strong>分析这些讨论。<strong>这得</strong>把问题和议题按顺序排列，以求突显主题</strong>。<strong>比较有共通性的议题，要放在比较没有共通性的议题之前</strong>。<strong>各个议题之间的关系也要清楚地界定出来。</strong></p><p><strong>注意：<strong>理想上，<strong>要一直保持对话式的疏离与客观</strong>。要做到这一点，每</strong>当你要解读某个作家对一个议题的观点时，必须从他自己的文章中引一段话来并列。</strong></p><h3 id="第二十一章-阅读与心智的成长">第二十一章 阅读与心智的成长</h3><p>我们已经完成了在本书一开始时就提出的内容大要。我们已经说明清楚，<strong>良好的阅读基础在于主动的阅读。阅读时越主动，就读得越好。</strong></p><p><strong>所谓主动的阅读，也就是能提出问题来</strong>。我们也指出在阅读任何一本书时该<strong>提出什么样的问题</strong>，以及<strong>不同种类的</strong>书必须<strong>怎样以不同的方式回答这些问题。</strong></p><p>我们也区分并讨论了阅读的四种层次，并说明这<strong>四个层次是累积渐进的，前面或较低层次的内容包含在后面较高层次的阅读里</strong>。接着，我们刻意强调后面较高层次的阅读，而比较不强调前面较低层次的阅读。因此，我们特别<strong>强调分析阅读与主题阅读</strong>。因为对大多数的读者来说，分析阅读可能是最不熟悉的一种阅读方式，我们特别花了很长的篇幅来讨论，定出规则，并说明应用的方法。不过分析阅读中的所有规则，只要照最后一章所说的略加调整，就同样适用于接下来的主题阅读。</p><p>我们完成我们的工作了，但是你可能还没有完成你的工作。我们用不着再提醒你，这是一本实用性的书，或是阅读这种书的读者有什么特殊的义务。我们认为，<strong>如果读者阅读了一本实用的书，并接受作者的观点，认同他的建议是适当又有效的，那么读者一定要照着这样的建议行事。<strong>你可能不接受我们所支持的</strong>主要目标</strong>——也就是你<strong>应该有能力读得更透彻</strong>——也不同意我们建议达到目标的方法——也就是<strong>检视阅读、分析阅读与主题阅读的规则</strong>。（但如果是这样，你可能也读不到这一页了。）不过如果你<strong>接受这个目标</strong>，也<strong>同意这些方法是适当的</strong>，那你就<strong>一定要以自己以前可能从没有经历过的方式来努力阅读了。</strong></p><h4 id="21-1-好书能给我们什么帮助">21.1 好书能给我们什么帮助</h4><p>“手段"(means)这两个字可以解释成两种意义。在前面的章节中，我们将<strong>手段当作是阅读的规则</strong>，也就是<strong>使你变成一个更好的阅读者的方法</strong>。但是<strong>手段也可以解释为你所阅读的东西</strong>。空有方法却没有可以运用的材料，就和空有材料却没有可以运用的方法一样是毫无用处的。</p><p>以“手段”的后一种意思来说，<strong>未来提升你阅读能力的手段其实是你将阅读的那些书</strong>。我们说过**，这套阅读方法适用于任何一本**，以及任何一种你所阅读的书——无论是小说还是非小说，想像文学还是论说性作品，实用性还是理论性。但是事实上，起码就我们在探讨分析阅读与主题阅读过程中所显示的这套方法<strong>井不适用于所有的书</strong>。原因是<strong>有些书根本用不上这样的阅读</strong>。</p><p>我们在前面已经提过这一点了，但我们想要再提一遍，因为这与你马上要做的工作有关。**如果你的阅读目的是想变成一个更好的阅读者，你就不能摸到任何书或文章都读。**如果你所读的书都在你的能力范围之内，你就没法提升自己的阅读能力。<strong>你必须能操纵超越你能力的书</strong>，或像我们所说的，<strong>阅读超越你头脑的书</strong>。<strong>只有那样的书能帮助你的思想增长。除非你能增长心智，否则你学不到东西。</strong></p><p>因此，对你来说最重要的是，你<strong>不只要能读得好，还要有能力分辨出哪些书能帮助你增进阅读能力</strong>。</p><p>我们说过很多次，<strong>一个好的读者也是自我要求很高的读者</strong>。他<strong>在阅读时很主动，努力不懈</strong>。现在我们要谈的是另外一些观念。你想要用来练习阅读技巧，尤其是分析阅读技巧的书，一定要对你也有所要求**。这些书<strong>一定要</strong>看起来是超越你的能力才行**。你大可不必担心真的如此，**只要你能运用我们所说的阅读技巧，没有一本书能逃开你的掌握。**当然，这并不是说所有的技巧可以一下子像变魔术一样让你达到目标。<strong>无论你多么努力，总会有些书是跑在你前面的。事实上，这些书就是你要找的书，因为它们能让你变成一个更有技巧的读者。</strong></p><p>有些读者会有错误的观念，以为那些书——对读者的阅读技巧不断提出挑战的书籍——都是自己不熟悉的领域中的书。结果一般人都相信，对大多数读者来说，只有科学作品，或是哲学作品才是这种书。但是事实并非如此。我们已经说过，<strong>伟大的科学作品比一些非科学的书籍还要容易阅读，因为这些科学作者很仔细地想要跟你达成共识，帮你找出关键主旨，同时还把论述说明清楚</strong>。在文学作品中，找不到这样的帮助，所以长期来说，那些书才是要求最多，最难读的书。譬如从许多方面来说，荷马的书就比牛顿的书难读——尽管你在第一次读的时候，可能对荷马的体会较多。荷马之所以难读，是因为他所处理的主题是很难写好的东西。</p><p>我们在这里所谈的困难，跟阅读一本烂书所谈的困难是不同的。<strong>阅读一本烂书</strong>也是很困难的事，因为那样的书<strong>会抵消你为分析阅读所作的努力</strong>，每当你认为能掌握到什么的时候又会溜走。事实上，<strong>一本烂书根本不值得你花时间去努力，甚至根本不值得作这样的尝试。你努力半天还是一无所获</strong>。</p><p>读一本好书，却会计你的努力有所回报。最好的书对你的回馈也最多。当然，<strong>这样的回馈分成两种：</strong><br><strong>第一</strong>，当<strong>你成功地阅读了一本难读的好书</strong>之后，你的<strong>阅读技巧必然增进了。</strong><br><strong>第二</strong>，长期来说这一点更重要——<strong>一本好书能教你了解这个世界以及你自己。<strong>你</strong>不只更懂得如何读得更好，还更懂得生命</strong>。你<strong>变得更有智慧</strong>，而不只是更有知识——像只提供讯息的书所形成的那样。<strong>你会成为一位智者，对人类生命中永恒的真理有更深刻的体认。</strong></p><p><strong>伟大的经典就是在帮助你把这些问题像的更清楚一点，因为这些书的作者都是比一般人思想更深刻的人。</strong></p><h4 id="21-2-书的金字塔">21.2 书的金字塔</h4><p>**西方传统所写出的几百万册的书籍中，百分之九十九都对你的阅读技巧毫无帮助。**这似乎是个令人困恼的事实，不过连这个百分比也似乎高估了。但是，想想有这么多数量的书籍，这样的估算还是没错。有许多书只能当作娱乐消遣或接收资讯用。娱乐的方式有很多种，有趣的资讯也不胜枚举，但是你别想从中学习到任何重要的东西。<strong>事实上，你根本用不着对这些书做分析阅读。扫描一下便够了。</strong></p><p><strong>第二种类型的书籍是可以让你学习的书——学习如何阅读，如何生活。<strong>只有百分之一，千分之一，甚或万分之一的书籍合乎这样的标准。<strong>这些书是作者的精心杰作，所谈论的也是人类永远感兴趣，又有特殊洞察力的主题。<strong>这些书可能不会超过几千本，对读者的要求却很严苛，<strong>值得做一次分析阅读</strong>——一次。如果你的技巧很熟练了，<strong>好好地阅读过一次</strong>，你就能</strong>获得所有要获得的主要概念</strong>了。你把这本书读过一遍，便可以放回架上。你知道你用不着再读一遍，但你可能要</strong>常常翻阅，找出一些特定的重点，或是重新复习一下一些想法或片段</strong>。（你<strong>在这类书中的空白处所做的一些笔记</strong>，对你会特别有帮助。）</p><p><strong>你怎么知道不用再读那本书了呢？</strong><br>因为你<strong>在阅读时，你的心智反应已经与书中的经验合而为一</strong>了。这样的书会<strong>增长你的心智，增进你的理解力</strong>。就在<strong>你的心智成长，理解力增加之后</strong>，你<strong>了解到</strong>——这是多少有点<strong>神秘的经验</strong>——这本书对你以后的心智成长不会再有帮助了。你知道你已经<strong>掌握这本书的精髓</strong>了。你将<strong>精华完全吸</strong>收了。你很感激这本书对你的贡献，但你知道它能付出的仅止于此了。</p><p>在几千本这样的书里，还有更少的一些书——很可能不到一百种——却是你读得再通，也不可能尽其究竟。你要如何分辨哪些书是属于这一类的呢？这又是有点神秘的事了，不过当你<strong>尽最大的努力用分析阅读读完</strong>一本书，把书放回架上的时候，你心中会有点疑惑，好像还也有什么你没弄清楚的事。我们说“疑惑＂，是因为在这个阶段可能仅只是这种状态。<strong>如果你确知你错过了什么，身为分析阅读者，就有义务立刻重新打开书来，厘清自己的问题是什么</strong>。事实上，你没法一下子指出问题在哪里，但你知道在哪里。你会发现自己忘不了这本书，一直想着这本书的内容，以及自己的反应。最后，你又<strong>重看一次</strong>。然后<strong>非常特殊的事就发生</strong>了。</p><p>如果这本书是属于前面我们所说第<strong>二种类型的书</strong>，重读的时候，你会发现<strong>书中的内容好像比你记忆中的少了许多</strong>。当然，原因是<strong>在这个阶段中你的心智成长了许多</strong>。你的头脑充实了，理解力也增进了。书籍本身并没有改变，改变的是你自己。这样的重读，无疑是计人失望的。</p><p>但是如果这本书是属于更高层次的书——只占浩瀚书海一小部分的书——你在重读时会发现<strong>这本书好像与你一起成长了</strong>。你<strong>会在其中看到新的事物</strong>——<strong>一套套全新的事物</strong>——那是你<strong>以前没看到的东西</strong>。你<strong>以前对这本书的理解并不是没有价值</strong>（假设你第一次就读得很仔细了），<strong>真理还是真理</strong>．<strong>只是过去是某一种面貌，现在却呈现出不同的面貌</strong>。</p><p>一本书怎么会跟你一起成长呢？当然这是不可能的。<strong>一本书只要写完出版了，就不会改变了。<strong>只是你到这时才会开始明白，你最初阅读这本书的时候，这本书的层次就远超过你，现在你重读时仍然超过你，未来很可能也一直超过你。因为这是</strong>一本真正的好书</strong>——我们可说是<strong>伟大的书——所以可以适应不同层次的需要</strong>。你<strong>先前读过的时候感到心智上的成长，并不是虚假的</strong>。那本书的确<strong>提升了你</strong>。但是现在，<strong>就算你已经变得更有智慧也更有知识，这样的书还是能提升你，而且直到你生命的尽头</strong>。</p><p>显然并没有很多书能为我们做到这一点。我们评估这样的书应该少于一百本。但<strong>对任何一个特定的读者来说，数目还会更少</strong>。<strong>人类除了心智力最的不同之外，还有许多其他的不同</strong>。**他们的品味不同，同一件事对这个人的意义就大过对另一个人。**你对牛顿可能就从没有对莎士比亚的那种感觉，这或许是因为你能把牛顿的书读得很好，所以用不着再读一遍，或许是因为数学系统的世界从来就不是你能亲近的领域。如果你喜欢数学——像达尔文就是个例子——牛顿跟其他少数的几本书对你来说就是伟大的作品，而不是莎士比亚。</p><p>我们并不希望很权威地告诉你，哪些书对你来说是伟大的作品。不过在我们的第一个附录中，我们还是列了一些清单，因为根据我们的经验，这些书对许多读者来说都是很有价值的书。我们的重点是，<strong>你该自己去找出对你有特殊价值的书来</strong>。这样的书能<strong>教你很多关于阅读与生命的事情</strong>。这样的书你会想一读再读。这也是会帮助你不断成长的书。</p><h4 id="21-3-生命与心智的成长">21.3 生命与心智的成长</h4><p>有一种很古老的测验——上一个世纪很流行的测验——目的在于帮你找出对你最有意义的书目。测验是这样进行的：如果你被警告将在一个无人荒岛度过余生，或至少很长的一段时间，而假设你有时间作一些准备，可以带一些实际有用的物品到岛上，还能带十本书去，你会选哪十本？</p><p>试着列这样一份书单是很有指导性的，这倒不只是因为可以帮助你发现自己最想一读再读的书是哪些。事实上，和另外一件事比起来，这一点很可能是微不足道的。那件事就是：当你想像自已被隔绝在一个没有娱乐、没有资讯、没有可以理解的一般事物的世界时，比较起来你是否会对自己了解得更多一点？记住，岛上没有电视也没有收音机，更没有图书馆，只有你跟十本书。</p><p>你开始想的时候，会觉得这样想像的情况有点稀奇古怪，不太真实。当真如此吗？我们不这么认为。<strong>在某种程度上，我们都跟被放逐到荒岛上的人没什么两样。<strong>我们面对的都是</strong>同样的挑战——如何找出内在的资源，过更美好的人类生活的挑战。</strong></p><p><strong>人类的心智有很奇怪的一点，主要是这一点划分了我们心智与身体的截然不同。<strong>我们的</strong>身体是有限制的，心智却没有限制</strong>。其中一个迹象是，<strong>在力量与技巧上，身体不能无限制地成长</strong>。人们到了30岁左在身体状况就达到了巅峰，<strong>随着时间的变化，身体的状况只有越来越恶化，而我们的头脑却能无限地成长与发展下去</strong>。我们的心智不会因为到了某个年纪死就停止成长，只有当大脑失去活力，僵化了，才会失去了增加技巧与理解力的力量。</p><p>这是人类最明显的特质，也是万物之灵与其他动物最主要不同之处。其他的动物似乎发展到某个层次之后，便不再有心智上的发展。但是人<strong>类独有的特质，却也潜藏着巨大的危险</strong>。<strong>心智就跟肌肉一样，如果不常运用就会萎缩。</strong> <strong>心智的萎缩就是在惩罚我们不经常动脑</strong>。这是个可怕的惩罚，因为证据显示，<strong>心智萎缩也可能要人的命</strong>。除此之外，似乎也没法说明为什么<strong>许多工作忙碌的人一旦退休之后就会立刻死亡</strong>。他们<strong>活着是因为工作对他们的心智上有所要求，那是一种人为的支撑力量，也就是外界的力量</strong>。<strong>一旦外界要求的力量消失之后，他们又没有内在的心智活动，他们便停止了思考，死亡也跟着来了</strong>。</p><p>电视、收音机及其他天天围绕在我们身边的娱乐或资讯，也都是些人为的支撑物。它们会让我们觉得自己在动脑，因为我们要<strong>对外界的刺激作出反应</strong>。但是<strong>这些外界刺激我们的力量毕竟是有限的</strong>。像药品一样，一旦习惯了之后，需要的量就会越来越大。到最后，这些力量就只剩下一点点，甚或毫无作用了。这时，<strong>如果我们没有内在的生命力量，我们的智力、品德与心灵就会停止成长。当我们停止成长时，也就迈向了死亡。</strong></p><p><strong>好的阅读，也就是主动的阅读，不只是对阅读本身有用，也不只对我们的工作或事业有帮助，更能帮助我们的心智保持活力与成长。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第二章 Python基础语法</title>
      <link href="/2020/05/02/di_er_zhang_python_ji_chu_yu_fa/"/>
      <url>/2020/05/02/di_er_zhang_python_ji_chu_yu_fa/</url>
      
        <content type="html"><![CDATA[<h2 id="第二章-Python-基础语法">第二章 Python 基础语法</h2><h3 id="1、Python-常用数据类型">1、Python 常用数据类型</h3><ol><li>在 Python 中变量不直接存储值，而是存储值的内存地址或者引用。</li><li>在 Python 中，不需要事先声明变量名及其类型，使用赋值语句可以直接创建任意类型的变量，变量的类型取决于等号右侧表达式的类型。</li><li>赋值（比如a=‘ABC’）时，Python 解释器干了两件事：<br>1）在内存中创建一个 ‘ABC’ 的字符串<br>2）在内存中创建一个名为 a 的变量，并把它指向 ‘ABC’</li></ol><h3 id="2、Python-的核心数据类型">2、Python 的核心数据类型</h3><h4 id="2-1-Number（数字）">2.1 Number（数字）</h4><p>Python支持int,float,complex三种不同的数字类型</p><pre><code class="highlight plaintext">a = 3b = 3.14c = 3+4jprint(type(a),type(b),type(c))isinstance(a, int)</code></pre><p><strong>结果：</strong><br>&lt;class ‘int’&gt; &lt;class ‘float’&gt; &lt;class ‘complex’&gt;<br>True</p><p><strong>示例代码</strong></p><pre><code class="highlight plaintext">import math print(math.factorial(32))# 计算32的阶乘print(0.4-0.3 == 0.1)# 实数之间尽量避免直接比较大小print(math.isclose(0.4-0.3, 0.1))# 测试两个实数是否足够接近c = 3+4j# Python内置支持复数及其运算print(c+c)# 复数相加print(c.real)# 查看复数的实部print(c.imag)# 查看复数的虚部print(3+4j.imag)# 相当于3+(4j).imag</code></pre><p><strong>结果：</strong><br>263130836933693530167218012160000000<br>False<br>True<br>(6+8j)<br>3.0<br>4.0<br>7.0</p><h4 id="2-2-String（字符串）">2.2 String（字符串）</h4><ol><li>Python 中的字符串可以使用单引号、双引号和三引号（三个单引号或三个双引号）括起来，使用反斜杠<code>\</code>转义特殊字符。</li><li>Python3 源码文件默认以UTF-8编码，所有字符串都是 unicode 字符串</li><li>支持字符串拼接、截取等多种运算</li></ol><pre><code class="highlight plaintext">a = "Hello"b = "Python"print("a+b 输出结果：", a+b)print("a[1:4] 输出结果：", a[1:4])</code></pre><p><strong>结果：</strong><br>a+b 输出结果： HelloPython<br>a[1:4] 输出结果： ell</p><p><strong>示例代码</strong></p><pre><code class="highlight plaintext">text = '''Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.'''print(len(text))    # 字符串长度，即所有字符的数量print(text.count('is'))# 字符串中单词is出现的次数print('beautiful' in text)# 测试字符串中是否包含单词beautifulprint('='*20)        # 字符串重复print('Good'+'Morning')    # 字符串连接</code></pre><p><strong>结果：</strong><br>208<br>6<br>False<br><code>====================</code><br>GoodMorning</p><h4 id="2-3-List（列表）">2.3 List（列表）</h4><ol><li>列表可以完成大多数集合类的数据结构实现，列表中元素的类型可以不相同，它支持数字，字符串甚至可以包含列表（所谓嵌套）。</li><li>列表是写在方括号<code>[]</code>之间，用逗号分隔开的元素列表。</li><li>列表索引值以<code>0</code>位开始值，<code>-1</code>为从末尾的开始位置。</li><li>列表可以使用<code>+</code>操作符进行拼接，使用<code>*</code> 表示重复。</li></ol><pre><code class="highlight plaintext">list = ['abcd', 786, 2.23, 'runoob', 70.2]print(list[1:3])tinylist = [123, 'runoob']print(list + tinylist)</code></pre><p><strong>结果：</strong><br>[786, 2.23]<br>[‘abcd’, 786, 2.23, ‘runoob’, 70.2, 123, ‘runoob’]</p><h4 id="2-4-Tuple（元组）">2.4 Tuple（元组）</h4><ol><li>tuple 与 list 类似，不同之处在于tuple的元素不能修改。tuple 写在小括号里，元素之间用逗号隔开。</li><li>元组的元素不可变，但可以包含可变对象，如 list。<br>"注意: " 定义一个只有一个元素的 tuple，<code>必须加逗号</code>。</li></ol><pre><code class="highlight plaintext">t = ('abcd', 786, 2.23, 'runoob', 70.2)t1 = (1,)t2 = ('a','b',['A','B'])t[2][0] = 'X't</code></pre><p><strong>结果：</strong><br>(‘a’,‘b’,[‘’,‘B’])</p><h4 id="2-5-dict（字典）">2.5 dict（字典）</h4><ol><li>字典是无序的对象集合，使用键-值（key-value）存储，具有极快的查找速度。</li><li>键（key）必须使用不可变类型。</li><li>同一字典中，键（key）必须是唯一的。</li></ol><pre><code class="highlight plaintext">d = {'Michael':95, 'Bob':75, 'Tracy':85}d['Michael']</code></pre><p><strong>结果：</strong><br>95</p><h4 id="2-6-set（集合）">2.6 set（集合）</h4><ol><li>set 和 dict 类似，也是一组 key 的集合，但不存储 value，由于 key 不能重复，所以，在 set 中，没有重复的 key.</li><li>set是无序的，重复元素在 set 中自动被过滤。</li></ol><pre><code class="highlight plaintext">s = set([1,2,3])ss = set([1,1,2,2,3,3])s</code></pre><p><strong>结果：</strong><br>{1, 2, 3}<br>{1, 2, 3}</p><p><code>注意：</code> set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集（&amp;）、并集（|）、差集（-）等操作。</p><h4 id="2-7-列表、元组、字典与集合综合示例代码">2.7 列表、元组、字典与集合综合示例代码</h4><pre><code class="highlight plaintext"># 创建列表对象x_list = [1,2,3]# 创建元组对象x_tuple = (1,2,3)# 创建字典对象，元素形式为“键:值”x_dict = {'a':97, 'b':98, 'c':99}# 创建集合对象x_set = {1,2,3}# 使用下标访问列表中指定位置的元素，元素下标从0开始print(x_list[1])# 元组也支持使用序号作为下标，1表示第二个元素的下标print(x_tuple[1])# 访问字典中特定“键”对应的“值”，字典对象的下标是“键”print(x_dict['a'])# 查看列表长度，也就是其中元素的个数print(len(x_list))# 查看元素2在元组中首次出现的位置print(x_tuple.index(2))# 查看字典中哪些“键”对应的“值”为98for key,value in x_dict.items():if value == 98:print(key)# 查看集合中的元素的最大值print(max(x_set))</code></pre><p><strong>结果：</strong><br>2<br>2<br>97<br>3<br>1<br>b<br>3</p><h3 id="3、运算符">3、运算符</h3><h4 id="3-1-算术运算符">3.1 算术运算符</h4><p>以下假设变量 a 为10，变量 b 为21：</p><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:center">+</td><td style="text-align:left">加 - 两个对象相加</td><td style="text-align:left">a + b 输出结果31</td></tr><tr><td style="text-align:center">-</td><td style="text-align:left">减 - 得到复数或是一个数减去另一个数</td><td style="text-align:left">a - b 输出结果-11</td></tr><tr><td style="text-align:center">*</td><td style="text-align:left">乘 - 两个数相乘或是返回一个被重复若干次的字符串</td><td style="text-align:left">a * b 输出结果210</td></tr><tr><td style="text-align:center">/</td><td style="text-align:left">除 - x 除以 y</td><td style="text-align:left">b / a 输出结果2.1</td></tr><tr><td style="text-align:center">%</td><td style="text-align:left">取模 - 返回除法的余数</td><td style="text-align:left">b % a 输出结果1</td></tr><tr><td style="text-align:center">**</td><td style="text-align:left">幂 - 返回x的y次幂</td><td style="text-align:left">a <code>**</code> b 为10的21次方</td></tr><tr><td style="text-align:center">//</td><td style="text-align:left">取整除 - 向下取接近除数的整数</td><td style="text-align:left">9 // 2 结果是4 <br> -9 // 2的结果是-5</td></tr></tbody></table><p><strong>要点：</strong></p><ol><li><code>+</code> 运算符除了用于算术加法外，还可以用户列表、元组、字符串的连接。</li><li><code>- </code>运算符除了用于整数、实数、复数之间的算术减法和相反数之外，还可以计算集合的差集。需要注意的是，在进行实数之间的运算时，有可能会出现误差。</li><li><code> *</code> 运算符除了表示整数、实数、复数之间的算术乘法，还可以用于列表、元组、字符串这几个类型的对象与整数的乘法，表示序列元素的重复，生成新的列表、元组或字符串。</li><li><code>%</code> 运算符可以用于求余运算，还可以用于字符串格式化。</li></ol><p><strong>算术运算符示例</strong></p><pre><code class="highlight plaintext"># + 运算符除了用于算术加法外，还可以用于列表、元组、字符串的连接print(3 + 5)print(3.4 + 4.5)print((3+4j) + (5+6j))print('abc' + 'def')print([1,2] + [3,4])print((1,2) + (3,))print("\n")# - 运算符除了用于整数、实数、复数之间的算术减法和相反数之外，还可以计算集合的差集。print(7.9 - 4.5)# 注意，结果有误差print(5 -3)num = 3print(-num)print(--num)# 注意，这里的--是两个负号，负负得正print(-(-num))# 与上一行代码含义相同print({1,2,3} - {3,4,5})# 计算差集print({3,4,5} - {1,2,3})print("\n")</code></pre><p><strong>结果：</strong><br>8<br>7.9<br>(8+10j)<br>abcdef<br>[1, 2, 3, 4]<br>(1, 2, 3)</p><p>3.4000000000000004<br>2<br>-3<br>3<br>3<br>{1, 2}<br>{4, 5}</p><h4 id="3-2-比较运算符">3.2 比较运算符</h4><p>以下假设变量 a 为10，变量 b 为20：</p><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:center">==</td><td style="text-align:left">等于 - 比较对象是否相等</td><td style="text-align:left">(a == b)  返回Fasle</td></tr><tr><td style="text-align:center">!=</td><td style="text-align:left">不等于 - 比较两个对象是否不相等</td><td style="text-align:left">(a != b)  返回True</td></tr><tr><td style="text-align:center">&gt;</td><td style="text-align:left">大于 - 返回x是否大于y</td><td style="text-align:left">(a &gt; b) 返回Fasle</td></tr><tr><td style="text-align:center">&lt;</td><td style="text-align:left">小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价</td><td style="text-align:left">(a &lt; b) 返回True</td></tr><tr><td style="text-align:center">&gt;=</td><td style="text-align:left">大于等于 - 返回x是否大于等于y</td><td style="text-align:left">(a &gt;= b) 返回Fasle</td></tr><tr><td style="text-align:center">&lt;=</td><td style="text-align:left">小于等于 - 返回x是否小于等于y</td><td style="text-align:left">(a &lt;= b) 返回True</td></tr></tbody></table><p><strong>比较运算符示例</strong></p><pre><code class="highlight plaintext">print(3+2 &lt; 7+8)# 关系运算符优先级低于算术运算符print(3 &lt; 5 &gt;2)# 等价于3&lt;5 and 5&gt;2print(3 == 3 &lt; 5)# 等价于3==3 and 3&lt;5print('12345' &gt; '23456')# 第一个字符'1'&lt;'2'，直接得出结论print('abcd' &gt; 'Abcd')# 第一个字符'a'&gt;'A'，直接得出结论print([85,92,73,84] &lt; [91,82,73])# 第一个数字85&lt;91，直接得出结论print([180,90,101] &gt; [180, 90, 99])# 前两个数字相等，第三个数字101&gt;99print({1,2,3,4} &gt; {3,4,5})# 第一个集合不是第二个集合的超集print({1,2,3,4} &lt;= {3,4,5})# 第一个集合不是第二个集合的子集print([1,2,3,4] &gt; [1,2,3])# 前三个元素相等，并且，第一个列表有多余的元素</code></pre><p><strong>结果：</strong><br>True<br>True<br>True<br>False<br>True<br>True<br>True<br>False<br>False<br>True</p><h4 id="3-3-赋值运算符">3.3 赋值运算符</h4><p>以下假设变量 a 为10，变量 b 为20：</p><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:center">=</td><td style="text-align:left">简单的赋值运算符</td><td style="text-align:left">c = a + b 将 a + b 的运算结果赋值为c</td></tr><tr><td style="text-align:center">+=</td><td style="text-align:left">加法赋值运算符</td><td style="text-align:left">c += a 等效于 c = c + a</td></tr><tr><td style="text-align:center">-=</td><td style="text-align:left">减法赋值运算符</td><td style="text-align:left">c -= a 等效于 c = c - a</td></tr><tr><td style="text-align:center">*=</td><td style="text-align:left">乘法赋值运算符</td><td style="text-align:left">c *= a 等效于 c = c * a</td></tr><tr><td style="text-align:center">/=</td><td style="text-align:left">除法赋值运算符</td><td style="text-align:left">c /= a 等效于 c = c / a</td></tr><tr><td style="text-align:center">%=</td><td style="text-align:left">取模赋值运算符</td><td style="text-align:left">c %= a 等效于 c = c % a</td></tr><tr><td style="text-align:center"><code>**=</code></td><td style="text-align:left">幂赋值运算符</td><td style="text-align:left">c <code>**=</code> a 等效于 c = c ** a</td></tr><tr><td style="text-align:center">//=</td><td style="text-align:left">取整除赋值运算符</td><td style="text-align:left">c //= a 等效于 c = c // a</td></tr></tbody></table><h4 id="3-4-逻辑运算符">3.4 逻辑运算符</h4><p>以下假设变量 a 为10，变量 b 为20：</p><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:center">and</td><td style="text-align:left">布尔“与” - 如果x为False，x and y 返回Fasle，否则它返回y的计算值</td><td style="text-align:left">(a and b) 返回20</td></tr><tr><td style="text-align:center">or</td><td style="text-align:left">布尔“或” - 如果x为True，它返回x的值，否则它返回y的计算值</td><td style="text-align:left">(a or b) 返回20</td></tr><tr><td style="text-align:center">not</td><td style="text-align:left">布尔“非” - 如果x为True，返回Fasle，如果x为False，它返回True</td><td style="text-align:left">not(a and b) 返回False</td></tr></tbody></table><p><strong>逻辑运算符示例</strong></p><pre><code class="highlight plaintext">print(3 in range(5) and 'abc' in 'abcdefg')print(3-3 or 5-2)print(not 5)print(not [])</code></pre><p><strong>结果：</strong><br>True<br>3<br>False<br>True</p><h4 id="3-5-成员运算符">3.5 成员运算符</h4><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:center">in</td><td style="text-align:left">如果在指定的序列中找到值返回True，否则返回Fasle</td><td style="text-align:left">x在y序列中，如果x在y序列中返回True</td></tr><tr><td style="text-align:center">not in</td><td style="text-align:left">如果在指定的序列中没有找到值返回True，否则返回False</td><td style="text-align:left">x不在y序列中，如果x不在y序列中返回True</td></tr></tbody></table><p><strong>成员运算符示例</strong></p><pre><code class="highlight plaintext">print(60 in [70, 60, 50, 80] )print('abc' in 'a1b2c3dfg')print([3] in [[3], [4], [5]])print('3' in map(str, range(5)))print(5 in range(5))</code></pre><p><strong>结果：</strong><br>True<br>False<br>True<br>True<br>False</p><h4 id="3-6-身份运算符">3.6 身份运算符</h4><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:center">is</td><td style="text-align:left">is 是判断两个标识符是不是引用一个对象</td><td style="text-align:left">x is y， 类似id(x) == id(y)，如果引用的是同一个对象则返回True，否则返回False</td></tr><tr><td style="text-align:center">is not</td><td style="text-align:left">is not 是判断两个标识符是不是引用自不同对象</td><td style="text-align:left">x is not y，类似id(a)!=id(b)。如果引用的不是同一个对象则，返回结果True，否则返回False</td></tr></tbody></table><p><code>注意</code>：<code>id(x)</code>函数用于获取对象内存地址</p><p><code>特别的</code>：<code>is</code> 与 <code>==</code> 区别：<code>is</code>用于判断两个变量引用对象是否为同一个，<code> ==</code>用于判断引用变量的值是否相等。</p><p><strong>身份运算符示例</strong></p><pre><code class="highlight plaintext">a = 20b = 20 if (a is b):print("1 : a 和 b 有相同的标识")else:print("1 : a 和 b 没有相同的标识")print(id(a))print(id(b))# 修改变量b的值b = 30if(a is b):print("3 : a 和 b 有相同的标识")else:print("3 : a 和 b 没有相同的标识")print(id(a))print(id(b))# is 与 == 的区别a = [1, 2, 3]b = [1, 2, 3]print(b == a)print(b is a)print(id(a))print(id(b))</code></pre><p><strong>结果：</strong><br>1 : a 和 b 有相同的标识<br>140715597430912<br>140715597430912<br>3 : a 和 b 没有相同的标识<br>140715597430912<br>140715597431232<br>True<br>False<br>1500602520840<br>1500602814024</p><p><strong>运算符优先级示例</strong></p><pre><code class="highlight plaintext">a = 20 b = 10c = 15d = 5e = 0 e = (a + b) * c / d # (30 * 15) / 5print("(a + b) * c / d 运算结果为：", e)e = ((a + b) * c) / d # (30 * 15) / 5print("((a + b) * c) / d 运算结果为：", e)e = (a + b) * (c / d) # (30) * (15/5)print("(a + b) * (c / d) 运算结果为：", e)e = a + (b * c) / d # 20 + (150/5)print("a + (b * c) / d  运算结果为：", e)</code></pre><p><strong>结果：</strong><br>(a + b) * c / d 运算结果为： 90.0<br>((a + b) * c) / d 运算结果为： 90.0<br>(a + b) * (c / d) 运算结果为： 90.0<br>a + (b * c) / d  运算结果为： 50.0</p><h3 id="4、列表">4、列表</h3><h4 id="4-1-列表的基本概念">4.1 列表的基本概念</h4><ol><li>列表是有序的元素集合，所有元素放在一对<code>中括号</code>中，用<code>逗号</code>隔开，没有长度限制。</li><li>列表索引值以<code>0</code>为开始值， <code>-1</code>为从末尾的开始位置。</li><li>列表可以使用<code>+</code>操作符进行拼接，使用<code>*</code>表示重复。</li><li>当列表元素增加或删除时，列表对象自动进行扩展或收缩內存，保证元素之间没有缝隙。</li></ol><p><strong>列表元素可以通过索引访问单个元素</strong><br>a=[4, 2, 3, 6, 6, 9, 5, 8, 1]<br>a[3]=6<br>a[0]=4<br>a9]=异常</p><p><strong>列表</strong></p><ol><li>列表可以完成大多数集合类的数据结构实现。</li><li>列表中元素的类型可以不相同，它支持数字，字符串甚至可以包含列表（所谓嵌套）。</li></ol><p><strong>列表元素修改</strong></p><ol><li>列表大小没有限制，可以随时修改。</li><li>列表元素变可随时修改。</li></ol><pre><code class="highlight plaintext">a=[4, 2, 3, 6, 6, 9, 5, 8, 1]a.insert(0, 1)print(a)a[0]=10print(a)</code></pre><p><strong>结果：</strong><br>[1, 4, 2, 3, 6, 6, 9, 5, 8, 1]<br>[10, 4, 2, 3, 6, 6, 9, 5, 8, 1]</p><h4 id="4-2-列表的基本操作">4.2 列表的基本操作</h4><table><thead><tr><th style="text-align:center">列表操作符</th><th style="text-align:center">操作符含义</th></tr></thead><tbody><tr><td style="text-align:center"><code>&lt;list1&gt;</code> + <code>&lt;list2&gt;</code></td><td style="text-align:center">连接两个列表</td></tr><tr><td style="text-align:center"><code>&lt;list&gt;</code> * <code>&lt;整数类型&gt;</code></td><td style="text-align:center">对列表进行整数次重复</td></tr><tr><td style="text-align:center"><code>&lt;list&gt;</code>[<code>&lt;整数类型&gt;</code>]</td><td style="text-align:center">索引列表中的元素</td></tr><tr><td style="text-align:center">len(<code>&lt;seq&gt;</code>)</td><td style="text-align:center">列表中元素个数</td></tr><tr><td style="text-align:center"><code>&lt;list&gt;</code>[<code>&lt;整数类型&gt;</code>:<code>&lt;整数类型&gt;</code>]</td><td style="text-align:center">取列表的一个子序列</td></tr><tr><td style="text-align:center">for <code>&lt;var&gt;</code> in <code>&lt;list&gt;</code></td><td style="text-align:center">对列表进行循环列举</td></tr><tr><td style="text-align:center"><code>&lt;expr&gt;</code> in <code>&lt;list&gt;</code></td><td style="text-align:center">成员检查，判断<code>&lt;expr&gt;</code>是否在列表中</td></tr></tbody></table><h4 id="4-3-列表相关方法">4.3 列表相关方法</h4><table><thead><tr><th style="text-align:left">方法</th><th style="text-align:left">方法含义</th></tr></thead><tbody><tr><td style="text-align:left"><code>&lt;list&gt;</code>.append(x)</td><td style="text-align:left">将元素<code>x</code>增加到列表的最后</td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.sort()</td><td style="text-align:left">将列表元素排序</td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.reverse()</td><td style="text-align:left">将序列元素反转</td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.index(x)</td><td style="text-align:left">返回第一次出现元素<code>x</code>的索引值</td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.insert(i,x)</td><td style="text-align:left">在<code>i</code>位置处插入新元素<code>x</code></td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.count(x)</td><td style="text-align:left">返回元素<code>x</code>在列表中的数量</td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.remove(x)</td><td style="text-align:left">删除列表中第一次出现的元素<code>x</code></td></tr><tr><td style="text-align:left"><code>&lt;list&gt;</code>.pop(i)</td><td style="text-align:left">取出列表中位置<code>i</code>的元素，并删除它</td></tr></tbody></table><h4 id="4-4-创建列表">4.4 创建列表</h4><pre><code class="highlight plaintext">&gt;&gt;&gt; list((3,5,7,9,11))    # 将元组转换为列表[3,5,7,9,11]&gt;&gt;&gt; list(range(1, 10, 2)  # 将range对象转换为列表[1, 3, 5, 7, 9]&gt;&gt;&gt; list('hello world')   # 将字符串转换为列表，每个字符转换为列中的一个元素['h','e','l','l','o','w','o','r','l','d']&gt;&gt;&gt; list({3,7,5})  # 将集合转换为列表，集合中的元素是无序的[3, 5, 7]&gt;&gt;&gt; x = list()     # 创建空列表&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; del x          # 删除列表对象&gt;&gt;&gt; x              # 对象删除后无法再访问，抛出异常NameError: name 'x' is not defined</code></pre><h4 id="4-5-利用索引访问列表">4.5  利用索引访问列表</h4><pre><code class="highlight plaintext">data = list(range(10))print(data)print(data[0])      # 第一个元素的下标为0print(data[1])      # 第二个元素的下标为1print(data[-1])     # -1表示最后一个元素的下标print(data[15])     # 15不是有效下标，代码抛出异常</code></pre><p><strong>结果：</strong></p><pre><code class="highlight plaintext">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]019Traceback (most recent call last):  File "C:\Users\xz\.spyder-py3\temp.py", line 12, in &lt;module&gt;    print(data[15])     # 15不是有效下标，代码抛出异常IndexError: list index out of range</code></pre><h4 id="4-6-列表常用方法">4.6  列表常用方法</h4><p><strong>append()、insert()、 extend()</strong></p><pre><code class="highlight plaintext">list = [1,2,3,4]print(list)list. append(5)print(list)list.insert(0, 0)print(list)list.insert(2, 1.5)print(list)list.extend([6, 7])print(list)</code></pre><p><strong>结果：</strong><br>[1, 2, 3, 4]<br>[1, 2, 3, 4, 5]<br>[0, 1, 2, 3, 4, 5]<br>[0, 1, 1.5, 2, 3, 4, 5]<br>[0, 1, 1.5, 2, 3, 4, 5, 6, 7]</p><p><strong>pop()、remove()</strong></p><pre><code class="highlight plaintext">list = [1, 2, 3, 4, 5, 6]print(list.pop())# 删除并返回最后一个元素print(list)print(list.pop(0))# 删除并返回下标为0的元素，后面的元素向前移动print(list)print(list.pop(2))# 删除并返回下标为2的元素，后面的元素向前移动print(list)list = [1, 2, 3,  2, 4, 2]list.remove(2)# 删除第一个2， 该方法没有返回值print(list)</code></pre><p><strong>结果：</strong><br>6<br>[1, 2, 3, 4, 5]<br>1<br>[2, 3, 4, 5]<br>4<br>[2, 3, 5]<br>[1, 3, 2, 4, 2]</p><p><strong>sort()、reverse()</strong></p><pre><code class="highlight plaintext">from random import sample# 在range(10000) 中任选10个不重复的随机数data = sample(range(10000), 10)print(data)data.reverse()# 翻转，首尾交换，该方法没有返回值print(data)data.sort()# 按元素大小进行排序，该方法没有返回值print(data)data.sort(key=str)# 按所有元素转换为字符串后的大小进行排序print(data)</code></pre><p><strong>结果：</strong><br>[1680, 5901, 5733, 45, 8628, 5475, 3446, 4598, 555, 9934]<br>[9934, 555, 4598, 3446, 5475, 8628, 45, 5733, 5901, 1680]<br>[45, 555, 1680, 3446, 4598, 5475, 5733, 5901, 8628, 9934]<br>[1680, 3446, 45, 4598, 5475, 555, 5733, 5901, 8628, 9934]</p><p><strong>count()、index()</strong></p><pre><code class="highlight plaintext">list = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]print(list.count(2))    # 输出2print(list)print(list.index(4))# 输出6print(list)print(list.index(5))# 代码抛出异常，提示5 is not in list</code></pre><p><strong>结果：</strong></p><pre><code class="highlight plaintext">2[1, 2, 2, 3, 3, 3, 4, 4, 4, 4]6[1, 2, 2, 3, 3, 3, 4, 4, 4, 4]---------------------------------------------------------------------ValueError                        Traceback (most recent call last)&lt;ipython-input-28-36d2725a5d78&gt; in &lt;module&gt;      4 print(list.index(4))    # 输出6      5 print(list)----&gt; 6 print(list.index(5))    # 代码抛出异常，提示5 is not in listValueError: 5 is not in list</code></pre><h4 id="4-7-列表推导式">4.7  列表推导式</h4><pre><code class="highlight plaintext">data = [2**i for i in range(64)]等价于data = []for i in range(64):data.append(2**i)</code></pre><pre><code class="highlight plaintext">data = [num for num in range(20) if num%2==1]等价于data = []for num in range(20):if num%2 == 1:data.append(num)</code></pre><h3 id="5、元组">5、元组</h3><h4 id="5-1-基本概念">5.1 基本概念</h4><ol><li><p>元组(tuple)是包含多个元素的类型，元素之间用逗号分割。<br>如：t1 = (123, 456, “hello”)</p></li><li><p>可以通过把若干元素放在一对圆括号中创建元组，如果只有一个元素的话则需要多加一个逗号，例如(3,)</p></li><li><p>也可以使用tuple()函数把列表、字典、集合、字符串以及range对象、map对象、zip对象或其他类似对象转换为元组。</p></li><li><p>元组可以是空的，t2=()</p></li><li><p>一个元组也可以作为另一个元组的元素，此时，作为元素的元组需要增加括号，从而避免歧义，如：t3 = (123, 456, (“hello”, “world”))</p></li><li><p>元组中各元素存在先后关系，可以通过索引访问元组中的元素。<br>例如：t3[0]</p></li><li><p>元组定义后不能更改，也不能删除。<br>t3[0]  = 789</p></li><li><p>与字符串类型类似，可以通过索引区来访问元组中的部分元素。<br>例如：t3[1:]</p></li><li><p>与字符串一样，元组之间可以用<code>+</code>号和<code>*</code>号进行运算</p></li></ol><h4 id="5-2-元组与列表的区别">5.2 元组与列表的区别</h4><ol><li><p>元组是<code>不可变</code>的，不能直接修改元组中元素的值，也不能为元组增加或删除元素。因此，元组没有提供 append()、 extend()和insert()等方法，也没有 remove()和pop()方法。</p></li><li><p>元组的访问速度比列表<code>更快，开销更小</code>。如果定义了一系列常量值，主要用途只是对它们进行遍历或其他类似操作，那么一般建议使用元组而不用列表。</p></li><li><p>元组可以使得<code>代码更加安全</code>。例如，调用函数时使用元组传递参数可以防止在函数中修改元组，而使用列表则无法保证这一点。</p></li><li><p>元组可用作字典的键，也可以作为集合的元素，但列表不可以，包含列表的元组也不可以。</p></li></ol><h4 id="5-3-生成器表达式">5.3 生成器表达式</h4><pre><code class="highlight plaintext">gen = (2**i for i in range(8))# 创建生成器对象print(gen)print(list(gen))# 转换为列表，用完了生成器对象中的所有元素print(tuple(gen))# 转换为元组，得到空元组gen = (2**i for i in range(8))# 重新创建生成器对象print(next(gen))# 使用next()函数访问下一个元素print(next(gen))for item in gen:# 使用for循环访问剩余的所有元素print(item, end='  ')</code></pre><pre><code class="highlight plaintext">&lt;generator object &lt;genexpr&gt; at 0x0000015D62F32138&gt;(1, 2, 4, 8, 16, 32, 64, 128)()124  8  16  32  64  128</code></pre><h3 id="6、切片操作">6、切片操作</h3><p><strong>适用于列表和元组</strong></p><ol><li><p>切片是用来获取列表、元组、字符串等有序序列中部分元素的一种语法。在形式上，切片使用2个冒号分割的3个数字来完成。</p></li><li><p>[start<span class="github-emoji"><span>🔚</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f51a.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>step]</p></li><li><p>其中第一个数字<code>start</code>表示切片开始位置，默认为0；第二个数字<code>end</code>表示切片截止（但不包含）位置（默认为列表长度）；第三个数字<code>step</code>表示切片的步长（默认为1），省略步长时还可以同时省略最后一个冒号。</p></li><li><p>当step为<code>负整数</code>时，表示反向切片，这时start应该在end的右侧。</p></li></ol><pre><code class="highlight plaintext">data = list(range(20))print(data[:])# 获取所有元素的副本print(data[:3])# 前三个元素print(data[3:])# 下标3之后的所有元素print(data[::3])# 每3个元素选取1个print(data[-3:])# 最后3个元素print(data[:-5])# 除最后5个元素之外的所有元素</code></pre><p><strong>结果：</strong><br>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]<br>[0, 1, 2]<br>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]<br>[0, 3, 6, 9, 12, 15, 18]<br>[17, 18, 19]<br>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]</p><h3 id="7、字典">7、字典</h3><h4 id="7-1-基本概念">7.1 基本概念</h4><ol><li>字典是<code>无序</code>的对象集合，使用键-值(key- value)存储，具有极快的查找速度。</li><li>键(key)必须使用不可变类型</li><li>同一个字典中，键(key)必须是唯一的</li><li>字典的每个键值key=&gt;value对用冒号:分割，每个键值对之间用逗号，分割，整个字典包括在花括号{}中，格式如下所示<br>dic = {key1: value1, key2: value2)</li></ol><pre><code class="highlight plaintext">&gt;&gt;&gt; d={'Michael':95, 'Bob':75, 'Tracy':85}&gt;&gt;&gt; d['Michael']95</code></pre><h4 id="7-2-常用方法">7.2 常用方法</h4><table><thead><tr><th style="text-align:left">方法</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">keys()</td><td style="text-align:left">返回字典中键的列表</td></tr><tr><td style="text-align:left">values()</td><td style="text-align:left">返回字典中值的列表</td></tr><tr><td style="text-align:left">items()</td><td style="text-align:left">返回tuples的列表。每个tuple由字典的键和相应值组成</td></tr><tr><td style="text-align:left">clear()</td><td style="text-align:left">删除字典的所有条目</td></tr><tr><td style="text-align:left">copy()</td><td style="text-align:left">返回字典高层结构的一个拷贝，但不复制嵌入结构，而只复制对那些结构的引用</td></tr><tr><td style="text-align:left">update(x)</td><td style="text-align:left">用字典x中的键值对更新字典内容</td></tr><tr><td style="text-align:left">get(x[,y])</td><td style="text-align:left">返回键x，若未找到该键返回none，若提供y，则未找到x时返回y</td></tr></tbody></table><p>字典键<code>一般是唯一</code>的，如果<code>重复最后的一个键值</code>对会<code>替换前面的</code>，<code>值不需要唯一</code>。</p><pre><code class="highlight plaintext">dict = {'a':1, 'b':2, 'b':'3'}dict['b']dict</code></pre><p><strong>jupyter一行一行运行结果：</strong><br>‘3’<br>{‘a’: 1, ‘b’: ‘3’}</p><h4 id="7-3-创建字典：基础语法方式">7.3 创建字典：基础语法方式</h4><ol><li>字典中值<code>可以取任何数据类型</code>，但<code>键必须是不可变</code>的，如<code>字符串</code>，<code>数字</code>或<code>元组</code>。如<br>dict={‘Alice’: ‘2341’, ‘Beth’: ‘9102’, ‘Cecil’: ‘3258’}<br><br></li><li>也可如此创建字典，如<br>dict1={‘abc’: 456}<br>dict2={‘abc’: 123, 98.6: 37}</li></ol><h4 id="7-4-创建字典：dict函数">7.4 创建字典：dict函数</h4><ol><li>使用dict函数，通过其他映射(比如字典)或者(键,值)序列对创建字典</li></ol><pre><code class="highlight plaintext">items = [('name', 'Gumby'),('age', 42)]d= dict(items)print(d)</code></pre><p><strong>结果：</strong><br>{‘name’: ‘Gumby’, ‘age’: 42}</p><ol start="2"><li>dict函数也可以通过关键字参数来创建字典</li></ol><pre><code class="highlight plaintext">d = dict(name='Gumby', age=42)print(d)</code></pre><p><strong>结果：</strong><br>{‘name’: ‘Gumby’, ‘age’: 42}</p><h4 id="7-5-字典元素访问">7.5 字典元素访问</h4><pre><code class="highlight plaintext">data = dict(name='张三', age=18, sex='M')print(data['name'])# 使用“键”作为下标，访问“值”print(data.get('age'))print(data.get('address', '不存在这个键'))# “键”不存在，返回默认值print(list(data))# 把所有的“键”转换为列表print(list(data.values()))# 把所有的“值”转换为列表print(list(data.items()))# 把所有的元素转换为列表for key,value in data.items():# 遍历字典的“键:值”元素print(key, value, sep='\t')</code></pre><p><strong>结果：</strong><br>张三<br>18<br>不存在这个键<br>[‘name’, ‘age’, ‘sex’]<br>[‘张三’, 18, ‘M’]<br>[(‘name’, ‘张三’), (‘age’, 18), (‘sex’, ‘M’)]<br>name    张三<br>age     18<br>sex     M</p><h4 id="7-6-字典元素修改、添加与删除">7.6 字典元素修改、添加与删除</h4><ol><li>当以指定“键”为下标为字典元素赋值时，有两种含义：<br>1）若该“键”存在，表示修改该“键”对应的值。<br>2）若不存在，表示添加一个新元素。</li></ol><pre><code class="highlight plaintext">sock = {'IP': '127.0.0.1', 'port': 80}sock['port'] = 8080# 修改已有元素的“值”sock['protocol'] = 'TCP'# 增加新元素print(sock)</code></pre><p><strong>结果：</strong><br>{‘IP’: ‘127.0.0.1’, ‘port’: 8080, ‘protocol’: ‘TCP’}</p><ol start="2"><li>使用字典对象的update()方法可以将另一个字典的元素一次性全部添加到当前字典对象，如果两个字典中存在相同的“键”，则以另一个字典中的“值”为准对当前字典进行更新。</li></ol><pre><code class="highlight plaintext">sock = {'IP': '127.0.0.1', 'port': 80}# 更新了一个元素的“值”，增加了一个新元素sock.update({'IP': '192.168.9.62', 'protocol': 'TCP'})print(sock)</code></pre><p><strong>结果：</strong><br>{‘IP’: ‘192.168.9.62’, ‘port’: 80, ‘protocol’: ‘TCP’}</p><ol start="3"><li>可以使用字典对象的pop()删除指定“键”对应的元素，同时返回对应的“值”。<br><br></li><li>popitem()方法用于删除字典的一个键对，并返回一个包含两个元素的元组，其中的两个元素分别是字典元素的“键”和“值”。<br><br></li><li>也可以使用del删除指定的“键”对应的元素。</li></ol><pre><code class="highlight plaintext">sock = {'IP':'192.168.9.62','port':80,'protocol':'TCP'}print(sock.pop('IP'))# 朋除并返回指定键的元素print(sock.popitem())# 删除并返回一个元素del sock['port']# 朋除指定键的元素print(sock)</code></pre><p><strong>结果：</strong><br>192.168.9.62<br>(‘protocol’, ‘TCP’)<br>{}</p><h3 id="8、集合">8、集合</h3><h4 id="8-1-概述">8.1 概述</h4><ol><li>Python集合是<code>无序</code>、<code>可变</code>的容器对象，所有元素放在一对<code>大括号</code>中，元素之间使用逗号分隔，同一个集合内的每个<code>元素都是唯一</code>的，<code>不允许重复</code>。</li><li>集合中只能包含<code>数字、字符串、元组</code>等不可变类型的数据，而<code>不能包含列表、字典、集合</code>等可变类型的数据，包含列表等可变类型数据的元组也不能作为集合的元素。</li><li>集合中的元素是<code>无序</code>的，元素存储顺序和添加顺序并不一致。</li><li>集合不支持使用下标直接访问特定位置上的元素，也不支持使用 random中的 choice()函数从集合中随机选取元素，但支持使用 random模块中的 sample函数随机选取部分元素。</li></ol><h4 id="8-2-set（集合）">8.2 set（集合）</h4><ol><li>set和dict类似，也是一组key的集合，但不存储value，由于key不能重复，所以，在set中，没有重复的key。<br><br></li><li>set是无序的，重复元素在set中自动被过滤。</li></ol><pre><code class="highlight plaintext">s = set([1,2,3])ss = set([1,1,2,2,3,3])s</code></pre><p><strong>jupyter一行一行运行结果：</strong><br>{1, 2, 3}<br>{1, 2, 3}</p><p><code>注意；</code>set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集(&amp;)、并集(|)、差集(-)等操作。</p><h4 id="8-3-集合常用方法">8.3 集合常用方法</h4><ol><li>s = add(x)：将元素x添加到集合s中，如果元素已存在，则不进行任何操作。</li><li>s = update(x)：将x的元素添加到集合s中，x可以是列表、元组、字典等。</li></ol><pre><code class="highlight plaintext">data = {30, 40, 50}data.add(20)# 增加新元素20print(data)data.add(50)# 集合中已包含50，忽略本次操作print(data)data.update({40, 60})# 忽略40，增加新元素60print(data)</code></pre><p><strong>结果：</strong><br>{40, 50, 20, 30}<br>{40, 50, 20, 30}<br>{50, 20, 40, 60, 30}</p><ol start="3"><li>s.pop(x)：随机删除集合中的一个元素。</li><li>s.remove(x)：将元素x从集合s中移除，如果元素不存在，则会发生错误。</li><li>s.discard(x)：将元素x从集合s中移除，如果元素不存在，<code>不会发生错误</code>。</li></ol><pre><code class="highlight plaintext">data = {30, 40, 50}data.remove(30)# 删除元素30print(data)data.discard(30)# 集合中没有30，忽略本次操作print(data.pop())# 删除并返回集合中的一个元素print(data)</code></pre><p><strong>结果：</strong><br>{40, 50}<br>40<br>{50}</p><h3 id="9、字符串">9、字符串</h3><h4 id="9-1-概述">9.1 概述</h4><ol><li>字符串(str)是用双引号""或者单引号’'括起来的一个或多个字符。</li><li>字符串可以保存在变量中，也可以单独存在。</li><li>字符串属于不可变对象，所有方法都是返回处理后的字符串或字节串，不对原字符串进行任何修改。</li><li>可以用type()函数测试一个字符串的类型。</li></ol><pre><code class="highlight plaintext">In[1]:  type("1")Out[1]: strIn[2]:  type(1)Out[2]: int</code></pre><ol start="5"><li>字符串是一个字符序列：字符串最左端位置标记为0，依次增加。字符串中的编号叫做"索引"。</li></ol><table><thead><tr><th style="text-align:center">H</th><th style="text-align:center">e</th><th style="text-align:center">l</th><th style="text-align:center">l</th><th style="text-align:center">o</th><th style="text-align:center"></th><th style="text-align:center">J</th><th style="text-align:center">a</th><th style="text-align:center">c</th><th style="text-align:center">k</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">5</td><td style="text-align:center">6</td><td style="text-align:center">7</td><td style="text-align:center">8</td><td style="text-align:center">9</td></tr></tbody></table><h4 id="9-2-转义">9.2 转义</h4><ol><li>Python语言转义符：<code>\</code>，在字符串中表示转义，即该字符与后面相邻的一个字符共同组，成了新的含义。</li><li>输出带有引号的字符串，可以使用转义符。</li><li>使用<code>\\</code>输出带有转义符的字符串。<br>print(“"你好"”)<br>print(“<code>\\</code>”)</li><li>用转义符可以在字符串中表达一些不可直接打印的信息，例如：用<code>\n</code>表示换行;<code>\t</code>表示制表符。<br>print(“Hello\nWorld\n\nGoodbye\t32”)</li></ol><h4 id="9-3-字符串操作">9.3 字符串操作</h4><ol><li>单个索引辅助访问字符串中的特定位置，格式为<code>&lt;string&gt;[&lt;索引&gt;]</code>。<br>str1 = “hello, world”<br>print(str1[1])</li><li>Python中字符串索引<code>从0开始</code>，一个长度为L的字符串最后一个字符的<code>L-1</code>。</li><li>Python同时允许使用负数从字符串右边末尾位置是向左边进行反向索引，<code>最右侧索引 值是-1</code>。</li><li>可以通过两个索引值确定一个位置范围，返回这个范围的子串，字符串的切片。<br>格式：<code>&lt; string&gt;[&lt; start&gt;:&lt;end&gt;]</code></li><li>start和end都是整数型数值，这个子序列从索引 start开始直到索引end结束，但不包括end位置。</li><li>字符串之间可以通过<code>+或*</code>进行连接。<br>加法操作(+)将两个字符串<code>连接</code>成为一个新的字符串。<br>乘法操作()生成一个由其本身字符串<code>重复连接</code>而成的字符串。<br>x in s：如果x是s的子串，返回True，否则返回 False。<br>str[N:M]：切片，返回子串。</li><li>len()函数能返回一个字符串的长度。<br>str1 = "hello, world”<br>len(str1)</li><li>大多数数据类型都可以通过<code>str()</code>函数转换为字符串：如str(123)。</li><li>type函数测试一个字符串的类型。</li></ol><h4 id="9-4-字符串遍历操作">9.4 字符串遍历操作</h4><p>可以通过for和in组成的循环来遍历字符串中每个字符</p><pre><code class="highlight plaintext">for &lt;var&gt; in &lt;string&gt;:操作</code></pre><pre><code class="highlight plaintext">str1 = "Hello, world"for p in str1:print(p)</code></pre><p><strong>结果：</strong><br>H<br>e<br>l<br>l<br>o<br>,</p><p>w<br>o<br>r<br>l<br>d</p><h4 id="9-5-字符串处理方法">9.5 字符串处理方法</h4><table><thead><tr><th style="text-align:left">操作</th><th style="text-align:left">含义</th></tr></thead><tbody><tr><td style="text-align:left">+</td><td style="text-align:left">连接</td></tr><tr><td style="text-align:left">*</td><td style="text-align:left">重复</td></tr><tr><td style="text-align:left"><code>&lt;string&gt;</code>[]</td><td style="text-align:left">索引</td></tr><tr><td style="text-align:left"><code>&lt;string&gt;</code>[:]</td><td style="text-align:left">剪切</td></tr><tr><td style="text-align:left">len(<code>&lt;sting&gt;</code>)</td><td style="text-align:left">长度</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>.upper()</td><td style="text-align:left">字符串中字母大写</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>.lower()</td><td style="text-align:left">字符串中字母小写</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>。strip()</td><td style="text-align:left">去两边空格及去指定字符串</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>.split()</td><td style="text-align:left">按指定字符分割字符串为数组</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>.join()</td><td style="text-align:left">连接两个字符串序列</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>.find()</td><td style="text-align:left">搜索指定字符串</td></tr><tr><td style="text-align:left"><code>&lt;sting&gt;</code>.replace()</td><td style="text-align:left">字符串替换</td></tr><tr><td style="text-align:left">for <code>&lt;var&gt;</code> in <code>&lt;string&gt;</code></td><td style="text-align:left">字符串迭代</td></tr></tbody></table><h4 id="9-6-常用方法">9.6 常用方法</h4><ol><li>Index(x)、rindex(0)：检测是否包含在字符串中，返回相应的索引值，如果不存在，返回异常。</li><li>count(x)：返回str在string里面出现的次数。</li></ol><pre><code class="highlight plaintext">text = '处处飞花飞处处，声声笑语笑声声。'print(text.rindex('处'))print(text.index('声'))print(text.count('处'))</code></pre><p><strong>结果：</strong><br>6<br>8<br>4</p><ol start="3"><li>replace(str1, str2, [,max])：把将字符串中的str1替换成str2，如果max指定，则替换不超过max次。</li></ol><pre><code class="highlight plaintext">text = "Python是一门非常棒的编程语言。"# replace()方法返回替换后的新字符申，可以直接再次调用replace()方法print(text.replace('棒', '优雅').replace('编程', '程序设计'))print(text)</code></pre><p><strong>结果：</strong><br>Python是一门非常优雅的程序设计语言。<br>Python是一门非常棒的编程语言。</p><ol start="4"><li>maketrans()：创建字符映射的转换表。</li><li>translate(str)：根据str给出的映射转换表转换string字符。</li></ol><pre><code class="highlight plaintext">table = ''.maketrans('0123456789', '零一二三四伍陆柒捌玖')print('Tel:62819743'.translate(table))</code></pre><p><strong>结果：</strong><br>Tel:陆二捌一玖柒四三</p><ol start="6"><li>ljust(width[,fillchar])：返回一个原字符串左对齐，并使用fillchar填充至长度width的新字符串，fillchar默认为空格。rjust()、center()类似。</li></ol><pre><code class="highlight plaintext">print('居左'.ljust(20)+'结束')print('居右'.rjust(20, '#'))# 左侧使用并号填充print('居中'.center(20, '='))# 两侧使用等号填充</code></pre><p><strong>结果：</strong></p><pre><code class="highlight plaintext">居左                  结束##################居右=========居中=========</code></pre><ol start="7"><li>split(str= “”, num=string.count(str))，其中num=string.count(str)以str为分隔符截取字符串，如果num有指定值，则仅截取num+1个子字符串。rsplit()类似，从右侧开始截取。</li><li>join(seq)：以指定字符串作为分隔符，将seq中所有的元素（的字符串表示）合并为一个新的字符串。</li></ol><pre><code class="highlight plaintext">text = 'Beautiful is better than ugly.'print(text.split())# 使用空白字符进行分隔print(text.split(maxsplit=1))# 最多分隔一次print(text.rsplit(maxsplit=2))# 最多分隔两侧print('1,2,3,4'.split(','))# 使用逗号作为分隔符print(','.join(['1', '2', '3', '4']))# 使用逗号作为连接符print(':'.join(map(str, range(1, 5))))# 使用冒号作为连接符print(''.join(map(str, range(1, 5))))# 直接连接，不插入任何连接符</code></pre><p><strong>结果：</strong><br>[‘Beautiful’, ‘is’, ‘better’, ‘than’, ‘ugly.’]<br>[‘Beautiful’, ‘is better than ugly.’]<br>[‘Beautiful is better’, ‘than’, ‘ugly.’]<br>[‘1’, ‘2’, ‘3’, ‘4’]<br>1,2,3,4<br>1:2:3:4<br>1234</p><ol start="9"><li>lower()、upper()、capitalize()（句子首个单词大写）、title()（每个单词大写）、swapcase()（小写和大写相互转换）。</li></ol><pre><code class="highlight plaintext">text = 'Simple is better than complex.'print(text.lower())print(text.upper())print(text.capitalize())print(text.title())print(text.swapcase())</code></pre><p><strong>结果：</strong><br>simple is better than complex.<br>SIMPLE IS BETTER THAN COMPLEX.<br>Simple is better than complex.<br>Simple Is Better Than Complex.<br>sIMPLE IS BETTER THAN COMPLEX.</p><ol start="10"><li>startswith()、endswith()：检查字符串是否是以指定子字符串substr开头或结束，是则返回True。</li></ol><pre><code class="highlight plaintext">text = 'Simple is better than complex.'print(text.startswith('simple'))print(text.startswith('Simple'))print(text.endswith(('.', '!', '?')))</code></pre><p><strong>结果：</strong><br>False<br>True<br>True</p><ol start="11"><li>strip()、rstrip()、lstrip()：截取字符串的指定字符。</li></ol><pre><code class="highlight plaintext">text = '   ======test===#####    'print(text.strip())# 删除两侧的空白字符print(text.strip('=# '))# 删除两侧的=、#和空格</code></pre><p><strong>结果：</strong></p><pre><code class="highlight plaintext">======test===#####test</code></pre><h3 id="10、程序控制流">10、程序控制流</h3><h4 id="10-1-程序基本结构">10.1 程序基本结构</h4><ol><li>顺序结构是程序的基础，但单一的顺序结构不可能解决所有问题。</li><li>程序由三种基本结构组成：<br>顺序结构<br>分支结构<br>循环结构</li><li>任何算法(程序)都可以由这三种基本结构组合来实现。</li></ol><h5 id="10-1-1-顺序结构">10.1.1 顺序结构</h5><p>程序按线性顺序依次执行</p><pre><code class="highlight plaintext">   ↓&lt;语句块1&gt;   ↓&lt;语句块2&gt;</code></pre><h5 id="10-1-2-分支结构">10.1.2 分支结构</h5><p>程序根据条件判断结果而选择不同执行路径<br>有单分支和二分支结构，二分支结构可组合成多分支结构</p><p><img src="/medias/%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="分支结构流程图"></p><h5 id="10-1-3-循环结构">10.1.3 循环结构</h5><p>程序根据条件判断结果向后反复执行<br>根据循环体触发条件不同，包括条件循环和遍历循环结构</p><p><img src="/medias/%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="循环结构流程图"></p><h4 id="10-2-分支结构（单分支、二分支、多分支）">10.2 分支结构（单分支、二分支、多分支）</h4><h5 id="10-2-1-单分支结构：if语句">10.2.1 单分支结构：if语句</h5><p>if 语句语法格式</p><pre><code class="highlight plaintext">if &lt;条件&gt;:语句块</code></pre><ol><li>语句块是 <code>if条件满足</code>后执行的一个或多个语句序列，语句块中语句通过与 if 所在行形成<code>缩进</code>表达包含关系。</li><li>if 语句首先评估&lt;条件&gt;的结果值，如果结果为True，则执行语句块里的语句序列，然后控制转向程序的下一条语句。</li><li>如果结果为 False，语句块里的语句会被跳过。</li></ol><p><strong>单分支结构示例</strong></p><p>**题目：**生成包含两个或三个汉字的人名。</p><pre><code class="highlight plaintext">from random import choice, randomname = choice('董孙李周赵钱王')condition = random()if condition&gt;0.5:# random()函数返回[0,1)区间上的随机数name += choice('付玉延邵子凯')name += choice('国楠栋涵雪玲瑞')print(condition)print(name)</code></pre><p><strong>结果：</strong><br>0.05645875733667094<br>钱国</p><h5 id="10-2-2-二分支结构：if-else语句">10.2.2 二分支结构：if-else语句</h5><ol><li>if-else 语句语法格式</li></ol><pre><code class="highlight plaintext">if &lt;条件&gt;:&lt;语句块1&gt;else:&lt;语句块2&gt;</code></pre><ol start="2"><li>&lt;语句块1&gt;是在 if 条件满足后执行的一个或多个语句序列</li><li>&lt;语句块2&gt;是if条件不满足后执行的语句序列</li></ol><p><strong>二分支结构示例</strong></p><p>**题目：**PM2.5空气质量提醒。</p><pre><code class="highlight plaintext">PM = eval(input("请输入PM2.5数值："))if PM &gt;= 75:print("空气存在污染，请小心！")else:print("空气没有污染，可以展开户外活动！")</code></pre><p><strong>结果：</strong><br>请输入PM2.5数值：98<br>空气存在污染，请小心！</p><h5 id="10-2-3-二分支结构简洁表达方式">10.2.3 二分支结构简洁表达方式</h5><ol><li>适合通过判断返回特定值，语法格式：</li></ol><pre><code class="highlight plaintext">&lt;表达式1&gt; if &lt;条件&gt; else &lt;表达式2&gt;</code></pre><pre><code class="highlight plaintext">PM = eval(input("请输入PM2.5数值："))print("空气存在污染，请小心！") if PM &gt;= 75 else print("空气没有污染，可以展开户外活动！")</code></pre><p><strong>结果：</strong><br>请输入PM2.5数值：98<br>空气存在污染，请小心！</p><p>请输入PM2.5数值：50<br>空气没有污染，可以展开户外活动！</p><ol start="2"><li>这种紧凑结构适合对特殊值进行处理的情况</li></ol><h5 id="10-2-4-多分支结：if-elif-else语句">10.2.4 多分支结：if-elif-else语句</h5><p><strong>if-elif-else语句语法格式</strong></p><pre><code class="highlight plaintext">if &lt;条件1&gt;:&lt;语句块1&gt;elif &lt;条件2&gt;:&lt;语句块2&gt;...else:&lt;语句块N&gt;</code></pre><ol><li>多分支结构是二分支结构的扩展。</li><li>通常用于设置同一判断条件的多条执行路径。</li><li>运行时依次评估寻找第一个结果为 True 的条件，执行该条件下的语句块，结束后跳过整个多分支结构，执行后面的语句。</li><li>如果没有任何条件成立，则执行 else 下的语句块。</li><li>else 语句是可选的，不一定要有。</li></ol><p><strong>多分支结构示例</strong><br>**题目：**PM2.5空气质量（分级）提醒。</p><pre><code class="highlight plaintext">PM = eval(input("请输入PM2.5数值："))if 0 &lt;= PM &lt; 35:print("空气优质，快去户外运动！")elif 35 &lt;= PM &lt; 75:print("空气良好，适度户外运动！")else:print("空气污染，请小心！")</code></pre><hr><p>请输入PM2.5数值：24<br>空气优质，快去户外运动！</p><h4 id="10-3-循环结构（for循环、while循环）">10.3 循环结构（for循环、while循环）</h4><h5 id="10-3-1-for-循环">10.3.1 for 循环</h5><ol><li>Python 可以使用 for 语句循环遍历整个序列的值。</li><li>for 循环中，循环变量 var 遍历队列中每一个值，循环的语句体为每个 var 值执行一次。</li></ol><pre><code class="highlight plaintext">for &lt;var&gt; in &lt;sequence&gt;:&lt;body&gt;</code></pre><ol start="3"><li>for 循环在执行过程中，直接在序列上进行遍历，而非在内存中生成一个新的序列拷贝进行遍历。</li></ol><p><strong>for 循环结构示例</strong><br>**题目：**输入N个数，求平均数。</p><pre><code class="highlight plaintext">#average n = eval(input("How many numbers? "))sum = 0.0for i in range(n):x = eval(input("Enter a number&gt;&gt;"))sum += xprint("\nThe average is: ", sum / n)</code></pre><p><strong>结果：</strong><br>How many numbers? 4<br>Enter a number&gt;&gt;12<br>Enter a number&gt;&gt;3<br>Enter a number&gt;&gt;4<br>Enter a number&gt;&gt;24<br>The average is:  10.75</p><ol start="4"><li>for 循环非常适合用来遍历容器类对象(列表、元组、字典、集合、字符串以及map、zip等类似对象)中的元素，语法形式为：</li></ol><pre><code class="highlight plaintext">for 循环遍历 in 容器类对象:循环体else:[else语句代码块]</code></pre><ol start="5"><li>range() 函数可创建一个整数列表，用 for 语句进行循环</li></ol><pre><code class="highlight plaintext">for i in range (10)</code></pre><ol start="6"><li><strong>for 循环缺点</strong><br>1）程序开始时必须提供输入数字总数。<br>2）大规模数字求平均值需要用户先数清楚个数。<br>3）for 循环是需要提供固定循环次数的循环方式。</li></ol><h5 id="10-3-2-while-循环语法">10.3.2 while 循环语法</h5><pre><code class="highlight plaintext">while 条件表达式:循环体else:[else 语句代码块]</code></pre><p><img src="/medias/while%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="while循环结构流程图"></p><p><code>while 循环</code>，只要条件满足，就不断循环，条件不满足时退出循环。<br>在while … else 在条件语句为 false 时执行 else 的语句块</p><pre><code class="highlight plaintext">sum = 0n =99while n &gt; 0:sum = sum +nn = n-2print(sum)</code></pre><p><strong>结果：</strong><br>2500</p><pre><code class="highlight plaintext">count = 0while count &lt; 3:print(count, "小于 3")count = count + 1else:print(count, "大于或等于 3")</code></pre><p><strong>结果：</strong><br>0 小于 3<br>1 小于 3<br>2 小于 3<br>3 大于或等于 3</p><p><strong>while循环结构示例</strong></p><pre><code class="highlight plaintext"># 比较复杂一点的有嵌套的while语句a = 1while a &lt; 8:if a &lt;= 4:print(a)else:print("hello")a = a + 1else:print("test")</code></pre><p><strong>结果：</strong><br>1<br>2<br>3<br>4<br>hello<br>hello<br>hello<br>test</p><h5 id="10-3-3-循环保留字（break、continue）">10.3.3 循环保留字（break、continue）</h5><ol><li><strong>循环保留字：break</strong><br>1）break用来跳出最内层 for 或 while 循环，脱离该循环后程序从循环后代码继续执行。<br>2）break语句跳出了最内层 while 循环，但仍然继续执行外层循环。每个 break语句只有能<br>力跳出当前层次循环。<br><br></li><li><strong>循环保留字：continue</strong><br>1）continue 结束当前当次循环，即跳出循环体中下面尚未执行的语句，但不跳出当前循环。<br>2）对于 while 循环，继续求解循环条件。而对于 for 循环，程序流程接着遍历循环列表。<br>3）区别：<code>continue 语句只结束本次循环，而不终止整个循环的执行。而 break 语句则是结 束整个循环过程，不再判断执行循环的条件是否成立</code>。</li></ol><p><strong>for循环结构break保留字示例</strong></p><pre><code class="highlight plaintext">for letter in 'Runoob':  # 第一个实例if letter == 'o':breakprint("当前字母为：",  letter)var = 10 # 第二个实例while var &gt; 0:print("当前变量值为：", var)var = var - 1if var == 7:breakprint("Good bye!")</code></pre><p><strong>结果：</strong><br>当前字母为： R<br>当前字母为： u<br>当前字母为： n<br>当前变量值为： 10<br>当前变量值为： 9<br>当前变量值为： 8<br>Good bye!</p><p><strong>for循环结构continue保留字示例</strong><br>**题目：**编写程序，输出各位数字都不相同的所有三位数。</p><pre><code class="highlight plaintext">digits = range(10)for i in digits:# 选择第一个数字if i == 0:continue                # 第一位数不能是0for j in digits:if j == i:continue            # 第二位与第一位相同，则忽略后面的操作for k in digits:if k in (i,j):continue        # 三位数字必须互不相同print(int(str(i)+str(j)+str(k)), end=' ')</code></pre><p><strong>结果：</strong><br>102 103 104 105 106 107 108 109 120 123 124 125 126 127 128 129 130 132 134 135 136 137 138 139 140 142 143 145 146 147 148 149 150 152 153 154 156 157 158 159 160 162 163 164 165 167 168 169 170 172 173 174 175 176 178 179 180 182 183 184 185 186 187 189 190 192 193 194 195 196 197 198 201 203 204 205 206 207 208 209 210 213 214 215 216 217 218 219 230 231 234 235 236 237 238 239 240 241 243 245 246 247 248 249 250 251 253 254 256 257 258 259 260 261 263 264 265 267 268 269 270 271 273 274 275 276 278 279 280 281 283 284 285 286 287 289 290 291 293 294 295 296 297 298 301 302 304 305 306 307 308 309 310 312 314 315 316 317 318 319 320 321 324 325 326 327 328 329 340 341 342 345 346 347 348 349 350 351 352 354 356 357 358 359 360 361 362 364 365 367 368 369 370 371 372 374 375 376 378 379 380 381 382 384 385 386 387 389 390 391 392 394 395 396 397 398 401 402 403 405 406 407 408 409 410 412 413 415 416 417 418 419 420 421 423 425 426 427 428 429 430 431 432 435 436 437 438 439 450 451 452 453 456 457 458 459 460 461 462 463 465 467 468 469 470 471 472 473 475 476 478 479 480 481 482 483 485 486 487 489 490 491 492 493 495 496 497 498 501 502 503 504 506 507 508 509 510 512 513 514 516 517 518 519 520 521 523 524 526 527 528 529 530 531 532 534 536 537 538 539 540 541 542 543 546 547 548 549 560 561 562 563 564 567 568 569 570 571 572 573 574 576 578 579 580 581 582 583 584 586 587 589 590 591 592 593 594 596 597 598 601 602 603 604 605 607 608 609 610 612 613 614 615 617 618 619 620 621 623 624 625 627 628 629 630 631 632 634 635 637 638 639 640 641 642 643 645 647 648 649 650 651 652 653 654 657 658 659 670 671 672 673 674 675 678 679 680 681 682 683 684 685 687 689 690 691 692 693 694 695 697 698 701 702 703 704 705 706 708 709 710 712 713 714 715 716 718 719 720 721 723 724 725 726 728 729 730 731 732 734 735 736 738 739 740 741 742 743 745 746 748 749 750 751 752 753 754 756 758 759 760 761 762 763 764 765 768 769 780 781 782 783 784 785 786 789 790 791 792 793 794 795 796 798 801 802 803 804 805 806 807 809 810 812 813 814 815 816 817 819 820 821 823 824 825 826 827 829 830 831 832 834 835 836 837 839 840 841 842 843 845 846 847 849 850 851 852 853 854 856 857 859 860 861 862 863 864 865 867 869 870 871 872 873 874 875 876 879 890 891 892 893 894 895 896 897 901 902 903 904 905 906 907 908 910 912 913 914 915 916 917 918 920 921 923 924 925 926 927 928 930 931 932 934 935 936 937 938 940 941 942 943 945 946 947 948 950 951 952 953 954 956 957 958 960 961 962 963 964 965 967 968 970 971 972 973 974 975 976 978 980 981 982 983 984 985 986 987</p><h3 id="11、函数">11、函数</h3><h4 id="11-1-基本概念">11.1 基本概念</h4><ol><li>函数是一段具有特定功能的、<code>可重用</code>的语句组，通过函数名进行功能调用。</li><li>函数也可以看作是一段具有名字的<code>子程序</code>，可以在需要的地方调用执行，不需要在每个执行地方重复编写这些语句。</li><li>每次使用函数可以提供不同的参数作为输入，以实现对不同数据的处理；函数执行后，还可以反馈相应的处理结果。</li><li>函数是一个功能抽象：完成特定功能，与黑盒类似，对函数的使用不需要了解函数内部实现原理，只要了解函数的输入输出方式。</li><li>分类：<br>1）用户定义函数：用户自己编写的子程序<br>2）系统自带函数及第三方函数：Python内嵌的函数（如abs()、map()）、Python标准库中的函数（如 math 库中的 sqrt() ）等</li><li>使用函数的目的<br>1）降低编程难度<br>2）代码复用</li></ol><h4 id="11-2-函数定义">11.2 函数定义</h4><ol><li>python 定义一个函数使用 def 保留字，语法形式如下：</li></ol><pre><code class="highlight plaintext">def &lt;函数名&gt;(&lt;参数列表&gt;):&lt;函数体&gt;return &lt;返回值列表&gt;</code></pre><ol start="2"><li><p>函数名<code>&lt;name&gt;</code>：可以是任何有效的Python标识符。</p></li><li><p>参数列表<code>&lt;parameters&gt;</code>：是调用函数时传递给它的值（可以由零个，一个或者多个参数组成），当有多个参数时，各个参数用逗号分隔。</p></li><li><p>函数体<code>&lt;body&gt;</code>：函数被调用时执行的代码，由一个或多个语句组成</p></li><li><p>函数调用的一般形式：</p></li></ol><pre><code class="highlight plaintext">&lt;name&gt;(parameters)</code></pre><h4 id="11-3-函数定义-Tips">11.3 函数定义 Tips</h4><ol><li>不需要说明形参类型，Python 解释器会根据实参的值<code>自动推断</code>形参类型。</li><li>不需要指定函数返回值类型，这由函数中 return 语句返回的值的类型来确定。如果函数没有明确的返回值，Python 认为返回空值 None。</li><li>即使该函数不需要接受任何参数，也必须保留一对空的英文半角圆括号。</li><li>函数头部括号后面的<code>冒号</code>必不可少。</li><li>函数体相对于 def 关键字必须保持一定的<code>空格缩进</code>。</li></ol><p><strong>函数定义示例1</strong></p><ol><li>定义函数</li></ol><pre><code class="highlight plaintext">def add1(x):x = x + 1return 1</code></pre><ol start="2"><li>函数功能：将传给它的数值增1，返回增加后的值 return 语句：结束函数调用，并将结果返回给调用者。</li><li>return 语句是可选的，可出现在函数体任意位置没有 return 语句，函数在函数体结束位置将控制权返回给调用方。</li></ol><p><strong>函数定义示例2</strong></p><ol><li>编写一个程序打印“Happy Birthday”的歌词。<br>标准的歌词：</li></ol><pre><code class="highlight plaintext">Happy Birthday to you!Happy Birthday to you!Happy Birthday to you, dear &lt;insert-name&gt;Happy Birthday to you!</code></pre><p><strong>方法一：使用4个 print 语句</strong></p><pre><code class="highlight plaintext">print("Happy Birthday to you!")print("Happy Birthday to you!")print("Happy Birthday to you, dear Jack!")print("Happy Birthday to you!")</code></pre><p><strong>方法二：使用函数来打印歌词的第一、二、四行</strong></p><pre><code class="highlight plaintext">def happy():print("Happy Birthday to you!")happy()happy()print("Happy Birthday to you, dear Jack!")happy()</code></pre><p><strong>写出给 Jack 和 Tom 唱生日歌的程序</strong></p><p><strong>方法三：函数嵌套调用、分别定义singJack()和singTom()函数</strong></p><pre><code class="highlight plaintext">def happy():print("Happy Birthday to you!")def singJack():happy()happy()print("Happy Birthday to you, dear Jack!")happy()def singTom():happy()happy()print("Happy Birthday to you, dear Tom!")happy()singJack()print()singTom()</code></pre><p><strong>方法四：简化程序，编写通用函数sing()函数唱生日歌</strong></p><pre><code class="highlight plaintext">def happy():print("Happy Birthday to you!")def sing(person):happy()happy()print("Happy Birthday to you,", person + "!")happy()sing("Jack")print()sing("Tom")</code></pre><p><strong>结果：</strong><br>Happy Birthday to you!<br>Happy Birthday to you!<br>Happy Birthday to you, Jack!<br>Happy Birthday to you!</p><p>Happy Birthday to you!<br>Happy Birthday to you!<br>Happy Birthday to you, Tom!<br>Happy Birthday to you!</p><h4 id="11-4-函数调用">11.4 函数调用</h4><ol><li>函数调用执行的四个步骤：<br>1）调用程序在调用处暂停执行。<br>2）函数的形参在调用时被赋值为实参。<br>3）执行函数体。<br>4）函数被调用结束，给出返回值。</li></ol><pre><code class="highlight plaintext">def happy():print("Happy Birthday to you!")def sing(person):happy()happy()print("Happy Birthday to you,", person + "!")happy()sing("Jack")print()sing("Tom")</code></pre><h4 id="11-5-函数参数传递">11.5 函数参数传递</h4><ol><li>可选参数和可变数量参数。</li><li>在定义函数时，有些参数可以存在默认值。</li><li>在函数定义时，可以设计可变数量参数，通过参数前增加星号（*）实现。</li></ol><pre><code class="highlight plaintext">def dup(str, times = 2):print(str * times)dup("knock~")dup("knock~", 4)</code></pre><p><strong>结果：</strong><br>knock~knock~<br>knock~knock~knock~knock~</p><h4 id="11-6-函数返回值">11.6 函数返回值</h4><ol><li>return 语句：程序退出该函数，并返回到函数被调用的地方。</li><li>return 语句返回的值传递给调用程序。</li><li>Python 函数的返回值有两种形式：<br>1）没有返回值：无返回值的 return 语句等价于 return None<br>2）返回一个或多个值</li><li>返回值可以是一个变量，也可以是一个表达式</li></ol><pre><code class="highlight plaintext">def square(x):y = x*xreturn ydef square(x):return x*x</code></pre><h4 id="11-7-lambda-函数">11.7 lambda 函数</h4><ol><li>lambda 保留字用于定义一种特殊的函数——匿名函数，又称 lambda函数</li><li>匿名函数并非没有名字，而是将函数名作为函数结果返回，如下：<br>&lt;函数名&gt; = lambda &lt;参数列表&gt; : &lt;表达式&gt;</li><li>lambda 函数与正常函数一样，等价于下面形式：</li></ol><pre><code class="highlight plaintext">def &lt;函数名&gt;(&lt;参数列表&gt;):return &lt;表达式&gt;</code></pre><ol start="4"><li>简单说，lambda 函数用于定义简单的、能够在一行内表示的函数，返回一个函数类型。</li></ol><p>f  = lambda x,y : x+y</p><p><strong>lambda函数示例</strong></p><ol><li><p>filter 操作 python 语法实现<br>print [x for x in foo if x % 3 == 0]</p></li><li><p>map 操作 python 语法实现<br>print [x * 2 + 10 for x in foo]</p></li></ol><pre><code class="highlight plaintext">foo = [2, 18, 9, 22, 17, 24, 8, 12, 27]print (list(filter(lambda x: x % 3 == 0, foo)))print (list(map(lambda x: x * 2 + 10, foo)))</code></pre><p><strong>结果：</strong><br>[18, 9, 24, 12, 27]<br>[14, 46, 28, 54, 44, 58, 26, 34, 64]</p><h4 id="11-8-lambda-函数特点">11.8 lambda 函数特点</h4><ol><li>lambda 的使用大量简化了代码，使代码简练清晰。但是值得注意的是，这会在一定程度上降低代码的可读性。</li><li>lambda 定义了一个匿名函数。</li><li>lambda 并不会带来程序运行效率的提高，只会使代码更简洁。</li><li>如果可以使用 for … in … if 来完成的，坚决不用 lambda。</li><li>如果使用 lambda，lambda 内不要包含循环，如果有，建议定义函数来完成，使代码获得可重用性和更好的可读性。</li><li>总结：lambda 是为了减少单行函数的定义而存在的。</li></ol><h4 id="11-9-变量作用域">11.9 变量作用域</h4><ol><li>一个程序中的变量包括两类：<code>全局变量</code>和<code>局部变量</code>。</li><li>全局变量指在<code>函数之外</code>定义的变量，一般没有缩进，在程序执行<code>全过程</code>有效。</li><li>局部变量指在<code>函数内部使用</code>的变量，仅在函数内部有效，当函数退出时变量将不存在。</li></ol><pre><code class="highlight plaintext">n = 1def func(a, b):global nn = bc = a*breturn cs = func("knock~", 4)print(s, n)</code></pre><p><strong>结果：</strong><br>knock~knock~knock~knock~ 4</p><h4 id="11-10-递归">11.10 递归</h4><ol><li>递归定义：函数定义中使用函数自身的方法。</li><li>递归在数学和计算机应用中非常强大，能够非常简洁的解决很多问题。</li><li>经典递归例子：阶乘。</li></ol><p>n! = n(n-1)(n-2)(n-3)…(1)<br>5! = 5(4)(3)(2)(1)<br>n! = n(n-1)!</p><ol start="4"><li>阶乘的递归定义函数：</li></ol><pre><code class="highlight plaintext">def fact(n):if n == 0:return 1else:return n* fact(n-1)print(fact(5))</code></pre><p><strong>结果：</strong><br>120</p><h4 id="11-11-递归示例：字符串反转">11.11 递归示例：字符串反转</h4><p><strong>方法一：字符串转换为字符列表，反转列表，列表转换回字符串。</strong></p><pre><code class="highlight plaintext">def reverseStr(s):ls = list(s)ls.reverse()s = "".join(ls)print(s)str = "sdfadfw8r873r323230"reverseStr(str)</code></pre><p><strong>结果：</strong><br>032323r378r8wfdafds</p><p><strong>方法二：递归</strong></p><ol><li>将字符串分割成首字符和剩余子字符串</li><li>反转了剩余部分后把首字符放到末尾，整个字符串反转就完成了</li></ol><pre><code class="highlight plaintext">def reverseRecu(s):if len(s) &lt;= 0:return ""else:return reverseRecu(s[1:]) + s[0]str = "sdfadfw8r873r323230"print(reverseRecu(str))</code></pre><p><strong>结果：</strong><br>032323r378r8wfdafds</p><h3 id="12、类与对象">12、类与对象</h3><h4 id="12-1-面向过程与面向对象">12.1 面向过程与面向对象</h4><ol><li><p>程序包括<br>数据：数据类型、数据结构<br>处理过程：算法</p></li><li><p>两种程序设计思想<br>1）面向过程：以操作为中心、面向过程把函数继续切分为子函数，即把大块函数通过切割成小块函数来降低系统的复杂度（C语言）</p></li></ol><p>2）面向对象：以数据为中心、把计算机程序视为一组对象的集合，而每个对象都可以接收其他对象发过来的消息，并处理这些消息，计算机程序的执行就是一系列消息在各个对象之间传递(Python)</p><h4 id="12-2-面向过程与面向对象">12.2 面向过程与面向对象</h4><ol><li><p>Python 虽然是解释型语言，但从设计之初就已经是一门面向对象的语言，对于 Python 来说<code>一切皆为对象</code>。</p></li><li><p>Python 中对象的概念很广泛，Python 中的一切内容都可以称为对象，而不一定必须是某个类的实例。例如，字符串、列表、字典、元组等内置数据类型都具有和类完全相似的语法和用法。</p></li></ol><h4 id="12-3-对象例子">12.3 对象例子</h4><ol><li><p>人<br>数据：姓名，出生日期，身高，体重，…<br>操作：计算年龄，判断体重是否标准，…</p></li><li><p>电视机<br>数据：型号，厂商，尺寸，频道数，…<br>操作：开机，关机，调频道，调音量，…</p></li><li><p>室内环境<br>数据：温度，湿度，容积，…<br>操作：调节温度，调节湿度，换算容积单位</p></li></ol><h4 id="12-4-类概述">12.4 类概述</h4><ol><li>类是类型概念的发展<br>1）对象是广义的“数据值”。<br>2）对象所属的数据类型就是“类”。<br>3）用于描述复杂数据的静态和动态行为。</li><li>类（class）：描述相似对象的共性。包括<br>1）数据<br>2）操作：方法（method）</li><li>对象是类的实例（instance）</li></ol><h4 id="12-5-类与对象">12.5 类与对象</h4><ol><li>类是对现实事物的抽象<br>1）数据抽象，例如：从具体学生抽象出姓名，年龄，地址等数据。<br>2）行为抽象，例如：从学生日常行为抽象出选课，加入社团等操作。<br>3）于是产生了类 Student 的定义。</li><li>抽象可以在多个层次上进行<br>例如：学生-人-动物-生物</li></ol><h4 id="12-6-类封装的好处">12.6 类封装的好处</h4><ol><li>安全：对象自己的方法处理自己的数据。</li><li>易用：使用者无需了解内部实现细节。</li><li>易维护：实现者修改内部实现不会影响使用者。</li><li>标准化：同类甚至不同类的对象对使用者都呈现同样的操作界面。</li></ol><h4 id="12-7-类定义">12.7 类定义</h4><p>实例化后，可以使用其属性。</p><pre><code class="highlight plaintext">class &lt;类名&gt;:&lt;方法定义&gt;</code></pre><h4 id="12-8-类对象">12.8 类对象</h4><ol><li>类对象支持两种操作：属性引用和实例化。</li><li>属性引用使用和 Python 中所有的属性引用一样的标准语法：<a href="http://obj.name">obj.name</a>。</li><li>类对象创建后，类命名空间中所有的命名都是有效属性名。</li></ol><h4 id="12-9-Person-类">12.9 Person 类</h4><p>Person 类定义</p><p><code>这是一个学校 Python 定义的一个 Person类</code></p><pre><code class="highlight plaintext">class Person:# 下面定义了一个类变量hair = 'black'def __init__(self, name='Charlie', age=8):# 下面为 Person 对象增加2个实例变量self.name = nameself.age = age# 下面定义了一个say方法def say(self, content):print(content)</code></pre><p><strong>注释：</strong></p><ol><li>类有一个名为<code>__init__()</code>的特殊方法（构造方法），该方法在类实例化时会自动调用</li><li>类的方法与普通的函数只有一个特别 的区别----他们必须有一个额外的第一个参数名称，按照惯例它的名称是self</li></ol><h4 id="12-10-Person-类实例化与使用">12.10 Person 类实例化与使用</h4><pre><code class="highlight plaintext"># 调用Person类的构造方法，返回一个Person对象# 将该Person对象赋给p对象p = Person()# 输出p的name、age实例变量print(p.name, p.age)  # Charlie8# 访问p的name实例变量，直接为该实例变量赋值p.name = '李刚'# 调用p的say()方法，声明say()方法时定义了2个形参# 但第一个形参（self）是自动绑定的，因此调用该方法只需为第二个形参指定一个值p.say('Python语言很简单，学习很容易！')# 再次输出p的name、age实例变量print(p.name, p.age) # 李刚 8</code></pre><p><strong>结果：</strong><br>Charlie 8<br>Python语言很简单，学习很容易！<br>李刚 8</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一章 Python 概述与开发环境安装</title>
      <link href="/2020/04/30/di_yi_zhang_python_gai_shu_yu_kai_fa_huan_jing_an_zhuang/"/>
      <url>/2020/04/30/di_yi_zhang_python_gai_shu_yu_kai_fa_huan_jing_an_zhuang/</url>
      
        <content type="html"><![CDATA[<h2 id="第一章-Python-概述与开发环境安装">第一章 Python 概述与开发环境安装</h2><h3 id="1、Python-开发环境安装">1、Python 开发环境安装</h3><h3 id="2、Anaconda-安装">2、Anaconda 安装</h3><p>选择 just me<br>不用勾选添加本地环境变量</p><ol><li>查看 Anaconda 环境是否安装成功（查看 Anaconda 版本号）：conda --version</li><li>查看目前安装了哪些环境变量：conda info --envs</li><li>查看 Anaconda 当前版本以及安装了哪些包：conda list</li></ol><h3 id="3、Spyder">3、Spyder</h3><h4 id="3-1-读取文件里面的行数">3.1 读取文件里面的行数</h4><pre><code class="highlight plaintext">import sys import os.path# 文件目录dir = os.path.dirname(sys.executable)# 打开文件进行操作with open(dir+'\\num.txt', encoding = 'utf-8') as fp:    content = fp.readlines()    # 打印文件内容的类型print(type(content))# 打印文件内容print(content)# 打印文件所在的目录print(dir)# 打印文件里面内容的行数print(len(content))</code></pre><p><strong>结果：</strong><br>&lt;class ‘list’&gt;<br>[‘12\n’, ‘6\n’, ‘2\n’, ‘35\n’, ‘11\n’, ‘22\n’, ‘23\n’, ‘11\n’, ‘254\n’, ‘12’]<br>F:\Anaconda<br>10</p><h3 id="4、Jupyter-Notebook">4、Jupyter Notebook</h3><p>默认地址：<a href="http://localhost:8888">http://localhost:8888</a></p><pre><code class="highlight plaintext"># 使用递归def fib(n):    if n==1 or n==2:        return 1    elif n==0:        return 0    return fib(n-1)+fib(n-2)# 输出第10个斐波那契数列print(fib(10))print(fib(0))</code></pre><p><strong>结果：</strong><br>55<br>0</p><h3 id="5、Python-环境管理">5、Python 环境管理</h3><h4 id="5-1-打开管理终端">5.1 打开管理终端</h4><p>Windows用户打开“Anaconda Prompt”</p><p>macOS和Linux用户打开"Terminal"（终端）</p><h4 id="5-2-创建新环境">5.2 创建新环境</h4><pre><code class="highlight plaintext">conda create --name &lt;env_name&gt; &lt;package_name&gt;</code></pre><p><strong>注：</strong></p><ol><li><code>env_name</code>–创建的环境名，建议英文命名，且不加空格，名称两边不加尖括号"&lt;&gt;"</li><li><code>package_name</code>–安装环境中的包名，名称两边不加尖括号"&lt;&gt;"</li><li>如果要安装指定的版本号， 则只需要在包名后面以=和版本号的形式执行。如：<code>conda create name python2  python=2.7</code>，即创建一个名为“python2”的环境，环境中安装版本为2.7的 python。</li><li>如果要在新创建的环境中创建多个包，则直接在<code>&lt;package_names&gt;</code>后以空格隔开，添加多个即可。如：<code>conda create -n python3 python=3.7 numpy pandas</code>，即创建一个名为“python”的环境，环境中安装版本为 3.7 的 python，同时也安装了<code>numpy</code>和<code>pandas</code>。</li><li>默认情况下，新创建的环境会被保存在<code>/User/&lt;username&gt;/anaconda3/env</code>目录下，其中<code>&lt;user_name&gt;</code>为系统当前用户的用户名。</li></ol><h4 id="5-3-激活-退出环境">5.3 激活/退出环境</h4><p>激活：<code>conda activate python3</code></p><p>退出：<code>conda deactivate</code></p><h4 id="5-4-删除环境">5.4 删除环境</h4><p><code>conda  remove --name python3 --all</code></p><h3 id="6、Python-扩展库安装">6、Python 扩展库安装</h3><h4 id="6-1-添加清华大学的-Anaconda-镜像">6.1 添加清华大学的 Anaconda 镜像</h4><pre><code class="highlight plaintext">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/# 设置搜索时显示通道地址conda config --set show_channel_urls yes</code></pre><p><code>conda install numpy</code> 测试</p><p><strong>查询可供安装的扩展库版本</strong><br><code>conda search --full-name pandas</code></p><p><strong>获取当前环境中已安装的扩展库信息</strong><br><code>conda list</code></p><h4 id="6-2-在指定环境中安装包">6.2 在指定环境中安装包</h4><pre><code class="highlight plaintext">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yesconda activate python3conda install numpy</code></pre><h4 id="6-3-在当前环境中卸载包">6.3 在当前环境中卸载包</h4><p><code>conda remove &lt;package_name&gt;</code></p><h4 id="6-4-在指定环境中卸载包">6.4 在指定环境中卸载包</h4><p><code>conda remove --name &lt;env_name&gt; &lt;package_name&gt;</code></p><h3 id="7、-Python-扩展库导入">7、 Python 扩展库导入</h3><p><strong>建议先导入标准库再导入扩展库对象，只导入确实需要使用的标准库和扩展库对象，提高加载速度，减少打包体积</strong></p><h4 id="7-1-import-模块名-as-别名">7.1 import 模块名[as 别名]</h4><p><strong>使用时需要在对象之前加上模块名作为前缀，即“模块名.对象名”</strong></p><pre><code class="highlight plaintext">import math import randomimport posixpath as pathprint(math.sqrt(16))# 计算并输出16的平方根print(math.cos(math.pi/4))# 计算余弦值print(random.choices('abcd', k=8))# 从字符串'abcd'随机选择8个字符# 允许重复print(path.isfile(r'C:Windows\notepad.exe'))#测试指定路径是否为文件</code></pre><p><strong>结果：</strong><br>4.0<br>0.7071067811865476<br>[‘b’, ‘b’, ‘d’, ‘b’, ‘a’, ‘d’, ‘a’, ‘c’]<br>False</p><h4 id="7-2-from-模块名-import-对象名-as-别名">7.2 from  模块名  import  对象名 [as 别名]</h4><p>不需要模块名作为前缀，导入方式可以减少查询次数，提高访问速度</p><pre><code class="highlight plaintext">from math import pi as PIfrom os.path import getsizefrom random import choicer = 3print(round(PI*r*r, 2)) # 计算半径为3的圆面积print(getsize(r'C:Windows\notepad.exe'))# 计算文件大小，单位为字节print(choice('Python'))# 从字符串中随机选择一个字符</code></pre><p><strong>结果：</strong><br>28.27<br>254464<br>o</p><h4 id="7-3-from-模块名-import">7.3 from  模块名  import  *</h4><p><strong>不推荐使用</strong></p><pre><code class="highlight plaintext">from itertools import *characters = '1234'for item in combinations(characters, 3):# 从4个字符中任选3个组合print(item, end=' ')                    # end=' ' 表示输出后不换行print('\n'+'='*20)                          # 行号后输出20个等于号for item in permutations(characters, 3):# 从4个字符中任选3个的排列print(item, end=' ')</code></pre><h3 id="8、Python-常用标准库">8、Python 常用标准库</h3><h4 id="8-1-字符串">8.1 字符串</h4><p><code>re</code>：正则表达式。用来判断是否是你指定的特定字符串。<br><code>StringIO</code>：提供以文件形式来读写字符串。<br><code>struct</code>：以二进制字节序列来解释字符串。可以通过格式化参数，指定类型、长度、字节序（大小端）、内存对齐等。</p><pre><code class="highlight plaintext">import re print(re.findall(r'f[a-z]*',  'which foot or hand fell fastest'))</code></pre><p><strong>结果：</strong><br>[‘foot’, ‘fell’, ‘fastest’]</p><p>如果只需要简单的功能，应该首先考虑字符串，因为简单，易于阅读和调试，如：</p><pre><code class="highlight plaintext">print('tea for too'.replace(''too,''two'))</code></pre><p>结果：<br>‘tea for two’</p><h4 id="8-2-数据类型">8.2  数据类型</h4><p><code>datetime</code>：提供操作日期和时间的类。<br><code>collections</code>：高性能容器数据类型。实现了Python的通用内置容器、字典、列表、集合，和元组专门的数据类型。<br><code>pprint</code>：提供“整洁打印”功能，具有打印任意Python数据结构的能力。</p><h4 id="8-3-数学运算">8.3 数学运算</h4><p><code>random</code>：各种分布的伪随机数的生成器。<br><code>math</code>：数学函数。提供了由C标准的数学函数访问。该库函数不适用于复数。<br><code>cmath</code>：为复数提供的数学函数。<br><code>operator</code>： 重载运算符。</p><p><strong>math 模块为浮点运算提供了对底层C函数库的访问</strong></p><pre><code class="highlight plaintext">import math print(math.cos(math.pi/4))print(math.log(1024, 2))</code></pre><p><strong>结果：</strong><br>0.7071067811865476<br>10.0</p><p><strong>random 提供了生成随机数的工具</strong></p><pre><code class="highlight plaintext">import randomfruits = random.choice(['apple', 'pear', 'banana'])x = random.sample(range(100), 10) # 0-100选择不能重复的10个数y = random.random()# 随机浮点数z = random.randrange(6)# 从范围0-6中选择随机整数print(fruits)print(x)print(y)print(z)</code></pre><p><strong>结果：</strong><br>apple<br>[64, 97, 91, 21, 40, 55, 63, 79, 77, 1]<br>0.8885638928051524<br>0</p><h4 id="8-4-文件和目录">8.4 文件和目录</h4><p><code>os.path</code>：常用路径名操作。<br><code>filecmp</code>：文件和目录的比较。<br><code>shutil</code>：高级的文件操作：支持文件复制和删除。</p><h4 id="8-5-操作系统">8.5 操作系统</h4><p><code>time</code>：时间获取和转换，各种与时间相关的函数。<br><code>argparse</code>：命令行选项、参数和子命令的解析器。<br><code>io</code>：提供接口处理的IO流。<br><code>logging</code>： Python的日志工具，提供日志记录的API。<br><code>logging.config</code>：Python日志配置，用于配置日志模块的API。<br><code>os</code>：提供丰富的与MAC，NT，Posix等操作系统进行交互的能力。<br><code>sys</code>：提供访问和维护python解释器的能力。这包括了提示信息，版本，整数的最大值，可用模块，路径钩子，标准错误，标准输入输出的定位和解释器调用的命令参数。</p><p><strong>os 模块提供了不少与操作系统相关联的函数</strong></p><pre><code class="highlight plaintext">import os print(os.getcwd())# 返回当前的工作目录os.chdir(r'C:Users\winner\Python3Learn\Lesson1Code') # 修改当前的工作目录os.system('mkdir today') # 执行系统命令 mkdirprint(os.getcwd())# 返回当前的工作目录</code></pre><p>建议使用 <code>import os</code> 风格而非<code>from os import *</code>，这样可以保证随操作系统不同而有所变化的 os.open() 不会覆盖内置函数 open()。</p><p>在使用 os 这样的大型模块时，内置的 dir() 和 help() 函数非常有用。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL将Windows和Linux时区同步的时区表</title>
      <link href="/2020/04/03/wang_zhan_zai_ai_dao_jie_ri_shi_shi_zheng_ge_ye_mian_hui_se_de_dai_ma/"/>
      <url>/2020/04/03/wang_zhan_zai_ai_dao_jie_ri_shi_shi_zheng_ge_ye_mian_hui_se_de_dai_ma/</url>
      
        <content type="html"><![CDATA[<h3 id="网站在哀悼节日时使整个页面灰色的代码">网站在哀悼节日时使整个页面灰色的代码</h3><p>html {<br>-webkit-filter: grayscale(100%);<br>-moz-filter: grayscale(100%);<br>-ms-filter: grayscale(100%);<br>-o-filter: grayscale(100%);<br>filter: grayscale(100%);<br>filter: progid:DXImageTransform.Microsoft.BasicImage(grayscale=1);<br>}</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 哀悼 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>npm换成淘宝的源</title>
      <link href="/2020/02/26/npm_huan_cheng_tao_bao_de_yuan/"/>
      <url>/2020/02/26/npm_huan_cheng_tao_bao_de_yuan/</url>
      
        <content type="html"><![CDATA[<p><strong>安装npm install时，长时间停留在fetchMetadata: sill fetchPackageMetaData error for …</strong></p><p><strong>方法如下</strong></p><h3 id="更换成淘宝的源">更换成淘宝的源</h3><p>npm config set registry&nbsp;<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a></p><h3 id="验证是否成功">验证是否成功</h3><p>npm config get registry</p>]]></content>
      
      
      <categories>
          
          <category> npm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> npm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL将Windows和Linux时区同步的时区表</title>
      <link href="/2020/02/26/mysql_jiang_windows_he_linux_shi_qu_tong_bu_de_shi_qu_biao/"/>
      <url>/2020/02/26/mysql_jiang_windows_he_linux_shi_qu_tong_bu_de_shi_qu_biao/</url>
      
        <content type="html"><![CDATA[<p><strong>时区表</strong> mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root mysql -p</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Github Hexo 建站</title>
      <link href="/2020/02/24/github_hexo_jian_zhan/"/>
      <url>/2020/02/24/github_hexo_jian_zhan/</url>
      
        <content type="html"><![CDATA[<h2 id="Github-Hexo-建站">Github Hexo 建站</h2><h3 id="初始化">初始化</h3><pre><code class="highlight plaintext">hexo initgit initnpm install --save hexo-deployer-git</code></pre><h3 id="代码高亮">代码高亮</h3><pre><code class="highlight plaintext">npm i -S hexo-prism-plugin</code></pre><h3 id="搜索">搜索</h3><pre><code class="highlight plaintext">npm install hexo-generator-search --save</code></pre><h3 id="中文链接转拼音">中文链接转拼音</h3><pre><code class="highlight plaintext">npm i hexo-permalink-pinyin --save</code></pre><h3 id="文章字数统计插件">文章字数统计插件</h3><pre><code class="highlight plaintext">npm i --save hexo-wordcount</code></pre><h3 id="添加-RSS-订阅支持">添加 RSS 订阅支持</h3><pre><code class="highlight plaintext">npm install hexo-generator-feed --save</code></pre><h3 id="添加百度sitemap-xml">添加百度sitemap.xml</h3><pre><code class="highlight plaintext">npm install hexo-generator-sitemap --save-devnpm install hexo-generator-baidu-sitemap --save-dev</code></pre><h3 id="生成静态文件和部署到github">生成静态文件和部署到github</h3><pre><code class="highlight plaintext">hexo ghexo d</code></pre>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django阿里云部署详解之服务器安装安装Nginx</title>
      <link href="/2020/02/22/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_an_zhuang_nginx/"/>
      <url>/2020/02/22/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_an_zhuang_nginx/</url>
      
        <content type="html"><![CDATA[<h3 id="Django阿里云部署详解之服务器安装安装Nginx">Django阿里云部署详解之服务器安装安装Nginx</h3><h4 id="（本系统就是阿里云部署的）">（本系统就是阿里云部署的）</h4><h4 id="大家照做就行，这我试了很多次才总结出来的">大家照做就行，这我试了很多次才总结出来的</h4><p>这个在开始准备环境时已经安装了</p><pre><code class="highlight plaintext">yum install epel-releaseyum install -y nginx</code></pre><p>在/etc/nginx/nginx.conf里面修改sever{}</p><pre><code class="highlight plaintext">listen 443 ssl;server_name 你的网站名字;charset utf-8;ssl_certificate cert/?.pem;ssl_certificate_key cert/?.key;ssl_session_timeout 5m;ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;ssl_protocols TLSv1 TLSv1.1 TLSv1.2;ssl_prefer_server_ciphers on;client_max_body_size 75M;location /static {alias /home/tests/static_collected;}location /media {alias /home/tests/media;}location / {uwsgi_pass 127.0.0.1:8001;include /etc/nginx/uwsgi_params;}</code></pre><p><strong>查看运行nginx</strong></p><pre><code class="highlight plaintext">nginx -tservice nginx restartservice nginx reloadservice nginx startservice nginx statusservice nginx stop</code></pre><p><strong>找到运行的端口号</strong></p><pre><code class="highlight plaintext">netstat -antp</code></pre><p><strong>杀死进程</strong></p><pre><code class="highlight plaintext">kill -9  编号</code></pre>]]></content>
      
      
      <categories>
          
          <category> Django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>github ssh 连接失败解决方法</title>
      <link href="/2020/02/21/github_ssh_lian_jie_shi_bai_jie_jue_fang_fa/"/>
      <url>/2020/02/21/github_ssh_lian_jie_shi_bai_jie_jue_fang_fa/</url>
      
        <content type="html"><![CDATA[<h3 id="github-ssh-连接失败">github ssh 连接失败</h3><p>$ ssh -T <a href="mailto:git@github.com">git@github.com</a><br>ssh: connect to host <a href="http://github.com">github.com</a> port 22: Connection timed out</p><h3 id="解决方法">解决方法</h3><p>在.ssh下面新加config文件，不要后缀，内容如下：</p><pre><code class="highlight plaintext">Host github.comUser 417952939@qq.comHostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 22</code></pre>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django阿里云部署详解之服务器安装安装uwsgi</title>
      <link href="/2020/02/16/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_an_zhuang_uwsgi/"/>
      <url>/2020/02/16/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_an_zhuang_uwsgi/</url>
      
        <content type="html"><![CDATA[<h3 id="Django阿里云部署详解之服务器安装安装uwsgi">Django阿里云部署详解之服务器安装安装uwsgi</h3><h4 id="（本系统就是阿里云部署的）">（本系统就是阿里云部署的）</h4><h4 id="大家照做就行，这我试了很多次才总结出来的">大家照做就行，这我试了很多次才总结出来的</h4><h4 id="1、安装uwsgi">1、安装uwsgi</h4><p>注意：<br>1）在系统环境安装，非虚拟环境<br>2）使用对应python版本安装<br>3）要先安装python开发包<br><strong>pip install uwsgi</strong></p><h4 id="2、测试-uwsgi-是否正常">2、测试 uwsgi 是否正常</h4><p>vim <a href="http://test.py">test.py</a><br>新建 <a href="http://test.py">test.py</a> 文件，内容如下：</p><pre><code class="highlight plaintext">def application(env, start_response):    start_response('200 OK', [('Content-Type','text/html')])    return "Hello World"</code></pre><p>然后在终端运行：</p><pre><code class="highlight plaintext">uwsgi --wsgi-file test.py  --http :8001</code></pre><p>注意：需要开启端口才可以正常访问<br><strong>杀死uwsgi</strong></p><pre><code class="highlight plaintext">ps -aux | grep uwsgi + awk '{print $2}' | xargs kill -9</code></pre><h4 id="3、可以用uwsgi的http协议访问django写的网站">3、可以用uwsgi的http协议访问django写的网站</h4><p>执行如下命令可以测试自己的项目</p><pre><code class="highlight plaintext">uwsgi --http :8001 --chdir /home/tests --home /home/test_env --module tests.wsgi:application</code></pre><p><strong>mkdir tests_uwsgi</strong><br><strong>tests.ini</strong></p><pre><code class="highlight plaintext">[uwsgi]chdir=/home/tests    #项目地质home=/home/test_env  #环境地质module=tests.wsgi:applicationmaster=Trueprocesses=4  #工作进程数harakiri=60  #60秒重启max-requests=5000  #服务5000个请求后重新启动进程socket=127.0.0.1:8001uid=nginxgid=nginxpidfile=/home/tests_uwsgi/master.piddaemonize=/home/tests_uwsgi/tests.logvacuum=True   #清理</code></pre><p><strong>初始化ini</strong><br>uwsgi --ini /home/tests_uwsgi/tests.ini</p><p><strong>重新运行uwsgi</strong><br>uwsgi --reload /home/tests_uwsgi/master.pid</p><p><strong>查看uwsgi是否运行</strong><br>ps aux | grep uwsgi</p>]]></content>
      
      
      <categories>
          
          <category> Django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django阿里云部署详解之服务器安装MySQL8.0系列的版本（服务器是Linux的系统）</title>
      <link href="/2020/02/10/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_mysql8.0_xi_lie_de_ban_ben_fu_wu_qi_shi_linux_de_xi_tong/"/>
      <url>/2020/02/10/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_mysql8.0_xi_lie_de_ban_ben_fu_wu_qi_shi_linux_de_xi_tong/</url>
      
        <content type="html"><![CDATA[<h3 id="Django阿里云部署详解之服务器安装MySQL8-0系列的版本（服务器是Linux的系统）">Django阿里云部署详解之服务器安装MySQL8.0系列的版本（服务器是Linux的系统）</h3><h4 id="（本系统就是阿里云部署的）">（本系统就是阿里云部署的）</h4><h4 id="大家照做就行，这我试了很多次才总结出来的">大家照做就行，这我试了很多次才总结出来的</h4><pre><code class="highlight plaintext">wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpmrpm -ivh mysql80-community-release-el7-3.noarch.rpmyum -y install mysql-community-server</code></pre><h4 id="修改-etc-my-cnf">修改/etc/my.cnf</h4><pre><code class="highlight plaintext">[mysqld]# 设置mysql的安装目录basedir=/usr/local/mysql# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql/data# 设置默认使用的端口port=3306# 允许最大连接数max_connections=200# 允许连接失败的次数。这是为了防止有人试图攻击数据库max_connect_errors=10# 服务端使用的字符集character-set-server=utf8mb4# 数据库字符集对应一些排序等规则使用的字符集collation-server=utf8mb4_general_ci# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用“mysql_native_password”插件作为认证加密方式# MySQL8.0默认认证加密方式为caching_sha2_passworddefault_authentication_plugin=mysql_native_password#server_id=socket=/var/lib/mysql/mysql.sock#这里可以加也可以不加，如果有lc_messages_dir警告就加上，，lc_messages_dir=/usr/local/mysql/share lc_messages=en_USlog-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid</code></pre><h4 id="创建目录（一定要，不然初始化不成功，因为是你自己设定好的文件夹）">创建目录（一定要，不然初始化不成功，因为是你自己设定好的文件夹）</h4><p>这里要自己创建/usr/local/mysql和/usr/local/mysql/share<br>报错的时候这里加（看自己报什么错，可选）</p><pre><code class="highlight plaintext">copy /usr/share/mysql-8.0/bulgarian/errmsg.sys /usr/local/mysql/share</code></pre><pre><code class="highlight plaintext">systemctl start mysqldsystemctl status mysqldsystemctl stop mysqld</code></pre><p>初始化MySQL(有时候不一定要，在/var/log/mysqld.log里面可能有，基本上systemctl start mysqld是可以找到临时密码的)</p><pre><code class="highlight plaintext">mysqld --initialize --user=mysql</code></pre><h4 id="重置root密码">重置root密码</h4><pre><code class="highlight plaintext">alter user  'root'@'localhost' identified by 'your passwoed';</code></pre><h4 id="新建新账户针对一个数据库（为了安全起见的）">新建新账户针对一个数据库（为了安全起见的）</h4><pre><code class="highlight plaintext">show databases;create database ?_db default charset=utf8 default collate utf8_unicode_ci;create user ''@'localhost' identified by '';grant all privileges on ?_db.* to 'xiezhouHCH'@'localhost';flush privileges;</code></pre><p>新账户只能访问指定的数据库</p>]]></content>
      
      
      <categories>
          
          <category> Django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django阿里云部署详解之服务器安装虚拟环境、Python</title>
      <link href="/2020/01/31/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_xu_ni_huan_jing_python/"/>
      <url>/2020/01/31/django_a_li_yun_bu_shu_xiang_jie_zhi_fu_wu_qi_an_zhuang_xu_ni_huan_jing_python/</url>
      
        <content type="html"><![CDATA[<h3 id="Django阿里云部署详解之服务器安装虚拟环境、Python">Django阿里云部署详解之服务器安装虚拟环境、Python</h3><h4 id="（本系统就是阿里云部署的）">（本系统就是阿里云部署的）</h4><h4 id="大家照做就行，这我试了很多次才总结出来的">大家照做就行，这我试了很多次才总结出来的</h4><pre><code class="highlight plaintext">yum update -yyum -y install gcc gcc-c++yum -y groupinstall "Development tools"yum -y install zlib zlib-devel openssl openssl-devel ncurses-devel sqlite sqlite-devel bzip2-deve readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-develyum install epel-releaseyum -y install nginxyum install libffi-devel -y</code></pre><pre><code class="highlight plaintext">wget https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz</code></pre><pre><code class="highlight plaintext">mkdir -p /usr/local/python3tar -zxvf Python-3.8.1.tgz</code></pre><pre><code class="highlight plaintext">cd Python-3.8.1./configure --prefix=/usr/local/python3make &amp;&amp; make install</code></pre><pre><code class="highlight plaintext">ln -s /usr/local/python3/bin/python3 /usr/bin/python3</code></pre><p>原来的pip自己备份下：<br>mv /usr/bin/pip /usr/bin/pip.bak<br>这里使用新的pip</p><pre><code class="highlight plaintext">ln -s /usr/local/python3/bin/pip3 /usr/bin/pippip install --upgrade pip</code></pre><h4 id="修改系统默认的python为自己装的版本">修改系统默认的python为自己装的版本</h4><p>先找到新版本python安装位置，<br>然后</p><pre><code class="highlight plaintext">vi /etc/profile.d/python.sh</code></pre><p>创建新文件，然后输入</p><pre><code class="highlight plaintext">alias python='/usr/bin/python3'  # 此处的路径为新版本python的路径，通过我上一篇文章来</code></pre><p>查找此路径<br>重启会话使配置生效</p><pre><code class="highlight plaintext">source /etc/profile.d/python.sh</code></pre><pre><code class="highlight plaintext">pip install --upgrade pippip install --upgrade setuptoolspip install virtualenv</code></pre><pre><code class="highlight plaintext">ln -s /usr/local/python3/bin/virtualenv /usr/bin/virtualenvcd /home/virtualenv --python=/usr/bin/python test_envvirtualenv test_env(也一样是python3，之前已经修改了默认Python版本)source test_env/bin/activate</code></pre><h4 id="进入虚拟环境安装各个软件">进入虚拟环境安装各个软件</h4><pre><code class="highlight plaintext">pip install Django==3.0.2 pip install uwsgiln -s /usr/local/python3/bin/uwsgi /usr/bin/uwsgipip install pillowpip install django-mdeditorpip install Markdown</code></pre><h4 id="特别的，安装mysqlclient需要系统安装过mysql-devel，不然报错">特别的，安装mysqlclient需要系统安装过mysql-devel，不然报错</h4><pre><code class="highlight plaintext">yum -y install mysql-devel</code></pre><pre><code class="highlight plaintext">pip install mysqlclient</code></pre>]]></content>
      
      
      <categories>
          
          <category> Django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Django开启虚拟环境（Windows中）</title>
      <link href="/2020/01/10/django_kai_qi_xu_ni_huan_jing_windows_zhong/"/>
      <url>/2020/01/10/django_kai_qi_xu_ni_huan_jing_windows_zhong/</url>
      
        <content type="html"><![CDATA[<h3 id="Django开启虚拟环境（Windows中）">Django开启虚拟环境（Windows中）</h3><p>开启本地虚拟环境<br>1)避免多个项目之间python库的冲突<br>2)完整便捷导出python库的列表</p><pre><code class="highlight plaintext">pip install virtualenv</code></pre><p>创建：virtualenv &lt;虚拟环境名称&gt;</p><pre><code class="highlight plaintext">virtualenv blog_env</code></pre><p>启动：Scripts\activate</p><pre><code class="highlight plaintext">pip install Django</code></pre><p>退出：deactivate</p><p>建立目录</p><pre><code class="highlight plaintext">django-admin startproject django_introduction</code></pre><p>运行</p><pre><code class="highlight plaintext">python manage.py runserver 80</code></pre><p>创建应用</p><pre><code class="highlight plaintext">python manage.py startapp blog</code></pre><p>制作数据迁移</p><pre><code class="highlight plaintext">python manage.py makemigrations (app)</code></pre><p>迁移动作</p><pre><code class="highlight plaintext">python manage.py migrate</code></pre><pre><code class="highlight plaintext">python manage.py createsuperuser</code></pre>]]></content>
      
      
      <categories>
          
          <category> Django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pip 一键导出和安装</title>
      <link href="/2020/01/10/pip_yi_jian_dao_chu_he_an_zhuang/"/>
      <url>/2020/01/10/pip_yi_jian_dao_chu_he_an_zhuang/</url>
      
        <content type="html"><![CDATA[<h3 id="pip-一键导出和安装">pip 一键导出和安装</h3><p>将本地使用的虚拟环境pip install 的所有软件导出<br>pip freeze &gt; requirements.txt</p><p>另一个新的环境安装<br>pip install -r requirements.txt</p>]]></content>
      
      
      <categories>
          
          <category> pip </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决IDEA创建Maven项目速度慢问题</title>
      <link href="/2019/08/02/jie_jue_idea_chuang_jian_maven_xiang_mu_su_du_man_wen_ti/"/>
      <url>/2019/08/02/jie_jue_idea_chuang_jian_maven_xiang_mu_su_du_man_wen_ti/</url>
      
        <content type="html"><![CDATA[<p>add Maven Property<br>Name:archetypeCatalog<br>Value:internal</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark-submit提交集群执行</title>
      <link href="/2019/07/29/spark_submit_ti_jiao_ji_qun_zhi_xing/"/>
      <url>/2019/07/29/spark_submit_ti_jiao_ji_qun_zhi_xing/</url>
      
        <content type="html"><![CDATA[<p>spark-submit<br><code>--</code>master yarn-cluster    //集群启动<br><code>--</code>num-executors 1        //分配多少个进程<br><code>--</code>driver-memory 500m  //driver内存<br><code>--</code>executor-memory 1g //进程内存<br><code>--</code>executor-cores 1       //开多少个核，线程<br><code>--</code>jars $(echo /usr/chl/spark8/jars/*.jar | tr ’ ’ ‘,’) //加载jar<br><code>--</code>class com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> SparkStreaming </tag>
            
            <tag> spark-sumbit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IDEA中jar冲突查找快捷键快速定位</title>
      <link href="/2019/07/27/idea_zhong_jar_chong_tu_cha_zhao_kuai_jie_jian_kuai_su_ding_wei/"/>
      <url>/2019/07/27/idea_zhong_jar_chong_tu_cha_zhao_kuai_jie_jian_kuai_su_ding_wei/</url>
      
        <content type="html"><![CDATA[<p><strong>Ctrl+Alt+Shift+N</strong></p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业网络日志分析</title>
      <link href="/2019/07/27/qi_ye_wang_luo_ri_zhi_fen_xi/"/>
      <url>/2019/07/27/qi_ye_wang_luo_ri_zhi_fen_xi/</url>
      
        <content type="html"><![CDATA[<h3 id="一、背景数据介绍">一、背景数据介绍</h3><p><strong>1.WiFi有哪些数据？</strong><br>手机号<br>机构<br>机构<br>机构<br>网页快照<br>论坛帖子<br>微博<br>邮件<br>IM聊天<br>表单数据<br>APP使用</p><p><strong>2.WiFi价值</strong><br>客户体验：方便客户、基础设施<br>客户数据：精准营销、获取客户上网行为、获取客户信息、客户接触渠道</p><p><strong>3.WiFi数据获取</strong><br>Wi-Fi 网络可以捕获附近智能手机的 IMSI 号码，无线跟踪并监控用户的根源在于智能手机（包括 Android 和 iOS 设备）连接 Wi-Fi 网络的方式。</p><p>在大多数现代移动操作系统中有两种广泛实现的协议：<br>可扩展认证协议（EAP）<br>认证和密钥协商（AKA）协议</p><p>这些协议允许智能手机通过自身设备的 IMSI 号码切换登录到已知的 Wi-Fi 网络，实现 WiFi 网络自动连接而无需所有者交互。</p><p><strong>4.wifi数据应用</strong><br><img src="/medias/wifi%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8.PNG" alt="wifi数据应用"></p><p>画像系统<br><img src="/medias/%E7%94%BB%E5%83%8F%E7%B3%BB%E7%BB%9F.PNG" alt="画像系统"></p><p><strong>5.数据架构</strong><br><img src="/medias/%E7%BD%91%E7%BB%9C%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E5%9B%BE.PNG" alt="网络用户行为数据架构图"></p><p><strong>6.数据结构</strong><br>（1）<strong>文件命名</strong><br>数据类型_来源_UUID.txt<br>如BASE_SOURCE_UUID.txt</p><p>定一套字段标准 ，类型标准<br>（2）<strong>字段</strong><br>（3）  <strong>通用字段</strong></p><table><thead><tr><th style="text-align:center">参数1</th><th style="text-align:center">参数2</th><th style="text-align:center">参数3</th><th style="text-align:center">参数4</th></tr></thead><tbody><tr><td style="text-align:center">imei</td><td style="text-align:center">imei号，手机唯一识别码</td><td style="text-align:center"></td><td style="text-align:center">手机IMEI码由15-17位数字组成</td></tr><tr><td style="text-align:center">imsi</td><td style="text-align:center">IMSI，SIM卡唯一识别码</td><td style="text-align:center">460011418603055</td><td style="text-align:center">14-15位数字</td></tr><tr><td style="text-align:center">longitude</td><td style="text-align:center">经度</td><td style="text-align:center"></td><td style="text-align:center">精确到小数点6位</td></tr><tr><td style="text-align:center">latitude</td><td style="text-align:center">纬度</td><td style="text-align:center"></td><td style="text-align:center">精确到小数点6位</td></tr><tr><td style="text-align:center">phone_mac</td><td style="text-align:center">手机MAC</td><td style="text-align:center"></td><td style="text-align:center">格式需要统一（清洗）aa-aa-aa-aa-aa-aa（范围1-9，a-f）</td></tr><tr><td style="text-align:center">device_mac</td><td style="text-align:center">采集设备MAC</td><td style="text-align:center"></td><td style="text-align:center">格式需要统一（清洗）aa-aa-aa-aa-aa-aa（范围任意数字加字母）</td></tr><tr><td style="text-align:center">device_number</td><td style="text-align:center">采集设备号</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">collect_time</td><td style="text-align:center">collect_time</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p><strong>微信数据(wechat)</strong></p><table><thead><tr><th style="text-align:center">参数1</th><th style="text-align:center">参数2</th><th style="text-align:center">参数3</th><th style="text-align:center">参数4</th></tr></thead><tbody><tr><td style="text-align:center">username</td><td style="text-align:center">微信昵称</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">phone</td><td style="text-align:center">手机号</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">object_username</td><td style="text-align:center">对方微信号</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">send_message</td><td style="text-align:center">发送内容（不能破解）</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">accept_message</td><td style="text-align:center">接收内容（不能破解）</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">message_time</td><td style="text-align:center">通信时间</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p><strong>邮箱数据(Mail)</strong></p><table><thead><tr><th style="text-align:center">参数1</th><th style="text-align:center">参数2</th><th style="text-align:center">参数3</th><th style="text-align:center">参数4</th></tr></thead><tbody><tr><td style="text-align:center">send_mail</td><td style="text-align:center">发送邮箱</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">send_time</td><td style="text-align:center">发送时间</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">accept_mail</td><td style="text-align:center">接收邮箱</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">accept_time</td><td style="text-align:center">接收时间</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">mail_content</td><td style="text-align:center">发送内容</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">mail_type</td><td style="text-align:center">发送还是接收</td><td style="text-align:center"></td><td style="text-align:center">send  accept</td></tr></tbody></table><p><strong>搜索数据(Search)</strong></p><table><thead><tr><th style="text-align:center">参数1</th><th style="text-align:center">参数2</th><th style="text-align:center">参数3</th><th style="text-align:center">参数4</th></tr></thead><tbody><tr><td style="text-align:center">search_content</td><td style="text-align:center">搜索内容</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">search_url</td><td style="text-align:center">搜索URL</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">search_type</td><td style="text-align:center">搜索引擎</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">search_time</td><td style="text-align:center">搜索时间</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p><strong>基础数据(Base)</strong></p><table><thead><tr><th style="text-align:center">参数1</th><th style="text-align:center">参数2</th><th style="text-align:center">参数3</th><th style="text-align:center">参数4</th></tr></thead><tbody><tr><td style="text-align:center">name</td><td style="text-align:center">姓名</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">is_marry</td><td style="text-align:center">是否已婚</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">phone</td><td style="text-align:center">手机号</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">address</td><td style="text-align:center">户籍所在地</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">address_new</td><td style="text-align:center">现在居住地址</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">birthday</td><td style="text-align:center">出生日期</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">car_number</td><td style="text-align:center">车牌号</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">idcard</td><td style="text-align:center">身份证</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p>问题：数据结构，数据字段如何确定？<br>根据实际的需求自己确定。</p><h3 id="二．基础架构搭建">二．基础架构搭建</h3><h4 id="1、创建Maven父项">1、创建Maven父项</h4><p><strong>总的pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;  &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;  &lt;packaging&gt;pom&lt;/packaging&gt;  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;modules&gt;    &lt;module&gt;xz_bigdata_common&lt;/module&gt;    &lt;module&gt;xz_bigdata_es&lt;/module&gt;    &lt;module&gt;xz_bigdata_flume&lt;/module&gt;    &lt;module&gt;xz_bigdata_hbase&lt;/module&gt;    &lt;module&gt;xz_bigdata_kafka&lt;/module&gt;    &lt;module&gt;xz_bigdata_redis&lt;/module&gt;    &lt;module&gt;xz_bigdata_resources&lt;/module&gt;    &lt;module&gt;xz_bigdata_spark&lt;/module&gt;  &lt;/modules&gt;  &lt;name&gt;xz_bigdata2&lt;/name&gt;  &lt;properties&gt;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;cdh.version&gt;cdh5.14.0&lt;/cdh.version&gt;    &lt;junit.version&gt;4.12&lt;/junit.version&gt;    &lt;org.slf4j.version&gt;1.7.5&lt;/org.slf4j.version&gt;    &lt;zookeeper.version&gt;3.4.5&lt;/zookeeper.version&gt;    &lt;scala.version&gt;2.10.5&lt;/scala.version&gt;  &lt;/properties&gt;  &lt;repositories&gt;    &lt;repository&gt;      &lt;id&gt;Akka repository&lt;/id&gt;      &lt;url&gt;https://repo.akka.io/releases&lt;/url&gt;    &lt;/repository&gt;    &lt;!--cloudera依赖--&gt;    &lt;repository&gt;      &lt;id&gt;cloudera&lt;/id&gt;      &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;    &lt;/repository&gt;  &lt;/repositories&gt;  &lt;!--日志依赖--&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.slf4j&lt;/groupId&gt;      &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;      &lt;version&gt;${org.slf4j.version}&lt;/version&gt;    &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;    &lt;plugins&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;        &lt;version&gt;3.1&lt;/version&gt;        &lt;configuration&gt;          &lt;source&gt;1.8&lt;/source&gt;          &lt;target&gt;1.8&lt;/target&gt;          &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;    &lt;/plugins&gt;  &lt;/build&gt;&lt;/project&gt;</code></pre><h4 id="2、项目整体结构">2、项目整体结构</h4><p><img src="/medias/xz_bigdata2%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84.PNG" alt="xz_bigdata2整体结构"></p><h4 id="3、创建子模块">3、创建子模块</h4><p>选中xz_bigdata2，右键选择Module，新建maven子模块，上面图中的那些模块都是这样创建的。<br>注意：开发时使用jdk1.8以上版本，里面使用了jdk1.8特有的内容，低版本开发是报错的，使用jdk1.8方便开发。</p><p>ctrl+shift+alt+s：打开Project Structure里面可以进行操作。</p><p>ctrl+alt+s：打开Settings，可以配置本地Maven（在Build,Execution,Deployment下面的Build Tools下面的Maven配置自己的本地Maven仓库路径）。</p><p>Settings里面还可以看见之前说的Plugins，安装插件，Maven Helper以及后面的Scala插件都可以这里安装。</p><h3 id="三、Common开发">三、Common开发</h3><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_common&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;ant.version&gt;1.9.1&lt;/ant.version&gt;        &lt;jaxen.version&gt;1.1.6&lt;/jaxen.version&gt;        &lt;guava.version&gt;12.0.1&lt;/guava.version&gt;        &lt;dom4j.version&gt;1.6.1&lt;/dom4j.version&gt;        &lt;fastjson.version&gt;1.2.5&lt;/fastjson.version&gt;        &lt;disruptor.version&gt;3.3.6&lt;/disruptor.version&gt;        &lt;org.slf4j.version&gt;1.7.5&lt;/org.slf4j.version&gt;        &lt;commons.io.version&gt;2.4&lt;/commons.io.version&gt;        &lt;httpclient.version&gt;4.2.5&lt;/httpclient.version&gt;        &lt;commons.exec.version&gt;1.3&lt;/commons.exec.version&gt;        &lt;commons.lang.version&gt;2.4&lt;/commons.lang.version&gt;        &lt;commons-vfs2.version&gt;2.1&lt;/commons-vfs2.version&gt;        &lt;commons.math3.version&gt;3.4.1&lt;/commons.math3.version&gt;        &lt;commons.logging.version&gt;1.2&lt;/commons.logging.version&gt;        &lt;commons-httpclient.version&gt;3.1&lt;/commons-httpclient.version&gt;        &lt;commons.collections4.version&gt;4.1&lt;/commons.collections4.version&gt;        &lt;commons.configuration.version&gt;1.6&lt;/commons.configuration.version&gt;        &lt;mysql.connector.version&gt;5.1.46&lt;/mysql.connector.version&gt;        &lt;commons-dbutils.version&gt;1.6&lt;/commons-dbutils.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-dbutils&lt;/groupId&gt;            &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt;            &lt;version&gt;${commons-dbutils.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;5.1.46&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;            &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;            &lt;version&gt;${org.slf4j.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;            &lt;version&gt;${org.slf4j.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-io&lt;/groupId&gt;            &lt;artifactId&gt;commons-io&lt;/artifactId&gt;            &lt;version&gt;${commons.io.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-lang&lt;/groupId&gt;            &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;            &lt;version&gt;${commons.lang.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-configuration&lt;/groupId&gt;            &lt;artifactId&gt;commons-configuration&lt;/artifactId&gt;            &lt;version&gt;${commons.configuration.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;dom4j&lt;/groupId&gt;            &lt;artifactId&gt;dom4j&lt;/artifactId&gt;            &lt;version&gt;${dom4j.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;            &lt;version&gt;${fastjson.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- &lt;dependency&gt;             &lt;groupId&gt;log4j&lt;/groupId&gt;             &lt;artifactId&gt;log4j&lt;/artifactId&gt;             &lt;version&gt;1.2.17&lt;/version&gt;         &lt;/dependency&gt;--&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><h4 id="1、config-ConfigUtil-java—配置文件读取">1、config/ConfigUtil.java—配置文件读取</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.config;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.io.InputStream;import java.util.Properties;public class ConfigUtil {    private static Logger LOG = LoggerFactory.getLogger(ConfigUtil.class);    private static ConfigUtil configUtil;    public static ConfigUtil getInstance(){        if(configUtil == null){            configUtil = new ConfigUtil();        }        return configUtil;    }    public Properties getProperties(String path){        Properties properties = new Properties();        try {            LOG.info("开始加载配置文件" + path);//流式读取配置文件            InputStream insss = this.getClass().getClassLoader().getResourceAsStream(path);            properties = new Properties();            properties.load(insss);        } catch (IOException e) {            LOG.info("加载配置文件" + path + "失败");            LOG.error(null,e);        }        LOG.info("加载配置文件" + path + "成功");        System.out.println("文件内容："+properties);        return properties;    }    public static void main(String[] args) {        ConfigUtil instance = ConfigUtil.getInstance();        Properties properties = instance.getProperties("common/datatype.properties");        //Properties properties = instance.getProperties("spark/relation.properties");       // properties.get("relationfield");        System.out.println(properties);    }}</code></pre><h4 id="2、config-JsonReader-java">2、config/JsonReader.java</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.config;import org.apache.commons.io.FileUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.File;public class JsonReader {    private static Logger LOG = LoggerFactory.getLogger(JsonReader.class);    public static String readJson(String json_path){        JsonReader jsonReader = new JsonReader();        return jsonReader.getJson(json_path);    }    private String getJson(String json_path){        String jsonStr = "";        try {            String path = getClass().getClassLoader().getResource(json_path).toString();            path = path.replace("\\", "/");            if (path.contains(":")) {                path = path.replace("file:/","");            }            jsonStr = FileUtils.readFileToString(new File(path), "UTF-8");            LOG.error("读取json文件{}成功",path);        } catch (Exception e) {            LOG.error("读取json文件失败",e);        }        return jsonStr;    }}</code></pre><h4 id="3、adjuster-Adjuster-java—数据调整接口">3、adjuster/Adjuster.java—数据调整接口</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.adjuster;/** * 数据调整接口 */public interface Adjuster&lt;T, E&gt; {    E doAdjust(T data);}</code></pre><h4 id="4、adjuster-StringAdjuster-java">4、adjuster/StringAdjuster.java</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.adjuster;public abstract class StringAdjuster&lt;E&gt; implements Adjuster&lt;String, E&gt; {}</code></pre><h4 id="5、file-FileCommon-java">5、file/FileCommon.java</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.file;import org.apache.commons.io.FileUtils;import org.apache.commons.io.IOUtils;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.net.URL;import java.util.List;public class FileCommon {private FileCommon(){}/** * 判断文件是否存在 * @param name * @return */public static boolean exist(String name){return exist(new File(name));}public static boolean exist(File file){return file.exists();}/** * 创建文件 * @param file * @return * @throws IOException */public static boolean createFile(String file) throws IOException {return createFile(new File(file));}public static boolean createFile(File file) throws IOException {if(!file.exists()){if(file.isDirectory()){return file.mkdirs();}else{File parentDir = file.getParentFile();if(!parentDir.exists()) {if (parentDir.mkdirs()) {return file.createNewFile();}}else{return file.createNewFile();}}}return true;}/** * 读取文件内容 按行 * @param file * @return * @throws IOException */public static List&lt;String&gt; readLines(String file) throws IOException{return readLines(new File(file), "UTF-8");}public static List&lt;String&gt; readLines(String file, String encording) throws IOException{return readLines(new File(file), encording);}public static List&lt;String&gt; readLines(File file, String encording) throws IOException {List&lt;String&gt; lines = null;if(FileCommon.exist(file)) {FileInputStream fileInputStream = new FileInputStream(file);lines = IOUtils.readLines(fileInputStream, encording);fileInputStream.close();}return lines;}/** * 获取文件前缀 * @param fileName * @return */public static String getPrefix(String fileName){String prefix = fileName;int pos = fileName.lastIndexOf(".");if (pos != -1){prefix = fileName.substring(0,pos);}return prefix;}/** * 获取文件名后缀 * @param fileName * @return */public static String getFilePostfix(String fileName){String filePostfix = fileName.substring(fileName.lastIndexOf(".") + 1);return filePostfix.toLowerCase();}/** * 删除文件 * @param filePath * @return */public static boolean delFile(String filePath) {boolean flag = false;File file = new File(filePath);if (file.isFile() &amp;&amp; file.exists()) {flag = file.delete();}return flag;}/** * 移动文件 * @param oldPath * @param newPath * @return */public static boolean mvFile(String oldPath,String newPath){boolean flag = false;File oldfile = new File(oldPath);File newfile = new File(newPath);if(oldfile.isFile() &amp;&amp; oldfile.exists()){if(newfile.exists()){delFile(newfile.getAbsolutePath());}flag = oldfile.renameTo(newfile);}return flag;}/** * 删除目录 * @param dir * @return */public static boolean deleteDir(File dir){if (dir.isDirectory()) {String[] children = dir.list();//递归删除目录中的子目录下if(children!=null){for (int i=0; i&lt;children.length; i++) {boolean success = deleteDir(new File(dir, children[i]));if (!success) {return false;}}}}// 目录此时为空，可以删除return dir.delete();}//递归建立目录，解压缩相关类中使用public static void mkdirs(File file) {File parent = file.getParentFile();if (parent != null &amp;&amp; (!parent.exists())) {parent.mkdirs();}}public static String getJarFilePathByClass(String clazz) throws ClassNotFoundException {return getJarFilePathByClass(Class.forName(clazz));}public static String getJarFileDirByClass(String clazz) throws ClassNotFoundException {return getJarFileDirByClass(Class.forName(clazz));}public static String getJarFilePathByClass(Class&lt;?&gt; clazz){return new File(clazz.getProtectionDomain().getCodeSource().getLocation().getFile()).getAbsolutePath();}public static String getJarFileDirByClass(Class&lt;?&gt; clazz){return new File(getJarFilePathByClass(clazz)).getParent();}public static String getAbstractPath(String abstractPath) throws Exception{URL url = FileCommon.class.getClassLoader().getResource(abstractPath);System.out.println("配置文件路径为" + url);File file = new File(url.getFile());String content= FileUtils.readFileToString(file,"UTF-8");return content;}public static String getAbstractPath111(String abstractPath) throws Exception{File file = new File(abstractPath);String content= FileUtils.readFileToString(file,"UTF-8");return content;}}</code></pre><h4 id="6、filter—数据过滤顶层接口">6、filter—数据过滤顶层接口</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.filter;/** * 数据过滤顶层接口 */public interface Filter&lt;T&gt; {    boolean filter(T obj);}</code></pre><h4 id="7、net-HttpRequest-java">7、net/HttpRequest.java</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.net;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.*;import java.net.HttpURLConnection;import java.net.URL;import java.net.URLConnection;import java.net.URLEncoder;import java.util.Map;public class HttpRequest {    private static final Logger LOG = LoggerFactory.getLogger(HttpRequest.class);    /**     * 向指定URL发送GET方法的请求     * @param url  发送请求的URL     * @param param  请求参数，请求参数应该是 name1=value1&amp;name2=value2 的形式。     * @return URL  所代表远程资源的响应结果     */    public static String sendGet(String url, String param) {        String result = "";        BufferedReader in = null;        try {            String urlNameString = url + "?" + param;            URL realUrl = new URL(urlNameString);            // 打开和URL之间的连接            URLConnection connection = realUrl.openConnection();            // 设置通用的请求属性            connection.setRequestProperty("accept", "*/*");            connection.setRequestProperty("connection", "Keep-Alive");            connection.setRequestProperty("user-agent",                    "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1;SV1)");            // 建立实际的连接            connection.connect();            // 获取所有响应头字段            //Map&lt;String, List&lt;String&gt;&gt; map = connection.getHeaderFields();            // 遍历所有的响应头字段            // 定义 BufferedReader输入流来读取URL的响应            in = new BufferedReader(new InputStreamReader(connection.getInputStream(),"UTF-8"));            String line;            while ((line = in.readLine()) != null) {                result += line;            }        } catch (Exception e) {            LOG.info("发送GET请求出现异常！" + (url+param));            System.out.println("发送GET请求出现异常！" + e);            e.printStackTrace();        }        // 使用finally块来关闭输入流        finally {            try {                if (in != null) {                    in.close();                }            } catch (Exception e2) {                e2.printStackTrace();            }        }        return result;    }    /**     * 向指定URL发送GET方法的请求     * @param url  发送请求的URL     * @param param  请求参数，请求参数应该是 name1=value1&amp;name2=value2 的形式。     * @return URL 所代表远程资源的响应结果     */    public static String sendGet(String url, String param,String authorization) {        String result = "";        BufferedReader in = null;        try {            String urlNameString = url + "?" + param;            URL realUrl = new URL(urlNameString);            // 打开和URL之间的连接            URLConnection connection = realUrl.openConnection();            // 设置通用的请求属性            connection.setRequestProperty("accept", "*/*");            connection.setRequestProperty("connection", "Keep-Alive");            connection.setRequestProperty("Authorization", authorization);            connection.setRequestProperty("user-agent",                    "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1;SV1)");            // 建立实际的连接            connection.connect();            // 获取所有响应头字段            connection.getHeaderFields();            // 遍历所有的响应头字段/*            for (String key : map.keySet()) {                System.out.println(key + "---&gt;" + map.get(key));            }*/            // 定义 BufferedReader输入流来读取URL的响应            in = new BufferedReader(new InputStreamReader(                    connection.getInputStream(),"UTF-8"));            String line;            while ((line = in.readLine()) != null) {                result += line;            }        } catch (Exception e) {            LOG.info("发送POST请求出现异常！" + (url+param));            System.out.println("发送POST请求出现异常！" + e);            e.printStackTrace();        }        // 使用finally块来关闭输入流        finally {            try {                if (in != null) {                    in.close();                }            } catch (Exception e2) {                e2.printStackTrace();            }        }        return result;    }    public static void main(String[] args) throws Exception{    }    /**     * 向指定 URL 发送POST方法的请求     * @param url  发送请求的 URL     * @param param  请求参数，请求参数应该是 name1=value1&amp;name2=value2 的形式。     * @return  所代表远程资源的响应结果     */    public static String sendPost(String url, String param) {        PrintWriter out = null;        BufferedReader in = null;        String result = "";        try {            URL realUrl = new URL(url);            // 打开和URL之间的连接            URLConnection conn = realUrl.openConnection();            // 设置通用的请求属性            conn.setRequestProperty("Content-Type","application/json");            //conn.setInstanceFollowRedirects(false);            // conn.setRequestProperty("Content-Type","application/x-www-form-urlencoded");            conn.setRequestProperty("accept", "*/*");            conn.setRequestProperty("connection", "Keep-Alive");            conn.setRequestProperty("user-agent",                    "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1;SV1)");            // 发送POST请求必须设置如下两行            conn.setReadTimeout(30000);            conn.setDoOutput(true);            conn.setDoInput(true);            // 获取URLConnection对象对应的输出流            out = new PrintWriter(conn.getOutputStream());            // 发送请求参数            out.print(param);            // flush输出流的缓冲            out.flush();            // 定义BufferedReader输入流来读取URL的响应            InputStream inputStream = conn.getInputStream();            in = new BufferedReader(new InputStreamReader(inputStream,"UTF-8"));            String line;            while ((line = in.readLine()) != null) {                result += line;            }        }        catch (IOException e) {            LOG.info("发送POST请求出现异常！" + (url+param),e);        }        //使用finally块来关闭输出流、输入流        finally{            try{                if(out!=null){                    out.close();                }                if(in!=null){                    in.close();                }            }            catch(IOException ex){                ex.printStackTrace();            }        }        return result;    }    /*     * params 填写的URL的参数 encode 字节编码     */    public static String sendPostMessage(String url1,Map&lt;String,Object&gt; params){        String response = null;        Reader in = null;        try {            //访问准备            URL url = new URL(url1);            //开始访问            StringBuilder postData = new StringBuilder();            for (Map.Entry&lt;String,Object&gt; param : params.entrySet()) {                if (postData.length() != 0) postData.append('&amp;');                postData.append(URLEncoder.encode(param.getKey(), "UTF-8"));                postData.append('=');                postData.append(URLEncoder.encode(String.valueOf(param.getValue()), "UTF-8"));            }            byte[] postDataBytes = postData.toString().getBytes("UTF-8");            URLConnection conn = url.openConnection();            //URLConnection conn = url.openConnection();            //conn.setRequestMethod("POST");            //conn.setInstanceFollowRedirects(false);            //conn.setRequestProperty("Content-Type", "application/x-www-form-urlencoded");            conn.setRequestProperty("Content-Type", "application/json");            conn.setRequestProperty("Content-Length", String.valueOf(postDataBytes.length));            conn.setDoOutput(true);            conn.getOutputStream().write(postDataBytes);            in = new BufferedReader(new InputStreamReader(conn.getInputStream(), "UTF-8"));            StringBuilder sb = new StringBuilder();            for (int c; (c = in.read()) &gt;= 0;)                sb.append((char)c);            response = sb.toString();           //System.out.println(response);        } catch (IOException e) {            LOG.error(null,e);        }finally {            if(in != null){                try {                    in.close();                } catch (IOException e) {                    e.printStackTrace();                }            }        }        return response;    }    /**     * 向指定 URL 发送POST方法的请求     * @param url  发送请求的 URL     * @param param  请求参数，请求参数应该是 name1=value1&amp;name2=value2 的形式。     * @return  所代表远程资源的响应结果     */    public static void sendPostWithoutReturn(String url, String param) {        PrintWriter out = null;        BufferedReader in = null;        String result = "";        try {            URL realUrl = new URL(url);            // 打开和URL之间的连接            HttpURLConnection conn = (HttpURLConnection )realUrl.openConnection();            // 设置通用的请求属性            conn.setRequestProperty("Content-Type","application/json");            conn.setRequestProperty("accept", "*/*");            conn.setRequestProperty("connection", "Keep-Alive");            conn.setRequestProperty("user-agent",                    "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1;SV1)");            //根据需求设置读超时的时间            conn.setReadTimeout(1000);            // 发送POST请求必须设置如下两行            conn.setDoOutput(true);            conn.setDoInput(true);            // 获取URLConnection对象对应的输出流            out = new PrintWriter(conn.getOutputStream());            // 发送请求参数            out.print(param);            // flush输出流的缓冲            out.flush();            // 定义BufferedReader输入流来读取URL的响应            if (conn.getResponseCode() == 200) {                System.out.println("连接成功,传送数据...");            } else {                System.out.println("连接失败,错误代码:"+conn.getResponseCode());            }        }        catch (IOException e) {            LOG.info("发送POST请求出现异常！" + (url+param),e);        }        //使用finally块来关闭输出流、输入流        finally{            try{                if(out!=null){                    out.close();                }                in.close();            }            catch(Exception ex){                ex.printStackTrace();            }        }    }}</code></pre><h4 id="8、netb-db-DBCommon—mysql的连接、关闭基础类">8、netb/db/DBCommon—mysql的连接、关闭基础类</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.netb.db;import com.hsiehchou.common.config.ConfigUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.sql.*;import java.util.Properties;public class DBCommon {    private static Logger LOG = LoggerFactory.getLogger(DBCommon.class);    private static String MYSQL_PATH = "common/mysql.properties";    private static Properties properties = ConfigUtil.getInstance().getProperties(MYSQL_PATH);    private static Connection conn ;    private DBCommon(){}    public static void main(String[] args) {        System.out.println(properties);        Connection xz_bigdata = DBCommon.getConn("test");        System.out.println(xz_bigdata);    }    //TODO  配置文件    private static final String JDBC_DRIVER = "com.mysql.jdbc.Driver";    private static final String USER_NAME = properties.getProperty("user");    private static final String PASSWORD = properties.getProperty("password");    private static final String IP = properties.getProperty("db_ip");    private static final String PORT = properties.getProperty("db_port");    private static final String DB_CONFIG = "?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&amp;failOverReadOnly=false";    static {        try {            Class.forName(JDBC_DRIVER);        } catch (ClassNotFoundException e) {            LOG.error(null, e);        }    }    /**     * 获取数据库连接     * @param dbName     * @return     */    public static Connection getConn(String dbName) {        Connection conn = null;        String  connstring = "jdbc:mysql://"+IP+":"+PORT+"/"+dbName+DB_CONFIG;        try {            conn = DriverManager.getConnection(connstring, USER_NAME, PASSWORD);        } catch (SQLException e) {            e.printStackTrace();            LOG.error(null, e);        }        return conn;    }    /**     * @param url eg:"jdbc:oracle:thin:@172.16.1.111:1521:d406"     * @param driver eg:"oracle.jdbc.driver.OracleDriver"     * @param user eg:"ucase"     * @param password eg:"ucase123"     * @return     * @throws ClassNotFoundException     * @throws SQLException     */    public static Connection getConn(String url, String driver, String user,                                     String password) throws ClassNotFoundException, SQLException{        Class.forName(driver);        conn = DriverManager.getConnection(url, user, password);        return  conn;    }    public static void close(Connection conn){        try {            if( conn != null ){                conn.close();            }        } catch (SQLException e) {            LOG.error(null,e);        }    }    public static void close(Statement statement){        try {            if( statement != null ){                statement.close();            }        } catch (SQLException e) {            LOG.error(null,e);        }    }    public static void close(Connection conn,PreparedStatement statement){        try {            if( conn != null ){                conn.close();            }            if( statement != null ){                statement.close();            }        } catch (SQLException e) {            LOG.error(null,e);        }    }    public static void close(Connection conn,Statement statement,ResultSet resultSet) throws SQLException{        if( resultSet != null ){            resultSet.close();        }        if( statement != null ){            statement.close();        }        if( conn != null ){            conn.close();        }    }}</code></pre><h4 id="9、project-datatype-DataTypeProperties-java">9、project/datatype/DataTypeProperties.java</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.project.datatype;import com.hsiehchou.common.config.ConfigUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.*;public class DataTypeProperties {    private static final Logger logger = LoggerFactory.getLogger(DataTypeProperties.class);    private static final String DATA_PATH = "common/datatype.properties";    public static Map&lt;String,ArrayList&lt;String&gt;&gt; dataTypeMap = null;    static {        Properties properties = ConfigUtil.getInstance().getProperties(DATA_PATH);        dataTypeMap = new HashMap&lt;&gt;();        Set&lt;Object&gt; keys = properties.keySet();        keys.forEach(key-&gt;{            String[] split = properties.getProperty(key.toString()).split(",");            dataTypeMap.put(key.toString(),new ArrayList&lt;&gt;(Arrays.asList(split)));        });    }    public static void main(String[] args) {        Map&lt;String, ArrayList&lt;String&gt;&gt; dataTypeMap = DataTypeProperties.dataTypeMap;        System.out.println(dataTypeMap.toString());    }}</code></pre><h4 id="10、regex-Validation-java—验证工具类">10、regex/Validation.java—验证工具类</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.regex;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 验证工具类 */public class Validation {// ------------------常量定义/** * Email正则表达式= * "^([a-z0-9A-Z]+[-|\\.]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\.)+[a-zA-Z]{2,}$" * ; */// public static final String EMAIL =// "^([a-z0-9A-Z]+[-|\\.]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\.)+[a-zA-Z]{2,}$";;public static final String EMAIL = "\\w+(\\.\\w+)*@\\w+(\\.\\w+)+";/** * 电话号码正则表达式= * (^(\d{2,4}[-_－—]?)?\d{3,8}([-_－—]?\d{3,8})?([-_－—]?\d{1,7})?$)| * (^0?1[35]\d{9}$) */public static final String PHONE = "(^(\\d{2,4}[-_－—]?)?\\d{3,8}([-_－—]?\\d{3,8})?([-_－—]?\\d{1,7})?$)|(^0?1[35]\\d{9}$)";/** * 手机号码正则表达式=^(13[0-9]|15[0-9]|18[0-9])\d{8}$ */public static final String MOBILE = "^((13[0-9])|(14[5-7])|(15[^4])|(17[0-8])|(18[0-9]))\\d{8}$";/** * Integer正则表达式 ^-?(([1-9]\d*$)|0) */public static final String INTEGER = "^-?(([1-9]\\d*$)|0)";/** * 正整数正则表达式 &gt;=0 ^[1-9]\d*|0$ */public static final String INTEGER_NEGATIVE = "^[1-9]\\d*|0$";/** * 负整数正则表达式 &lt;=0 ^-[1-9]\d*|0$ */public static final String INTEGER_POSITIVE = "^-[1-9]\\d*|0$";/** * Double正则表达式 ^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ */public static final String DOUBLE = "^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$";/** * 正Double正则表达式 &gt;=0 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$　 */public static final String DOUBLE_NEGATIVE = "^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$";/** * 负Double正则表达式 &lt;= 0 ^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$ */public static final String DOUBLE_POSITIVE = "^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$";/** * 年龄正则表达式 ^(?:[1-9][0-9]?|1[01][0-9]|120)$ 匹配0-120岁 */public static final String AGE = "^(?:[1-9][0-9]?|1[01][0-9]|120)$";/** * 邮编正则表达式 [0-9]\d{5}(?!\d) 国内6位邮编 */public static final String CODE = "[0-9]\\d{5}(?!\\d)";/** * 匹配由数字、26个英文字母或者下划线组成的字符串 ^\w+$ */public static final String STR_ENG_NUM_ = "^\\w+$";/** * 匹配由数字和26个英文字母组成的字符串 ^[A-Za-z0-9]+$ */public static final String STR_ENG_NUM = "^[A-Za-z0-9]+";/** * 匹配由26个英文字母组成的字符串 ^[A-Za-z]+$ */public static final String STR_ENG = "^[A-Za-z]+$";/** * 过滤特殊字符串正则 regEx= * "[`~!@#$%^&amp;*()+=|{}':;',\\[\\].&lt;&gt;/?~！@#￥%……&amp;*（）——+|{}【】‘；：”“’。，、？]"; */public static final String STR_SPECIAL = "[`~!@#$%^&amp;*()+=|{}':;',\\[\\].&lt;&gt;/?~！@#￥%……&amp;*（）——+|{}【】‘；：”“’。，、？]";/*** * 日期正则 支持： YYYY-MM-DD YYYY/MM/DD YYYY_MM_DD YYYYMMDD YYYY.MM.DD的形式 */public static final String DATE_ALL = "((^((1[8-9]\\d{2})|([2-9]\\d{3}))([-\\/\\._]?)(10|12|0?[13578])([-\\/\\._]?)(3[01]|[12][0-9]|0?[1-9])$)"+ "|(^((1[8-9]\\d{2})|([2-9]\\d{3}))([-\\/\\._]?)(11|0?[469])([-\\/\\._]?)(30|[12][0-9]|0?[1-9])$)"+ "|(^((1[8-9]\\d{2})|([2-9]\\d{3}))([-\\/\\._]?)(0?2)([-\\/\\._]?)(2[0-8]|1[0-9]|0?[1-9])$)|(^([2468][048]00)([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|(^([3579][26]00)"+ "([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)"+ "|(^([1][89][0][48])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|(^([2-9][0-9][0][48])([-\\/\\._]?)"+ "(0?2)([-\\/\\._]?)(29)$)"+ "|(^([1][89][2468][048])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|(^([2-9][0-9][2468][048])([-\\/\\._]?)(0?2)"+ "([-\\/\\._]?)(29)$)|(^([1][89][13579][26])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|"+ "(^([2-9][0-9][13579][26])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$))";/*** * 日期正则 支持： YYYY-MM-DD */public static final String DATE_FORMAT1 = "(([0-9]{3}[1-9]|[0-9]{2}[1-9][0-9]{1}|[0-9]{1}[1-9][0-9]{2}|[1-9][0-9]{3})-(((0[13578]|1[02])-(0[1-9]|[12][0-9]|3[01]))|((0[469]|11)-(0[1-9]|[12][0-9]|30))|(02-(0[1-9]|[1][0-9]|2[0-8]))))|((([0-9]{2})(0[48]|[2468][048]|[13579][26])|((0[48]|[2468][048]|[3579][26])00))-02-29)";/** * URL正则表达式 匹配 http www ftp */public static final String URL = "^(http|www|ftp|)?(://)?(\\w+(-\\w+)*)(\\.(\\w+(-\\w+)*))*((:\\d+)?)(/(\\w+(-\\w+)*))*(\\.?(\\w)*)(\\?)?"+ "(((\\w*%)*(\\w*\\?)*(\\w*:)*(\\w*\\+)*(\\w*\\.)*(\\w*&amp;)*(\\w*-)*(\\w*=)*(\\w*%)*(\\w*\\?)*"+ "(\\w*:)*(\\w*\\+)*(\\w*\\.)*"+ "(\\w*&amp;)*(\\w*-)*(\\w*=)*)*(\\w*)*)$";/** * 身份证正则表达式 */public static final String IDCARD = "((11|12|13|14|15|21|22|23|31|32|33|34|35|36|37|41|42|43|44|45|46|50|51|52|53|54|61|62|63|64|65)[0-9]{4})"+ "(([1|2][0-9]{3}[0|1][0-9][0-3][0-9][0-9]{3}"+ "[Xx0-9])|([0-9]{2}[0|1][0-9][0-3][0-9][0-9]{3}))";/** * 机构代码 */public static final String JIGOU_CODE = "^[A-Z0-9]{8}-[A-Z0-9]$";/** * 匹配数字组成的字符串 ^[0-9]+$ */public static final String STR_NUM = "^[0-9]+$";// //------------------验证方法/** * 判断字段是否为空 符合返回ture * @param str * @return boolean */public static synchronized boolean StrisNull(String str) {return null == str || str.trim().length() &lt;= 0 ? true : false;}/** * 判断字段是非空 符合返回ture * @param str * @return boolean */public static boolean StrNotNull(String str) {return !StrisNull(str);}/** * 字符串null转空 * @param str * @return boolean */public static String nulltoStr(String str) {return StrisNull(str) ? "" : str;}/** * 字符串null赋值默认值 * @param str  目标字符串 * @param defaut  默认值 * @return  String */public static String nulltoStr(String str, String defaut) {return StrisNull(str) ? defaut : str;}/** * 判断字段是否为Email 符合返回ture * @param str * @return boolean */public static boolean isEmail(String str) {return Regular(str, EMAIL);}/** * 判断是否为电话号码 符合返回ture * @param str * @return boolean */public static boolean isPhone(String str) {return Regular(str, PHONE);}/** * 判断是否为手机号码 符合返回ture * @param str * @return boolean */public static boolean isMobile(String str) {return RegularSJHM(str, MOBILE);}/** * 判断是否为Url 符合返回ture * @param str * @return boolean */public static boolean isUrl(String str) {return Regular(str, URL);}/** * 判断字段是否为数字 正负整数 正负浮点数 符合返回ture * @param str * @return boolean */public static boolean isNumber(String str) {return Regular(str, DOUBLE);}/** * 判断字段是否为INTEGER 符合返回ture * @param str * @return boolean */public static boolean isInteger(String str) {return Regular(str, INTEGER);}/** * 判断字段是否为正整数正则表达式 &gt;=0 符合返回ture * @param str * @return boolean */public static boolean isINTEGER_NEGATIVE(String str) {return Regular(str, INTEGER_NEGATIVE);}/** * 判断字段是否为负整数正则表达式 &lt;=0 符合返回ture * @param str * @return boolean */public static boolean isINTEGER_POSITIVE(String str) {return Regular(str, INTEGER_POSITIVE);}/** * 判断字段是否为DOUBLE 符合返回ture * @param str * @return boolean */public static boolean isDouble(String str) {return Regular(str, DOUBLE);}/** * 判断字段是否为正浮点数正则表达式 &gt;=0 符合返回ture * @param str * @return boolean */public static boolean isDOUBLE_NEGATIVE(String str) {return Regular(str, DOUBLE_NEGATIVE);}/** * 判断字段是否为负浮点数正则表达式 &lt;=0 符合返回ture * @param str * @return boolean */public static boolean isDOUBLE_POSITIVE(String str) {return Regular(str, DOUBLE_POSITIVE);}/** * 判断字段是否为日期 符合返回ture * @param str * @return boolean */public static boolean isDate(String str) {return Regular(str, DATE_ALL);}/** * 验证2010-12-10 * @param str * @return */public static boolean isDate1(String str) {return Regular(str, DATE_FORMAT1);}/** * 判断字段是否为年龄 符合返回ture * @param str * @return boolean */public static boolean isAge(String str) {return Regular(str, AGE);}/** * 判断字段是否超长 字串为空返回fasle, 超过长度{leng}返回ture 反之返回false * @param str * @param leng * @return boolean */public static boolean isLengOut(String str, int leng) {return StrisNull(str) ? false : str.trim().length() &gt; leng;}/** * 判断字段是否为身份证 符合返回ture * @param str * @return boolean */public static boolean isIdCard(String str) {if (StrisNull(str))return false;if (str.trim().length() == 15 || str.trim().length() == 18) {return Regular(str, IDCARD);} else {return false;}}/** * 判断字段是否为邮编 符合返回ture * @param str * @return boolean */public static boolean isCode(String str) {return Regular(str, CODE);}/** * 判断字符串是不是全部是英文字母 * @param str * @return boolean */public static boolean isEnglish(String str) {return Regular(str, STR_ENG);}/** * 判断字符串是不是全部是英文字母+数字 * @param str * @return boolean */public static boolean isENG_NUM(String str) {return Regular(str, STR_ENG_NUM);}/** * 判断字符串是不是全部是英文字母+数字+下划线 * @param str * @return boolean */public static boolean isENG_NUM_(String str) {return Regular(str, STR_ENG_NUM_);}/** * 过滤特殊字符串 返回过滤后的字符串 * @param str * @return boolean */public static String filterStr(String str) {Pattern p = Pattern.compile(STR_SPECIAL);Matcher m = p.matcher(str);return m.replaceAll("").trim();}/** * 校验机构代码格式 * @return */public static boolean isJigouCode(String str) {return Regular(str, JIGOU_CODE);}/** * 判断字符串是不是数字组成 * @param str * @return boolean */public static boolean isSTR_NUM(String str) {return Regular(str, STR_NUM);}/** * 匹配是否符合正则表达式pattern 匹配返回true * @param str 匹配的字符串 * @param pattern 匹配模式 * @return boolean */private static boolean Regular(String str, String pattern) {if (null == str || str.trim().length() &lt;= 0)return false;Pattern p = Pattern.compile(pattern);Matcher m = p.matcher(str);return m.matches();}/** * 匹配是否符合正则表达式pattern 匹配返回true * @param str 匹配的字符串 * @param pattern 匹配模式 * @return boolean */private static boolean RegularSJHM(String str, String pattern) {if (null == str || str.trim().length() &lt;= 0){return false;}if(str.contains("+86")){str=str.replace("+86","");}Pattern p = Pattern.compile(pattern);Matcher m = p.matcher(str);return m.matches();}/** * description:匹配yyyyMMddHHmmss格式时间 * @param time * @return boolean 2016-7-19 下午5:13:25 by  */public static final String yyyyMMddHHmmss = "[0-9]{14}";public static boolean isyyyyMMddHHmmss(String time) {if (time == null) {return false;}boolean bool = time.matches(yyyyMMddHHmmss);return bool;}/** * description:匹配yyyyMMddHHmmss格式时间 * @param time * @return boolean 2016-7-19 下午5:13:25 by  */public static final String isMac = "^[A-F0-9]{2}(-[A-F0-9]{2}){5}$";public static boolean isMac(String mac) {if (mac == null) {return false;}boolean bool = mac.matches(isMac);return bool;}/** * description:匹配yyyyMMddHHmmss格式时间 * @param time * @return boolean 2016-7-19 下午5:13:25 by  */public static final String longtime = "[0-9]{10}";public static boolean isTimestamp(String timestamp) {if (timestamp == null) {return false;}boolean bool = timestamp.matches(longtime);return bool;}/** * 判断字段是否为datatype 符合返回ture * @param str * @return boolean */public static final String DATATYPE = "^\\d{7}$";public static boolean isDATATYPE(String str) {return Regular(str, DATATYPE);}/** * 判断字段是否为QQ 符合返回ture * @param str * @return boolean */public static final String QQ = "^\\d{5,15}$";public static boolean isQQ(String str) {return Regular(str, QQ);}/** * 判断字段是否为IMSI 符合返回ture * @param str * @return boolean *///public static final String IMSI = "^4600[0,1,2,3,4,5,6,7,9]\\d{10}|(46011|46020)\\d{10}$";public static final String IMSI = "^[1-9][0-9][0-9]0[0,1,2,3,4,5,6,7,9]\\d{10}|[1-9][0-9][0-9](11|20)\\d{10}$";public static boolean isIMSI(String str) {return Regular(str, IMSI);}/** * 判断字段是否为IMEI 符合返回ture * @param str * @return boolean */public static final String IMEI = "^\\d{8}$|^[a-fA-F0-9]{14}$|^\\d{15}$";public static boolean isIMEI(String str) {return Regular(str, IMEI);}/** * 判断字段是否为CAPTURETIME 符合返回ture * @param str * @return boolean */public static final String CAPTURETIME = "^\\d{10}|(20[0-9][0-9])\\d{10}$";public static boolean isCAPTURETIME(String str) {return Regular(str, CAPTURETIME);}/** * description:检测认证类型 * @param auth * @return boolean */public static final String AUTH_TYPE = "^\\d{7}$";public static boolean isAUTH_TYPE(String str) {return Regular(str, CAPTURETIME);}/** * description:检测FIRM_CODE * @param auth * @return boolean */public static final String FIRM_CODE = "^\\d{9}$";public static boolean isFIRM_CODE(String str) {return Regular(str, FIRM_CODE);}/** * description:检测经度 * @param auth * @return boolean */public static final String LONGITUDE = "^-?(([1-9]\\d?)|(1[0-7]\\d)|180)(\\.\\d{1,8})?$";//public static final String LONGITUDE ="^([-]?(\\d|([1-9]\\d)|(1[0-7]\\d)|(180))(\\.\\d*)\\,[-]?(\\d|([1-8]\\d)|(90))(\\.\\d*))$";public static boolean isLONGITUDE(String str) {return Regular(str, LONGITUDE);}/** * description:检测纬度 * @param auth * @return boolean */public static final String LATITUDE = "^-?(([1-8]\\d?)|([1-8]\\d)|90)(\\.\\d{1,8})?$";public static boolean isLATITUDE(String str) {return Regular(str, LATITUDE);}public static void main(String[] args) {boolean bool = isLATITUDE("26.0615854");System.out.println(bool);}}</code></pre><h4 id="11、thread-ThreadPoolManager-java—线程池管理器单例">11、thread/ThreadPoolManager.java—线程池管理器单例</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.thread;import java.io.Serializable;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * 线程池管理器单例 *  默认创建   ewCachedThreadPool ：创建一个可缓存的线程池 *  可通过指定线程的数量来创建：newFixedThreadPool  ： 创建固定大小的线程池 */public class ThreadPoolManager implements Serializable {private static final long serialVersionUID = 1465361469484903956L;public static final ThreadPoolManager threadPoolManager =  new ThreadPoolManager();private static ThreadPoolManager tpm;private transient ExecutorService newCachedThreadPool;private transient ExecutorService newFixedThreadPool;private int poolCapacity;private ThreadPoolManager(){if( newCachedThreadPool == null )newCachedThreadPool = Executors.newCachedThreadPool();}@Deprecatedpublic static ThreadPoolManager getInstance(){if( tpm == null ){synchronized(ThreadPoolManager.class){if( tpm == null )tpm =  new ThreadPoolManager();}}return tpm;}/**  * 返回 newCachedThreadPool */public ExecutorService getExecutorService(){if( newCachedThreadPool == null ){synchronized(ThreadPoolManager.class){if( newCachedThreadPool == null )newCachedThreadPool = Executors.newCachedThreadPool();}}return newCachedThreadPool;}/**   * 返回 newFixedThreadPool */public ExecutorService getExecutorService(int poolCapacity){return getExecutorService(poolCapacity, false);}/**  * 返回 newFixedThreadPool */public synchronized ExecutorService getExecutorService(int poolCapacity, boolean closeOld){if(newFixedThreadPool == null || (this.poolCapacity != poolCapacity)){if(newFixedThreadPool != null &amp;&amp; closeOld){newFixedThreadPool.shutdown();}newFixedThreadPool = Executors.newFixedThreadPool(poolCapacity);this.poolCapacity = poolCapacity;}return newFixedThreadPool;}}</code></pre><h4 id="12、time-TimeTranstationUtils-java—时间转换工具类">12、time/TimeTranstationUtils.java—时间转换工具类</h4><pre><code class="highlight plaintext">package com.hsiehchou.common.time;import org.apache.commons.lang.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.HashMap;import java.util.Map;/** * Description: 时间转换工具类 */public class TimeTranstationUtils {private static final Logger logger = LoggerFactory.getLogger(TimeTranstationUtils.class);/*private static SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");private static SimpleDateFormat sdFormatternew = new SimpleDateFormat("yyyyMMddHH");private static SimpleDateFormat sdFormatter1 = new SimpleDateFormat("yyyy-MM-dd");private static SimpleDateFormat sdFormatter2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");private static SimpleDateFormat sdFormatter3 = new SimpleDateFormat("yyyyMMdd");*/private static Date nowTime;public static String Date2yyyyMMddHHmmss() {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");nowTime = new Date(System.currentTimeMillis());String time = sdFormatter.format(nowTime);return time;}public static String Date2yyyyMMddHHmmss(long timestamp) {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");nowTime = new Date(timestamp);String time = sdFormatter.format(nowTime);return time;}public static String Date2yyyyMMdd(long timestamp) {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMdd");nowTime = new Date(timestamp);String time = sdFormatter.format(nowTime);return time;}public static String Date2yyyyMMddHH(String str) {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");SimpleDateFormat sdFormatternew = new SimpleDateFormat("yyyyMMddHH");try {nowTime = sdFormatter.parse(str);} catch (ParseException e) {e.printStackTrace();}String time = sdFormatternew.format(nowTime);return time;}public static String Date2yyyy_MM_dd() {SimpleDateFormat sdFormatter1 = new SimpleDateFormat("yyyy-MM-dd");nowTime = new Date(System.currentTimeMillis());String time = sdFormatter1.format(nowTime);return time;}public static String Date2yyyy_MM_dd_HH_mm_ss() {SimpleDateFormat sdFormatter2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");nowTime = new Date(System.currentTimeMillis());String time = sdFormatter2.format(nowTime);return time;}public static String Date2yyyyMMdd() {SimpleDateFormat sdFormatter3 = new SimpleDateFormat("yyyyMMdd");nowTime = new Date(System.currentTimeMillis());String time = sdFormatter3.format(nowTime);return time;}public static String Date2yyyyMMdd(String str) {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");SimpleDateFormat sdFormatter3 = new SimpleDateFormat("yyyyMMdd");try {nowTime = sdFormatter.parse(str);} catch (ParseException e) {e.printStackTrace();}String time = sdFormatter3.format(nowTime);return time;}public static Long Date2yyyyMMddHHmmssToLong() {return System.currentTimeMillis() / 1000;}public static String long2date(String capturetime){SimpleDateFormat sdf= new SimpleDateFormat("yyyyMMdd");//前面的lSysTime是秒数，先乘1000得到毫秒数，再转为java.util.Date类型Date dt = new Date(Long.valueOf(capturetime) * 1000);String sDateTime = sdf.format(dt);  //得到精确到秒的表示：08/31/2006 21:08:00return sDateTime;}public static Long yyyyMMddHHmmssToLong(String time) {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");if (StringUtils.isBlank(time)) {return 0L;} else {boolean isNum = time.matches("[0-9]+");if (isNum) {long long1 = 0;try {long1 = sdFormatter.parse(time).getTime();} catch (ParseException e) {logger.error(time + "时间转换为long错误" + isNum);return 0L;}return long1 / 1000;}}return 0L;}public static Date yyyyMMddHHmmssToDate(String time) {SimpleDateFormat sdFormatter = new SimpleDateFormat("yyyyMMddHHmmss");if (StringUtils.isBlank(time)) {return new Date();} else {boolean isNum = time.matches("[0-9]+");if (isNum) {Date date = null;try {date = sdFormatter.parse(time);} catch (ParseException e) {logger.error(time + "时间转换为date错误" + isNum, e);System.out.println(time);System.out.println(isNum);e.printStackTrace();}return date;}}return new Date();}public static Date yyyyMMddHHmmssToDate() {Date date = null;SimpleDateFormat sdFormatter2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");try {date = sdFormatter2.parse(Date2yyyy_MM_dd_HH_mm_ss());} catch (ParseException e) {// TODO Auto-generated catch blocke.printStackTrace();}return date;}public static java.sql.Date strToDate(String strDate) {String str = strDate;SimpleDateFormat format = new SimpleDateFormat("yyyy-mm-dd");Date d = null;try {d = format.parse(str);} catch (Exception e) {e.printStackTrace();}java.sql.Date date = new java.sql.Date(d.getTime());return date;}public static Long str2Long(String str){if(!StringUtils.isBlank(str)){return Long.valueOf(str);}else{return 0L;}}public static Double str2Double(String str){if(!StringUtils.isBlank(str)){return Double.valueOf(str);}else{return 0.0;}}public static HashMap&lt;String,Object&gt; mapString2Long(Map&lt;String,String&gt; map, String key, HashMap&lt;String,Object&gt; objectMap) {String logouttime = map.get(key);if (!StringUtils.isBlank(logouttime)) {objectMap.put(key, Long.valueOf(logouttime));} else {objectMap.put(key, 0L);}return objectMap;}public static void main(String[] args) throws InterruptedException {System.out.println(long2date("1463487992"));}}</code></pre><h3 id="四、Resources开发">四、Resources开发</h3><h4 id="xz-bigdata-resources结构">xz_bigdata_resources结构</h4><p><img src="/medias/xz_bigdata_resources%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84.PNG" alt="xz_bigdata_resources整体结构"></p><p>注意：这里的resources要选中右键，选择Make Directory as，选择下级的Resources Root，变成Resources配置源文件，项目可以任意调用。</p><h4 id="1、resources下面">1、resources下面</h4><p><strong>log4j2.properties</strong></p><pre><code class="highlight plaintext">log4j.rootLogger = error,stdout,D,Elog4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = [%-5p] %d{yyyy-MM-dd HH:mm:ss,SSS} method:%l%n%m%nlog4j.appender.D = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.D.File = F://logs/log.loglog4j.appender.D.Append = truelog4j.appender.D.Threshold = DEBUG log4j.appender.D.layout = org.apache.log4j.PatternLayoutlog4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%nlog4j.appender.E = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.E.File =F://logs/error.log log4j.appender.E.Append = truelog4j.appender.E.Threshold = ERROR log4j.appender.E.layout = org.apache.log4j.PatternLayoutlog4j.appender.E.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%n</code></pre><h4 id="2、common">2、common</h4><p><strong>datatype.properties</strong></p><pre><code class="highlight plaintext"># base = datatype,idcard,name,age,collecttime,imei# wechat = datatype,wechat,phone,collecttime,imeiwechat = imei,imsi,longitude,latitude,phone_mac,device_mac,device_number,collect_time,username,phone,object_username,send_message,accept_message,message_timemail = imei,imsi,longitude,latitude,phone_mac,device_mac,device_number,collect_time,send_mail,send_time,accept_mail,accept_time,mail_content,mail_typeqq = imei,imsi,longitude,latitude,phone_mac,device_mac,device_number,collect_time,username,phone,object_username,send_message,accept_message,message_time</code></pre><p><strong>mysql.properties</strong></p><pre><code class="highlight plaintext">db_ip = 192.168.116.201db_port = 3306user = rootpassword = root</code></pre><h4 id="3、es">3、es</h4><p><strong>es_cluster.properties</strong></p><pre><code class="highlight plaintext">es.cluster.name=xz_eses.cluster.nodes = hadoop1,hadoop2,hadoop3es.cluster.nodes1 = hadoop1es.cluster.nodes2 = hadoop2es.cluster.nodes3 = hadoop3es.cluster.tcp.port = 9300es.cluster.http.port = 9200</code></pre><p><strong>mapping/base.json</strong></p><pre><code class="highlight plaintext">{  "_source": {    "enabled": true  },  "properties": {    "datatype":{"type": "keyword"},    "idcard":{"type": "keyword"},    "name":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "age":{"type": "long"},    "collecttime":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "imei":{"type": "keyword"}  }}</code></pre><p><strong>mapping/fieldmapping.properties</strong></p><pre><code class="highlight plaintext">tables = wechat,mail,qqwechat.imei = stringwechat.imsi = stringwechat.longitude = doublewechat.latitude = doublewechat.phone_mac = stringwechat.device_mac = stringwechat.device_number = stringwechat.collect_time = longwechat.username = stringwechat.phone = stringwechat.object_username = stringwechat.send_message = stringwechat.accept_message = stringwechat.message_time = longwechat.id = stringwechat.table = stringwechat.filename = stringwechat.absolute_filename  = stringmail.imei = stringmail.imsi = stringmail.longitude = doublemail.latitude = doublemail.phone_mac = stringmail.device_mac = stringmail.device_number = stringmail.collect_time = longmail.send_mail = stringmail.send_time = longmail.accept_mail = stringmail.accept_time = longmail.mail_content = stringmail.mail_type = stringmail.id = stringmail.table = stringmail.filename = stringmail.absolute_filename  = stringqq.imei = stringqq.imsi = stringqq.longitude = doubleqq.latitude = doubleqq.phone_mac = stringqq.device_mac = stringqq.device_number = stringqq.collect_time = longqq.username = stringqq.phone = stringqq.object_username = stringqq.send_message = stringqq.accept_message = stringqq.message_time = longqq.id = stringqq.table = stringqq.filename = stringqq.absolute_filename  = string</code></pre><p><strong>mapping/mail.json</strong></p><pre><code class="highlight plaintext">{  "_source": {    "enabled": true  },  "properties": {    "imei":{"type": "keyword"},    "imsi":{"type": "keyword"},    "longitude":{"type": "double"},    "latitude":{"type": "double"},    "phone_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_number":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "collect_time":{"type": "long"},    "send_mail":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "send_time":{"type": "long"},    "accept_mail":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "accept_time":{"type": "long"},    "mail_content":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "mail_type":{"type": "keyword"},     "id":{"type": "keyword"},    "table":{"type": "keyword"},    "filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "absolute_filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}</code></pre><p><strong>mapping/qq.json</strong></p><pre><code class="highlight plaintext">{  "_source": {    "enabled": true  },  "properties": {    "imei":{"type": "keyword"},    "imsi":{"type": "keyword"},    "longitude":{"type": "double"},    "latitude":{"type": "double"},    "phone_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_number":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "collect_time":{"type": "long"},    "username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "phone":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "object_username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "send_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "accept_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "message_time":{"type": "long"},    "id":{"type": "keyword"},    "table":{"type": "keyword"},    "filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "absolute_filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}</code></pre><p><strong>mapping/test.json</strong></p><pre><code class="highlight plaintext">{  "_source": {    "enabled": true  },  "properties": {    "id":{"type": "keyword"},    "source":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "target":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "library_id":{"type": "long"},    "source_sign":{"type": "keyword"},    "target_sign":{"type": "keyword"},    "create_time":{"type": "long"},    "create_user_id":{"type": "keyword"},    "is_audit":{"type": "long"},    "is_del":{"type": "long"},    "last_modify_user_id":{"type": "keyword"},    "last_modify_time":{"type": "long"},    "init_version":{"type": "long"},    "version":{"type": "long"},    "score":{"type": "keyword"},    "level":{"type": "keyword"},    "example":{"type": "keyword"},    "conflict":{"type": "keyword"},    "srcLangId":{"type": "long"},    "srcLangCN":{"type": "keyword"},    "tarLangId":{"type": "long"},    "tarLangCN":{"type": "keyword"},    "docId":{"type": "keyword"},    "source_simhash":{"type": "keyword"},    "sentence_id":{"type": "long"},    "section_id":{"type": "long"},    "type":{"type": "long"},    "industry":{"type": "long"},    "industry_name":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "querycount":{"type": "long"},    "reviser":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "comment":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}</code></pre><p><strong>mapping/wechat.json</strong></p><pre><code class="highlight plaintext">{  "_source": {    "enabled": true  },  "properties": {    "imei":{"type": "keyword"},    "imsi":{"type": "keyword"},    "longitude":{"type": "double"},    "latitude":{"type": "double"},    "phone_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_number":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "collect_time":{"type": "long"},    "username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "phone":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "object_username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "send_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "accept_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "message_time":{"type": "long"},    "id":{"type": "keyword"},    "table":{"type": "keyword"},    "filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "absolute_filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}</code></pre><h4 id="4、flume">4、flume</h4><p><strong>datatype.properties</strong></p><p><strong>flume-config.properties</strong></p><pre><code class="highlight plaintext">#kafka topickafkatopic=test100</code></pre><p><strong>validation.properties</strong></p><pre><code class="highlight plaintext"># 文件名验证开关FILENAME_VALIDATION=1# DATATYPE转换开关DATATYPE_TRANSACTION=1# 经纬度验证开关LONGLAIT_VALIDATION=1# 是否入错误数据到ESERROR_ES=1</code></pre><h4 id="5、hadoop">5、hadoop</h4><p><strong>core-site.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hadoop1:8020&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;fs.trash.interval&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;io.compression.codecs&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.authentication&lt;/name&gt;    &lt;value&gt;simple&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.authorization&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.rpc.protection&lt;/name&gt;    &lt;value&gt;authentication&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;    &lt;value&gt;DEFAULT&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.mapred.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.mapred.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.flume.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.flume.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.HTTP.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.HTTP.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hive.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hive.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hdfs.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hdfs.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.yarn.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.yarn.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.group.mapping&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.security.ShellBasedUnixGroupsMapping&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.instrumentation.requires.admin&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;net.topology.script.file.name&lt;/name&gt;    &lt;value&gt;/etc/hadoop/conf.cloudera.yarn/topology.py&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;io.file.buffer.size&lt;/name&gt;    &lt;value&gt;65536&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.require.client.cert&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.keystores.factory.class&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.server.conf&lt;/name&gt;    &lt;value&gt;ssl-server.xml&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.client.conf&lt;/name&gt;    &lt;value&gt;ssl-client.xml&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><p><strong>hdfs-site.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;    &lt;value&gt;file:///dfs/nn&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.servicerpc-address&lt;/name&gt;    &lt;value&gt;hadoop1:8022&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.https.address&lt;/name&gt;    &lt;value&gt;hadoop1:50470&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.https.port&lt;/name&gt;    &lt;value&gt;50470&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;    &lt;value&gt;hadoop1:50070&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;3&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.blocksize&lt;/name&gt;    &lt;value&gt;134217728&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.use.datanode.hostname&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;fs.permissions.umask-mode&lt;/name&gt;    &lt;value&gt;022&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.use.legacy.blockreader&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;    &lt;value&gt;/var/run/hdfs-sockets/dn&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.read.shortcircuit.skip.checksum&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.domain.socket.data.traffic&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="6、hbase">6、hbase</h4><p><strong>core-site.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hadoop1:8020&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;fs.trash.interval&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;io.compression.codecs&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.authentication&lt;/name&gt;    &lt;value&gt;simple&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.authorization&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.rpc.protection&lt;/name&gt;    &lt;value&gt;authentication&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;    &lt;value&gt;DEFAULT&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.mapred.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.mapred.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.flume.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.flume.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.HTTP.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.HTTP.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hive.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hive.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hdfs.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.hdfs.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.yarn.hosts&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.proxyuser.yarn.groups&lt;/name&gt;    &lt;value&gt;*&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.group.mapping&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.security.ShellBasedUnixGroupsMapping&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.security.instrumentation.requires.admin&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.require.client.cert&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.keystores.factory.class&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.server.conf&lt;/name&gt;    &lt;value&gt;ssl-server.xml&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hadoop.ssl.client.conf&lt;/name&gt;    &lt;value&gt;ssl-client.xml&lt;/value&gt;    &lt;final&gt;true&lt;/final&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><p><strong>hbase-server-config.properties</strong></p><pre><code class="highlight plaintext">#hbase  开发环境need.init.hbase=true# hbase.zookeeper.quorum=hadoop1.ultiwill.com,hadoop2.ultiwill.com,hadoop3.ultiwill.comhbase.zookeeper.quorum=hadoop1,hadoop2,hadoop3hbase.zookeeper.property.clientPort=2181hbase.rpc.timeout=120000hbase.client.scanner.timeout.period=120000</code></pre><p><strong>hbase-site.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;hbase.rootdir&lt;/name&gt;    &lt;value&gt;hdfs://hadoop1:8020/hbase&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.replication&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.write.buffer&lt;/name&gt;    &lt;value&gt;2097152&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.pause&lt;/name&gt;    &lt;value&gt;100&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.retries.number&lt;/name&gt;    &lt;value&gt;35&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.scanner.caching&lt;/name&gt;    &lt;value&gt;100&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.keyvalue.maxsize&lt;/name&gt;    &lt;value&gt;10485760&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.ipc.client.allowsInterrupt&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.primaryCallTimeout.get&lt;/name&gt;    &lt;value&gt;10&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.primaryCallTimeout.multiget&lt;/name&gt;    &lt;value&gt;10&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.fs.tmp.dir&lt;/name&gt;    &lt;value&gt;/user/${user.name}/hbase-staging&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.client.scanner.timeout.period&lt;/name&gt;    &lt;value&gt;60000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.regionserver.thrift.http&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.thrift.support.proxyuser&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.rpc.timeout&lt;/name&gt;    &lt;value&gt;60000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.snapshot.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.snapshot.master.timeoutMillis&lt;/name&gt;    &lt;value&gt;60000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.snapshot.region.timeout&lt;/name&gt;    &lt;value&gt;60000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.snapshot.master.timeout.millis&lt;/name&gt;    &lt;value&gt;60000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.security.authentication&lt;/name&gt;    &lt;value&gt;simple&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.rpc.protection&lt;/name&gt;    &lt;value&gt;authentication&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;    &lt;value&gt;60000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;zookeeper.znode.parent&lt;/name&gt;    &lt;value&gt;/hbase&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;zookeeper.znode.rootserver&lt;/name&gt;    &lt;value&gt;root-region-server&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;    &lt;value&gt;hadoop1,hadoop3,hadoop2&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;    &lt;value&gt;2181&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.rest.ssl.enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><p><strong>hdfs-site.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;dfs.permissions&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;    &lt;value&gt;file:///dfs/nn&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.servicerpc-address&lt;/name&gt;    &lt;value&gt;hadoop1:8022&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.https.address&lt;/name&gt;    &lt;value&gt;hadoop1:50470&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.https.port&lt;/name&gt;    &lt;value&gt;50470&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;    &lt;value&gt;hadoop1:50070&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;3&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.blocksize&lt;/name&gt;    &lt;value&gt;134217728&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.use.datanode.hostname&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;fs.permissions.umask-mode&lt;/name&gt;    &lt;value&gt;022&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.use.legacy.blockreader&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;    &lt;value&gt;/var/run/hdfs-sockets/dn&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.read.shortcircuit.skip.checksum&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.client.domain.socket.data.traffic&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="7、kafka">7、kafka</h4><p><strong>kafka-data-push-info</strong></p><pre><code class="highlight plaintext">--config                            kafka自动推送数据配置目录--timeOut                           推送超时时间    默认 15 min  单位为分钟kafka自动推送数据配置：data.sources                        数据源列表。  （例如：data.sources =bhdb1,dpxx）  {source}.source.type                某个数据源的类型。 （数据源分为数据库和文件两大类， 若为数据库 则使用 数据的名称 例如 oracle,mysql,sqlserver等， 否则使用 file）                                                                                                            例如：bhdb1.source.type=oracle 或者  dpxx.source.type=file数据源为数据库：{source}.db.name                    数据库的名称{source}.db.host                    数据库的ip或者主机名{source}.db.port                    数据库的访问端口， 若不填写则使用该种数据库的默认端口{source}.db.user                    用户名{source}.db.pwd                     密码                                                                 {source}.push.topic                 推送到topic的全局配置，即该数据库下配置的表没有配置topic的时候，其数据会推送到该topic。   {source}.push.tables                需要推送数的表列表 {source}.{table}.push.sql           只推送使用该sql查询到的数据    。       不填则表示推送全部。{source}.{table}.push.adjusterfactory 对推送的数据进行调整  ， 必须为com.bh.d406.bigdata.kafka.producer.DataAdjuster的子类   ，  需要进行调整数据的时候填写{source}.{table}.push.topic         该表的数据推送到topic名称  ， 若不填则使用全局的topic配置数据源为文件：{source}.file.dir                   文件目录    （注意：只支持本地目录 ）    {source}.file.encoding              文件编码      （默认UTF-8）{source}.file.extensions            需要过滤的文件格式列表{source}.file.data.loaderfactory    文件加载器工厂类   {source}.file.data.fields           记录的字段列表      与顺序有关{source}.file.data.spliter          数据的分割符         默认 \t{source}.file.skip.firstline        是否跳过第一行数据                       false  or true{source}.file.data.adjusterfactory  数据矫正工厂类{source}.push.thread.num            读取文件的线程数{source}.push.batch.size            分批推送数据 ， 每批数据大小{source}.push.topic                 数据推送的目标topic名称{source}.store.table                存储的表名</code></pre><p><strong>kafka-server-config.properties</strong></p><pre><code class="highlight plaintext">#################Kafka 全局配置 ######################## 格式为host1:port1,host2:port2，# 这是一个broker列表，用于获得元数据(topics，partitions和replicas)，建立起来的socket连接用于发送实际数据，# 这个列表可以是broker的一个子集，或者一个VIP，指向broker的一个子集# metadata.broker.list=hadoop1:9092,slaver01:9092,slaver02:9092metadata.broker.list=hadoop1:9092# zookeeper列表zk.connect=hadoop1:2181,hadoop2:2181,hadoop3:2181# 字消息的序列化类，默认是的encoder处理一个byte[]，返回一个byte[]# 默认值为 kafka.serializer.DefaultEncoderserializer.class=kafka.serializer.StringEncoder# 用来控制一个produce请求怎样才能算完成，准确的说，是有多少broker必须已经提交数据到log文件，并向leader发送ack，可以设置如下的值：# 0，意味着producer永远不会等待一个来自broker的ack，这就是0.7版本的行为。这个选项提供了最低的延迟，但是持久化的保证是最弱的，当server挂掉的时候会丢失一些数据。# 1，意味着在leader replica已经接收到数据后，producer会得到一个ack。这个选项提供了更好的持久性，因为在server确认请求成功处理后，client才会返回。如果刚写到leader上，还没来得及复制leader就挂了，那么消息才可能会丢失。# -1，意味着在所有的ISR都接收到数据后，producer才得到一个ack。这个选项提供了最好的持久性，只要还有一个replica存活，那么数据就不会丢失。# 默认值  为 0request.required.acks=1# 请求超时时间     默认为 10000request.timeout.ms=60000#决定消息是否应在一个后台线程异步发送。#合法的值为sync，表示异步发送；sync表示同步发送。#设置为async则允许批量发送请求，这回带来更高的吞吐量，但是client的机器挂了的话会丢失还没有发送的数据。#默认值为 syncproducer.type=sync</code></pre><h4 id="8、redis">8、redis</h4><p><strong>redis.properties</strong></p><pre><code class="highlight plaintext">redis.hostname = 192.168.116.202redis.port  = 6379</code></pre><h4 id="9、spark">9、spark</h4><p><strong>hive_fields_mapping.properties</strong></p><pre><code class="highlight plaintext">datatype= base,wechat#base = datatype,idcard,name,age,collecttime,imei#wechat = datatype,wechat,phone,collecttime,imei#============================================================basebase.datatype = stringbase.idcard = stringbase.name = stringbase.age = longbase.collecttime = stringbase.imei = string#============================================================wechatwechat.datatype = stringwechat.wechat = stringwechat.phone = stringwechat.collecttime = stringwechat.imei = string</code></pre><p><strong>relation.properties</strong></p><pre><code class="highlight plaintext">#需要关联的字段relationfield = phone_mac,phone,username,send_mail,imei,imsicomplex_relationfield = card,phone_mac,phone,username,send_mail,imei,imsi</code></pre><p><strong>spark-batch-config.properties</strong></p><pre><code class="highlight plaintext"># spark 常规 配置   不包括 流式处理的 配置#################### 全局  ############################## 在用户没有指定时，用于分布式随机操作(groupByKey,reduceByKey等等)的默认的任务数（ shuffle过程中 task的个数 ）# 默认为 8spark.default.parallelism=16# Spark用于缓存的内存大小所占用的Java堆的比率。这个不应该大于JVM中老年代所分配的内存大小# 默认情况下老年代大小是堆大小的2/3，但是你可以通过配置你的老年代的大小，然后再去增加这个比率# 默认为 0.66# spark 1.6 后 过期# spark.storage.memoryFraction=0.66# 在spark1.6.0版本默认大小为： (“Java Heap” – 300MB) * 0.75# 例如：如果堆内存大小有4G，将有2847MB的Spark Memory,Spark Memory=(4*1024MB-300)*0.75=2847MB# 这部分内存会被分成两部分：Storage Memory和Execution Memory# 而且这两部分的边界由spark.memory.storageFraction参数设定，默认是0.5即50%# 新的内存管理模型中的优点是，这个边界不是固定的，在内存压力下这个边界是可以移动的# 如一个区域内存不够用时可以从另一区域借用内存spark.memory.fraction=0.75spark.memory.storageFraction=0.5# 是否要压缩序列化的RDD分区（比如，StorageLevel.MEMORY_ONLY_SER）# 在消耗一点额外的CPU时间的代价下，可以极大的提高减少空间的使用# 默认为 falsespark.rdd.compress=true# The codec used to compress internal data such as RDD partitions,# broadcast variables and shuffle outputs. By default,# Spark provides three codecs: lz4, lzf, and snappy. You can also use fully qualified class names to specify the codec,# e.g.# 1. org.apache.spark.io.LZ4CompressionCodec, # 2. org.apache.spark.io.LZFCompressionCodec, # 3. org.apache.spark.io.SnappyCompressionCodec.   defaultspark.io.compression.codec=org.apache.spark.io.SnappyCompressionCodec# Block size (in bytes) used in Snappy compression,# in the case when Snappy compression codec is used.# Lowering this block size will also lower shuffle memory usage when Snappy is used.# default : 32Kspark.io.compression.snappy.blockSize=32768# 同时获取每一个分解任务的时候，映射输出文件的最大的尺寸（以兆为单位）。# 由于对每个输出都需要我们去创建一个缓冲区去接受它，这个属性值代表了对每个分解任务所使用的内存的一个上限值，# 因此除非你机器内存很大，最好还是配置一下这个值。# 默认48spark.reducer.maxSizeInFlight=48# 这个配置参数仅适用于HashShuffleMananger的实现，同样是为了解决生成过多文件的问题，# 采用的方式是在不同批次运行的Map任务之间重用Shuffle输出文件，也就是说合并的是不同批次的Map任务的输出数据，# 但是每个Map任务所需要的文件还是取决于Reduce分区的数量，因此，它并不减少同时打开的输出文件的数量，# 因此对内存使用量的减少并没有帮助。只是HashShuffleManager里的一个折中的解决方案。# 默认为false#spark.shuffle.consolidateFiles=false#java.io.Externalizable. Java serialization is flexible but often quite slow, and leads to large serialized formats for many classes.#default java.io.Serializable#spark.serializer=org.apache.spark.serializer.KryoSerializer# Speculation是在任务调度的时候，如果没有适合当前本地性要求的任务可供运行，# 将跑得慢的任务在空闲计算资源上再度调度的行为，这些参数调整这些行为的频率和判断指标，默认是不使用Speculation的# 默认为false# 慎用   可能导致数据重复的现象#spark.speculation=true# task失败重试次数# 默认为4spark.task.maxFailures=8# Spark 是有任务的黑名单机制的，但是这个配置在官方文档里面并没有写，可以设置下面的参数，# 比如设置成一分钟之内不要再把任务发到这个 Executor 上了，单位是毫秒。# spark.scheduler.executorTaskBlacklistTime=60000# 超过这个时间，可以执行 NODE_LOCAL 的任务# 默认为 3000spark.locality.wait.process=1# 超过这个时间，可以执行 RACK_LOCAL 的任务# 默认为 3000spark.locality.wait.node=3 # 超过这个时间，可以执行 ANY 的任务# 默认为 3000spark.locality.wait.rack=1000#################### yarn  ############################ 提交的jar文件  的副本数# 默认为 3spark.yarn.submit.file.replication=1# container中的线程数# 默认为 25spark.yarn.containerLauncherMaxThreads=25# 解决yarn-cluster模式下 对处理  permGen space oom异常很有用# spark.yarn.am.extraJavaOptions=# spark.driver.extraJavaOptions=-XX:PermSize=512M -XX:MaxPermSize=1024M# 对象指针压缩 和 gc日志收集打印# spark.executor.extraJavaOptions=-XX:PermSize=512M -XX:MaxPermSize=1024M -XX:MaxDirectMemorySize=1536M -XX:+UseCompressedOops -XX:+PrintGCDetails -XX:+PrintGCTimeStamps# -XX:-UseGCOverheadLimit# GC默认情况下有一个限制，默认是GC时间不能超过2%的CPU时间，但是如果大量对象创建（在Spark里很容易出现，代码模式就是一个RDD转下一个RDD），# 就会导致大量的GC时间，从而出现OutOfMemoryError: GC overhead limit exceeded，可以通过设置-XX:-UseGCOverheadLimit关掉它。# -XX:+UseCompressedOops  可以压缩指针（8字节变成4字节）spark.executor.extraJavaOptions=-XX:PermSize=512M -XX:MaxPermSize=1024m -XX:+CMSClassUnloadingEnabled -Xmn512m -XX:MaxTenuringThreshold=15 -XX:-UseGCOverheadLimit -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseCompressedOops -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError# 当shuffle缓存的数据超过此值  强制刷磁盘  单位为 byte# spark.shuffle.spill.initialMemoryThreshold=671088640################### AKKA 相关 ########################### 在控制面板通信（序列化任务和任务结果）的时候消息尺寸的最大值，单位是MB。# 如果你需要给驱动器发回大尺寸的结果（比如使用在一个大的数据集上面使用collect()方法），那么你就该增加这个值了。# 默认为 10spark.akka.frameSize=1024# 用于通信的actor线程数量。如果驱动器有很多CPU核心，那么在大集群上可以增大这个值。# 默认为 4spark.akka.threads=8# Spark节点之间通信的超时时间，以秒为单位# 默认为20sspark.akka.timeout=120# exector的堆外内存（不会占用 分配给executor的jvm内存）# spark.yarn.executor.memoryOverhead=2560</code></pre><p><strong>spark-start-config.properties</strong></p><pre><code class="highlight plaintext"># Spark 任务 使用java -cp 方式启动的参数配置#spark.executor.extraLibraryPath=/opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/hadoop/lib/nativespark.yarn.jar=local:/opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/spark/lib/spark-assembly.jarspark.authenticate=falsespark.driver.extraLibraryPath=/opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/hadoop/lib/nativespark.yarn.historyServer.address=http://BH-LAN-Virtual-hadoop-9:18088spark.yarn.am.extraLibraryPath=/opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/hadoop/lib/nativespark.eventLog.enabled=truespark.dynamicAllocation.schedulerBacklogTimeout=1SPARK_SUBMIT=truespark.yarn.config.gatewayPath=/opt/cloudera/parcelsspark.ui.killEnabled=truespark.serializer=org.apache.spark.serializer.KryoSerializerspark.shuffle.service.enabled=truespark.dynamicAllocation.minExecutors=0spark.dynamicAllocation.executorIdleTimeout=60spark.yarn.config.replacementPath={{HADOOP_COMMON_HOME}}/../../..spark.shuffle.service.port=7337spark.eventLog.dir=hdfs://nameservice1/user/spark/applicationHistoryspark.dynamicAllocation.enabled=true#/opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/spark/lib/*#/etc/spark/conf.cloudera.spark_on_yarn/#/etc/hadoop/conf.cloudera.yarn/spark.submit.deployMode=clientspark.app.name=defaultspark.master=yarn-clientspark.driver.memory=1gspark.executor.instances=1spark.executor.memory=4gspark.executor.cores=2spark.jars=</code></pre><p><strong>spark-streaming-config.properties</strong></p><pre><code class="highlight plaintext"># spark  流式处理的 配置# job的并行度# 默认为 1spark.streaming.concurrentJobs=1# Spark记忆任何元数据(stages生成，任务生成等等)的时间(秒)。周期性清除保证在这个时间之前的元数据会被遗忘。#当长时间几小时，几天的运行Spark的时候设置这个是很有用的。注意：任何内存中的RDD只要过了这个时间就会被清除掉。# 默认 disablespark.cleaner.ttl=3600# 将不再使用的缓存数据清除# 默认为falsespark.streaming.unpersist=true# 从网络中批量接受对象时的持续时间 , 单位  ms。# 默认为200msspark.streaming.blockInterval=200# 控制Receiver速度  单位 s# 因为当streaming程序的数据源的数据量突然变大巨大，可能会导致streaming被撑住导致吞吐不过来，所以可以考虑对于最大吞吐做一下限制。# 默认为 100000spark.streaming.receiver.maxRate=10000# kafka每个分区最大的读取速度   单位 s# 控制kafka读取的量spark.streaming.kafka.maxRatePerPartition=50# 读取kafka的分区最新offset的最大尝试次数# 默认为1spark.streaming.kafka.maxRetries=5# 1、为什么引入Backpressure# 默认情况下，Spark Streaming通过Receiver以生产者生产数据的速率接收数据，计算过程中会出现batch processing time &gt; batch interval的情况，# 其中batch processing time 为实际计算一个批次花费时间， batch interval为Streaming应用设置的批处理间隔。# 这意味着Spark Streaming的数据接收速率高于Spark从队列中移除数据的速率，也就是数据处理能力低，在设置间隔内不能完全处理当前接收速率接收的数据。# 如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题（如果设置StorageLevel包含disk, 则内存存放不下的数据会溢写至disk, 加大延迟）。# Spark 1.5以前版本，用户如果要限制Receiver的数据接收速率，可以通过设置静态配制参数“spark.streaming.receiver.maxRate”的值来实现，# 此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer数据生产高于maxRate，当前集群处理能力也高于maxRate，这就会造成资源利用率下降等问题。# 为了更好的协调数据接收速率与资源处理能力，Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。# 2、Backpressure# Spark Streaming Backpressure:  根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。# 通过属性“spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用spark.streaming.backpressure.enabled=truespark.streaming.backpressure.initialRate=200</code></pre><p><strong>datatype/fieldtype.properties</strong></p><p><strong>hive/hive-server-config.properties</strong></p><pre><code class="highlight plaintext"># hbase  开发环境</code></pre><p><strong>hive/hive-site.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;hive.metastore.uris&lt;/name&gt;    &lt;value&gt;thrift://hadoop1:9083&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.metastore.client.socket.timeout&lt;/name&gt;    &lt;value&gt;300&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;    &lt;value&gt;/user/hive/warehouse&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.warehouse.subdir.inherit.perms&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.auto.convert.join&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.auto.convert.join.noconditionaltask.size&lt;/name&gt;    &lt;value&gt;20971520&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.optimize.bucketmapjoin.sortedmerge&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.smbjoin.cache.rows&lt;/name&gt;    &lt;value&gt;10000&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.server2.logging.operation.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;    &lt;value&gt;/hadoop_log/log/hive/operation_logs&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;mapred.reduce.tasks&lt;/name&gt;    &lt;value&gt;-1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.exec.reducers.bytes.per.reducer&lt;/name&gt;    &lt;value&gt;67108864&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.exec.copyfile.maxsize&lt;/name&gt;    &lt;value&gt;33554432&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.exec.reducers.max&lt;/name&gt;    &lt;value&gt;1099&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.vectorized.groupby.checkinterval&lt;/name&gt;    &lt;value&gt;4096&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.vectorized.groupby.flush.percent&lt;/name&gt;    &lt;value&gt;0.1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.compute.query.using.stats&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.vectorized.execution.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.vectorized.execution.reduce.enabled&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.merge.mapfiles&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.merge.mapredfiles&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.cbo.enable&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.fetch.task.conversion&lt;/name&gt;    &lt;value&gt;minimal&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.fetch.task.conversion.threshold&lt;/name&gt;    &lt;value&gt;268435456&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.limit.pushdown.memory.usage&lt;/name&gt;    &lt;value&gt;0.1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.merge.sparkfiles&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.merge.smallfiles.avgsize&lt;/name&gt;    &lt;value&gt;16777216&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.merge.size.per.task&lt;/name&gt;    &lt;value&gt;268435456&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.optimize.reducededuplication&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.optimize.reducededuplication.min.reducer&lt;/name&gt;    &lt;value&gt;4&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.map.aggr&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.map.aggr.hash.percentmemory&lt;/name&gt;    &lt;value&gt;0.5&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.optimize.sort.dynamic.partition&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.execution.engine&lt;/name&gt;    &lt;value&gt;mr&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.executor.memory&lt;/name&gt;    &lt;value&gt;1369020825&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.driver.memory&lt;/name&gt;    &lt;value&gt;966367641&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.executor.cores&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.yarn.driver.memoryOverhead&lt;/name&gt;    &lt;value&gt;102&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.yarn.executor.memoryOverhead&lt;/name&gt;    &lt;value&gt;230&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.dynamicAllocation.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.dynamicAllocation.initialExecutors&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.dynamicAllocation.minExecutors&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.dynamicAllocation.maxExecutors&lt;/name&gt;    &lt;value&gt;2147483647&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.metastore.execute.setugi&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.support.concurrency&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;    &lt;value&gt;hadoop1,hadoop3,hadoop2&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.zookeeper.client.port&lt;/name&gt;    &lt;value&gt;2181&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.zookeeper.namespace&lt;/name&gt;    &lt;value&gt;hive_zookeeper_namespace_hive&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.cluster.delegation.token.store.class&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.hive.thrift.MemoryTokenStore&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hive.server2.use.SSL&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;spark.shuffle.service.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><h3 id="五．Flume开发">五．Flume开发</h3><p><strong>xz_bigdata_flume</strong></p><p><strong>FTP–&gt;FlumeSource–&gt;拦截器–&gt;FlumeChannel–&gt;FlumeSink–&gt;Kafka</strong></p><p><strong>自定义的内容有：FlumeSource、拦截器、FlumeSink</strong></p><h4 id="1、maven冲突解决和pom-xml">1、maven冲突解决和pom.xml</h4><p>1.1 安装Maven Helper插件，在Settings里面的Plugins里面搜索Maven Helper，点击Install，安装完毕。</p><p>1.2 ETL包括数据的抽取、转换、加载<br>①数据抽取：从源数据源系统抽取目的数据源系统需要的数据：<br>②数据转换：将从源数据源获取的数据按照业务需求，转换成目的数据源要求的形式，并对错误、不一致的数据进行清洗和加工；<br>③数据加载：将转换后的数据装载到目的数据源。</p><p><img src="/medias/Flume%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.PNG" alt="Flume数据处理流程"></p><p>1.3 pom.xml</p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_flume&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_flume&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;flume-ng.version&gt;1.6.0&lt;/flume-ng.version&gt;        &lt;hadoop.version&gt;2.6.0&lt;/hadoop.version&gt;        &lt;jdom.version&gt;1.0&lt;/jdom.version&gt;        &lt;c3p0.version&gt;0.9.5&lt;/c3p0.version&gt;        &lt;hadoop.version&gt;2.6.0&lt;/hadoop.version&gt;        &lt;mybatis.version&gt;3.1.1&lt;/mybatis.version&gt;        &lt;zookeeper.version&gt;3.4.6&lt;/zookeeper.version&gt;        &lt;net.sf.json.version&gt;2.2.3&lt;/net.sf.json.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;                    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-configuration&lt;/artifactId&gt;                    &lt;groupId&gt;commons-configuration&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-io&lt;/artifactId&gt;                    &lt;groupId&gt;commons-io&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;                    &lt;groupId&gt;commons-lang&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_kafka&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;snappy-java&lt;/artifactId&gt;                    &lt;groupId&gt;org.xerial.snappy&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;scala-library&lt;/artifactId&gt;                    &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;                    &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;log4j&lt;/artifactId&gt;                    &lt;groupId&gt;log4j&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;!--flume核心依赖--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;            &lt;artifactId&gt;flume-ng-core&lt;/artifactId&gt;            &lt;version&gt;${flume-ng.version}-${cdh.version}&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;guava&lt;/artifactId&gt;                    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-codec&lt;/artifactId&gt;                    &lt;groupId&gt;commons-codec&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;                    &lt;groupId&gt;commons-logging&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;jetty&lt;/artifactId&gt;                    &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;jetty-util&lt;/artifactId&gt;                    &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;                    &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-io&lt;/artifactId&gt;                    &lt;groupId&gt;commons-io&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;                    &lt;groupId&gt;commons-lang&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;            &lt;artifactId&gt;flume-ng-sdk&lt;/artifactId&gt;            &lt;version&gt;${flume-ng.version}-${cdh.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--flume配置依赖--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;            &lt;artifactId&gt;flume-ng-configuration&lt;/artifactId&gt;            &lt;version&gt;${flume-ng.version}-${cdh.version}&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;guava&lt;/artifactId&gt;                    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;jdom&lt;/groupId&gt;            &lt;artifactId&gt;jdom&lt;/artifactId&gt;            &lt;version&gt;${jdom.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;log4j&lt;/groupId&gt;            &lt;artifactId&gt;log4j&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-io&lt;/groupId&gt;            &lt;artifactId&gt;commons-io&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-lang&lt;/groupId&gt;            &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;commons-configuration&lt;/groupId&gt;            &lt;artifactId&gt;commons-configuration&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;            &lt;artifactId&gt;guava&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;defaultGoal&gt;compile&lt;/defaultGoal&gt;        &lt;sourceDirectory&gt;src/main/java/&lt;/sourceDirectory&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;manifest&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;classpathPrefix&gt;jars/&lt;/classpathPrefix&gt;                            &lt;mainClass&gt;&lt;/mainClass&gt;                        &lt;/manifest&gt;                    &lt;/archive&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;id&gt;copy&lt;/id&gt;                        &lt;phase&gt;install&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;copy-dependencies&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;outputDirectory&gt;                                ${project.build.directory}/jars                            &lt;/outputDirectory&gt;                            &lt;excludeArtifactIds&gt;javaee-api&lt;/excludeArtifactIds&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                &lt;version&gt;2.7&lt;/version&gt;                &lt;configuration&gt;                    &lt;encoding&gt;UTF-8&lt;/encoding&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><h4 id="2、自定义source">2、自定义source</h4><p><strong>2.1 继承AbstractSource 实现 Configurable, PollableSource接口</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.source;import com.hsiehchou.flume.constant.FlumeConfConstant;import com.hsiehchou.flume.fields.MapFields;import com.hsiehchou.flume.utils.FileUtilsStronger;import org.apache.commons.io.FileUtils;import org.apache.flume.Context;import org.apache.flume.Event;import org.apache.flume.PollableSource;import org.apache.flume.channel.ChannelProcessor;import org.apache.flume.conf.Configurable;import org.apache.flume.event.SimpleEvent;import org.apache.flume.source.AbstractSource;import org.apache.log4j.Logger;import java.io.File;import java.util.*;/** * 固定写法，自定义Source 直接继承 AbstractSource 和 实现 Configurable, PollableSource 接口 * 可参照官网 http://flume.apache.org/releases/content/1.9.0/FlumeDeveloperGuide.html#source */public class FolderSource extends AbstractSource implements Configurable, PollableSource {    private final Logger logger = Logger.getLogger(FolderSource.class);    //tier1.sources.source1.sleeptime=5    //tier1.sources.source1.filenum=3000    //tier1.sources.source1.dirs =/usr/chl/data/filedir/    //tier1.sources.source1.successfile=/usr/chl/data/filedir_successful/    //以下为配置在flume.conf文件中    //读取的文件目录    private String dirStr;    //读取的文件目录，如果多个，以","分割，在flume.conf里面配置    private String[] dirs;    //处理成功的文件写入的目录    private String successfile;    //睡眠时间    private long sleeptime = 5;    //每批文件数量    private int filenum = 500;    //以下为配置在txtparse.properties文件中    //读取的所有文件集合    private Collection&lt;File&gt; allFiles;    //一批处理的文件大小    private List&lt;File&gt; listFiles;    private ArrayList&lt;Event&gt; eventList = new ArrayList&lt;Event&gt;();    /**     * @param context 拿到flume配置里面的所有参数     */    @Override    public void configure(Context context) {        logger.info("开始初始化flume参数");        initFlumeParams(context);        logger.info("初始化flume参数成功");    }    @Override    public Status process() {        //定义处理逻辑        try {            Thread.currentThread().sleep(sleeptime * 1000);        } catch (InterruptedException e) {            logger.error(null, e);        }        Status status = null;        try {            // for (String dir : dirs) {            logger.info("dirStr===========" + dirStr);            //TODO 1.监控目录下面的所有文件            //读取目录下的文件，获取目录下所有以 "txt", "bcp" 结尾的文件            allFiles = FileUtils.listFiles(new File(dirStr), new String[]{"txt", "bcp"}, true);            //如果目录下文件总数大于阈值，则只取 filenum 个文件进行处理            if (allFiles.size() &gt;= filenum) {                //文件数量大于3000 只取3000条                listFiles = ((List&lt;File&gt;) allFiles).subList(0, filenum);            } else {                //文件数量小于3000，取所有文件进行处理                listFiles = ((List&lt;File&gt;) allFiles);            }            //TODO 2.遍历所有的文件进行解析            if (listFiles.size() &gt; 0) {                for (File file : listFiles) {                    //文件名是需要传到channel中的                    String fileName = file.getName();                    //解析文件  获取文件名及文件内容 文件绝对路径  文件内容                    Map&lt;String, Object&gt; stringObjectMap = FileUtilsStronger.parseFile(file, successfile);                    //返回的内容2个参数  一个是文件绝对路径  另一个是lines文件的所有内容                    //获取文件绝对路径                    String absoluteFilename = (String) stringObjectMap.get(MapFields.ABSOLUTE_FILENAME);                    //获取文件内容                    List&lt;String&gt; lines = (List&lt;String&gt;) stringObjectMap.get(MapFields.VALUE);                    //TODO 解析出来之后，需要把解析出来的数据封装为Event                    if (lines != null &amp;&amp; lines.size() &gt; 0) {                        //遍历读取的内容                        for (String line : lines) {                            //封装event Header 将文件名及文件绝对路径通过header传送到channel中                            //构建event头                            Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();                            //文件名                            map.put(MapFields.FILENAME, fileName);                            //文件绝对路径                            map.put(MapFields.ABSOLUTE_FILENAME, absoluteFilename);                            //构建event                            SimpleEvent event = new SimpleEvent();                            //把读取的一行数据转成字节                            byte[] bytes = line.getBytes();                            event.setBody(bytes);                            event.setHeaders(map);                            eventList.add(event);                        }                    }                    try {                        if (eventList.size() &gt; 0) {                            //获取channelProcessor                            ChannelProcessor channelProcessor = getChannelProcessor();                            //通过channelProcessor把eventList发送出去，可以通过拦截器进行拦截                            channelProcessor.processEventBatch(eventList);                            logger.info("批量推送到 拦截器 数据大小为" + eventList.size());                        }                        eventList.clear();                    } catch (Exception e) {                        eventList.clear();                        logger.error("发送数据到channel失败", e);                    } finally {                        eventList.clear();                    }                }            }            // 处理成功，返回成功状态            status = Status.READY;            return status;        } catch (Exception e) {            status = Status.BACKOFF;            logger.error("异常", e);            return status;        }    }    /**     * 初始化flume參數     * @param context     */    public void initFlumeParams(Context context) {        //读取flume，conf配置文件，初始化参数        try {            //文件处理目录            //监控的文件目录            dirStr = context.getString(FlumeConfConstant.DIRS);            //监控多个目录            dirs = dirStr.split(",");            //成功处理的文件存放目录            successfile = context.getString(FlumeConfConstant.SUCCESSFILE);            //每批处理文件个数            filenum = context.getInteger(FlumeConfConstant.FILENUM);            //睡眠时间            sleeptime = context.getLong(FlumeConfConstant.SLEEPTIME);            logger.info("dirStr============" + dirStr);            logger.info("dirs==============" + dirs);            logger.info("successfile=======" + successfile);            logger.info("filenum===========" + filenum);            logger.info("sleeptime=========" + sleeptime);        } catch (Exception e) {            logger.error("初始化flume参数失败", e);        }    }    @Override    public long getBackOffSleepIncrement() {        return 0;    }    @Override    public long getMaxBackOffSleepInterval() {        return 0;    }}</code></pre><p><strong>2.2 实现process()方法</strong><br>此处代码已经在2.1里面，不用再写了</p><pre><code class="highlight plaintext">public Status process() {       //定义处理逻辑       try {           Thread.currentThread().sleep(sleeptime * 1000);       } catch (InterruptedException e) {           logger.error(null, e);       }       Status status = null;       try {           // for (String dir : dirs) {           logger.info("dirStr===========" + dirStr);           //TODO 1.监控目录下面的所有文件           //读取目录下的文件，获取目录下所有以 "txt", "bcp" 结尾的文件           allFiles = FileUtils.listFiles(new File(dirStr), new String[]{"txt", "bcp"}, true);           //如果目录下文件总数大于阈值，则只取 filenum 个文件进行处理           if (allFiles.size() &gt;= filenum) {               //文件数量大于3000 只取3000条               listFiles = ((List&lt;File&gt;) allFiles).subList(0, filenum);           } else {               //文件数量小于3000，取所有文件进行处理               listFiles = ((List&lt;File&gt;) allFiles);           }           //TODO 2.遍历所有的文件进行解析           if (listFiles.size() &gt; 0) {               for (File file : listFiles) {                   //文件名是需要传到channel中的                   String fileName = file.getName();                   //解析文件  获取文件名及文件内容 文件绝对路径  文件内容                   Map&lt;String, Object&gt; stringObjectMap = FileUtilsStronger.parseFile(file, successfile);                   //返回的内容2个参数  一个是文件绝对路径  另一个是lines文件的所有内容                   //获取文件绝对路径                   String absoluteFilename = (String) stringObjectMap.get(MapFields.ABSOLUTE_FILENAME);                   //获取文件内容                   List&lt;String&gt; lines = (List&lt;String&gt;) stringObjectMap.get(MapFields.VALUE);                   //TODO 解析出来之后，需要把解析出来的数据封装为Event                   if (lines != null &amp;&amp; lines.size() &gt; 0) {                       //遍历读取的内容                       for (String line : lines) {                           //封装event Header 将文件名及文件绝对路径通过header传送到channel中                           //构建event头                           Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();                           //文件名                           map.put(MapFields.FILENAME, fileName);                           //文件绝对路径                           map.put(MapFields.ABSOLUTE_FILENAME, absoluteFilename);                           //构建event                           SimpleEvent event = new SimpleEvent();                           //把读取的一行数据转成字节                           byte[] bytes = line.getBytes();                           event.setBody(bytes);                           event.setHeaders(map);                           eventList.add(event);                       }                   }                   try {                       if (eventList.size() &gt; 0) {                           //获取channelProcessor                           ChannelProcessor channelProcessor = getChannelProcessor();                           //通过channelProcessor把eventList发送出去，可以通过拦截器进行拦截                           channelProcessor.processEventBatch(eventList);                           logger.info("批量推送到 拦截器 数据大小为" + eventList.size());                       }                       eventList.clear();                   } catch (Exception e) {                       eventList.clear();                       logger.error("发送数据到channel失败", e);                   } finally {                       eventList.clear();                   }               }           }           // 处理成功，返回成功状态           status = Status.READY;           return status;       } catch (Exception e) {           status = Status.BACKOFF;           logger.error("异常", e);           return status;       }   }</code></pre><p><strong>source/MySource.java—Flume官网上的案例</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.source;import org.apache.flume.Context;import org.apache.flume.Event;import org.apache.flume.EventDeliveryException;import org.apache.flume.PollableSource;import org.apache.flume.conf.Configurable;import org.apache.flume.event.SimpleEvent;import org.apache.flume.source.AbstractSource;public class MySource extends AbstractSource implements Configurable, PollableSource {    private String myProp;    /**     * 配置读取     * @param context     */    @Override    public void configure(Context context) {        String myProp = context.getString("myProp", "defaultValue");        // Process the myProp value (e.g. validation, convert to another type, ...)        // Store myProp for later retrieval by process() method        this.myProp = myProp;    }    /**     * 定义自己的业务逻辑     * @return     * @throws EventDeliveryException     */    @Override    public Status process() throws EventDeliveryException {        Status status = null;        try {            // This try clause includes whatever Channel/Event operations you want to do            // Receive new data            //需要把自己的数据封装为event进行传输            Event e = new SimpleEvent();            // Store the Event into this Source's associated Channel(s)            getChannelProcessor().processEvent(e);            status = Status.READY;        } catch (Throwable t) {            // Log exception, handle individual exceptions as needed            status = Status.BACKOFF;            // re-throw all Errors            if (t instanceof Error) {                throw (Error)t;            }        } finally {        }        return status;    }    @Override    public long getBackOffSleepIncrement() {        return 0;    }    @Override    public long getMaxBackOffSleepInterval() {        return 0;    }    @Override    public void start() {        // Initialize the connection to the external client    }    @Override    public void stop () {        // Disconnect from external client and do any additional cleanup        // (e.g. releasing resources or nulling-out field values) ..    }}</code></pre><h4 id="3、自定义interceptor—数据清洗过滤器">3、自定义interceptor—数据清洗过滤器</h4><p><strong>3.1实现Interceptor 接口</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.interceptor;import com.alibaba.fastjson.JSON;import com.hsiehchou.flume.fields.MapFields;import com.hsiehchou.flume.service.DataCheck;import org.apache.commons.io.Charsets;import org.apache.flume.Context;import org.apache.flume.Event;import org.apache.flume.event.SimpleEvent;import org.apache.flume.interceptor.Interceptor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;import java.util.Map;/** * 数据清洗过滤器 */public class DataCleanInterceptor implements Interceptor {    private static final Logger LOG = LoggerFactory.getLogger(DataCleanInterceptor.class);    //datatpye.properties    //private static Map&lt;String,ArrayList&lt;String&gt;&gt; dataMap = DataTypeProperties.dataTypeMap;    /**     *  初始化     */    @Override    public void initialize() {    }    /**     * 单条处理     * 拦截方法。数据解析，封装，数据清洗     * @param event     * @return     */    @Override    public Event intercept(Event event) {        SimpleEvent eventNew = new SimpleEvent();        try {            LOG.info("拦截器Event开始执行");            Map&lt;String, String&gt; map = parseEvent(event);            if(map == null){                return null;            }            String lineJson = JSON.toJSONString(map);            LOG.info("拦截器推送数据到channel:" +lineJson);            eventNew.setBody(lineJson.getBytes());        } catch (Exception e) {            LOG.error(null,e);        }        return eventNew;    }    /**     * 批处理     * @param events     * @return     */    @Override    public List&lt;Event&gt; intercept(List&lt;Event&gt; events) {        List&lt;Event&gt; list = new ArrayList&lt;Event&gt;();        for (Event event : events) {            Event intercept = intercept(event);            if (intercept != null) {                list.add(intercept);            }        }        return list;    }    @Override    public void close() {    }    /**     * 数据解析     * @param event     * @return     */    public static Map&lt;String,String&gt; parseEvent(Event event){        if (event == null) {            return null;        }        //00000000000000000000000000000024.00000025.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305985andiy18609765432judy1789098763        String line = new String(event.getBody(), Charsets.UTF_8);        //文件名 和 文件绝对路径        String filename = event.getHeaders().get(MapFields.FILENAME);        String absoluteFilename = event.getHeaders().get(MapFields.ABSOLUTE_FILENAME);        //String转map，进行数据校验，检验错误入ES错误表        Map&lt;String, String&gt; map = DataCheck.txtParseAndalidation(line,filename,absoluteFilename);        return map;        //wechat_source1_1111115.txt        //String[] fileNames = filename.split("_");        // String转map，并进行数据长度校验，校验错误入ES错误表        //Map&lt;String, String&gt; map = JZDataCheck.txtParse(type, line, source, filename,absoluteFilename);        //Map&lt;String,String&gt; map = new HashMap&lt;&gt;();        //00000000000000000000000000000024.00000025.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305985andiy18609765432judy1789098763        //String[] split = line.split("\t");        //数据类别        //String dataType = fileNames[0];        //imei,imsi,longitude,latitude,phone_mac,device_mac,device_number,collect_time,username,phone,object_username,send_message,accept_message,message_time        //ArrayList&lt;String&gt; fields = dataMap.get(dataType);        //for (int i = 0; i &lt; split.length; i++) {        //    map.put(fields.get(i),split[i]);        //}        //添加ID        //map.put(MapFields.ID, UUID.randomUUID().toString().replace("-",""));        // map.put(MapFields.TABLE, dataType);        // map.put(MapFields.FILENAME, filename);        // map.put(MapFields.ABSOLUTE_FILENAME, absoluteFilename);//        Map&lt;String, String&gt; map = DataCheck.txtParseAndalidation(line,filename,absoluteFilename);//        return map;    }    /**     * 实例化创建     */    public static class Builder implements Interceptor.Builder {        @Override        public void configure(Context context) {        }        @Override        public Interceptor build() {            return new DataCleanInterceptor();        }    }}</code></pre><h4 id="4、utils工具类">4、utils工具类</h4><p><strong>utils/FileUtilsStronger.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.utils;import com.hsiehchou.common.time.TimeTranstationUtils;import com.hsiehchou.flume.fields.MapFields;import org.apache.commons.io.FileUtils;import org.apache.log4j.Logger;import java.io.File;import java.util.*;import static java.io.File.separator;public class FileUtilsStronger {    private static final Logger logger = Logger.getLogger(FileUtilsStronger.class);    /**     * @param file     * @param path     */    public static Map&lt;String,Object&gt; parseFile(File file, String path) {        Map&lt;String,Object&gt; map=new HashMap&lt;String,Object&gt;();        List&lt;String&gt; lines;        String fileNew = path+ TimeTranstationUtils.Date2yyyy_MM_dd()+getDir(file);        try {            if((new File(fileNew+file.getName())).exists()){                try{                    logger.info("文件名已经存在，开始删除同名已经存在文件"+file.getAbsolutePath());                    file.delete();                    logger.info("删除同名已经存在文件"+file.getAbsolutePath()+"成功");                }catch (Exception e){                    logger.error("删除同名已经存在文件"+file.getAbsolutePath()+"失败",e);                }            }else{                lines = FileUtils.readLines(file);                map.put(MapFields.ABSOLUTE_FILENAME,fileNew+file.getName());                map.put(MapFields.VALUE,lines);                FileUtils.moveToDirectory(file, new File(fileNew), true);                logger.info("移动文件到"+file.getAbsolutePath()+"到"+fileNew+"成功");            }        } catch (Exception e) {            logger.error("移动文件" + file.getAbsolutePath() + "到" + fileNew + "失败", e);        }        return map;    }    /**     * @param file     * @param path     */    public static List&lt;String&gt; chanmodName(File file, String path) {        List&lt;String&gt; lines=null;        try {            if((new File(path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"/"+file.getName())).exists()){                logger.warn("文件名已经存在，开始删除同名文件" +path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"/"+file.getName());                try{                    file.delete();                    logger.warn("删除同名文件"+file.getAbsolutePath()+"成功");                }catch (Exception e){                    logger.warn("删除同名文件"+file.getAbsolutePath()+"失败",e);                }            }else{                lines = FileUtils.readLines(file);                FileUtils.moveToDirectory(file, new File(path+ TimeTranstationUtils.Date2yyyy_MM_dd()), true);                logger.info("移动文件到"+file.getAbsolutePath()+"到"+path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"成功");            }        } catch (Exception e) {            logger.error("移动文件" + file.getName() + "到" + path+ TimeTranstationUtils.Date2yyyy_MM_dd() + "失败", e);        }        return lines;    }    /**     * @param file     * @param path     */    public static void moveFile2unmanage(File file, String path) {        try {            if((new File(path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"/"+file.getName())).exists()){                logger.warn("文件名已经存在，开始删除同名文件" +file.getAbsolutePath());                try{                    file.delete();                    logger.warn("删除同名文件"+file.getAbsolutePath()+"成功");                }catch (Exception e){                    logger.warn("删除同名文件"+file.getAbsolutePath()+"失败",e);                }            }else{                FileUtils.moveToDirectory(file, new File(path+ TimeTranstationUtils.Date2yyyy_MM_dd()), true);                //logger.info("移动文件到"+file.getAbsolutePath()+"到"+path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"成功");            }        } catch (Exception e) {            logger.error("移动错误文件" + file.getName() + "到" + path+ TimeTranstationUtils.Date2yyyy_MM_dd() + "失败", e);        }    }    /**     * @param file     * @param path     */    public static void shnegtingChanmodName(File file, String path) {        try {            if((new File(path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"/"+file.getName())).exists()){                logger.warn("文件名已经存在，开始删除同名文件" +path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"/"+file.getName());                try{                    file.delete();                    logger.warn("删除同名文件"+file.getAbsolutePath()+"成功");                }catch (Exception e){                    logger.warn("删除同名文件"+file.getAbsolutePath()+"失败",e);                }            }else{                FileUtils.moveToDirectory(file, new File(path+ TimeTranstationUtils.Date2yyyy_MM_dd()), true);                logger.info("移动文件到"+file.getAbsolutePath()+"到"+path+ TimeTranstationUtils.Date2yyyy_MM_dd()+"成功");            }        } catch (Exception e) {            logger.error("移动文件" + file.getName() + "到" + path+ TimeTranstationUtils.Date2yyyy_MM_dd() + "失败", e);        }    }    /**     * 获取文件父目录     * @param file     * @return     */    public static String getDir(File file){        String dir=file.getParent();        StringTokenizer dirs = new StringTokenizer(dir, separator);        List&lt;String&gt; list=new ArrayList&lt;String&gt;();        while(dirs.hasMoreTokens()){            list.add((String)dirs.nextElement());        }        String str="";        for(int i=2;i&lt;list.size();i++){            str=str+separator+list.get(i);        }        return str+"/";    }}</code></pre><p><strong>utils/Validation.java—验证工具类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.utils;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 验证工具类 */@Deprecatedpublic class Validation { // ------------------常量定义/** * Email正则表达式= * "^([a-z0-9A-Z]+[-|\\.]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\.)+[a-zA-Z]{2,}$" * ; */// public static final String EMAIL =// "^([a-z0-9A-Z]+[-|\\.]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\.)+[a-zA-Z]{2,}$";;public static final String EMAIL = "\\w+(\\.\\w+)*@\\w+(\\.\\w+)+";/** * 电话号码正则表达式= * (^(\d{2,4}[-_－—]?)?\d{3,8}([-_－—]?\d{3,8})?([-_－—]?\d{1,7})?$)| * (^0?1[35]\d{9}$) */public static final String PHONE = "(^(\\d{2,4}[-_－—]?)?\\d{3,8}([-_－—]?\\d{3,8})?([-_－—]?\\d{1,7})?$)|(^0?1[35]\\d{9}$)";/** * 手机号码正则表达式=^(13[0-9]|15[0-9]|18[0-9])\d{8}$ */public static final String MOBILE = "^((13[0-9])|(14[5-7])|(15[^4])|(17[0-8])|(18[0-9]))\\d{8}$";/** * Integer正则表达式 ^-?(([1-9]\d*$)|0) */public static final String INTEGER = "^-?(([1-9]\\d*$)|0)";/** * 正整数正则表达式 &gt;=0 ^[1-9]\d*|0$ */public static final String INTEGER_NEGATIVE = "^[1-9]\\d*|0$";/** * 负整数正则表达式 &lt;=0 ^-[1-9]\d*|0$ */public static final String INTEGER_POSITIVE = "^-[1-9]\\d*|0$";/** * Double正则表达式 ^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ */public static final String DOUBLE = "^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$";/** * 正Double正则表达式 &gt;=0 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$　 */public static final String DOUBLE_NEGATIVE = "^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$";/** * 负Double正则表达式 &lt;= 0 ^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$ */public static final String DOUBLE_POSITIVE = "^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$";/** * 年龄正则表达式 ^(?:[1-9][0-9]?|1[01][0-9]|120)$ 匹配0-120岁 */public static final String AGE = "^(?:[1-9][0-9]?|1[01][0-9]|120)$";/** * 邮编正则表达式 [0-9]\d{5}(?!\d) 国内6位邮编 */public static final String CODE = "[0-9]\\d{5}(?!\\d)";/** * 匹配由数字、26个英文字母或者下划线组成的字符串 ^\w+$ */public static final String STR_ENG_NUM_ = "^\\w+$";/** * 匹配由数字和26个英文字母组成的字符串 ^[A-Za-z0-9]+$ */public static final String STR_ENG_NUM = "^[A-Za-z0-9]+";/** * 匹配由26个英文字母组成的字符串 ^[A-Za-z]+$ */public static final String STR_ENG = "^[A-Za-z]+$";/** * 过滤特殊字符串正则 regEx= * "[`~!@#$%^&amp;*()+=|{}':;',\\[\\].&lt;&gt;/?~！@#￥%……&amp;*（）——+|{}【】‘；：”“’。，、？]"; */public static final String STR_SPECIAL = "[`~!@#$%^&amp;*()+=|{}':;',\\[\\].&lt;&gt;/?~！@#￥%……&amp;*（）——+|{}【】‘；：”“’。，、？]";/*** * 日期正则 支持： YYYY-MM-DD YYYY/MM/DD YYYY_MM_DD YYYYMMDD YYYY.MM.DD的形式 */public static final String DATE_ALL = "((^((1[8-9]\\d{2})|([2-9]\\d{3}))([-\\/\\._]?)(10|12|0?[13578])([-\\/\\._]?)(3[01]|[12][0-9]|0?[1-9])$)"+ "|(^((1[8-9]\\d{2})|([2-9]\\d{3}))([-\\/\\._]?)(11|0?[469])([-\\/\\._]?)(30|[12][0-9]|0?[1-9])$)"+ "|(^((1[8-9]\\d{2})|([2-9]\\d{3}))([-\\/\\._]?)(0?2)([-\\/\\._]?)(2[0-8]|1[0-9]|0?[1-9])$)|(^([2468][048]00)([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|(^([3579][26]00)"+ "([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)"+ "|(^([1][89][0][48])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|(^([2-9][0-9][0][48])([-\\/\\._]?)"+ "(0?2)([-\\/\\._]?)(29)$)"+ "|(^([1][89][2468][048])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|(^([2-9][0-9][2468][048])([-\\/\\._]?)(0?2)"+ "([-\\/\\._]?)(29)$)|(^([1][89][13579][26])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$)|"+ "(^([2-9][0-9][13579][26])([-\\/\\._]?)(0?2)([-\\/\\._]?)(29)$))";/*** * 日期正则 支持： YYYY-MM-DD */public static final String DATE_FORMAT1 = "(([0-9]{3}[1-9]|[0-9]{2}[1-9][0-9]{1}|[0-9]{1}[1-9][0-9]{2}|[1-9][0-9]{3})-(((0[13578]|1[02])-(0[1-9]|[12][0-9]|3[01]))|((0[469]|11)-(0[1-9]|[12][0-9]|30))|(02-(0[1-9]|[1][0-9]|2[0-8]))))|((([0-9]{2})(0[48]|[2468][048]|[13579][26])|((0[48]|[2468][048]|[3579][26])00))-02-29)";/** * URL正则表达式 匹配 http www ftp */public static final String URL = "^(http|www|ftp|)?(://)?(\\w+(-\\w+)*)(\\.(\\w+(-\\w+)*))*((:\\d+)?)(/(\\w+(-\\w+)*))*(\\.?(\\w)*)(\\?)?"+ "(((\\w*%)*(\\w*\\?)*(\\w*:)*(\\w*\\+)*(\\w*\\.)*(\\w*&amp;)*(\\w*-)*(\\w*=)*(\\w*%)*(\\w*\\?)*"+ "(\\w*:)*(\\w*\\+)*(\\w*\\.)*"+ "(\\w*&amp;)*(\\w*-)*(\\w*=)*)*(\\w*)*)$";/** * 身份证正则表达式 */public static final String IDCARD = "((11|12|13|14|15|21|22|23|31|32|33|34|35|36|37|41|42|43|44|45|46|50|51|52|53|54|61|62|63|64|65)[0-9]{4})"+ "(([1|2][0-9]{3}[0|1][0-9][0-3][0-9][0-9]{3}"+ "[Xx0-9])|([0-9]{2}[0|1][0-9][0-3][0-9][0-9]{3}))";/** * 机构代码 */public static final String JIGOU_CODE = "^[A-Z0-9]{8}-[A-Z0-9]$";/** * 匹配数字组成的字符串 ^[0-9]+$ */public static final String STR_NUM = "^[0-9]+$";// //------------------验证方法/** * 判断字段是否为空 符合返回ture * @param str * @return boolean */public static synchronized boolean StrisNull(String str) {return null == str || str.trim().length() &lt;= 0 ? true : false;}/** * 判断字段是非空 符合返回ture * @param str * @return boolean */public static boolean StrNotNull(String str) {return !StrisNull(str);}/** * 字符串null转空 * @param str * @return boolean */public static String nulltoStr(String str) {return StrisNull(str) ? "" : str;}/** * 字符串null赋值默认值 * @param str 目标字符串 * @param defaut 默认值 * @return String */public static String nulltoStr(String str, String defaut) {return StrisNull(str) ? defaut : str;}/** * 判断字段是否为Email 符合返回ture * @param str * @return boolean */public static boolean isEmail(String str) {return Regular(str, EMAIL);}/** * 判断是否为电话号码 符合返回ture * @param str * @return boolean */public static boolean isPhone(String str) {return Regular(str, PHONE);}/** * 判断是否为手机号码 符合返回ture * @param str * @return boolean */public static boolean isMobile(String str) {return RegularSJHM(str, MOBILE);}/** * 判断是否为Url 符合返回ture * @param str * @return boolean */public static boolean isUrl(String str) {return Regular(str, URL);}/** * 判断字段是否为数字 正负整数 正负浮点数 符合返回ture * @param str * @return boolean */public static boolean isNumber(String str) {return Regular(str, DOUBLE);}/** * 判断字段是否为INTEGER 符合返回ture * @param str * @return boolean */public static boolean isInteger(String str) {return Regular(str, INTEGER);}/** * 判断字段是否为正整数正则表达式 &gt;=0 符合返回ture * @param str * @return boolean */public static boolean isINTEGER_NEGATIVE(String str) {return Regular(str, INTEGER_NEGATIVE);}/** * 判断字段是否为负整数正则表达式 &lt;=0 符合返回ture * @param str * @return boolean */public static boolean isINTEGER_POSITIVE(String str) {return Regular(str, INTEGER_POSITIVE);}/** * 判断字段是否为DOUBLE 符合返回ture * @param str * @return boolean */public static boolean isDouble(String str) {return Regular(str, DOUBLE);}/** * 判断字段是否为正浮点数正则表达式 &gt;=0 符合返回ture * @param str * @return boolean */public static boolean isDOUBLE_NEGATIVE(String str) {return Regular(str, DOUBLE_NEGATIVE);}/** * 判断字段是否为负浮点数正则表达式 &lt;=0 符合返回ture * @param str * @return boolean */public static boolean isDOUBLE_POSITIVE(String str) {return Regular(str, DOUBLE_POSITIVE);}/** * 判断字段是否为日期 符合返回ture * @param str * @return boolean */public static boolean isDate(String str) {return Regular(str, DATE_ALL);}/** * 验证 * @param str * @return */public static boolean isDate1(String str) {return Regular(str, DATE_FORMAT1);}/** * 判断字段是否为年龄 符合返回ture * @param str * @return boolean */public static boolean isAge(String str) {return Regular(str, AGE);}/** * 判断字段是否超长 字串为空返回fasle, 超过长度{leng}返回ture 反之返回false * @param str * @param leng * @return boolean */public static boolean isLengOut(String str, int leng) {return StrisNull(str) ? false : str.trim().length() &gt; leng;}/** * 判断字段是否为身份证 符合返回ture * @param str * @return boolean */public static boolean isIdCard(String str) {if (StrisNull(str))return false;if (str.trim().length() == 15 || str.trim().length() == 18) {return Regular(str, IDCARD);} else {return false;}}/** * 判断字段是否为邮编 符合返回ture * @param str * @return boolean */public static boolean isCode(String str) {return Regular(str, CODE);}/** * 判断字符串是不是全部是英文字母 * @param str * @return boolean */public static boolean isEnglish(String str) {return Regular(str, STR_ENG);}/** * 判断字符串是不是全部是英文字母+数字 * @param str * @return boolean */public static boolean isENG_NUM(String str) {return Regular(str, STR_ENG_NUM);}/** * 判断字符串是不是全部是英文字母+数字+下划线 * @param str * @return boolean */public static boolean isENG_NUM_(String str) {return Regular(str, STR_ENG_NUM_);}/** * 过滤特殊字符串 返回过滤后的字符串 * @param str * @return boolean */public static String filterStr(String str) {Pattern p = Pattern.compile(STR_SPECIAL);Matcher m = p.matcher(str);return m.replaceAll("").trim();}/** * 校验机构代码格式 * @return */public static boolean isJigouCode(String str) {return Regular(str, JIGOU_CODE);}/** * 判断字符串是不是数字组成 * @param str * @return boolean */public static boolean isSTR_NUM(String str) {return Regular(str, STR_NUM);}/** * 匹配是否符合正则表达式pattern 匹配返回true * @param str 匹配的字符串 * @param pattern 匹配模式 * @return boolean */private static boolean Regular(String str, String pattern) {if (null == str || str.trim().length() &lt;= 0)return false;Pattern p = Pattern.compile(pattern);Matcher m = p.matcher(str);return m.matches();}/** * 匹配是否符合正则表达式pattern 匹配返回true * @param str 匹配的字符串 * @param pattern 匹配模式 * @return boolean */private static boolean RegularSJHM(String str, String pattern) {if (null == str || str.trim().length() &lt;= 0){return false;}if(str.contains("+86")){str=str.replace("+86","");}Pattern p = Pattern.compile(pattern);Matcher m = p.matcher(str);return m.matches();}/** * description:匹配yyyyMMddHHmmss格式时间 * @param time * @return boolean */public static final String yyyyMMddHHmmss = "[0-9]{14}";public static boolean isyyyyMMddHHmmss(String time) {if (time == null) {return false;}boolean bool = time.matches(yyyyMMddHHmmss);return bool;}/** * description:匹配yyyyMMddHHmmss格式时间 * @param time * @return boolean */public static final String isMac = "^[A-Fa-f0-9]{2}(-[A-Fa-f0-9]{2}){5}$";public static boolean isMac(String mac) {if (mac == null) {return false;}boolean bool = mac.matches(isMac);return bool;}/** * description:匹配yyyyMMddHHmmss格式时间 * @param time * @return boolean */public static final String longtime = "[0-9]{10}";public static boolean isTimestamp(String timestamp) {if (timestamp == null) {return false;}boolean bool = timestamp.matches(longtime);return bool;}/** * 判断字段是否为datatype 符合返回ture * @param str * @return boolean */public static final String DATATYPE = "^\\d{7}$";public static boolean isDATATYPE(String str) {return Regular(str, DATATYPE);}/** * 判断字段是否为QQ 符合返回ture * @param str * @return boolean */public static final String QQ = "^\\d{5,15}$";public static boolean isQQ(String str) {return Regular(str, QQ);}/** * 判断字段是否为IMSI 符合返回ture * @param str * @return boolean */public static final String IMSI = "^4600[0,1,2,3,4,5,6,7,9]\\d{10}|(46011|46020)\\d{10}$";public static boolean isIMSI(String str) {return Regular(str, IMSI);}/** * 判断字段是否为IMEI 符合返回ture * @param str * @return boolean */public static final String IMEI = "^\\d{8}$|^[a-fA-F0-9]{14}$|^\\d{15}$";public static boolean isIMEI(String str) {return Regular(str, IMEI);}/** * 判断字段是否为CAPTURETIME 符合返回ture * @param str * @return boolean */public static final String CAPTURETIME = "^\\d{10}|(20[0-9][0-9])\\d{10}$";public static boolean isCAPTURETIME(String str) {return Regular(str, CAPTURETIME);}/** * description:检测认证类型 * @param auth * @return boolean */public static final String AUTH_TYPE = "^\\d{7}$";public static boolean isAUTH_TYPE(String str) {return Regular(str, CAPTURETIME);}/** * description:检测FIRM_CODE * @param auth * @return boolean */public static final String FIRM_CODE = "^\\d{9}$";public static boolean isFIRM_CODE(String str) {return Regular(str, FIRM_CODE);}/** * description:检测经度 * @param auth * @return boolean */public static final String LONGITUDE = "^-?(([1-9]\\d?)|(1[0-7]\\d)|180)(\\.\\d{1,6})?$";//public static final String LONGITUDE ="^([-]?(\\d|([1-9]\\d)|(1[0-7]\\d)|(180))(\\.\\d*)\\,[-]?(\\d|([1-8]\\d)|(90))(\\.\\d*))$";public static boolean isLONGITUDE(String str) {return Regular(str, LONGITUDE);}/** * description:检测纬度 * * @param auth * @return boolean 2016-7-19 下午4:50:06 by  */public static final String LATITUDE = "^-?(([1-8]\\d?)|([1-8]\\d)|90)(\\.\\d{1,6})?$";public static boolean isLATITUDE(String str) {return Regular(str, LATITUDE);}public static void main(String[] args) {boolean bool = isLATITUDE("25.546685");System.out.println(bool);}}</code></pre><h4 id="5、constant常量">5、constant常量</h4><p><strong>constant/FlumeConfConstant.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.constant;public class FlumeConfConstant {    //flumeSource配置    public static final String UNMANAGE="unmanage";    public static final String DIRS="dirs";    public static final String SUCCESSFILE="successfile";    public static final String ALL="all";    public static final String SOURCE="source";    public static final String FILENUM="filenum";    public static final String SLEEPTIME="sleeptime";    //ESSINK配置    public static final String TIMECELL="timecell";    public static final String MAXNUM="maxnum";    public static final String SINK_SOURCE="source";    public static final String THREADNUM="threadnum";    public static final String REDISHOST="redishost";}</code></pre><p><strong>constant/TxtConstant.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.constant;public class TxtConstant {    public static final String TYPE_ES="TYPE_ES";    public static final String STATIONCENTER="STATIONCENTER";    public static final String APCENTER="APCENTER";    public static final String IPLOGINLOG="IPLOGINLOG";    public static final String IMSIIMEI="IMSIIMEI";    public static final String MACHOUR="MACHOUR";    public static final String TYPE_SITEMANAGE="TYPE_SITEMANAGE";    public static final String JZWA="JZWA";    public static final String FIRMCODE="FIRMCODE";    public static final String FILENAME_FIELDS1="FILENAME_FIELDS1";    public static final String FILENAME_FIELDS2="FILENAME_FIELDS2";    public static final String FILENAME_FIELDS3="FILENAME_FIELDS3";    public static final String FILENAME_FIELDS4="FILENAME_FIELDS4";    public static final String FILENAME_FIELDS5="FILENAME_FIELDS5";    public static final String FILENAME_VALIDATION="FILENAME_VALIDATION";    public static final String AUTHTYPE_LIST="AUTHTYPE_LIST";    public static final String SOURCE_FEIJING="SOURCE_FEIJING";    public static final String SOURCE_650="SOURCE_650";    public static final String OFFICE_11="OFFICE_11";    public static final String OFFICE_12="OFFICE_12";    public static final String WLZK="WLZK";    public static final String FEIJING="FEIJING";    public static final String HLWZC="HLWZC";    public static final String WIFIWL="WIFIWL";    // 错误索引    public static final String ERROR_INDEX="es.errorindex";    public static final String ERROR_TYPE="es.errortype";    //WIFI索引    public static final String WIFILOG_INDEX="es.index.wifilog";    public static final String IPLOGINLOG_TYPE="es.type.iploginlog";    public static final String EMAIL_TYPE="es.type.email";    public static final String FTP_TYPE="es.type.ftp";    public static final String GAME_TYPE="es.type.game";    public static final String HEARTBEAT_TYPE="es.type.heartbeat";    public static final String HTTP_TYPE="es.type.http";    public static final String IMINFO_TYPE="es.type.iminfo";    public static final String ORGANIZATION_TYPE="es.type.organization";    public static final String SEARCH_TYPE="es.type.search";    public static final String IMSIIMEI_TYPE="es.type.imsiimei";}</code></pre><h4 id="6、field字段">6、field字段</h4><p><strong>field/ErrorMapFields.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.fields;public class ErrorMapFields {    public static final String RKSJ="RKSJ";    public static final String RECORD="RECORD";    public static final String LENGTH="LENGTH";    public static final String LENGTH_ERROR="LENGTH_ERROR";    public static final String LENGTH_ERROR_NUM="10001";    public static final String FILENAME="FILENAME";    public static final String FILENAME_ERROR="FILENAME_ERROR";    public static final String FILENAME_ERROR_NUM="10010";    public static final String ABSOLUTE_FILENAME="ABSOLUTE_FILENAME";    public static final String SJHM="SJHM";    public static final String SJHM_ERROR="SJHM_ERROR";    public static final String SJHM_ERRORCODE="10007";    public static final String DATA_TYPE="DATA_TYPE";    public static final String DATA_TYPE_ERROR="DATA_TYPE_ERROR";    public static final String DATA_TYPE_ERRORCODE="10011";    public static final String QQ="QQ";    public static final String QQ_ERROR="QQ_ERROR";    public static final String QQ_ERRORCODE="10002";    public static final String IMSI="IMSI";    public static final String IMSI_ERROR="IMSI_ERROR";    public static final String IMSI_ERRORCODE="10005";    public static final String IMEI="IMEI";    public static final String IMEI_ERROR="IMEI_ERROR";    public static final String IMEI_ERRORCODE="10006";    public static final String MAC="MAC";    public static final String CLIENTMAC="CLIENTMAC";    public static final String STATIONMAC="STATIONMAC";    public static final String BSSID="BSSID";    public static final String MAC_ERROR="MAC_ERROR";    public static final String MAC_ERRORCODE="10003";    public static final String DEVICENUM="DEVICENUM";    public static final String DEVICENUM_ERROR="DEVICENUM_ERROR";    public static final String DEVICENUM_ERRORCODE="10014";    public static final String CAPTURETIME="CAPTURETIME";    public static final String CAPTURETIME_ERROR="CAPTURETIME_ERROR";    public static final String CAPTURETIME_ERRORCODE="10019";    public static final String EMAIL="EMAIL";    public static final String EMAIL_ERROR="EMAIL_ERROR";    public static final String EMAIL_ERRORCODE="10004";    public static final String AUTH_TYPE="AUTH_TYPE";    public static final String AUTH_TYPE_ERROR="AUTH_TYPE_ERROR";    public static final String AUTH_TYPE_ERRORCODE="10020";    public static final String FIRM_CODE="FIRM_CODE";    public static final String FIRMCODE_NUM="FIRMCODE_NUM";    public static final String FIRM_CODE_ERROR="FIRM_CODE_ERROR";    public static final String FIRM_CODE_ERRORCODE="10009";    public static final String STARTTIME="STARTTIME";    public static final String STARTTIME_ERROR="STARTTIME_ERROR";    public static final String STARTTIME_ERRORCODE="10015";    public static final String ENDTIME="ENDTIME";    public static final String ENDTIME_ERROR="ENDTIME_ERROR";    public static final String ENDTIME_ERRORCODE="10016";    public static final String LOGINTIME="LOGINTIME";    public static final String LOGINTIME_ERROR="LOGINTIME_ERROR";    public static final String LOGINTIME_ERRORCODE="10017";    public static final String LOGOUTTIME="LOGOUTTIME";    public static final String LOGOUTTIME_ERROR="LOGOUTTIME_ERROR";    public static final String LOGOUTTIME_ERRORCODE="10018";    public static final String LONGITUDE="LONGITUDE";    public static final String LONGITUDE_ERROR="LONGITUDE_ERROR";    public static final String LONGITUDE_ERRORCODE="10012";    public static final String LATITUDE="LATITUDE";    public static final String LATITUDE_ERROR="LATITUDE_ERROR";    public static final String LATITUDE_ERRORCODE="10013";    //TODO 其他类型DATA_TYPE  记录    public static final String DATA_TYPE_OTHER="DATA_TYPE_OTHER";    public static final String DATA_TYPE_OTHER_ERROR="DATA_TYPE_OTHER_ERROR";    public static final String DATA_TYPE_OTHER_ERRORCODE="10022";    //TODO USERNAME 错误    public static final String USERNAME="USERNAME";    public static final String USERNAME_ERROR="USERNAME_ERROR";    public static final String USERNAME_ERRORCODE="10023";}</code></pre><p><strong>field/MapFields.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.fields;public class MapFields {    public static final String ID="id";    public static final String SOURCE="source";    public static final String TYPE="TYPE";    public static final String TABLE="table";    public static final String FILENAME="filename";    public static final String RKSJ="rksj";    public static final String ABSOLUTE_FILENAME="absolute_filename";    public static final String BSSID="BSSID";    public static final String USERNAME="USERNAME";    public static final String DAYID="DAYID";    public static final String FIRMCODE_NUM="FIRMCODE_NUM";    public static final String FIRM_CODE="FIRM_CODE";    public static final String IMEI="IMEI";    public static final String IMSI="IMSI";    public static final String DATA_TYPE_NAME="DATA_TYPE_NAME";    public static final String AUTH_TYPE="AUTH_TYPE";    public static final String AUTH_ACCOUNT="AUTH_ACCOUNT";    //TODO 时间类参数    public static final String CAPTURETIME="CAPTURETIME";    public static final String LOGINTIME="LOGINTIME";    public static final String LOGOUTTIME="LOGOUTTIME";    public static final String STARTTIME="STARTTIME";    public static final String ENDTIME="ENDTIME";    public static final String FIRSTTIME="FIRSTTIME";    public static final String LASTTIME="LASTTIME";    //TODO 去重参数    public static final String COUNT="COUNT";    public static final String DATA_TYPE="DATA_TYPE";    public static final String VALUE="value";    public static final String SITECODE="SITECODE";    public static final String SITECODENEW="SITECODENEW";    public static final String DEVICENUM="DEVICENUM";    public static final String MAC="MAC";    public static final String CLIENTMAC="CLIENTMAC";    public static final String STATIONMAC="STATIONMAC";    public static final String BRAND="BRAND";    public static final String INDEX="INDEX";    public static final String ACTION_TYPE="ACTION_TYPE";    public static final String CITY_CODE="CITY_CODE";    /* public static final String FILENAME_FIELDS1="FILENAME_FIELDS1";    public static final String FILENAME_FIELDS1="FILENAME_FIELDS1";    public static final String FILENAME_FIELDS1="FILENAME_FIELDS1";    public static final String FILENAME_FIELDS1="FILENAME_FIELDS1";*/}</code></pre><h4 id="7、自定义sink">7、自定义sink</h4><p><strong>sink/KafkaSink.java—将数据下沉到kafka</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.sink;import com.google.common.base.Throwables;import com.hsiehchou.kafka.producer.StringProducer;import org.apache.flume.*;import org.apache.flume.conf.Configurable;import org.apache.flume.sink.AbstractSink;import org.apache.log4j.Logger;import java.util.ArrayList;import java.util.List;public class KafkaSink extends AbstractSink implements Configurable {private final Logger logger = Logger.getLogger(KafkaSink.class);private String[] kafkatopics = null;//private List&lt;KeyedMessage&lt;String,String&gt;&gt; listKeyedMessage=null;private List&lt;String&gt; listKeyedMessage=null;private Long proTimestamp=System.currentTimeMillis();/** * 配置读取 * @param context */@Overridepublic void configure(Context context) {//tier1.sinks.sink1.kafkatopic=chl_test7//获取 推送kafkatopic参数kafkatopics = context.getString("kafkatopics").split(",");logger.info("获取kafka topic配置" + context.getString("kafkatopics"));listKeyedMessage=new ArrayList&lt;&gt;();}@Overridepublic Status process() throws EventDeliveryException {logger.info("sink开始执行");Channel channel = getChannel();Transaction transaction = channel.getTransaction();transaction.begin();try {//从channel中拿到eventEvent event = channel.take();if (event == null) {transaction.rollback();return Status.BACKOFF;}// 解析记录 获取事件内容String recourd = new String(event.getBody());// 发送数据到kafkatry {//调用kafka的消息推送，将数据推送到kafkaStringProducer.producer(kafkatopics[0],recourd);/*if(listKeyedMessage.size()&gt;1000){logger.info("数据大与10000,推送数据到kafka");sendListKeyedMessage();logger.info("数据大与10000,推送数据到kafka成功");}else if(System.currentTimeMillis()-proTimestamp&gt;=60*1000){logger.info("时间间隔大与60,推送数据到kafka");sendListKeyedMessage();logger.info("时间间隔大与60,推送数据到kafka成功"+listKeyedMessage.size());}*/} catch (Exception e) {logger.error("推送数据到kafka失败" , e);throw Throwables.propagate(e);}transaction.commit();return Status.READY;} catch (ChannelException e) {logger.error(e);transaction.rollback();return Status.BACKOFF;} finally {if(transaction != null){transaction.close();}}}@Overridepublic synchronized void stop() {super.stop();}/*private void sendListKeyedMessage(){Producer&lt;String, String&gt; producer = new Producer&lt;&gt;(KafkaConfig.getInstance().getProducerConfig());producer.send(listKeyedMessage);listKeyedMessage.clear();proTimestamp=System.currentTimeMillis();producer.close();}*/}</code></pre><h4 id="8、service">8、service</h4><p><strong>DataCheck.java—数据校验</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.service;import com.alibaba.fastjson.JSON;import com.hsiehchou.common.net.HttpRequest;import com.hsiehchou.common.project.datatype.DataTypeProperties;import com.hsiehchou.common.time.TimeTranstationUtils;import com.hsiehchou.flume.fields.ErrorMapFields;import com.hsiehchou.flume.fields.MapFields;import org.apache.log4j.Logger;import java.util.*;/** * 数据校验 */public class DataCheck {    private final static Logger LOG = Logger.getLogger(DataCheck.class);    /**     * 获取数据类型对应的字段  对应的文件     * 结构为 [ 数据类型1 = [字段1，字段2。。。。]，     * 数据类型2 = [字段1，字段2。。。。]]     */    private static Map&lt;String, ArrayList&lt;String&gt;&gt; dataMap = DataTypeProperties.dataTypeMap;    /**     * 数据解析     * @param line     * @param fileName     * @param absoluteFilename     * @return     */    public static Map&lt;String, String&gt; txtParse(String line, String fileName, String absoluteFilename) {        Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();        String[] fileNames = fileName.split("_");        String dataType = fileNames[0];        if (dataMap.containsKey(dataType)) {            List&lt;String&gt; fields = dataMap.get(dataType.toLowerCase());            String[] splits = line.split("\t");            //长度校验            if (fields.size() == splits.length) {                //添加公共字段                map.put(MapFields.ID, UUID.randomUUID().toString().replace("-", ""));                map.put(MapFields.TABLE, dataType.toLowerCase());                map.put(MapFields.RKSJ, (System.currentTimeMillis() / 1000) + "");                map.put(MapFields.FILENAME, fileName);                map.put(MapFields.ABSOLUTE_FILENAME, absoluteFilename);                for (int i = 0; i &lt; splits.length; i++) {                    map.put(fields.get(i), splits[i]);                }            } else {                map = null;                LOG.error("字段长度不匹配fields"+fields.size()  + "/t" + splits.length);            }        } else {            map = null;            LOG.error("配置文件中不存在此数据类型");        }        return map;    }    /**     * 数据长度校验添加必要字段并转map，将长度不符合的插入ES数据库     * @param line     * @param fileName     * @param absoluteFilename     * @return     */    public static Map&lt;String, String&gt; txtParseAndalidation(String line, String fileName, String absoluteFilename) {        Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();        Map&lt;String, Object&gt; errorMap = new HashMap&lt;String, Object&gt;();        //文件名按"_"切分  wechat_source1_1111142.txt        //wechat 数据类型        //source1 数据来源        //1111142  不让文件名相同        String[] fileNames = fileName.split("_");        String dataType = fileNames[0];        String source = fileNames[1];        if (dataMap.containsKey(dataType)) {            //获取数据类型字段            // imei,imsi,longitude,latitude,phone_mac,device_mac,device_number,collect_time,username,phone,object_username,send_message,accept_message,message_time            //根据数据类型，获取改类型的字段            List&lt;String&gt; fields = dataMap.get(dataType.toLowerCase());            //line            String[] splits = line.split("\t");            //长度校验            if (fields.size() == splits.length) {                for (int i = 0; i &lt; splits.length; i++) {                    map.put(fields.get(i), splits[i]);                }                //添加公共字段                // map.put(SOURCE, source);                map.put(MapFields.ID, UUID.randomUUID().toString().replace("-", ""));                map.put(MapFields.TABLE, dataType.toLowerCase());                map.put(MapFields.RKSJ, (System.currentTimeMillis() / 1000) + "");                map.put(MapFields.FILENAME, fileName);                map.put(MapFields.ABSOLUTE_FILENAME, absoluteFilename);                //数据封装完成  开始进行数据校验                errorMap = DataValidation.dataValidation(map);            } else {                errorMap.put(ErrorMapFields.LENGTH, "字段数不匹配 实际" + fields.size() + "\t" + "结果" + splits.length);                errorMap.put(ErrorMapFields.LENGTH_ERROR, ErrorMapFields.LENGTH_ERROR_NUM);                LOG.info("字段数不匹配 实际" + fields.size() + "\t" + "结果" + splits.length);                map = null;            }            //判断数据是否存在错误            if (null != errorMap &amp;&amp; errorMap.size() &gt; 0) {                LOG.info("errorMap===" + errorMap);                if ("1".equals("1")) {                    //addErrorMapES(errorMap, map, fileName, absoluteFilename);                    //验证没通过，将错误数据写到ES，并将map置空                    addErrorMapESByHTTP(errorMap, map, fileName, absoluteFilename);                }                map = null;            }        } else {            map = null;            LOG.error("配置文件中不存在此数据类型");        }        return map;    }    /**     *  将错误信息写入ES，方便查错     * @param errorMap     * @param map     * @param fileName     * @param absoluteFilename     */    public static void addErrorMapESByHTTP(Map&lt;String, Object&gt; errorMap, Map&lt;String, String&gt; map, String fileName, String absoluteFilename) {        String errorType = fileName.split("_")[0];        errorMap.put(MapFields.TABLE, errorType);        errorMap.put(MapFields.ID, UUID.randomUUID().toString().replace("-", ""));        errorMap.put(ErrorMapFields.RECORD, map);        errorMap.put(ErrorMapFields.FILENAME, fileName);        errorMap.put(ErrorMapFields.ABSOLUTE_FILENAME, absoluteFilename);        errorMap.put(ErrorMapFields.RKSJ, TimeTranstationUtils.Date2yyyy_MM_dd_HH_mm_ss());        String url="http://192.168.116.201:9200/error_recourd/error_recourd/"+ errorMap.get(MapFields.ID).toString();        String json = JSON.toJSONString(errorMap);        HttpRequest.sendPost(url,json);        //HttpRequest.sendPostMessage(url, errorMap);    }    /*    public static void addErrorMapES(Map&lt;String, Object&gt; errorMap, Map&lt;String, String&gt; map, String fileName, String absoluteFilename) {        String errorType = fileName.split("_")[0];        errorMap.put(MapFields.TABLE, errorType);        errorMap.put(MapFields.ID, UUID.randomUUID().toString().replace("-", ""));        errorMap.put(ErrorMapFields.RECORD, map);        errorMap.put(ErrorMapFields.FILENAME, fileName);        errorMap.put(ErrorMapFields.ABSOLUTE_FILENAME, absoluteFilename);        errorMap.put(ErrorMapFields.RKSJ, TimeTranstationUtils.Date2yyyy_MM_dd_HH_mm_ss());        TransportClient client = null;        try {            LOG.info("开始获取客户端===============================" + errorMap);            client = ESClientUtils.getClient();        } catch (Throwable t) {            if (t instanceof Error) {                throw (Error)t;            }            LOG.error(null,t);        }        //JestClient jestClient = JestService.getJestClient();        //boolean bool = JestService.indexOne(jestClient,TxtConstant.ERROR_INDEX, TxtConstant.ERROR_TYPE,errorMap.get(MapFields.ID).toString(),errorMap);        LOG.info("开始写入错误数据到ES===============================" + errorMap);        boolean bool = IndexUtil.putIndexData(TxtConstant.ERROR_INDEX, TxtConstant.ERROR_TYPE, errorMap.get(MapFields.ID).toString(), errorMap,client);        if(bool){            LOG.info("写入错误数据到ES===============================" + errorMap);        }else{            LOG.info("写入错误数据到ES===============================失败");        }    }*/    public static void main(String[] args) {    }}</code></pre><p><strong>DataValidation.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.flume.service;import com.hsiehchou.flume.fields.ErrorMapFields;import com.hsiehchou.flume.fields.MapFields;import com.hsiehchou.flume.utils.Validation;import org.apache.commons.lang.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.HashMap;import java.util.List;import java.util.Map;public class DataValidation {    private static final Logger LOG = LoggerFactory.getLogger(DataValidation.class);   //  private static final TxtConfigurationFileReader reader = TxtConfigurationFileReader.getInstance();   //  private static final DataTypeConfigurationFileReader datatypereader = DataTypeConfigurationFileReader.getInstance();   //  private static final ValidationConfigurationFileReader readerValidation = ValidationConfigurationFileReader.getInstance();    private static Map&lt;String,String&gt;  dataTypeMap;    private static List&lt;String&gt; listAuthType;    private static String isErrorES;    private static final String USERNAME=ErrorMapFields.USERNAME;    private static final String DATA_TYPE=ErrorMapFields.DATA_TYPE;    private static final String DATA_TYPE_ERROR=ErrorMapFields.DATA_TYPE_ERROR;    private static final String DATA_TYPE_ERRORCODE=ErrorMapFields.DATA_TYPE_ERRORCODE;    private static final String SJHM=ErrorMapFields.SJHM;    private static final String SJHM_ERROR=ErrorMapFields.SJHM_ERROR;    private static final String SJHM_ERRORCODE=ErrorMapFields.SJHM_ERRORCODE;    private static final String QQ=ErrorMapFields.QQ;    private static final String QQ_ERROR=ErrorMapFields.QQ_ERROR;    private static final String QQ_ERRORCODE=ErrorMapFields.QQ_ERRORCODE;    private static final String IMSI=ErrorMapFields.IMSI;    private static final String IMSI_ERROR=ErrorMapFields.IMSI_ERROR;    private static final String IMSI_ERRORCODE=ErrorMapFields.IMSI_ERRORCODE;    private static final String IMEI=ErrorMapFields.IMEI;    private static final String IMEI_ERROR=ErrorMapFields.IMEI_ERROR;    private static final String IMEI_ERRORCODE=ErrorMapFields.IMEI_ERRORCODE;    private static final String MAC=ErrorMapFields.MAC;    private static final String CLIENTMAC=ErrorMapFields.CLIENTMAC;    private static final String STATIONMAC=ErrorMapFields.STATIONMAC;    private static final String BSSID=ErrorMapFields.BSSID;    private static final String MAC_ERROR=ErrorMapFields.MAC_ERROR;    private static final String MAC_ERRORCODE=ErrorMapFields.MAC_ERRORCODE;    private static final String DEVICENUM=ErrorMapFields.DEVICENUM;    private static final String DEVICENUM_ERROR=ErrorMapFields.DEVICENUM_ERROR;    private static final String DEVICENUM_ERRORCODE=ErrorMapFields.DEVICENUM_ERRORCODE;    private static final String CAPTURETIME=ErrorMapFields.CAPTURETIME;    private static final String CAPTURETIME_ERROR=ErrorMapFields.CAPTURETIME_ERROR;    private static final String CAPTURETIME_ERRORCODE=ErrorMapFields.CAPTURETIME_ERRORCODE;    private static final String EMAIL=ErrorMapFields.EMAIL;    private static final String EMAIL_ERROR=ErrorMapFields.EMAIL_ERROR;    private static final String EMAIL_ERRORCODE=ErrorMapFields.EMAIL_ERRORCODE;    private static final String AUTH_TYPE=ErrorMapFields.AUTH_TYPE;    private static final String AUTH_TYPE_ERROR=ErrorMapFields.AUTH_TYPE_ERROR;    private static final String AUTH_TYPE_ERRORCODE=ErrorMapFields.AUTH_TYPE_ERRORCODE;    private static final String FIRM_CODE=ErrorMapFields.FIRM_CODE;    private static final String FIRM_CODE_ERROR=ErrorMapFields.FIRM_CODE_ERROR;    private static final String FIRM_CODE_ERRORCODE=ErrorMapFields.FIRM_CODE_ERRORCODE;    private static final String STARTTIME=ErrorMapFields.STARTTIME;    private static final String STARTTIME_ERROR=ErrorMapFields.STARTTIME_ERROR;    private static final String STARTTIME_ERRORCODE=ErrorMapFields.STARTTIME_ERRORCODE;    private static final String ENDTIME=ErrorMapFields.ENDTIME;    private static final String ENDTIME_ERROR=ErrorMapFields.ENDTIME_ERROR;    private static final String ENDTIME_ERRORCODE=ErrorMapFields.ENDTIME_ERRORCODE;    private static final String LOGINTIME=ErrorMapFields.LOGINTIME;    private static final String LOGINTIME_ERROR=ErrorMapFields.LOGINTIME_ERROR;    private static final String LOGINTIME_ERRORCODE=ErrorMapFields.LOGINTIME_ERRORCODE;    private static final String LOGOUTTIME=ErrorMapFields.LOGOUTTIME;    private static final String LOGOUTTIME_ERROR=ErrorMapFields.LOGOUTTIME_ERROR;    private static final String LOGOUTTIME_ERRORCODE=ErrorMapFields.LOGOUTTIME_ERRORCODE;    public static Map&lt;String, Object&gt; dataValidation( Map&lt;String, String&gt; map){        if(map == null){            return null;        }        Map&lt;String,Object&gt; errorMap = new HashMap&lt;String,Object&gt;();        //验证手机号码        sjhmValidation(map,errorMap);        //验证MAC        macValidation(map,errorMap);        //验证经纬度        longlaitValidation(map,errorMap);        //定义自己的清洗规则        //TODO 大小写统一        //TODO 时间类型统一        //TODO 数据字段统一        //TODO 业务字段转换        //TODO 数据矫正        //TODO 验证MAC不能为空        //TODO 验证IMSI不能为空        //TODO 验证 QQ IMSI IMEI        //TODO 验证DEVICENUM是否为空 为空返回错误        /*devicenumValidation(map,errorMap);        //TODO 验证CAPTURETIME是否为空 为空过滤   不为10，14位数字过滤        capturetimeValidation(map,errorMap);        //TODO 验证EMAIL        emailValidation(map,errorMap);        //TODO 验证STARTTIME ENDTIME LOGINTIME LOGOUTTIME        timeValidation(map,errorMap);        */        return errorMap;    }    /**     * 手机号码验证     * @param map     * @param errorMap     */    public static void sjhmValidation(Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map.containsKey("phone")){            String sjhm=map.get("phone");            //调用正则做手机号码验证，是否是正确的一个，检验            boolean ismobile = Validation.isMobile(sjhm);            if(!ismobile){                errorMap.put(SJHM,sjhm);                errorMap.put(SJHM_ERROR,SJHM_ERRORCODE);            }        }    }    //TODO QQ验证  10002  QQ编码 1030001    需要根据DATATYPE来判断数据类型的一起验证    public static void virtualValidation(String dataType, Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        //TODO USERNAME验证  10023  长度》=2        if(map.containsKey(ErrorMapFields.USERNAME)){            String username=map.get(ErrorMapFields.USERNAME);            if(StringUtils.isNotBlank(username)){                if(username.length()&lt;2){                    errorMap.put(ErrorMapFields.USERNAME,username);                    errorMap.put(ErrorMapFields.USERNAME_ERROR,ErrorMapFields.USERNAME_ERRORCODE);                }            }        }        //TODO QQ验证  10002  QQ编码 1030001        if("1030001".equals(dataType)&amp;&amp; map.containsKey(USERNAME)){            String qqnum= map.get(USERNAME);            boolean bool = Validation.isQQ(qqnum);            if(!bool){                errorMap.put(QQ,qqnum);                errorMap.put(QQ_ERROR,QQ_ERRORCODE);            }        }        //TODO IMSI验证  10005  IMSI编码 1429997        if("1429997".equals(dataType)&amp;&amp; map.containsKey(IMSI)){            String imsi= map.get(IMSI);            boolean bool = Validation.isIMSI(imsi);            if(!bool){                errorMap.put(IMSI,imsi);                errorMap.put(IMSI_ERROR,IMSI_ERRORCODE);            }        }        //TODO IMEI验证  10006  IMEI编码 1429998        if("1429998".equals(dataType)&amp;&amp; map.containsKey(IMEI)){            String imei= map.get(IMEI);            boolean bool = Validation.isIMEI(imei);            if(!bool){                errorMap.put(IMEI,imei);                errorMap.put(IMEI_ERROR,IMEI_ERRORCODE);            }        }    }    //MAC验证  10003    public static void macValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        if(map.containsKey("phone_mac")){            String mac=map.get("phone_mac");            if(StringUtils.isNotBlank(mac)){                boolean bool = Validation.isMac(mac);                if(!bool){                    LOG.info("MAC验证失败");                    errorMap.put(MAC,mac);                    errorMap.put(MAC_ERROR,MAC_ERRORCODE);                }            }else{                LOG.info("MAC验证失败");                errorMap.put(MAC,mac);                errorMap.put(MAC_ERROR,MAC_ERRORCODE);            }        }    }    /**     * TODO DEVICENUM 验证 为空过滤     * @param map     * @param errorMap     */    public static void devicenumValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        if(map.containsKey("device_number")){            String devicenum=map.get("device_number");            if(StringUtils.isBlank(devicenum)){                errorMap.put(DEVICENUM,"设备编码不能为空");                errorMap.put(DEVICENUM_ERROR,DEVICENUM_ERRORCODE);            }        }    }    /**     * TODO CAPTURETIME验证 为空过滤  10019  验证时间长度为10或14位     * @param map     * @param errorMap     */    public static void capturetimeValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        if(map.containsKey(CAPTURETIME)){            String capturetime=map.get(CAPTURETIME);            if(StringUtils.isBlank(capturetime)){                errorMap.put(CAPTURETIME,"CAPTURETIME不能为空");                errorMap.put(CAPTURETIME_ERROR,CAPTURETIME_ERRORCODE);            }else{                boolean bool = Validation.isCAPTURETIME(capturetime);                if(!bool){                    errorMap.put(CAPTURETIME,capturetime);                    errorMap.put(CAPTURETIME_ERROR,CAPTURETIME_ERRORCODE);                }            }        }    }    //TODO EMAIL验证 为空过滤 为错误过滤  10004  通过TABLE取USERNAME验证    public static void emailValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        if(map.get("TABLE").equals(EMAIL)){            String email=map.get(USERNAME);            if(StringUtils.isNotBlank(email)){                boolean bool = Validation.isEmail(email);                if(!bool){                    errorMap.put(EMAIL,email);                    errorMap.put(EMAIL_ERROR,EMAIL_ERRORCODE);                }            }else{                errorMap.put(EMAIL,"EMAIL不能为空");                errorMap.put(EMAIL_ERROR,EMAIL_ERRORCODE);            }        }    }    //TODO EMAIL验证 为空过滤 为错误过滤  10004  通过TABLE取USERNAME验证    public static void timeValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        if(map.containsKey(STARTTIME)&amp;&amp;map.containsKey(ENDTIME)){            String starttime=map.get(STARTTIME);            String endtime=map.get(ENDTIME);            if(StringUtils.isBlank(starttime)&amp;&amp;StringUtils.isBlank(endtime)){                errorMap.put(STARTTIME,"STARTTIME和ENDTIME不能同时为空");                errorMap.put(STARTTIME_ERROR,STARTTIME_ERRORCODE);                errorMap.put(ENDTIME,"STARTTIME和ENDTIME不能同时为空");                errorMap.put(ENDTIME_ERROR,ENDTIME_ERRORCODE);            }else{                Boolean bool1 = istime(starttime, STARTTIME, STARTTIME_ERROR, STARTTIME_ERRORCODE, errorMap);                Boolean bool2 = istime(endtime, ENDTIME, ENDTIME_ERROR, ENDTIME_ERRORCODE, errorMap);                if(bool1&amp;&amp;bool2&amp;&amp;(starttime.length()!=endtime.length())){                    errorMap.put(STARTTIME,"STARTTIME和ENDTIME长度不等 STARTTIME："+starttime + "\t"+"ENDTIME:" + endtime);                    errorMap.put(STARTTIME_ERROR,STARTTIME_ERRORCODE);                    errorMap.put(ENDTIME,"STARTTIME和ENDTIME长度不等 STARTTIME："+starttime + "\t"+"ENDTIME:" + endtime);                    errorMap.put(ENDTIME_ERROR,ENDTIME_ERRORCODE);                }                else if(bool1&amp;&amp;bool2&amp;&amp;(endtime.compareTo(starttime)&lt;0)){                    errorMap.put(STARTTIME,"ENDTIME必须大于STARTTIME  STARTTIME:"+starttime + "\t"+"ENDTIME:" + endtime);                    errorMap.put(STARTTIME_ERROR,STARTTIME_ERRORCODE);                    errorMap.put(ENDTIME,"ENDTIME必须大于STARTTIME  STARTTIME:"+starttime + "\t"+"ENDTIME:" + endtime);                    errorMap.put(ENDTIME_ERROR,ENDTIME_ERRORCODE);                }            }        }else if(map.containsKey(LOGINTIME)&amp;&amp;map.containsKey(LOGOUTTIME)){            String logintime=map.get(LOGINTIME);            String logouttime=map.get(LOGOUTTIME);            if(StringUtils.isBlank(logintime)&amp;&amp;StringUtils.isBlank(logouttime)){                errorMap.put(LOGINTIME,"LOGINTIME和LOGOUTTIME不能同时为空");                errorMap.put(LOGINTIME_ERROR,LOGINTIME_ERRORCODE);                errorMap.put(LOGOUTTIME,"LOGINTIME和LOGOUTTIME不能同时为空");                errorMap.put(LOGOUTTIME_ERROR,LOGOUTTIME_ERRORCODE);            }else{                Boolean bool1 = istime(logintime, LOGINTIME, LOGINTIME_ERROR, LOGINTIME_ERRORCODE, errorMap);                Boolean bool2 = istime(logouttime, LOGOUTTIME, LOGOUTTIME_ERROR, LOGOUTTIME_ERRORCODE, errorMap);                if(bool1&amp;&amp;bool2&amp;&amp;(logintime.length()!=logouttime.length())){                    errorMap.put(LOGINTIME,"LOGOUTTIME LOGINTIME长度不等 LOGINTIME："+logintime + "\t"+"LOGOUTTIME:" + logouttime);                    errorMap.put(LOGINTIME_ERROR,LOGINTIME_ERRORCODE);                    errorMap.put(LOGOUTTIME,"LOGOUTTIME LOGINTIME长度不等 LOGINTIME："+logintime + "\t"+"LOGOUTTIME:" + logouttime);                    errorMap.put(LOGOUTTIME_ERROR,LOGOUTTIME_ERRORCODE);                }                else if(bool1&amp;&amp;bool2&amp;&amp;(logouttime.compareTo(logintime)&lt;0)){                    errorMap.put(LOGINTIME,"LOGOUTTIME必须大于LOGINTIME  LOGINTIME:"+logintime + "\t"+"LOGOUTTIME:" + logouttime);                    errorMap.put(LOGINTIME_ERROR,LOGINTIME_ERRORCODE);                    errorMap.put(LOGOUTTIME,"LOGOUTTIME必须大于LOGINTIME  LOGINTIME:"+logintime + "\t"+"LOGOUTTIME:" + logouttime);                    errorMap.put(LOGOUTTIME_ERROR,LOGOUTTIME_ERRORCODE);                }            }        }    }    //TODO AUTH_TYPE验证  为空过滤 为错误过滤  10020    public static void authtypeValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        String fileName=map.get(MapFields.FILENAME);        if(fileName.split("_").length&lt;=2){            map = null;            return;        }        if(StringUtils.isNotBlank(fileName)){            if("bh".equals(fileName.split("_")[2])||"wy".equals(fileName.split("_")[2])||"yc".equals(fileName.split("_")[2])){                return ;            }else if(map.containsKey(AUTH_TYPE)){                String authtype=map.get(AUTH_TYPE);                if(StringUtils.isNotBlank(authtype)){                    if(listAuthType.contains(authtype)){                        if("1020004".equals(authtype)){                            String sjhm=map.get(MapFields.AUTH_ACCOUNT);                            boolean ismobile = Validation.isMobile(sjhm);                            if(!ismobile){                                errorMap.put(SJHM,sjhm);                                errorMap.put(SJHM_ERROR,SJHM_ERRORCODE);                            }                        }                        if("1020002".equals(authtype)){                            String mac=map.get(MapFields.AUTH_ACCOUNT);                            boolean ismac = Validation.isMac(mac);                            if(!ismac){                                errorMap.put(MAC,mac);                                errorMap.put(MAC_ERROR,MAC_ERRORCODE);                            }                        }                    }else{                        errorMap.put(AUTH_TYPE,"AUTHTYPE_LIST 影射里没有"+ "\t"+ "["+ authtype+"]");                        errorMap.put(AUTH_TYPE_ERROR,AUTH_TYPE_ERRORCODE);                    }                }else{                    errorMap.put(AUTH_TYPE,"AUTH_TYPE 不能为空");                    errorMap.put(AUTH_TYPE_ERROR,AUTH_TYPE_ERRORCODE);                }            }        }    }    private static final String LONGITUDE = "longitude";    private static final String LATITUDE = "latitude";    private static final String LONGITUDE_ERROR=ErrorMapFields.LONGITUDE_ERROR;    private static final String LONGITUDE_ERRORCODE=ErrorMapFields.LONGITUDE_ERRORCODE;    private static final String LATITUDE_ERROR=ErrorMapFields.LATITUDE_ERROR;    private static final String LATITUDE_ERRORCODE=ErrorMapFields.LATITUDE_ERRORCODE;    /**     * 经纬度验证  错误过滤  10012  10013     * @param map     * @param errorMap     */    public static void longlaitValidation( Map&lt;String, String&gt; map,Map&lt;String,Object&gt; errorMap){        if(map == null){            return ;        }        if(map.containsKey(LONGITUDE)&amp;&amp;map.containsKey(LATITUDE)){            String longitude=map.get(LONGITUDE);            String latitude=map.get(LATITUDE);            boolean bool1 = Validation.isLONGITUDE(longitude);            boolean bool2 = Validation.isLATITUDE(latitude);            if(!bool1){                errorMap.put(LONGITUDE,longitude);                errorMap.put(LONGITUDE_ERROR,LONGITUDE_ERRORCODE);            }            if(!bool2){                errorMap.put(LATITUDE,latitude);                errorMap.put(LATITUDE_ERROR,LATITUDE_ERRORCODE);            }        }    }    public static Boolean istime(String time,String str1,String str2,String str3,Map&lt;String,Object&gt; errorMap){        if(StringUtils.isNotBlank(time)){            boolean bool = Validation.isCAPTURETIME(time);            if(!bool){                errorMap.put(str1,time);                errorMap.put(str2,str3);                return false;            }            return true;        }        return false;    }}</code></pre><h4 id="9、配置CDH上的Agent文件-跟FolderSource等里面读取配置文件相对应">9、配置CDH上的Agent文件----跟FolderSource等里面读取配置文件相对应</h4><p><img src="/medias/Flume%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.PNG" alt="Flume配置文件"></p><p><strong>Flume配置：</strong></p><pre><code class="highlight plaintext">tier1.sources= source1tier1.channels=channel1tier1.sinks=sink1#定义source1tier1.sources.source1.type = com.hsiehchou.flume.source.FolderSource#读取文件之后睡眠时间tier1.sources.source1.sleeptime=5tier1.sources.source1.filenum=3000tier1.sources.source1.dirs =/usr/chl/data/filedir/tier1.sources.source1.successfile=/usr/chl/data/filedir_successful/tier1.sources.source1.deserializer.outputCharset=UTF-8tier1.sources.source1.channels = channel1# 定义拦截器1tier1.sources.source1.interceptors=i1tier1.sources.source1.interceptors.i1.type=com.hsiehchou.flume.interceptor.DataCleanInterceptor$Builder#定义channeltier1.channels.channel1.type = memorytier1.channels.channel1.keep-alive= 300tier1.channels.channel1.capacity = 1000000tier1.channels.channel1.transactionCapacity = 5000tier1.channels.channel1.byteCapacityBufferPercentage = 200tier1.channels.channel1.byteCapacity = 80000#定义sink1tier1.sinks.sink1.type = com.hsiehchou.flume.sink.KafkaSinktier1.sinks.sink1.kafkatopics = chl_test7tier1.sinks.sink1.channel = channel1</code></pre><p><img src="/medias/ftp%E7%9B%91%E6%8E%A7%E6%96%87%E4%BB%B6.PNG" alt="ftp监控文件"></p><p><strong>flumesource 不断监控 ftp 文件目录，通过自定义拦截器拦截，然后推送到flumechannel，然后通过flumesink下沉到kafka</strong></p><h4 id="10、flume打包到服务器执行">10、flume打包到服务器执行</h4><p><img src="/medias/flume%E6%8F%92%E4%BB%B6%E7%9B%AE%E5%BD%95.PNG" alt="flume插件目录"></p><p><strong>不能放在默认的/usr/lib/flume-ng/plugins.d下面</strong></p><p>mkdir -p /var/lib/flume-ng/plugins.d/chl/lib<br>mkdir -p /usr/chl/data/filedir/<br>mkdir -p /usr/chl/data/filedir_successful/</p><p><strong>要设置777，flume启动的时候是以flume权限启动的，所以要更改权限</strong><br><strong>chmod 777 /usr/chl/data/filedir/</strong></p><p>kafka-topics --zookeeper hadoop1:2181 --topic chl_test7 --create --replication-factor 1 --partitions 3</p><p>kafka-topics --zookeeper hadoop1:2181 --list</p><p>kafka-topics --zookeeper hadoop1:2181 --delete --topic chl_test7</p><p>kafka-console-consumer --bootstrap-server hadoop1:9092 --topic chl_test7 --from-beginning<br><img src="/medias/%E6%B6%88%E8%B4%B9kafka.PNG" alt="消费kafka"></p><h3 id="六、Kafka开发">六、Kafka开发</h3><p><strong>xz_bigdata_kafka</strong></p><h4 id="1、pom-xml">1、pom.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_kafka&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_kafka&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;poi.version&gt;3.14&lt;/poi.version&gt;        &lt;kafka.version&gt;0.9.0-kafka-2.0.2&lt;/kafka.version&gt;        &lt;mysql.connector.version&gt;5.1.46&lt;/mysql.connector.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;            &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;            &lt;version&gt;${zookeeper.version}-${cdh.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;            &lt;artifactId&gt;kafka_2.10&lt;/artifactId&gt;            &lt;version&gt;${kafka.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.poi&lt;/groupId&gt;            &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt;            &lt;version&gt;${poi.version}&lt;/version&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;            &lt;artifactId&gt;scala-library&lt;/artifactId&gt;            &lt;version&gt;${scala.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;artifactId&gt;scala-reflect&lt;/artifactId&gt;            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;            &lt;version&gt;${scala.version}&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><h4 id="2、config-KafkaConfig-java—kafka配置文件-解析器">2、config/KafkaConfig.java—kafka配置文件 解析器</h4><pre><code class="highlight plaintext">package com.hsiehchou.kafka.config;import com.hsiehchou.common.config.ConfigUtil;import kafka.producer.ProducerConfig;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.Properties;/** * kafka配置文件 解析器 */public class KafkaConfig {private static final Logger LOG = LoggerFactory.getLogger(KafkaConfig.class);private static final String DEFUALT_CONFIG_PATH = "kafka/kafka-server-config.properties";private volatile static KafkaConfig kafkaConfig = null;private ProducerConfig config;    private Properties properties;private KafkaConfig() throws IOException{try {properties = ConfigUtil.getInstance().getProperties(DEFUALT_CONFIG_PATH);} catch (Exception e) {IOException ioException = new IOException();ioException.addSuppressed(e);throw ioException;}config = new ProducerConfig(properties);}public static KafkaConfig getInstance(){if(kafkaConfig == null){synchronized (KafkaConfig.class) {if(kafkaConfig == null){try {kafkaConfig = new KafkaConfig();} catch (IOException e) {LOG.error("实例化kafkaConfig失败", e);}}}}return kafkaConfig;}    public ProducerConfig getProducerConfig(){    return config;    }        /**      * 获取当前时间的字符串   格式为：yyyy-MM-dd HH:mm:ss      * @return String     */    public static String nowStr(){    return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format( new Date() );    }}</code></pre><h4 id="3、producer-StringProducer-java—生产者">3、producer/StringProducer.java—生产者</h4><pre><code class="highlight plaintext">package com.hsiehchou.kafka.producer;import com.hsiehchou.common.thread.ThreadPoolManager;import com.hsiehchou.kafka.config.KafkaConfig;import kafka.javaapi.producer.Producer;import kafka.producer.KeyedMessage;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;public class StringProducer {    private static final Logger LOG = LoggerFactory.getLogger(StringProducer.class);    public static void main(String[] args) {        StringProducer.producer("chl_test2","{\"rksj\":\"1558177156\",\"latitude\":\"24.000000\",\"imsi\":\"000000000000000\",\"accept_message\":\"\",\"phone_mac\":\"aa-aa-aa-aa-aa-aa\",\"device_mac\":\"bb-bb-bb-bb-bb-bb\",\"message_time\":\"1789098762\",\"filename\":\"wechat_source1_1111119.txt\",\"absolute_filename\":\"/usr/chl/data/filedir_successful/2019-05-18/data/filedir/wechat_source1_1111119.txt\",\"phone\":\"18609765432\",\"device_number\":\"32109231\",\"imei\":\"000000000000000\",\"id\":\"1792d6529e2143fa85717e706403c83c\",\"collect_time\":\"1557305988\",\"send_message\":\"\",\"table\":\"wechat\",\"object_username\":\"judy\",\"longitude\":\"23.000000\",\"username\":\"andiy\"}");    }    private static int threadSize = 6;    /**     * 生产单条消息 单条推送     * @param topic     * @param recourd     */    public static void producer(String topic,String recourd){        Producer&lt;String, String&gt; producer = new Producer&lt;&gt;(KafkaConfig.getInstance().getProducerConfig());        KeyedMessage&lt;String, String&gt; keyedMessage = new KeyedMessage&lt;&gt;(topic, recourd);        producer.send(keyedMessage);        LOG.info("发送数据"+recourd+"到kafka成功");        producer.close();    }    /**     * 批量推送     * @param topic     * @param listRecourd     */    public static void producerList(String topic,List&lt;String&gt; listRecourd){        Producer&lt;String, String&gt; producer = new Producer&lt;&gt;(KafkaConfig.getInstance().getProducerConfig());        List&lt;KeyedMessage&lt;String, String&gt;&gt; listKeyedMessage= new ArrayList&lt;&gt;();        listRecourd.forEach(recourd-&gt;{            listKeyedMessage.add(new KeyedMessage&lt;&gt;(topic, recourd));        });        producer.send(listKeyedMessage);        producer.close();    }    /**     * 多线程推送     * @param topic  kafka  topic     * @param listMessage 消息     * @throws Exception     */    public void producer(String topic,List&lt;String&gt; listMessage) throws Exception{        //  int size = listMessage.size();        List&lt;List&lt;String&gt;&gt; lists = splitList(listMessage, 5);        int threadNum = lists.size();        long t1 = System.currentTimeMillis();        CountDownLatch cdl = new CountDownLatch(threadNum);        //使用线程池        ExecutorService executorService = ThreadPoolManager.getInstance().getExecutorService();        LOG.info("开启 " + threadNum + " 个线程来向  topic " + topic + " 生产数据 . ");        for (int i = 0; i &lt; threadNum; i++) {            try {                executorService.execute(new ProducerTask(topic,lists.get(i)));            } catch (Exception e) {                LOG.error("", e);            }        }        cdl.await();        long t = System.currentTimeMillis() - t1;        LOG.info(  " 一共耗时  ：" + t + "  毫秒 ... " );        executorService.shutdown();    }    /**     * 拆分消息集合,计算使用多少个线程执行运算     * @param mtList     */    public static List&lt;List&lt;String&gt;&gt; splitList(List&lt;String&gt; mtList, int splitSize){        if(mtList == null || mtList.size()==0){            return null;        }        int length = mtList.size();        // 计算可以分成多少组        int num = ( length + splitSize - 1 )/splitSize ;        List&lt;List&lt;String&gt;&gt; spiltList = new ArrayList&lt;&gt;(num);        for (int i = 0; i &lt; num; i++) {            // 开始位置            int fromIndex = i * splitSize;            // 结束位置            int toIndex = (i+1) * splitSize &lt; length ? ( i+1 ) * splitSize : length ;            spiltList.add(mtList.subList(fromIndex,toIndex)) ;        }        return  spiltList;    }    class ProducerTask implements Runnable{        private String topic;        private List&lt;String&gt; listRecourd;        public ProducerTask( String topic, List&lt;String&gt; listRecourd){            this.topic = topic;            this.listRecourd = listRecourd;        }        public void run() {            producerList(topic,listRecourd);        }    }   /* public static void producer(String topic,List&lt;KeyedMessage&lt;String,String&gt;&gt; listMessage) throws Exception{        int size = listMessage.size();        int threads = ( ( size - 1  ) / threadSize ) + 1;        long t1 = System.currentTimeMillis();        CountDownLatch cdl = new CountDownLatch(threads);        //使用线程池        ExecutorService executorService = ThreadPoolManager.getInstance().getExecutorService();        LOG.info("开启 " + threads + " 个线程来向  topic " + topic + " 生产数据 . ");      *//*  for( int i = 0 ; i &lt; threads ; i++ ){            executorService.execute( new StringProducer.ChildProducer( start , end ,  topic , id,  cdl ));        }*//*        cdl.await();        long t = System.currentTimeMillis() - t1;        LOG.info(  " 一共耗时  ：" + t + "  毫秒 ... " );        executorService.shutdown();    }    static class ChildProducer implements Runnable{        public ChildProducer( int start , int end ,  String topic , String id,  CountDownLatch cdl ){        }        public void run() {        }    }    */}</code></pre><h3 id="七、Spark—kafka2es开发">七、Spark—kafka2es开发</h3><h4 id="Cloudera查找对应的maven依赖地址">Cloudera查找对应的maven依赖地址</h4><p><a href="https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh5_maven_repo_514x.html#concept_flv_nwn_yk">https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh5_maven_repo_514x.html#concept_flv_nwn_yk</a></p><p><strong>SparkStreaming+Kafka的两种模式receiver模式和Direct模式</strong></p><h4 id="Sparkstreming-kafka-receiver模式理解">Sparkstreming + kafka receiver模式理解</h4><p><img src="/medias/kafka%E7%9A%84receiver%E6%A8%A1%E5%BC%8F.PNG" alt="kafka的receiver模式"></p><p><strong>receiver模式理解</strong><br>在SparkStreaming程序运行起来后，Executor中会有receiver tasks接收kafka推送过来的数据。数据会被持久化，默认级别为MEMORY_AND_DISK_SER_2,这个级别也可以修改。receiver task对接收过来的数据进行存储和备份，这个过程会有节点之间的数据传输。备份完成后去zookeeper中更新消费偏移量，然后向Driver中的receiver tracker汇报数据的位置。最后Driver根据数据本地化将task分发到不同节点上执行。</p><p><strong>receiver模式中存在的问题</strong><br>当Driver进程挂掉后，Driver下的Executor都会被杀掉，当更新完zookeeper消费偏移量的时候，Driver如果挂掉了，就会存在找不到数据的问题，相当于丢失数据。</p><p><strong>如何解决这个问题？</strong><br>开启WAL(write ahead log)预写日志机制,在接受过来数据备份到其他节点的时候，同时备份到HDFS上一份（我们需要将接收来的数据的持久化级别降级到MEMORY_AND_DISK），这样就能保证数据的安全性。不过，因为写HDFS比较消耗性能，要在备份完数据之后才能进行更新zookeeper以及汇报位置等，这样会增加job的执行时间，这样对于任务的执行提高了延迟度。</p><p><strong>注意</strong><br>1）开启WAL之后，接受数据级别要降级，有效率问题<br>2）开启WAL要checkpoint<br>3）开启WAL(write ahead log),往HDFS中备份一份数据</p><h4 id="Sparkstreming-kafka-receiver模式理解-2">Sparkstreming + kafka receiver模式理解</h4><p><img src="/medias/kafka%E7%9A%84direct%E6%A8%A1%E5%BC%8F.PNG" alt="kafka的direct模式"></p><ol><li>简化数据处理流程</li><li>自己定义offset存储，保证数据0丢失，但是会存在重复消费问题。（解决消费等幂问题）</li><li>不用接收数据，自己去kafka中拉取</li></ol><h4 id="1、spark下的pom-xml">1、spark下的pom.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_spark&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_spark&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;spark.version&gt;1.6.0&lt;/spark.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_es&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_redis&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_hbase&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;                    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;gson&lt;/artifactId&gt;                    &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;            &lt;version&gt;${spark.version}-${cdh.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-hive_2.10&lt;/artifactId&gt;            &lt;version&gt;${spark.version}-${cdh.version}&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;httpcore&lt;/artifactId&gt;                    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;                    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;gson&lt;/artifactId&gt;                    &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-streaming_2.10&lt;/artifactId&gt;            &lt;version&gt;${spark.version}-${cdh.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-streaming-kafka_2.10&lt;/artifactId&gt;            &lt;version&gt;${spark.version}-${cdh.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;            &lt;artifactId&gt;elasticsearch-spark-13_2.10&lt;/artifactId&gt;            &lt;version&gt;6.2.3&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;                &lt;version&gt;2.15.2&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                            &lt;goal&gt;compile&lt;/goal&gt;                            &lt;goal&gt;testCompile&lt;/goal&gt;                        &lt;/goals&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;plugin&gt;&lt;!--打包依赖的jar包--&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;outputDirectory&gt;${project.build.directory}/lib&lt;/outputDirectory&gt;                    &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt; &lt;!-- 表示是否不包含间接依赖的包 --&gt;                    &lt;stripVersion&gt;false&lt;/stripVersion&gt; &lt;!-- 去除版本信息 --&gt;                &lt;/configuration&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;id&gt;copy-dependencies&lt;/id&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;copy-dependencies&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;!-- 拷贝项目依赖包到lib/目录下 --&gt;                            &lt;outputDirectory&gt;${project.build.directory}/jars&lt;/outputDirectory&gt;                            &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt;                            &lt;stripVersion&gt;false&lt;/stripVersion&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><h4 id="2、spark中的文件结构">2、spark中的文件结构</h4><p><img src="/medias/spark%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84.PNG" alt="spark中的文件结构"></p><p><img src="/medias/%E8%AE%A9IDEA%E8%83%BD%E6%96%B0%E5%BB%BAscala.class.PNG" alt="让IDEA能新建scala.class"></p><p>点击"+"号，选择Scala SDK，点击Browse，选择本地下载的scala-sdk-2.10.4</p><h4 id="3、xz-bigdata-spark-spark-common">3、xz_bigdata_spark/spark/common</h4><p><strong>SparkContextFactory.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.commonimport org.apache.spark.streaming.{Seconds, StreamingContext}import org.apache.spark.{Accumulator, SparkContext}object SparkContextFactory {  def newSparkBatchContext(appName:String = "sparkBatch") : SparkContext = {    val sparkConf = SparkConfFactory.newSparkBatchConf(appName)    new SparkContext(sparkConf)  }  def newSparkLocalBatchContext(appName:String = "sparkLocalBatch" , threads : Int = 2) : SparkContext = {    val sparkConf = SparkConfFactory.newSparkLoalConf(appName, threads)    sparkConf.set("","")    new SparkContext(sparkConf)  }  def getAccumulator(appName:String = "sparkBatch") : Accumulator[Int] = {    val sparkConf = SparkConfFactory.newSparkBatchConf(appName)    val accumulator: Accumulator[Int] = new SparkContext(sparkConf).accumulator(0,"")    accumulator  }  /**    * 创建本地流streamingContext    * @param appName             appName    * @param batchInterval      多少秒读取一次    * @param threads            开启多少个线程    * @return    */  def newSparkLocalStreamingContext(appName:String = "sparkStreaming" ,                                    batchInterval:Long = 30L ,                                    threads : Int = 4) : StreamingContext = {    val sparkConf =  SparkConfFactory.newSparkLocalConf(appName, threads)    // sparkConf.set("spark.streaming.receiver.maxRate","10000")    sparkConf.set("spark.streaming.kafka.maxRatePerPartition","1")    new StreamingContext(sparkConf, Seconds(batchInterval))  }  /**    * 创建集群模式streamingContext    * 这里不设置线程数，在submit中指定    * @param appName    * @param batchInterval    * @return    */  def newSparkStreamingContext(appName:String = "sparkStreaming" , batchInterval:Long = 30L) : StreamingContext = {    val sparkConf = SparkConfFactory.newSparkStreamingConf(appName)    new StreamingContext(sparkConf, Seconds(batchInterval))  }  def startSparkStreaming(ssc:StreamingContext){    ssc.start()  ssc.awaitTermination()  ssc.stop()  }}</code></pre><p><strong>convert/DataConvert.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.common.convertimport java.utilimport com.hsiehchou.common.config.ConfigUtilimport org.apache.spark.Loggingimport scala.collection.JavaConversions._/**  * 数据类型转换  */object DataConvert extends Serializable with Logging {  val fieldMappingPath = "es/mapping/fieldmapping.properties"  private val typeFieldMap: util.HashMap[String, util.HashMap[String, String]] = getEsFieldtypeMap()  /**    * 将Map&lt;String,String&gt;转化为Map&lt;String,Object&gt;    */  def strMap2esObjectMap(map:util.Map[String,String]):util.Map[String,Object] ={    //获取配置文件中的数据类型    val dataType = map.get("table")    //获取配置文件中的数据类型的 字段类型    val fieldMap = typeFieldMap.get(dataType)    //获取数据类型的所有字段，配置文件里的字段    val keySet = fieldMap.keySet()    //var objectMap:util.HashMap[String,Object] = new util.HashMap[String,Object]()    var objectMap = new java.util.HashMap[String, Object]()    //数据里的字段    val set = map.keySet().iterator()    try {      //遍历真实数据的所有字段      while (set.hasNext()) {        val key = set.next()        var dataType:String = "string"        //如果在配置文件中的key包含真实数据的key        if (keySet.contains(key)) {          //则获取真实数据字段的数据类型          dataType = fieldMap.get(key)        }        dataType match {          case "long" =&gt; objectMap = BaseDataConvert.mapString2Long(map, key, objectMap)          case "string" =&gt; objectMap = BaseDataConvert.mapString2String(map, key, objectMap)          case "double" =&gt; objectMap = BaseDataConvert.mapString2Double(map, key, objectMap)          case _ =&gt; objectMap = BaseDataConvert.mapString2String(map, key, objectMap)        }      }    }catch {      case e: Exception =&gt; logInfo("转换异常", e)    }    println("转换后" + objectMap)    objectMap  }  /**    * 读取 "es/mapping/fieldmapping.properties 配置文件    * 主要作用是将 真实数据 根据配置来作数据类型转换 转换为和ES mapping结构保持一致    * @return    */  def getEsFieldtypeMap(): util.HashMap[String, util.HashMap[String, String]] = {    // ["wechat":["phone_mac":"string","latitude":"long"]]    //定义返回Map    val mapMap = new util.HashMap[String, util.HashMap[String, String]]    val properties = ConfigUtil.getInstance().getProperties(fieldMappingPath)    val tables = properties.get("tables").toString.split(",")    val tableFields = properties.keySet()    tables.foreach(table =&gt; {      val map = new util.HashMap[String, String]()      tableFields.foreach(tableField =&gt; {        if (tableField.toString.startsWith(table)) {          val key = tableField.toString.split("\\.")(1)          val value = properties.get(tableField).toString          map.put(key, value)        }      })      mapMap.put(table, map)    })    mapMap  }}</code></pre><p><img src="/medias/scala%E4%B8%AD%E7%9A%84scala%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84.PNG" alt="scala中的scala文件结构"></p><h4 id="4、org-apache-spark-streaming-kafka-KafkaManager-scala">4、org/apache/spark/streaming/kafka/KafkaManager.scala</h4><p>构建Kafka时用到，KafkaCluster在org.apache.spark.streaming.kafka下面，而且只能在spark里面使用，这时候我们就可以新建相同的目录结构，就可以引用了，如下图所示：</p><p><img src="/medias/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%96%B0%E5%BB%BAorg.apache.spark.streaming.kafka.PNG" alt="为什么要新建org.apache.spark.streaming.kafka"></p><pre><code class="highlight plaintext">package org.apache.spark.streaming.kafkaimport com.alibaba.fastjson.TypeReferenceimport kafka.common.TopicAndPartitionimport kafka.message.MessageAndMetadataimport kafka.serializer.{Decoder, StringDecoder}import org.apache.spark.Loggingimport org.apache.spark.rdd.RDDimport org.apache.spark.streaming.StreamingContextimport org.apache.spark.streaming.dstream.{DStream, InputDStream}import scala.reflect.ClassTag/**  * 包名说明 ：KafkaCluster是私有类，只能在spark包中使用，  *           所以包名保持和 KafkaCluster 一致才能调用  * @param kafkaParams  * @param autoUpdateoffset  */class KafkaManager(val kafkaParams:Map[String, String],                   val autoUpdateoffset:Boolean =true) extends Serializable with Logging {  //构造一个KafkaCluster  @transient  private var cluster = new KafkaCluster(kafkaParams)  //定义一个单例  def kc(): KafkaCluster = {    if (cluster == null) {      cluster = new KafkaCluster(kafkaParams)    }    cluster  }  /**    * 泛型流读取器    * @param ssc    * @param topics kafka topics,多个topic按","分割    * @tparam K  泛型 K    * @tparam V  泛型 V    * @tparam KD scala泛型 KD &lt;: Decoder[K] 说明KD 的类型必须是Decoder[K]的子类型  上下界    * @tparam VD scala泛型 VD &lt;: Decoder[V] 说明VD 的类型必须是Decoder[V]的子类型  上下界    * @return    */  def createDirectStream[K: ClassTag, V: ClassTag,  KD &lt;: Decoder[K] : ClassTag,  VD &lt;: Decoder[V] : ClassTag](ssc: StreamingContext, topics: Set[String]): InputDStream[(K, V)] = {    //获取消费者组ID    //val groupId = "test"    val groupId = kafkaParams.get("group.id").getOrElse("default")    // 在zookeeper上读取offsets前先根据实际情况更新offsets    setOrUpdateOffsets(topics, groupId)    //把所有的offsets处理完成，就可以从zookeeper上读取offset开始消费message    val messages = {      //获取kafka分区信息  为了打印信息      val partitionsE = kc.getPartitions(topics)      require(partitionsE.isRight, s"获取 kafka topic ${topics}`s partition 失败。")      val partitions = partitionsE.right.get      println("打印分区信息")      partitions.foreach(println(_))      //获取分区的offset      val consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)      require(consumerOffsetsE.isRight, s"获取 kafka topic ${topics}`s consumer offsets 失败。")      val consumerOffsets = consumerOffsetsE.right.get      println("打印消费者分区偏移信息")      consumerOffsets.foreach(println(_))      //读取数据      KafkaUtils.createDirectStream[K, V, KD, VD, (K, V)](        ssc, kafkaParams, consumerOffsets, (mmd: MessageAndMetadata[K, V]) =&gt; (mmd.key, mmd.message))    }    if (autoUpdateoffset) {      //更新offset      messages.foreachRDD(rdd =&gt; {        logInfo("RDD 消费成功，开始更新zookeeper上的偏移")        updateZKOffsets(rdd)      })    }    messages  }  /**    * 创建数据流前，根据实际消费情况更新消费offsets    * @param topics    * @param groupId    */  private def setOrUpdateOffsets(topics: Set[String], groupId: String): Unit = {    topics.foreach(topic =&gt; {      //先获取Kafka offset信息  Kafka partions的节点信息      //获取kafka本身的偏移量, Either类型可以认为就是封装了2种信息      val partitionsE = kc.getPartitions(Set(topic))      logInfo(partitionsE + "")      //require(partitionsE.isRight, "获取partition失败")      require(partitionsE.isRight, s"获取 kafka topic ${topic}`s partition 失败。")      println("partitionsE=" + partitionsE)      val partitions = partitionsE.right.get      println("打印分区信息")      partitions.foreach(println(_))      //获取kafka partions最早的offsets      val earliestLeader = kc.getEarliestLeaderOffsets(partitions)      require(earliestLeader.isRight, "获取earliestLeader失败")      val earliestLeaderOffsets = earliestLeader.right.get      println("kafka最早的消息偏移量")      earliestLeaderOffsets.foreach(println(_))      //获取kafka最末尾的offsets      val latestLeader = kc.getLatestLeaderOffsets(partitions)      //require(latestLeader.isRight, "获取latestLeader失败")      val latestLeaderOffsets = latestLeader.right.get      println("kafka最末尾的消息偏移量")      latestLeaderOffsets.foreach(println(_))      //获取消费者的offsets      val consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)      //判断消费者是否消费过,消费者offset存在      if (consumerOffsetsE.isRight) {        /**          * 如果zk上保存的offsets已经过时了，即kafka的定时清理策略已经将包含该offsets的文件删除。          * 针对这种情况，只要判断一下zk上的consumerOffsets和earliestLeaderOffsets的大小，          * 如果consumerOffsets比earliestLeaderOffsets还小的话，说明consumerOffsets已过时,          * 这时把consumerOffsets更新为earliestLeaderOffsets          */        //如果消费过，直接取过来的kafka消费，，earliestLeader 存在        if (earliestLeader.isRight) {          //获取到最早的offset  也就是最小的offset          require(earliestLeader.isRight, "获取earliestLeader失败")          val earliestLeaderOffsets = earliestLeader.right.get          //获取消费者组的offset          val consumerOffsets = consumerOffsetsE.right.get          // 将 consumerOffsets 和 earliestLeaderOffsets 的offsets 做比较          // 可能只是存在部分分区consumerOffsets过时，所以只更新过时分区的consumerOffsets为earliestLeaderOffsets          var offsets: Map[TopicAndPartition, Long] = Map()          consumerOffsets.foreach({ case (tp, n) =&gt;            val earliestLeaderOffset = earliestLeaderOffsets(tp).offset            //如果消費者的偏移小于 kafka中最早的offset,那么，將最早的offset更新到zk            if (n &lt; earliestLeaderOffset) {              logWarning("consumer group:" + groupId + ",topic:" + tp.topic + ",partition:" + tp.partition +                " offsets已经过时，更新为" + earliestLeaderOffset)              offsets += (tp -&gt; earliestLeaderOffset)            }          })          //设置offsets          setOffsets(groupId, offsets)        }      } else {        //如果没有消费过，那么就去取kafka获取earliestLeader写到zk中        // 消费者还没有消费过  也就是zookeeper中还没有消费者的信息        if (earliestLeader.isLeft)          logError(s"${topic} hasConsumed but earliestLeaderOffsets is null。")        //看是从头消费还是从末开始消费  smallest表示从头开始消费        val reset = kafkaParams.get("auto.offset.reset").map(_.toLowerCase).getOrElse("smallest")        //往zk中去写，构建消费者 偏移        var leaderOffsets: Map[TopicAndPartition, Long] = Map.empty        //从头消费        if (reset.equals("smallest")) {          //分为 存在 和 不存在 最早的消费记录 两种情况          //如果kafka 最小偏移存在，则将消费者偏移设置为和kafka偏移一样          if (earliestLeader.isRight) {            leaderOffsets = earliestLeader.right.get.map {              case (tp, offset) =&gt; (tp, offset.offset)            }          } else {            //如果不存在，则从新构建偏移全部为0 offsets            leaderOffsets = partitions.map(tp =&gt; (tp, 0L)).toMap          }        } else {          //直接获取最新的offset          leaderOffsets = kc.getLatestLeaderOffsets(partitions).right.get.map {            case (tp, offset) =&gt; (tp, offset.offset)          }        }        //设置offsets 写到zk中        setOffsets(groupId, leaderOffsets)      }    })  }  /**    * 设置消费者组的offsets    * @param groupId    * @param offsets    */  private def setOffsets(groupId: String, offsets: Map[TopicAndPartition, Long]): Unit = {    if (offsets.nonEmpty) {      //更新offset      val o = kc.setConsumerOffsets(groupId, offsets)      logInfo(s"更新zookeeper中消费组为：${groupId} 的 topic offset信息为： ${offsets}")      if (o.isLeft) {        logError(s"Error updating the offset to Kafka cluster: ${o.left.get}")      }    }  }  /**    * 通过spark的RDD 更新zookeeper上的消费offsets    * @param rdd    */  def updateZKOffsets[K: ClassTag, V: ClassTag](rdd: RDD[(K, V)]) : Unit = {    //获取消费者组    val groupId = kafkaParams.get("group.id").getOrElse("default")    //spark使用kafka低阶API进行消费的时候,每个partion的offset是保存在 spark的RDD中，所以这里可以直接在    //RDD的 HasOffsetRanges 中获取倒offsets信息。因为这个信息spark不会把则个信息存储到zookeeper中，所以    //我们需要自己实现将这部分offsets信息存储到zookeeper中    val offsetsList = rdd.asInstanceOf[HasOffsetRanges].offsetRanges    //打印出spark中保存的offsets信息    offsetsList.foreach(x=&gt;{      println("获取spark 中的偏移信息"+x)    })    for (offsets &lt;- offsetsList) {      //根据topic和partition 构建topicAndPartition      val topicAndPartition = TopicAndPartition(offsets.topic, offsets.partition)      logInfo("将SPARK中的 偏移信息 存到zookeeper中")      //将消费者组的offsets更新到zookeeper中      setOffsets(groupId, Map((topicAndPartition, offsets.untilOffset)))    }  }  //(null,{"rksj":"1558178497","latitude":"24.000000","imsi":"000000000000000"})  //读取kafka流，并将json数据转为map  def createJsonToJMapObjectDirectStreamWithOffset(ssc:StreamingContext, topicsSet:Set[String]): DStream[java.util.Map[String,Object]] = {    //一个转换器    val converter = {json:String =&gt;      println(json)      var res : java.util.Map[String,Object] = null      try {        //JSON转map的操作        res = com.alibaba.fastjson.JSON.parseObject(json,          new TypeReference[java.util.Map[String, Object]]() {})      } catch {        case e: Exception =&gt; logError(s"解析topic ${topicsSet}, 的记录 ${json} 失败。", e)      }      res    }    createDirectStreamWithOffset(ssc, topicsSet, converter).filter(_ != null)  }  /**    * 根据converter创建流数据    * @param ssc    * @param topicsSet    * @param converter    * @tparam T    * @return    */  def createDirectStreamWithOffset[T:ClassTag](ssc:StreamingContext,                                               topicsSet:Set[String], converter:String =&gt; T): DStream[T] = {    createDirectStream[String, String, StringDecoder, StringDecoder](ssc, topicsSet)      .map(pair =&gt;converter(pair._2))  }  def createJsonToJMapDirectStreamWithOffset(ssc:StreamingContext,                                             topicsSet:Set[String]): DStream[java.util.Map[String,String]] = {    val converter = {json:String =&gt;      var res : java.util.Map[String,String] = null      try {        res = com.alibaba.fastjson.JSON.parseObject(json, new TypeReference[java.util.Map[String, String]]() {})      } catch {        case e: Exception =&gt; logError(s"解析topic ${topicsSet}, 的记录 ${json} 失败。", e)      }      res    }    createDirectStreamWithOffset(ssc, topicsSet, converter).filter(_ != null)  }  /*    /**      * @param ssc      * @param topicsSet      * @return      */    def createJsonToJavaBeanDirectStreamWithOffset(ssc:StreamingContext ,                                                   topicsSet:Set[String]): DStream[Object] = {      val converter = {json:String =&gt;        var res : Object = null        try {          res = com.alibaba.fastjson.JSON.parseObject(json, new TypeReference[Object]() {})        } catch {          case e: Exception =&gt; logError(s"解析topic ${topicsSet}, 的记录 ${json} 失败。", e)        }        res      }      createDirectStreamWithOffset(ssc, topicsSet, converter).filter(_ != null)    }  */  /*    def createStringDirectStreamWithOffset(ssc:StreamingContext ,                                           topicsSet:Set[String]): DStream[String] = {      val converter = {json:String =&gt;        json      }      createDirectStreamWithOffset(ssc, topicsSet, converter).filter(_ != null)    }  */  /**    * 读取JSON的流 并将JSON流 转为MAP流  并且这个流支持RDD向zookeeper中记录消费信息    * @param ssc   spark ssc    * @param topicsSet topic 集合 支持从多个kafka topic同时读取数据    * @return  DStream[java.util.Map[String,String    */  def createJsonToJMapStringDirectStreamWithOffset(ssc:StreamingContext , topicsSet:Set[String]): DStream[java.util.Map[String,String]] = {    val converter = {json:String =&gt;      var res : java.util.Map[String,String] = null      try {        res = com.alibaba.fastjson.JSON.parseObject(json, new TypeReference[java.util.Map[String, String]]() {})      } catch {        case e: Exception =&gt; logError(s"解析topic ${topicsSet}, 的记录 ${json} 失败。", e)      }      res    }    createDirectStreamWithOffset(ssc, topicsSet, converter).filter(_ != null)  }  /**    * 读取JSON的流 并将JSON流 转为MAP流  并且这个流支持RDD向zookeeper中记录消费信息    * @param ssc   spark ssc    * @param topicsSet topic 集合 支持从多个kafka topic同时读取数据    * @return  DStream[java.util.Map[String,String    */  def createJsonToJMapStringDirectStreamWithoutOffset(ssc:StreamingContext , topicsSet:Set[String]): DStream[java.util.Map[String,String]] = {    val converter = {json:String =&gt;      var res : java.util.Map[String,String] = null      try {        res = com.alibaba.fastjson.JSON.parseObject(json, new TypeReference[java.util.Map[String, String]]() {})      } catch {        case e: Exception =&gt; logError(s"解析topic ${topicsSet}, 的记录 ${json} 失败。", e)      }      res    }    createDirectStreamWithOffset(ssc, topicsSet, converter).filter(_ != null)  }}object KafkaManager extends Logging{  def apply(broker:String, groupId:String = "default",            numFetcher:Int = 1, offset:String = "smallest",            autoUpdateoffset:Boolean = true): KafkaManager ={    new KafkaManager(      createKafkaParam(broker, groupId, numFetcher, offset),      autoUpdateoffset)  }  def createKafkaParam(broker:String, groupId:String = "default",                       numFetcher:Int = 1, offset:String = "smallest"): Map[String, String] ={    //创建 stream 时使用的 topic 名字集合    Map[String, String](      "metadata.broker.list" -&gt; broker,      "auto.offset.reset" -&gt; offset,      "group.id" -&gt; groupId,      "num.consumer.fetchers" -&gt; numFetcher.toString)  }}</code></pre><h4 id="5、resources-log4j-properties">5、resources/log4j.properties</h4><pre><code class="highlight plaintext">### 设置###log4j.rootLogger = error,stdout,D,E### 输出信息到控制抬 ###log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = [%-5p] %d{yyyy-MM-dd HH:mm:ss,SSS} method:%l%n%m%n### 输出DEBUG 级别以上的日志到=E://logs/error.log ###log4j.appender.D = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.D.File = E://logs/log.loglog4j.appender.D.Append = truelog4j.appender.D.Threshold = stdout log4j.appender.D.layout = org.apache.log4j.PatternLayoutlog4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%n###输出ERROR 级别以上的日志到=E://logs/error.log ###log4j.appender.E = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.E.File =E://logs/error.log log4j.appender.E.Append = truelog4j.appender.E.Threshold = ERROR log4j.appender.E.layout = org.apache.log4j.PatternLayoutlog4j.appender.E.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%n</code></pre><h4 id="6、xz-bigdata-spark-spark-streaming-kafka">6、xz_bigdata_spark/spark/streaming/kafka</h4><p><strong>Spark_Es_ConfigUtil.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafkaimport org.apache.spark.Loggingobject Spark_Es_ConfigUtil extends Serializable with Logging{ // val ES_NODES = "es.cluster.nodes" // val ES_PORT = "es.cluster.http.port" // val ES_CLUSTERNAME = "es.cluster.name"  val ES_NODES = "es.nodes"  val ES_PORT = "es.port"  val ES_CLUSTERNAME = "es.clustername"  def getEsParam(id_field : String): Map[String,String] ={    Map[String ,String]("es.mapping.id" -&gt; id_field,      ES_NODES -&gt; "hadoop1,hadoop2,hadoop3",      //ES_NODES -&gt; "hadoop1",      ES_PORT -&gt; "9200",      ES_CLUSTERNAME -&gt; "xz_es",      "es.batch.size.entries"-&gt;"6000",      /*   "es.nodes.wan.only"-&gt;"true",*/      "es.nodes.discovery"-&gt;"true",      "es.batch.size.bytes"-&gt;"300000000",      "es.batch.write.refresh"-&gt;"false"    )  }}</code></pre><p><strong>Spark_Kafka_ConfigUtil.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafkaimport org.apache.spark.Loggingobject Spark_Kafka_ConfigUtil extends Serializable with Logging{  def getKafkaParam(brokerList:String,groupId : String): Map[String,String]={    val kafkaParam=Map[String,String](      "metadata.broker.list" -&gt; brokerList,      "auto.offset.reset" -&gt; "smallest",      "group.id" -&gt; groupId,      "refresh.leader.backoff.ms" -&gt; "1000",      "num.consumer.fetchers" -&gt; "8")    kafkaParam  }}</code></pre><h4 id="7、kafka2es">7、kafka2es</h4><p><strong>Kafka2esJob.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.kafka2esimport com.hsiehchou.es.admin.AdminUtilimport com.hsiehchou.es.client.ESClientUtilsimport com.hsiehchou.spark.common.convert.DataConvertimport com.hsiehchou.spark.streaming.kafka.Spark_Es_ConfigUtilimport org.apache.spark.Loggingimport org.apache.spark.rdd.RDDimport org.apache.spark.streaming.dstream.DStreamimport org.elasticsearch.client.transport.TransportClientimport org.elasticsearch.spark.rdd.EsSparkobject Kafka2esJob extends Serializable with Logging {  /**    * 按日期分组写入ES    * @param dataType    * @param typeDS    */  def insertData2EsBydate(dataType:String,typeDS:DStream[java.util.Map[String,String]]): Unit ={    //通过 dataType + 日期来动态创建 分索引。 日期格式为 yyyyMMdd    //主要就是时间混杂  通过时间分组就行了 groupby       filter    //index前缀  通过对日期进行过滤 避免shuffle操作    val index_prefix = dataType    val client: TransportClient = ESClientUtils.getClient    typeDS.foreachRDD(rdd=&gt;{      //如果时少量数据可以这样处理      //rdd.groupBy()      //吧所有的日期拿到      val days = getDays(dataType,rdd)      //我们使用日期对数据进行过滤  par时scala并发集合      days.par.foreach(day=&gt;{        //通过前缀+日期组成一个动态的索引   比例  qq + "_" + "20190508"        val index = index_prefix + "_" + day        //判断索引是否存在        val bool = AdminUtil.indexExists(client,index)        if(!bool){          //如果不存在，创建          val mappingPath = s"es/mapping/${index_prefix}.json"          AdminUtil.buildIndexAndTypes(index, index, mappingPath, 5, 1)        }        //构建RDD，数据类型 某一天的数据RDD        //返回一个map[String,obJECT] 的RDD   //就是一个单一类型  单一天数的RDD        val tableRDD = rdd.filter(map=&gt;{          day.equals(map.get("index_date"))        }).map(x=&gt;{          //将map[String,String] 转为map[String,obJECT]          DataConvert.strMap2esObjectMap(x)        })        EsSpark.saveToEs(tableRDD,index+ "/"+index,Spark_Es_ConfigUtil.getEsParam("id"))      })    })    //日期为后  }  /**    * 获取日期的集合    * @param dataType    * @param rdd    * @return    */  def getDays(dataType:String,rdd:RDD[java.util.Map[String,String]]): Array[String] ={    //对日期去重，然后集中到driver    return  rdd.map(x=&gt;{x.get("index_date")}).distinct().collect()  }  /**    * 将RDD转换之后写入ES    * @param dataType    * @param typeRDD    */  def insertData2Es(dataType:String,typeRDD:RDD[java.util.Map[String,String]]): Unit = {    val index = dataType    val esRDD =  typeRDD.map(x=&gt;{      DataConvert.strMap2esObjectMap(x)    })    EsSpark.saveToEs(esRDD,index+ "/"+index,Spark_Es_ConfigUtil.getEsParam("id"))    println("写入ES" + esRDD.count() + "条数据成功")  }  /**    * 将RDD转换后写入ES    * @param dataType    * @param typeDS    */  def insertData2Es(dataType:String, typeDS:DStream[java.util.Map[String, String]]): Unit = {    val index = dataType    typeDS.foreachRDD(rdd=&gt;{      val esRDD = rdd.map(x=&gt;{        DataConvert.strMap2esObjectMap(x)      })      EsSpark.saveToEs(rdd, dataType+"/"+dataType, Spark_Es_ConfigUtil.getEsParam("id"))      println("写入ES" + esRDD.count() + "条数据成功")    })  }}</code></pre><p><strong>Kafka2esStreaming.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.kafka2esimport java.utilimport java.util.Propertiesimport com.hsiehchou.common.config.ConfigUtilimport com.hsiehchou.common.project.datatype.DataTypePropertiesimport com.hsiehchou.common.time.TimeTranstationUtilsimport com.hsiehchou.spark.common.SparkContextFactoryimport com.hsiehchou.spark.streaming.kafka.Spark_Kafka_ConfigUtilimport org.apache.commons.lang3.StringUtilsimport org.apache.spark.Loggingimport org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.dstream.DStreamimport org.apache.spark.streaming.kafka.KafkaManagerimport scala.collection.JavaConversions._object Kafka2esStreaming extends Serializable with Logging {  //获取数据类型  private val dataTypes: util.Set[String] = DataTypeProperties.dataTypeMap.keySet()  val kafkaConfig: Properties = ConfigUtil.getInstance().getProperties("kafka/kafka-server-config.properties")  def main(args: Array[String]): Unit = {    //val topics = "chl_test7".split(",")    val topics = args(1).split(",")        //   val ssc = SparkConfFactory.newSparkLocalStreamingContext("XZ_kafka2es", java.lang.Long.valueOf(10),1)    val ssc = SparkContextFactory.newSparkStreamingContext("Kafka2esStreaming", java.lang.Long.valueOf(10))    //构建kafkaManager    val kafkaManager = new KafkaManager(      Spark_Kafka_ConfigUtil.getKafkaParam(kafkaConfig.getProperty("metadata.broker.list"), "XZ3")    )    //使用kafkaManager创建DStreaming流    val kafkaDS = kafkaManager.createJsonToJMapStringDirectStreamWithOffset(ssc, topics.toSet)      //添加一个日期分组字段      //如果数据其他的转换，可以先在这里进行统一转换      .map(map=&gt;{      map.put("index_date",TimeTranstationUtils.Date2yyyyMMddHHmmss(java.lang.Long.valueOf(map.get("collect_time")+"000")))      map    }).persist(StorageLevel.MEMORY_AND_DISK)    //使用par并发集合可以是任务并发执行。在资源充足的情况下    dataTypes.foreach(datatype=&gt;{      //过滤出单个类别的数据种类      val tableDS = kafkaDS.filter(x=&gt;{datatype.equals(x.get("table"))})      Kafka2esJob.insertData2Es(datatype,tableDS)    })    ssc.start()    ssc.awaitTermination()  }  /**    * 启动参数检查    * @param args    */  def sparkParamCheck(args: Array[String]): Unit ={    if (args.length == 4) {      if (StringUtils.isBlank(args(1))) {        logInfo("kafka集群地址不能为空")        logInfo("kafka集群地址格式为     主机1名：9092,主机2名：9092,主机3名：9092...")        logInfo("格式为     主机1名：9092,主机2名：9092,主机3名：9092...")        System.exit(-1)      }      if (StringUtils.isBlank(args(2))) {        logInfo("kafka topic1不能为空")        System.exit(-1)      }      if (StringUtils.isBlank(args(3))) {        logInfo("kafka topic2不能为空")        System.exit(-1)      }    }else{      logError("启动参数个数错误")    }  }  def startJob(ds:DStream[String]): Unit ={  }}</code></pre><p><strong>java/com/hsiehchou/spark/common/convert/BaseDataConvert.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.common.convert;import org.apache.commons.lang.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.HashMap;import java.util.Map;public class BaseDataConvert {    private static final Logger LOG = LoggerFactory.getLogger(BaseDataConvert.class);    public static HashMap&lt;String,Object&gt; mapString2Long(Map&lt;String,String&gt; map, String key, HashMap&lt;String,Object&gt; objectMap) {        String logouttime = map.get(key);        if (StringUtils.isNotBlank(logouttime)) {            objectMap.put(key, Long.valueOf(logouttime));        } else {            objectMap.put(key, 0L);        }        return objectMap;    }    public static HashMap&lt;String,Object&gt; mapString2Double(Map&lt;String,String&gt; map, String key, HashMap&lt;String,Object&gt; objectMap) {        String logouttime = map.get(key);        if (StringUtils.isNotBlank(logouttime)) {            objectMap.put(key, Double.valueOf(logouttime));        } else {            objectMap.put(key, 0.000000);        }        return objectMap;    }    public static HashMap&lt;String,Object&gt; mapString2String(Map&lt;String,String&gt; map, String key, HashMap&lt;String,Object&gt; objectMap) {        String logouttime = map.get(key);        if (StringUtils.isNotBlank(logouttime)) {            objectMap.put(key, logouttime);        } else {            objectMap.put(key, "");        }        return objectMap;    }}</code></pre><h4 id="8、ES动态索引创建">8、ES动态索引创建</h4><pre><code class="highlight plaintext">/**    * 按日期分组写入ES    * @param dataType    * @param typeDS    */  def insertData2EsBydate(dataType:String,typeDS:DStream[java.util.Map[String,String]]): Unit ={    //通过 dataType + 日期来动态创建 分索引。 日期格式为 yyyyMMdd    //主要就是时间混杂  通过时间分组就行了 groupby       filter    //index前缀  通过对日期进行过滤 避免shuffle操作    val index_prefix = dataType    val client: TransportClient = ESClientUtils.getClient    typeDS.foreachRDD(rdd=&gt;{      //如果时少量数据可以这样处理      //rdd.groupBy()      //吧所有的日期拿到      val days = getDays(dataType,rdd)      //我们使用日期对数据进行过滤  par时scala并发集合      days.par.foreach(day=&gt;{        //通过前缀+日期组成一个动态的索引   比例  qq + "_" + "20190508"        val index = index_prefix + "_" + day        //判断索引是否存在        val bool = AdminUtil.indexExists(client,index)        if(!bool){          //如果不存在，创建          val mappingPath = s"es/mapping/${index_prefix}.json"          AdminUtil.buildIndexAndTypes(index, index, mappingPath, 5, 1)        }        //构建RDD，数据类型 某一天的数据RDD        //返回一个map[String,obJECT] 的RDD   //就是一个单一类型  单一天数的RDD        val tableRDD = rdd.filter(map=&gt;{          day.equals(map.get("index_date"))        }).map(x=&gt;{          //将map[String,String] 转为map[String,obJECT]          DataConvert.strMap2esObjectMap(x)        })        EsSpark.saveToEs(tableRDD,index+ "/"+index,Spark_Es_ConfigUtil.getEsParam("id"))      })    })    //日期为后  }</code></pre><p><strong>xz_bigdata_es下一节展示代码</strong><br><img src="/medias/%E5%85%A5ES%E4%BD%BF%E7%94%A8%E5%8A%A8%E6%80%81%E7%B4%A2%E5%BC%95.PNG" alt="入ES使用动态索引"></p><h4 id="9、CDH的java配置和Elasticsearch的配置">9、CDH的java配置和Elasticsearch的配置</h4><p><strong>cdh的jdk设置</strong><br>/usr/local/jdk1.8</p><p><strong>kafka配置</strong></p><p>Default Number of Partitions：num.partitions 8</p><p>Offset Commit Topic Number of Partitions：180天</p><p>Log Compaction Delete Record Retention Time：<a href="http://log.cleaner.delete.retention.ms">log.cleaner.delete.retention.ms</a> 30天</p><p>Data Log Roll Hours：log.retention.hours 30天  log.roll.hours 30天</p><p>Java Heap Size of Broker：broker_max_heap_size  1吉字节</p><p><strong>YARN</strong><br>容器内存 5g 5g 1g 10g</p><p><strong>这里的CDH安装另一篇文章介绍</strong></p><p><strong>前提安装好elasticsearch</strong></p><p>mkdir /opt/software/elasticsearch/data/</p><p>mkdir /opt/software/elasticsearch/logs/</p><p>chmod 777 /opt/software/elasticsearch/data/</p><p>useradd elasticsearch<br>passwd elasticsearch</p><p>chown -R elasticsearch elasticsearch/</p><p><strong>vim /etc/security/limits.conf</strong><br>添加如下内容:<br><code>*</code> <strong>soft nofile 65536</strong><br><code>*</code> <strong>hard nofile 131072</strong><br><code>*</code> <strong>soft nproc 2048</strong><br><code>*</code> <strong>hard nproc 4096</strong></p><p>进入limits.d目录下修改配置文件<br><strong>vim /etc/security/limits.d/90-nproc.conf</strong></p><p>修改如下内容：<br><strong>soft nproc 4096（修改为此参数，6版本的默认就是4096）</strong></p><p>修改配置sysctl.conf<br><strong>vim /etc/sysctl.conf</strong></p><p>添加下面配置：<br><strong>vm.max_map_count=655360</strong></p><p>并执行命令：<br><strong>sysctl -p</strong></p><p><strong>hadoop1的conf配置</strong><br><strong>elasticsearch.yml</strong></p><pre><code class="highlight plaintext"># ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.#       Before you set out to tweak and tune the configuration, make sure you#       understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:##cluster.name: my-applicationcluster.name: xz_es## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:##node.name: node-1#node.name: node-1node.master: truenode.data: true# Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##path.data: /path/to/datapath.data: /opt/software/elasticsearch/data## Path to log files:##path.logs: /path/to/logspath.logs: /opt/software/elasticsearch/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: truebootstrap.memory_lock: falsebootstrap.system_call_filter: false## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):##network.host: 192.168.0.1network.host: 192.168.116.201## Set a custom port for HTTP:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is ["127.0.0.1", "[::1]"]##discovery.zen.ping.unicast.hosts: ["host1", "host2"]discovery.zen.ping.unicast.hosts: ["hadoop1", "hadoop2", "hadoop3"]## Prevent the "split brain" by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):##discovery.zen.minimum_master_nodes: ## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true</code></pre><p><strong>jvm.options</strong><br>修改下<br>-Xms64m<br>-Xmx64m</p><p><strong>hadoop2的conf配置</strong><br><strong>elasticsearch.yml</strong></p><pre><code class="highlight plaintext"># ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.#       Before you set out to tweak and tune the configuration, make sure you#       understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:##cluster.name: my-applicationcluster.name: xz_es## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:##node.name: node-1node.name: node-2node.master: falsenode.data: true## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##path.data: /path/to/datapath.data: /opt/software/elasticsearch/data## Path to log files:##path.logs: /path/to/logspath.logs: /opt/software/elasticsearch/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: truebootstrap.memory_lock: falsebootstrap.system_call_filter: false## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):##network.host: 192.168.0.1network.host: 192.168.116.202## Set a custom port for HTTP:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is ["127.0.0.1", "[::1]"]##discovery.zen.ping.unicast.hosts: ["host1", "host2"]discovery.zen.ping.unicast.hosts: ["hadoop1", "hadoop2", "hadoop3"]## Prevent the "split brain" by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):##discovery.zen.minimum_master_nodes: ## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true</code></pre><p><strong>jvm.options</strong><br>修改下<br>-Xms64m<br>-Xmx64m</p><p><strong>hadoop3的conf配置</strong><br><strong>elasticsearch.yml</strong></p><pre><code class="highlight plaintext"># ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.#       Before you set out to tweak and tune the configuration, make sure you#       understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:##cluster.name: my-applicationcluster.name: xz_es## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:##node.name: node-1node.name: node-3node.master: falsenode.data: true## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):##path.data: /path/to/datapath.data: /opt/software/elasticsearch/data## Path to log files:##path.logs: /path/to/logspath.logs: /opt/software/elasticsearch/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: truebootstrap.memory_lock: falsebootstrap.system_call_filter: false## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):##network.host: 192.168.0.1network.host: 192.168.116.203## Set a custom port for HTTP:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is ["127.0.0.1", "[::1]"]##discovery.zen.ping.unicast.hosts: ["host1", "host2"]discovery.zen.ping.unicast.hosts: ["hadoop1", "hadoop2", "hadoop3"]## Prevent the "split brain" by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):##discovery.zen.minimum_master_nodes: ## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true</code></pre><p><strong>jvm.options</strong><br>修改下<br>-Xms64m<br>-Xmx64m</p><p><strong>Kibana的conf配置</strong></p><p><strong>kibana.yml</strong></p><pre><code class="highlight plaintext"># Kibana is served by a back end server. This setting specifies the port to use.server.port: 5601# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.# The default is 'localhost', which usually means remote machines will not be able to connect.# To allow connections from remote users, set this parameter to a non-loopback address.#server.host: "localhost"server.host: "192.168.116.202"# Enables you to specify a path to mount Kibana at if you are running behind a proxy. This only affects# the URLs generated by Kibana, your proxy is expected to remove the basePath value before forwarding requests# to Kibana. This setting cannot end in a slash.#server.basePath: ""# The maximum payload size in bytes for incoming server requests.#server.maxPayloadBytes: 1048576# The Kibana server's name.  This is used for display purposes.#server.name: "your-hostname"# The URL of the Elasticsearch instance to use for all your queries.#elasticsearch.url: "http://localhost:9200"elasticsearch.url: "http://192.168.116.201:9200"</code></pre><p><strong>运行Elasticsearch</strong><br>cd /opt/software/elasticsearch<br>su elasticsearch<br>bin/elasticsearch &amp;</p><p><strong>运行Kibana</strong><br>cd /opt/software/kibana/<br>bin/kibana &amp;</p><h4 id="10、kafka2es打包到集群执行">10、kafka2es打包到集群执行</h4><p><strong>打包</strong><br>使用maven工具点击install</p><p><strong>放入集群</strong><br>将打包完成的jar文件和xz_bigdata_spark-1.0-SNAPSHOT.jar 一起放入/usr/chl/spark7/目录下面</p><p><strong>执行</strong><br>spark-submit <code>--</code>master yarn-cluster <code>--</code>num-executors 1 <code>--</code>driver-memory 500m <code>--</code>executor-memory 1g <code>--</code>executor-cores 1 <code>--</code>jars $(echo /usr/chl/spark7/jars/*.jar | tr ’ ’ ‘,’) <code>--</code>class com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar chl_test7 chl_test7</p><p>spark-submit<br><code>--</code>master yarn-cluster    //集群启动<br><code>--</code>num-executors 1        //分配多少个进程<br><code>--</code>driver-memory 500m  //driver内存<br><code>--</code>executor-memory 1g //进程内存<br><code>--</code>executor-cores 1       //开多少个核，线程<br><code>--</code>jars $(echo /usr/chl/spark8/jars/*.jar | tr ’ ’ ‘,’) //加载jar<br><code>--</code>class com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</p><h4 id="11、运行截图">11、运行截图</h4><p><img src="/medias/kafka2esstreaming%E6%88%AA%E5%9B%BE.PNG" alt="kafka2esstreaming截图"></p><p><img src="/medias/Elasticsearch%E5%90%84%E4%B8%AA%E8%8A%82%E7%82%B9%E7%8A%B6%E5%86%B5.PNG" alt="Elasticsearch各个节点状况"></p><h4 id="12、冲突查找快捷键">12、冲突查找快捷键</h4><p><strong>Ctrl+Alt+Shift+N</strong></p><h3 id="八、xz-bigdata-es开发">八、xz_bigdata_es开发</h3><h4 id="1、pom-xml-2">1、pom.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_es&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_es&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;            &lt;artifactId&gt;transport&lt;/artifactId&gt;            &lt;version&gt;6.2.3&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;io.searchbox&lt;/groupId&gt;            &lt;artifactId&gt;jest&lt;/artifactId&gt;            &lt;version&gt;6.3.1&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><h4 id="2、admin">2、admin</h4><p><strong>AdminUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.admin;import com.hsiehchou.common.file.FileCommon;import com.hsiehchou.es.client.ESClientUtils;import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;import org.elasticsearch.action.admin.indices.exists.indices.IndicesExistsResponse;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.settings.Settings;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class AdminUtil {    private static Logger LOG = LoggerFactory.getLogger(AdminUtil.class);    public static void main(String[] args) throws Exception{        //创建索引核mapping        AdminUtil.buildIndexAndTypes("tanslator_test1111","tanslator_test1111", "es/mapping/test.json",3,1);        //index = 类型+日期        //查找类  Ctrl+Shift+Alt+N    }    /**     * @param index     * @param type     * @param path     * @param shard     * @param replication     * @return     * @throws Exception     */    public static boolean buildIndexAndTypes(String index,String type,String path,int shard,int replication) throws Exception{        boolean flag ;        TransportClient client = ESClientUtils.getClient();        String mappingJson = FileCommon.getAbstractPath(path);        boolean indices = AdminUtil.createIndices(client, index, shard, replication);        if(indices){            LOG.info("创建索引"+ index + "成功");            flag = MappingUtil.addMapping(client, index, type, mappingJson);        }        else{            LOG.error("创建索引"+ index + "失败");            flag = false;        }        return flag;    }    /**     * @desc 判断需要创建的index是否存在     * */    public static boolean indexExists(TransportClient client,String index){        boolean ifExists = false;        try {            System.out.println("client===" + client);            IndicesExistsResponse existsResponse = client.admin().indices().prepareExists(index).execute().actionGet();            ifExists = existsResponse.isExists();        } catch (Exception e) {            e.printStackTrace();            LOG.error("判断index是否存在失败...");            return ifExists;        }        return ifExists;    }    /**     * 创建索引     * @param client     * @param index     * @param shard     * @param replication     * @return     */    public static boolean createIndices(TransportClient client, String index, int shard , int replication){        if(!indexExists(client,index)) {            LOG.info("该index不存在，创建...");            CreateIndexResponse createIndexResponse =null;            try {                createIndexResponse = client.admin().indices().prepareCreate(index)                        .setSettings(Settings.builder()                                .put("index.number_of_shards", shard)                                .put("index.number_of_replicas", replication)                                .put("index.codec", "best_compression")                                .put("refresh_interval", "30s"))                        .execute().actionGet();                return createIndexResponse.isAcknowledged();            } catch (Exception e) {                LOG.error(null, e);                return false;            }        }        LOG.warn("该index " + index + " 已经存在...");        return false;    }}</code></pre><p><strong>MappingUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.admin;import com.alibaba.fastjson.JSON;import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.xcontent.XContentBuilder;import org.elasticsearch.common.xcontent.XContentFactory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;public class MappingUtil {private static Logger LOG = LoggerFactory.getLogger(MappingUtil.class);//关闭自动添加字段，关闭后索引数据中如果有多余字段不会修改mapping,默认trueprivate boolean dynamic = true;public static XContentBuilder buildMapping(String tableName) throws IOException {XContentBuilder builder = null;try {builder = XContentFactory.jsonBuilder().startObject().startObject(tableName).startObject("_source").field("enabled", true).endObject().startObject("properties").startObject("id").field("type", "long").endObject().startObject("sn").field("type", "text").endObject().endObject()      .endObject()      .endObject();} catch (IOException e) {e.printStackTrace();}return builder;}public static boolean addMapping(TransportClient client, String index, String type, String jsonString){PutMappingResponse putMappingResponse = null;try {PutMappingRequest mappingRequest = new PutMappingRequest(index).type(type).source(JSON.parseObject(jsonString));putMappingResponse = client.admin().indices().putMapping(mappingRequest).actionGet();} catch (Exception e) {LOG.error(null,e);e.printStackTrace();LOG.error("添加" + type + "的mapping失败....",e);return false;}boolean success = putMappingResponse.isAcknowledged();if (success){LOG.info("创建" + type + "的mapping成功....");return success;}return success;}public static void main(String[] args) throws Exception {/*String singleConf = ConsulConfigUtil.getSingleConf("es6.1.0/mapping/http");int i = singleConf.length() / 2;System.out.println(i);*/}}</code></pre><h4 id="3、client">3、client</h4><p><strong>ESClientUtils.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.client;import com.hsiehchou.common.config.ConfigUtil;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.settings.Settings;import org.elasticsearch.common.transport.TransportAddress;import org.elasticsearch.transport.client.PreBuiltTransportClient;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.Serializable;import java.net.InetAddress;import java.util.Properties;/** * ES 客户端获取 */public class ESClientUtils implements Serializable{    private static Logger LOG = LoggerFactory.getLogger(ESClientUtils.class);    private volatile static TransportClient esClusterClient;    private ESClientUtils(){}    private static Properties properties;    static {        properties = ConfigUtil.getInstance().getProperties("es/es_cluster.properties");    }    public static TransportClient getClient(){        System.setProperty("es.set.netty.runtime.available.processors", "false");        String clusterName = properties.getProperty("es.cluster.name");        String clusterNodes1 = properties.getProperty("es.cluster.nodes1");        String clusterNodes2 = properties.getProperty("es.cluster.nodes2");        String clusterNodes3 = properties.getProperty("es.cluster.nodes3");        LOG.info("clusterName:"+ clusterName);        LOG.info("clusterNodes:"+ clusterNodes1);        LOG.info("clusterNodes:"+ clusterNodes2);        LOG.info("clusterNodes:"+ clusterNodes3);        if(esClusterClient==null){            synchronized (ESClientUtils.class){                if(esClusterClient==null){                    try{                        Settings settings = Settings.builder()                                .put("cluster.name", clusterName)                                //.put("searchguard.ssl.transport.enabled", false)                                //.put("xpack.security.user", "sc_xy_mn_es:xy@66812.com")                               // .put("transport.type","netty3")                               // .put("http.type","netty3")                                .put("client.transport.sniff",true).build();//开启自动嗅探功能                        esClusterClient = new PreBuiltTransportClient(settings)                                .addTransportAddress(new TransportAddress(InetAddress.getByName(clusterNodes1), 9300))                                .addTransportAddress(new TransportAddress(InetAddress.getByName(clusterNodes2), 9300))                                .addTransportAddress(new TransportAddress(InetAddress.getByName(clusterNodes3), 9300));                        LOG.info("esClusterClient========" + esClusterClient.listedNodes());                    }catch (Exception e){                        LOG.error("获取客户端失败",e);                    }finally {                    }                }            }        }        return esClusterClient;    }    public static void main(String[] args) {        TransportClient client = ESClientUtils.getClient();        System.out.println(client);    }}</code></pre><h4 id="4、jest-service">4、jest/service</h4><p><strong>IndexTypeUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.jest.service;import com.hsiehchou.common.config.JsonReader;import io.searchbox.client.JestClient;public class IndexTypeUtil {    public static void main(String[] args) {        IndexTypeUtil.createIndexAndType("tanslator","es/mapping/tanslator.json");       // IndexTypeUtil.createIndexAndType("task");      //  IndexTypeUtil.createIndexAndType("ability");       // IndexTypeUtil.createIndexAndType("paper");    }    public static void createIndexAndType(String index,String jsonPath){        try{            JestClient jestClient = JestService.getJestClient();            JestService.createIndex(jestClient, index);            JestService.createIndexMapping(jestClient,index,index,getSourceFromJson(jsonPath));        }catch (Exception e){            e.printStackTrace();            //LOG.error("创建索引失败",e);        }    }    public static String getSourceFromJson(String path){        return JsonReader.readJson(path);    }    public static String getSource(String index){        if(index.equals("task")){            return "{\"_source\": {\n" +                    "    \"enabled\": true\n" +                    "  },\n" +                    "  \"properties\": {\n" +                    "    \"taskwordcount\": {\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"taskprice\": {\n" +                    "      \"type\": \"float\"\n" +                    "    }\n" +                    "  }\n" +                    "}";        }        if(index.equals("tanslator")){            return "{\n" +                    "  \"_source\": {\n" +                    "    \"enabled\": true\n" +                    "  },\n" +                    "  \"properties\": {\n" +                    "    \"birthday\": {\n" +                    "      \"type\": \"text\",\n" +                    "      \"fields\": {\n" +                    "        \"keyword\": {\n" +                    "          \"ignore_above\": 256,\n" +                    "          \"type\": \"keyword\"\n" +                    "        }\n" +                    "      }\n" +                    "    },\n" +                    "    \"createtime\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"updatetime\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"avgcooperation\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"cooperationwordcount\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"cooperation\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"cooperationtime\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"age\":{\n" +                    "      \"type\": \"long\"\n" +                    "    },\n" +                    "    \"industry\": {\n" +                    "      \"type\": \"nested\",\n" +                    "      \"properties\": {\n" +                    "        \"industryname\": {\n" +                    "          \"type\": \"text\",\n" +                    "          \"fields\": {\n" +                    "            \"keyword\": {\n" +                    "              \"ignore_above\": 256,\n" +                    "              \"type\": \"keyword\"\n" +                    "            }\n" +                    "          }\n" +                    "        },\n" +                    "        \"count\": {\n" +                    "          \"type\": \"long\"\n" +                    "        },\n" +                    "        \"industryid\": {\n" +                    "          \"type\": \"text\",\n" +                    "          \"fields\": {\n" +                    "            \"keyword\": {\n" +                    "              \"ignore_above\": 256,\n" +                    "              \"type\": \"keyword\"\n" +                    "            }\n" +                    "          }\n" +                    "        }\n" +                    "      }\n" +                    "    }\n" +                    "\n" +                    "  }\n" +                    "}";        }        return "";    }}</code></pre><p><strong>JestService.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.jest.service;import com.hsiehchou.common.file.FileCommon;import com.google.gson.GsonBuilder;import io.searchbox.action.Action;import io.searchbox.client.JestClient;import io.searchbox.client.JestClientFactory;import io.searchbox.client.JestResult;import io.searchbox.client.config.HttpClientConfig;import io.searchbox.core.*;import io.searchbox.indices.CreateIndex;import io.searchbox.indices.DeleteIndex;import io.searchbox.indices.IndicesExists;import io.searchbox.indices.mapping.GetMapping;import io.searchbox.indices.mapping.PutMapping;import org.apache.commons.lang.StringUtils;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.aggregations.AggregationBuilder;import org.elasticsearch.search.aggregations.AggregationBuilders;import org.elasticsearch.search.builder.SearchSourceBuilder;import org.elasticsearch.search.sort.SortOrder;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.util.List;import java.util.Map;public class JestService {    private static Logger LOG = LoggerFactory.getLogger(JestService.class);    /**     * 获取JestClient对象     *     * @return     */    public static JestClient getJestClient() {        JestClientFactory factory = new JestClientFactory();        factory.setHttpClientConfig(new HttpClientConfig                .Builder("http://hadoop1:9200")                //.defaultCredentials("sc_xy_mn_es","xy@66812.com")                .gson(new GsonBuilder().setDateFormat("yyyy-MM-dd'T'hh:mm:ss").create())                .connTimeout(1500)                .readTimeout(3000)                .multiThreaded(true)                .build());        return factory.getObject();    }    public static void main(String[] args) throws Exception {        JestClient jestClient = null;//        Map&lt;String, Long&gt; stringLongMap = null;        List&lt;Map&lt;String, Object&gt;&gt; maps = null;        try {            jestClient = JestService.getJestClient();           /* SearchResult aggregation = JestService.aggregation(jestClient,                    "wechat",                    "wechat",                    "collect_time");            stringLongMap = ResultParse.parseAggregation(aggregation);*/           /* SearchResult search = search(jestClient,                    "wechat",                    "wechat",                    "id",                    "65a3d548bd3e42b1972191bc2bd2829b",                    "collect_time",                    "desc",                    1,                    2);*/            /*SearchResult search = search(jestClient,                    "",                    "",                    "phone_mac",                    "aa-aa-aa-aa-aa-aa",                    "collect_time",                    "asc",                    1,                    1000);*///            System.out.println(indexExists(jestClient,"wechat"));            System.out.println("wechat数据量："+count(jestClient,"wechat","wechat"));            System.out.println(aggregation(jestClient,"wechat","wechat", "phone"));            String[] includes = new String[]{"latitude","longitude","collect_time"};//            try{            SearchResult search = JestService.search(jestClient,                        "",                        "",                        "phone_mac.keyword",                        "aa-aa-aa-aa-aa-aa",                        "collect_time",                        "asc",                        1,                        2000);                maps = ResultParse.parseSearchResultOnly(search);                System.out.println(maps.size());                System.out.println(maps);            } catch (Exception e) {                e.printStackTrace();            } finally {                JestService.closeJestClient(jestClient);            }        System.out.println(maps);//        } catch (Exception e) {//            e.printStackTrace();//        }finally {//            JestService.closeJestClient(jestClient);//        }//        System.out.println(stringLongMap);    }    /**     * 统计一个索引所有数据     * @param jestClient     * @param indexName     * @param typeName     * @return     * @throws Exception     */    public static Long count(JestClient jestClient,                             String indexName,                             String typeName) throws Exception {        Count count = new Count.Builder()                .addIndex(indexName)                .addType(typeName)                .build();        CountResult results = jestClient.execute(count);        return results.getCount().longValue();    }    /**     * 聚合分组查询     * @param jestClient     * @param indexName     * @param typeName     * @param field     * @return     * @throws Exception     */    public static SearchResult  aggregation(JestClient jestClient, String indexName, String typeName, String field) throws Exception {        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();        //分组聚合API        AggregationBuilder group1 = AggregationBuilders.terms("group1").field(field);        //group1.subAggregation(AggregationBuilders.terms("group2").field(query));        searchSourceBuilder.aggregation(group1);        searchSourceBuilder.size(0);        System.out.println(searchSourceBuilder.toString());        Search search = new Search.Builder(searchSourceBuilder.toString())                .addIndex(indexName)                .addType(typeName).build();        SearchResult result = jestClient.execute(search);        return result;    }    //基础封装    public static SearchResult search(            JestClient jestClient,            String indexName,            String typeName,            String field,            String fieldValue,            String sortField,            String sortValue,            int pageNumber,            int pageSize,            String[] includes) {        //构造一个查询体  封装的就是查询语句        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();        searchSourceBuilder.fetchSource(includes,new String[0]);        //查询构造器        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        if(StringUtils.isEmpty(field)){            boolQueryBuilder = boolQueryBuilder.must(QueryBuilders.matchAllQuery());        }else{            boolQueryBuilder = boolQueryBuilder.must(QueryBuilders.termQuery(field,fieldValue));        }        searchSourceBuilder.query(boolQueryBuilder);        //定义分页        //从什么时候开始        searchSourceBuilder.from((pageNumber-1)*pageSize);        searchSourceBuilder.size(pageSize);        //设置排序        if("desc".equals(sortValue)){            searchSourceBuilder.sort(sortField,SortOrder.DESC);        }else{            searchSourceBuilder.sort(sortField,SortOrder.ASC);        }        System.out.println("sql =====" + searchSourceBuilder.toString());        //构造一个查询执行器        Search.Builder builder = new Search.Builder(searchSourceBuilder.toString());        //设置indexName typeName        if(StringUtils.isNotBlank(indexName)){            builder.addIndex(indexName);        }        if(StringUtils.isNotBlank(typeName)){            builder.addType(typeName);        }        Search build = builder.build();        SearchResult searchResult = null;        try {            searchResult = jestClient.execute(build);        } catch (IOException e) {            LOG.error("查询失败",e);        }        return searchResult;    }    //基础封装    public static SearchResult search(            JestClient jestClient,            String indexName,            String typeName,            String field,            String fieldValue,            String sortField,            String sortValue,            int pageNumber,            int pageSize) {        //构造一个查询体  封装的就是查询语句        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();        //查询构造器        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        if(StringUtils.isEmpty(field)){            boolQueryBuilder = boolQueryBuilder.must(QueryBuilders.matchAllQuery());        }else{            boolQueryBuilder = boolQueryBuilder.must(QueryBuilders.termQuery(field,fieldValue));        }        searchSourceBuilder.query(boolQueryBuilder);        //定义分页        //从什么时候开始        searchSourceBuilder.from((pageNumber-1)*pageSize);        searchSourceBuilder.size(pageSize);        //设置排序        if("desc".equals(sortValue)){            searchSourceBuilder.sort(sortField,SortOrder.DESC);        }else{            searchSourceBuilder.sort(sortField,SortOrder.ASC);        }        System.out.println("sql =====" + searchSourceBuilder.toString());        //构造一个查询执行器        Search.Builder builder = new Search.Builder(searchSourceBuilder.toString());        //设置indexName typeName        if(StringUtils.isNotBlank(indexName)){            builder.addIndex(indexName);        }        if(StringUtils.isNotBlank(typeName)){            builder.addType(typeName);        }        Search build = builder.build();        SearchResult searchResult = null;        try {            searchResult = jestClient.execute(build);        } catch (IOException e) {            LOG.error("查询失败",e);        }        return searchResult;    }   /* //基础封装    public static SearchResult search(            JestClient jestClient,            String indexName,            String typeName,            String field,            String fieldValue,            String sortField,            String sortValue,            int pageNumber,            int pageSize) {        //构造一个查询体  封装的就是查询语句        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();        //查询构造器        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        if(StringUtils.isEmpty(field)){            boolQueryBuilder = boolQueryBuilder.must(QueryBuilders.matchAllQuery());        }else{            boolQueryBuilder = boolQueryBuilder.must(QueryBuilders.termQuery(field,fieldValue));        }        searchSourceBuilder.query(boolQueryBuilder);        //定义分页        //从什么时候开始        searchSourceBuilder.from((pageNumber-1)*pageSize);        searchSourceBuilder.size(pageSize);        //设置排序        if("desc".equals(sortValue)){            searchSourceBuilder.sort(sortField,SortOrder.DESC);        }else{            searchSourceBuilder.sort(sortField,SortOrder.ASC);        }        System.out.println("sql =====" + searchSourceBuilder.toString());        //构造一个查询执行器        Search.Builder builder = new Search.Builder(searchSourceBuilder.toString());        //设置indexName typeName        if(StringUtils.isNotBlank(indexName)){            builder.addIndex(indexName);        }        if(StringUtils.isNotBlank(typeName)){            builder.addType(typeName);        }        Search build = builder.build();        SearchResult searchResult = null;        try {            searchResult = jestClient.execute(build);        } catch (IOException e) {            LOG.error("查询失败",e);        }        return searchResult;    }*/    /**     * 判断索引是否存在     *     * @param jestClient     * @param indexName     * @return     * @throws Exception     */    public static boolean indexExists(JestClient jestClient, String indexName) {        JestResult result = null;        try {            Action action = new IndicesExists.Builder(indexName).build();            result = jestClient.execute(action);        } catch (IOException e) {            LOG.error(null, e);        }        return result.isSucceeded();    }    /**     * 创建索引     *     * @param jestClient     * @param indexName     * @return     * @throws Exception     */    public static boolean createIndex(JestClient jestClient, String indexName) throws Exception {        if (!JestService.indexExists(jestClient, indexName)) {            JestResult jr = jestClient.execute(new CreateIndex.Builder(indexName).build());            return jr.isSucceeded();        } else {            LOG.info("该索引已经存在");            return false;        }    }    public static boolean createIndexWithSettingsMapAndMappingsString(JestClient jestClient, String indexName, String type, String path) throws Exception {        // String mappingJson = "{\"type1\": {\"_source\":{\"enabled\":false},\"properties\":{\"field1\":{\"type\":\"keyword\"}}}}";        String mappingJson = FileCommon.getAbstractPath(path);        String realMappingJson = "{" + type + ":" + mappingJson + "}";        System.out.println(realMappingJson);        CreateIndex createIndex = new CreateIndex.Builder(indexName)                .mappings(realMappingJson)                .build();        JestResult jr = jestClient.execute(createIndex);        return jr.isSucceeded();    }    /**     * Put映射     *     * @param jestClient     * @param indexName     * @param typeName     * @param source     * @return     * @throws Exception     */    public static boolean createIndexMapping(JestClient jestClient, String indexName, String typeName, String source) throws Exception {        PutMapping putMapping = new PutMapping.Builder(indexName, typeName, source).build();        JestResult jr = jestClient.execute(putMapping);        return jr.isSucceeded();    }    /**     * Get映射     *     * @param jestClient     * @param indexName     * @param typeName     * @return     * @throws Exception     */    public static String getIndexMapping(JestClient jestClient, String indexName, String typeName) throws Exception {        GetMapping getMapping = new GetMapping.Builder().addIndex(indexName).addType(typeName).build();        JestResult jr = jestClient.execute(getMapping);        return jr.getJsonString();    }    /**     * 索引文档     *     * @param jestClient     * @param indexName     * @param typeName     * @return     * @throws Exception     */    public static boolean index(JestClient jestClient, String indexName, String typeName, String idField, List&lt;Map&lt;String, Object&gt;&gt; listMaps) throws Exception {        Bulk.Builder bulk = new Bulk.Builder().defaultIndex(indexName).defaultType(typeName);        for (Map&lt;String, Object&gt; map : listMaps) {            if (map != null &amp;&amp; map.containsKey(idField)) {                Object o = map.get(idField);                Index index = new Index.Builder(map).id(map.get(idField).toString()).build();                bulk.addAction(index);            }        }        BulkResult br = jestClient.execute(bulk.build());        return br.isSucceeded();    }    /**     * 索引文档     *     * @param jestClient     * @param indexName     * @param typeName     * @return     * @throws Exception     */    public static boolean indexString(JestClient jestClient, String indexName, String typeName, String idField, List&lt;Map&lt;String, String&gt;&gt; listMaps) throws Exception {        if (listMaps != null &amp;&amp; listMaps.size() &gt; 0) {            Bulk.Builder bulk = new Bulk.Builder().defaultIndex(indexName).defaultType(typeName);            for (Map&lt;String, String&gt; map : listMaps) {                if (map != null &amp;&amp; map.containsKey(idField)) {                    Index index = new Index.Builder(map).id(map.get(idField)).build();                    bulk.addAction(index);                }            }            BulkResult br = jestClient.execute(bulk.build());            return br.isSucceeded();        } else {            return false;        }    }    /**     * 索引文档     *     * @param jestClient     * @param indexName     * @param typeName     * @return     * @throws Exception     */    public static boolean indexOne(JestClient jestClient, String indexName, String typeName, String id, Map&lt;String, Object&gt; map) {        Index.Builder builder = new Index.Builder(map);        builder.id(id);        builder.refresh(true);        Index index = builder.index(indexName).type(typeName).build();        try {            JestResult result = jestClient.execute(index);            if (result != null &amp;&amp; !result.isSucceeded()) {                throw new RuntimeException(result.getErrorMessage() + "插入更新索引失败!");            }        } catch (Exception e) {            e.printStackTrace();            return false;        }        return true;    }    /**     * 搜索文档     *     * @param jestClient     * @param indexName     * @param typeName     * @param query     * @return     * @throws Exception     */    public static SearchResult search(JestClient jestClient, String indexName, String typeName, String query) throws Exception {        Search search = new Search.Builder(query)                .addIndex(indexName)                .addType(typeName)                .build();        return jestClient.execute(search);    }    /**     * Get文档     *     * @param jestClient     * @param indexName     * @param typeName     * @param id     * @return     * @throws Exception     */    public static JestResult get(JestClient jestClient, String indexName, String typeName, String id) throws Exception {        Get get = new Get.Builder(indexName, id).type(typeName).build();        return jestClient.execute(get);    }    /**     * Delete索引     *     * @param jestClient     * @param indexName     * @return     * @throws Exception     */    public boolean delete(JestClient jestClient, String indexName) throws Exception {        JestResult jr = jestClient.execute(new DeleteIndex.Builder(indexName).build());        return jr.isSucceeded();    }    /**     * Delete文档     *     * @param jestClient     * @param indexName     * @param typeName     * @param id     * @return     * @throws Exception     */    public static boolean delete(JestClient jestClient, String indexName, String typeName, String id) throws Exception {        DocumentResult dr = jestClient.execute(new Delete.Builder(id).index(indexName).type(typeName).build());        return dr.isSucceeded();    }    /**     * 关闭JestClient客户端     *     * @param jestClient     * @throws Exception     */    public static void closeJestClient(JestClient jestClient) {        if (jestClient != null) {            jestClient.shutdownClient();        }    }    public static String query = "{\n" +            "  \"size\": 1,\n" +            "  \"query\": {\n" +            "     \"match\": {\n" +            "       \"taskexcuteid\": \"89899143\"\n" +            "     }\n" +            "  },\n" +            "  \"aggs\": {\n" +            "    \"count\": {\n" +            "      \"terms\": {\n" +            "        \"field\": \"source.keyword\"\n" +            "      },\n" +            "      \"aggs\": {\n" +            "        \"sum_price\": {\n" +            "          \"sum\": {\n" +            "            \"field\": \"taskprice\"\n" +            "          }\n" +            "        },\n" +            "        \"sum_wordcount\": {\n" +            "          \"sum\": {\n" +            "            \"field\": \"taskwordcount\"\n" +            "          }\n" +            "        },\n" +            "        \"avg_taskprice\": {\n" +            "          \"avg\": {\n" +            "            \"field\": \"taskprice\"\n" +            "          }\n" +            "        }\n" +            "      }\n" +            "    }\n" +            "  }\n" +            "}";}</code></pre><p><strong>ResultParse.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.jest.service;import com.google.gson.Gson;import com.google.gson.JsonElement;import com.google.gson.JsonObject;import com.google.gson.JsonPrimitive;import io.searchbox.client.JestClient;import io.searchbox.client.JestResult;import io.searchbox.core.SearchResult;import io.searchbox.core.search.aggregation.MetricAggregation;import io.searchbox.core.search.aggregation.TermsAggregation;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.*;public class ResultParse {    private static Logger LOG = LoggerFactory.getLogger(ResultParse.class);    public static void main(String[] args) throws Exception {        JestClient jestClient = JestService.getJestClient();        /*long l = System.currentTimeMillis();        JestClient jestClient = JestClientUtil.getJestClient();        System.out.println(jestClient);        String json ="{\n" +                "  \"size\": 1, \n" +                "  \"query\": {\n" +                "    \"query_string\": {\n" +                "      \"query\": \"中文\"\n" +                "    }\n" +                "  },\n" +                "  \"highlight\": {\n" +                "    \"pre_tags\" : [ \"&lt;red&gt;\" ],\n" +                "    \"post_tags\" : [ \"&lt;/red&gt;\" ],\n" +                "    \"fields\":{\n" +                "      \"secondlanguage\": {}\n" +                "      ,\"firstlanguage\": {}\n" +                "    }\n" +                "  }\n" +                "}";        SearchResult search = JestService.search(jestClient, ES_INDEX.TANSLATOR_TEST, ES_INDEX.TANSLATOR_TEST,json);        ResultParse.parseSearchResult(search);        jestClient.shutdownClient();        long l1 = System.currentTimeMillis();        System.out.println(l1-l);*/    }    public static Map&lt;String,Object&gt; parseGet(JestResult getResult){        Map&lt;String,Object&gt; map = null;        JsonObject jsonObject = getResult.getJsonObject().getAsJsonObject("_source");        if(jsonObject != null){            map = new HashMap&lt;String,Object&gt;();            //System.out.println(jsonObject);            Set&lt;Map.Entry&lt;String, JsonElement&gt;&gt; entries = jsonObject.entrySet();            for(Map.Entry&lt;String, JsonElement&gt; entry:entries){                JsonElement value = entry.getValue();                if(value.isJsonPrimitive()){                    JsonPrimitive value1 = (JsonPrimitive) value;                  //  LOG.error("转换前==========" + value1);                    if( value1.isString() ){                       // LOG.error("转换后==========" + value1.getAsString());                        map.put(entry.getKey(),value1.getAsString());                    }else{                        map.put(entry.getKey(),value1);                    }                }else{                    map.put(entry.getKey(),value);                }             }        }        return map;    }    public static Map&lt;String,Object&gt; parseGet2map(JestResult getResult){        JsonObject source = getResult.getJsonObject().getAsJsonObject("_source");        Gson gson = new Gson();        Map map = gson.fromJson(source, Map.class);        return map;    }    /**     * 解析listMap     * 结果格式为  {hits=0, total=0, data=[]}     * @param search     * @return     */    public static List&lt;Map&lt;String,Object&gt;&gt; parseSearchResultOnly(SearchResult search){        List&lt;Map&lt;String,Object&gt;&gt; list = new ArrayList&lt;Map&lt;String,Object&gt;&gt;();        List&lt;SearchResult.Hit&lt;Object, Void&gt;&gt; hits = search.getHits(Object.class);        for(SearchResult.Hit&lt;Object, Void&gt; hit : hits){            Map&lt;String,Object&gt; source = (Map&lt;String,Object&gt;)hit.source;            list.add(source);        }        return list;    }    /**     * 解析listMap     * 结果格式为  {hits=0, total=0, data=[]}     * @param search     * @return     */    public static Map&lt;String,Long&gt; parseAggregation(SearchResult search){        Map&lt;String,Long&gt; mapResult = new HashMap&lt;&gt;();        MetricAggregation aggregations = search.getAggregations();        TermsAggregation group1 = aggregations.getTermsAggregation("group1");        List&lt;TermsAggregation.Entry&gt; buckets = group1.getBuckets();        buckets.forEach(x-&gt;{            String key = x.getKey();            Long count = x.getCount();            mapResult.put(key,count);        });        return mapResult;    }    /**     * 解析listMap     * 结果格式为  {hits=0, total=0, data=[]}     * @param search     * @return     */    public static Map&lt;String,Object&gt; parseSearchResult(SearchResult search){        Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;();        List&lt;Map&lt;String,Object&gt;&gt; list = new ArrayList&lt;Map&lt;String,Object&gt;&gt;();        Long total = search.getTotal();        map.put("total",total);        List&lt;SearchResult.Hit&lt;Object, Void&gt;&gt; hits = search.getHits(Object.class);        map.put("hits",hits.size());        for(SearchResult.Hit&lt;Object, Void&gt; hit : hits){            Map&lt;String, List&lt;String&gt;&gt; highlight = hit.highlight;            Map&lt;String,Object&gt; source = (Map&lt;String,Object&gt;)hit.source;            source.put("highlight",highlight);            list.add(source);        }        map.put("data",list);        return map;    }}</code></pre><h4 id="5、search">5、search</h4><p><strong>BuilderUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.search;import org.apache.commons.lang.StringUtils;import org.elasticsearch.action.search.SearchRequestBuilder;import org.elasticsearch.client.transport.TransportClient;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class BuilderUtil {    private static Logger LOG = LoggerFactory.getLogger(BuilderUtil.class);    public static SearchRequestBuilder getSearchBuilder(TransportClient client, String index, String type){        SearchRequestBuilder builder = null;        try {            if (StringUtils.isNotBlank(index)) {                builder = client.prepareSearch(index.split(","));            } else {                builder = client.prepareSearch();            }            if (StringUtils.isNotBlank(type)) {                builder.setTypes(type.split(","));            }        } catch (Exception e) {            LOG.error(null, e);        }        return builder;    }    public static SearchRequestBuilder getSearchBuilder(TransportClient client, String[] indexs, String type){        SearchRequestBuilder builder = null;        try {            if (indexs.length&gt;0) {                for(String index:indexs){                    builder = client.prepareSearch(index);                }            } else {                builder = client.prepareSearch();            }            if (StringUtils.isNotBlank(type)) {                builder.setTypes(type);            }        } catch (Exception e) {            LOG.error(null, e);        }        return builder;    }}</code></pre><p><strong>QueryUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.search;import com.hsiehchou.es.utils.UnicodeUtil;import org.apache.lucene.queryparser.classic.QueryParser;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.index.query.QueryStringQueryBuilder;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Map;public class QueryUtil {    private static Logger LOG = LoggerFactory.getLogger(QueryUtil.class);    /**     * EQ   等於     * NEQ  不等於     * GE   大于等于     * GT   大于     * LE   小于等于     * LT   小于     * RANGE 区间范围     */    public static enum OPREATOR {EQ, NEQ,WILDCARD, GE, LE, GT, LT, FUZZY, RANGE, IN, PREFIX}    /**     * @param paramMap     * @return     */    public static BoolQueryBuilder getSearchParam(Map&lt;OPREATOR, Map&lt;String, Object&gt;&gt; paramMap) {        BoolQueryBuilder qb = QueryBuilders.boolQuery();        if (null != paramMap &amp;&amp; !paramMap.isEmpty()) {            for (Map.Entry&lt;OPREATOR, Map&lt;String, Object&gt;&gt; paramEntry : paramMap.entrySet()) {                OPREATOR key = paramEntry.getKey();                Map&lt;String, Object&gt; fieldMap = paramEntry.getValue();                for (Map.Entry&lt;String, Object&gt; fieldEntry : fieldMap.entrySet()) {                    String field = fieldEntry.getKey();                    Object value = fieldEntry.getValue();                    switch (key) {                        case EQ:/**等於查詢 equale**/                            qb.must(QueryBuilders.matchPhraseQuery(field, value).slop(0));                            break;                        case NEQ:/**不等於查詢 not equale**/                            qb.mustNot(QueryBuilders.matchQuery(field, value));                            break;                        case GE: /**大于等于查詢  great than or equal to**/                            qb.must(QueryBuilders.rangeQuery(field).gte(value));                            break;                        case LE: /**小于等于查詢 less than or equal to**/                            qb.must(QueryBuilders.rangeQuery(field).lte(value));                            break;                        case GT: /**大于查詢**/                            qb.must(QueryBuilders.rangeQuery(field).gt(value));                            break;                        case LT: /**小于查詢**/                            qb.must(QueryBuilders.rangeQuery(field).lt(value));                            break;                        case FUZZY:                            String text = String.valueOf(value);                            if (!UnicodeUtil.hasChinese(text)) {                                text = "*" + text + "*";                            }                            text = QueryParser.escape(text);                            qb.must(new QueryStringQueryBuilder(text).field(field));                            break;                        case RANGE: /**区间查詢**/                            String[] split = value.toString().split(",");                            if(split.length==2){                                qb.must(QueryBuilders.rangeQuery(field).from(Long.valueOf(split[0]))                                        .to(Long.valueOf(split[1])));                            }                             /*  if (value instanceof Map) {                                Map&lt;String, Object&gt; rangMap = (Map&lt;String, Object&gt;) value;                                qb.must(QueryBuilders.rangeQuery(field).from(rangMap.get("ge"))                                        .to(rangMap.get("le")));                            }*/                            break;                        case PREFIX: /**前缀查詢**/                            qb.must(QueryBuilders.prefixQuery(field, String.valueOf(value)));                            break;                        case IN:                            qb.must(QueryBuilders.termsQuery(field, (Object[]) value));                            break;                        default:                            qb.must(QueryBuilders.matchQuery(field, value));                            break;                    }                }            }        }        return qb;    }}</code></pre><p><strong>ResponseParse.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.search;import org.elasticsearch.action.get.GetResponse;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Map;public class ResponseParse {    private static Logger LOG = LoggerFactory.getLogger(BuilderUtil.class);    public static Map&lt;String, Object&gt; parseGetResponse(GetResponse getResponse){        Map&lt;String, Object&gt; source = null;        try {            source = getResponse.getSource();        } catch (Exception e) {            LOG.error(null,e);        }        return source;    }}</code></pre><p><strong>SearchUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.search;import com.hsiehchou.es.client.ESClientUtils;import org.elasticsearch.action.get.GetRequestBuilder;import org.elasticsearch.action.get.GetResponse;import org.elasticsearch.action.search.SearchRequestBuilder;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.MatchQueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.SearchHit;import org.elasticsearch.search.SearchHits;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;import java.util.Map;public class SearchUtil {    private static Logger LOG = LoggerFactory.getLogger(SearchUtil.class);    private static TransportClient client = ESClientUtils.getClient();    public static void main(String[] args) {        TransportClient client = ESClientUtils.getClient();        List&lt;Map&lt;String, Object&gt;&gt; maps = searchSingleData(client, "wechat", "wechat", "phone_mac", "aa-aa-aa-aa-aa-aa");        System.out.println(maps);        /* long l = System.currentTimeMillis();        searchSingleData("tanslator", "tanslator","4e1117d7-c434-48a7-9134-45f7c90f94ee_TR1100397895_2");        System.out.println("消耗时间" + (System.currentTimeMillis() - l));        long lll = System.currentTimeMillis();        searchSingleData("tanslator", "tanslator","4e1117d7-c434-48a7-9134-45f7c90f94ee_TR1100397895_2");        System.out.println("消耗时间" + (System.currentTimeMillis() - lll));        long ll = System.currentTimeMillis();        List&lt;Map&lt;String, Object&gt;&gt; maps = searchSingleData(client,"tanslator", "tanslator", "iolid", "TR1100397895");        System.out.println("消耗时间" + (System.currentTimeMillis() - ll));        System.out.println(maps);*/    }    /**     * 查询单条数据     * @param index  索引     * @param type   表名     * @param id     字段     * @return     */    public static GetResponse searchSingleData(String index, String type, String id) {        GetResponse response = null;        try {            GetRequestBuilder builder = null;            builder = client.prepareGet(index, type, id);            response = builder.execute().actionGet();        } catch (Exception e) {            LOG.error(null, e);        }        return response;    }    /**     * @param index     * @param type     * @param field     * @param value     * @return     */    public static List&lt;Map&lt;String, Object&gt;&gt; searchSingleData(TransportClient client,String index, String type,String field, String value) {        List&lt;Map&lt;String, Object&gt;&gt; result = new ArrayList&lt;&gt;();        try {            SearchRequestBuilder builder = BuilderUtil.getSearchBuilder(client,index,type);            MatchQueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(field, value);            builder.setQuery(matchQueryBuilder).setExplain(false);            SearchResponse searchResponse = builder.execute().actionGet();            SearchHits hits = searchResponse.getHits();            SearchHit[] searchHists = hits.getHits();            for (SearchHit sh : searchHists) {                result.add(sh.getSourceAsMap());            }        } catch (Exception e) {            e.printStackTrace();            LOG.error(null, e);        }        return result;    }    /**     * 多条件查詢     * @param index     * @param type     * @param paramMap 组合查询条件     * @return     */    public static SearchResponse searchListData(String index, String type,                                                Map&lt;QueryUtil.OPREATOR,Map&lt;String,Object&gt;&gt; paramMap) {        SearchRequestBuilder builder = BuilderUtil.getSearchBuilder(client,index,type);        builder.setQuery(QueryUtil.getSearchParam(paramMap)).setExplain(false);        SearchResponse searchResponse = builder.get();        return searchResponse;    }    /**     * 多条件查詢     * @param index     * @param type     * @param paramMap 组合查询条件     * @return     */    public static SearchResponse searchListData1(String index, String type, Map&lt;String,String&gt; paramMap) {        BoolQueryBuilder qb = QueryBuilders.boolQuery();        qb.must(QueryBuilders.matchQuery("", ""));        BoolQueryBuilder qb1 = QueryBuilders.boolQuery();        qb1.should(QueryBuilders.matchQuery("",""));        qb1.should(QueryBuilders.matchQuery("",""));        qb.must(qb1);        return null;    }}</code></pre><h4 id="6、utils">6、utils</h4><p><strong>ESresultUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.utils;import org.apache.commons.lang.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Map;public class ESresultUtil {    private static Logger LOG = LoggerFactory.getLogger(ESresultUtil.class);    public static Long getLong(Map&lt;String,Object&gt; esMAp,String field){        Long valueLong = 0L;        if(esMAp!=null &amp;&amp; esMAp.size()&gt;0){            if(esMAp.containsKey(field)){                 Object value = esMAp.get(field);                 if(value!=null &amp;&amp; StringUtils.isNotBlank(value.toString())){                     valueLong = Long.valueOf(value.toString());                 }            }        }        return valueLong;    }}</code></pre><p><strong>UnicodeUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.utils;import java.util.regex.Pattern;public class UnicodeUtil {// 根据Unicode编码完美的判断中文汉字和符号    private static boolean isChinese(char c) {        Character.UnicodeBlock ub = Character.UnicodeBlock.of(c);        if (ub == Character.UnicodeBlock.CJK_UNIFIED_IDEOGRAPHS || ub == Character.UnicodeBlock.CJK_COMPATIBILITY_IDEOGRAPHS                || ub == Character.UnicodeBlock.CJK_UNIFIED_IDEOGRAPHS_EXTENSION_A || ub == Character.UnicodeBlock.CJK_UNIFIED_IDEOGRAPHS_EXTENSION_B                || ub == Character.UnicodeBlock.CJK_SYMBOLS_AND_PUNCTUATION || ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS                || ub == Character.UnicodeBlock.GENERAL_PUNCTUATION) {            return true;        }        return false;    }     // 完整的判断中文汉字和符号    public static boolean isChinese(String strName) {        char[] ch = strName.toCharArray();        for (int i = 0; i &lt; ch.length; i++) {            char c = ch[i];            if (isChinese(c)) {                return true;            }        }        return false;    }        // 完整的判断中文汉字和符号    public static boolean hasChinese(String strName) {        char[] ch = strName.toCharArray();        for (int i = 0; i &lt; ch.length; i++) {            char c = ch[i];            if (isChinese(c)) {                return true;            }        }        return false;    }     // 只能判断部分CJK字符（CJK统一汉字）    public static boolean isChineseByREG(String str) {        if (str == null) {            return false;        }        Pattern pattern = Pattern.compile("[\\u4E00-\\u9FBF]+");        return pattern.matcher(str.trim()).find();    }     // 只能判断部分CJK字符（CJK统一汉字）    /*    public static boolean isChineseByName(String str) {        if (str == null) {            return false;        }        // 大小写不同：\\p 表示包含，\\P 表示不包含        // \\p{Cn} 的意思为 Unicode 中未被定义字符的编码，\\P{Cn} 就表示 Unicode中已经被定义字符的编码        String reg = "\\p{InCJK Unified Ideographs}&amp;&amp;\\P{Cn}";        Pattern pattern = Pattern.compile(reg);        return pattern.matcher(str.trim()).find();    }*/        public static void main(String[] args) {System.out.println(hasChinese("aa表aa"));}}</code></pre><h4 id="7、V2">7、V2</h4><p><strong>ElasticSearchService.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.V2;import com.hsiehchou.es.client.ESClientUtils;import org.apache.commons.collections.map.HashedMap;import org.apache.commons.lang.StringUtils;import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;import org.elasticsearch.action.admin.indices.delete.DeleteIndexResponse;import org.elasticsearch.action.admin.indices.exists.indices.IndicesExistsRequest;import org.elasticsearch.action.admin.indices.exists.indices.IndicesExistsResponse;import org.elasticsearch.action.bulk.BulkRequestBuilder;import org.elasticsearch.action.search.SearchRequestBuilder;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.action.update.UpdateRequest;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.text.Text;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.SearchHit;import org.elasticsearch.search.SearchHits;import org.elasticsearch.search.aggregations.AggregationBuilder;import org.elasticsearch.search.aggregations.AggregationBuilders;import org.elasticsearch.search.aggregations.bucket.terms.Terms;import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder;import org.elasticsearch.search.fetch.subphase.highlight.HighlightField;import org.elasticsearch.search.sort.SortBuilder;import org.elasticsearch.search.sort.SortOrder;import java.util.*;/** *  ES检索封装 */public class ElasticSearchService {    private final static int MAX = 10000;    private static TransportClient client = ESClientUtils.getClient();    /**     * 功能描述：新建索引     * @param indexName 索引名     */    public void createIndex(String indexName) {        client.admin().indices().create(new CreateIndexRequest(indexName))                .actionGet();    }    /**     * 功能描述：新建索引     * @param index 索引名     * @param type 类型     */    public void createIndex(String index, String type) {        client.prepareIndex(index, type).setSource().get();    }    /**     * 功能描述：删除索引     * @param index 索引名     */    public void deleteIndex(String index) {        if (indexExist(index)) {            DeleteIndexResponse dResponse = client.admin().indices().prepareDelete(index)                    .execute().actionGet();            if (!dResponse.isAcknowledged()) {            }        } else {        }    }    /**     * 功能描述：验证索引是否存在     * @param index 索引名     */    public boolean indexExist(String index) {        IndicesExistsRequest inExistsRequest = new IndicesExistsRequest(index);        IndicesExistsResponse inExistsResponse = client.admin().indices()                .exists(inExistsRequest).actionGet();        return inExistsResponse.isExists();    }    /**     * 功能描述：插入数据     * @param index 索引名     * @param type 类型     * @param json 数据     */    public void insertData(String index, String type, String json) {       client.prepareIndex(index, type)                .setSource(json)                .get();    }    /**     * 功能描述：插入数据     * @param index 索引名     * @param type 类型     * @param _id 数据id     * @param json 数据     */    public void insertData(String index, String type, String _id, String json) {        client.prepareIndex(index, type).setId(_id)                .setSource(json)                .get();    }    /**     * 功能描述：更新数据     * @param index 索引名     * @param type 类型     * @param _id 数据id     * @param json 数据     */    public void updateData(String index, String type, String _id, String json) throws Exception {        try {            UpdateRequest updateRequest = new UpdateRequest(index, type, _id)                    .doc(json);            client.update(updateRequest).get();        } catch (Exception e) {            //throw new MessageException("update data failed.", e);        }    }    /**     * 功能描述：删除数据     * @param index 索引名     * @param type 类型     * @param _id 数据id     */    public void deleteData(String index, String type, String _id) {        client.prepareDelete(index, type, _id)                .get();    }    /**     * 功能描述：批量插入数据     * @param index 索引名     * @param type 类型     * @param data (_id 主键, json 数据)     */    public void bulkInsertData(String index, String type, Map&lt;String, String&gt; data) {        BulkRequestBuilder bulkRequest = client.prepareBulk();        data.forEach((param1, param2) -&gt; {            bulkRequest.add(client.prepareIndex(index, type, param1)                    .setSource(param2)            );        });        bulkRequest.get();    }    /**     * 功能描述：批量插入数据     * @param index 索引名     * @param type 类型     * @param jsonList 批量数据     */    public void bulkInsertData(String index, String type, List&lt;String&gt; jsonList) {        BulkRequestBuilder bulkRequest = client.prepareBulk();        jsonList.forEach(item -&gt; {            bulkRequest.add(client.prepareIndex(index, type)                    .setSource(item)            );        });        bulkRequest.get();    }    /**     * 功能描述：查询     * @param index 索引名     * @param type 类型     * @param constructor 查询构造     */    public List&lt;Map&lt;String, Object&gt;&gt; search(String index, String type, ESQueryBuilderConstructor constructor) {        List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;();        SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index).setTypes(type);        //排序        if (StringUtils.isNotEmpty(constructor.getAsc()))            searchRequestBuilder.addSort(constructor.getAsc(), SortOrder.ASC);        if (StringUtils.isNotEmpty(constructor.getDesc()))            searchRequestBuilder.addSort(constructor.getDesc(), SortOrder.DESC);        //设置查询体        searchRequestBuilder.setQuery(constructor.listBuilders());        //返回条目数        int size = constructor.getSize();        if (size &lt; 0) {            size = 0;        }        if (size &gt; MAX) {            size = MAX;        }        //返回条目数        searchRequestBuilder.setSize(size);        searchRequestBuilder.setFrom(constructor.getFrom() &lt; 0 ? 0 : constructor.getFrom());        SearchResponse searchResponse = searchRequestBuilder.execute().actionGet();        SearchHits hits = searchResponse.getHits();        SearchHit[] searchHists = hits.getHits();        for (SearchHit sh : searchHists) {            list.add(sh.getSourceAsMap());        }        return list;    }    /**     * 功能描述：查询     * @param index 索引名     * @param type 类型     * @param constructor 查询构造     */    public Map&lt;String,Object&gt; searchCountAndMessage(String index, String type, ESQueryBuilderConstructor constructor) {        Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;();        List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;();        SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index).setTypes(type);        //排序        if (StringUtils.isNotEmpty(constructor.getAsc()))            searchRequestBuilder.addSort(constructor.getAsc(), SortOrder.ASC);        if (StringUtils.isNotEmpty(constructor.getDesc()))            searchRequestBuilder.addSort(constructor.getDesc(), SortOrder.DESC);        //设置查询体        searchRequestBuilder.setQuery(constructor.listBuilders());        //返回条目数        int size = constructor.getSize();        if (size &lt; 0) {            size = 0;        }        if (size &gt; MAX) {            size = MAX;        }        //返回条目数        searchRequestBuilder.setSize(size);        searchRequestBuilder.setFrom(constructor.getFrom() &lt; 0 ? 0 : constructor.getFrom());        SearchResponse searchResponse = searchRequestBuilder.execute().actionGet();        long totalHits = searchResponse.getHits().getTotalHits();        SearchHits hits = searchResponse.getHits();        SearchHit[] searchHists = hits.getHits();        for (SearchHit sh : searchHists) {            list.add(sh.getSourceAsMap());        }        map.put("total",(long)searchHists.length);        map.put("count",totalHits);        map.put("data",list);        return map;    }    /**     * 功能描述：查询     * @param index 索引名     * @param type 类型     * @param constructor 查询构造     */    public Map&lt;String,Object&gt; searchCountAndMessageNew(String index, String type, ESQueryBuilderConstructorNew constructor) {        Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;();        List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;();        SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index).setTypes(type);        //排序        List&lt;SortBuilder&gt; sortBuilderList = constructor.getSortBuilderList();        if(sortBuilderList!=null &amp;&amp; sortBuilderList.size()&gt;0){            sortBuilderList.forEach(sortBuilder-&gt;{                searchRequestBuilder.addSort(sortBuilder);            });        }        //设置查询体        searchRequestBuilder.setQuery(constructor.listBuilders());        //返回条目数        int size = constructor.getSize();        if (size &lt; 0) {            size = 0;        }        if (size &gt; MAX) {            size = MAX;        }        //返回条目数        searchRequestBuilder.setSize(size);        searchRequestBuilder.setFrom(constructor.getFrom() &lt; 0 ? 0 : constructor.getFrom());        //设置高亮        HighlightBuilder highlightBuilder = new HighlightBuilder();        List&lt;String&gt; highLighterFields = constructor.getHighLighterFields();        if(highLighterFields.size()&gt;0){            highLighterFields.forEach(field -&gt; {                highlightBuilder.field(field);            });        }        highlightBuilder.preTags("&lt;font color=\"red\"&gt;");        highlightBuilder.postTags("&lt;/font&gt;");        SearchResponse searchResponse = searchRequestBuilder.highlighter(highlightBuilder).execute().actionGet();        long totalHits = searchResponse.getHits().getTotalHits();        SearchHits hits = searchResponse.getHits();        SearchHit[] searchHists = hits.getHits();        for (SearchHit hit : searchHists) {            Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();            Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();            //获取高亮结果            Set&lt;String&gt; set = highlightFields.keySet();            for (String str : set) {                Text[] fragments = highlightFields.get(str).getFragments();                String st1r="";                for(Text text:fragments){                    st1r = st1r + text.toString();                }                sourceAsMap.put(str,st1r);                System.out.println("str(==============" + st1r);            }            list.add(sourceAsMap);        }        map.put("total",(long)searchHists.length);        map.put("count",totalHits);        map.put("data",list);        return map;    }    /**     * 功能描述：统计查询     * @param index 索引名     * @param type 类型     * @param constructor 查询构造     * @param groupBy 统计字段     */    public Map&lt;Object, Object&gt; statSearch(String index, String type, ESQueryBuilderConstructor constructor, String groupBy) {        Map&lt;Object, Object&gt; map = new HashedMap();        SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index).setTypes(type);        //排序        if (StringUtils.isNotEmpty(constructor.getAsc()))            searchRequestBuilder.addSort(constructor.getAsc(), SortOrder.ASC);        if (StringUtils.isNotEmpty(constructor.getDesc()))            searchRequestBuilder.addSort(constructor.getDesc(), SortOrder.DESC);        //设置查询体        if (null != constructor) {            searchRequestBuilder.setQuery(constructor.listBuilders());        } else {            searchRequestBuilder.setQuery(QueryBuilders.matchAllQuery());        }        int size = constructor.getSize();        if (size &lt; 0) {            size = 0;        }        if (size &gt; MAX) {            size = MAX;        }        //返回条目数        searchRequestBuilder.setSize(size);        searchRequestBuilder.setFrom(constructor.getFrom() &lt; 0 ? 0 : constructor.getFrom());        SearchResponse sr = searchRequestBuilder.addAggregation(                AggregationBuilders.terms("agg").field(groupBy)        ).get();        Terms stateAgg = sr.getAggregations().get("agg");        Iterator&lt;? extends Terms.Bucket&gt; iter = stateAgg.getBuckets().iterator();        while (iter.hasNext()) {            Terms.Bucket gradeBucket = iter.next();            map.put(gradeBucket.getKey(), gradeBucket.getDocCount());        }        return map;    }    /**     * 功能描述：统计查询     * @param index 索引名     * @param type 类型     * @param constructor 查询构造     * @param agg 自定义计算     */    public Map&lt;Object, Object&gt; statSearch(String index, String type, ESQueryBuilderConstructor constructor, AggregationBuilder agg) {        if (agg == null) {            return null;        }        Map&lt;Object, Object&gt; map = new HashedMap();        SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index).setTypes(type);        //排序        if (StringUtils.isNotEmpty(constructor.getAsc()))            searchRequestBuilder.addSort(constructor.getAsc(), SortOrder.ASC);        if (StringUtils.isNotEmpty(constructor.getDesc()))            searchRequestBuilder.addSort(constructor.getDesc(), SortOrder.DESC);        //设置查询体        if (null != constructor) {            searchRequestBuilder.setQuery(constructor.listBuilders());        } else {            searchRequestBuilder.setQuery(QueryBuilders.matchAllQuery());        }        int size = constructor.getSize();        if (size &lt; 0) {            size = 0;        }        if (size &gt; MAX) {            size = MAX;        }        //返回条目数        searchRequestBuilder.setSize(size);        searchRequestBuilder.setFrom(constructor.getFrom() &lt; 0 ? 0 : constructor.getFrom());        SearchResponse sr = searchRequestBuilder.addAggregation(                agg        ).get();        Terms stateAgg = sr.getAggregations().get("agg");        Iterator&lt;? extends Terms.Bucket&gt; iter = stateAgg.getBuckets().iterator();        while (iter.hasNext()) {            Terms.Bucket gradeBucket = iter.next();            map.put(gradeBucket.getKey(), gradeBucket.getDocCount());        }        return map;    }    /**     * 功能描述：关闭链接     */    public void close() {        client.close();    }    public static void test() {        try{            ElasticSearchService service = new ElasticSearchService();            ESQueryBuilderConstructorNew constructor = new ESQueryBuilderConstructorNew();            constructor.must(new ESQueryBuilders().bool(QueryBuilders.boolQuery()));            constructor.must(new ESQueryBuilders().match("secondlanguage", "4"));            constructor.must(new ESQueryBuilders().match("secondlanguage", "4"));            constructor.should(new ESQueryBuilders().match("source", "5"));            constructor.should(new ESQueryBuilders().match("source", "5"));            service.searchCountAndMessageNew("", "", constructor);        }catch (Exception e){            e.printStackTrace();        }    }    public static void main(String[] args) {        try {            ElasticSearchService service = new ElasticSearchService();            ESQueryBuilderConstructor constructor = new ESQueryBuilderConstructor();         /*   constructor.must(new ESQueryBuilders().term("gender", "f").range("age", 20, 50));            constructor.should(new ESQueryBuilders().term("gender", "f").range("age", 20, 50).fuzzy("age", 20));            constructor.mustNot(new ESQueryBuilders().term("gender", "m"));            constructor.setSize(15);  //查询返回条数，最大 10000            constructor.setFrom(11);  //分页查询条目起始位置， 默认0            constructor.setAsc("age"); //排序            List&lt;Map&lt;String, Object&gt;&gt; list = service.search("bank", "account", constructor);            Map&lt;Object, Object&gt; map = service.statSearch("bank", "account", constructor, "state");*/            constructor.must(new ESQueryBuilders().match("id", "WE16000190TR"));            List&lt;Map&lt;String, Object&gt;&gt; list = service.search("test01", "test01", constructor);             for(Map&lt;String, Object&gt; map : list){                 System.out.println(map);             }        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p><strong>ESCriterion.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.V2;import org.elasticsearch.index.query.QueryBuilder;import java.util.List;/** * 条件接口 */public interface ESCriterion {    public enum Operator {        PREFIX,             /**根据字段前缀查询**/        MATCH,              /**匹配查询**/        MATCH_PHRASE,       /**精确匹配**/        MULTI_MATCH,        /**多字段匹配**/        TERM,               /**term查询**/        TERMS,              /**term查询**/        RANGE,              /**范围查询**/        GTE,                 /**大于等于查询**/        LTE,        FUZZY,              /**根据字段前缀查询**/        QUERY_STRING,       /**根据字段前缀查询**/        MISSING ,           /**根据字段前缀查询**/        BOOL    }    public enum MatchMode {        START, END, ANYWHERE    }    public enum Projection {        MAX, MIN, AVG, LENGTH, SUM, COUNT    }    public List&lt;QueryBuilder&gt; listBuilders();}</code></pre><p><strong>ESQueryBuilderConstructor.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.V2;import org.apache.commons.collections.CollectionUtils;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import java.util.ArrayList;import java.util.List;/** * 查询条件容器 */public class ESQueryBuilderConstructor {    private int size = Integer.MAX_VALUE;    private int from = 0;    private String asc;    private String desc;    //查询条件容器    private List&lt;ESCriterion&gt; mustCriterions = new ArrayList&lt;ESCriterion&gt;();    private List&lt;ESCriterion&gt; shouldCriterions = new ArrayList&lt;ESCriterion&gt;();    private List&lt;ESCriterion&gt; mustNotCriterions = new ArrayList&lt;ESCriterion&gt;();    //构造builder    public QueryBuilder listBuilders() {        int count = mustCriterions.size() + shouldCriterions.size() + mustNotCriterions.size();        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        QueryBuilder queryBuilder = null;        if (count &gt;= 1) {            //must容器            if (!CollectionUtils.isEmpty(mustCriterions)) {                for (ESCriterion criterion : mustCriterions) {                    for (QueryBuilder builder : criterion.listBuilders()) {                        queryBuilder = boolQueryBuilder.must(builder);                    }                }            }            //should容器            if (!CollectionUtils.isEmpty(shouldCriterions)) {                for (ESCriterion criterion : shouldCriterions) {                    for (QueryBuilder builder : criterion.listBuilders()) {                        queryBuilder = boolQueryBuilder.should(builder);                    }                }            }            //must not 容器            if (!CollectionUtils.isEmpty(mustNotCriterions)) {                for (ESCriterion criterion : mustNotCriterions) {                    for (QueryBuilder builder : criterion.listBuilders()) {                        queryBuilder = boolQueryBuilder.mustNot(builder);                    }                }            }            return queryBuilder;        } else {            return null;        }    }    /**     * 增加简单条件表达式     */    public ESQueryBuilderConstructor must(ESCriterion criterion){        if(criterion!=null){            mustCriterions.add(criterion);        }        return this;    }    /**     * 增加简单条件表达式     */    public ESQueryBuilderConstructor should(ESCriterion criterion){        if(criterion!=null){            shouldCriterions.add(criterion);        }        return this;    }    /**     * 增加简单条件表达式     */    public ESQueryBuilderConstructor mustNot(ESCriterion criterion){        if(criterion!=null){            mustNotCriterions.add(criterion);        }        return this;    }    public int getSize() {        return size;    }    public void setSize(int size) {        this.size = size;    }    public String getAsc() {        return asc;    }    public void setAsc(String asc) {        this.asc = asc;    }    public String getDesc() {        return desc;    }    public void setDesc(String desc) {        this.desc = desc;    }    public int getFrom() {        return from;    }    public void setFrom(int from) {        this.from = from;    }}</code></pre><p><strong>ESQueryBuilderConstructorNew.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.V2;import org.apache.commons.collections.CollectionUtils;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.sort.SortBuilder;import java.util.ArrayList;import java.util.List;import java.util.Map;/** * 查询条件容器 */public class ESQueryBuilderConstructorNew {    private List&lt;String&gt; highLighterFields = new ArrayList&lt;String&gt;();    private int size = Integer.MAX_VALUE;    private int from = 0;    private List&lt;SortBuilder&gt; sortBuilderList;    public List&lt;SortBuilder&gt; getSortBuilderList() {        return sortBuilderList;    }    public void setSortBuilderList(List&lt;SortBuilder&gt; sortBuilderList) {        this.sortBuilderList = sortBuilderList;    }    private Map&lt;String,List&lt;String&gt;&gt; sortMap;    //查询条件容器    private List&lt;ESCriterion&gt; mustCriterions = new ArrayList&lt;ESCriterion&gt;();    private List&lt;ESCriterion&gt; shouldCriterions = new ArrayList&lt;ESCriterion&gt;();    private List&lt;ESCriterion&gt; mustNotCriterions = new ArrayList&lt;ESCriterion&gt;();    //构造builder    public QueryBuilder listBuilders() {        int count = mustCriterions.size() + shouldCriterions.size() + mustNotCriterions.size();        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        QueryBuilder queryBuilder = null;        if (count &gt;= 1) {            //must容器            if (!CollectionUtils.isEmpty(mustCriterions)) {                for (ESCriterion criterion : mustCriterions) {                    for (QueryBuilder builder : criterion.listBuilders()) {                        queryBuilder = boolQueryBuilder.must(builder);                    }                }            }            //should容器            if (!CollectionUtils.isEmpty(shouldCriterions)) {                for (ESCriterion criterion : shouldCriterions) {                    for (QueryBuilder builder : criterion.listBuilders()) {                        queryBuilder = boolQueryBuilder.should(builder);                    }                }            }            //must not 容器            if (!CollectionUtils.isEmpty(mustNotCriterions)) {                for (ESCriterion criterion : mustNotCriterions) {                    for (QueryBuilder builder : criterion.listBuilders()) {                        queryBuilder = boolQueryBuilder.mustNot(builder);                    }                }            }            return queryBuilder;        } else {            return null;        }    }    /**     * 增加简单条件表达式     */    public ESQueryBuilderConstructorNew must(ESCriterion criterion){        if(criterion!=null){            mustCriterions.add(criterion);        }        return this;    }    /**     * 增加简单条件表达式     */    public ESQueryBuilderConstructorNew should(ESCriterion criterion){        if(criterion!=null){            shouldCriterions.add(criterion);        }        return this;    }    /**     * 增加简单条件表达式     */    public ESQueryBuilderConstructorNew mustNot(ESCriterion criterion){        if(criterion!=null){            mustNotCriterions.add(criterion);        }        return this;    }    public List&lt;String&gt; getHighLighterFields() {        return highLighterFields;    }    public void setHighLighterFields(List&lt;String&gt; highLighterFields) {        this.highLighterFields = highLighterFields;    }    public int getSize() {        return size;    }    public void setSize(int size) {        this.size = size;    }    public Map&lt;String, List&lt;String&gt;&gt; getSortMap() {        return sortMap;    }    public void setSortMap(Map&lt;String, List&lt;String&gt;&gt; sortMap) {        this.sortMap = sortMap;    }    public int getFrom() {        return from;    }    public void setFrom(int from) {        this.from = from;    }}</code></pre><p><strong>ESQueryBuilders.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.V2;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.NestedQueryBuilder;import org.elasticsearch.index.query.QueryBuilder;import java.util.ArrayList;import java.util.Collection;import java.util.List;/** * 条件构造器 */public class ESQueryBuilders implements ESCriterion{    private List&lt;QueryBuilder&gt; list = new ArrayList&lt;QueryBuilder&gt;();    /**     * 功能描述：match 查询     * @param field 字段名     * @param value 值     */    public ESQueryBuilders match(String field, Object value) {        list.add(new ESSimpleExpression (field, value, Operator.MATCH).toBuilder());        return this;    }    /**     * 功能描述：match 查询     * @param field 字段名     * @param value 值     */    public ESQueryBuilders match_phrase(String field, Object value) {        list.add(new ESSimpleExpression (field, value, Operator.MATCH_PHRASE).toBuilder());        return this;    }    /**     * 功能描述：match 查询     * @param fieldNames 字段名     * @param value 值     */    public ESQueryBuilders multi_match(Object value , String... fieldNames ) {        String[] fields = fieldNames;        list.add(new ESSimpleExpression (value, Operator.MULTI_MATCH,fields).toBuilder());        return this;    }    /**     * 功能描述：Term 查询     * @param field 字段名     * @param value 值     */    public ESQueryBuilders term(String field, Object value) {        list.add(new ESSimpleExpression (field, value, Operator.TERM).toBuilder());        return this;    }    /**     * 功能描述：Terms 查询     * @param field 字段名     * @param values 集合值     */    public ESQueryBuilders terms(String field, Collection&lt;Object&gt; values) {        list.add(new ESSimpleExpression (field, values).toBuilder());        return this;    }    /**     * 功能描述：fuzzy 查询     * @param field 字段名     * @param value 值     */    public ESQueryBuilders fuzzy(String field, Object value) {        list.add(new ESSimpleExpression (field, value, Operator.FUZZY).toBuilder());        return this;    }    /**     * 功能描述：Range 查询     * @param from 起始值     * @param to 末尾值     */    public ESQueryBuilders range(String field, Object from, Object to) {        list.add(new ESSimpleExpression (field, from, to).toBuilder());        return this;    }    /**     * 功能描述：GTE 大于等于查询     * @param     */    public ESQueryBuilders gte(String field, Object num) {        list.add(new ESSimpleExpression (field, num,Operator.GTE).toBuilder());        return this;    }    /**     * 功能描述：LTE 小于等于查询     * @param     */    public ESQueryBuilders lte(String field, Object num) {        list.add(new ESSimpleExpression (field, num,Operator.LTE).toBuilder());        return this;    }    /**     * 功能描述：prefix 查询     * @param field 字段名     * @param value 值     */    public ESQueryBuilders prefix(String field, Object value) {        list.add(new ESSimpleExpression (field, value, Operator.PREFIX).toBuilder());        return this;    }    /**     * 功能描述：Range 查询     * @param queryString 查询语句     */    public ESQueryBuilders queryString(String queryString) {        list.add(new ESSimpleExpression (queryString, Operator.QUERY_STRING).toBuilder());        return this;    }    /**     * 功能描述：Range 查询     * @param     */    public ESQueryBuilders bool(BoolQueryBuilder boolQueryBuilder) {        list.add(boolQueryBuilder);        return this;    }    public ESQueryBuilders nested(NestedQueryBuilder nestedQueryBuilder) {        list.add(nestedQueryBuilder);        return this;    }    public List&lt;QueryBuilder&gt; listBuilders() {        return list;    }}</code></pre><p><strong>ESSimpleExpression.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.es.V2;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import java.util.Collection;import com.hsiehchou.es.V2.ESCriterion.Operator;import static org.elasticsearch.index.search.MatchQuery.Type.PHRASE;/** * 条件表达式 */public class ESSimpleExpression {    private String[] fieldNames;         //属性名    private String fieldName;         //属性名    private Object value;             //对应值    private Collection&lt;Object&gt; values;//对应值    private Operator operator;        //计算符    private Object from;    private Object to;    protected  ESSimpleExpression() {    }    protected  ESSimpleExpression(Object value, Operator operator,String... fieldNames) {        this.fieldNames = fieldNames;        this.value = value;        this.operator = operator;    }    protected  ESSimpleExpression(String fieldName, Object value, Operator operator) {        this.fieldName = fieldName;        this.value = value;        this.operator = operator;    }    protected  ESSimpleExpression(String value, Operator operator) {        this.value = value;        this.operator = operator;    }    protected ESSimpleExpression(String fieldName, Collection&lt;Object&gt; values) {        this.fieldName = fieldName;        this.values = values;        this.operator = Operator.TERMS;    }    protected ESSimpleExpression(String fieldName, Object from, Object to) {        this.fieldName = fieldName;        this.from = from;        this.to = to;        this.operator = Operator.RANGE;    }    public BoolQueryBuilder toBoolQueryBuilder(){        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        boolQueryBuilder.mustNot(QueryBuilders.matchQuery("",""));        boolQueryBuilder.mustNot(QueryBuilders.matchQuery("",""));        return null;    }    public QueryBuilder toBuilder() {        QueryBuilder qb = null;        switch (operator) {            case MATCH:                qb = QueryBuilders.matchQuery(fieldName, value);                break;            case MATCH_PHRASE:                qb = QueryBuilders.matchPhraseQuery(fieldName, value);                break;            case MULTI_MATCH:                qb = QueryBuilders.multiMatchQuery(value,fieldNames).type(PHRASE);                break;            case TERM:                qb = QueryBuilders.termQuery(fieldName, value);                break;            case TERMS:                qb = QueryBuilders.termsQuery(fieldName, values);                break;            case RANGE:                qb = QueryBuilders.rangeQuery(fieldName).from(from).to(to).includeLower(true).includeUpper(true);                break;            case GTE:                qb = QueryBuilders.rangeQuery(fieldName).gte(value);                break;            case LTE:                qb = QueryBuilders.rangeQuery(fieldName).lte(value);                break;            case FUZZY:                qb = QueryBuilders.fuzzyQuery(fieldName, value);                break;            case PREFIX:                qb = QueryBuilders.prefixQuery(fieldName, value.toString());                break;            case QUERY_STRING:                qb = QueryBuilders.queryStringQuery(value.toString());                default:        }        return qb;    }}</code></pre><h3 id="九、预警">九、预警</h3><p>通过后台或者界面设置规则，保存到mysql，然后同步到redis。</p><p>数据量大的话，用mysql是非常慢的，使用内存数据库redis进行规则缓存，使用时直接比对预警。</p><p><img src="/medias/%E9%A2%84%E8%AD%A6%E6%B5%81%E7%A8%8B.PNG" alt="预警流程"></p><p><img src="/medias/%E9%A2%84%E8%AD%A6%E8%BF%87%E7%A8%8B.PNG" alt="预警过程"></p><p>MySQL 需要2张表<br>一张是规则表   用来存储规则<br>一张是消息表   存储告警消息</p><h4 id="1、创建规则表（由界面控制规则发布）">1、创建规则表（由界面控制规则发布）</h4><p>规则首先存放在mysql中，会使用一个定时任务将mysql中的规则同步到redis<br>直接在test库中创建<br>创建脚本<br><strong>xz_rule.sql</strong></p><pre><code class="highlight plaintext">SET FOREIGN_KEY_CHECKS=0;DROP TABLE IF EXISTS `xz_rule`;CREATE TABLE `xz_rule` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `warn_fieldname` varchar(20) DEFAULT NULL,  `warn_fieldvalue` varchar(255) DEFAULT NULL,  `publisher` varchar(255) DEFAULT NULL,  `send_type` varchar(255) CHARACTER SET utf8 DEFAULT NULL,  `send_mobile` varchar(255) DEFAULT NULL,  `send_mail` varchar(255) DEFAULT NULL,  `send_dingding` varchar(255) DEFAULT NULL,  `create_time` date DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=MyISAM AUTO_INCREMENT=2 DEFAULT CHARSET=latin1;INSERT INTO `xz_rule` VALUES ('1', 'phone', '18609765432', '?????1', '2', '13724536789', '1782324@qq.com', '32143243', '2019-06-28');</code></pre><h4 id="2、创建消息表">2、创建消息表</h4><ol><li>用于存放预警的消息，供界面定时刷新预警消息 或者是滚屏预警</li><li>预警消息统计</li></ol><p><strong>warn_message.sql</strong></p><pre><code class="highlight plaintext">SET FOREIGN_KEY_CHECKS=0;DROP TABLE IF EXISTS `warn_message`;CREATE TABLE `warn_message` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `alarmRuleid` varchar(255) DEFAULT NULL,  `alarmType` varchar(255) DEFAULT NULL,  `sendType` varchar(255) DEFAULT NULL,  `sendMobile` varchar(255) DEFAULT NULL,  `sendEmail` varchar(255) DEFAULT NULL,  `sendStatus` varchar(255) DEFAULT NULL,  `senfInfo` varchar(255) CHARACTER SET utf8 DEFAULT NULL,  `hitTime` datetime DEFAULT NULL,  `checkinTime` datetime DEFAULT NULL,  `isRead` varchar(255) DEFAULT NULL,  `readAccounts` varchar(255) DEFAULT NULL,  `alarmaccounts` varchar(255) DEFAULT NULL,  `accountid` varchar(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=MyISAM AUTO_INCREMENT=31 DEFAULT CHARSET=latin1;</code></pre><h4 id="3、创建数据库连接工具类">3、创建数据库连接工具类</h4><p><strong>新建com.hsiehchou.common.netb.db包</strong><br><strong>创建DBCommon类</strong></p><p><strong>DBCommon.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.common.netb.db;import com.hsiehchou.common.config.ConfigUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.sql.*;import java.util.Properties;public class DBCommon {    private static Logger LOG = LoggerFactory.getLogger(DBCommon.class);    private static String MYSQL_PATH = "common/mysql.properties";    private static Properties properties = ConfigUtil.getInstance().getProperties(MYSQL_PATH);    private static Connection conn ;    private DBCommon(){}    public static void main(String[] args) {        System.out.println(properties);        Connection xz_bigdata = DBCommon.getConn("test");        System.out.println(xz_bigdata);    }    //TODO  配置文件    private static final String JDBC_DRIVER = "com.mysql.jdbc.Driver";    private static final String USER_NAME = properties.getProperty("user");    private static final String PASSWORD = properties.getProperty("password");    private static final String IP = properties.getProperty("db_ip");    private static final String PORT = properties.getProperty("db_port");    private static final String DB_CONFIG = "?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&amp;failOverReadOnly=false";    static {        try {            Class.forName(JDBC_DRIVER);        } catch (ClassNotFoundException e) {            LOG.error(null, e);        }    }    /**     * 获取数据库连接     * @param dbName     * @return     */    public static Connection getConn(String dbName) {        Connection conn = null;        String  connstring = "jdbc:mysql://"+IP+":"+PORT+"/"+dbName+DB_CONFIG;        try {            conn = DriverManager.getConnection(connstring, USER_NAME, PASSWORD);        } catch (SQLException e) {            e.printStackTrace();            LOG.error(null, e);        }        return conn;    }    /**     * @param url eg:"jdbc:oracle:thin:@172.16.1.111:1521:d406"     * @param driver eg:"oracle.jdbc.driver.OracleDriver"     * @param user eg:"ucase"     * @param password eg:"ucase123"     * @return     * @throws ClassNotFoundException     * @throws SQLException     */    public static Connection getConn(String url, String driver, String user,                                     String password) throws ClassNotFoundException, SQLException{        Class.forName(driver);        conn = DriverManager.getConnection(url, user, password);        return  conn;    }    public static void close(Connection conn){        try {            if( conn != null ){                conn.close();            }        } catch (SQLException e) {            LOG.error(null,e);        }    }    public static void close(Statement statement){        try {            if( statement != null ){                statement.close();            }        } catch (SQLException e) {            LOG.error(null,e);        }    }    public static void close(Connection conn,PreparedStatement statement){        try {            if( conn != null ){                conn.close();            }            if( statement != null ){                statement.close();            }        } catch (SQLException e) {            LOG.error(null,e);        }    }    public static void close(Connection conn,Statement statement,ResultSet resultSet) throws SQLException{        if( resultSet != null ){            resultSet.close();        }        if( statement != null ){            statement.close();        }        if( conn != null ){            conn.close();        }    }}</code></pre><p><strong>引入maven依赖</strong></p><pre><code class="highlight plaintext">&lt;dependency&gt;    &lt;groupId&gt;commons-dbutils&lt;/groupId&gt;    &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt;    &lt;version&gt;${commons-dbutils.version}&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="4、创建实体类和dao">4、创建实体类和dao</h4><p><strong>新建com.hsiehchou.spark.warn.domain包</strong><br><strong>新建 XZ_RuleDomain，WarningMessage</strong></p><p><strong>XZ_RuleDomain.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.domain;import java.sql.Date;public class XZ_RuleDomain {    private int id;    private String warn_fieldname;   //预警字段    private String warn_fieldvalue; //预警内容    private String publisher;       //发布者    private String send_type;       //消息接收方式    private String send_mobile;     //接收手机号    private String send_mail;       //接收邮箱    private String send_dingding;   //接收钉钉    private Date create_time;       //创建时间    public int getId() {        return id;    }    public void setId(int id) {        this.id = id;    }    public String getWarn_fieldname() {        return warn_fieldname;    }    public void setWarn_fieldname(String warn_fieldname) {        this.warn_fieldname = warn_fieldname;    }    public String getWarn_fieldvalue() {        return warn_fieldvalue;    }    public void setWarn_fieldvalue(String warn_fieldvalue) {        this.warn_fieldvalue = warn_fieldvalue;    }    public String getPublisher() {        return publisher;    }    public void setPublisher(String publisher) {        this.publisher = publisher;    }    public String getSend_type() {        return send_type;    }    public void setSend_type(String send_type) {        this.send_type = send_type;    }    public String getSend_mobile() {        return send_mobile;    }    public void setSend_mobile(String send_mobile) {        this.send_mobile = send_mobile;    }    public String getSend_mail() {        return send_mail;    }    public void setSend_mail(String send_mail) {        this.send_mail = send_mail;    }    public String getSend_dingding() {        return send_dingding;    }    public void setSend_dingding(String send_dingding) {        this.send_dingding = send_dingding;    }    public Date getCreate_time() {        return create_time;    }    public void setCreate_time(Date create_time) {        this.create_time = create_time;    }}</code></pre><p><strong>WarningMessage.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.domain;import java.sql.Date;public class WarningMessage {    private String id;            //主键id    private String alarmRuleid;   //规则id    private String alarmType;     //告警类型    private String sendType;      //发送方式    private String sendMobile;    //发送至手机    private String sendEmail;     //发送至邮箱    private String sendStatus;    //发送状态    private String senfInfo;      //发送内容    private Date hitTime;         //命中时间    private Date checkinTime;     //入库时间    private String isRead;        //是否已读    private String readAccounts;  //已读用户    private String alarmaccounts;    private String accountid;    public String getId() {        return id;    }    public void setId(String id) {        this.id = id;    }    public String getAlarmRuleid() {        return alarmRuleid;    }    public void setAlarmRuleid(String alarmRuleid) {        this.alarmRuleid = alarmRuleid;    }    public String getAlarmType() {        return alarmType;    }    public void setAlarmType(String alarmType) {        this.alarmType = alarmType;    }    public String getSendType() {        return sendType;    }    public void setSendType(String sendType) {        this.sendType = sendType;    }    public String getSendMobile() {        return sendMobile;    }    public void setSendMobile(String sendMobile) {        this.sendMobile = sendMobile;    }    public String getSendEmail() {        return sendEmail;    }    public void setSendEmail(String sendEmail) {        this.sendEmail = sendEmail;    }    public String getSendStatus() {        return sendStatus;    }    public void setSendStatus(String sendStatus) {        this.sendStatus = sendStatus;    }    public String getSenfInfo() {        return senfInfo;    }    public void setSenfInfo(String senfInfo) {        this.senfInfo = senfInfo;    }    public Date getHitTime() {        return hitTime;    }    public void setHitTime(Date hitTime) {        this.hitTime = hitTime;    }    public Date getCheckinTime() {        return checkinTime;    }    public void setCheckinTime(Date checkinTime) {        this.checkinTime = checkinTime;    }    public String getIsRead() {        return isRead;    }    public void setIsRead(String isRead) {        this.isRead = isRead;    }    public String getReadAccounts() {        return readAccounts;    }    public void setReadAccounts(String readAccounts) {        this.readAccounts = readAccounts;    }    public String getAlarmaccounts() {        return alarmaccounts;    }    public void setAlarmaccounts(String alarmaccounts) {        this.alarmaccounts = alarmaccounts;    }    public String getAccountid() {        return accountid;    }    public void setAccountid(String accountid) {        this.accountid = accountid;    }    @Override    public String toString() {        return "WarningMessage{" +                "id='" + id + '\'' +                ", alarmRuleid='" + alarmRuleid + '\'' +                ", alarmType='" + alarmType + '\'' +                ", sendType='" + sendType + '\'' +                ", sendMobile='" + sendMobile + '\'' +                ", sendEmail='" + sendEmail + '\'' +                ", sendStatus='" + sendStatus + '\'' +                ", senfInfo='" + senfInfo + '\'' +                ", hitTime=" + hitTime +                ", checkinTime=" + checkinTime +                ", isRead='" + isRead + '\'' +                ", readAccounts='" + readAccounts + '\'' +                ", alarmaccounts='" + alarmaccounts + '\'' +                ", accountid='" + accountid + '\'' +                '}';    }}</code></pre><p><strong>新建com.hsiehchou.spark.warn.dao包</strong><br><strong>新建 XZ_RuleDao，WarningMessageDao</strong></p><p><strong>XZ_RuleDao.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.dao;import com.hsiehchou.common.netb.db.DBCommon;import com.hsiehchou.spark.warn.domain.XZ_RuleDomain;import org.apache.commons.dbutils.QueryRunner;import org.apache.commons.dbutils.handlers.BeanListHandler;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.sql.Connection;import java.sql.SQLException;import java.util.List;public class XZ_RuleDao {    private static final Logger LOG = LoggerFactory.getLogger(XZ_RuleDao.class);    /**     *  获取所有的规则     * @return     */    public static List&lt;XZ_RuleDomain&gt; getRuleList(){        List&lt;XZ_RuleDomain&gt; listRules = null;        //获取连接        Connection conn = DBCommon.getConn("test");        //执行器        QueryRunner query = new QueryRunner();        String sql = "select * from xz_rule";        try {            listRules = query.query(conn,sql,new BeanListHandler&lt;&gt;(XZ_RuleDomain.class));        } catch (SQLException e) {            LOG.error(null,e);        }finally {            DBCommon.close(conn);        }        return listRules;    }    public static void main(String[] args) {        List&lt;XZ_RuleDomain&gt; ruleList = XZ_RuleDao.getRuleList();        System.out.println(ruleList.size());        ruleList.forEach(x-&gt;{            System.out.println(x);        });    }}</code></pre><p><strong>WarningMessageDao.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.dao;import com.hsiehchou.common.netb.db.DBCommon;import com.hsiehchou.spark.warn.domain.WarningMessage;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.sql.*;public class WarningMessageDao {    private static final Logger LOG = LoggerFactory.getLogger(WarningMessageDao.class);    /**     * 写入消息到mysql     * @param warningMessage     * @return     */    public static Integer insertWarningMessageReturnId(WarningMessage warningMessage) {        Connection conn= DBCommon.getConn("test");        String sql="insert into warn_message(alarmruleid,sendtype,senfinfo,hittime,sendmobile,alarmtype) " +                "values(?,?,?,?,?,?)";        PreparedStatement stmt=null;        ResultSet resultSet=null;        int id=-1;        try{            stmt = conn.prepareStatement(sql);            stmt.setString(1,warningMessage.getAlarmRuleid());            stmt.setInt(2,Integer.valueOf(warningMessage.getSendType()));            stmt.setString(3,warningMessage.getSenfInfo());            stmt.setTimestamp(4,new Timestamp(System.currentTimeMillis()));            stmt.setString(5,warningMessage.getSendMobile());            stmt.setInt(6,Integer.valueOf(warningMessage.getAlarmType()));            stmt.executeUpdate();        }catch(Exception e) {            LOG.error(null,e);        }finally {            try {                DBCommon.close(conn,stmt,resultSet);            } catch (SQLException e) {                e.printStackTrace();            }        }        return id;    }}</code></pre><h4 id="5、告警工具类">5、告警工具类</h4><p><strong>新建com.hsiehchou.spark.warn.service包</strong><br><strong>新建 BlackRuleWarning，WarningMessageSendUtil</strong></p><p><strong>BlackRuleWarning.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.service;import com.hsiehchou.spark.warn.dao.WarningMessageDao;import com.hsiehchou.spark.warn.domain.WarningMessage;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.Jedis;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.List;import java.util.Map;public class BlackRuleWarning {    private static final Logger LOG = LoggerFactory.getLogger(BlackRuleWarning.class);    //可以通过数据库，配置文件加载    //为了遍历所有预警字段    private static List&lt;String&gt; listWarnFields = new ArrayList&lt;&gt;();    static {        listWarnFields.add("phone");        listWarnFields.add("mac");    }    /**     * 预警流程处理     * @param map     * @param jedis15     */    public static void blackWarning(Map&lt;String, Object&gt; map, Jedis jedis15) {        listWarnFields.forEach(warnField -&gt; {            if (map.containsKey(warnField) &amp;&amp; StringUtils.isNotBlank(map.get(warnField).toString())) {                //获取预警字段核预警值  相当于手机号                String warnFieldValue = map.get(warnField).toString();                //去redis中进行比对                //数据中  通过   "字段" + "字段值" 去拼接key                //            phone       :    186XXXXXX                String key = warnField + ":" + warnFieldValue;                //redis中的key是   phone:18609765435                System.out.println("拼接数据流中的key=======" + key);                if (jedis15.exists(key)) {                    //对比命中之后 就可以发送消息提醒                    System.out.println("命中REDIS中的" + key + "===========开始预警");                    beginWarning(jedis15, key);                } else {                    //直接过                    System.out.println("未命中" + key + "===========不进行预警");                }            }        });    }    /**     * 规则已经命中，开始预警     * @param jedis15     * @param key     */    private static void beginWarning( Jedis jedis15, String key) {        System.out.println("============MESSAGE -1- =========");        //封装告警  信息及告警消息        WarningMessage warningMessage = getWarningMessage(jedis15, key);        System.out.println("============MESSAGE -4- =========");        if (warningMessage != null) {            //将预警信息写入预警信息表            WarningMessageDao.insertWarningMessageReturnId(warningMessage);            //String accountid = warningMessage.getAccountid();            //String readAccounts = warningMessage.getAlarmaccounts();            // WarnService.insertRead_status(messageId, accountid);            if (warningMessage.getSendType().equals("2")) {                //手机短信告警 默认告警方式                WarningMessageSendUtil.messageWarn(warningMessage);            }        }    }    /**     * 封装告警信息及告警消息     * @param jedis15     * @param key     * @return     */    private static WarningMessage getWarningMessage(Jedis jedis15, String key) {        System.out.println("============MESSAGE -2- =========");        //封装消息        String[] split = key.split(":");        if (split.length == 2) {            WarningMessage warningMessage = new WarningMessage();            String time = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").toString();            String clew_type = split[0];//告警字段            String rulecontent = split[1];//告警字段值            //从redis中获取消息信息进行封装            Map&lt;String, String&gt; valueMap = jedis15.hgetAll(key);            //规则ID (是哪条规则命中的)            warningMessage.setAlarmRuleid(valueMap.get("id"));            //预警方式            warningMessage.setSendType(valueMap.get("send_type"));//告警方式，0：界面 1：邮件 2：短信 3：邮件+短信            //预警信息接收手机号            warningMessage.setSendMobile(valueMap.get("send_mobile"));            //arningMessage.setSendEmail(valueMap.get("sendemail"));            /*arningMessage.setAlarmaccounts(valueMap.get("alarmaccounts"));*/            //规则发布人            warningMessage.setAccountid(valueMap.get("publisher"));            warningMessage.setAlarmType("2");            StringBuffer warn_content = new StringBuffer();            //预警内容 信息   时间  地点  人物            //预警字段来进行设置  phone            //我们有手机号            //数据关联            // 手机  MAC  身份证， 车牌  人脸。。URL 姓名            // 全部设在推送消息里面            warn_content.append("【网络告警】：手机号为:" + "[" + rulecontent + "]在时间" + time + "出现在" + "&gt;附近,设备号"            );            String content = warn_content.toString();            warningMessage.setSenfInfo(content);            System.out.println("============MESSAGE -3- =========");            return warningMessage;        } else {            return null;        }    }}</code></pre><p><strong>WarningMessageSendUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.service;import com.hsiehchou.common.regex.Validation;import com.hsiehchou.spark.warn.domain.WarningMessage;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class WarningMessageSendUtil {    private static final Logger LOG = LoggerFactory.getLogger(WarningMessageSendUtil.class);    public static void messageWarn(WarningMessage warningMessage) {        String[] mobiles = warningMessage.getSendMobile().split(",");        for(String phone:mobiles){            if(Validation.isMobile(phone)){                System.out.println("开始向手机号为" + phone + "发送告警消息====" + warningMessage);                StringBuffer sb= new StringBuffer();                String content=warningMessage.getSenfInfo().toString();                //TODO  调用短信接口发送消息                //TODO  怎么通过短信发送  这个是需要公司开通接口                //TODO  DINGDING                // 专门的接口             /*   sb.append(ClusterProperties.https_url + "username=" + ClusterProperties.https_username +                        "&amp;password=" + ClusterProperties.https_password + "&amp;mobile=" + phone +                        "&amp;apikey=" + ClusterProperties.https_apikey+                        "&amp;content=" + URLEncoder.encode(content));*/               // sendMessage(sb.toString());            }        }    }}</code></pre><h4 id="6、创建redis子项目">6、创建redis子项目</h4><p><strong>操作redis 使用</strong></p><p><strong>新建xz_bigdata_redis子模块</strong></p><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_redis&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_redis&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;jedis.version&gt;2.7.0&lt;/jedis.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;redis.clients&lt;/groupId&gt;            &lt;artifactId&gt;jedis&lt;/artifactId&gt;            &lt;version&gt;${jedis.version}&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><p><strong>新建com.hsiehchou.redis.client包</strong><br><strong>创建redis连接类—JedisSingle</strong></p><p><strong>JedisSingle.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.redis.client;import com.hsiehchou.common.config.ConfigUtil;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.Jedis;import redis.clients.jedis.exceptions.JedisConnectionException;import java.net.SocketTimeoutException;import java.util.Map;import java.util.Properties;public class JedisSingle {    private static final Logger LOG = LoggerFactory.getLogger(JedisSingle.class);    private static Properties redisConf;    /**     * 读取redis配置文件     * redis.hostname = 192.168.247.103     * redis.port  = 6379     */    static {        redisConf = ConfigUtil.getInstance().getProperties("redis/redis.properties");        System.out.println(redisConf);    }    public static Jedis getJedis(int db){        Jedis jedis = JedisSingle.getJedis();        if(jedis!=null){            jedis.select(db);        }        return jedis;    }    public static void main(String[] args) {        Jedis jedis = JedisSingle.getJedis(15);        Map&lt;String, String&gt; Map = jedis.hgetAll("phone:18609765435");        System.out.println(Map.toString());    }    public static Jedis getJedis(){        int timeoutCount = 0;        while (true) {// 如果是网络超时则多试几次            try            {                 Jedis jedis = new Jedis(redisConf.get("redis.hostname").toString(),                         Integer.valueOf(redisConf.get("redis.port").toString()));                return jedis;            } catch (Exception e)            {                if (e instanceof JedisConnectionException || e instanceof SocketTimeoutException)                {                    timeoutCount++;                    LOG.warn("获取jedis连接超时次数:" +timeoutCount);                    if (timeoutCount &gt; 4)                    {                        LOG.error("获取jedis连接超时次数a:" +timeoutCount);                        LOG.error(null,e);                        break;                    }                }else                {                    LOG.error("getJedis error", e);                    break;                }            }        }        return null;    }    public static void close(Jedis jedis){        if(jedis!=null){            jedis.close();        }    }}</code></pre><h4 id="7、创建定时任务，将规则同步到redis">7、创建定时任务，将规则同步到redis</h4><p><strong>新建 com.hsiehchou.spark.warn.timer 包</strong><br><strong>新建 SyncRule2Redis，WarnHelper</strong></p><p><strong>SyncRule2Redis.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.timer;import java.util.TimerTask;public class SyncRule2Redis extends TimerTask {    @Override    public void run() {        //这里定义同步方法        //就是读取mysql的数据 然后写入到redis中        System.out.println("========开始同步MYSQL规则到redis=======");        WarnHelper.syncRuleFromMysql2Redis();        System.out.println("============开始同步规则成功===========");    }}</code></pre><p><strong>WarnHelper.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.warn.timer;import com.hsiehchou.redis.client.JedisSingle;import com.hsiehchou.spark.warn.dao.XZ_RuleDao;import com.hsiehchou.spark.warn.domain.XZ_RuleDomain;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.Jedis;import java.util.List;public class WarnHelper {    private static final Logger LOG = LoggerFactory.getLogger(WarnHelper.class);    /**     * 同步mysql规则数据到redis     */    public static void syncRuleFromMysql2Redis(){        //获取所有的规则        List&lt;XZ_RuleDomain&gt; ruleList = XZ_RuleDao.getRuleList();        Jedis jedis = null;        try {            //获取redis 客户端            jedis = JedisSingle.getJedis(15);            for (int i = 0; i &lt; ruleList.size(); i++) {                XZ_RuleDomain rule = ruleList.get(i);                String id = rule.getId()+"";                String publisher = rule.getPublisher();                String warn_fieldname = rule.getWarn_fieldname();                String warn_fieldvalue = rule.getWarn_fieldvalue();                String send_mobile = rule.getSend_mobile();                String send_type = rule.getSend_type();                //拼接redis key值                String redisKey = warn_fieldname +":" + warn_fieldvalue;                //通过redis hash结构   hashMap                jedis.hset(redisKey,"id",StringUtils.isNoneBlank(id) ? id : "");                jedis.hset(redisKey,"publisher",StringUtils.isNoneBlank(publisher) ? publisher : "");                jedis.hset(redisKey,"warn_fieldname",StringUtils.isNoneBlank(warn_fieldname) ? warn_fieldname : "");                jedis.hset(redisKey,"warn_fieldvalue",StringUtils.isNoneBlank(warn_fieldvalue) ? warn_fieldvalue : "");                jedis.hset(redisKey,"send_mobile",StringUtils.isNoneBlank(send_mobile) ? send_mobile : "");                jedis.hset(redisKey,"send_type",StringUtils.isNoneBlank(send_type) ? send_type : "");            }        } catch (Exception e) {           LOG.error("同步规则到es失败",e);        } finally {            JedisSingle.close(jedis);        }    }    public static void main(String[] args)    {        WarnHelper.syncRuleFromMysql2Redis();    }}</code></pre><h4 id="8、创建streaming流任务">8、创建streaming流任务</h4><p><strong>scala/com/hsiehchou/spark/streaming/kafka/warn</strong><br><strong>WarningStreamingTask.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.warnimport java.util.Timerimport com.hsiehchou.redis.client.JedisSingleimport com.hsiehchou.spark.common.SparkContextFactoryimport com.hsiehchou.spark.streaming.kafka.Spark_Kafka_ConfigUtilimport com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming.kafkaConfigimport com.hsiehchou.spark.warn.service.BlackRuleWarningimport com.hsiehchou.spark.warn.timer.SyncRule2Redisimport org.apache.spark.Loggingimport org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.StreamingContextimport org.apache.spark.streaming.kafka.KafkaManagerimport redis.clients.jedis.Jedisobject WarningStreamingTask extends Serializable with Logging{  def main(args: Array[String]): Unit = {     //定义一个定时器去定时同步 MYSQL到REDIS     val timer : Timer = new Timer    //SyncRule2Redis 任务类    //0 第一次开始执行    //1*60*1000  隔多少时间执行一次    timer.schedule(new SyncRule2Redis,0,1*60*1000)     //从kafka中获取数据流     //val topics = "chl_test7".split(",")     //kafka topic     val topics = "chl_test7".split(",")     //val ssc = SparkContextFactory.newSparkLocalStreamingContext("WarningStreamingTask1", java.lang.Long.valueOf(10),1)     val ssc:StreamingContext = SparkContextFactory.newSparkStreamingContext("Kafka2esStreaming", java.lang.Long.valueOf(10))    //构建kafkaManager    val kafkaManager = new KafkaManager(      Spark_Kafka_ConfigUtil.getKafkaParam(kafkaConfig.getProperty("metadata.broker.list"), "WarningStreamingTask111")    )    //使用kafkaManager创建DStreaming流    val kafkaDS = kafkaManager.createJsonToJMapStringDirectStreamWithOffset(ssc, topics.toSet)      //添加一个日期分组字段      //如果数据其他的转换，可以先在这里进行统一转换       .persist(StorageLevel.MEMORY_AND_DISK)    kafkaDS.foreachRDD(rdd=&gt;{      //流量预警      //if(!rdd.isEmpty()){/*      val count_flow = rdd.map(x=&gt;{          val flow = java.lang.Long.valueOf(x.get("collect_time"))          flow        }).reduce(_+_)      if(count_flow &gt; 1719179595L){        println("流量预警: 阈值[1719179595L] 实际值:"+ count_flow)      }*/      //}      //客户端连接之类的 最好不要放在RDD外面，因为在处理partion时，数据需要分发到各个节点上去      //数据分发必须需要序列化才可以，如果不能序列化，分发会报错      //如果这个数据 包括他里面的内容 都可以序列化，那么可以直接放在RDD外面      var jedis:Jedis = null      try {        //jedis = JedisSingle.getJedis(15)        rdd.foreachPartition(partion =&gt; {          jedis = JedisSingle.getJedis(15)          while (partion.hasNext) {            val map = partion.next()            val table = map.get("table")            val mapObject = map.asInstanceOf[java.util.Map[String,Object]]            println(table)            //开始比对            BlackRuleWarning.blackWarning(mapObject,jedis)          }        })      } catch {        case e =&gt; e.printStackTrace()      } finally {        JedisSingle.close(jedis)      } /*       rdd.foreachPartition(partion =&gt; {          var jedis: Jedis = null          try {            jedis = JedisSingle.getJedis(15)            while (partion.hasNext) {              val map = partion.next()              val mapObject = map.asInstanceOf[java.util.Map[String, Object]]              //开始比对              BlackRuleWarning.blackWarning(mapObject, jedis)            }          } catch {            case e =&gt; logError(null,e)          }finally {            JedisSingle.close(jedis)          }        })*/    })    ssc.start()    ssc.awaitTermination()  }}</code></pre><h4 id="9、执行">9、执行</h4><p>spark-submit <code>--</code>master local[1] <code>--</code>num-executors 1 <code>--</code>driver-memory 300m <code>--</code>executor-memory 500m <code>--</code>executor-cores 1 <code>--</code>jars $(echo /usr/chl/spark7/jars/*.jar | tr ’ ’ ‘,’) <code>--</code>class com.hsiehchou.spark.streaming.kafka.warn.WarningStreamingTask /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</p><h4 id="10、截图">10、截图</h4><p><img src="/medias/redis%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F.PNG" alt="redis安装成功"></p><p><img src="/medias/%E9%A2%84%E8%AD%A6.PNG" alt="预警"></p><p><img src="/medias/RedisManager.PNG" alt="RedisManager"></p><p><img src="/medias/mysql-xz_rule.PNG" alt="mysql-xz_rule"></p><p><img src="/medias/%E5%8F%91%E9%80%81%E9%A2%84%E8%AD%A6.PNG" alt="发送预警"></p><h4 id="11、redis安装">11、redis安装</h4><p>解压：tar -zxvf redis-3.0.5.tar.gz<br>cd redis-3.0.5/<br>make<br>make PREFIX=/opt/software/redis install</p><p><strong>redis-benchmark</strong> ： Redis提供的压力测试工具。模拟产生客户端的压力<br><strong>redis-check-aof</strong> ： 检查aof日志文件<br><strong>redis-check-dump</strong> ： 检查rdb文件<br><strong>redis-cli</strong> ： Redis客户端脚本<br><strong>redis-sentinel</strong> ： 哨兵<br><strong>redis-server</strong> ： Redis服务器脚本</p><p><strong>核心配置文件:redis.conf</strong><br>[root@hsiehchou202 redis-3.0.5]# cp redis.conf /opt/software/redis<br>[root@hsiehchou202 redis]# mkdir conf<br>[root@hsiehchou202 redis]# mv redis.conf conf/<br>[root@hsiehchou202 conf]# vi redis.conf</p><p>42行 <strong>daemonize yes //后台方式运行</strong><br>50行 <strong>port 6379</strong></p><p>启动<strong>redis ./bin/redis-server conf/redis.conf</strong></p><p><strong>检测是否启动好</strong><br>[root@hsiehchou202 redis]# <strong>bin/redis-server conf/redis.conf</strong></p><h3 id="十、Spark—kafka2hive">十、Spark—kafka2hive</h3><h4 id="1、CDH启用Hive-on-spark">1、CDH启用Hive on spark</h4><p><strong>设置 hive on spark 参数</strong><br>原来的HIVE执行引擎使用的hadoop的mapreduce，Hive on Spark 就是讲执行引擎换为spark 引擎</p><h4 id="2、hive配置文件">2、hive配置文件</h4><p><strong>scala/com/hsiehchou/spark/streaming/kafka/kafka2hdfs/</strong></p><p><strong>HiveConfig.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.kafka2hdfsimport java.utilimport org.apache.commons.configuration.{CompositeConfiguration, ConfigurationException, PropertiesConfiguration}import org.apache.spark.Loggingimport org.apache.spark.sql.types.{StringType, StructField, StructType}import scala.collection.mutable.ArrayBufferimport scala.collection.JavaConversions._object HiveConfig extends Serializable with Logging {  //HIVE 文件根目录  var hive_root_path = "/apps/hive/warehouse/external/"  var hiveFieldPath = "es/mapping/fieldmapping.properties"  var config: CompositeConfiguration = null  //所有的表  var tables: util.List[_] = null  //表对应所有的字段映射,可以通过table名获取 这个table的所有字段  var tableFieldsMap: util.Map[String, util.HashMap[String, String]] = null  //StructType  var mapSchema: util.Map[String, StructType] = null  //建表语句  var hiveTableSQL: util.Map[String, String] = null  /**    * 主要就是创建mapSchema  和  hiveTableSQL    */  initParams()  def main(args: Array[String]): Unit = {  }  /**    * 初始化HIVE参数    */  def initParams(): Unit = {    //加载es/mapping/fieldmapping.properties 配置文件    config = HiveConfig.readCompositeConfiguration(hiveFieldPath)    println("==========================config====================================")    config.getKeys.foreach(key =&gt; {      println(key + ":" + config.getProperty(key.toString))    })    println("==========================tables====================================")    //wechat,mail,qq    tables = config.getList("tables")    tables.foreach(table =&gt; {      println(table)    })    var tables1 = config.getProperty("tables")    println("======================tableFieldsMap================================")    //(qq,{qq.imsi=string, qq.id=string, qq.send_message=string, qq.filename=string})    tableFieldsMap = HiveConfig.getKeysByType()    tableFieldsMap.foreach(x =&gt; {      println(x)    })    println("=========================mapSchema===================================")    mapSchema = HiveConfig.createSchema()    mapSchema.foreach(x =&gt; {//      val structType = x._2//      println("-----------")//      println(structType)//////      val names = structType.fieldNames//      names.foreach(field =&gt; {//        println(field)//      })      println(x)    })    println("=========================hiveTableSQL===================================")    hiveTableSQL = HiveConfig.getHiveTables()    hiveTableSQL.foreach(x =&gt; {      println(x)    })  }  /**    * 读取hive 字段配置文件    * @param path    * @return    */  def readCompositeConfiguration(path: String): CompositeConfiguration = {    logInfo("加载配置文件 " + path)    //多配置工具    val compositeConfiguration = new CompositeConfiguration    try {      val configuration = new PropertiesConfiguration(path)      compositeConfiguration.addConfiguration(configuration)    } catch {      case e: ConfigurationException =&gt; {        logError("加载配置文件 " + path + "失败", e)      }    }    logInfo("加载配置文件" + path + "成功。 ")    compositeConfiguration  }  /**    * 获取table-字段 对应关系    * 使用 util.Map[String,util.HashMap[String, String结构保存    * @return    */  def getKeysByType(): util.Map[String, util.HashMap[String, String]] = {    val map = new util.HashMap[String, util.HashMap[String, String]]()    println("__________________tables_____________________"+tables)    //wechat, mail, qq    val iteratorTable = tables.iterator()    //对每个表进行遍历    while (iteratorTable.hasNext) {      //使用一个MAP保存一种对应关系      val fieldMap = new util.HashMap[String, String]()      //获取一个表      val table: String = iteratorTable.next().toString      //获取这个表的所有字段      val fields = config.getKeys(table)      //获取通用字段  这里暂时没有      val commonKeys: util.Iterator[String] = config.getKeys("common").asInstanceOf[util.Iterator[String]]      //将通用字段放到map结构中去      while (commonKeys.hasNext) {        val key = commonKeys.next()        fieldMap.put(key.replace("common", table), config.getString(key))      }      //将每种表的私有字段放到map中去      while (fields.hasNext) {        val field = fields.next().toString        fieldMap.put(field, config.getString(field))        println("__________________field_____________________"+"\n"+field)      }      map.put(table, fieldMap)    }    map  }  /**    * 构建建表语句* 例如CREATE external TABLE IF NOT EXISTS qq (imei string,imsi string,longitude string,latitude string,phone_mac string,device_mac string,device_number string,collect_time string,username string,phone string,object_username string,send_message string,accept_message string,message_time string,id string,table string,filename string,absolute_filename string)    * @return    */  def getHiveTables(): util.Map[String, String] = {    val hiveTableSqlMap: util.Map[String, String] = new util.HashMap[String, String]()    //获取没中数据的建表语句    tables.foreach(table =&gt; {      var sql: String = s"CREATE external TABLE IF NOT EXISTS ${table} ("      val tableFields = config.getKeys(table.toString)      tableFields.foreach(tableField =&gt; {        //qq.imsi=string, qq.id=string, qq.send_message=string        val fieldType = config.getProperty(tableField.toString)        val field = tableField.toString.split("\\.")(1)        sql = sql + field        fieldType match {          //就是将配置中的类型映射为HIVE 建表语句中的类型          case "string" =&gt; sql = sql + " string,"          case "long" =&gt; sql = sql + " string,"          case "double" =&gt; sql = sql + " string,"          case _ =&gt; println("Nothing Matched!!" + fieldType)        }      })      sql = sql.substring(0, sql.length - 1)      //sql = sql + s")STORED AS PARQUET location '${hive_root_path}${table}'"      sql = sql + s") partitioned by(year string,month string,day string) STORED AS PARQUET " + s"location '${hive_root_path}${table}'"      hiveTableSqlMap.put(table.toString, sql)    })    hiveTableSqlMap  }  /**    * 使用tableFieldsMap    * 对每种类型数据创建对应的Schema    * @return    */  def createSchema(): util.Map[String, StructType] = {    // schema  表结构    /*   CREATE TABLE `warn_message` (         //arrayStructType         `id` int(11) NOT NULL AUTO_INCREMENT,         `alarmRuleid` varchar(255) DEFAULT NULL,         `alarmType` varchar(255) DEFAULT NULL,         `sendType` varchar(255) DEFAULT NULL,         `sendMobile` varchar(255) DEFAULT NULL,         `sendEmail` varchar(255) DEFAULT NULL,         `sendStatus` varchar(255) DEFAULT NULL,         `senfInfo` varchar(255) CHARACTER SET utf8 DEFAULT NULL,         `hitTime` datetime DEFAULT NULL,         `checkinTime` datetime DEFAULT NULL,         `isRead` varchar(255) DEFAULT NULL,         `readAccounts` varchar(255) DEFAULT NULL,         `alarmaccounts` varchar(255) DEFAULT NULL,         `accountid` varchar(11) DEFAULT NULL,         PRIMARY KEY (`id`)       ) ENGINE=MyISAM AUTO_INCREMENT=528 DEFAULT CHARSET=latin1;*/    val mapStructType: util.Map[String, StructType] = new util.HashMap[String, StructType]()    for (table &lt;- tables) {      //通过tableFieldsMap 拿到这个表的所有字段      val tableFields = tableFieldsMap.get(table)      //对这个字段进行遍历      val keyIterator = tableFields.keySet().iterator()      //创建ArrayBuffer      var arrayStructType = ArrayBuffer[StructField]()      while (keyIterator.hasNext) {        val key = keyIterator.next()        val value = tableFields.get(key)        //将key拆分 获取 "."后面的部分作为数据字段        val field = key.split("\\.")(1)        value match {          /* case "string" =&gt; arrayStructType += StructField(field, StringType, true)           case "long"   =&gt; arrayStructType += StructField(field, LongType, true)           case "double"   =&gt; arrayStructType += StructField(field, DoubleType, true)*/          case "string" =&gt; arrayStructType += StructField(field, StringType, true)          case "long" =&gt; arrayStructType += StructField(field, StringType, true)          case "double" =&gt; arrayStructType += StructField(field, StringType, true)          case _ =&gt; println("Nothing Matched!!" + value)        }      }      val schema = StructType(arrayStructType)      mapStructType.put(table.toString, schema)    }    mapStructType  }}</code></pre><h4 id="3、kafka写hdfs和创建hive表">3、kafka写hdfs和创建hive表</h4><p><strong>Kafka2HiveTest.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.kafka2hdfsimport java.utilimport com.hsiehchou.hdfs.HdfsAdminimport com.hsiehchou.hive.HiveConfimport com.hsiehchou.spark.common.{SparkContextFactory}import com.hsiehchou.spark.streaming.kafka.Spark_Kafka_ConfigUtilimport com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming.kafkaConfigimport org.apache.hadoop.fs.Pathimport org.apache.spark.{Logging}import org.apache.spark.rdd.RDDimport org.apache.spark.sql.hive.HiveContextimport org.apache.spark.sql.{DataFrame, Row, SaveMode}import org.apache.spark.sql.types.StructTypeimport org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.kafka.KafkaManagerimport scala.collection.JavaConversions._object Kafka2HiveTest extends Serializable with Logging{  val topics = "chl_test7".split(",")  //获取所有数据类型  //获取所有数据的Schema  def main(args: Array[String]): Unit = {    //val ssc = SparkContextFactory.newSparkLocalStreamingContext("XZ_kafka2es", java.lang.Long.valueOf(10),1)    val ssc = SparkContextFactory.newSparkStreamingContext("Kafka2HiveTest", java.lang.Long.valueOf(10))    //1.创建HIVE表  hiveSQL已經創建好了    val sc = ssc.sparkContext    val hiveContext: HiveContext = HiveConf.getHiveContext(sc)    hiveContext.setConf("spark.sql.parquet.mergeSchema", "true")    createHiveTable(hiveContext)    //kafka拿到流数据    val kafkaDS = new KafkaManager(Spark_Kafka_ConfigUtil                                    .getKafkaParam(kafkaConfig.getProperty("metadata.broker.list"),                                      "Kafka2HiveTest"))                                    .createJsonToJMapStringDirectStreamWithOffset(ssc, topics.toSet)                                    .persist(StorageLevel.MEMORY_AND_DISK)    HiveConfig.tables.foreach(table=&gt;{      //过滤出单一数据类型(获取和table相同类型的所有数据)       val tableDS = kafkaDS.filter(x =&gt; {table.equals(x.get("table"))})      //获取数据类型的schema 表结构      val schema = HiveConfig.mapSchema.get(table)      //获取这个表的所有字段      val schemaFields: Array[String] = schema.fieldNames      tableDS.foreachRDD(rdd=&gt;{        //TODO 数据写入HDFS        /* val sc = rdd.sparkContext        val hiveContext = HiveConf.getHiveContext(sc)        hiveContext.sql(s"USE DEFAULT")*/        //将RDD转为DF   原因：要加字段描述，写比较方便        val tableDF = rdd2DF(rdd,schemaFields,hiveContext,schema)        //多种数据一起处理        val path_all = s"hdfs://hadoop1:8020${HiveConfig.hive_root_path}${table}"        val exists = HdfsAdmin.get().getFs.exists(new Path(path_all))        //2.写到HDFS   不管存不存在我们都要把数据写入进去 通过追加的方式        //每10秒写一次，写一次会生成一个文件        tableDF.write.mode(SaveMode.Append).parquet(path_all)        //3.加载数据到HIVE        if (!exists) {          //如果不存在 进行首次加载          System.out.println("===================开始加载数据到分区=============")          hiveContext.sql(s"ALTER TABLE ${table} LOCATION '${path_all}'")        }      })    })    ssc.start()    ssc.awaitTermination()  }  /**    * 创建HIVE表    * @param hiveContext    */  def createHiveTable(hiveContext: HiveContext): Unit ={    val keys = HiveConfig.hiveTableSQL.keySet()    keys.foreach(key=&gt;{      val sql = HiveConfig.hiveTableSQL.get(key)      //通过hiveContext 和已经创建好的SQL语句去创建HIVE表      hiveContext.sql(sql)      println(s"创建表${key}成功")    })  }  /**    * 将RDD转为DF    * @param rdd    * @param schemaFields    * @param hiveContext    * @param schema    * @return    */  def rdd2DF(rdd:RDD[util.Map[String,String]],             schemaFields: Array[String],             hiveContext:HiveContext,             schema:StructType): DataFrame ={      //将RDD[Map[String,String]]转为RDD[ROW]      val rddRow = rdd.map(recourd =&gt; {        val listRow: util.ArrayList[Object] = new util.ArrayList[Object]()          for (schemaField &lt;- schemaFields) {            listRow.add(recourd.get(schemaField))          }          Row.fromSeq(listRow)  //所有分区合并成一个      }).repartition(1)    //构建DF    //def createDataFrame(rowRDD: RDD[Row], schema: StructType)    val typeDF = hiveContext.createDataFrame(rddRow, schema)    typeDF  }}</code></pre><h4 id="4、Kafka2HiveTest-执行">4、Kafka2HiveTest 执行</h4><p>spark-submit <code>--</code>master local[1] <code>--</code>num-executors 1 <code>--</code>driver-memory 300m <code>--</code>executor-memory 500m <code>--</code>executor-cores 1 <code>--</code>jars $(echo /usr/chl/spark7/jars/*.jar | tr ’ ’ ‘,’) <code>--</code>class com.hsiehchou.spark.streaming.kafka.kafka2hdfs.Kafka2HiveTest /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</p><p><img src="/medias/%E5%AD%98%E5%88%B0hdfs%E4%B8%AD.PNG" alt="存到hdfs中"></p><p><img src="/medias/hive%E6%9F%A5%E8%AF%A21.PNG" alt="hive查询1"></p><h4 id="5、xz-bigdata-spark-src-java">5、xz_bigdata_spark/src/java/</h4><p><strong>com/hsiehchou/hdfs</strong><br><strong>HdfsAdmin.java—HDFS 文件操作类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hdfs;import com.hsiehchou.common.adjuster.StringAdjuster;import com.hsiehchou.common.file.FileCommon;import com.google.common.base.Preconditions;import com.google.common.collect.Lists;import org.apache.commons.io.IOUtils;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.*;import org.apache.log4j.Logger;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.lang.reflect.Array;import java.util.Collection;import java.util.List;/** * HDFS 文件操作类 */public class HdfsAdmin {    private static Logger LOG;    private static final String HDFS_SITE = "/hadoop/hdfs-site.xml";    private static final String CORE_SITE = "/hadoop/core-site.xml";    private volatile static HdfsAdmin hdfsAdmin;    private  FileSystem fs;    private HdfsAdmin(Configuration conf, Logger logger){        try {            if(conf == null) conf = newConf();            conf.set("fs.defaultFS","hdfs://hadoop1:8020");            fs = FileSystem.get(conf);        } catch (IOException e) {            LOG.error("获取 hdfs的FileSystem出现异常。", e);        }        Preconditions.checkNotNull(fs, "没有获取到可用的Hdfs的FileSystem");        this.LOG = logger;        if(this.LOG == null)            this.LOG = Logger.getLogger(HdfsAdmin.class);    }    private Configuration newConf(){        Configuration conf = new Configuration();        if(FileCommon.exist(HDFS_SITE)) conf.addResource(HDFS_SITE);        if(FileCommon.exist(CORE_SITE)) conf.addResource(CORE_SITE);        return conf;    }    public static HdfsAdmin get(){        return get(null);    }    /**     * 获取hdfsAdmin     * @param logger     * @return     */    public static HdfsAdmin get(Logger logger){        if(hdfsAdmin == null){            synchronized (HdfsAdmin.class){                if(hdfsAdmin == null) hdfsAdmin = new HdfsAdmin(null, logger);            }        }        return hdfsAdmin;    }    public static HdfsAdmin get(Configuration conf, Logger logger){        if(hdfsAdmin == null){            synchronized (HdfsAdmin.class){                if(hdfsAdmin == null) hdfsAdmin = new HdfsAdmin(conf, logger);            }        }        return hdfsAdmin;    }    public FileStatus getFileStatus(String dir) {        FileStatus fileStatus = null;        try {            fileStatus = fs.getFileStatus(new Path(dir));        } catch (IOException e) {            LOG.error(String.format("获取文件 %s信息失败。", dir), e);        }        return fileStatus;    }    public void createFile(String dst , byte[] contents){        //目标路径        Path dstPath = new Path(dst);        //打开一个输出流        FSDataOutputStream outputStream;        try {            outputStream = fs.create(dstPath);            outputStream.write(contents);            outputStream.flush();            outputStream.close();        } catch (IOException e) {            LOG.error(String.format("创建文件 %s 失败。", dst), e);        }        LOG.info(String.format("文件: %s 创建成功！", dst));    }    //上传本地文件    public void uploadFile(String src,String dst){        //原路径        Path srcPath = new Path(src);        //目标路径        Path dstPath = new Path(dst);        //调用文件系统的文件复制函数,前面参数是指是否删除原文件，true为删除，默认为false        try {            fs.copyFromLocalFile(false,srcPath, dstPath);        } catch (IOException e) {            LOG.error(String.format("上传文件 %s 到 %s 失败。", src, dst), e);        }        //打印文件路径        LOG.info(String.format("上传文件 %s 到 %s 完成。", src, dst));    }    public void downloadFile(String src , String dst){        Path dstPath = new Path(dst) ;        try {            fs.copyToLocalFile(false, new Path(src), dstPath);        } catch (IOException e) {            LOG.error(String.format("下载文件 %s 到 %s 失败。", src, dst), e);        }        LOG.info(String.format("下载文件 %s 到 %s 完成", src, dst));    }    //文件重命名    public void rename(String oldName,String newName){        Path oldPath = new Path(oldName);        Path newPath = new Path(newName);        boolean isok = false;        try {            isok = fs.rename(oldPath, newPath);        } catch (IOException e) {            LOG.error(String.format("重命名文件 %s 为 %s 失败。", oldName, newName), e);        }        if(isok){            LOG.info(String.format("重命名文件 %s 为 %s 完成。", oldName, newName));        }else{            LOG.error(String.format("重命名文件 %s 为 %s 失败。", oldName, newName));        }    }    public void delete(String path){        delete(path, true);    }    //删除文件    public void delete(String path, boolean recursive){        Path deletePath = new Path(path);        boolean isok = false;        try {            isok = fs.delete(deletePath, recursive);        } catch (IOException e) {            LOG.error(String.format("删除文件 %s 失败。", path), e);        }        if(isok){            LOG.info(String.format("删除文件 %s 完成。", path));        }else{            LOG.error(String.format("删除文件 %s 失败。", path));        }    }    //创建目录    public void mkdir(String path){        Path srcPath = new Path(path);        boolean isok = false;        try {            isok = fs.mkdirs(srcPath);        } catch (IOException e) {            LOG.error(String.format("创建目录 %s 失败。", path), e);        }        if(isok){            LOG.info(String.format("创建目录 %s 完成。", path));        }else{            LOG.error(String.format("创建目录 %s 失败。", path));        }    }    //读取文件的内容    public InputStream readFile(String filePath){        Path srcPath = new Path(filePath);        InputStream in = null;        try {           in = fs.open(srcPath);        } catch (IOException e) {            LOG.error(String.format("读取文件  %s 失败。", filePath), e);        }        return in;    }    public &lt;T&gt; void readFile(String filePath, StringAdjuster&lt;T&gt; adjuster, Collection&lt;T&gt; result){        InputStream inputStream = readFile(filePath);        if(inputStream != null){            InputStreamReader reader = new InputStreamReader(inputStream);            BufferedReader bufferedReader = new BufferedReader(reader);            String line;            try {                T t;                while((line = bufferedReader.readLine()) != null){                    t = adjuster.doAdjust(line);                    if(t != null)result.add(t);                }            } catch (IOException e) {                LOG.error(String.format("利用缓冲流读取文件  %s 失败。", filePath), e);            }finally {                IOUtils.closeQuietly(bufferedReader);                IOUtils.closeQuietly(reader);                IOUtils.closeQuietly(inputStream);            }        }    }    public List&lt;String&gt; readLines(String filePath){        return readLines(filePath, "UTF-8");    }    public  List&lt;String&gt; readLines(String filePath, String encoding){        InputStream inputStream = readFile(filePath);        List&lt;String&gt; lines = null;        if(inputStream != null) {            try {                lines = IOUtils.readLines(inputStream, encoding);            } catch (IOException e) {                LOG.error(String.format("按行读取文件 %s 失败。", filePath), e);            }finally {                IOUtils.closeQuietly(inputStream);            }        }        return lines;    }    public List&lt;FileStatus&gt; findNewFileOrDirInDir(String dir, HdfsFileFilter filter,                                                final boolean onlyFile, final boolean onlyDir){       return findNewFileOrDirInDir(dir, filter, onlyFile, onlyDir, false);    }    public List&lt;FileStatus&gt; findNewFileOrDirInDir(String dir, HdfsFileFilter filter,                          final boolean onlyFile, final boolean onlyDir, boolean recursive){        if(onlyFile &amp;&amp; onlyDir){            FileStatus fileStatus = getFileStatus(dir);            if(fileStatus == null)return Lists.newArrayList();            if(isAccepted(fileStatus,filter)){                return Lists.newArrayList(fileStatus);            }            return Lists.newArrayList();        }       if(onlyFile){           return findNewFileInDir(dir, filter, recursive);       }       if(onlyDir){           return findNewDirInDir(dir, filter, recursive);       }       return Lists.newArrayList();    }    /**     * 查找一个文件夹中 新建的目录     * @param dir     * @param filter     * @return     */    public List&lt;FileStatus&gt; findNewDirInDir(String dir, HdfsFileFilter filter){        return findNewDirInDir(new Path(dir), filter, false);    }    public List&lt;FileStatus&gt; findNewDirInDir(Path path, HdfsFileFilter filter){        return findNewDirInDir(path, filter, false);    }    public List&lt;FileStatus&gt; findNewDirInDir(String dir, HdfsFileFilter filter, boolean recursive){        return findNewDirInDir(new Path(dir), filter, recursive);    }    public List&lt;FileStatus&gt; findNewDirInDir(Path path, HdfsFileFilter filter, boolean recursive){        FileStatus[] files = null;        try {            files = fs.listStatus(path);        } catch (IOException e) {            LOG.error(String.format("获取目录 %s下的文件列表失败。", path), e);        }        if(files == null)return Lists.newArrayList();        List&lt;FileStatus&gt; paths = Lists.newArrayList();        List&lt;String&gt; res = Lists.newArrayList();        for(FileStatus fileStatus : files){            if (fileStatus.isDirectory()) {                if (isAccepted(fileStatus, filter)) {                    paths.add(fileStatus);                    res.add(fileStatus.getPath().toString());                }else if(recursive){                    paths.addAll(findNewDirInDir(fileStatus.getPath(), filter, recursive));                }            }        }        LOG.info(String.format("从目录%s 找到满足条件%s 有如下 %s 个文件： %s",                path, filter,res.size(), res));        return paths;    }    /**     * 查找一个文件夹中 新建的文件     * @param dir     * @param filter     * @return     */    public List&lt;FileStatus&gt; findNewFileInDir(String dir, HdfsFileFilter filter){        return  findNewFileInDir(new Path(dir), filter, false);    }    public List&lt;FileStatus&gt; findNewFileInDir(String dir, HdfsFileFilter filter, boolean recursive){        return  findNewFileInDir(new Path(dir), filter, recursive);    }    public List&lt;FileStatus&gt; findNewFileInDir(Path path, HdfsFileFilter filter){        return  findNewFileInDir(path, filter, false);    }    public List&lt;FileStatus&gt; findNewFileInDir(Path path, HdfsFileFilter filter, boolean recursive){        FileStatus[] files = null;        try {            files = fs.listStatus(path);        } catch (IOException e) {            LOG.error(String.format("获取目录 %s下的文件列表失败。", path), e);        }        if(files == null)return Lists.newArrayList();        List&lt;FileStatus&gt; paths = Lists.newArrayList();        List&lt;String&gt; res = Lists.newArrayList();        for(FileStatus fileStatus : files){            if (fileStatus.isFile()) {                if (isAccepted(fileStatus, filter)) {                    paths.add(fileStatus);                    res.add(fileStatus.getPath().toString());                }            }else if(recursive){                paths.addAll(findNewFileInDir(fileStatus.getPath(), filter, recursive));            }        }        LOG.info(String.format("从目录%s 找到满足条件%s 有如下 %s 个文件： %s", path, filter,res.size(), res));        return paths;    }    private boolean isAccepted(String file, HdfsFileFilter filter) {        if(filter == null) return true;        FileStatus fileStatus = getFileStatus(file);        if(fileStatus == null)return false;        return isAccepted(fileStatus, filter);    }    private boolean isAccepted(FileStatus fileStatus, HdfsFileFilter filter) {        return  filter == null ? true : filter.filter(fileStatus);    }    public long getModificationTime(Path path){        try {            FileStatus status = fs.getFileStatus(path);            return status.getModificationTime();        } catch (IOException e) {            LOG.error(String.format("获取路径 %s信息失败。", path), e);        }        return -1L;    }    public FileSystem getFs() {        return fs;    }    public static void main(String[] args) throws Exception {        // HdfsAdmin hdfsAdmin = HdfsAdmin.get();       // hdfsAdmin.mkdir("hdfs://hdp04.ultiwill.com:8020/test1111");        //System.out.println(hdfsAdmin.getFs().exists(new Path("hdfs://hdp04.ultiwill.com:8020/test")));        //hdfsAdmin.delete("hdfs://hdp04.ultiwill.com:8020/test1111");        //System.out.println("hdfsAdmin = " + );       // List&lt;FileStatus&gt; status = hdfsAdmin.findNewDirInDir("hdfs://hdp04.ultiwill.com:50070/hdp", null);        //System.out.println("status = " + status.size());    }}</code></pre><p><strong>HdfsFileFilter.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hdfs;import com.hsiehchou.common.filter.Filter;import org.apache.hadoop.fs.FileStatus;public abstract class HdfsFileFilter implements Filter&lt;FileStatus&gt; {}</code></pre><p><strong>com/hsiehchou/hive</strong><br><strong>HiveConf.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hive;import org.apache.hadoop.conf.Configuration;import org.apache.spark.SparkContext;import org.apache.spark.sql.hive.HiveContext;import java.util.Iterator;import java.util.Map;public class HiveConf {    //private static String DEFUALT_CONFIG = "spark/hive/hive-server-config";    private static HiveConf hiveConf;    private static HiveContext hiveContext;    private HiveConf(){    }    public static HiveConf getHiveConf(){        if(hiveConf==null){            synchronized (HiveConf.class){                if(hiveConf==null){                    hiveConf=new  HiveConf();                }            }        }        return hiveConf;    }    public static HiveContext getHiveContext(SparkContext sparkContext){        if(hiveContext==null){            synchronized (HiveConf.class){                if(hiveContext==null){                    hiveContext = new  HiveContext(sparkContext);                    Configuration conf = new Configuration();                    conf.addResource("spark/hive/hive-site.xml");                    Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = conf.iterator();                    while (iterator.hasNext()) {                        Map.Entry&lt;String, String&gt; next = iterator.next();                        hiveContext.setConf(next.getKey(), next.getValue());                    }                    hiveContext.setConf("spark.sql.parquet.mergeSchema", "true");                }            }        }        return hiveContext;    }}</code></pre><h4 id="6、小文件合并">6、小文件合并</h4><p><strong>scala/com/hsiehchou/spark/streaming/kafka/kafka2hdfs</strong></p><p><strong>CombineHdfs.scala—合并HDFS小文件任务</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.kafka2hdfsimport com.hsiehchou.hdfs.HdfsAdminimport com.hsiehchou.spark.common.SparkContextFactoryimport org.apache.hadoop.fs.{FileSystem, FileUtil, Path}import org.apache.spark.Loggingimport org.apache.spark.sql.{SQLContext, SaveMode}import scala.collection.JavaConversions._/**  * 合并HDFS小文件任务  */object CombineHdfs extends Serializable with Logging{  def main(args: Array[String]): Unit = {    //  val sparkContext = SparkContextFactory.newSparkBatchContext("CombineHdfs")    val sparkContext = SparkContextFactory.newSparkLocalBatchContext("CombineHdfs")    //创建一个 sparkSQL    val sqlContext: SQLContext = new SQLContext(sparkContext)    //遍历表 就是遍历HIVE表    HiveConfig.tables.foreach(table=&gt;{      //获取HDFS文件目录      //apps/hive/warehouse/external/mail类似  //apps/hive/warehouse/external/mail      val table_path =s"${HiveConfig.hive_root_path}$table"       //通过sparkSQL 加载 这些目录的文件      val tableDF = sqlContext.read.load(table_path)      //先获取原来数据种的所有文件  HDFS文件 API      val fileSystem:FileSystem = HdfsAdmin.get().getFs      //通过globStatus 获取目录下的正则匹配文件      //fileSystem.listFiles()      val arrayFileStatus = fileSystem.globStatus(new Path(table_path+"/part*"))      //stat2Paths将文件状态转为文件路径   这个文件路径是用来删除的      val paths = FileUtil.stat2Paths(arrayFileStatus)      //写入合并文件   //repartition 需要根据生产中实际情况去定义      tableDF.repartition(1).write.mode(SaveMode.Append).parquet(table_path)      println("写入" + table_path +"成功")      //删除小文件      paths.foreach(path =&gt;{        HdfsAdmin.get().getFs.delete(path)        println("删除文件" + path + "成功")      })    })  }}</code></pre><h4 id="7、定时任务">7、定时任务</h4><p><strong>命令行输入：crontab -e</strong></p><p><strong>内容：</strong><br><code>0 1 * * *</code> spark-submit <code>--</code>master local[1] <code>--</code>num-executors 1 <code>--</code>driver-memory 300m <code>--</code>executor-memory 500m <code>--</code>executor-cores 1 <code>--</code>jars $(echo /usr/chl/spark7/jars/*.jar | tr ’ ’ ‘,’) <code>--</code>class com.hsiehchou.spark.streaming.kafka.kafka2hdfs.CombineHdfs /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</p><p><strong>说明：</strong><br><code>* * * * *</code> 执行的任务</p><table><thead><tr><th style="text-align:center">项目</th><th style="text-align:center">含义</th><th style="text-align:center">范围</th></tr></thead><tbody><tr><td style="text-align:center">第一个“*”</td><td style="text-align:center">一小时当中的第几分钟（分）</td><td style="text-align:center">0-59</td></tr><tr><td style="text-align:center">第二个“*”</td><td style="text-align:center">一天当中的第几小时（时）</td><td style="text-align:center">0-23</td></tr><tr><td style="text-align:center">第三个“*”</td><td style="text-align:center">一个月当中的第几天（天）</td><td style="text-align:center">1-31</td></tr><tr><td style="text-align:center">第四个“*”</td><td style="text-align:center">一年当中的第几月（月）</td><td style="text-align:center">1-12</td></tr><tr><td style="text-align:center">第五个“*”</td><td style="text-align:center">一周当中的星期几（周）</td><td style="text-align:center">0-7（0和7都代表星期日）</td></tr></tbody></table><h4 id="8、合并小文件截图">8、合并小文件截图</h4><p><img src="/medias/%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6.PNG" alt="合并小文件"></p><h4 id="9、hive命令">9、hive命令</h4><p>show tales;</p><p>hdfs dfs -ls /apps/hive/warehouse/external</p><p>hdfs dfs -rm -r /apps/hive/warehouse/external/mail</p><p>drop table mail;</p><p>desc qq;</p><p>select * from qq limit 1;<br>select count(*) from qq;</p><p>/usr/bin下面的启动zookeeper客户端<br>zookeeper-client</p><p>删除zookeeper里面的消费者数据<br>rmr /consumers/WarningStreamingTask2/offsets</p><p>rmr /consumers/Kafka2HiveTest/offsets</p><p>rmr /consumers/DataRelationStreaming1/offsets</p><h3 id="十一、Spark—Kafka2Hbase">十一、Spark—Kafka2Hbase</h3><h4 id="1、数据关联">1、数据关联</h4><p><strong>（1）为什么需要关联</strong><br><strong>问题</strong>：我们不能充分了解数据之间的关联关系。</p><p><strong>公司中应用的非常多</strong><br><strong>离线关联</strong>，传通数据 mysql 通过关联字段去关联。<br>但是，如果数据量非常大，关联表非常多。处理不了。</p><p>数据零散，只能从单一维度去看数据，看的面比较窄。<br>如果需要从多个维度分析，关联成本比较大。</p><p>建立数据之间的关联关系，实现<strong>关联查询</strong>的<strong>毫秒级响应</strong>；<br>另一个方面，可以为数据挖掘，机器学习<strong>提供训练数据</strong>。</p><p>后面进行机器学习的时候，都需要从<strong>多维度</strong>对数据进行<strong>分析和建模</strong>。</p><p><strong>（2）HBASE 只要rowkey一样，那么他们就是一条数据</strong><br>QQ<br>aa-aa-aa-aa-aa-aa 666666</p><p>微信<br>aa-aa-aa-aa-aa-aa weixin</p><p>邮箱<br>aa-aa-aa-aa-aa-aa <a href="mailto:666666@qq.com">666666@qq.com</a></p><p><strong>（3）如何关联</strong><br>一对一的情况 :<br><a href="https://blog.csdn.net/shujuelin/article/details/83657485">https://blog.csdn.net/shujuelin/article/details/83657485</a></p><p><strong>使用HBASE写入特性</strong><br>比如 MAC1  1789932321<br>MAC1  <a href="mailto:88888@qq.com">88888@qq.com</a><br>MAC1  88888</p><p>一对多的情况怎么处理<br><strong>使用多版本</strong><br>aa-aa-aa-aa-aa-aa 666666<br>aa-aa-aa-aa-aa-aa 777777</p><p><strong>（4）一对多</strong><br>使用多版本存一堆多的关系<br>多版本 插入了一个777777 一个版本<br>再插入一个777777   一个版本</p><p>所以需要自定义版本号 确定版本唯一<br>通过 “888888”.hashCode() &amp; Integer.MAX_VALUE</p><p><strong>（5）如果实现hbase多字段查询</strong><br>往主关联表 test:relation 里面写入数据  rowkey=&gt;aa-aa-aa-aa-aa-aa version=&gt;1637094383 类型phone_mac value=&gt;aa-aa-aa-aa-aa-aa<br>往二级索表 test:phone_mac里面写入数据  rowkey=&gt;aa-aa-aa-aa-aa-aa version=&gt;1736188717 value=&gt;aa-aa-aa-aa-aa-aa</p><p><img src="/medias/Hbase%E5%85%B3%E8%81%94.PNG" alt="Hbase关联"></p><p>查询不直接查主关联表，因为查询字段不在主键里面，没办法查或者性能非常低下。</p><p>查询是分2步rowkey查询<br>第一步， 通过查询字段取对应的二级索引表里面去找主关联表的ROWKEY<br>第二步， 通过主关联表的ROWKEY 获取HBASE中的全量数据</p><p>WIFI 已经入库的情况下，手机号也必须已经入库了，才能找到<br>加入WIFI的手机号还没有入库</p><p>如果是基础数据先过来   没有mac 没有主键</p><table><thead><tr><th style="text-align:center">Card</th><th style="text-align:center">phone</th></tr></thead><tbody><tr><td style="text-align:center">400000000000000</td><td style="text-align:center">18612345678</td></tr></tbody></table><p>关联</p><table><thead><tr><th style="text-align:center">Phone</th><th style="text-align:center">value （识别这个字段是身份证才可以）</th></tr></thead><tbody><tr><td style="text-align:center">18612345678</td><td style="text-align:center">400000000000000</td></tr></tbody></table><p>1）因为检索的时候都是通过索引表直接找MAC，混入了身份证<br>2）要进行一个合并</p><p><strong>（6）关联及二级索引示意</strong></p><p><img src="/medias/%E5%85%B3%E8%81%94%E5%8F%8A%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E7%A4%BA%E6%84%8F.PNG" alt="关联及二级索引示意"></p><p><img src="/medias/Hbase%E5%85%B3%E8%81%94%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.PNG" alt="Hbase关联表示意图"></p><p><strong>（7）如果使用ES建立二级索引</strong></p><p><img src="/medias/%E4%BD%BF%E7%94%A8ES%E5%BB%BA%E7%AB%8B%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.PNG" alt="使用ES建立二级索引"></p><p>如果hbase 里面有100个字段，存放的是全量信息，但是只有20个字段参与查询、检索，那么我们可以把这个20个字段单独提出来存放到es中，因为ES是对对字段，多条件查询非常灵活。所以我们可以先在ES中对条件进行检索，根据检索的结果拿到hbaSe的rowkey，然后再通过rowkey到hbase里面获取全量信息。</p><p><strong>（8）Hbase 预分区</strong><br>主要是根据rowkey分布来进行预分区</p><p>分区主要是为了防止热点问题</p><p>relation表为例<br>这个表的rowkey 是不是就是 mac</p><p>phone_mac 都是以0-9  a-f开头的<br>device_mac 都是以0-9  a-z开头的<br>Hbase 是按字典序排序</p><p><strong>（9）自定义版本号</strong><br>通过这样的一个转换我们可以精确定位数据的多版本号，，然后可以根据版本号对数据进行多版本删除。<br>156511 aaaaaaaa</p><h4 id="2、DataRelationStreaming—数据关联">2、DataRelationStreaming—数据关联</h4><p><strong>DataRelationStreaming.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafka.kafka2hbaseimport java.util.Propertiesimport com.hsiehchou.common.config.ConfigUtilimport com.hsiehchou.hbase.config.HBaseTableUtilimport com.hsiehchou.hbase.insert.HBaseInsertHelperimport com.hsiehchou.hbase.spilt.SpiltRegionUtilimport com.hsiehchou.spark.common.SparkContextFactoryimport com.hsiehchou.spark.streaming.kafka.Spark_Kafka_ConfigUtilimport org.apache.hadoop.hbase.client.Putimport org.apache.hadoop.hbase.util.Bytesimport org.apache.spark.Loggingimport org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.kafka.KafkaManagerobject DataRelationStreaming extends Serializable with Logging{  // 读取需要关联的配置文件字段  // phone_mac,phone,username,send_mail,imei,imsi  val relationFields = ConfigUtil.getInstance()    .getProperties("spark/relation.properties")    .get("relationfield")    .toString    .split(",")  def main(args: Array[String]): Unit = {    //初始化hbase表    //initRelationHbaseTable(relationFields)    val ssc = SparkContextFactory.newSparkLocalStreamingContext("DataRelationStreaming", java.lang.Long.valueOf(10),1)    //  val ssc = SparkContextFactory.newSparkStreamingContext("DataRelationStreaming", java.lang.Long.valueOf(10))    val kafkaConfig: Properties = ConfigUtil.getInstance().getProperties("kafka/kafka-server-config.properties")    val topics = "chl_test7".split(",")    val kafkaDS = new KafkaManager(Spark_Kafka_ConfigUtil      .getKafkaParam(kafkaConfig.getProperty("metadata.broker.list"),        "DataRelationStreaming2"))      .createJsonToJMapStringDirectStreamWithOffset(ssc, topics.toSet)      .persist(StorageLevel.MEMORY_AND_DISK)    kafkaDS.foreachRDD(rdd=&gt;{      rdd.foreachPartition(partion=&gt;{        //对partion进行遍历        while (partion.hasNext){          //获取每一条流数据          val map = partion.next()          //获取mac 主键          var phone_mac:String = map.get("phone_mac")          //获取所有关联字段 //phone_mac,phone,username,send_mail,imei,imsi          relationFields.foreach(relationFeild =&gt;{            //relationFields 是关联字段，需要进行关联处理的，所有判断            //map中是不是包含这个字段，如果包含的话，取出来进行处理            if(map.containsKey(relationFeild)){              //创建主关联，并遍历关联字段进行关联              val put = new Put(phone_mac.getBytes())              //取关联字段的值              //TODO  到这里  主关联表的 主键和值都有了  然后封装成PUT写入hbase主关联表就行了              val value = map.get(relationFeild)              //自定义版本号  通过 (表字段名 + 字段值 取hashCOde)              //因为值有可能是字符串，但是版本号必须是long类型，所以这里我们需要              //将字符串影射唯一数字，而且必须是正整数              val versionNum = (relationFeild+value).hashCode() &amp; Integer.MAX_VALUE              put.addColumn("cf".getBytes(), Bytes.toBytes(relationFeild),versionNum ,Bytes.toBytes(value.toString))              HBaseInsertHelper.put("test:relation",put)              println(s"往主关联表 test:relation 里面写入数据  rowkey=&gt;${phone_mac} version=&gt;${versionNum} 类型${relationFeild} value=&gt;${value}")              // 建立二级索引              // 使用关联字段的值最为二级索引的rowkey              // 二级索引就是把这个字段的值作为索引表rowkey              // 把这个字段的mac做为索引表的值              val put_2 = new Put(value.getBytes())//把这个字段的值作为索引表rowkey              val table_name = s"test:${relationFeild}"//往索引表里面取写              //使用主表的rowkey  就是 取hash作为二级索引的版本号              val versionNum_2 = phone_mac.hashCode() &amp; Integer.MAX_VALUE              put_2.addColumn("cf".getBytes(), Bytes.toBytes("phone_mac"),versionNum_2 ,Bytes.toBytes(phone_mac.toString))              HBaseInsertHelper.put(table_name,put_2)              println(s"往二级索表 ${table_name}里面写入数据  rowkey=&gt;${value} version=&gt;${versionNum_2} value=&gt;${phone_mac}")            }          })        }      })    })    ssc.start()    ssc.awaitTermination()  }  def initRelationHbaseTable(relationFields:Array[String]): Unit ={    //初始化总关联表    val relation_table = "test:relation"    HBaseTableUtil.createTable(relation_table,      "cf",      true,      -1,      100,      SpiltRegionUtil.getSplitKeysBydinct)    //HBaseTableUtil.deleteTable(relation_table)    //遍历所有关联字段，根据字段创建二级索引表    relationFields.foreach(field=&gt;{      val hbase_table = s"test:${field}"      HBaseTableUtil.createTable(hbase_table, "cf", true, -1, 100, SpiltRegionUtil.getSplitKeysBydinct)      // HBaseTableUtil.deleteTable(hbase_table)    })  }}</code></pre><h4 id="3、com-hsiehchou-spark-streaming">3、com.hsiehchou.spark.streaming</h4><p><strong>common/SparkContextFactory.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.commonimport org.apache.spark.streaming.{Seconds, StreamingContext}import org.apache.spark.{Accumulator, SparkContext}object SparkContextFactory {  def newSparkBatchContext(appName:String = "sparkBatch") : SparkContext = {    val sparkConf = SparkConfFactory.newSparkBatchConf(appName)    new SparkContext(sparkConf)  }  def newSparkLocalBatchContext(appName:String = "sparkLocalBatch" , threads : Int = 2) : SparkContext = {    val sparkConf = SparkConfFactory.newSparkLoalConf(appName, threads)    sparkConf.set("","")    new SparkContext(sparkConf)  }  def getAccumulator(appName:String = "sparkBatch") : Accumulator[Int] = {    val sparkConf = SparkConfFactory.newSparkBatchConf(appName)    val accumulator: Accumulator[Int] = new SparkContext(sparkConf).accumulator(0,"")    accumulator  }  /**    * 创建本地流streamingContext    * @param appName             appName    * @param batchInterval      多少秒读取一次    * @param threads            开启多少个线程    * @return    */  def newSparkLocalStreamingContext(appName:String = "sparkStreaming" ,                                    batchInterval:Long = 30L ,                                    threads : Int = 4) : StreamingContext = {    val sparkConf =  SparkConfFactory.newSparkLocalConf(appName, threads)    // sparkConf.set("spark.streaming.receiver.maxRate","10000")    sparkConf.set("spark.streaming.kafka.maxRatePerPartition","1")    new StreamingContext(sparkConf, Seconds(batchInterval))  }  /**    * 创建集群模式streamingContext    * 这里不设置线程数，在submit中指定    * @param appName    * @param batchInterval    * @return    */  def newSparkStreamingContext(appName:String = "sparkStreaming" , batchInterval:Long = 30L) : StreamingContext = {    val sparkConf = SparkConfFactory.newSparkStreamingConf(appName)    new StreamingContext(sparkConf, Seconds(batchInterval))  }  def startSparkStreaming(ssc:StreamingContext){    ssc.start()  ssc.awaitTermination()  ssc.stop()  }}</code></pre><p><strong>streaming/kafka/Spark_Kafka_ConfigUtil.scala</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.spark.streaming.kafkaimport org.apache.spark.Loggingobject Spark_Kafka_ConfigUtil extends Serializable with Logging{  def getKafkaParam(brokerList:String,groupId : String): Map[String,String]={    val kafkaParam=Map[String,String](      "metadata.broker.list" -&gt; brokerList,      "auto.offset.reset" -&gt; "smallest",      "group.id" -&gt; groupId,      "refresh.leader.backoff.ms" -&gt; "1000",      "num.consumer.fetchers" -&gt; "8")    kafkaParam  }}</code></pre><h4 id="4、com-hsiehchou-common-config-ConfigUtil">4、com/hsiehchou/common/config/ConfigUtil</h4><p><strong>ConfigUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.common.config;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.io.InputStream;import java.util.Properties;public class ConfigUtil {    private static Logger LOG = LoggerFactory.getLogger(ConfigUtil.class);    private static ConfigUtil configUtil;    public static ConfigUtil getInstance(){        if(configUtil == null){            configUtil = new ConfigUtil();        }        return configUtil;    }    public Properties getProperties(String path){        Properties properties = new Properties();        try {            LOG.info("开始加载配置文件" + path);            InputStream insss = this.getClass().getClassLoader().getResourceAsStream(path);            properties = new Properties();            properties.load(insss);        } catch (IOException e) {            LOG.info("加载配置文件" + path + "失败");            LOG.error(null,e);        }        LOG.info("加载配置文件" + path + "成功");        System.out.println("文件内容："+properties);        return properties;    }    public static void main(String[] args) {        ConfigUtil instance = ConfigUtil.getInstance();        Properties properties = instance.getProperties("common/datatype.properties");        //Properties properties = instance.getProperties("spark/relation.properties");       // properties.get("relationfield");        System.out.println(properties);    }}</code></pre><h4 id="5、构建模块—xz-bigdata-hbase">5、构建模块—xz_bigdata_hbase</h4><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata2&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_hbase&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_hbase&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;hbase.version&gt;1.2.0&lt;/hbase.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_resources&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;            &lt;version&gt;${hbase.version}-${cdh.version}&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;guava&lt;/artifactId&gt;                    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;                    &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;            &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;            &lt;version&gt;${hbase.version}-${cdh.version}&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;servlet-api-2.5&lt;/artifactId&gt;                    &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><p><strong>com/hsiehchou/hbase/config/HBaseConf.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.config;import com.hsiehchou.hbase.spilt.SpiltRegionUtil;import org.apache.commons.configuration.CompositeConfiguration;import org.apache.commons.configuration.ConfigurationException;import org.apache.commons.configuration.PropertiesConfiguration;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.BufferedMutator;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.ConnectionFactory;import org.apache.log4j.Logger;import java.io.IOException;import java.io.Serializable;public class HBaseConf implements Serializable {    private static final long serialVersionUID = 1L;    private static final Logger LOG = Logger.getLogger(HBaseConf.class);    private static final String HBASE_SERVER_CONFIG = "hbase/hbase-server-config.properties";    private static final String HBASE_SITE = "hbase/hbase-site.xml";    private volatile static HBaseConf hbaseConf;    private CompositeConfiguration hbase_server_config;    public CompositeConfiguration getHbase_server_config() {        return hbase_server_config;    }    public void setHbase_server_config(CompositeConfiguration hbase_server_config) {        this.hbase_server_config = hbase_server_config;    }    //hbase 配置文件    private  Configuration configuration;    //hbase 连接    private volatile transient Connection conn;    /**     * 初始化HBaseConf的时候加载配置文件     */    private HBaseConf() {        hbase_server_config = new CompositeConfiguration();        //加载配置文件        loadConfig(HBASE_SERVER_CONFIG,hbase_server_config);        //初始化连接        getHconnection();    }    //获取连接    public Configuration getConfiguration(){        if(configuration==null){            configuration = HBaseConfiguration.create();            configuration.addResource(HBASE_SITE);            LOG.info("加载配置文件" + HBASE_SITE + "成功");        }        return configuration;    }    public BufferedMutator getBufferedMutator(String tableName) throws IOException {        return getHconnection().getBufferedMutator(TableName.valueOf(tableName));    }    public Connection getHconnection(){        if(conn==null){            //获取配置文件            getConfiguration();            synchronized (HBaseConf.class) {                if (conn == null) {                    try {                        conn = ConnectionFactory.createConnection(configuration);                    } catch (IOException e) {                        LOG.error(String.format("获取hbase的连接失败  参数为： %s", toString()), e);                    }                }            }        }        return conn;    }    /**     * 加载配置文件     * @param path     * @param configuration     */    private void loadConfig(String path,CompositeConfiguration configuration) {        try {            LOG.info("加载配置文件 " + path);            configuration.addConfiguration(new PropertiesConfiguration(path));            LOG.info("加载配置文件" + path +"成功。 ");        } catch (ConfigurationException e) {            LOG.error("加载配置文件 " + path + "失败", e);        }    }    /**     * 单例 初始化HBaseConf     * @return     */    public static HBaseConf getInstance() {        if (hbaseConf == null) {            synchronized (HBaseConf.class) {                if (hbaseConf == null) {                    hbaseConf = new HBaseConf();                }            }        }        return hbaseConf;    }    public static void main(String[] args) {        String hbase_table = "test:chl_test2";        HBaseTableUtil.createTable(hbase_table, "cf", true, -1, 1, SpiltRegionUtil.getSplitKeysBydinct());      /*  Connection hconnection = HBaseConf.getInstance().getHconnection();        Connection hconnection1 = HBaseConf.getInstance().getHconnection();        System.out.println(hconnection);        System.out.println(hconnection1);*/    }}</code></pre><p><strong>com/hsiehchou/hbase/config/HBaseTableFactory.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.config;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.BufferedMutator;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.client.Table;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.io.Serializable;public class HBaseTableFactory implements Serializable {private static final long serialVersionUID = -1071596337076137201L;private static final Logger LOG = LoggerFactory.getLogger(HBaseTableFactory.class);private HBaseConf conf;private transient Connection conn  ;private boolean isReady = true;public HBaseTableFactory(){conf = HBaseConf.getInstance();if(true){conn = conf.getHconnection();}else{isReady = false;LOG.warn("HBase 连接没有启动。");}}public HBaseTableFactory(Connection conn){this.conn = conn;}/**  * 根据表名创建 表的实例  * @param tableName  * @return  * @throws IOException  * HTableInterface */public Table getHBaseTableInstance(String tableName) throws IOException{if(conn == null){if(conf == null){conf = HBaseConf.getInstance();isReady = true;LOG.warn("HBaseConf为空，重新初始化。");}synchronized (HBaseTableFactory.class) {if(conn == null) {conn = conf.getHconnection();LOG.warn("初始 hbase Connection 为空 ， 获取  Connection成功。");}}}return  isReady ? conn.getTable(TableName.valueOf(tableName)) : null;}public HTable getHTable(String tableName) throws IOException{return  (HTable) getHBaseTableInstance(tableName);}public BufferedMutator getBufferedMutator(String tableName) throws IOException {return getConf().getBufferedMutator(tableName);}public boolean isReady() {return isReady;}private HBaseConf getConf(){if(conf == null){conf = HBaseConf.getInstance();}return conf;}public void close() throws IOException{conn.close();conn = null;}}</code></pre><p><strong>com/hsiehchou/hbase/config/HBaseTableUtil</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.config;import com.google.common.collect.Sets;import org.apache.hadoop.fs.Path;import org.apache.hadoop.hbase.*;import org.apache.hadoop.hbase.client.Admin;import org.apache.hadoop.hbase.client.Table;import org.apache.hadoop.hbase.io.compress.Compression;import org.apache.hadoop.hbase.io.encoding.DataBlockEncoding;import org.apache.hadoop.hbase.regionserver.BloomType;import org.apache.hadoop.hbase.util.Bytes;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.util.*;import static com.google.common.base.Preconditions.checkArgument;public class HBaseTableUtil {    private static final Logger LOG = LoggerFactory.getLogger(HBaseTableUtil.class);    private static final String COPROCESSORCLASSNAME =  "org.apache.hadoop.hbase.coprocessor.AggregateImplementation";    private static HBaseConf conf = HBaseConf.getInstance() ;    private HBaseTableUtil(){}    /**     * 获取hbase 表连接     * @param tableName     * @return     */    public static Table getTable(String tableName){        Table table =null;        if(tableExists(tableName)){            try {                table = conf.getHconnection().getTable(TableName.valueOf(tableName));            } catch (IOException e) {                LOG.error(null,e);            }        }        return table;    }    public static void close(Table table){        if(table != null) {            try {                table.close();            } catch (IOException e) {                e.printStackTrace();            }        }    }    /**     * 判断   HBase中是否存在  名为  tableName 的表     * @param tableName     * @return  boolean     */    public static boolean tableExists(String tableName){        boolean  isExists = false;        try {            isExists = conf.getHconnection().getAdmin().tableExists(TableName.valueOf(tableName));        } catch (MasterNotRunningException e) {            LOG.error("HBase  master  未运行 。 ", e);        } catch (ZooKeeperConnectionException e) {            LOG.error("zooKeeper 连接异常。 ", e);        } catch (IOException e) {            LOG.error("", e);        }        return isExists;    }    /**     * 删除表     * @param tableName     * @return     */    public static boolean deleteTable(String tableName){        boolean status = false;        TableName name = TableName.valueOf(tableName);        try {            Admin admin = conf.getHconnection().getAdmin();            if(admin.tableExists(name)){                if(!admin.isTableDisabled(name)){                    admin.disableTable(name);                }                admin.deleteTable(name);            }else{                LOG.warn(" HBase中不存在 表 " + tableName);            }            admin.close();            status = true;        } catch (MasterNotRunningException e) {            LOG.error("HBase  master  未运行 。 ", e);        } catch (ZooKeeperConnectionException e) {            LOG.error("zooKeeper 连接异常。 ", e);        } catch (IOException e) {            LOG.error("", e);        }        return status;    }    /**     * 清空表     * @param tableName     * @return     */    public static boolean truncateTable(String tableName){        boolean status = false;        TableName name = TableName.valueOf(tableName);        try {            Admin admin = conf.getHconnection().getAdmin();            if(admin.tableExists(name)){                if(admin.isTableAvailable(name)){                    admin.disableTable(name);                }                admin.truncateTable(name, true);            }else{                LOG.warn(" HBase中不存在 表 " + tableName);            }            admin.close();            status = true;        } catch (MasterNotRunningException e) {            LOG.error("HBase  master  未运行 。 ", e);        } catch (ZooKeeperConnectionException e) {            LOG.error("zooKeeper 连接异常。 ", e);        } catch (IOException e) {            LOG.error("", e);        }        return status;    }    /**     * 创建HBase表     * @param tableName     * @param cf       列族名     * @param inMemory     * @param ttl    ttl &lt; 0     则为永久保存     */    public static boolean createTable(String tableName, String cf, boolean inMemory, int ttl, int maxVersion){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, COPROCESSORCLASSNAME);        return createTable(htd);    }    public static boolean createTable(String tableName, String cf, boolean inMemory, int ttl, int maxVersion,  boolean useSNAPPY){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, useSNAPPY , COPROCESSORCLASSNAME);        return createTable(htd);    }    public static boolean createTable(String tableName, String cf, boolean inMemory, int ttl, int maxVersion,  boolean useSNAPPY, byte[][] splits){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, useSNAPPY, COPROCESSORCLASSNAME);        return createTable(htd , splits);    }    /**     * @param tableName    表名     * @param cf           列簇     * @param inMemory     是否存在内存     * @param ttl          数据过期时间     * @param maxVersion   最大版本     * @param splits       分区     * @return     */    public static boolean createTable(String tableName,                                      String cf,                                      boolean inMemory,                                      int ttl,                                      int maxVersion,                                      byte[][] splits){        //返回表说明        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, COPROCESSORCLASSNAME);        //通过HTableDescriptor 和 splits 分区策略来定义表        return createTable(htd , splits);    }    public static List&lt;String&gt; listTables(){        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            TableName[] listTableNames = admin.listTableNames();            for( TableName t :  listTableNames ){                list.add( t.getNameAsString() );            }        } catch(IOException e )  {            LOG.error("创建HBase表失败。", e);        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return list;    }    /**     * 列出所有表     * @param reg     * @return     */    public static List&lt;String&gt; listTables(String reg){        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            TableName[] listTableNames = admin.listTableNames(reg);            for(TableName t :  listTableNames){                list.add(t.getNameAsString());            }        } catch(IOException e)  {            LOG.error("创建HBase表失败。", e);        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return list;    }    /**     * 创建HBase表     * @param tableName     * @param cf       列族名     * @param inMemory     * @param ttl      ttl &lt; 0     则为永久保存     */    public static boolean  createTable(String tableName, String cf, boolean inMemory, int ttl , int maxVersion, String ... coprocessorClassNames){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, coprocessorClassNames);        return createTable(htd);    }    public static boolean  createTable( String tableName, String cf, boolean inMemory, int ttl, int maxVersion, boolean useSNAPPY, String ... coprocessorClassNames){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, useSNAPPY, coprocessorClassNames);        return createTable(htd);    }    public static boolean  createTable( String tableName,String cf,boolean inMemory, int ttl ,int maxVersion ,  boolean useSNAPPY ,byte[][] splits, String ... coprocessorClassNames){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, useSNAPPY ,coprocessorClassNames);        return createTable(htd,splits );    }    public static boolean  createTable(String tableName, String cf, boolean inMemory, int ttl, int maxVersion, byte[][] splits, String ... coprocessorClassNames){        HTableDescriptor htd = createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, coprocessorClassNames);        return createTable(htd,splits );    }    /**     * 通过HTableDescriptor 和 分区 来构建hbase     * @param htd     * @param splits     * @return     */    public static boolean createTable(HTableDescriptor htd, byte[][] splits){        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            TableName tableName = htd.getTableName();            boolean exist = admin.tableExists(tableName);            if(exist){                LOG.error("表"+tableName.getNameAsString() + "已经存在");            }else{                //使用Admin进行创建表                admin.createTable(htd, splits);            }        } catch(IOException e )  {            LOG.error("创建HBase表失败。", e);            return false;        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return true;    }    public static boolean createTable(HTableDescriptor htd){        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            if(admin.tableExists(htd.getTableName())){                LOG.info("表" + htd.getTableName() + "已经存在");            }else{                admin.createTable(htd);            }        } catch(IOException e )  {            LOG.error("创建HBase表失败。", e);            return false;        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return true;    }    /**     * 创建命名空间     * @param nameSpace     * @return     */    public static boolean createNameSpace(String nameSpace){        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            NamespaceDescriptor[] listNamespaceDescriptors = admin.listNamespaceDescriptors();            boolean exist = false;            for(NamespaceDescriptor namespaceDescriptor : listNamespaceDescriptors){                if(namespaceDescriptor.getName().equals(nameSpace)){                    exist = true;                }            }            if(!exist) admin.createNamespace(NamespaceDescriptor.create(nameSpace).build());        } catch(IOException e )  {            LOG.error("创建HBase命名空间失败。", e);            return false;        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return true;    }    /**     * 为 HBase中的表  tableName添加 协处理器  coprocessorClassName     * @param tableName     * @param coprocessorClassName    必须是已经存在与HBase集群中     * @return  boolean     */    public static boolean addCoprocessorClassForTable(String tableName,String coprocessorClassName){        boolean status = false;        TableName name = TableName.valueOf(tableName);        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            HTableDescriptor htd = admin.getTableDescriptor(name);            if(!htd.hasCoprocessor(coprocessorClassName)){                htd.addCoprocessor(coprocessorClassName);                admin.disableTable(name);                admin.modifyTable(name, htd);                admin.enableTable(name);            }else{                LOG.warn(String.format("表 %s中已经存在协处理器%s", tableName, coprocessorClassName));            }            status = true;        } catch (MasterNotRunningException e) {            LOG.error("HBase  master  未运行 。 ", e);        } catch (ZooKeeperConnectionException e) {            LOG.error("zooKeeper 连接异常。 ", e);        } catch (IOException e) {            LOG.error("", e);        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return status;    }    /**     * 为HBase中的表 tableName添加指定位置的 协处理器 jar     * @param tableName     * @param coprocessorClassName   jar中的具体的协处理器     * @param jarPath     hdfs的路径     * @param level       执行级别     * @param kvs         运行参数    可以为 null     * @return   boolean     */    public static boolean addCoprocessorJarForTable(String  tableName, String coprocessorClassName,String jarPath,int level ,Map&lt;String, String&gt; kvs ){        boolean status = false;        TableName name = TableName.valueOf(tableName);        Admin admin = null;        try {            admin = conf.getHconnection().getAdmin();            HTableDescriptor htd = admin.getTableDescriptor(name);            if(!htd.hasCoprocessor(coprocessorClassName)){                admin.disableTable(name);                htd.addCoprocessor(coprocessorClassName, new Path(jarPath), level, kvs);                admin.modifyTable(name, htd);                admin.enableTable(name);            }else{                LOG.warn(String.format("表 %s中已经存在协处理器%s", tableName, coprocessorClassName));            }            status = true;        } catch (MasterNotRunningException e) {            LOG.error("HBase  master  未运行 。 ", e);        } catch (ZooKeeperConnectionException e) {            LOG.error("zooKeeper 连接异常。 ", e);        } catch (IOException e) {            LOG.error("", e);        }finally{            try {                if(admin!=null){                    admin.close();                }            } catch (IOException e) {                LOG.error("", e);            }        }        return status;    }    /**     * @param tableName     * @param cf     * @param inMemory     * @param ttl     * @param maxVersion     * @param coprocessorClassNames     * @return     */    public static HTableDescriptor createHTableDescriptor( String tableName,String cf,boolean inMemory, int ttl ,int maxVersion ,String ... coprocessorClassNames ){        return createHTableDescriptor(tableName, cf, inMemory, ttl, maxVersion, true , COPROCESSORCLASSNAME);    }    /**     * @param tableName     * @param cf     * @param inMemory     * @param ttl     * @param maxVersion     * @param useSNAPPY     * @param coprocessorClassNames     * @return     */    public static HTableDescriptor createHTableDescriptor( String tableName,String cf,boolean inMemory, int ttl ,int maxVersion , boolean useSNAPPY , String ... coprocessorClassNames ){        // 1.创建命名空间        String[] split = tableName.split(":");        if(split.length==2){            createNameSpace(split[0]);        }        // 2.添加协处理器        HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(tableName));        for( String coprocessorClassName : coprocessorClassNames ){            try {                htd.addCoprocessor(coprocessorClassName);            } catch (IOException e1) {                LOG.error("为表" + tableName + " 添加协处理器失败。 ", e1);            }        }        // 创建HColumnDescriptor        HColumnDescriptor hcd = new HColumnDescriptor(cf);        if( maxVersion &gt; 0 )            //定义最大版本号            hcd.setMaxVersions(maxVersion);        /**         * 设置布隆过滤器         * 默认是NONE 是否使用布隆过虑及使用何种方式         * 布隆过滤可以每列族单独启用         * Default = ROW 对行进行布隆过滤。         * 对 ROW，行键的哈希在每次插入行时将被添加到布隆。         * 对 ROWCOL，行键 + 列族 + 列族修饰的哈希将在每次插入行时添加到布隆         * 使用方法: create ‘table’,{BLOOMFILTER =&gt;’ROW’}         * 启用布隆过滤可以节省读磁盘过程，可以有助于降低读取延迟         * */        hcd.setBloomFilterType(BloomType.ROWCOL);        /**         * hbase在LRU缓存基础之上采用了分层设计，整个blockcache分成了三个部分，分别是single、multi和inMemory。三者区别如下：         * single：如果一个block第一次被访问，放在该优先队列中；         * multi：如果一个block被多次访问，则从single队列转移到multi队列         * inMemory：优先级最高，常驻cache，因此一般只有hbase系统的元数据，如meta表之类的才会放到inMemory队列中。普通的hbase列族也可以指定IN_MEMORY属性，方法如下：         * create 'table', {NAME =&gt; 'f', IN_MEMORY =&gt; true}         * 修改上表的inmemory属性，方法如下：         * alter 'table',{NAME=&gt;'f',IN_MEMORY=&gt;true}         * */        hcd.setInMemory(inMemory);        hcd.setScope(1);        /**         * 数据量大，边压边写也会提升性能的，毕竟IO是大数据的最严重的瓶颈，         * 哪怕使用了SSD也是一样。众多的压缩方式中，推荐使用SNAPPY。从压缩率和压缩速度来看，         * 性价比最高。         **/        if(useSNAPPY)hcd.setCompressionType(Compression.Algorithm.SNAPPY);        //默认为NONE        //如果数据存储时设置了编码， 在缓存到内存中的时候是不会解码的，这样和不编码的情况相比，相同的数据块，编码后占用的内存更小， 即提高了内存的使用率        //如果设置了编码，用户必须在取数据的时候进行解码， 因此在内存充足的情况下会降低读写性能。        //在任何情况下开启PREFIX_TREE编码都是安全的        //不要同时开启PREFIX_TREE和SNAPPY        //通常情况下 SNAPPY并不能比 PREFIX_TREE取得更好的优化效果        //hcd.setDataBlockEncoding(DataBlockEncoding.PREFIX_TREE);        //默认为64k     65536        //随着blocksize的增大， 系统随机读的吞吐量不断的降低，延迟也不断的增大，        //64k大小比16k大小的吞吐量大约下降13%，延迟增大13%        //128k大小比64k大小的吞吐量大约下降22%，延迟增大27%        //对于随机读取为主的业务，可以考虑调低blocksize的大小        //随着blocksize的增大， scan的吞吐量不断的增大，延迟也不断降低，        //64k大小比16k大小的吞吐量大约增加33%，延迟降低24%        //128k大小比64k大小的吞吐量大约增加7%，延迟降低7%        //对于scan为主的业务，可以考虑调大blocksize的大小        //如果业务请求以Get为主，则可以适当的减小blocksize的大小        //如果业务是以scan请求为主，则可以适当的增大blocksize的大小        //系统默认为64k, 是一个scan和get之间取的平衡值        //hcd.setBlocksize(s)        //设置表中数据的存储生命期，过期数据将自动被删除，        // 例如如果只需要存储最近两天的数据，        // 那么可以设置setTimeToLive(2 * 24 * 60 * 60)        if( ttl &lt; 0 ) ttl = HConstants.FOREVER;        hcd.setTimeToLive(ttl);        htd.addFamily( hcd);        return htd;    }    public static boolean createTable(HBaseTableParam param){        String nameSpace = param.getNameSpace();        if(!"default".equalsIgnoreCase(nameSpace)){            checkArgument(createNameSpace(nameSpace), String.format("创建命名空间%s失败。", nameSpace));        }        HTableDescriptor desc = createHTableDescriptor(param);        byte[][] splits = param.getSplits();        if(splits == null){            return createTable(desc);        }else{            return createTable(desc, splits);        }    }    public static HTableDescriptor createHTableDescriptor(HBaseTableParam param){        String tableName = String.format("%s:%s", param.getNameSpace(), param.getTableName());        HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(tableName));        for(String coprocessorClassName : param.getCoprocessorClazz()){            try {                htd.addCoprocessor(coprocessorClassName);            } catch (IOException e) {                LOG.error(String.format("为表  %s 添加协处理器失败。", tableName), e);            }        }        HColumnDescriptor hcd = new HColumnDescriptor(param.getCf());        hcd.setBloomFilterType(param.getBloomType());        hcd.setMaxVersions(param.getMaxVersions());        hcd.setScope(param.getReplicationScope());        hcd.setBlocksize(param.getBlocksize());        hcd.setInMemory(param.isInMemory());        hcd.setTimeToLive(param.getTtl());        /* 数据量大，边压边写也会提升性能的，毕竟IO是大数据的最严重的瓶颈，哪怕使用了SSD也是一样。众多的压缩方式中，推荐使用SNAPPY。从压缩率和压缩速度来看，性价比最高。  */        if(param.isUsePrefix_tree())hcd.setDataBlockEncoding(DataBlockEncoding.PREFIX_TREE);        if(param.isUseSnappy())hcd.setCompressionType(Compression.Algorithm.SNAPPY);        htd.addFamily( hcd);        return htd;    }    public static void closeTable( Table table ){        if( table != null ){            try {                table.close();            } catch (IOException e) {                LOG.error(" ", e);            }            table = null;        }    }    public static byte[][] getSplitKeys() {        //String[] keys = new String[]{"50|"};        //String[] keys = new String[]{"25|","50|","75|"};        //String[] keys = new String[]{"13|","26|","39|", "52|","65|","78|","90|"};        String[] keys = new String[]{ "06|","13|","20|", "26|","33|", "39|","46|", "52|","58|", "65|","72|","78|", "84|","90|","95|"};        //String[] keys = new String[]{"10|", "20|", "30|", "40|", "50|", "60|", "70|", "80|", "90|"};        byte[][] splitKeys = new byte[keys.length][];        TreeSet&lt;byte[]&gt; rows = new TreeSet&lt;byte[]&gt;(Bytes.BYTES_COMPARATOR);//升序排序        for (int i = 0; i &lt; keys.length; i++) {            rows.add(Bytes.toBytes(keys[i]));        }        Iterator&lt;byte[]&gt; rowKeyIter = rows.iterator();        int i = 0;        while (rowKeyIter.hasNext()) {            byte[] tempRow = rowKeyIter.next();            rowKeyIter.remove();            splitKeys[i] = tempRow;            i++;        }        return splitKeys;    }    public static class HBaseTableParam{        private final String nameSpace; //命名空间        private final String tableName; //表名        private final String cf;        //列簇        private Set&lt;String&gt;  coprocessorClazz = Sets.newHashSet("org.apache.hadoop.hbase.coprocessor.AggregateImplementation");        private int maxVersions = 1;    //版本号 默认为1        private BloomType bloomType = BloomType.ROWCOL;        private boolean inMemory = false;        private int replicationScope = 1;        private boolean useSnappy = false; //默认不使用压缩        private boolean usePrefix_tree = false;        private int blocksize = 65536;        private int ttl = HConstants.FOREVER;        private byte[][] splits;        public HBaseTableParam(String nameSpace, String tableName, String cf) {            super();            this.nameSpace = nameSpace == null ? "default" : nameSpace;            this.tableName = tableName;            this.cf = cf;        }        public String getNameSpace() {            return nameSpace;        }        public String getTableName() {            return tableName;        }        public String getCf() {            return cf;        }        public Set&lt;String&gt; getCoprocessorClazz() {            return coprocessorClazz;        }        public void clearCoprocessor(){            coprocessorClazz.clear();        }        public void addCoprocessorClazz(String clazz) {            this.coprocessorClazz.add(clazz);        }        public void addCoprocessorClazz(String ... clazz) {            addCoprocessorClazz(Arrays.asList(clazz));        }        public void addCoprocessorClazz(Collection&lt;String&gt;  clazz) {            this.coprocessorClazz.addAll(clazz);        }        public int getMaxVersions() {            return maxVersions;        }        public void setMaxVersions(int maxVersions) {            this.maxVersions = maxVersions &lt;= 0 ? 1 : maxVersions;        }        public BloomType getBloomType() {            return bloomType;        }        public void setBloomType(BloomType bloomType) {            this.bloomType = bloomType == null ? BloomType.ROWCOL : bloomType;        }        public boolean isInMemory() {            return inMemory;        }        public void setInMemory(boolean inMemory) {            this.inMemory = inMemory;        }        public int getReplicationScope() {            return replicationScope;        }        public void setReplicationScope(int replicationScope) {            this.replicationScope = replicationScope &lt; 0 ? 1 : replicationScope;        }        public boolean isUseSnappy() {            return useSnappy;        }        /**         * 控制是否使用 snappy 压缩数据， 默认是不启用         * @param useSnappy         */        public void setUseSnappy(boolean useSnappy) {            this.useSnappy = useSnappy;        }        public boolean isUsePrefix_tree() {            return usePrefix_tree;        }        /**         * 控制是否使用数据编码，默认是不使用         *         * 如果数据存储时设置了编码， 在缓存到内存中的时候是不会解码的，这样和不编码的情况相比，相同的数据块，编码后占用的内存更小， 即提高了内存的使用率         * 如果设置了编码，用户必须在取数据的时候进行解码， 因此在内存充足的情况下会降低读写性能。         * 在任何情况下开启PREFIX_TREE编码都是安全的         * 不要同时开启PREFIX_TREE和SNAPPY         * 通常情况下 SNAPPY并不能比 PREFIX_TREE取得更好的优化效果         */        public void setUsePrefix_tree(boolean usePrefix_tree) {            this.usePrefix_tree = usePrefix_tree;        }        public int getBlocksize() {            return blocksize;        }        /**         *默认为64k     65536         *随着blocksize的增大， 系统随机读的吞吐量不断的降低，延迟也不断的增大，         *64k大小比16k大小的吞吐量大约下降13%，延迟增大13%         *128k大小比64k大小的吞吐量大约下降22%，延迟增大27%         *对于随机读取为主的业务，可以考虑调低blocksize的大小         *         *随着blocksize的增大， scan的吞吐量不断的增大，延迟也不断降低，         *64k大小比16k大小的吞吐量大约增加33%，延迟降低24%         *128k大小比64k大小的吞吐量大约增加7%，延迟降低7%         *对于scan为主的业务，可以考虑调大blocksize的大小         *         *如果业务请求以Get为主，则可以适当的减小blocksize的大小         *如果业务是以scan请求为主，则可以适当的增大blocksize的大小         *系统默认为64k, 是一个scan和get之间取的平衡值         *         */        public void setBlocksize(int blocksize) {            this.blocksize = blocksize &lt;= 0 ? 65536 : blocksize;        }        public int getTtl() {            return ttl;        }        /**         * 默认是永久保存         * @param ttl  大于 零的整数，  &lt;= 0 ? tt 为  永久保存         */        public void setTtl(int ttl) {            this.ttl = ttl &lt;= 0 ? HConstants.FOREVER : ttl;        }        public byte[][] getSplits() {            return splits;        }        /*         * 预分区的rowKey范围配置         * @param splits         */        /*        public void setSplits(byte[][] splits) {            this.splits = splits;        }*/    }    public static void main(String[] args) throws Exception{        Admin admin = conf.getHconnection().getAdmin();        System.out.println(admin);        //deleteTable("test:user");        // HBaseTableUtil.createTable("aaaaa","info1",true,-1,1);        //  HBaseTableUtil.truncateTable("aaaaa");     /*   boolean b = tableExists("test:user2");        Table table = getTable("test:user2");        System.out.println("=================="+table);        System.out.println("=================="+table.getName());*/        //HBaseTableUtil.deleteTable("aaaaa");       /* Table table = HBaseTableUtil.getTable("countform:typecount");        System.out.println(table);*//*        boolean b = HBaseTableUtil.tableExists("countform:typecount");        System.out.println(b);*/        HBaseTableUtil.deleteTable("tanslator");        HBaseTableUtil.deleteTable("ability");        HBaseTableUtil.deleteTable("task");        HBaseTableUtil.deleteTable("paper");        //  HbaseSearchService hbaseSearchService=new HbaseSearchService();        //  Map&lt;String, String&gt; stringStringMap = hbaseSearchService.get("countform:bsid","", new BaseMapRowExtrator());        // Map&lt;String, String&gt; aaaaa = hbaseSearchService.get("countform:bsid", "aaaaa", new BaseMapRowExtrator());        // System.out.println(aaaaa);    }}</code></pre><p><strong>com/hsiehchou/hbase/entity/AbstractRow.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.entity;import com.google.common.collect.HashMultimap;import com.google.common.collect.Sets;import java.util.Collection;import java.util.Map;import java.util.Set;public abstract class AbstractRow&lt;T extends HBaseCell&gt; {protected String rowKey;protected HashMultimap&lt;String, T&gt; cells;    protected Set&lt;String&gt; fields;protected long maxCapTime;public AbstractRow(String rowKey){this.rowKey = rowKey;cells = HashMultimap.create();        fields = Sets.newHashSet();    }public boolean addCell(String field, String value, long capTime){return addCell(field, createCell(field, value, capTime));}public boolean addCell(String field, T cell){        fields.add(cell.getField());if(cell.getCapTime() &gt; maxCapTime)maxCapTime = cell.getCapTime();return cells.put(field, cell);}public boolean[] addCell(String field, Collection&lt;T&gt; cells){boolean[] status = new boolean[cells.size()];int n = 0;for(T cell : cells){status[n] = addCell(field, cell);n++;}return status;}public String getRowKey() {return rowKey;}protected abstract T createCell(String field, String value, long capTime);public Map&lt;String, Collection&lt;T&gt;&gt; getCell() {return cells.asMap();}public Collection&lt;T&gt; getCellByField(String field){return cells.get(field);}public Set&lt;Map.Entry&lt;String, T&gt;&gt; entries(){return  cells.entries();}@Overridepublic String toString() {return "AbstractRow [rowKey=" + rowKey + ", cells=" + cells + "]";}public boolean equals(Object obj) {   if(this == obj)return true ;   if(!(obj instanceof AbstractRow))return false ;   @SuppressWarnings("unchecked")   AbstractRow&lt;T&gt; row = (AbstractRow&lt;T&gt;) obj;   if(rowKey.equals(row.getRowKey()))return true;   return false;}public int hashCode(){return this.rowKey.hashCode();}public long getMaxCapTime() {return maxCapTime;}    public Set&lt;String&gt; getFields() {        return Sets.newHashSet(fields);    }}</code></pre><p><strong>com/hsiehchou/hbase/entity/HBaseCell.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.entity;public class HBaseCell implements Comparable&lt;HBaseCell&gt;{protected String field;           protected String value;protected Long capTime;public HBaseCell(String field, String value, long capTime){this.field = field;this.capTime = capTime;this.value = value;}public String getField(){return field;}public String getValue(){return value;}public void setCapTime(long capTime) {this.capTime = capTime;}public Long getCapTime() {return capTime;}public String toString(){return String.format("%s_[%s]_%s", field, capTime, value);}public int compareTo(HBaseCell o) {return o.getCapTime().compareTo(this.capTime);}public boolean equals(Object obj) {   if(this == obj)return true ;   if(!(obj instanceof HBaseCell))return false ;   HBaseCell cell = (HBaseCell)obj;   if(field.equals(cell.getField()) &amp;&amp; value.equals(cell.getValue())){   if(cell.getCapTime() &lt; capTime){   cell.setCapTime(this.capTime);   }   return true;   }   return false;}public int hashCode(){return this.field.hashCode() +  31*this.value.hashCode();}}</code></pre><p><strong>com/hsiehchou/hbase/entity/HBaseRow.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.entity;public class HBaseRow extends AbstractRow&lt;HBaseCell&gt; {public HBaseRow(String rowKey){super(rowKey);}public boolean[] addCell(String field, HBaseCell ... cells){boolean[] status = new boolean[cells.length];for(int i = 0; i &lt; cells.length; i++){status[i] = addCell(field, cells[i]);}return status;}protected HBaseCell createCell(String field, String value, long capTime) {return new HBaseCell(field, value, capTime);}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/BaseListRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.ArrayList;import java.util.List;public class BaseListRowExtrator implements RowExtractor&lt;List&lt;String&gt;&gt;{private List&lt;String&gt; row;public Long lastcjtime = 0l;public Long firstcjtime = 0l;@Overridepublic List&lt;String&gt; extractRowData(Result result, int rowNum)throws IOException {row = new ArrayList&lt;String&gt;();for(Cell cell :  result.listCells()) {String column = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());if(column.equalsIgnoreCase("cjtime")) {Long v = Long.parseLong(value);if(lastcjtime &lt; v) {lastcjtime = v;}else if(firstcjtime &gt; v) {firstcjtime = v;}}row.add(value);}return row;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/BaseMapRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.HashMap;import java.util.List;import java.util.Map;public class BaseMapRowExtrator implements RowExtractor&lt;Map&lt;String,String&gt;&gt; {private Map&lt;String,String&gt; row;private List&lt;byte[]&gt; rows;private String longTimeField;private SimpleDateFormat format;private String field;private String value;private long time;public BaseMapRowExtrator(){}/** * @param rows   需要提取 所有的 rowKey  , null 则不提取 */public BaseMapRowExtrator(List&lt;byte[]&gt; rows){this.rows = rows;}/** * @param rows             需要提取 所有的 rowKey  , null 则不提取 * @param longTimeField    long类型的时间字段   表示需要将其转换称 String 类型 */public BaseMapRowExtrator(List&lt;byte[]&gt; rows,String longTimeField){this.rows = rows;this.longTimeField = longTimeField;}/** * @param rows                  需要提取 所有的 rowKey  , null 则不提取 * @param longTimeField         long类型的时间字段 * @param timePattern           表示需要已该指定的格式  将时间字段的值转换成字符串 */public BaseMapRowExtrator(List&lt;byte[]&gt; rows,String longTimeField,String timePattern){this.rows = rows;this.longTimeField = longTimeField;if(StringUtils.isNotBlank(timePattern)){format = new SimpleDateFormat(timePattern);}}public Map&lt;String, String&gt; extractRowData(Result result, int rowNum) throws IOException {row = new HashMap&lt;String,String&gt;();List&lt;Cell&gt; cells = result.listCells();for(Cell cell :  cells) {field = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());if( field.equals(longTimeField)  ){time = Bytes.toLong(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());if( format != null ){value = format.format(new Date(time));}else{value = String.valueOf(time);}}else{value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());}row.put(field,value);}if( rows != null ){rows.add(result.getRow());}return row;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/BaseMapWithRowKeyExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.HashMap;import java.util.Map;public class BaseMapWithRowKeyExtrator implements RowExtractor&lt;Map&lt;String,String&gt;&gt; {private Map&lt;String,String&gt; row;/* (non-Javadoc) * @see com.bh.d406.bigdata.hbase.extractor.RowExtractor#extractRowData(org.apache.hadoop.hbase.client.Result, int) */@Overridepublic Map&lt;String, String&gt; extractRowData(Result result, int rowNum)throws IOException {row = new HashMap&lt;String,String&gt;();row.put("rowKey", Bytes.toString( result.getRow() ));for(Cell cell :  result.listCells()) {row.put(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()),Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));}return row;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/BeanRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import com.google.common.collect.Maps;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.lang.reflect.Field;import java.util.Map;public class BeanRowExtrator&lt;T&gt; implements RowExtractor&lt;T&gt; {private static final Logger LOG = LoggerFactory.getLogger(BeanRowExtrator.class);private Class&lt;T&gt; clazz;private Map&lt;String,Field&gt; fieldMap;public BeanRowExtrator(Class&lt;T&gt; clazz){this.clazz = clazz;this.fieldMap = getDeclaredFields(clazz);}public T extractRowData(Result result, int rowNum) throws IOException {return resultReflectToClass(result, rowNum);}private T resultReflectToClass(Result result, int rowNum){String column = null;Field field = null;T obj = null;try {obj = clazz.newInstance();for(Cell cell : result.listCells()){column = Bytes.toString(cell.getQualifierArray(),cell.getQualifierOffset(), cell.getQualifierLength());/*检查该列是否在实体类中存在对应的属性,若存在则 为其赋值*/if((field = fieldMap.get(column.toLowerCase())) != null){field.set(obj, Bytes.toString(cell.getValueArray(),cell.getValueOffset(), cell.getValueLength()));}}} catch (InstantiationException e) {LOG.error(String.format("解析第%个满足条件的记录%s失败。", rowNum, result), e);} catch (IllegalAccessException e) {LOG.error(String.format("解析第%s个满足条件的记录%s失败。", rowNum, result), e);}return obj;}private  Map&lt;String,Field&gt;  getDeclaredFields(Class&lt;?&gt; clazz){Field[] fields = clazz.getDeclaredFields();Field field = null;Map&lt;String,Field&gt; fieldMap = Maps.newHashMapWithExpectedSize(fields.length);for(int i = 0; i &lt; fields.length; i++){field = fields[i];if(field.getModifiers() == 2){field.setAccessible(true);fieldMap.put(field.getName().toLowerCase(), field);}}fields = null;return fieldMap;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/CellNumExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.client.Result;import java.io.IOException;public class CellNumExtrator implements RowExtractor&lt;Integer&gt; {public Integer extractRowData(Result result, int rowNum) throws IOException {return  result.listCells().size();}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/MapLongRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.HashMap;import java.util.Map;public class MapLongRowExtrator implements RowExtractor&lt;Map&lt;String,Long&gt;&gt; {private Map&lt;String,Long&gt; row;@Overridepublic Map&lt;String, Long&gt; extractRowData(Result result, int rowNum) throws IOException {row = new HashMap&lt;String,Long&gt;();for(Cell cell :  result.listCells()) {row.put(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()),Bytes.toLong(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));}return row;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/MapRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.io.Serializable;import java.util.HashMap;import java.util.Map;public class MapRowExtrator implements RowExtractor&lt;Map&lt;String,String&gt;&gt;,Serializable {private static final long serialVersionUID = 1543027485077396235L;private Map&lt;String,String&gt; row;/* (non-Javadoc) * @see com.bh.d406.bigdata.hbase.extractor.RowExtractor#extractRowData(org.apache.hadoop.hbase.client.Result, int) */@Overridepublic Map&lt;String, String&gt; extractRowData(Result result, int rowNum) throws IOException {row = new HashMap&lt;String,String&gt;();for(Cell cell :  result.listCells()) {row.put(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()),Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));}return row;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/MultiVersionRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import com.hsiehchou.hbase.entity.HBaseRow;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;public class MultiVersionRowExtrator implements RowExtractor&lt;HBaseRow&gt;{private HBaseRow row;public HBaseRow extractRowData(Result result, int rowNum) throws IOException {row = new HBaseRow(Bytes.toString(result.getRow()));String field = null;String value = null;long capTime = 0L;for(Cell cell : result.listCells()){field = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());capTime = cell.getTimestamp();row.addCell(field, value, capTime);}return  row ;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/OneColumnRowByteExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.client.Result;import java.io.IOException;import java.io.Serializable;public class OneColumnRowByteExtrator implements RowExtractor&lt;byte[]&gt; ,Serializable{private static final long serialVersionUID = -3420092335124240222L;private byte[] cf;private byte[] cl;public OneColumnRowByteExtrator( byte[] cf,byte[] cl ){this.cf = cf;this.cl = cl;}public byte[] extractRowData(Result result, int rowNum) throws IOException {return result.getValue(cf, cl);}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/OneColumnRowStringExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.io.Serializable;public class OneColumnRowStringExtrator implements RowExtractor&lt;String&gt;  , Serializable{private static final long serialVersionUID = -8585637277902568648L;private byte[] cf ;private byte[] cl ;public OneColumnRowStringExtrator( byte[] cf , byte[] cl ){this.cf = cf;this.cl = cl;}/* (non-Javadoc) * @see com.bh.d406.bigdata.hbase.extractor.RowExtractor#extractRowData(org.apache.hadoop.hbase.client.Result, int) */@Overridepublic String extractRowData(Result result, int rowNum) throws IOException {byte[] value = result.getValue(cf, cl);if( value == null ) return null;return  Bytes.toString( value ) ;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/OnlyRowKeyExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.client.Result;import java.io.IOException;public class OnlyRowKeyExtrator implements RowExtractor&lt;byte[]&gt; {@Overridepublic byte[] extractRowData(Result result, int rowNum) throws IOException {// TODO Auto-generated method stubreturn result.getRow();}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/OnlyRowKeyStringExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;public class OnlyRowKeyStringExtrator implements RowExtractor&lt;String&gt; {public String extractRowData(Result result, int rowNum) throws IOException {return Bytes.toString( result.getRow() );}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/RowExtractor.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.client.Result;import java.io.IOException;public interface RowExtractor&lt;T&gt;  {/**  * description:  * @param result  result解析器  * @param rowNum    * @return  * @throws Exception  * T */T extractRowData(Result result, int rowNum) throws IOException;}</code></pre><p><strong>com/hsiehchou/hbase/extractor/SingleColumnMultiVersionRowExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.Set;public class SingleColumnMultiVersionRowExtrator implements RowExtractor&lt;Set&lt;String&gt;&gt;{private Set&lt;String&gt; values;private byte[] cf;private byte[] cl;/** * 单列解析器  获取hbase 单列多版本数据 * @param cf     列簇 * @param cl     列 * @param values 返回值 */public SingleColumnMultiVersionRowExtrator(byte[] cf, byte[] cl, Set&lt;String&gt; values){this.cf = cf;this.cl = cl;this.values = values;}public Set&lt;String&gt; extractRowData(Result result, int rowNum) throws IOException {for(Cell cell : result.getColumnCells(cf, cl)){values.add(Bytes.toString(cell.getValueArray(),cell.getValueOffset(), cell.getValueLength()));}return values;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/StrToByteExtrator.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.io.Serializable;import java.util.HashMap;import java.util.Map;public class StrToByteExtrator implements RowExtractor&lt;Map&lt;String,byte[]&gt;&gt; ,Serializable {private static final long serialVersionUID = 4633698173362569711L;private Map&lt;String,byte[]&gt; row;@Overridepublic Map&lt;String, byte[]&gt; extractRowData(Result result, int rowNum) throws IOException {row = new HashMap&lt;String,byte[]&gt;();for(Cell cell :  result.listCells()) {row.put(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()),Bytes.copy(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));}return row;}}</code></pre><p><strong>com/hsiehchou/hbase/extractor/ToRowList.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;/** * Hbase数据库中数据提取接口实现： * 提取result的rowKey，和每个cell的值作为一行数据， * 一个cell=(row, family:qualifier:value, version) * * &lt;p&gt; * 每行数据的格式为：{rowKey column${separator}value column${separator}value ...} * 其中，不同的列之间用空格分隔，同样列元素的描述符与值之间用${separator}分隔 */public class ToRowList implements RowExtractor&lt;List&lt;String&gt;&gt; {    private Boolean currentVersion; //currentVersion为true:只取当前最新版本，false:取所有版本    private char separator; //不同元素之间拼接时的分隔符，默认为`#`    private ToRowList(Boolean currentVersion, char separator) {        this.separator = separator;        this.currentVersion = currentVersion;    }    public ToRowList(Boolean currentVersion) {        this(currentVersion, '#');    }    public ToRowList() {        this(true, '#');    }    /**      * 对{当前版本}存放在list[0] = {rowKey` `column`#`value` `column`#`value ...}      * 多版本的时候list({rowKey`#`version1` `column`#`value` `column`#`value ...},      * {rowKey`#`version2` `column`#`value` `column`#`value ...})      */    @Override    public List&lt;String&gt; extractRowData(Result result, int rowNum) throws IOException {        if(result == null || result.isEmpty()) return null;        final char SPACE = ' ';        List&lt;String&gt; rows = new LinkedList&lt;&gt;();        //一个result是同一个rowKey的所有cells集合        String rowKey = Bytes.toString(result.getRow());        //build rowKey` `column`#`value` `column`#`value ...        StringBuilder row = new StringBuilder();        row.append(rowKey).append(SPACE);        //用于处理不同版本的映射        Map&lt;Long, String&gt; version2qualifiersAndValues = new HashMap&lt;&gt;();        List&lt;Cell&gt; cells = result.listCells();        for (Cell cell : cells) {            String value = Bytes.toString(cell.getValueArray(),                    cell.getValueOffset(), cell.getValueLength());            String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));            if (currentVersion) {                row.append(qualifier).append(separator).append(value).append(SPACE);            } else {                Long version = cell.getTimestamp();                String tmp = version2qualifiersAndValues.get(version);                version2qualifiersAndValues.put(version,                        StringUtils.isNotBlank(tmp) ? tmp + " " + qualifier + separator + value                                : rowKey + separator + version + " " + qualifier + separator + value);            }        }        if (currentVersion) {            rows.add(row.toString());        } else {            for (String v : version2qualifiersAndValues.values()) {                rows.add(v);            }        }        return rows;    }}</code></pre><p><strong>com/hsiehchou/hbase/extractor/ToRowMap.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.extractor;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.HashMap;import java.util.Map;/** * currentVersion 标识是否取多版本的数据，默认取当前版本 * 对当前版本，返回row`#`qualifier-&gt;value的映射 * 对多个版本，返回row`#`version`#`qualifier-&gt;value的映射 */public class ToRowMap implements RowExtractor&lt;Map&lt;String, String&gt;&gt; {    private Boolean currentVersion;    public ToRowMap() {        this(true);    }    private ToRowMap(Boolean currentVersion) {        this.currentVersion = currentVersion;    }    @Override    public Map&lt;String, String&gt; extractRowData(Result result, int rowNum)            throws IOException {        if(result == null || result.isEmpty()) return null;        final char HashTag = '#';        HashMap&lt;String, String&gt; col2value = new HashMap&lt;&gt;();        String rowKey = Bytes.toString(result.getRow());        for (Cell cell : result.listCells()) {            String value = Bytes.toString(cell.getValueArray(),                    cell.getValueOffset(), cell.getValueLength());            String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));            if (currentVersion)                col2value.put(rowKey + HashTag + qualifier, value);            else {                long version = cell.getTimestamp();                col2value.put(rowKey + HashTag + version + HashTag + qualifier, value);            }        }        return col2value;    }}</code></pre><p><strong>com/hsiehchou/hbase/insert/HBaseInsertException.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.insert;import java.util.Iterator;public class HBaseInsertException extends Exception{    public HBaseInsertException(String message) {        super(message);    }    public final synchronized void addSuppresseds(Iterable&lt;Exception&gt; exceptions){        if(exceptions != null){            Iterator&lt;Exception&gt; iterator = exceptions.iterator();            while (iterator.hasNext()){                addSuppressed(iterator.next());            }        }    }}</code></pre><p><strong>com/hsiehchou/hbase/insert/HBaseInsertHelper.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.insert;import com.hsiehchou.hbase.config.HBaseTableUtil;import com.google.common.collect.Lists;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.client.Table;import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;import java.io.Serializable;import java.util.ArrayList;import java.util.Collections;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * 添加HBASE 插入数据类 */public class HBaseInsertHelper implements Serializable{private HBaseInsertHelper(){}public static void put(String tableName, Put put) throws Exception {put(tableName, Lists.newArrayList(put));}public static void put(String tableName, List&lt;Put&gt; puts) throws Exception {if(!puts.isEmpty()){Table table = HBaseTableUtil.getTable(tableName);try {table.put(puts);}catch (Exception e){e.printStackTrace();}finally {HBaseTableUtil.close(table);}} }public static void put(final String tableName, List&lt;Put&gt; puts, int perThreadPutSize) throws Exception {int size = puts.size();if(size &gt; perThreadPutSize){int threadNum = (int)Math.ceil(size / (double)perThreadPutSize);ExecutorService executorService = Executors.newFixedThreadPool(threadNum);final CountDownLatch  cdl = new CountDownLatch(threadNum);final List&lt;Exception&gt;  es = Collections.synchronizedList(new ArrayList&lt;Exception&gt;());try {for(int i = 0; i &lt; threadNum; i++){final List&lt;Put&gt; tmp;if(i == (threadNum - 1)){tmp = puts.subList(perThreadPutSize*i, size);}else{tmp = puts.subList(perThreadPutSize*i, perThreadPutSize*(i + 1));}executorService.execute(new Runnable() {public void run() {try {if(es.isEmpty()) put(tableName, tmp);} catch (Exception e) {es.add(e);}finally {cdl.countDown();}}});}cdl.await();}finally {executorService.shutdown();}if(es.size() &gt; 0){HBaseInsertException insertException = new HBaseInsertException(String.format("put数据到表%s失败。"));insertException.addSuppresseds(es);throw insertException;}}else {put(tableName, puts);}}public static void checkAndPut(String tableName, byte[] row, byte[] family, byte[] qualifier,   byte[] value, Put put) throws Exception {checkAndPut(tableName, row, family, qualifier, null, value, put);}public static void checkAndPut(String tableName, byte[] row, byte[] family, byte[] qualifier,   CompareOp compareOp, byte[] value, Put put) throws Exception {if(!put.isEmpty() ){Table table = HBaseTableUtil.getTable(tableName);try {if(compareOp == null){table.checkAndPut(row, family, qualifier, value, put);}else{table.checkAndPut(row, family, qualifier, compareOp, value, put);}}finally{HBaseTableUtil.close(table);}}}}</code></pre><p><strong>com/hsiehchou/hbase/search/HBaseSearchService.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.search;import com.hsiehchou.hbase.extractor.RowExtractor;import org.apache.hadoop.hbase.client.Get;import org.apache.hadoop.hbase.client.Scan;import java.io.IOException;import java.util.List;import java.util.Map;public interface HBaseSearchService {/**  *  根据  用户 给定的解析类  解析  查询结果  * @param tableName  * @param scan  * @param extractor  用户自定义的 结果解析 类  * @return  * @throws IOException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; search(String tableName, Scan scan, RowExtractor&lt;T&gt; extractor) throws IOException;/**  * 当存在多个  scan时  采用多线程查询  * @param tableName  * @param scans  * @param extractor  用户自定义的 结果解析 类  * @return  * @throws IOException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Scan&gt; scans, RowExtractor&lt;T&gt; extractor) throws IOException;/**  * 采用多线程  同时查询多个表  * @param more  * @return  * @throws IOException  * List&lt;T&gt; */&lt;T&gt; Map&lt;String,List&lt;T&gt;&gt; searchMore(List&lt;SearchMoreTable&lt;T&gt;&gt; more) throws IOException;/**  * 利用反射  自动封装实体类  * @param tableName  * @param scan      * @param cls   HBase表对应的实体类，属性只包含对应表的 列 ， 不区分大小写  * @return  * @throws IOException  * @throws InstantiationException  * @throws IllegalAccessException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; search(String tableName, Scan scan, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException;/**  * 当存在多个 scan 时  采用多线程查询  * @param tableName  * @param scans  * @param cls   HBase表对应的实体类，属性只包含对应表的 列 ， 不区分大小写  * @return  * @throws IOException  * @throws InstantiationException  * @throws IllegalAccessException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Scan&gt; scans, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException;/**  * 批量 get 查询  并按自定义的方式解析结果集  * @param tableName  * @param gets  * @param extractor  用户自定义的 结果解析 类  * @return  * @throws IOException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; search(String tableName, List&lt;Get&gt; gets, RowExtractor&lt;T&gt; extractor) throws IOException;/**  * 多线程批量get, 并按自定义的方式解析结果集  * 建议 : perThreadExtractorGetNum &gt;= 100  * @param tableName  * @param gets  * @param perThreadExtractorGetNum    每个线程处理的 get的个数   * @param extractor  用户自定义的 结果解析 类  * @return  * @throws IOException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Get&gt; gets, int perThreadExtractorGetNum, RowExtractor&lt;T&gt; extractor) throws IOException;/**  * 批量 get 查询  并利用反射 封装到指定的实体类中  * @param tableName  * @param gets  * @param  cls   HBase表对应的实体类，属性只包含对应表的 列 ， 不区分大小写  * @return        * @throws IOException  * @throws InstantiationException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; search(String tableName, List&lt;Get&gt; gets, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException;/**  * 多线程批量 get 查询  并利用反射 封装到指定的实体类中  * 建议 : perThreadExtractorGetNum &gt;= 100  * @param tableName  * @param gets  * @param perThreadExtractorGetNum  每个线程处理的 get的个数   * @param  cls   HBase表对应的实体类，属性只包含对应表的 列 ， 不区分大小写  * @return  * @throws IOException  * @throws InstantiationException  * @throws IllegalAccessException  * List&lt;T&gt; */&lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Get&gt; gets, int perThreadExtractorGetNum, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException;/**  * get 查询  并按自定义的方式解析结果集  * @param tableName  * @param extractor   用户自定义的 结果解析 类  * @return     如果 查询不到  则 返回  null  * @throws IOException  * List&lt;T&gt; */&lt;T&gt; T search(String tableName, Get get, RowExtractor&lt;T&gt; extractor) throws IOException;/**  * get 查询  并利用反射 封装到指定的实体类中  * @param tableName  * @param  cls   HBase表对应的实体类，属性只包含对应表的 列 ， 不区分大小写  * @return     如果 查询不到  则 返回  null  * @throws IOException  * @throws InstantiationException  * List&lt;T&gt; */&lt;T&gt; T search(String tableName, Get get, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException;}</code></pre><p><strong>com/hsiehchou/hbase/search/HBaseSearchServiceImpl.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.search;import com.hsiehchou.hbase.config.HBaseTableFactory;import com.hsiehchou.hbase.extractor.RowExtractor;import org.apache.hadoop.hbase.client.*;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.io.Serializable;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.Map;public class HBaseSearchServiceImpl implements HBaseSearchService,Serializable{private static final long serialVersionUID = -8657479861137115645L;private static final Logger LOG = LoggerFactory.getLogger(HBaseSearchServiceImpl.class);private HBaseTableFactory factory = new HBaseTableFactory();private int poolCapacity = 6;@Overridepublic &lt;T&gt; List&lt;T&gt; search(String tableName, Scan scan, RowExtractor&lt;T&gt; extractor) throws IOException {return null;}@Overridepublic &lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Scan&gt; scans, RowExtractor&lt;T&gt; extractor) throws IOException {return null;}@Overridepublic &lt;T&gt; Map&lt;String, List&lt;T&gt;&gt; searchMore(List&lt;SearchMoreTable&lt;T&gt;&gt; more) throws IOException {return null;}@Overridepublic &lt;T&gt; List&lt;T&gt; search(String tableName, Scan scan, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException {return null;}@Overridepublic &lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Scan&gt; scans, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException {return null;}@Overridepublic &lt;T&gt; List&lt;T&gt; search(String tableName, List&lt;Get&gt; gets, RowExtractor&lt;T&gt; extractor) throws IOException {List&lt;T&gt; data = new ArrayList&lt;T&gt;();search(tableName, gets, extractor,data);return data;}@Overridepublic &lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Get&gt; gets, int perThreadExtractorGetNum, RowExtractor&lt;T&gt; extractor) throws IOException {return null;}@Overridepublic &lt;T&gt; List&lt;T&gt; search(String tableName, List&lt;Get&gt; gets, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException {return null;}@Overridepublic &lt;T&gt; List&lt;T&gt; searchMore(String tableName, List&lt;Get&gt; gets, int perThreadExtractorGetNum, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException {return null;}@Overridepublic &lt;T&gt; T search(String tableName, Get get, RowExtractor&lt;T&gt; extractor) throws IOException {T obj = null;List&lt;T&gt; res = search(tableName,Arrays.asList(get),extractor);if( !res.isEmpty()){obj = res.get(0);}return obj;}@Overridepublic &lt;T&gt; T search(String tableName, Get get, Class&lt;T&gt; cls) throws IOException, InstantiationException, IllegalAccessException {return null;}private &lt;T&gt; void search(String tableName, List&lt;Get&gt; gets,RowExtractor&lt;T&gt; extractor , List&lt;T&gt; data ) throws IOException {//根据table名获取表连接Table table = factory.getHBaseTableInstance(tableName);if(table != null ){Result[] results = table.get(gets);int n = 0;T row = null;for( Result result : results){if( !result.isEmpty() ){row = extractor.extractRowData(result, n);if(row != null )data.add(row);n++;}}close( table, null);}else{throw new IOException(" table  " + tableName + " is not exists ..");}}public static boolean  existsRowkey( Table table, String rowkey){boolean exists =true;try {exists = table.exists(new Get(rowkey.getBytes()));} catch (IOException e) {LOG.error("失败。", e );}return exists;}public static void  close( Table table, ResultScanner scanner ){try {if( table != null ){table.close();table = null;}if( scanner != null ){scanner.close();scanner = null;}} catch (IOException e) {LOG.error("关闭 HBase的表  " + table.getName().toString() + " 失败。", e );}}}</code></pre><p><strong>com/hsiehchou/hbase/search/SearchMoreTable.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.search;import com.hsiehchou.hbase.extractor.RowExtractor;import org.apache.hadoop.hbase.client.Scan;public class SearchMoreTable&lt;T&gt; {private String tableName;private Scan scan;private RowExtractor&lt;T&gt; extractor;public SearchMoreTable() {super();}public SearchMoreTable(String tableName, Scan scan,RowExtractor&lt;T&gt; extractor) {super();this.tableName = tableName;this.scan = scan;this.extractor = extractor;}public String getTableName() {return tableName;}public void setTableName(String tableName) {this.tableName = tableName;}public Scan getScan() {return scan;}public void setScan(Scan scan) {this.scan = scan;}public RowExtractor&lt;T&gt; getExtractor() {return extractor;}public void setExtractor(RowExtractor&lt;T&gt; extractor) {this.extractor = extractor;}}</code></pre><p><strong>com/hsiehchou/hbase/spilt/SpiltRegionUtil.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.hbase.spilt;import org.apache.hadoop.hbase.util.Bytes;import java.util.Iterator;import java.util.TreeSet;/** * hbase 预分区 */public class SpiltRegionUtil {    /**     * 定义分区     * @return     */    public static byte[][] getSplitKeysBydinct() {        String[] keys = new String[]{"1","2", "3","4", "5","6", "7","8", "9","a","b", "c","d","e","f"};        //String[] keys = new String[]{"10|", "20|", "30|", "40|", "50|", "60|", "70|", "80|", "90|"};        byte[][] splitKeys = new byte[keys.length][];        //通过treeset排序        TreeSet&lt;byte[]&gt; rows = new TreeSet&lt;byte[]&gt;(Bytes.BYTES_COMPARATOR);//升序排序        for (int i = 0; i &lt; keys.length; i++) {            rows.add(Bytes.toBytes(keys[i]));        }        Iterator&lt;byte[]&gt; rowKeyIter = rows.iterator();        int i = 0;        while (rowKeyIter.hasNext()) {            byte[] tempRow = rowKeyIter.next();            rowKeyIter.remove();            splitKeys[i] = tempRow;            i++;        }        return splitKeys;    }}</code></pre><h4 id="6、执行">6、执行</h4><p>spark-submit <code>--</code>master local[1] <code>--</code>num-executors 1 <code>--</code>driver-memory 300m <code>--</code>executor-memory 500m <code>--</code>executor-cores 1 <code>--</code>jars $(echo /usr/chl/spark7/jars/*.jar | tr ’ ’ ‘,’) <code>--</code>class com.hsiehchou.spark.streaming.kafka.kafka2hbase.DataRelationStreaming /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</p><h4 id="7、执行截图">7、执行截图</h4><p><img src="/medias/hbase_list.PNG" alt="hbase_list"></p><p><img src="/medias/hbase_scan.PNG" alt="hbase_scan"></p><p><img src="/medias/hbase%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE.PNG" alt="hbase写入数据"></p><h3 id="十二、SpringCloud-项目构建">十二、SpringCloud 项目构建</h3><p><img src="/medias/SpringCloud%E5%BE%AE%E6%9C%8D%E5%8A%A1.PNG" alt="SpringCloud微服务"></p><p><img src="/medias/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C.PNG" alt="服务注册"></p><p><strong>解决IntelliJ IDEA 创建Maven项目速度慢问题</strong><br>add Maven Property<br>Name:archetypeCatalog<br>Value:internal</p><h4 id="1、构建SpringCloud父项目">1、构建SpringCloud父项目</h4><p>在原项目下新建 xz_bigdata_springcloud_dir目录</p><p><img src="/medias/%E6%96%B0%E5%BB%BA%20xz_bigdata_springcloud_dir%E7%9B%AE%E5%BD%95.PNG" alt="新建 xz_bigdata_springcloud_dir目录"></p><h4 id="2、在此目录下新建-xz-bigdata-springclod-root项目">2、在此目录下新建 xz_bigdata_springclod_root项目</h4><p><img src="/medias/%E6%96%B0%E5%BB%BA%20xz_bigdata_springcloud_root%E9%A1%B9%E7%9B%AE.PNG" alt="新建 xz_bigdata_springcloud_root项目"></p><h4 id="3、引入SpringCloud依赖">3、引入SpringCloud依赖</h4><p><strong>父pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;modules&gt;    &lt;module&gt;xz_bigdata_springcloud_common&lt;/module&gt;    &lt;module&gt;xz_bigdata_springcloud_esquery&lt;/module&gt;    &lt;module&gt;xz_bigdata_springcloud_eureka&lt;/module&gt;    &lt;module&gt;xz_bigdata_springcloud_hbasequery&lt;/module&gt;  &lt;/modules&gt;  &lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.0.9.RELEASE&lt;/version&gt;  &lt;/parent&gt;  &lt;groupId&gt;com.hsiehchou.springcloud&lt;/groupId&gt;  &lt;artifactId&gt;xz_bigdata_springcloud_root&lt;/artifactId&gt;  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;packaging&gt;pom&lt;/packaging&gt;    &lt;name&gt;xz_bigdata_springcloud_root&lt;/name&gt;  &lt;properties&gt;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;  &lt;/properties&gt;  &lt;!--CDH源--&gt;  &lt;repositories&gt;    &lt;repository&gt;      &lt;id&gt;cloudera&lt;/id&gt;      &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;    &lt;/repository&gt;  &lt;/repositories&gt;  &lt;!--依赖管理，用于管理spring-cloud的依赖--&gt;  &lt;dependencyManagement&gt;    &lt;dependencies&gt;      &lt;!--spring-cloud-dependencies--&gt;      &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;        &lt;version&gt;Finchley.SR1&lt;/version&gt;        &lt;type&gt;pom&lt;/type&gt;        &lt;scope&gt;import&lt;/scope&gt;      &lt;/dependency&gt;    &lt;/dependencies&gt;  &lt;/dependencyManagement&gt;  &lt;!--打包插件--&gt;  &lt;build&gt;    &lt;plugins&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;        &lt;version&gt;3.1&lt;/version&gt;        &lt;configuration&gt;          &lt;source&gt;1.8&lt;/source&gt;          &lt;target&gt;1.8&lt;/target&gt;          &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;    &lt;/plugins&gt;  &lt;/build&gt;&lt;/project&gt;</code></pre><p><strong>删除父项目src目录。因为这个项目主要是管理子项目不做任何逻辑业务</strong></p><h4 id="4、构建SpringCloud-Common子项目">4、构建SpringCloud Common子项目</h4><p><strong>新建子模块</strong><br>xz_bigdata_springcloud_common</p><p><strong>引入依赖</strong></p><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata_springcloud_root&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou.springcloud&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_springcloud_common&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_springcloud_common&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;/properties&gt;    &lt;dependencies&gt;&lt;!--eureka-server--&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt;                    &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;com.alibaba&lt;/groupId&gt;&lt;artifactId&gt;fastjson&lt;/artifactId&gt;&lt;version&gt;1.2.24&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt;&lt;/project&gt;</code></pre><h4 id="5、构建Eureka服务注册中心">5、构建Eureka服务注册中心</h4><p><strong>新建xz_bigdata_springcloud_eureka子模块</strong></p><p><img src="/medias/%E6%96%B0%E5%BB%BAxz_bigdata_springcloud_eureka%E5%AD%90%E6%A8%A1%E5%9D%97.PNG" alt="新建xz_bigdata_springcloud_eureka子模块"></p><p><strong>引入依赖</strong></p><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata_springcloud_root&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou.springcloud&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_springcloud_eureka&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_springcloud_eureka&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;/properties&gt;&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;com.hsiehchou.springcloud&lt;/groupId&gt;&lt;artifactId&gt;xz_bigdata_springcloud_common&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;&lt;!--用户验证--&gt;  &lt;!--      &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;            &lt;version&gt;1.4.1.RELEASE&lt;/version&gt;        &lt;/dependency&gt;--&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;&lt;!--打包依赖的jar包--&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;outputDirectory&gt;${project.build.directory}/lib&lt;/outputDirectory&gt;                    &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt; &lt;!-- 表示是否不包含间接依赖的包 --&gt;                    &lt;stripVersion&gt;false&lt;/stripVersion&gt; &lt;!-- 去除版本信息 --&gt;                &lt;/configuration&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;id&gt;copy-dependencies&lt;/id&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;copy-dependencies&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;!-- 拷贝项目依赖包到lib/目录下 --&gt;                            &lt;outputDirectory&gt;${project.build.directory}/jars&lt;/outputDirectory&gt;                            &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt;                            &lt;stripVersion&gt;false&lt;/stripVersion&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;!-- 打成jar包插件 --&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;2.5&lt;/version&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;!--                        生成的jar中，不要包含pom.xml和pom.properties这两个文件                    --&gt;                        &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt;                        &lt;!-- 生成MANIFEST.MF的设置 --&gt;                        &lt;manifest&gt;                            &lt;!-- 为依赖包添加路径, 这些路径会写在MANIFEST文件的Class-Path下 --&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;classpathPrefix&gt;jars/&lt;/classpathPrefix&gt;                            &lt;!-- jar启动入口类--&gt;                            &lt;mainClass&gt;com.cn.hbase.mr.HbaseMr&lt;/mainClass&gt;                        &lt;/manifest&gt;                        &lt;!--       &lt;manifestEntries&gt;                                   &amp;lt;!&amp;ndash; 在Class-Path下添加配置文件的路径 &amp;ndash;&amp;gt;                                   &lt;Class-Path&gt;&lt;/Class-Path&gt;                               &lt;/manifestEntries&gt;--&gt;                    &lt;/archive&gt;                    &lt;outputDirectory&gt;${project.build.directory}/&lt;/outputDirectory&gt;                    &lt;includes&gt;                        &lt;!-- 打jar包时，只打包class文件 --&gt;                        &lt;include&gt;**/*.class&lt;/include&gt;                        &lt;include&gt;**/*.properties&lt;/include&gt;                        &lt;include&gt;**/*.yml&lt;/include&gt;                    &lt;/includes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>新建resources配置文件目录，添加application.yml配置文件或者 application.properties</p><p><strong>application.yml</strong></p><pre><code class="highlight plaintext">server:  port: 8761eureka:  client:    register-with-eureka: false    fetch-registry: false    service-url:      defaultZone: http://root:root@hadoop3:8761/eureka/</code></pre><p><img src="/medias/xz_bigdata_springcloud_eureka%E7%BB%93%E6%9E%84.PNG" alt="xz_bigdata_springcloud_eureka结构"></p><p><strong>新建EurekaApplication 启动类</strong></p><p><strong>EurekaApplication.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.eureka;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * 注册中心 */@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication{    public static void main( String[] args )    {        SpringApplication.run(EurekaApplication.class, args);    }}</code></pre><p><strong>执行EurekaApplication 启动</strong></p><p><strong>访问localhost:8761</strong></p><p><img src="/medias/%E8%AE%BF%E9%97%AEhadoop38761.PNG" alt="访问hadoop3:8761"></p><h4 id="6、构建HBase查询服务模块">6、构建HBase查询服务模块</h4><p><strong>新建xz_bigdata_springcloud_root子模块</strong></p><p><img src="/medias/%E6%96%B0%E5%BB%BAxz_bigdata_springcloud_root%E5%AD%90%E6%A8%A1%E5%9D%97.PNG" alt="新建xz_bigdata_springcloud_root子模块"></p><p><strong>添加依赖</strong></p><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;parent&gt;        &lt;artifactId&gt;xz_bigdata_springcloud_root&lt;/artifactId&gt;        &lt;groupId&gt;com.hsiehchou.springcloud&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;xz_bigdata_springcloud_hbasequery&lt;/artifactId&gt;    &lt;name&gt;xz_bigdata_springcloud_hbasequery&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;!--spring common依赖--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou.springcloud&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_springcloud_common&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt;                    &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;!--基础服务hbase依赖--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;            &lt;artifactId&gt;xz_bigdata_hbase&lt;/artifactId&gt;            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;                    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;&lt;!--打包依赖的jar包--&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;outputDirectory&gt;${project.build.directory}/lib&lt;/outputDirectory&gt;                    &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt; &lt;!-- 表示是否不包含间接依赖的包 --&gt;                    &lt;stripVersion&gt;false&lt;/stripVersion&gt; &lt;!-- 去除版本信息 --&gt;                &lt;/configuration&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;id&gt;copy-dependencies&lt;/id&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;copy-dependencies&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;!-- 拷贝项目依赖包到lib/目录下 --&gt;                            &lt;outputDirectory&gt;${project.build.directory}/jars&lt;/outputDirectory&gt;                            &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt;                            &lt;stripVersion&gt;false&lt;/stripVersion&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;!-- 打成jar包插件 --&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;2.5&lt;/version&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;!--                        生成的jar中，不要包含pom.xml和pom.properties这两个文件                    --&gt;                        &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt;                        &lt;!-- 生成MANIFEST.MF的设置 --&gt;                        &lt;manifest&gt;                            &lt;!-- 为依赖包添加路径, 这些路径会写在MANIFEST文件的Class-Path下 --&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;classpathPrefix&gt;jars/&lt;/classpathPrefix&gt;                            &lt;!-- jar启动入口类--&gt;                            &lt;mainClass&gt;com.cn.hbase.mr.HbaseMr&lt;/mainClass&gt;                        &lt;/manifest&gt;                        &lt;!--       &lt;manifestEntries&gt;                                   &amp;lt;!&amp;ndash; 在Class-Path下添加配置文件的路径 &amp;ndash;&amp;gt;                                   &lt;Class-Path&gt;&lt;/Class-Path&gt;                               &lt;/manifestEntries&gt;--&gt;                    &lt;/archive&gt;                    &lt;outputDirectory&gt;${project.build.directory}/&lt;/outputDirectory&gt;                    &lt;includes&gt;                        &lt;!-- 打jar包时，只打包class文件 --&gt;                        &lt;include&gt;**/*.class&lt;/include&gt;                        &lt;include&gt;**/*.properties&lt;/include&gt;                        &lt;include&gt;**/*.yml&lt;/include&gt;                    &lt;/includes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p><strong>添加配置文件</strong></p><p><strong>新建 resources 目录</strong><br>添加 <strong>application.properties</strong> 文件</p><pre><code class="highlight plaintext">server.port=8002logging.level.root=INFOlogging.level.org.hibernate=INFOlogging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACElogging.level.org.hibernate.type.descriptor.sql.BasicExtractor= TRACElogging.level.com.itmuch=DEBUGspring.http.encoding.charset=UTF-8spring.http.encoding.enable=truespring.http.encoding.force=trueeureka.client.serviceUrl.defaultZone=http://root:root@hadoop3:8761/eureka/spring.application.name=xz-bigdata-springcloud-hbasequeryeureka.instance.prefer-ip-address=true</code></pre><p><strong>构建启动类</strong></p><p>新建 <strong>com.hsiehchou.springcloud.hbase</strong>包<br>构建 <strong>HbaseApplication</strong> 启动类</p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class HbaseQueryApplication{    public static void main( String[] args )    {        SpringApplication.run(HbaseQueryApplication.class, args);    }}</code></pre><p><img src="/medias/%E6%B3%A8%E5%86%8C%E6%88%90%E5%8A%9F.PNG" alt="注册成功"><br>说明注册成功</p><p><strong>构建服务</strong></p><p><img src="/medias/%E6%9E%84%E5%BB%BAHbase%E6%9C%8D%E5%8A%A1.PNG" alt="构建Hbase服务"></p><p>构建 <strong>com.hsiehchou.springcloud.hbase.controller</strong></p><p>创建 <strong>HbaseBaseController</strong></p><p><strong>HbaseBaseController.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.hbase.controller;import com.hsiehchou.hbase.extractor.SingleColumnMultiVersionRowExtrator;import com.hsiehchou.hbase.search.HBaseSearchService;import com.hsiehchou.hbase.search.HBaseSearchServiceImpl;import com.hsiehchou.springcloud.hbase.service.HbaseBaseService;import org.apache.hadoop.hbase.client.Get;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;import java.io.IOException;import java.util.HashSet;import java.util.List;import java.util.Map;import java.util.Set;@Controller@RequestMapping(value="/hbase")public class HbaseBaseController {    private static Logger LOG = LoggerFactory.getLogger(HbaseBaseController.class);    //注入 通过这个注解可以直接拿到HbaseBaseService这个的实例    @Resource    private HbaseBaseService hbaseBaseService;    @ResponseBody    @RequestMapping(value="/search/{table}/{rowkey}", method={RequestMethod.GET,RequestMethod.POST})    public Set&lt;String&gt; search(@PathVariable(value = "table") String table,                              @PathVariable(value = "rowkey") String rowkey){        return hbaseBaseService.getSingleColumn(table,rowkey);    }    @ResponseBody    @RequestMapping(value="/search1", method={RequestMethod.GET,RequestMethod.POST})    public Set&lt;String&gt; search1( @RequestParam(name = "table") String table,                                @RequestParam(name = "rowkey") String rowkey){        //通过二级索引去找主关联表的rowkey 这个rowkey就是MAC        return hbaseBaseService.getSingleColumn(table,rowkey);    }    @ResponseBody    @RequestMapping(value = "/getHbase",method = {RequestMethod.GET,RequestMethod.POST})    public Set&lt;String&gt; getHbase(@RequestParam(name="table") String table,                                @RequestParam(name="rowkey") String rowkey){        return hbaseBaseService.getSingleColumn(table, rowkey);    }    @ResponseBody    @RequestMapping(value = "/getRelation",method = {RequestMethod.GET,RequestMethod.POST})    public Map&lt;String,List&lt;String&gt;&gt; getRelation(@RequestParam(name = "field") String field,                                                @RequestParam(name = "fieldValue") String fieldValue){        return hbaseBaseService.getRealtion(field,fieldValue);    }    public static void main(String[] args) {        HbaseBaseController hbaseBaseController = new HbaseBaseController();        hbaseBaseController.getHbase("send_mail", "65497873@qq.com");    }}</code></pre><p>构建 <strong>com.hsiehchou.springcloud.hbase.service</strong></p><p>创建 <strong>HbaseBaseService</strong></p><p><strong>HbaseBaseService.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.hbase.service;import com.hsiehchou.hbase.entity.HBaseCell;import com.hsiehchou.hbase.entity.HBaseRow;import com.hsiehchou.hbase.extractor.MultiVersionRowExtrator;import com.hsiehchou.hbase.extractor.SingleColumnMultiVersionRowExtrator;import com.hsiehchou.hbase.search.HBaseSearchService;import com.hsiehchou.hbase.search.HBaseSearchServiceImpl;import org.apache.hadoop.hbase.client.Get;import org.apache.hadoop.hbase.client.Put;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.io.IOException;import java.util.*;@Servicepublic class HbaseBaseService {    private static Logger LOG = LoggerFactory.getLogger(HbaseBaseService.class);    @Resource    private HbaseBaseService hbaseBaseService;    /**     * 获取hbase单列数据的多版本信息     * @param field     * @param rowkey     * @return     */    public Set&lt;String&gt; getSingleColumn(String field,String rowkey){        //从索引表中获取总关联表的rowkey,获取phone对应的多版本MAC        Set&lt;String&gt; search = null;        HBaseSearchService hBaseSearchService = new HBaseSearchServiceImpl();        String table = "test:"+field;        Get get = new Get(rowkey.getBytes());        try {            get.setMaxVersions(100);        } catch (IOException e) {            e.printStackTrace();        }        Set set = new HashSet&lt;String&gt;();        SingleColumnMultiVersionRowExtrator singleColumnMultiVersionRowExtrator = new SingleColumnMultiVersionRowExtrator("cf".getBytes(), "phone_mac".getBytes(), set);        try {            search = hBaseSearchService.search(table, get, singleColumnMultiVersionRowExtrator);            System.out.println(search.toString());        } catch (IOException e) {            e.printStackTrace();        }        return search;    }    /**     *  获取单列多版本     * @param table     * @param rowkey     * @param versions     * @return     */    public Set&lt;String&gt; getSingleColumn(String table,String rowkey,int versions){        Set&lt;String&gt; search = null;        try {            HBaseSearchService baseSearchService = new HBaseSearchServiceImpl();            Get get = new Get(rowkey.getBytes());            get.setMaxVersions(versions);            Set set = new HashSet&lt;String&gt;();            SingleColumnMultiVersionRowExtrator singleColumnMultiVersionRowExtrator = new SingleColumnMultiVersionRowExtrator("cf".getBytes(), "phone_mac".getBytes(), set);            search = baseSearchService.search(table, get, singleColumnMultiVersionRowExtrator);        } catch (IOException e) {            LOG.error(null,e);        }        System.out.println(search);        return search;    }    /**     * 直接通过关联表字段值获取整条记录     * hbase 二级查找     * @param field     * @param fieldValue     * @return     */    public Map&lt;String,List&lt;String&gt;&gt; getRealtion(String field,String fieldValue){        //第一步 从二级索引表中找到多版本的rowkey        Map&lt;String,List&lt;String&gt;&gt; map = new HashMap&lt;&gt;();        //首先查找索引表        //查找的表名        String table = "test:" + field;        String indexRowkey = fieldValue;        HbaseBaseService hbaseBaseService = new HbaseBaseService();        Set&lt;String&gt; relationRowkeys = hbaseBaseService.getSingleColumn(table, indexRowkey, 100);        //第二步 拿到二级索引表中得到的 主关联表的rowkey        //对这些rowkey进行遍历 获取主关联表中rowkey对应的所有多版本数据        //遍历relationRowkeys，将其封装成List&lt;Get&gt;        List&lt;Get&gt; list = new ArrayList&lt;&gt;();        relationRowkeys.forEach(relationRowkey-&gt;{            //通过relationRowkey去找relation表中的所有信息            Get get = new Get(relationRowkey.getBytes());            try {                get.setMaxVersions(100);            } catch (IOException e) {                e.printStackTrace();            }            list.add(get);        });        MultiVersionRowExtrator multiVersionRowExtrator = new MultiVersionRowExtrator();        HBaseSearchService hBaseSearchService = new HBaseSearchServiceImpl();        try {            //&lt;T&gt; List&lt;T&gt; search(String tableName, List&lt;Get&gt; gets, RowExtractor&lt;T&gt; extractor) throws IOException;            List&lt;HBaseRow&gt; search = hBaseSearchService.search("test:relation", list, multiVersionRowExtrator);            search.forEach(hbaseRow-&gt;{                Map&lt;String, Collection&lt;HBaseCell&gt;&gt; cellMap = hbaseRow.getCell();                cellMap.forEach((key,value)-&gt;{                    //把Map&lt;String,Collection&lt;HBaseCell&gt;&gt;转为Map&lt;String,List&lt;String&gt;&gt;                    List&lt;String&gt; listValue = new ArrayList&lt;&gt;();                    value.forEach(x-&gt;{                        listValue.add(x.toString());                    });                    map.put(key,listValue);                });            });        } catch (IOException e) {            e.printStackTrace();        }        System.out.println(map.toString());     return map;    }    public static void main(String[] args) {        HbaseBaseService hbaseBaseService = new HbaseBaseService();//        hbaseBaseService.getRealtion("send_mail","65494533@qq.com");        hbaseBaseService.getSingleColumn("phone","18609765012");    }}</code></pre><h4 id="7、构建ES查询服务">7、构建ES查询服务</h4><p>使用jest API 是走的 <strong>HTTP 请求</strong>  <strong>9200端口</strong><br>依赖如下:</p><pre><code class="highlight plaintext">&lt;dependency&gt;    &lt;groupId&gt;io.searchbox&lt;/groupId&gt;    &lt;artifactId&gt;jest&lt;/artifactId&gt;    &lt;version&gt;6.3.1&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>9200作为Http协议，<strong>主要用于外部通讯</strong></p><p>9300作为Tcp协议，jar之间就是通过 <strong>tcp协议通讯</strong></p><p><strong>ES集群之间是通过9300进行通讯</strong></p><p><strong>新建xz_bigdata_springcloud_esquery</strong></p><p><strong>新建xz_bigdata_springcloud_esquery子项目</strong></p><p><strong>准备</strong></p><p>新建 <strong>resources</strong> 配置文件目录</p><p><strong>增加配置文件</strong></p><p><strong>application.properties</strong></p><pre><code class="highlight plaintext">server.port=8003logging.level.root=INFOlogging.level.org.hibernate=INFOlogging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACElogging.level.org.hibernate.type.descriptor.sql.BasicExtractor= TRACElogging.level.com.itmuch=DEBUGspring.http.encoding.charset=UTF-8spring.http.encoding.enable=truespring.http.encoding.force=trueeureka.client.serviceUrl.defaultZone=http://root:root@hadoop3:8761/eureka/spring.application.name=xz-bigdata-springcloud-esqueryeureka.instance.prefer-ip-address=true#关闭EDES检测management.health.elasticsearch.enabled=falsespring.elasticsearch.jest.uris=["http://192.168.116.201:9200"]#全部索引esIndexs=wechat,mail,qq</code></pre><p><strong>新建ES微服务启动类</strong></p><p><strong>ESqueryApplication.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.es;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableEurekaServer@EnableDiscoveryClient@EnableFeignClientspublic class ESqueryApplication {    public static void main(String[] args) {        SpringApplication.run(ESqueryApplication.class,args);    }}</code></pre><p><strong>启动 Eureka  ES 微服务</strong></p><p><img src="/medias/%E6%B3%A8%E5%86%8C%E6%88%90%E5%8A%9F.PNG" alt="注册成功"><br>说明注册成功</p><p><img src="/medias/ES%E8%B0%83%E7%94%A8Hbase.PNG" alt="ES调用Hbase"></p><p>构建 <strong>com.hsiehchou.springcloud.es.controller</strong></p><p>创建 <strong>EsBaseController</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.es.controller;import com.hsiehchou.springcloud.es.feign.HbaseFeign;import com.hsiehchou.springcloud.es.service.EsBaseService;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import javax.annotation.Resource;import java.util.List;import java.util.Map;import java.util.Set;@Controller@RequestMapping(value = "/es")public class EsBaseController {    @Value("${esIndexs}")    private String esIndexs;    @Resource    private EsBaseService esBaseService;    @Resource    private HbaseFeign hbaseFeign;    /**     * 基础查询     * @param indexName     * @param typeName     * @param sortField     * @param sortValue     * @param pageNumber     * @param pageSize     * @return     */    @ResponseBody    @RequestMapping(value = "/getBaseInfo", method = {RequestMethod.GET, RequestMethod.POST})    public List&lt;Map&lt;String, Object&gt;&gt; getBaseInfo(@RequestParam(name = "indexName") String indexName,                                                 @RequestParam(name = "typeName") String typeName,                                                 @RequestParam(name = "sortField") String sortField,                                                 @RequestParam(name = "sortValue") String sortValue,                                                 @RequestParam(name = "pageNumber") int pageNumber,                                                 @RequestParam(name = "pageSize") int pageSize) {        // 根据数据类型, 排序，分页        // indexName typeName        // sortField sortValue        // pageNumber  pageSize        return  esBaseService.getBaseInfo(indexName,typeName,sortField,sortValue,pageNumber,pageSize);    }    /**     * 根据任意条件查找轨迹数据     * @param field     * @param fieldValue     * @return     */    @ResponseBody    @RequestMapping(value = "/getLocus", method = {RequestMethod.GET, RequestMethod.POST})    public List&lt;Map&lt;String, Object&gt;&gt; getLocus(@RequestParam(name = "field") String field,                                                 @RequestParam(name = "fieldValue") String fieldValue) {        Set&lt;String&gt; macs = hbaseFeign.search1(field, fieldValue);        System.out.println(macs.toString());        // 根据数据类型, 排序，分页        // indexName typeName        // sortField sortValue        // pageNumber  pageSize        String mac = macs.iterator().next();        return  esBaseService.getLocus(mac);    }    /**     * 所有表数据总量     * @return     */    @ResponseBody    @RequestMapping(value="/getAllCount", method={RequestMethod.GET,RequestMethod.POST})    public Map&lt;String,Long&gt; getAllCount(){        Map&lt;String, Long&gt; allCount = esBaseService.getAllCount(esIndexs);        System.out.println(allCount);        return allCount;    }    @ResponseBody    @RequestMapping(value="/group", method={RequestMethod.GET,RequestMethod.POST})    public Map&lt;String,Long&gt; group(@RequestParam(name = "indexName") String indexName,                                  @RequestParam(name = "typeName") String typeName,                                  @RequestParam(name = "field") String field){        return esBaseService.aggregation(indexName,typeName,field);    }    public static void main(String[] args){        EsBaseController esBaseController = new EsBaseController();        esBaseController.getLocus("phone","18609765432");    }}</code></pre><p>构建 <strong>com.hsiehchou.springcloud.es.service</strong></p><p>创建 <strong>EsBaseService</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.es.service;import com.hsiehchou.es.jest.service.JestService;import com.hsiehchou.es.jest.service.ResultParse;import io.searchbox.client.JestClient;import io.searchbox.core.SearchResult;import org.springframework.stereotype.Service;import java.util.HashMap;import java.util.List;import java.util.Map;@Servicepublic class EsBaseService {    // 根据数据类型, 排序，分页    // indexName typeName    // sortField sortValue    // pageNumber  pageSize    public List&lt;Map&lt;String, Object&gt;&gt; getBaseInfo(String indexName,                                                 String typeName,                                                 String sortField,                                                 String sortValue,                                                 int pageNumber,                                                 int pageSize) {        //实现查询        JestClient jestClient = null;        List&lt;Map&lt;String, Object&gt;&gt; maps = null;        try {            jestClient = JestService.getJestClient();            SearchResult search = JestService.search(jestClient,                    indexName,                    typeName,                    "",                    "",                    sortField,                    sortValue,                    pageNumber,                    pageSize);            maps = ResultParse.parseSearchResultOnly(search);        } catch (Exception e) {            e.printStackTrace();        } finally {            JestService.closeJestClient(jestClient);        }        return maps;    }    // 传时间范围   比如你要查3天之内的轨迹    // es中text的类型的可以直接查询，而keyword类型的必须带.keyword，例如，phone_mac.keyword    public List&lt;Map&lt;String, Object&gt;&gt; getLocus(String mac){        //实现查询        JestClient jestClient = null;        List&lt;Map&lt;String, Object&gt;&gt; maps = null;        String[] includes = new String[]{"latitude","longitude","collect_time"};        try {            jestClient = JestService.getJestClient();            SearchResult search = JestService.search(jestClient,                    "",                    "",                    "phone_mac.keyword",                    mac,                    "collect_time",                    "asc",                    1,                    2000,                    includes);            maps = ResultParse.parseSearchResultOnly(search);        } catch (Exception e) {            e.printStackTrace();        } finally {            JestService.closeJestClient(jestClient);        }        return maps;    }     public Map&lt;String,Long&gt; getAllCount(String esIndexs){        Map&lt;String,Long&gt; countMap = new HashMap&lt;&gt;();        JestClient jestClient = null;        try {            jestClient = JestService.getJestClient();            String[] split = esIndexs.split(",");            for (int i = 0; i &lt; split.length; i++) {                String index = split[i];                Long count = JestService.count(jestClient, index, index);                countMap.put(index,count);            }        } catch (Exception e) {            e.printStackTrace();        }finally {            JestService.closeJestClient(jestClient);        }        return countMap;    }    public Map&lt;String,Long&gt; aggregation(String indexName,String typeName,String field){        JestClient jestClient = null;        Map&lt;String, Long&gt; stringLongMap = null;        try {            jestClient = JestService.getJestClient();            SearchResult aggregation = JestService.aggregation(jestClient, indexName, typeName, field);            stringLongMap = ResultParse.parseAggregation(aggregation);        } catch (Exception e) {            e.printStackTrace();        }finally {            JestService.closeJestClient(jestClient);        }        return stringLongMap;    }}</code></pre><p><strong>这里用到了ES的大数据基础服务</strong></p><p><strong>轨迹查询</strong></p><p>用到了 <strong>HBase</strong> 的服务，使用 <strong>Fegin</strong><br><strong>SpringCloud Feign</strong></p><p><strong>Feign</strong> 是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用 <strong>Feign</strong> ，只需要创建一个接口并用注解的方式来配置它，即可完成对服务提供方的接口绑定服务调用客户端的开发量。</p><p>构建 <strong>com.hsiehchou.springcloud.es.fegin</strong></p><p>创建 <strong>HbaseFeign</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.springcloud.es.feign;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import java.util.Set;@FeignClient(name = "xz-bigdata-springcloud-hbasequery")public interface HbaseFeign {    @ResponseBody    @RequestMapping(value="/hbase/search1", method=RequestMethod.GET)    public Set&lt;String&gt; search1(@RequestParam(name = "table") String table,                               @RequestParam(name = "rowkey") String rowkey);}</code></pre><h4 id="8、微服务手动部署">8、微服务手动部署</h4><p><strong>Maven添加打包插件</strong></p><pre><code class="highlight plaintext">&lt;build&gt;       &lt;plugins&gt;           &lt;plugin&gt;&lt;!--打包依赖的jar包--&gt;               &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;               &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;               &lt;configuration&gt;                   &lt;outputDirectory&gt;${project.build.directory}/lib&lt;/outputDirectory&gt;                   &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt; &lt;!-- 表示是否不包含间接依赖的包 --&gt;                   &lt;stripVersion&gt;false&lt;/stripVersion&gt; &lt;!-- 去除版本信息 --&gt;               &lt;/configuration&gt;               &lt;executions&gt;                   &lt;execution&gt;                       &lt;id&gt;copy-dependencies&lt;/id&gt;                       &lt;phase&gt;package&lt;/phase&gt;                       &lt;goals&gt;                           &lt;goal&gt;copy-dependencies&lt;/goal&gt;                       &lt;/goals&gt;                       &lt;configuration&gt;                           &lt;!-- 拷贝项目依赖包到lib/目录下 --&gt;                           &lt;outputDirectory&gt;${project.build.directory}/jars&lt;/outputDirectory&gt;                           &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt;                           &lt;stripVersion&gt;false&lt;/stripVersion&gt;                       &lt;/configuration&gt;                   &lt;/execution&gt;               &lt;/executions&gt;           &lt;/plugin&gt;           &lt;!-- 打成jar包插件 --&gt;           &lt;plugin&gt;               &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;               &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;               &lt;version&gt;2.4&lt;/version&gt;               &lt;configuration&gt;                   &lt;archive&gt;                       &lt;!--                       生成的jar中，不要包含pom.xml和pom.properties这两个文件                   --&gt;                       &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt;                       &lt;!-- 生成MANIFEST.MF的设置 --&gt;                       &lt;manifest&gt;                           &lt;!-- 为依赖包添加路径, 这些路径会写在MANIFEST文件的Class-Path下 --&gt;                           &lt;addClasspath&gt;true&lt;/addClasspath&gt;                           &lt;classpathPrefix&gt;jars/&lt;/classpathPrefix&gt;                           &lt;!-- jar启动入口类--&gt;                           &lt;mainClass&gt;com.cn.hbase.mr.HbaseMr&lt;/mainClass&gt;                       &lt;/manifest&gt;                       &lt;!--       &lt;manifestEntries&gt;                                  &amp;lt;!&amp;ndash; 在Class-Path下添加配置文件的路径 &amp;ndash;&amp;gt;                                  &lt;Class-Path&gt;&lt;/Class-Path&gt;                              &lt;/manifestEntries&gt;--&gt;                   &lt;/archive&gt;                   &lt;outputDirectory&gt;${project.build.directory}/&lt;/outputDirectory&gt;                   &lt;includes&gt;                       &lt;!-- 打jar包时，只打包class文件 --&gt;                       &lt;include&gt;**/*.class&lt;/include&gt;                       &lt;include&gt;**/*.properties&lt;/include&gt;                       &lt;include&gt;**/*.yml&lt;/include&gt;                   &lt;/includes&gt;               &lt;/configuration&gt;           &lt;/plugin&gt;       &lt;/plugins&gt;   &lt;/build&gt;</code></pre><p>因为微服务<strong>依赖 xz_bigdata2</strong> 所以<strong>先打包xz_bigdata2</strong></p><p><strong>修改配置文件</strong></p><pre><code class="highlight plaintext">defaultZone: http://root:root@hadoop3:8761/eureka/</code></pre><p>将注册中心 IP 改为部署服务器的IP<br>微服务同理</p><p>上面给出的配置文件已经修改好了</p><p><strong>部署</strong></p><ol><li><strong>先部署Erueka服务中心</strong><br>新建**/usr/chl/springcloud/eureka**</li></ol><p><img src="/medias/%E9%83%A8%E7%BD%B2%E5%9C%B0%E6%96%B9.PNG" alt="部署地方"></p><p>上传jars 和jar</p><p><img src="/medias/eureka.PNG" alt="eureka"></p><ol start="2"><li><strong>启动服务中心</strong><br>eureka服务注册中心启动</li></ol><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/eureka/xz_bigdata_springcloud_eureka-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.eureka.EurekaApplication &amp;</code></pre><p>查看日志</p><pre><code class="highlight plaintext">tail -f nohup.out</code></pre><ol start="3"><li><strong>部署esquery</strong><br>esquery微服务启动</li></ol><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/esquery/xz_bigdata_springcloud_esquery-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.es.ESqueryApplication &amp;</code></pre><ol start="4"><li><strong>部署hbasequery</strong><br>hbasequery微服务启动</li></ol><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/hbasequery/xz_bigdata_springcloud_hbasequery-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.HbaseQueryApplication &amp;</code></pre><h4 id="9、执行-2">9、执行</h4><ol><li><p>hadoop3:8002/hbase/getRelation?field=phone&amp;fieldValue=18609765012<br><img src="/medias/10.PNG" alt="1"></p></li><li><p>hadoop3:8002/hbase/search1?table=phone&amp;rowkey=18609765012<br><img src="/medias/20.PNG" alt="2"></p></li><li><p>hadoop3:8002/hbase/getHbase?table=send_mail&amp;rowkey=65497873@qq.com<br><img src="/medias/30.PNG" alt="3"></p></li><li><p>hadoop3:8002/hbase/getHbase?table=phone&amp;rowkey=18609765012<br><img src="/medias/40.PNG" alt="4"></p></li><li><p>hadoop3:8002/hbase/search/phone/18609765012<br><img src="/medias/5.PNG" alt="5"></p></li><li><p>hadoop3:8003/es/getAllCount<br><img src="/medias/6.PNG" alt="6"></p></li><li><p>hadoop3:8003/es/getBaseInfo<br><img src="/medias/7.PNG" alt="7"></p></li><li><p>hadoop3:8003/es/getLocus<br><img src="/medias/8.PNG" alt="8"></p></li><li><p>hadoop3:8003/es/group<br><img src="/medias/9.PNG" alt="9"></p></li></ol><h3 id="十三、附录">十三、附录</h3><h4 id="1、测试数据">1、测试数据</h4><p><strong>mail_source1_1111101.txt</strong></p><pre><code class="highlight plaintext">00000000000001100000000000001123.00001124.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b32109246155730008865497873@qq.com178909076311111111@qq.com1789097863今天出去打球吗send00000000000001100000000000001124.00001125.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b32109246155730008565497873@qq.com178909076422222222@qq.com1789097864今天出去打球吗send00000000000001100000000000001123.00001124.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b32109246155730008865497873@qq.com178909076333333333@qq.com1789097863今天出去打球吗send00000000000001100000000000001124.00001125.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b32109246155730008565497873@qq.com178909076444444444@qq.com1789097864今天出去打球吗send00000000000000000000000000000023.00000124.000001aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb3210923115573059881323243@qq.com178909876343432543@qq.com1789098863今天出去打球吗send00000000000000000000000000000024.00000125.000001aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb3210923115573059851323243@qq.com178909876443432543@qq.com1789098864今天出去打球吗send00000000000000000000000000000023.00000124.000001aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb3210923115573059881323243@qq.com178909876343432543@qq.com1789098863今天出去打球吗send00000000000000000000000000000024.00000125.000001aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb3210923115573059851323243@qq.com178909876443432543@qq.com1789098864今天出去打球吗send</code></pre><p><strong>qq_source1_1111101.txt</strong></p><pre><code class="highlight plaintext">00000000000000000000000000000023.00000024.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305988andiy18609765432judy178909876200000000000000000000000000000024.00000025.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305985andiy18609765432judy178909876300000000000000000000000000000023.00000024.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305988andiy18609765432judy178909876200000000000000000000000000000024.00000025.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305985andiy18609765432judy178909876300000000000001100000000000001123.00001124.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300388xz18609765012ls178900065300000000000001100000000000001124.00001125.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300545xz18609765012ls178900034300000000000001100000000000001123.00001124.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300658xz18609765012ls178900054200000000000001100000000000001124.00001125.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300835xz18609765012ls178900026300000000000001100000000000001123.00002124.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557300388xz18609765016ls178900165300000000000001100000000000001124.00002125.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557302235xz18609765016ls178900134300000000000001100000000000001123.00002124.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557303658xz18609765016ls178900154200000000000001100000000000001124.00002125.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557303835xz18609765016ls178900126300000000000001100000000000001123.00003124.0000414c-6f-c7-3d-a4-3d9g-gd-3h-3k-ld-3f321092461557300001xz18609765014ls178905065300000000000001100000000000001124.00003125.0000517c-8e-d4-a6-3d-5c54-hg-gi-yx-ef-ge321092461557300005xz18609765015ls178907034300000000000001100000000000001123.00003124.0000618c-g1-ed-7b-5f-1b47-fy-vv-hs-ue-fd321092461557300008xz18609765017ls178908054200000000000001100000000000001124.00003125.0000710c-76-2a-b1-3c-1af5-nw-hf-ud-ht-ea321092461557300115xz18609765010ls1789082263</code></pre><p><strong>wechat_source1_1111101.txt</strong></p><pre><code class="highlight plaintext">00000000000000000000000000000023.00000024.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305988andiy18609765432judy178909876200000000000000000000000000000024.00000025.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305985andiy18609765432judy178909876300000000000000000000000000000023.00000024.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305988andiy18609765432judy178909876200000000000000000000000000000024.00000025.000000aa-aa-aa-aa-aa-aabb-bb-bb-bb-bb-bb321092311557305985andiy18609765432judy178909876300000000000001100000000000001123.00001124.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300388xz18609765012ls178900065300000000000001100000000000001124.00001125.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300545xz18609765012ls178900034300000000000001100000000000001123.00001124.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300658xz18609765012ls178900054200000000000001100000000000001124.00001125.0000111c-41-cd-b1-df-3f1b-3d-zg-fg-ef-1b321092461557300835xz18609765012ls178900026300000000000001100000000000001123.00002124.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557300388xz18609765016ls178900165300000000000001100000000000001124.00002125.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557302235xz18609765016ls178900134300000000000001100000000000001123.00002124.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557303658xz18609765016ls178900154200000000000001100000000000001124.00002125.0000311c-31-5d-b1-6f-3f3y-5g-g6-du-bv-2f321092461557303835xz18609765016ls178900126300000000000001100000000000001123.00003124.0000414c-6f-c7-3d-a4-3d9g-gd-3h-3k-ld-3f321092461557300001xz18609765014ls178905065300000000000001100000000000001124.00003125.0000517c-8e-d4-a6-3d-5c54-hg-gi-yx-ef-ge321092461557300005xz18609765015ls178907034300000000000001100000000000001123.00003124.0000618c-g1-ed-7b-5f-1b47-fy-vv-hs-ue-fd321092461557300008xz18609765017ls178908054200000000000001100000000000001124.00003125.0000710c-76-2a-b1-3c-1af5-nw-hf-ud-ht-ea321092461557300115xz18609765010ls1789082263</code></pre><h4 id="2、Kafka">2、Kafka</h4><p>创建topic，1个副本3个分区<br>kafka-topics --zookeeper hadoop1:2181 --topic chl_test7 --create --replication-factor 1 --partitions 3</p><p><strong>删除topic</strong><br>kafka-topics --zookeeper hadoop1:2181 --delete --topic chl_test7</p><p><strong>列出所有的topic</strong><br>kafka-topics --zookeeper hadoop1:2181 --list</p><p><strong>消费</strong><br>kafka-console-consumer --bootstrap-server hadoop1:9092 --topic chl_test7 --from-beginning</p><h4 id="3、kafka2es">3、kafka2es</h4><p><strong>启动sparkstreaming任务</strong></p><pre><code class="highlight plaintext">spark-submit --master yarn-cluster --num-executors 1 --driver-memory 500m --executor-memory 1g --executor-cores 1 --jars $(echo /usr/chl/spark7/jars/*.jar | tr ' ' ',') --class com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar chl_test7 chl_test7</code></pre><pre><code class="highlight plaintext">spark-submit --master yarn-cluster    //集群启动--num-executors 1        //分配多少个进程--driver-memory 500m  //driver内存--executor-memory 1g //进程内存--executor-cores 1       //开多少个核，线程--jars $(echo /usr/chl/spark8/jars/*.jar | tr ' ' ',') //加载jar--class com.hsiehchou.spark.streaming.kafka.kafka2es.Kafka2esStreaming //执行类 /usr/chl/spark8/xz_bigdata_spark-1.0-SNAPSHOT.jar //包的位置</code></pre><h4 id="4、Yarn">4、Yarn</h4><p><strong>将yarn的执行日志输出</strong><br>yarn logs -applicationId application_1561627166793_0002 &gt; log.log</p><p><strong>查看日志</strong><br>more log.log</p><p>cat log.log</p><h4 id="5、CDH的7180打不开">5、CDH的7180打不开</h4><p><strong>查看cloudera-scm-server状态</strong><br>service cloudera-scm-server status</p><p><strong>查看cloudera-scm-server 日志</strong><br>cat /var/log/cloudera-scm-server/cloudera-scm-server.log</p><p><strong>重启cloudera-scm-server</strong><br>service cloudera-scm-server restart</p><h4 id="6、CDH的jdk设置—重要">6、CDH的jdk设置—重要</h4><p><strong>/usr/local/jdk1.8</strong></p><h4 id="7、预警">7、预警</h4><pre><code class="highlight plaintext">spark-submit --master local[1] --num-executors 1 --driver-memory 300m --executor-memory 500m --executor-cores 1 --jars $(echo /usr/chl/spark7/jars/*.jar | tr ' ' ',') --class com.hsiehchou.spark.streaming.kafka.warn.WarningStreamingTask /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</code></pre><h4 id="8、Kibana的DEV-Tools">8、Kibana的DEV Tools</h4><pre><code class="highlight plaintext">GET _search{  "query": {    "match_all": {}  }}GET  _cat/indicesDELETE tanslator_test1111DELETE qqDELETE wechatDELETE mailGET wechatGET mailGET _searchGET mail/_searchGET mail/_mappingPUT mailPUT mail/mail/_mapping{  "_source": {    "enabled": true  },  "properties": {    "imei":{"type": "keyword"},    "imsi":{"type": "keyword"},    "longitude":{"type": "double"},    "latitude":{"type": "double"},    "phone_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_number":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "collect_time":{"type": "long"},    "send_mail":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "send_time":{"type": "long"},    "accept_mail":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "accept_time":{"type": "long"},    "mail_content":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "mail_type":{"type": "keyword"},     "id":{"type": "keyword"},    "table":{"type": "keyword"},    "filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "absolute_filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}GET qq/_searchGET qq/_mappingPUT qqPUT qq/qq/_mapping{  "_source": {    "enabled": true  },  "properties": {    "imei":{"type": "keyword"},    "imsi":{"type": "keyword"},    "longitude":{"type": "double"},    "latitude":{"type": "double"},    "phone_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_number":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "collect_time":{"type": "long"},    "username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "phone":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "object_username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "send_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "accept_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "message_time":{"type": "long"},"id":{"type": "keyword"},    "table":{"type": "keyword"},    "filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "absolute_filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}GET wechat/_searchGET wechat/_mappingPUT wechatPUT wechat/wechat/_mapping{  "_source": {    "enabled": true  },  "properties": {    "imei":{"type": "keyword"},    "imsi":{"type": "keyword"},    "longitude":{"type": "double"},    "latitude":{"type": "double"},    "phone_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_mac":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "device_number":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "collect_time":{"type": "long"},    "username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "phone":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "object_username":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "send_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "accept_message":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "message_time":{"type": "long"},    "id":{"type": "keyword"},    "table":{"type": "keyword"},    "filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}},    "absolute_filename":{"type": "text","fields": {"keyword": {"ignore_above": 256,"type": "keyword"}}}  }}</code></pre><h4 id="9、Hive">9、Hive</h4><p><strong>kafka写入hive</strong></p><pre><code class="highlight plaintext">spark-submit --master local[1] --num-executors 1 --driver-memory 300m --executor-memory 500m --executor-cores 1 --jars $(echo /usr/chl/spark7/jars/*.jar | tr ' ' ',') --class com.hsiehchou.spark.streaming.kafka.kafka2hdfs.Kafka2HiveTest /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</code></pre><pre><code class="highlight plaintext">show tables;hdfs dfs -ls /apps/hive/warehouse/externalhdfs dfs -rm -r /apps/hive/warehouse/external/maildrop table mail;desc qq;select * from qq limit 1;注意了：cdh的hive版本跟其对应的spark版本不一致的话此处执行不了select count(*) from qq;</code></pre><p><strong>合并小文件</strong></p><pre><code class="highlight plaintext">crontab -e0 1 * * * spark-submit --master local[1] --num-executors 1 --driver-memory 300m --executor-memory 500m --executor-cores 1 --jars $(echo /usr/chl/spark7/jars/*.jar | tr ' ' ',') --class com.hsiehchou.spark.streaming.kafka.kafka2hdfs.CombineHdfs /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</code></pre><p><img src="/medias/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1crontab.PNG" alt="定时任务crontab"></p><h4 id="10、Zookeeper">10、Zookeeper</h4><p><strong>启动zookeeper客户端</strong><br>zookeeper-client</p><p><strong>清除消费者</strong><br>rmr /consumers/WarningStreamingTask2/offsets</p><p>rmr /consumers/Kafka2HiveTest/offsets</p><p>rmr /consumers/DataRelationStreaming1/offsets</p><h4 id="11、Hbase">11、Hbase</h4><pre><code class="highlight plaintext">spark-submit --master local[1] --num-executors 1 --driver-memory 500m --executor-memory 1g --executor-cores 1 --jars $(echo /usr/chl/spark7/jars/*.jar | tr ' ' ',') --class com.hsiehchou.spark.streaming.kafka.kafka2hbase.DataRelationStreaming /usr/chl/spark7/xz_bigdata_spark-1.0-SNAPSHOT.jar</code></pre><pre><code class="highlight plaintext">hbase shelllistcreate 't1','cf'desc 't1'put 't1','aa-aa-aa-aa-aa-aa','cf:qq','66666666'put 't1','aa-aa-aa-aa-aa-aa','cf:weixin','weixin1'put 't1','aa-aa-aa-aa-aa-aa','cf:mail','66666@qq.com'scan 't1'将表变成多版本alter 't1',{NAME=&gt;'cf',VERSIONS=&gt;50}put 't1','aa-aa-aa-aa-aa-aa','cf:qq','77777777'get 't1','aa-aa-aa-aa-aa-aa',{COLUMN=&gt;'cf',VERSIONS=&gt;10}put 't1','aa-aa-aa-aa-aa-aa','cf:qq','55555555'put 't1','aa-aa-aa-aa-aa-aa','cf:qq','88888888',1290300544执行DataRelationStreamingscan 'test:relation'get 'test:username','andiy'scan 'test:relation'mail 改mac 邮箱get  'test:relation','',{COLUMN=&gt;'cf',VERSIONS=&gt;10}disable 'test:imei'drop 'test:imei'disable 'test:imsi'drop 'test:imsi'disable 'test:phone'drop 'test:phone'disable 'test:phone_mac'drop 'test:phone_mac'disable 'test:relation'drop 'test:relation'disable 'test:send_mail'drop 'test:send_mail'disable 'test:username'drop 'test:username'</code></pre><h4 id="12、SpringCloud">12、SpringCloud</h4><p><strong>eureka服务注册中心启动</strong></p><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/eureka/xz_bigdata_springcloud_eureka-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.eureka.EurekaApplication &amp;</code></pre><p><strong>查看日志</strong></p><pre><code class="highlight plaintext">tail -f nohup.out</code></pre><p><strong>esquery微服务启动</strong></p><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/esquery/xz_bigdata_springcloud_esquery-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.es.ESqueryApplication &amp;</code></pre><p><strong>hbasequery微服务启动</strong></p><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/hbasequery/xz_bigdata_springcloud_hbasequery-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.HbaseQueryApplication &amp;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据项目 </tag>
            
            <tag> 网络日志分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Eureka服务注册中心启动</title>
      <link href="/2019/07/25/eureka_fu_wu_zhu_ce_zhong_xin_qi_dong/"/>
      <url>/2019/07/25/eureka_fu_wu_zhu_ce_zhong_xin_qi_dong/</url>
      
        <content type="html"><![CDATA[<p><strong>nohup启动（nohup不间断运行）</strong></p><pre><code class="highlight plaintext">nohup java -cp /usr/chl/springcloud/eureka/xz_bigdata_springcloud_eureka-1.0-SNAPSHOT.jar com.hsiehchou.springcloud.eureka.EurekaApplication &amp;</code></pre><p><strong>查看日志</strong></p><pre><code class="highlight plaintext">tail -f nohup.out</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringCloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
            <tag> Eureka </tag>
            
            <tag> nohup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ZooKeeper清除已有的消费的offsets</title>
      <link href="/2019/07/23/zookeeper_qing_chu_yi_you_de_xiao_fei_de_offsets/"/>
      <url>/2019/07/23/zookeeper_qing_chu_yi_you_de_xiao_fei_de_offsets/</url>
      
        <content type="html"><![CDATA[<p><strong>CDH集群中的ZooKeeper</strong></p><p><strong>启动ZooKeeper客户端</strong><br>zookeeper-client</p><p><strong>清除消费者</strong></p><p><strong>例如</strong><br>rmr /consumers/WarningStreamingTask/offsets</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ZooKeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SparkStreaming+Kafka的两种模式Receiver模式和Direct模式</title>
      <link href="/2019/07/19/sparkstreaming_kafka_de_liang_chong_mo_shi_receiver_mo_shi_he_direct_mo_shi/"/>
      <url>/2019/07/19/sparkstreaming_kafka_de_liang_chong_mo_shi_receiver_mo_shi_he_direct_mo_shi/</url>
      
        <content type="html"><![CDATA[<h3 id="SparkStreming-Kafka-Receiver模式理解">SparkStreming + Kafka Receiver模式理解</h3><p><img src="/medias/kafka%E7%9A%84receiver%E6%A8%A1%E5%BC%8F.PNG" alt="Kafka的Receiver模式"></p><h4 id="Receiver模式理解">Receiver模式理解</h4><p>在SparkStreaming程序运行起来后，Executor中会有Receiver Tasks接收Kafka推送过来的数据。数据会被持久化，默认级别为MEMORY_AND_DISK_SER_2,这个级别也可以修改。Receiver Task对接收过来的数据进行存储和备份，这个过程会有节点之间的数据传输。备份完成后去ZooKeeper中更新消费偏移量，然后向Driver中的Receiver Tracker汇报数据的位置。最后Driver根据数据本地化将Task分发到不同节点上执行。</p><h4 id="Receiver模式中存在的问题">Receiver模式中存在的问题</h4><p>当Driver进程挂掉后，Driver下的Executor都会被杀掉，当更新完ZooKeeper消费偏移量的时候，Driver如果挂掉了，就会存在找不到数据的问题，相当于丢失数据。</p><h4 id="如何解决这个问题？">如何解决这个问题？</h4><p>开启WAL(write ahead log)预写日志机制,在接受过来数据备份到其他节点的时候，同时备份到HDFS上一份（我们需要将接收来的数据的持久化级别降级到MEMORY_AND_DISK），这样就能保证数据的安全性。不过，因为写HDFS比较消耗性能，要在备份完数据之后才能进行更新ZooKeeper以及汇报位置等，这样会增加job的执行时间，这样对于任务的执行提高了延迟度。</p><h4 id="注意">注意</h4><ol><li>开启WAL之后，接受数据级别要降级，有效率问题</li><li>开启WAL要checkpoint</li><li>开启WAL(write ahead log),往HDFS中备份一份数据</li></ol><h3 id="SparkStreming-Kafka-Receiver模式理解-2">SparkStreming + Kafka Receiver模式理解</h3><p><img src="/medias/kafka%E7%9A%84direct%E6%A8%A1%E5%BC%8F.PNG" alt="Kafka的Direct模式"></p><ol><li>简化数据处理流程</li><li>自己定义offset存储，保证数据0丢失，但是会存在重复消费问题。（解决消费等幂问题）</li><li>不用接收数据，自己去Kafka中拉取</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Kafka </tag>
            
            <tag> SparkStreaming </tag>
            
            <tag> Receiver </tag>
            
            <tag> Direct </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch的9200端口和9300端口的区别</title>
      <link href="/2019/07/18/elasticsearch_de_9200_duan_kou_he_9300_duan_kou_de_qu_bie/"/>
      <url>/2019/07/18/elasticsearch_de_9200_duan_kou_he_9300_duan_kou_de_qu_bie/</url>
      
        <content type="html"><![CDATA[<p>9200端口作为HTTP协议，<strong>主要用于外部通讯</strong></p><p>9300端口作为TCP协议，jar之间就是通过 <strong>TCP协议通讯</strong></p><p><strong>ES集群之间是通过9300端口进行通讯</strong></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch集群配置</title>
      <link href="/2019/07/06/elasticsearch_ji_qun_an_zhuang_pei_zhi/"/>
      <url>/2019/07/06/elasticsearch_ji_qun_an_zhuang_pei_zhi/</url>
      
        <content type="html"><![CDATA[<p><strong>安装Elasticsearch</strong><br>mkdir /opt/software/elasticsearch/data/</p><p>mkdir /opt/software/elasticsearch/logs/</p><p>chmod 777 /opt/software/elasticsearch/data/</p><p>useradd elasticsearch<br>passwd elasticsearch</p><p>chown -R elasticsearch elasticsearch/</p><p><strong>vim /etc/security/limits.conf</strong><br>添加如下内容:<br><code>*</code> <strong>soft nofile 65536</strong><br><code>*</code> <strong>hard nofile 131072</strong><br><code>*</code> <strong>soft nproc 2048</strong><br><code>*</code> <strong>hard nproc 4096</strong></p><p>进入limits.d目录下修改配置文件<br><strong>vim /etc/security/limits.d/90-nproc.conf</strong></p><p>修改如下内容：<br><strong>soft nproc 4096（修改为此参数，6版本的默认就是4096）</strong></p><p>修改配置sysctl.conf<br><strong>vim /etc/sysctl.conf</strong></p><p>添加下面配置：<br><strong>vm.max_map_count=655360</strong></p><p>并执行命令：<br><strong>sysctl -p</strong></p><p><strong>hadoop1的conf配置</strong><br><strong>elasticsearch.yml</strong></p><pre><code class="highlight plaintext">cluster.name: xz_esnode.name: node-1node.master: truenode.data: truepath.data: /opt/software/elasticsearch/datapath.logs: /opt/software/elasticsearch/logsbootstrap.memory_lock: falsebootstrap.system_call_filter: falsenetwork.host: 192.168.116.201discovery.zen.ping.unicast.hosts: ["hadoop1", "hadoop2", "hadoop3"]</code></pre><p><strong>jvm.options</strong><br>修改下<br>-Xms64m<br>-Xmx64m</p><p><strong>hadoop2的conf配置</strong><br><strong>elasticsearch.yml</strong></p><pre><code class="highlight plaintext">cluster.name: xz_esnode.name: node-2node.master: falsenode.data: truepath.data: /opt/software/elasticsearch/datapath.logs: /opt/software/elasticsearch/logsbootstrap.memory_lock: falsebootstrap.system_call_filter: falsenetwork.host: 192.168.116.202discovery.zen.ping.unicast.hosts: ["hadoop1", "hadoop2", "hadoop3"]</code></pre><p><strong>jvm.options</strong><br>修改下<br>-Xms64m<br>-Xmx64m</p><p><strong>hadoop3的conf配置</strong><br><strong>elasticsearch.yml</strong></p><pre><code class="highlight plaintext">cluster.name: xz_esnode.name: node-3node.master: falsenode.data: truepath.data: /opt/software/elasticsearch/datapath.logs: /opt/software/elasticsearch/logsbootstrap.memory_lock: falsebootstrap.system_call_filter: falsenetwork.host: 192.168.116.203discovery.zen.ping.unicast.hosts: ["hadoop1", "hadoop2", "hadoop3"]</code></pre><p><strong>jvm.options</strong><br>修改下<br>-Xms64m<br>-Xmx64m</p><p><strong>Kibana的conf配置</strong></p><p><strong>kibana.yml</strong></p><pre><code class="highlight plaintext">server.port: 5601server.host: "192.168.116.202"elasticsearch.url: "http://192.168.116.201:9200"</code></pre><p><strong>运行Elasticsearch</strong><br>cd /opt/software/elasticsearch<br>su elasticsearch<br>bin/elasticsearch &amp;</p><p><strong>运行Kibana</strong><br>cd /opt/software/kibana/<br>bin/kibana &amp;</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一万小时天才理论（阅读笔记）</title>
      <link href="/2019/06/19/yi_wan_xiao_shi_tian_cai_li_lun/"/>
      <url>/2019/06/19/yi_wan_xiao_shi_tian_cai_li_lun/</url>
      
        <content type="html"><![CDATA[<p><strong>一万小时天才理论（阅读笔记）</strong></p><h3 id="前言"><strong>前言</strong></h3><p>上大一时，我就听人讲过一个人只要在一个领域专攻1万小时，那么这个人便会成为这个领域的专家，把时间分配到每天3小时，需要10年，每天8小时（当然这很不现实，不可能工作的所有时间都花在学习上，还有周末休息啥的），原则上4年就够了。</p><h3 id="总结"><strong>总结</strong></h3><p>1、中国目前发展飞速，想要在这个大的环境中生存，必须靠自己，靠别人是永远靠不住的，因为你永远不知道别人办事的进度，可能什么都没做，也可能做的差不多了。总之，相信自己，依靠自己，才能生存。</p><p>2、遗传因素对我们对影响不大，所以，还是需要靠我们后天的学习和发展才能壮大自己。</p><p>3、犯错不用怕，怕的是犯错了不去找解决的方法，这样永远不会进步的。我们可以从犯错中总结有效的解决方法，发现问题，解决问题。</p><p>4、学会去爱做一件事或者很多事，当自己爱上了做这些事，便会发现用的这些时间并不是浪费，花得值得，养成一种习惯，成为这个领域的专家。6分钟的时间可以学到很多，只要自己坚持去做，自己会在不知不觉中受益。</p><h3 id="第一部分-精深"><strong>第一部分 精深</strong></h3><h3 id="01-冒牌哈佛"><strong>01 冒牌哈佛</strong></h3><p><strong>谁也不能随随便便成功，它来自彻底的自我管理和毅力</strong> 。 ——哈佛图书馆训言</p><p><strong>犯错让你更聪明</strong> 。                                                               ——德国寓言</p><p>我们需要去完成我们和别人都认为不可能完成的任务，突破自己的极限。</p><p>在不断精深练习中培养自己的技能，让这种动作成为自己的习惯，不需要通过大脑的深度思考，当遇到这种情况，我们不需要考虑就能自动的进行相应的操作。这跟人类的潜意识的养成相似，也可以说一样的（我是这么认为的）。</p><p>需要 <strong>不断地进行正确的精深练习</strong> ，学习到独特的体会和技巧，让其成为自己的一种能力，潜意识就可以办到。</p><h3 id="02-才能细胞"><strong>02 才能细胞</strong></h3><p>髓鞘质是在我们不断地进行精深练习后不断地增加厚度、变厚。改善自己的神经回路，优化自己的神经回路。</p><p>需要 <strong>有明确的目标</strong> 、 <strong>重视错误的练习</strong> ，这样我们便可以 <strong>不断地去发现问题</strong> 、 <strong>处理问题</strong> 。在这个过程中我们需要 <strong>保持激情和坚持</strong> ，只有这样才能 <strong>让自己的髓鞘质进化到巅峰水平</strong> 。</p><p>人的各种行动都是通过大脑发出的指令信号来进行的，进行各种预判，对可能发生的情况进行预估，做出对应的对策。当自己的经验越多，自己会不知不觉的完成很多的事情，自己都没有察觉自己做了什么。髓鞘质对于大脑的神经信息处理非常的关键，它能把握住时间点， <strong>该出手时就出手</strong> ，控制大脑传输速度，让各种信号准时到达。</p><p>髓鞘质无法逆转，一旦技能回路包裹上了绝缘体，那将无法去除。髓鞘质只在乎我们自己做了什么，它把这些技能更好的发扬光大，让我们充分利用。</p><p>任何领域的任何专家都要经过10000小时专心致志地学习。</p><p>我们通过不断地精深练习，达到1万小时后，便能成为这个领域的专家，人才的培养最好从小时候就开始，这个幼时的不断地练习会让孩子一生受益（我们人人都可以这样，但必须投入足够的时间去做）。</p><h3 id="03-天降人才"><strong>03 天降人才</strong></h3><p>我们做任何事情都需要坚持到最后，不能快到终点了自己就放弃了，只要熬过最后的这一分钟，我们便能做成这件事，实现自己的梦想。</p><p>一个人的成功离不开他 <strong>自身的努力</strong> ，我们往往看到的是那些成功人士眼前的辉煌，但是没法看到他们背后付出的辛酸和泪水。 <strong>一个人的成功离不开自己默默地付出</strong> ，需要 <strong>自己一个人慢慢地前行</strong> ，探索未知的领域，当自己慢慢摸透了这个未知的领域，自己便可以翱翔其中。</p><p>我们的髓鞘质不在乎我们是谁，只关心我们做了什么，把这些做的东西经过我们的日积月累慢慢地形成我们的技能。</p><p><strong>文艺复兴时期伟大的艺术家的特点：</strong></p><p>每个人都把大部分的青春岁月投入在精深练习上，锤炼和优化技能回路，纠错，竞争，然后进步。每个人都参与了这副任何人都能创作的最伟大的艺术作品：构建自己的才能。</p><p><strong>造成青少年做出错误的决定的原因：</strong></p><p>冲动行为发生时，神经回路不会马上去阻止这个冲动行为，尽管它是可以的，青少年需要自己花时间去体会。</p><p>我们需要不断地学习，学习经验，因为髓鞘质也是会消亡的，我们需要生成新的髓鞘质来对已经消亡的髓鞘质做个补充。</p><p>读了本章，深刻体会到了髓鞘质对我们人类潜力的巨大作用，它在更新，也在消亡，但是我们需要不断地学习、不断地强化我们的髓鞘质（就是不断地进行精深练习），那我们的能力便会飞快的提升，从而成为一个领域的专家。</p><h3 id="04-三大秘技"><strong>04 三大秘技</strong></h3><p><strong>屡败屡战。屡战屡败。败了更好</strong> 。   ——塞缪尔·贝克特(Samuel Beckett)</p><p><strong>哇塞效应</strong></p><p><strong>组块化：</strong></p><p>整体吸收：花时间观察或者倾听自己想学习的技能，将技能具体化。</p><p>学会最高效地去模仿别人，把握住技巧，将学习的东西拆分成一个个的小模块，慢慢练习，找到自己的感觉，渐渐地就变成了自己的技能了。</p><p><strong>重复练习：</strong></p><p>我们不管干什么事，只要长时间不练习，我们便会忘记，这是我们人类的记忆规律。所以，想要掌握某一技能，就必须不间断地练习，每天练习2小时也好，只要不长时间地隔1个月不练习就行了。</p><p><strong>尝试体会：</strong></p><p>我们需要 <strong>自己切身去体会做</strong> ，不能看着别人感觉自己完成不了，我们需要去挑战自己，自己去体会，可能别人做不了的任务，而你却可以。有了这种尝试，我们就不再害怕，便对这些事感觉很平常。</p><p>除了亲自体会外，我们还需要自己去不断地练习，找到那种感觉，就是将那种要完成的任务牢牢地掌握在自己手心里。</p><p>注意力、连接、建立、完整的、警觉、关注、错误、重复、疲劳、边缘、唤醒</p><h3 id="第二部分-激情"><strong>第二部分 激情</strong></h3><h3 id="05-信号"><strong>05 信号</strong></h3><p>1、技能学习需要精深练习。</p><p>2、精深练习需要精力、激情和投入。</p><pre><code> 激情的存在就像为我们提供动力火箭的原料，维持我们不停地重新开始，锻炼技巧，不断进步。</code></pre><p>3、一次突破性的胜利，接着就会涌现出大规模的"人才井喷"。</p><p>4、总之，精深练习需要时间（1万小时的练习）。</p><p>我们意识到"我就想成为那样的人"的时刻，这就是激情工作的原理。只有激情才能刺激自己不断地突破极限。</p><p><strong>小小念头，影响深远</strong></p><p>短期承诺、中期承诺、长期承诺</p><p>研究表明，长期承诺的孩子，哪怕每周只花20分钟进行练习，也比那些花1个半小时的孩子进步神速。长期承诺的孩子充分的练习，技能已经出神入化了。</p><p>我想成为那样的人，可能就因为这个小小的念头，让我们改变一生，让我们走向成功。</p><p><strong>启动信号</strong></p><p>我们如果能够放弃眼前的舒适，去熬那些艰难的时光的话，就是让我们变成一个自己想要变成的人，自己为之不断地奋斗。</p><p>每个强烈的刺激人大脑神经的能让人立马行动信号指引人去做超级有意义的事情。这针对未来的归属感。</p><p>书上讲缺乏安全感会激发和引导自己的大脑去解决危险，处理生命中的可能性。</p><p>生活的不再安全让那些人开启了古老的自我保护的进化开关，从而让他们倾入时间和精力去耕耘事业，渐渐地，他们完成了一万小时的精深练习，养成了各自的才能。</p><p><strong>统治所有人的普遍原则：</strong></p><p>1、才能需要精深练习</p><p>2、精深练习需要充分的能量</p><p>3、某些信号会触发巨大能量的迸发</p><p>研究表明，往往家中老四是成就最高的。造成这种状况的原因是，家中老四，生得较晚，因为有兄长在前面作为榜样，往往会不断地去追赶自己的兄长们，长时间的练习形成了一种习惯，从而让自己最终走向人生的高处。</p><p><strong>好运临门</strong></p><p>稀缺感、归属感、安全感，通过激发人类自己的欲望，不断地针对这个去刺激自己。激情需要长久， <strong>长期的激情</strong> ， <strong>不断地去向自己地目标奋斗</strong> 。</p><h3 id="06-疯狂地海岛"><strong>06 疯狂地海岛</strong></h3><p><strong>打破保守，走出去，让激情之火不灭，永远保持</strong> ，这在开始的时候是非常困难的，但是一旦自己习惯了这种激情，便永远浇不灭了。</p><p>"嘿！你也可以"</p><p>相信自己，不停地去练习，一定会有很大收获的。</p><p><strong>激情的语言</strong></p><p>那些 <strong>鼓励的语言是我们前进的最大的动力</strong> 。（番外，这里让我想起了我高二的那个英语老师，我们英语差的从来不鼓励，破骂一顿，好像我们欠了她一个亿，那些英语好的基础好，表扬得不得了，醉了，反正我周围的同学都讨厌她；反之，我高二的物理老师，不断地鼓励我们，我高中物理总拿A（高三还进入了省级的物理竞赛，当然了省考特别难，什么都不会，写了点字也拿了个江苏省物理竞赛三等奖），而且当时我们班物理在整个理科都是佼佼者，有时候平均分超其他班20-30分，是不是有点过，这样的好的情况到了高三换了老师就没了，而且我们当时物理竞赛去省赛的5个人，其中4个都是我们高二物理老师教过的），我们这位物理老师，只要考好了，就有电影看，极大地刺激了我们的学习的动力。</p><p>激励性的语言是鼓励人们争取不断进步的语言，让我们向希望、梦想不断的前进。</p><p>精深练习需要深入认真的工作以及热情的劲头，集中我们的精力，然后慢慢进步。</p><p>赞人们勤奋的语句之所以有效，是因为它直达学习的核心，而想要点燃激情，没有比这更强大的了。</p><h3 id="07-点燃明灯"><strong>07 点燃明灯</strong></h3><p><strong>教育不是在填坑，而是点燃照明之火。</strong> ——叶芝</p><p><strong>X一代的荒谬念头</strong></p><p>KIPP这所学校的诞生也是原来两个创始人的一个奇特的想法，不再与教育系统抗衡，而是打算开办一所自己的学校。刚开始的一两年学校办的整体效果并不怎么好，但是，突然间，学生都变得非常优秀，我个人认为这是哲学上的量变向质变的转化，学生长时间的培养好的习惯，培养他们的思维，让他们能有自己的独立的想法，能安心做任何事情，学生成绩的提高就是KIPP学校使用这种模式的见证。</p><p>努力培养学生的整体素质，而不单纯是为了提高学生的学习成绩。学生做的任何一件事都会与其它事情有关联，这便让学生养成随时思考的好习惯，当学生独立生活时，他们便日子过得很滋润。</p><p>培养学生，一旦学生懂了，基本不需要老师去教了，自己会去学习的，所以KIPP就是这样的，为的是让学生终生受益，而不是为的只是学习成绩的提高。</p><h3 id="第三部分-伯乐"><strong>第三部分 伯乐</strong></h3><h3 id="08-伯乐的武器"><strong>08 伯乐的武器</strong></h3><p>伯乐，自古以来就流传很久，古传是伯乐相马，对马的研究非常出色，优质的马在他眼中是逃不掉的。古代就已经将伯乐相马比喻善于识别人才，爱惜人才。</p><p>一个好的伯乐是能找出自己要看的人的任何优点包括缺点，一眼就能看出来。长处、短处都能识别，优秀的人才在这里能够展现雄姿。</p><p>该怎么做，怎么做，何时强化。这样，不是那样。</p><p>上面那句红色的是著名的约翰·伍顿教练教他的学员的原则，先示范正确的动作，后示范错误的动作，最后再示范正确的动作。教学员该做什么，哪怕穿袜子这种简单的他都教学员，让其不容易起水泡。事实证明，他的教得非常得成功。</p><p>那些KEEP项目的人将其用在了阅读上，效果非常明显，还获得了格威文美尔奖。</p><p><strong>点燃热爱的火花</strong></p><p>一个人爱上做一件事是很难的，如果让一个人爱上一个事业是更难的，在打拼的过程中会遇到各种的磨难，克服它们是对我们的一种考验。</p><p>约翰·伍顿使用了人才理论中精深练习的部分，提供知识，纠正错误，加强技能回路。而玛丽对付的是激情部分，利用情绪开关，在邮箱中加满爱和动机。他们都取得了成功，因为髓鞘质回路不仅需要精深练习，也需要激情；他们的成功真实反应了天才理论的本身。</p><h3 id="09-伯乐的一万小时"><strong>09 伯乐的一万小时</strong></h3><p><strong>"我可不是为了钱，我只是在做自己喜欢的事情。当我还是个孩子的时候我就梦想成为奥运冠军。"</strong>                                               ——迈克尔·菲尔普斯</p><p><strong>教师的影响是永恒的；他永远无法知道自己的影响有多深远。</strong>      ——亨利·亚当斯</p><p><strong>教师的四大优势</strong></p><p>一个好的老师是关心学生的一言一行的，而且通过这种关心，可以利用他们老师自己对该课题已有的深刻的理解，捕捉到学生在技能学习道路上碰到的障碍，以及摸索过程中难以形容的状态，然后按照已经设定的目标与学生进行沟通。</p><p>老师是学生的学习导师，也是学生的人生导师，对学生前进的路起着向导的作用。这便要求导师有非常优秀的洞察力，能够找出学生目前的困难的解决方案的突破口，给出正确的信号，帮助学生达到真正的目标，并反复这个过程。</p><p><strong>优势一：知识矩阵 —— 伯乐的杀手锏</strong></p><p>知识矩阵是教练老师多年的技术上的知识、策略、经验等，是他们多年来知识等的总结，他们对自己的领域是非常的熟悉的，因为他们几乎全部遇到过，肯定都找到了解决方案了。他们对学生所遇到的几乎所有问题都是非常清楚的，可以不时的点拨下自己的学生。教练跟老师的知识矩阵并不是与生俱来的，而是通过激情和精深练习逐渐掌握的。</p><p>作为一个人，不可能做任何事情都很符合标准，多听听别人的建议，对自己进行相应的改进，成为一个优秀的人。不断地去尝试，不要放弃，增加自己的经验，然后通过精深练习，不断地掌握自己这个领域。</p><p><strong>优势二：洞察力 —— 鹰的视力</strong></p><p>教练跟老师都需要有敏锐的洞察力，对自己的学生要时刻进行观察，从观察中可以发现问题，从而解决问题，提高学生的整体素养。</p><p><strong>优势三：简明的指示 —— 神奇的教鞭</strong></p><p>作为一名导师，需要对他的学生进行指导，优秀的指导是直接指出错误，并给出一些专业的建议，话不需要多，言简意赅。导师不用说太多的废话，因为废话，学生听了没多大用，有用的信息不多，所以只要让学生知道自己的哪里有错并去改正就行了。</p><p><strong>优势四：气质与诚信 —— 不可阻挡的魅力</strong></p><p>导师需要有自己气质，有自己的个性。道德跟诚信是导师最需要的，因为作为一名导师，不能一直给自己的学生讲他已经知道的东西，这样学生不会成长，需要指出一个方向，按照导师自己规划的方向便可以走向自己能够达到的高度。</p><p><strong>足球训练与小提琴练习</strong></p><p>首先，足球训练与小提琴练习是大不相同的，这两样老师培养的性质是不一样的。</p><p>一个需要亲身体会技巧，自己琢磨技巧，老师是不能亲身感受到的，而另一个没有正确的技法便不会有好的结果，所以培养学生需要因行业而异。</p><p>实战中感悟技法是比老师传授的更加的好，因为这自己的实际情况是一致的，自己判断问题，解决问题。</p><h3 id="10-伯乐的赌注"><strong>10 伯乐的赌注</strong></h3><p>**教师就是为了逐步淡出。 **           ——托马斯·卡拉瑟斯 (Thomas Carruthers)</p><p>一名导师教了很多学生，培养人才，当学生远航的时候，自己留在原地仰望自己的学生，学生的成功自己便满足了。</p><p>导师对学生的教导也是赌注，可能失败也可能成功，毕竟不可能一种方法适合各种人，所以需要导师来对不同的学生选择不同的教导方法，这就考验导师的眼力了。</p><h3 id="后记"><strong>后记</strong></h3><p>如果出现问题，问5次为什么。先自己去看看能不能解决问题，去查找资料，再解决不了的话才去请教别人。</p><p>我们干什么事都 <strong>不要害羞</strong> ， <strong>克服自己的害怕的心理</strong> ，对自己害怕的领域不断地进行磨练，让自己变得娴熟，不再害怕。</p><p><strong>人脑越用越灵活</strong> 。</p>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书 </tag>
            
            <tag> 个人感悟 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统定时任务</title>
      <link href="/2019/06/04/xi_tong_ding_shi_ren_wu/"/>
      <url>/2019/06/04/xi_tong_ding_shi_ren_wu/</url>
      
        <content type="html"><![CDATA[<h3 id="crond系统定时任务">crond系统定时任务</h3><h4 id="1、crond服务管理">1、crond服务管理</h4><p>service crond restart （重新启动服务）</p><h4 id="2、crontab定时任务设置">2、crontab定时任务设置</h4><p><strong>1）基本语法</strong><br>crontab [选项]<br>选项：<br>-e：  编辑crontab定时任务<br>-l：  查询crontab任务<br>-r：  删除当前用户所有的crontab任务</p><p><strong>2）参数说明</strong><br>crontab -e<br>（1）进入crontab编辑界面。会打开vim编辑你的工作<br><code>* * * * *</code> 执行的任务</p><table><thead><tr><th style="text-align:center">项目</th><th style="text-align:center">含义</th><th style="text-align:center">范围</th></tr></thead><tbody><tr><td style="text-align:center">第一个“*”</td><td style="text-align:center">一小时当中的第几分钟（分）</td><td style="text-align:center">0-59</td></tr><tr><td style="text-align:center">第二个“*”</td><td style="text-align:center">一天当中的第几小时（时）</td><td style="text-align:center">0-23</td></tr><tr><td style="text-align:center">第三个“*”</td><td style="text-align:center">一个月当中的第几天（天）</td><td style="text-align:center">1-31</td></tr><tr><td style="text-align:center">第四个“*”</td><td style="text-align:center">一年当中的第几月（月）</td><td style="text-align:center">1-12</td></tr><tr><td style="text-align:center">第五个“*”</td><td style="text-align:center">一周当中的星期几（周）</td><td style="text-align:center">0-7（0和7都代表星期日）</td></tr></tbody></table><p>（2）特殊符号</p><table><thead><tr><th style="text-align:center">特殊符号</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center"><code>*</code></td><td style="text-align:center">代表任何时间。比如第一个“*”就代表一小时中每分钟都执行一次的意思</td></tr><tr><td style="text-align:center"><code>，</code></td><td style="text-align:center">代表不连续的时间。比如“0 8,12,16 * * * 命令”，就代表在每天的8点0分，12点0分，16点0分都执行一次命令</td></tr><tr><td style="text-align:center"><code>-</code></td><td style="text-align:center">代表连续的时间范围。比如“0 5  *  *  1-6命令”，代表在周一到周六的凌晨5点0分执行命令</td></tr><tr><td style="text-align:center"><code>*/n</code></td><td style="text-align:center">代表每隔多久执行一次。比如“*/10  *  *  *  *  命令”，代表每隔10分钟就执行一遍命令</td></tr></tbody></table><p>（3）特定时间执行命令</p><table><thead><tr><th style="text-align:center">时间</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">45 22 * * *  命令</td><td style="text-align:center">在22点45分执行命令</td></tr><tr><td style="text-align:center">0  17 * * 1  命令</td><td style="text-align:center">每周1 的17点0分执行命令</td></tr><tr><td style="text-align:center">0 5 1,15 * * 命令</td><td style="text-align:center">每月1号和15号的凌晨5点0分执行命令</td></tr><tr><td style="text-align:center">40 4 * * 1-5 命令</td><td style="text-align:center">每周一到周五的凌晨4点40分执行命令</td></tr><tr><td style="text-align:center"><code>*/10</code> 4 * * * 命令</td><td style="text-align:center">每天的凌晨4点，每隔10分钟执行一次命令</td></tr><tr><td style="text-align:center">0 0 1,15 * 1 命令</td><td style="text-align:center">每月1号和15号，每周1的0点0分都会执行命令</td></tr></tbody></table><p>**注意: **星期几和几号最好不要同时出现，因为他们定义的都是天，非常容易让管理员混乱</p><p><strong>3）案例</strong><br><code>*/5</code> * * * * /bin/echo ”11” &gt;&gt; /tmp/test</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 定时脚本 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电信大数据</title>
      <link href="/2019/05/19/dian_xin_da_shu_ju/"/>
      <url>/2019/05/19/dian_xin_da_shu_ju/</url>
      
        <content type="html"><![CDATA[<h3 id="一、项目背景">一、项目背景</h3><p>通信运营商每时每刻会产生大量的通信数据，例如通话记录，短信记录，彩信记录，第三方服务资费等等繁多信息。数据量如此巨大，除了要满足用户的实时查询和展示之外，还需要定时定期的对已有数据进行离线的分析处理。例如，当日话单，月度话单，季度话单，年度话单，通话详情，通话记录等等+。我们以此为背景，寻找一个切入点，学习其中的方法论</p><h3 id="二、项目架构">二、项目架构</h3><p><img src="/medias/%E7%94%B5%E4%BF%A1%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84.PNG" alt="电信项目架构"></p><h3 id="三、项目实现">三、项目实现</h3><p><strong>系统环境</strong></p><table><thead><tr><th style="text-align:center">系统</th><th style="text-align:center">版本</th></tr></thead><tbody><tr><td style="text-align:center">windows</td><td style="text-align:center">10 专业版</td></tr><tr><td style="text-align:center">linux</td><td style="text-align:center">CentOS7.2 1611内核</td></tr></tbody></table><p><strong>开发工具</strong></p><table><thead><tr><th style="text-align:center">工具</th><th style="text-align:center">版本</th></tr></thead><tbody><tr><td style="text-align:center">idea</td><td style="text-align:center">2018.2.5旗舰版</td></tr><tr><td style="text-align:center">maven</td><td style="text-align:center">3.3.9</td></tr><tr><td style="text-align:center">JDK</td><td style="text-align:center">1.8+</td></tr></tbody></table><p><strong>尖叫提示</strong>：idea2018.2.5必须使用Maven3.3.9，不要使用Maven3.5，有部分兼容性问题</p><h3 id="四、数据生产">四、数据生产</h3><p>此情此景，对于该模块的业务，即数据生产过程，一般并不会让你来进行操作，数据生产是一套完整且严密的体系，这样可以保证数据的鲁棒性。但是如果涉及到项目的一体化方案的设计（数据的产生、存储、分析、展示），则必须清楚每一个环节是如何处理的，包括其中每个环境可能隐藏的问题；数据结构，数据内容可能出现的问题</p><h4 id="1、数据结构">1、数据结构</h4><p>我们将在HBase中存储两个电话号码，以及通话建立的时间和通话持续时间，最后再加上一个flag作为判断第一个电话号码是否为主叫。姓名字段的存储我们可以放置于另外一张表做关联查询，当然也可以插入到当前表中</p><table><thead><tr><th style="text-align:center">列名</th><th style="text-align:center">解释</th><th style="text-align:center">举例</th></tr></thead><tbody><tr><td style="text-align:center">caller</td><td style="text-align:center">第一个手机号码</td><td style="text-align:center">15369468720</td></tr><tr><td style="text-align:center">callerName</td><td style="text-align:center">第一个手机号码人姓名(非必须)</td><td style="text-align:center">李雁</td></tr><tr><td style="text-align:center">callee</td><td style="text-align:center">第二个手机号码</td><td style="text-align:center">19920860202</td></tr><tr><td style="text-align:center">calleename</td><td style="text-align:center">第二个手机号码人姓名(非必须)</td><td style="text-align:center">卫艺</td></tr><tr><td style="text-align:center">dateTime</td><td style="text-align:center">建立通话的时间</td><td style="text-align:center">20181126091236</td></tr><tr><td style="text-align:center">date_time_ts</td><td style="text-align:center">建立通话的时间（时间戳形式）</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">duration</td><td style="text-align:center">通话持续时间（秒）</td><td style="text-align:center">0820</td></tr><tr><td style="text-align:center">flag</td><td style="text-align:center">用于标记本次通话第一个字段(caller)是主叫还是被叫</td><td style="text-align:center">1为主叫，0为被叫</td></tr></tbody></table><h4 id="2、编写代码">2、编写代码</h4><p><strong>思路</strong><br>a）创建Java集合类存放模拟的电话号码和联系人；<br>b） 随机选取两个手机号码当做“主叫”与“被叫”（注意判断两个手机号不能重复），产出<strong>caller</strong>与<strong>call2</strong>字段数据；<br>c） 创建随机生成通话建立时间的方法，可指定随机范围，最后生成通话建立时间，产出<strong>date_time</strong>字段数据；<br>d）随机一个通话时长，单位：秒，产出<strong>duration</strong>字段数据；<br>e）将产出的一条数据拼接封装到一个字符串中；<br>f）使用IO操作将产出的一条通话数据写入到本地文件中;</p><p>新建module项目：<strong>ct_producer</strong></p><p><strong>父pom.xml文件配置</strong></p><pre><code class="highlight plaintext">&lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                &lt;version&gt;2.12.4&lt;/version&gt;                &lt;configuration&gt;                    &lt;skipTests&gt;true&lt;/skipTests&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;version&gt;3.8.1&lt;/version&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><p>（1）随机输入一些手机号码以及联系人，保存于Java的集合中<br>新建类：ProductLog</p><pre><code class="highlight plaintext">package producer;import java.io.FileOutputStream;import java.io.OutputStreamWriter;import java.text.DecimalFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.*;public class ProductLog {    String startTime = "2018-01-01";    String endTime = "2018-12-31";    //存放tel的List集合    private List&lt;String&gt;  phoneList = new ArrayList&lt;String&gt;();    //存放tel和Name的Map集合    private Map&lt;String, String&gt; phoneNameMap = new HashMap&lt;&gt;();    /**     * 初始化数据     */    public void initPhone(){        phoneList.add("17078388295");        phoneList.add("13980337439");        phoneList.add("14575535933");        phoneList.add("18902496992");        phoneList.add("18549641558");        phoneList.add("17005930322");        phoneList.add("18468618874");        phoneList.add("18576581848");        phoneList.add("15978226424");        phoneList.add("15542823911");        phoneList.add("17526304161");        phoneList.add("15422018558");        phoneList.add("17269452013");        phoneList.add("17764278604");        phoneList.add("15711910344");        phoneList.add("15714728273");        phoneList.add("16061028454");        phoneList.add("16264433631");        phoneList.add("17601615878");        phoneList.add("15897468949");        phoneNameMap.put("17078388295", "李为");        phoneNameMap.put("13980337439", "王军");        phoneNameMap.put("14575535933", "时俊");        phoneNameMap.put("18902496992", "天机");        phoneNameMap.put("18549641558", "蔡铭");        phoneNameMap.put("17005930322", "陶尚");        phoneNameMap.put("18468618874", "魏山帅");        phoneNameMap.put("18576581848", "华倩");        phoneNameMap.put("15978226424", "焦君山");        phoneNameMap.put("15542823911", "钟尾田");        phoneNameMap.put("17526304161", "司可可");        phoneNameMap.put("15422018558", "官渡");        phoneNameMap.put("17269452013", "上贵坡");        phoneNameMap.put("17764278604", "时光机");        phoneNameMap.put("15711910344", "李发");        phoneNameMap.put("15714728273", "蒂冈");        phoneNameMap.put("16061028454", "范德");        phoneNameMap.put("16264433631", "周朝王");        phoneNameMap.put("17601615878", "谢都都");        phoneNameMap.put("15897468949", "刘何思");    }</code></pre><p>（2）创建随机生成通话时间的方法：randomDate<br>该时间生成后的格式为yyyy-MM-dd HH:mm:ss，并使之可以根据传入的起始时间和结束时间来随机生成</p><pre><code class="highlight plaintext">/**  * 注：传入时间要在时间[startTime, endTime]  * 公式：起始时间 + （结束时间 - 起始时间）* Math.random()  * @param startTime  * @param endTime  */ private String randomBuildTime(String startTime, String endTime) {     try {         SimpleDateFormat sdf1 = new SimpleDateFormat("yyyy-MM-dd");         Date startDate = sdf1.parse(startTime);         Date endDate = sdf1.parse(endTime);         if(endDate.getTime() &lt;= startDate.getTime()){             return null;         }         //公式：起始时间 + （结束时间 - 起始时间）* Math.random()         long randomTs = startDate.getTime() + (long) ((endDate.getTime() - startDate.getTime()) * Math.random());         Date resultDate = new Date(randomTs);         SimpleDateFormat sdf2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");         String resultTimeString = sdf2.format(resultDate);         return resultTimeString;     } catch (ParseException e) {         e.printStackTrace();     }     return null; }</code></pre><p>（3）创建生产日志一条日志的方法：productLog<br>随机抽取两个电话号码，随机产生通话建立时间，随机通话时长，将这几个字段拼接成一个字符串，然后return，便可以产生一条通话的记录。需要注意的是，如果随机出的两个电话号码一样，需要重新随机（随机过程可优化，但并非此次重点）。通话时长的随机为20分钟以内，即：60秒 * 30，并格式化为4位数字，例如：0600(10分钟)</p><pre><code class="highlight plaintext">/**  * 产生数据  * 格式： caller,callee,buildTime,duration  * @return  */ public String product(){     //ctrl + d 复制此行 ， ctrl + x 剪切此行 ，ctrl + y 删除此行     //主叫     String caller = null;     String callerName = null;     //被叫     String callee = null;     String calleeName = null;     //ctrl + alt + v 推导出前面的对象类型  Home前  End后     int callerIndex = (int) (Math.random() * phoneList.size());     caller = phoneList.get(callerIndex);     callerName = phoneNameMap.get(caller);     while(true) {         //ctrl + shift + 下  ：下移这行         int calleeIndex = (int) (Math.random() * phoneList.size());         callee = phoneList.get(calleeIndex);         calleeName = phoneNameMap.get(callee);         if(!caller.equals(callee)) break;     }     //第三个字段     String buildTime = randomBuildTime(startTime, endTime);     //第四个字段，最多时长     DecimalFormat df = new DecimalFormat("0000");     String duration = df.format((int) 30 * 60 * Math.random());     StringBuilder sb = new StringBuilder();     sb.append(caller + ",").append(callee + ",").append(buildTime + ",").append( duration);     return sb.toString(); }</code></pre><p>（4）创建写入日志方法：writeLog<br>productLog每产生一条日志，便将日志写入到本地文件中，所以建立一个专门用于日志写入的方法，需要涉及到IO操作，需要注意的是，输出流每次写一条日之后需要flush，不然可能导致积攒多条数据才输出一次。最后需要将productLog方法放置于while死循环中执行</p><pre><code class="highlight plaintext">/** * 把数据写到文件当中 * @param filePath */public void writeLog(String filePath){    try {        OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(filePath, true), "UTF-8");        while(true){            Thread.sleep(200);            String log = product();            System.out.println(log); //一定要手动flush才可以确保每条数据都写入到文件一次            osw.write(log + "\n");            osw.flush();        }    } catch (Exception e) {        e.printStackTrace();    }}</code></pre><p>（5）在主函数中初始化以上逻辑，并测试：</p><pre><code class="highlight plaintext">public static void main(String[] args) {       //args = new String[]{"E:\\CT Project file\\calllog.csv"};       if(args == null || args.length &lt;= 0){           System.out.println("没写路径");           return ;       }       ProductLog productLog = new ProductLog();       productLog.initPhone();       productLog.writeLog(args[0]);   }</code></pre><h4 id="3、打包测试">3、打包测试</h4><p>1）Maven打包方式<br>分别在Windows上和Linux中进行测试：<br>java -cp jar包的绝对路径 全类名 输出路径</p><p>2）将此包放在在/opt/jar下面，并写如下脚本</p><p><strong><a href="http://product.sh">product.sh</a></strong></p><pre><code class="highlight plaintext">#!bin.bashjava -cp /opt/jars/CT_producer-1.0-SNAPSHOT.jar producer.ProductLog /opt/jars/calllog.csv</code></pre><p>3）运行<br>sh <a href="http://product.sh">product.sh</a><br>产生calllog.csv文件</p><h3 id="五、数据采集-消费-存储">五、数据采集/消费(存储)</h3><p>欢迎来到数据采集模块（消费），在企业中你要清楚流式数据采集框架Flume和Kafka的定位是什么。我们在此需要将实时数据通过Flume采集到Kafka然后供给给HBase消费</p><p>Flume：Cloudera公司研发<br>适合下游数据消费者不多的情况；<br>适合数据安全性要求不高的操作；<br>适合与Hadoop生态圈对接的操作</p><p>Kafka：linkedin公司研发<br>适合数据下游消费众多的情况；<br>适合数据安全性要求较高的操作（支持replication）；</p><p><strong>因此我们常用的一种模型是</strong>：<br>线上数据 --&gt; Flume --&gt; Kafka --&gt; Flume(根据情景增删该流程) --&gt; HDFS</p><p><strong>消费存储模块流程图</strong>：</p><p><img src="/medias/%E6%B6%88%E8%B4%B9%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="消费存储模块流程图"></p><h4 id="1、数据采集：采集实时产生的数据到kafka集群">1、数据采集：采集实时产生的数据到kafka集群</h4><p>0）基础配置</p><ul><li>配置Kafka 略</li><li>配置Flume(flume2kafka.conf)</li></ul><pre><code class="highlight plaintext"># definea1.sources = r1a1.sinks = k1a1.channels = c1# sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F -c +0 /opt/jars/calllog.csva1.sources.r1.shell = /bin/bash -c# sinka1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.brokerList = hsiehchou121:9092,hsiehchou122:9092,hsiehchou123:9092a1.sinks.k1.topic = callloga1.sinks.k1.batchSize = 20a1.sinks.k1.requiredAcks = 1# channela1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# binda1.sources.r1.channels = c1a1.sinks.k1.channel = c1</code></pre><p>1）进入Flume根目录下，启动flume<br>/opt/module/flume-1.8.0/bin/flume-ng agent --conf /opt/module/flume-1.8.0/conf/ --name a1 --conf-file /opt/jars/flume2kafka.conf</p><p>2）运行生产日志的任务脚本，观察kafka控制台消费者是否成功显示产生的数据<br>$ sh <a href="http://productlog.sh">productlog.sh</a></p><h4 id="2、编写代码：数据消费（HBase）">2、编写代码：数据消费（HBase）</h4><p>如果以上操作均成功，则开始编写操作HBase的代码，用于消费数据，将产生的数据实时存储在HBase中</p><p><strong>思路</strong>：<br>a） 编写Kafka消费者，读取kafka集群中缓存的消息，并打印到控制台以观察是否成功；</p><p>b）既然能够读取到kafka中的数据了，就可以将读取出来的数据写入到HBase中，所以编写调用HBaseAPI相关方法，将从Kafka中读取出来的数据写入到HBase；</p><p>c） 以上两步已经足够完成消费数据，存储数据的任务，但是涉及到解耦，所以过程中需要将一些属性文件外部化，HBase通用性方法封装到某一个类中</p><p>创建新的module项目：<strong>ct_consumer</strong></p><p><strong>pom.xml文件配置</strong></p><pre><code class="highlight plaintext">&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;            &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;            &lt;version&gt;0.11.0.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-client --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;            &lt;version&gt;1.3.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-server --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;            &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;            &lt;version&gt;1.3.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;8.0.13&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                &lt;version&gt;2.12.4&lt;/version&gt;                &lt;configuration&gt;                    &lt;skipTests&gt;true&lt;/skipTests&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;version&gt;3.8.1&lt;/version&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><p>1）新建类：<strong>HBaseConsumer</strong>（kafka的package）<br>该类主要用于读取kafka中缓存的数据，然后调用HBaseAPI，持久化数据</p><pre><code class="highlight plaintext">package kafka;import hbase.HBaseDao;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import utils.PropertiesUtil;import java.util.Arrays;public class HBaseConsumer {    public static void main(String[] args) {        //消费者API        KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(PropertiesUtil.properties);        //kafka Topic        kafkaConsumer.subscribe(Arrays.asList(PropertiesUtil.getProperty("kafka.topics")));        //创建写入HBase的对象        HBaseDao hd = new HBaseDao();        while(true) {            //消费拉取数据            ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100);            //遍历打印数据            for(ConsumerRecord&lt;String, String&gt; cr : records){                String value = cr.value();                //13980337439,16264433631,2018-02-08 10:27:32,1740                System.out.println(value);                //把数据写入到HBase中                hd.put(value);            }        }    }}</code></pre><ol start="2"><li>新建类：<strong>PropertiesUtil</strong>（utils的package）<br>该类主要用于将常用的项目所需的参数外部化，解耦，方便配置</li></ol><pre><code class="highlight plaintext">package utils;import java.io.IOException;import java.io.InputStream;import java.util.Properties;public class PropertiesUtil {    public static Properties properties = null;    static {        //ctrl + alt + v        InputStream is = ClassLoader.getSystemResourceAsStream("hbase_consumer.properties");        properties = new Properties();        try {            properties.load(is);        } catch (IOException e) {            e.printStackTrace();        }    }    public static String getProperty(String key){        return properties.getProperty(key);    }}</code></pre><p>3） 创建kafka.properties文件，并放置于resources目录下</p><pre><code class="highlight plaintext"># 设置kafka的brokerlistbootstrap.servers=hsiehchou121:9092,hsiehchou122:9092,hsiehchou123:9092# 设置消费者所属的消费组group.id=hbase_consumer_group# 设置是否自动确认offsetenable.auto.commit=true# 自动确认offset的时间间隔auto.commit.interval.ms=30000# 设置key，value的反序列化类的全名key.deserializer=org.apache.kafka.common.serialization.StringDeserializervalue.deserializer=org.apache.kafka.common.serialization.StringDeserializer# 以下为自定义属性设置# 设置本次消费的主题kafka.topics=calllog# 设置HBase的一些变量hbase.calllog.regions=6hbase.calllog.namespace=ns_cthbase.calllog.tablename=ns_ct:calllog</code></pre><p>4）将hdfs-site.xml、core-site.xml、hbase-site.xml、log4j.properties放置于resources目录</p><p>5）新建类：HBaseUtil（utils的package）<br>该类主要用于封装一些HBase的常用操作，比如创建命名空间，创建表等等</p><pre><code class="highlight plaintext">package utils;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.NamespaceDescriptor;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Admin;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.ConnectionFactory;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.text.DecimalFormat;import java.util.Iterator;import java.util.TreeSet;/** * 1、NameSpace ====&gt;  命名空间 * 2、createTable ===&gt; 表 * 3、isTable   ====&gt;  判断表是否存在 * 4、Region、RowKey、分区键 */public class HBaseUtil {    /**     * 初始化命名空间     *     * @param conf  配置对象     * @param namespace 命名空间的名字     */    public static void initNameSpace(Configuration conf, String namespace) throws IOException {        //获取链接connection        Connection connection = ConnectionFactory.createConnection(conf);        //获取admin对象        Admin admin = connection.getAdmin();        //创建命名空间，命名空间描述器        NamespaceDescriptor nd = NamespaceDescriptor                .create(namespace)                //add配置信息不强制加                .addConfiguration("create_time", String.valueOf(System.currentTimeMillis()))                .build();        //通过admin对象创建namespace        admin.createNamespace(nd);        close(admin,connection);    }    /**     * 初始化表     *     * @param conf     * @param tableName     * @param regions     * @param columnFamily     */    public static void createTable(Configuration conf, String tableName, int regions, String... columnFamily) throws IOException {        //获取链接connection        Connection connection = ConnectionFactory.createConnection(conf);        //获取admin对象        Admin admin = connection.getAdmin();        //如果表已存在，就返回        if (isExistTable(conf, tableName)){            return ;        }        //创建表对象        HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(tableName));        for (String cf : columnFamily){            htd.addFamily(new HColumnDescriptor(cf));        }        //添加协处理器的全类名        htd.addCoprocessor("hbase.CalleeWriteObserver");        //通过admin创建表（htd（列族），分裂的regions）        admin.createTable(htd, getSplitKeys(regions));        //关闭        close(admin, connection);    }    /**     * 分区     *     * @param regions     * @return     */    private static byte[][] getSplitKeys(int regions) {        //第一步：定义分区键数组        String[] keys = new String[regions];        //分区位数格式化        DecimalFormat df = new DecimalFormat("00");        //  00|01|02|03|04|05        for (int i = 0; i &lt; regions; i++){            keys[i] = df.format(i) + "|";        }        //第二步        byte[][] splitsKeys = new byte[regions][];        //分区间有序        TreeSet&lt;byte[]&gt; treeSet = new TreeSet&lt;&gt;(Bytes.BYTES_COMPARATOR);        for (int i = 0; i &lt; regions; i++){            treeSet.add(Bytes.toBytes(keys[i]));        }        //第三步        Iterator&lt;byte[]&gt; splitKeysIterator = treeSet.iterator();        int index = 0;        while (splitKeysIterator.hasNext()){            byte[] next = splitKeysIterator.next();            splitsKeys[index++] = next;        }        return splitsKeys;    }    /**     * 判断表是否存在     *     * @param conf     * @param tableName     */    public static boolean isExistTable(Configuration conf, String tableName) throws IOException {        //获取链接connection        Connection connection = ConnectionFactory.createConnection(conf);        //获取admin对象        Admin admin = connection.getAdmin();        //判断表API        boolean b = admin.tableExists(TableName.valueOf(tableName));        //关闭        close(admin, connection);        return b;    }    /**     * 关闭     *     * @param admin     * @param connection     */    public static void close(Admin admin, Connection connection) throws IOException {        if (admin != null) {            admin.close();        }        if (connection != null) {            connection.close();        }    }    /**     * regionCode, caller, buildTime, callee, flag, duration     * regionCode（rowkey前的离散串）     * duration（通话建立时间）     * 主叫（flag:1）：13980337439,16264433631,2018-02-08 10:27:32,1740   ==&gt;f1列族     * 被叫（flag:0）：16264433631,13980337439,2018-02-08 10:27:32,1740   ==&gt;f2列族     *     * 面试常问rowkey相关的问题：你们公司如何设计的RowKey？怎么设计RowKey才能避免热点问题（频繁访问某个区）?     *     * @param regionCode 散列的键     * @param caller     叫     * @param buildTime  建立时间     * @param callee     被叫     * @param flag       标明是主叫还是被叫     * @param duration   通话持续时间     * @return     */    public static String getRowKey(String regionCode, String caller, String buildTime, String callee, String flag, String duration){        StringBuilder sb = new StringBuilder();        sb.append(regionCode + "_")                .append(caller + "_")                .append(buildTime + "_")                .append(callee + "_")                .append(flag + "_")                .append(duration);        return sb.toString();    }    /**     * 当数据进入HBase的Region的时候是足够的离散     *     * @param caller 主叫     * @param buildTime 通话建立时间     * @param regions region个数     * @return 返回分区号     */    public static String getRegionCode(String caller, String buildTime, int regions){        //取出主叫的后四位,lastPhone caller最后的后四位        String lastPhone = caller.substring(caller.length() - 4);        //取出年月   2018-02-08 10:27:32,1740 中取出年月        String yearMonth = buildTime                .replaceAll("-", "")                .replaceAll(":", "")                .replaceAll(" ", "")                .substring(0, 6);        //离散操作1：做异或处理 ^        Integer x = Integer.valueOf(lastPhone) ^ Integer.valueOf(yearMonth);        //离散操作2：把离散1的值再做hashcode        int y = x.hashCode();        //最终想要的分区号        int regionCode = y % regions;        DecimalFormat df = new DecimalFormat("00");        return df.format(regionCode);    }}</code></pre><p>6）新建类：ConnectionInstance（utils的package）</p><pre><code class="highlight plaintext">package utils;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.ConnectionFactory;import java.io.IOException;public class ConnectionInstance {    private static Connection conn;    public static synchronized Connection getConnection(Configuration configuration) {        try {            if (conn == null || conn.isClosed()) {                conn = ConnectionFactory.createConnection(configuration);            }        } catch (IOException e) {            e.printStackTrace();        }        return conn;    }}</code></pre><p>7）新建类：HBaseDAO（完成以下内容后，考虑数据put的效率如何优化）（hbase的package）<br>该类主要用于执行具体的保存数据的操作，rowkey的生成规则等等</p><pre><code class="highlight plaintext">package hbase;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.util.Bytes;import utils.ConnectionInstance;import utils.HBaseUtil;import utils.PropertiesUtil;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.List;public class HBaseDao {    public static final Configuration CONF;    private String namespace;    private int regions;    private String tableName;    private HTable table;    private Connection connection;    private SimpleDateFormat sdf1 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");    private SimpleDateFormat sdf2 = new SimpleDateFormat("yyyyMMddHHmmss");    //用来存放一小堆数据（30行），用于优化    private List&lt;Put&gt; cacheList = new ArrayList&lt;&gt;();    static {        CONF = HBaseConfiguration.create();    }    //Alt + Insert  Constructor    /**     * 用于构造命名空间和表     */    public HBaseDao() {        try {            namespace = PropertiesUtil.getProperty("hbase.calllog.namespace");            tableName = PropertiesUtil.getProperty("hbase.calllog.tablename");            regions = Integer.valueOf(PropertiesUtil.getProperty("hbase.calllog.regions"));            if (!HBaseUtil.isExistTable(CONF, tableName)){                HBaseUtil.initNameSpace(CONF, namespace);                HBaseUtil.createTable(CONF, tableName, regions, "f1", "f2");            }        } catch (IOException e) {            e.printStackTrace();        }    }    /**     *     * @param value 13980337439,16264433631,2018-02-08 10:27:32,1740     */    public void put(String value) {        try {            if(cacheList.size() == 0){                connection = ConnectionInstance.getConnection(CONF);                table = (HTable) connection.getTable(TableName.valueOf(tableName));                table.setAutoFlushTo(false);                table.setWriteBufferSize(2 * 1024 * 1024);            }            //如果出现下标越界异常            String[] splitValue = value.split(",");            String caller = splitValue[0];            String callee = splitValue[1];            String buildTime = splitValue[2];            String duration = splitValue[3];            //散列得分区号            String regionCode = HBaseUtil.getRegionCode(caller, buildTime, regions);            //这个变量用于插入到HBase的列中            String buildTimeReplace = sdf2.format(sdf1.parse(buildTime));            //作为rowkey所需的参数            String buildTimeTs = String.valueOf(sdf1.parse(buildTime).getTime());            String rowkey = HBaseUtil.getRowKey(regionCode, caller, buildTimeReplace, callee, "1", duration);            Put put = new Put(Bytes.toBytes(rowkey));            //通过put对象添加rowkey和列值，参数说明：(列族：f1)，(列名：caller)，（列值：caller）            //快捷键：ctrl + d            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("caller"), Bytes.toBytes(caller));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("callee"), Bytes.toBytes(callee));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("build_time"), Bytes.toBytes(buildTimeReplace));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("build_time_ts"), Bytes.toBytes(buildTimeTs));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("flag"), Bytes.toBytes("1"));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("duration"), Bytes.toBytes(duration));            //把rowkey，列族，列名，列值放到cacheList的对象中            cacheList.add(put);            if(cacheList.size() &gt;= 30) {                table.put(cacheList);                table.flushCommits();                table.close();                cacheList.clear();            }        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p>8）新建类：HBaseDao（hbase的package）</p><pre><code class="highlight plaintext">package hbase;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.util.Bytes;import utils.ConnectionInstance;import utils.HBaseUtil;import utils.PropertiesUtil;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.List;public class HBaseDao {    public static final Configuration CONF;    private String namespace;    private int regions;    private String tableName;    private HTable table;    private Connection connection;    private SimpleDateFormat sdf1 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");    private SimpleDateFormat sdf2 = new SimpleDateFormat("yyyyMMddHHmmss");    //用来存放一小堆数据（30行），用于优化    private List&lt;Put&gt; cacheList = new ArrayList&lt;&gt;();    static {        CONF = HBaseConfiguration.create();    }    //Alt + Insert  Constructor    /**     * 用于构造命名空间和表     */    public HBaseDao() {        try {            namespace = PropertiesUtil.getProperty("hbase.calllog.namespace");            tableName = PropertiesUtil.getProperty("hbase.calllog.tablename");            regions = Integer.valueOf(PropertiesUtil.getProperty("hbase.calllog.regions"));            if (!HBaseUtil.isExistTable(CONF, tableName)){                HBaseUtil.initNameSpace(CONF, namespace);                HBaseUtil.createTable(CONF, tableName, regions, "f1", "f2");            }        } catch (IOException e) {            e.printStackTrace();        }    }    /**     *     * @param value 13980337439,16264433631,2018-02-08 10:27:32,1740     */    public void put(String value) {        try {            if(cacheList.size() == 0){                connection = ConnectionInstance.getConnection(CONF);                table = (HTable) connection.getTable(TableName.valueOf(tableName));                table.setAutoFlushTo(false);                table.setWriteBufferSize(2 * 1024 * 1024);            }            //如果出现下标越界异常            String[] splitValue = value.split(",");            String caller = splitValue[0];            String callee = splitValue[1];            String buildTime = splitValue[2];            String duration = splitValue[3];            //散列得分区号            String regionCode = HBaseUtil.getRegionCode(caller, buildTime, regions);            //这个变量用于插入到HBase的列中            String buildTimeReplace = sdf2.format(sdf1.parse(buildTime));            //作为rowkey所需的参数            String buildTimeTs = String.valueOf(sdf1.parse(buildTime).getTime());            String rowkey = HBaseUtil.getRowKey(regionCode, caller, buildTimeReplace, callee, "1", duration);            Put put = new Put(Bytes.toBytes(rowkey));            //通过put对象添加rowkey和列值，参数说明：(列族：f1)，(列名：caller)，（列值：caller）            //快捷键：ctrl + d            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("caller"), Bytes.toBytes(caller));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("callee"), Bytes.toBytes(callee));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("build_time"), Bytes.toBytes(buildTimeReplace));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("build_time_ts"), Bytes.toBytes(buildTimeTs));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("flag"), Bytes.toBytes("1"));            put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("duration"), Bytes.toBytes(duration));            //把rowkey，列族，列名，列值放到cacheList的对象中            cacheList.add(put);            if(cacheList.size() &gt;= 30) {                table.put(cacheList);                table.flushCommits();                table.close();                cacheList.clear();            }        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><h4 id="3、运行测试：HBase消费数据">3、运行测试：HBase消费数据</h4><p>尖叫提示：请将Linux允许打开的文件个数和进程数进行优化，优化RegionServer与Zookeeper会话的超时时间。（参考HBase文档中优化章节）<br>项目成功后，则将项目打包后在linux中运行测试</p><p><strong>打包HBase消费者代码</strong><br>a）  在windows中，进入工程的pom.xml所在目录下（建议将该工程的pom.xml文件拷贝到其他临时目录中，例如我把pom.xml文件拷贝到了F:\maven-lib\目录下），然后使用mvn命令下载工程所有依赖的jar包<br>mvn -DoutputDirectory=./lib -DgroupId=com.hsiehchou -DartifactId=ct_consumer -Dversion=r-1.0-SNAPSHOT dependency:copy-dependencies<br>b）  使用maven打包工程<br>c） 测试执行该jar包</p><p>方案一：推荐，使用通配符，将所有依赖加入到classpath中，不可使用*.jar的方式<br>注意：如果是在Linux中实行，注意文件夹之间的分隔符。自己的工程要单独在cp中指定，不要直接放在maven-lib/lib目录下<br>java -cp F:\maven-lib\CT_consumerr-1.0-SNAPSHOT.jar;F:\maven-lib\lib* com.hsiehchou.CT_kafka.HBaseConsumer</p><p>方案二：最最推荐，使用java.ext.dirs参数将所有依赖的目录添加进classpath中<br>注意：-Djava.ext.dirs=属性后边的路径不能为”~”<br>java -Djava.ext.dirs=F:\maven-lib\lib\ -cp F:\maven-lib\CT_consumerr-1.0-SNAPSHOT.jar com.hsiehchou.CT_consumer.kafka.HBaseConsumer</p><h4 id="4、编写代码：优化数据存储方案">4、编写代码：优化数据存储方案</h4><p>现在我们要使用HBase查找数据时，尽可能的使用rowKey去精准的定位数据位置，而非使用ColumnValueFilter或者SingleColumnValueFilter，按照单元格Cell中的Value过滤数据，这样做在数据量巨大的情况下，效率是极低的——如果要涉及到全表扫描。所以尽量不要做这样可怕的事情。注意，这并非ColumnValueFilter就无用武之地。现在，我们将使用协处理器，将数据一分为二</p><p><strong>思路</strong></p><p>a）编写协处理器类，用于协助处理HBase的相关操作（增删改查）<br>b）在协处理器中，一条主叫日志成功插入后，将该日志切换为被叫视角再次插入一次，放入到与主叫日志不同的列族中<br>c）重新创建hbase表，并设置为该表设置协处理器<br>d）编译项目，发布协处理器的jar包到hbase的lib目录下，并群发该jar包<br>e）修改hbase-site.xml文件，设置协处理器，并群发该hbase-site.xml文件</p><p><strong>编码</strong></p><p>1） 新建协处理器类：CalleeWriteObserver，并覆写postPut方法，该方法会在数据成功插入之后被回调（hbase的package）</p><pre><code class="highlight plaintext">package hbase;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Durability;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.client.Table;import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;import org.apache.hadoop.hbase.coprocessor.ObserverContext;import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;import org.apache.hadoop.hbase.regionserver.wal.WALEdit;import org.apache.hadoop.hbase.util.Bytes;import utils.HBaseUtil;import utils.PropertiesUtil;import java.io.IOException;import java.text.ParseException;import java.text.SimpleDateFormat;public class CalleeWriteObserver extends BaseRegionObserver {    SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMddHHmmss");    //ctrl + 0    /**     * 插入主叫数据后，随即插入被叫数据     * @param e     * @param put     * @param edit     * @param durability     * @throws IOException     */    @Override    public void postPut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e,                        Put put,                        WALEdit edit,                        Durability durability) throws IOException {        //注意：一定到删除super.postPut(e, put, edit, durability);        //操作的目标表        String targetTableName = PropertiesUtil.getProperty("hbase.calllog.tablename");        //当前操作put后的表        String currentTableName = e.getEnvironment().getRegionInfo().getTable().getNameAsString();        //不是同一个表返回        if (!targetTableName.equals(currentTableName)){            return;        }        //05_18902496992_20180720182543_14575535933_1_0076        String oriRowKey = Bytes.toString(put.getRow());        System.out.println(oriRowKey);        String[] splitOriRowKey = oriRowKey.split("_");        String caller = splitOriRowKey[1];        String callee = splitOriRowKey[3];        String buildTime = splitOriRowKey[2];        String duration = splitOriRowKey[5];        //如果当前插入的是被叫数据，则直接返回(因为默认提供的数据全部为主叫数据)        String flag = splitOriRowKey[4];        String calleeflag = "0";        if (flag.equals(calleeflag) ){            return;        }        flag = calleeflag;        Integer regions = Integer.valueOf(PropertiesUtil.getProperty("hbase.calllog.regions"));        String regionCode = HBaseUtil.getRegionCode(callee, buildTime, regions);        String calleeRowKey = HBaseUtil.getRowKey(regionCode, callee, buildTime, caller, flag, duration);        String buildTimeTs = "";        try {            buildTimeTs = String.valueOf(sdf.parse(buildTime).getTime());        } catch (ParseException e1) {            e1.printStackTrace();        }        Put calleePut = new Put(Bytes.toBytes(calleeRowKey));        calleePut.addColumn(Bytes.toBytes("f2"), Bytes.toBytes("callee"), Bytes.toBytes(caller));        calleePut.addColumn(Bytes.toBytes("f2"), Bytes.toBytes("caller"), Bytes.toBytes(callee));        calleePut.addColumn(Bytes.toBytes("f2"), Bytes.toBytes("build_time"), Bytes.toBytes(buildTime));        calleePut.addColumn(Bytes.toBytes("f2"), Bytes.toBytes("build_time_ts"), Bytes.toBytes(buildTimeTs));        calleePut.addColumn(Bytes.toBytes("f2"), Bytes.toBytes("flag"), Bytes.toBytes(flag));        calleePut.addColumn(Bytes.toBytes("f2"), Bytes.toBytes("duration"), Bytes.toBytes(duration));        Bytes.toBytes(100L);        Table table = e.getEnvironment().getTable(TableName.valueOf(targetTableName));        table.put(calleePut);        table.close();    }}</code></pre><p>2）重新创建HBase表，并设置为该表设置协处理器。在“表描述器”中调用addCoprocessor方法进行协处理器的设置，大概是这样的：（你需要找到你的建表的那部分代码，添加如下逻辑）<br>tableDescriptor.addCoprocessor(“hbase.CalleeWriteObserver”);</p><h4 id="5、运行测试：协处理器">5、运行测试：协处理器</h4><p>重新编译项目，发布jar包到hbase的lib目录下（注意需群发）：<br>$ scp -r CT_consumer-1.0-SNAPSHOT.jar root@hsiehchou121:<code>pwd</code></p><p>重新修改<strong>hbase-site.xml</strong>：</p><pre><code class="highlight plaintext">&lt;property&gt;&lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;&lt;value&gt;hbase.CalleeWriteObserver&lt;/value&gt;&lt;/property&gt;</code></pre><p>完成以上步骤后，重新消费数据进行测试</p><h4 id="6、编写测试单元：范围查找数据">6、编写测试单元：范围查找数据</h4><p><strong>思路</strong><br>a）已知要查询的手机号码以及起始时间节点和结束时间节点，查询该节点范围内的该手机号码的通话记录</p><p>b）拼装startRowKey和stopRowKey，即扫描范围，要想拼接出扫描范围，首先需要了解rowkey组成结构，我们再来复习一下，举个大栗子<br>rowkey：<br>分区号_手机号码1_通话建立时间_手机号码2_主(被)叫标记_通话持续时间<br>01_15837312345_20180725071833_1_0180</p><p>c）比如按月查询通话记录，则startRowKey举例：<br>regionHash_158373123456_20180805010000<br>stopRowKey举例：<br>regionHash_158373123456_20180805010000</p><p><strong>注意</strong>：startRowKey和stopRowKey设计时，后面的部分已经被去掉</p><p><strong>尖叫提示</strong>：rowKey的扫描范围为前闭后开</p><p><strong>尖叫提示</strong>：rowKey默认是有序的，排序规则为字符的按位比较<br>d）如果查找所有的，需要多次scan表，每次scan设置为下一个时间窗口即可，该操作可放置于for循环中</p><p><strong>编码</strong>：<br>e）<strong>运行测试</strong><br>观察是否已经按照时间范围查询出对应的数据</p><h4 id="7、将数据从本地读取到HBase">7、将数据从本地读取到HBase</h4><p>1）<strong>启动ZooKeeper</strong>（配置了全局环境变量）</p><pre><code class="highlight plaintext">zkServer.sh start</code></pre><p>2）<strong>启动Kafka</strong>（配置了全局环境变量）</p><pre><code class="highlight plaintext">kafka-server-start.sh /root/hd/kafka/config/server.properties &amp;</code></pre><p><strong>创建主题</strong></p><pre><code class="highlight plaintext">bin/kafka-topics.sh --zookeeper hsiehchou121:2181 --topic calllog --create --replication-factor 1 --partitions 3</code></pre><p><strong>列出所有主题</strong></p><pre><code class="highlight plaintext">bin/kafka-topics.sh --zookeeper hsiehchou121:2181 --list</code></pre><p><strong>启动 Kafka消费者</strong></p><pre><code class="highlight plaintext">bin/kafka-console-consumer.sh --bootstrap-server hsiehchou121:9092 --topic calllog --from-beginning</code></pre><p>3）<strong>启动Hadoop</strong>（配置了全局环境变量）</p><pre><code class="highlight plaintext">start-all.sh</code></pre><p>4）<strong>启动HBase</strong>（配置了全局环境变量）<br><strong><a href="http://start-hbase.sh">start-hbase.sh</a></strong></p><p>5）<strong>启动Flume</strong>（没有配置全局环境变量，去flume目录下）</p><pre><code class="highlight plaintext">bin/flume-ng agent --conf conf/ --name a1 --conf-file myagent/flume2kafka.conf</code></pre><p>6）<strong>IDEA打包CT_consumer.jar</strong><br>此jar包要放入hbase的lib下面，不然HBase写不进数据</p><p>7）在IDEA里面<strong>运行HBaseConsumer.java</strong></p><h4 id="8、总结">8、总结</h4><p>数据（本地）-&gt;Flume采集数据-&gt;Kafka消费数据-&gt;HBase</p><h3 id="六、数据分析">六、数据分析</h3><p>我们的数据已经完整的采集到了HBase集群中，这次我们需要对采集到的数据进行分析，统计出我们想要的结果。注意，在分析的过程中，我们不一定会采取一个业务指标对应一个MapReduce-Job的方式，如果情景允许，我们会采取一个MapReduce分析多个业务指标的方式来进行任务</p><p><strong>数据分析模块流程图</strong></p><p><img src="/medias/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9D%97%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="数据分析模块流程图"></p><p><strong>业务指标</strong><br>a）用户每天主叫通话个数统计，通话时间统计<br>b）用户每月通话记录统计，通话时间统计<br>c）用户之间亲密关系统计。（通话次数与通话时间体现用户亲密关系）</p><h4 id="1、MySQL表结构设计">1、MySQL表结构设计</h4><p>我们将分析的结果数据保存到Mysql中，以方便Web端进行查询展示<br>1）表：<strong>db_telecom.tb_contacts</strong></p><p>用于存放用户手机号码与联系人姓名</p><table><thead><tr><th style="text-align:center">列</th><th style="text-align:center">备注</th><th style="text-align:center">类型</th></tr></thead><tbody><tr><td style="text-align:center">id</td><td style="text-align:center">自增主键</td><td style="text-align:center">int(11) NOT NULL</td></tr><tr><td style="text-align:center">telephone</td><td style="text-align:center">手机号码</td><td style="text-align:center">varchar(255) NOT NULL</td></tr><tr><td style="text-align:center">name</td><td style="text-align:center">联系人姓名</td><td style="text-align:center">varchar(255) NOT NULL</td></tr></tbody></table><p>2）表：<strong>db_telecom.tb_call</strong></p><p>用于存放某个时间维度下通话次数与通话时长的总和</p><table><thead><tr><th style="text-align:center">列</th><th style="text-align:center">备注</th><th style="text-align:center">类型</th></tr></thead><tbody><tr><td style="text-align:center">id_date_contact</td><td style="text-align:center">复合主键（联系人维度id，时间维度id）</td><td style="text-align:center">varchar(255) NOT NULL</td></tr><tr><td style="text-align:center">id_date_dimension</td><td style="text-align:center">时间维度id</td><td style="text-align:center">int(11) NOT NULL</td></tr><tr><td style="text-align:center">id_contact</td><td style="text-align:center">查询人的电话号码</td><td style="text-align:center">int(11) NOT NULL</td></tr><tr><td style="text-align:center">call_sum</td><td style="text-align:center">通话次数总和</td><td style="text-align:center">int(11) NOT NULL DEFAULT 0</td></tr><tr><td style="text-align:center">call_duration_sum</td><td style="text-align:center">通话时长总和</td><td style="text-align:center">int(11) NOT NULL DEFAULT 0</td></tr></tbody></table><p>3）表：<strong>db_telecom.tb_dimension_date</strong></p><p>用于存放时间维度的相关数据</p><table><thead><tr><th style="text-align:center">列</th><th style="text-align:center">备注</th><th style="text-align:center">类型</th></tr></thead><tbody><tr><td style="text-align:center">id</td><td style="text-align:center">自增主键</td><td style="text-align:center">int(11) NOT NULL</td></tr><tr><td style="text-align:center">year</td><td style="text-align:center">年，当前通话信息所在年</td><td style="text-align:center">int(11) NOT NULL</td></tr><tr><td style="text-align:center">month</td><td style="text-align:center">月，当前通话信息所在月，如果按照年来统计信息，则month为-1</td><td style="text-align:center">int(11) NOT NULL</td></tr><tr><td style="text-align:center">day</td><td style="text-align:center">日，当前通话信息所在日，如果是按照月来统计信息，则day为-1</td><td style="text-align:center">int(11) NOT NULL</td></tr></tbody></table><p>MySQL的建表语句：</p><p>CREATE TABLE <code>tb_call</code> (<br><code>id_date_contact</code> varchar(255) NOT NULL,<br><code>id_date_dimension</code> int(11) NOT NULL,<br><code>id_contact</code> int(11) NOT NULL,<br><code>call_sum</code> int(11) NOT NULL,<br><code>call_duration_sum</code> int(11) NOT NULL,<br>PRIMARY KEY (<code>id_date_contact</code>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p><p>CREATE TABLE <code>tb_contacts</code> (<br><code>id</code> int(11) NOT NULL AUTO_INCREMENT,<br><code>telephone</code> varchar(255) NOT NULL,<br><code>name</code> varchar(255) NOT NULL,<br>PRIMARY KEY (<code>id</code>)<br>) ENGINE=InnoDB AUTO_INCREMENT=21 DEFAULT CHARSET=utf8;</p><p>CREATE TABLE <code>tb_dimension_date</code> (<br><code>id</code> int(11) NOT NULL AUTO_INCREMENT,<br><code>year</code> int(11) NOT NULL,<br><code>month</code> int(11) NOT NULL,<br><code>day</code> int(11) NOT NULL,<br>PRIMARY KEY (<code>id</code>)<br>) ENGINE=InnoDB AUTO_INCREMENT=263 DEFAULT CHARSET=utf8;</p><h4 id="2、需求：按照不同的维度统计通话">2、需求：按照不同的维度统计通话</h4><p>根据需求目标，设计出如上表结构。我们需要按照时间范围（年月日），结合MapReduce统计出所属时间范围内所有手机号码的通话次数总和以及通话时长总和。<br>思路：<br>a）维度，即某个角度，某个视角，按照时间维度来统计通话，比如我想统计2018年所有月份所有日子的通话记录，那这个维度我们大概可以表述为2018年<code>*</code>月<code>*</code>日<br>b）通过Mapper将数据按照不同维度聚合给Reducer<br>c）通过Reducer拿到按照各个维度聚合过来的数据，进行汇总，输出。<br>d）根据业务需求，将Reducer的输出通过Outputformat把数据<br>数据输入：HBase<br>数据输出：MySQL<br>HBase中数据源结构：</p><table><thead><tr><th style="text-align:center">标签</th><th style="text-align:center">举例&amp;说明</th></tr></thead><tbody><tr><td style="text-align:center">rowkey</td><td style="text-align:center">hashregion_caller_datetime_callee_flag_duration;  01_15837312345_20180527081033_13766889900_1_0180</td></tr><tr><td style="text-align:center">family</td><td style="text-align:center">f1列族：存放主叫信息； f2列族：存放被叫信息</td></tr><tr><td style="text-align:center">caller</td><td style="text-align:center">第一个手机号码</td></tr><tr><td style="text-align:center">callee</td><td style="text-align:center">第二个手机号码</td></tr><tr><td style="text-align:center">date_time</td><td style="text-align:center">通话建立的时间，例如：20181017081520</td></tr><tr><td style="text-align:center">date_time_ts</td><td style="text-align:center">date_time对应的时间戳形式</td></tr><tr><td style="text-align:center">duration</td><td style="text-align:center">通话时长(单位：秒)</td></tr><tr><td style="text-align:center">flag</td><td style="text-align:center">标记caller是主叫还是被叫（caller的身份与call2的身份互斥）</td></tr></tbody></table><p>a）已知目标，那么需要结合目标思考已有数据是否能够支撑目标实现；<br>b） 根据目标数据结构，构建MySQL表结构，建表；<br>c）思考代码需要涉及到哪些功能模块，建立不同功能模块对应的包结构。<br>d）描述数据，一定是基于某个维度（视角）的，所以构建维度类。比如按照“年”与“手机号码”的组合作为key聚合所有的数据，便可以统计这个手机号码，这一年的相关结果<br>e）自定义OutputFormat用于对接MySQL，使数据输出<br>f）创建相关工具类</p><h4 id="3、环境准备">3、环境准备</h4><p>1） <strong>新建module：ct_analysis</strong><br><strong>pom文件配置</strong></p><pre><code class="highlight plaintext">&lt;properties&gt;      &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;  &lt;/properties&gt;  &lt;dependencies&gt;      &lt;dependency&gt;          &lt;groupId&gt;junit&lt;/groupId&gt;          &lt;artifactId&gt;junit&lt;/artifactId&gt;          &lt;version&gt;4.12&lt;/version&gt;          &lt;scope&gt;test&lt;/scope&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;mysql&lt;/groupId&gt;          &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;          &lt;version&gt;8.0.13&lt;/version&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;          &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;          &lt;version&gt;1.3.0&lt;/version&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;          &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;          &lt;version&gt;1.3.0&lt;/version&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;          &lt;artifactId&gt;hbase-common&lt;/artifactId&gt;          &lt;version&gt;1.3.0&lt;/version&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.aspectj&lt;/groupId&gt;          &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;          &lt;version&gt;1.8.10&lt;/version&gt;      &lt;/dependency&gt;      &lt;!--简化javabean--&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;          &lt;artifactId&gt;lombok&lt;/artifactId&gt;          &lt;version&gt;1.16.18&lt;/version&gt;          &lt;scope&gt;provided&lt;/scope&gt;      &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;      &lt;plugins&gt;          &lt;plugin&gt;              &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;              &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;              &lt;version&gt;2.12.4&lt;/version&gt;              &lt;configuration&gt;                  &lt;skipTests&gt;true&lt;/skipTests&gt;              &lt;/configuration&gt;          &lt;/plugin&gt;          &lt;plugin&gt;              &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;              &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;              &lt;version&gt;3.8.1&lt;/version&gt;              &lt;configuration&gt;                  &lt;source&gt;1.8&lt;/source&gt;                  &lt;target&gt;1.8&lt;/target&gt;              &lt;/configuration&gt;          &lt;/plugin&gt;      &lt;/plugins&gt;  &lt;/build&gt;</code></pre><p>2）<strong>创建包结构</strong>，根包：<strong>com.hsiehchou</strong>(不同颜色代表不同层级的递进)</p><p><img src="/medias/CT_XZ.PNG" alt="CT_XZ"></p><p>直接看CT_analysis</p><p>3） <strong>类表</strong></p><table><thead><tr><th style="text-align:center">类名</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">DimensionConverter</td><td style="text-align:center">负责实际的维度转id功能接口</td></tr><tr><td style="text-align:center">DimensionConverterImpl</td><td style="text-align:center">DimensionConverter  实现类，负责实际的维度转id功能</td></tr><tr><td style="text-align:center">BaseDimension</td><td style="text-align:center">维度（key）基类</td></tr><tr><td style="text-align:center">BaseValue</td><td style="text-align:center">值（value）基类</td></tr><tr><td style="text-align:center">ComDimension</td><td style="text-align:center">时间维度+联系人维度的组合维度</td></tr><tr><td style="text-align:center">ContactDimension</td><td style="text-align:center">联系人维度</td></tr><tr><td style="text-align:center">DateDimension</td><td style="text-align:center">时间维度</td></tr><tr><td style="text-align:center">CountDurationValue</td><td style="text-align:center">通话次数与通话时长的封装</td></tr><tr><td style="text-align:center">CountDurationMapper</td><td style="text-align:center">数据分析的Mapper类，继承自TableMapper</td></tr><tr><td style="text-align:center">MysqlOutputFormat</td><td style="text-align:center">自定义Outputformat，对接Mysql</td></tr><tr><td style="text-align:center">CountDurationReducer</td><td style="text-align:center">数据分析的Reducer类，继承自Reduccer</td></tr><tr><td style="text-align:center">CountDurationRunner</td><td style="text-align:center">数据分析的驱动类，组装Job</td></tr><tr><td style="text-align:center">JDBCInstance</td><td style="text-align:center">获取连接实例</td></tr><tr><td style="text-align:center">JDBCUtils</td><td style="text-align:center">连接Mysql的工具类</td></tr><tr><td style="text-align:center">LRUCache</td><td style="text-align:center">用于缓存已知的维度id，减少对mysql的操作次数，提高效率</td></tr></tbody></table><h4 id="4、编写代码：数据分析">4、编写代码：数据分析</h4><p>1）创建类：<strong>CountDurationMapper</strong></p><pre><code class="highlight plaintext">package mapper;import kv.key.ComDimension;import kv.key.ContactDimension;import kv.key.DateDimension;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableMapper;import org.apache.hadoop.hbase.util.Bytes;import org.apache.hadoop.io.Text;import java.io.IOException;import java.util.HashMap;import java.util.Map;public class CountDurationMapper extends TableMapper&lt;Comparable, Text&gt; {    private ComDimension comDimension = new ComDimension();    private Text durationText = new Text();    private Map&lt;String, String&gt; phoneMap;    @Override    protected void setup(Context context) throws IOException, InterruptedException {        phoneMap = new HashMap&lt;&gt;(20);        //批量修改名字Ctrl + Alt + Shift + J        phoneMap.put("17078388295", "李为");        phoneMap.put("13980337439", "王军");        phoneMap.put("14575535933", "时俊");        phoneMap.put("18902496992", "天机");        phoneMap.put("18549641558", "蔡铭");        phoneMap.put("17005930322", "陶尚");        phoneMap.put("18468618874", "魏山帅");        phoneMap.put("18576581848", "华倩");        phoneMap.put("15978226424", "焦君山");        phoneMap.put("15542823911", "钟尾田");        phoneMap.put("17526304161", "司可可");        phoneMap.put("15422018558", "官渡");        phoneMap.put("17269452013", "上贵坡");        phoneMap.put("17764278604", "时光机");        phoneMap.put("15711910344", "李发");        phoneMap.put("15714728273", "蒂冈");        phoneMap.put("16061028454", "范德");        phoneMap.put("16264433631", "周朝王");        phoneMap.put("17601615878", "谢都都");        phoneMap.put("15897468949", "刘何思");    }    @Override    protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException {        //05_18902496992_1525454104000_15711910344_1_1705        String rowkey = Bytes.toString(key.get());        String[] splits = rowkey.split("_");        if ("0".equals(splits[4])){            return;        }        //聚合的是主叫数据        String caller = splits[1];        String callee = splits[3];        String buildTime = splits[2];        String duration = splits[5];        durationText.set(duration);        String year = buildTime.substring(0,4);        String month = buildTime.substring(4,6);        String day = buildTime.substring(6,8);        //年、月、日整数        DateDimension yearDimension = new DateDimension(year, "-1", "-1");        DateDimension monthDimension = new DateDimension(year, month, "-1");        DateDimension dayDimension = new DateDimension(year, month, day);        //主叫callerContactDimension        ContactDimension callerContactDimension = new ContactDimension(caller, phoneMap.get(caller));        comDimension.setContactDimension(callerContactDimension);        //年        comDimension.setDateDimension(yearDimension);        context.write(comDimension, durationText);        //月        comDimension.setDateDimension(monthDimension);        context.write(comDimension, durationText);        //日        comDimension.setDateDimension(dayDimension);        context.write(comDimension, durationText);        //被叫callerContactDimension        ContactDimension calleeContactDimension = new ContactDimension(callee, phoneMap.get(callee));        comDimension.setContactDimension(calleeContactDimension);        //年        comDimension.setDateDimension(yearDimension);        context.write(comDimension, durationText);        //月        comDimension.setDateDimension(monthDimension);        context.write(comDimension, durationText);        //日        comDimension.setDateDimension(dayDimension);        context.write(comDimension, durationText);    }}</code></pre><p>2）创建类：<strong>CountDurationReducer</strong></p><pre><code class="highlight plaintext">package reducer;import kv.key.ComDimension;import kv.value.CountDurationValue;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;public class CountDurationReducer extends Reducer&lt;ComDimension, Text, ComDimension, CountDurationValue&gt; {    private CountDurationValue countDurationValue = new CountDurationValue();    @Override    protected void reduce(ComDimension key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {        int callSum = 0;        int callDuration = 0;        for (Text t : values){            callSum++;            callDuration += Integer.valueOf(t.toString());        }        countDurationValue.setCallSum(String.valueOf(callSum));        countDurationValue.setCallDurationSum(String.valueOf(callDuration));        context.write(key, countDurationValue);    }}</code></pre><p>3）创建类：<strong>CountDurationRunner</strong></p><pre><code class="highlight plaintext">package runner;import kv.key.ComDimension;import kv.value.CountDurationValue;import mapper.CountDurationMapper;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.Admin;import org.apache.hadoop.hbase.client.Connection;import org.apache.hadoop.hbase.client.ConnectionFactory;import org.apache.hadoop.hbase.client.Scan;import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.util.Tool;import org.apache.hadoop.util.ToolRunner;import outputformat.MysqlOutputFormat;import reducer.CountDurationReducer;import java.io.IOException;public class CountDurationRunner implements Tool {    private Configuration conf = null;    @Override    public void setConf(Configuration conf) {        this.conf = HBaseConfiguration.create(conf);    }    @Override    public Configuration getConf() {        return this.conf;    }    @Override    public int run(String[] strings) throws Exception {        //得到conf        Configuration conf = this.getConf();        //实例化Job        Job job = Job.getInstance(conf);        job.setJarByClass(CountDurationRunner.class);        //组装Mapper InputFormat        initHBaseInputConfig(job);        //组装Reducer OutputFormay        initReducerOutputConfig(job);        return job.waitForCompletion(true) ? 0:1;    }    private void initHBaseInputConfig(Job job) {        Connection connection = null;        Admin admin = null;        try {            String tableName = "ns_ct:calllog";            connection = ConnectionFactory.createConnection(job.getConfiguration());            admin = connection.getAdmin();            if (!admin.tableExists(TableName.valueOf(tableName))){                throw new RuntimeException("无法找到目标表");            }            Scan scan = new Scan();            //可以优化            TableMapReduceUtil.initTableMapperJob(                    tableName,                    scan,                    CountDurationMapper.class,                    ComDimension.class,                    Text.class,                    job,                    true);        } catch (IOException e) {            e.printStackTrace();        }finally {            try {                if (admin != null){                    admin.close();                }                if (connection != null &amp;&amp; !connection.isClosed()){                    connection.close();                }            } catch (IOException e) {                e.printStackTrace();            }        }    }    private void initReducerOutputConfig(Job job){        job.setReducerClass(CountDurationReducer.class);        job.setOutputKeyClass(ComDimension.class);        job.setOutputKeyClass(CountDurationValue.class);        job.setOutputFormatClass(MysqlOutputFormat.class);    }    public static void main(String[] args) {        try {            int status = ToolRunner.run(new CountDurationRunner(), args);            System.exit(status);        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p>4）创建类：<strong>MysqlOutputFormat</strong></p><pre><code class="highlight plaintext">package outputformat;import converter.DimensionConverterImpl;import kv.key.ComDimension;import kv.value.CountDurationValue;import org.apache.hadoop.fs.Path;import org.apache.hadoop.mapreduce.*;import org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import utils.JDBCInstance;import utils.JDBCUtils;import java.io.IOException;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.SQLException;public class MysqlOutputFormat extends OutputFormat&lt;ComDimension, CountDurationValue&gt; {    private OutputCommitter committer = null;    @Override    public RecordWriter&lt;ComDimension, CountDurationValue&gt; getRecordWriter(TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException {        //初始化JDBC连接对象        Connection conn = null;        conn = JDBCInstance.getInstance();        try {            //出问题的点之一，报空指针            conn.setAutoCommit(false);        } catch (SQLException e) {            throw new RuntimeException(e.getMessage());        }        return new MysqlRecordWriter(conn);    }    //输出校验    @Override    public void checkOutputSpecs(JobContext jobContext) throws InterruptedException {    }    @Override    public OutputCommitter getOutputCommitter(TaskAttemptContext context) throws IOException {        //此方法点击OutputFormat（按Ctrl + H的源码，复制getOutputCommitter，在FileOutputFormat）        if (committer == null){            String name = context.getConfiguration().get(FileOutputFormat.OUTDIR);            Path outputPath = name==null ? null:new Path(name);            committer = new FileOutputCommitter(outputPath, context);        }        return committer;    }    private static class MysqlRecordWriter extends RecordWriter&lt;ComDimension, CountDurationValue&gt;{        private DimensionConverterImpl dci = new DimensionConverterImpl();        private Connection conn = null;        private PreparedStatement preparedStatement = null;        private String insertSQL =null;        private int count = 0;        private final int BATCH_SIZE = 500;//批次大小        public MysqlRecordWriter(Connection conn){            this.conn = conn;        }        /**         * 输出到mysql         * @param key         * @param value         * @throws IOException         * @throws InterruptedException         */        @Override        public void write(ComDimension key, CountDurationValue value) throws IOException, InterruptedException {            try{                //tb_call                //id_date_contact, id_date_dimension, id_cantact, call_sum, call_duration_sum                //year month day                int idDateDimension = dci.getDimensionID(key.getDateDimension());                //telephone name                int idContactDimension = dci.getDimensionID(key.getContactDimension());                String idDateContact = idDateDimension + "_" + idContactDimension;                int callSum = Integer.valueOf(value.getCallSum());                int callDurationSum = Integer.valueOf(value.getCallDurationSum());                if (insertSQL == null){                    insertSQL = "INSERT INTO `tb_call` (`id_date_contact`, `id_date_dimension`, `id_contact`,  `call_sum`, `call_duration_sum`) values (?,?,?,?,?) ON DUPLICATE KEY UPDATE `id_date_contact` = ?;";                }                if (preparedStatement == null){                    preparedStatement = conn.prepareStatement(insertSQL);                }                //本次SQL                int i = 0;                preparedStatement.setString(++i, idDateContact);                preparedStatement.setInt(++i, idDateDimension);                preparedStatement.setInt(++i, idContactDimension);                preparedStatement.setInt(++i, callSum);                preparedStatement.setInt(++i, callDurationSum);                //无则插入，有则更新的判断依据，增加批次                preparedStatement.setString(++i, idDateContact);                preparedStatement.addBatch();                //当前缓存了多少个sql语句等待批量执行，计数器                count++;                if (count &gt;= BATCH_SIZE){                    preparedStatement.executeBatch();//执行批处理命令                    conn.commit();                    count = 0;                    preparedStatement.clearBatch();//清除批处理命令                }            }catch (Exception e){                e.printStackTrace();            }        }        @Override        public void close(TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException {            try {                if (preparedStatement != null){                    preparedStatement.executeBatch();                        this.conn.commit();                }            } catch (SQLException e) {                e.printStackTrace();            }finally {                JDBCUtils.close(conn, preparedStatement, null);            }        }    }}</code></pre><p>5）创建类：<strong>BaseDimension</strong></p><pre><code class="highlight plaintext">package kv.base;import org.apache.hadoop.io.WritableComparable;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;public abstract class BaseDimension implements WritableComparable&lt;BaseDimension&gt; {    public abstract int compareTo(BaseDimension o);    //将字节写入二进制流    public abstract void write(DataOutput out) throws IOException;    //从二进制流读取字节    public abstract void readFields(DataInput in) throws IOException;}</code></pre><p>6）创建类：<strong>BaseValue</strong></p><pre><code class="highlight plaintext">package kv.base;import org.apache.hadoop.io.Writable;public abstract class BaseValue implements Writable {}</code></pre><p>7）创建类：<strong>ComDimension</strong></p><pre><code class="highlight plaintext">package kv.key;import kv.base.BaseDimension;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;@Getter@Setter@NoArgsConstructor@AllArgsConstructorpublic class ComDimension extends BaseDimension {    //联系人维度    private ContactDimension contactDimension = new ContactDimension();    //时间维度    private DateDimension dateDimension = new DateDimension();    @Override    public int compareTo(BaseDimension o) {        ComDimension o1 = (ComDimension) o;        int result = this.dateDimension.compareTo(o1.dateDimension);        if (result != 0) {            return result;        }        result = this.contactDimension.compareTo(o1.contactDimension);        return result;    }    @Override    public void write(DataOutput out) throws IOException {        contactDimension.write(out);        dateDimension.write(out);    }    @Override    public void readFields(DataInput in) throws IOException {        this.contactDimension.readFields(in);        this.dateDimension.readFields(in);    }}</code></pre><p>8）创建类：<strong>ContactDimension</strong></p><pre><code class="highlight plaintext">package kv.key;import kv.base.BaseDimension;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;/** * 联系人维度类 */@Getter@Setter@NoArgsConstructor@AllArgsConstructorpublic class ContactDimension extends BaseDimension {    //手机号码    private String telephone;    //姓名    private String name;    @Override    public int compareTo(BaseDimension o) {        ContactDimension o1 = (ContactDimension) o;        int result = this.name.compareTo(o1.name);        if (result != 0){            return result;        }        result = this.telephone.compareTo(o1.telephone);        return result;    }    //将字节写入二进制流    @Override    public void write(DataOutput out) throws IOException {        out.writeUTF(this.telephone);        out.writeUTF(this.name);    }    //从二进制流读取字节    // Alt + Enter    @Override    public void readFields(DataInput in) throws IOException {        this.telephone = in.readUTF();        this.name = in.readUTF();    }}</code></pre><p>9）创建类：<strong>DateDimension</strong></p><pre><code class="highlight plaintext">package kv.key;import kv.base.BaseDimension;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;/** * 时间维度类 */@Getter@Setter@NoArgsConstructor@AllArgsConstructorpublic class DateDimension extends BaseDimension {    //时间维度：当前通话信息所在年    private String year;    //时间维度：当前通话信息所在月,如果按照年来统计信息，则month为-1    private String month;    //时间维度：当前通话信息所在日,如果按照年来统计信息，则day为-1。    private String day;    @Override    public int compareTo(BaseDimension o) {        DateDimension o1 = (DateDimension) o;        int result = this.year.compareTo(o1.year);        if (result != 0){            return result;        }        result = this.month.compareTo(o1.month);        if (result != 0){           return result;        }        result = this.day.compareTo(o1.day);        return result;    }    @Override    public void write(DataOutput out) throws IOException {        out.writeUTF(this.year);        out.writeUTF(this.month);        out.writeUTF(this.day);    }    @Override    public void readFields(DataInput in) throws IOException {        this.year = in.readUTF();        this.month = in.readUTF();        this.day = in.readUTF();    }}</code></pre><p>10）创建类：<strong>CountDurationValue</strong></p><pre><code class="highlight plaintext">package kv.value;import kv.base.BaseValue;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;@Setter@Getter@AllArgsConstructor@NoArgsConstructorpublic class CountDurationValue extends BaseValue {    //某个维度通话次数总和    private String callSum;    //某个维度通话时间总和    private String callDurationSum;    @Override    public void write(DataOutput dataOutput) throws IOException {        dataOutput.writeUTF(this.callSum);        dataOutput.writeUTF(this.callDurationSum);    }    @Override    public void readFields(DataInput dataInput) throws IOException {        this.callSum = dataInput.readUTF();        this.callDurationSum = dataInput.readUTF();    }}</code></pre><p>11） 创建类：<strong>JDBCUtil</strong></p><pre><code class="highlight plaintext">package utils;import java.sql.*;public class JDBCUtils {    private static final String MYSQL_DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";    private static final String MYSQL_URL = "jdbc:mysql://hsiehchou121:3306/db_telecom?useUnicode=true&amp;characterEncoding=UTF-8";    private static final String MYSQL_USERNAME = "root";    private static final String MYSQL_PASSWORD = "root";    /**     * 实例化JDBC连接器     * @return     */    public static Connection getConnection(){        try {            Class.forName(MYSQL_DRIVER_CLASS);            return DriverManager.getConnection(MYSQL_URL, MYSQL_USERNAME, MYSQL_PASSWORD);        } catch (ClassNotFoundException e) {            e.printStackTrace();        } catch (SQLException e) {            e.printStackTrace();        }        return null;    }    public static void close(Connection connection, Statement statement, ResultSet resultSet){        try {            if (resultSet != null &amp;&amp; !resultSet.isClosed()){                resultSet.close();            }            if (statement != null &amp;&amp; !statement.isClosed()){                statement.close();            }            if (connection != null &amp;&amp; !connection.isClosed()){                connection.close();            }        } catch (SQLException e) {            e.printStackTrace();        }    }}</code></pre><p>12）创建类：<strong>JDBCInstance</strong></p><pre><code class="highlight plaintext">package utils;import java.sql.Connection;import java.sql.SQLException;/** * 获取链接实例 */public class JDBCInstance {    private static Connection connection = null;    public JDBCInstance() {    }    public static Connection getInstance(){        try {            if (connection == null || connection.isClosed() || !connection.isValid(3)){                connection = JDBCUtils.getConnection();            }        } catch (SQLException e) {            e.printStackTrace();        }        return connection;    }}</code></pre><p>13） 创建接口：<strong>DimensionConverter</strong></p><pre><code class="highlight plaintext">package converter;import kv.base.BaseDimension;public interface DimensionConverter {    int getDimensionID(BaseDimension dimension);}</code></pre><p>14）创建类：<strong>DimensionConverterImpl</strong></p><pre><code class="highlight plaintext">package converter;import kv.base.BaseDimension;import kv.key.ContactDimension;import kv.key.DateDimension;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import utils.JDBCInstance;import utils.JDBCUtils;import utils.LRUCache;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;/** * 1、根据传入的维度数据，得到该数据对应的在表中的主键id * ** 做内存缓存，LRUCache * 分支 * -- 缓存中有数据 -&gt; 直接返回id * -- 缓存中无数据 -&gt; * ** 查询Mysql * 分支： * -- Mysql中有该条数据 -&gt; 直接返回id -&gt; 将本次读取到的id缓存到内存中 * -- Mysql中没有该数据  -&gt; 插入该条数据 -&gt; 再次反查该数据，得到id并返回 -&gt; 缓存到内存中 */public class DimensionConverterImpl implements DimensionConverter {    // Logger 打印该类的日志，取代resources里的log4j.properties    private static final Logger logger = LoggerFactory.getLogger(DimensionConverterImpl.class);    //对象线程化，用于每个线程管理自己的JDBC连接器    private ThreadLocal&lt;Connection&gt; threadLocalConnection = new ThreadLocal&lt;&gt;();    //构建内存缓存对象    private LRUCache lruCache = new LRUCache(3000);    public DimensionConverterImpl() {        //jvm关闭时，释放资源        Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; JDBCUtils.close(threadLocalConnection.get(), null, null)));    }    @Override    public int getDimensionID(BaseDimension dimension) {        //1、根据传入的维度对象获取对应的主键id，先从LRUCache中获取        //时间维度：date_dimension_year_month_day, 10        //联系人维度：contact_dimension_telephone_name(到了电话号码就不会重复了), 12        String cacheKey = getCacheKey(dimension);        //尝试获取缓存的id        if (lruCache.containsKey(cacheKey)) {            return lruCache.get(cacheKey);        }        //没有得到缓存id，需要执行select操作        //sqls包含了1组sql语句：查询和插入        String[] sqls = null;        if (dimension instanceof DateDimension) {            sqls = getDateDimensionSQL();        } else if (dimension instanceof ContactDimension) {            sqls = getContactDimensionSQL();        } else {            throw new RuntimeException("没有匹配到对应维度信息.");        }        //准备对Mysql表进行操作，先查询，有可能再插入        Connection conn = this.getConnection();        int id = -1;        synchronized (this) {            id = execSQL(conn, sqls, dimension);        }        //将刚查询的id加入到缓存中        lruCache.put(cacheKey, id);        return id;    }    /**     * 得到当前线程维护的Connection对象     *     * @return     */    public Connection getConnection() {        Connection conn = null;        try {            conn = threadLocalConnection.get();            if (conn == null || conn.isClosed()) {                conn = JDBCInstance.getInstance();                threadLocalConnection.set(conn);            }        } catch (SQLException e) {            e.printStackTrace();        }        return conn;    }    /**     * @param conn      JDBC连接器     * @param sqls      长度为2，第一个位置为查询语句，第二个位置为插入语句     * @param dimension 对应维度所保存的数据     * @return     */    private int execSQL(Connection conn, String[] sqls, BaseDimension dimension) {        PreparedStatement preparedStatement = null;        ResultSet resultSet = null;        try {            //1            //查询的preparedStatement            preparedStatement = conn.prepareStatement(sqls[0]);            //根据不同的维度，封装不同的SQL语句            setArguments(preparedStatement, dimension);            //执行查询            resultSet = preparedStatement.executeQuery();            if (resultSet.next()) {                int result = resultSet.getInt(1);                //释放资源                JDBCUtils.close(null, preparedStatement, resultSet);                return result;            }            //释放资源            JDBCUtils.close(null, preparedStatement, resultSet);            //2            //执行插入，封装插入的sql语句            preparedStatement = conn.prepareStatement(sqls[1]);            setArguments(preparedStatement, dimension);            //执行插入            preparedStatement.executeUpdate();            //释放资源            JDBCUtils.close(null, preparedStatement, null);            //3            //查询的preparedStatement            preparedStatement = conn.prepareStatement(sqls[0]);            //根据不同的维度，封装不同的SQL语句            setArguments(preparedStatement, dimension);            //执行查询            resultSet = preparedStatement.executeQuery();            if (resultSet.next()) {                return resultSet.getInt(1);            }        } catch (SQLException e) {            e.printStackTrace();        } finally {            //释放资源            JDBCUtils.close(null, preparedStatement, resultSet);        }        return -1;    }    /**     * 设置SQL语句的具体参数     *     * @param preparedStatement     * @param dimension     */    private void setArguments(PreparedStatement preparedStatement, BaseDimension dimension) {        int i = 0;        try {            if (dimension instanceof DateDimension) {                //可以优化                DateDimension dateDimension = (DateDimension) dimension;                preparedStatement.setString(++i, dateDimension.getYear());                preparedStatement.setString(++i, dateDimension.getMonth());                preparedStatement.setString(++i, dateDimension.getDay());            } else if (dimension instanceof ContactDimension) {                ContactDimension contactDimension = (ContactDimension) dimension;                preparedStatement.setString(++i, contactDimension.getTelephone());                preparedStatement.setString(++i, contactDimension.getName());            }        } catch (SQLException e) {            e.printStackTrace();        }    }    /**     * 返回联系人表的查询和插入语句     *     * @return     */    private String[] getContactDimensionSQL() {        String query = "SELECT `id` FROM `tb_contacts` WHERE `telephone` = ? AND `name` = ? ORDER BY `id`;";        String insert = "INSERT INTO `tb_contacts`(`telephone`, `name`) VALUES(?, ?);";        return new String[]{query, insert};    }    /**     * 返回时间表的查询和插入语句     *     * @return     */    private String[] getDateDimensionSQL() {        String query = "SELECT `id` FROM `tb_dimension_date` WHERE `year` = ? AND `month` = ? AND `day` = ? ORDER BY `id`;";        String insert = "INSERT INTO `tb_dimension_date`(`year`,`month`,`day`) VALUES(?, ?, ?);";        return new String[]{query, insert};    }    /**     * 根据维度信息得到维度对应的缓存键     *     * @param dimension     * @return     */    private String getCacheKey(BaseDimension dimension) {        StringBuilder sb = new StringBuilder();        if (dimension instanceof DateDimension) {            DateDimension dateDimension = (DateDimension) dimension;            sb.append("date_dimension")                    .append(dateDimension.getYear())                    .append(dateDimension.getMonth())                    .append(dateDimension.getDay());        } else if (dimension instanceof ContactDimension) {            ContactDimension contactDimension = (ContactDimension) dimension;            sb.append("contact_dimension")                    .append(contactDimension.getTelephone());        }        return sb.toString();    }}</code></pre><p>15） 创建类：<strong>LRUCache</strong></p><pre><code class="highlight plaintext">package utils;import java.util.LinkedHashMap;import java.util.Map;public class LRUCache extends LinkedHashMap&lt;String, Integer&gt; {    private static  final long serialVersionUID = 1L;    protected int maxElements;    public LRUCache(int maxSize){        super(maxSize, 0.75F, true);        this.maxElements = maxSize;    }    @Override    protected boolean removeEldestEntry(Map.Entry&lt;String, Integer&gt; eldest) {        return (size() &gt; this.maxElements);    }}</code></pre><h4 id="5、运行测试">5、运行测试</h4><p>1）将mysql驱动包放入到**/opt/jars的lib目录下**<br><strong>mysql-connector-java-8.0.13.jar</strong></p><p>2）<strong>提交任务</strong></p><pre><code class="highlight plaintext">$ /root/hd/hadoop-2.8.4/bin/yarn jar /opt/jars/CT_analysis-1.0-SNAPSHOT.jar runner.CountDurationRunner -libjars /opt/jars/lib/mysql-connector-java-8.0.13.jar</code></pre><p>观察Mysql中的结果</p><h3 id="七、数据展示">七、数据展示</h3><p>令人兴奋的时刻马上到了，接下来我们需要将某人按照不同维度查询出来的结果，展示到web页面上<br><strong>数据展示模块流程图</strong></p><p><img src="/medias/%E6%95%B0%E6%8D%AE%E5%B1%95%E7%A4%BA%E6%A8%A1%E5%9D%97%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="数据展示模块流程图"></p><h4 id="1、环境准备">1、环境准备</h4><p>1）新建module或项目：<strong>CT_web</strong><br>pom.xml配置文件：</p><pre><code class="highlight plaintext">&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;  &lt;artifactId&gt;CT_web&lt;/artifactId&gt;  &lt;packaging&gt;war&lt;/packaging&gt;  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;name&gt;ct_web Maven Webapp&lt;/name&gt;  &lt;url&gt;http://maven.apache.org&lt;/url&gt;  &lt;dependencies&gt;    &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;    &lt;dependency&gt;      &lt;groupId&gt;junit&lt;/groupId&gt;      &lt;artifactId&gt;junit&lt;/artifactId&gt;      &lt;version&gt;4.12&lt;/version&gt;      &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;mysql&lt;/groupId&gt;      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;      &lt;version&gt;8.0.13&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;c3p0&lt;/groupId&gt;      &lt;artifactId&gt;c3p0&lt;/artifactId&gt;      &lt;version&gt;0.9.1.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.mybatis&lt;/groupId&gt;      &lt;artifactId&gt;mybatis&lt;/artifactId&gt;      &lt;version&gt;3.2.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.springframework&lt;/groupId&gt;      &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;      &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.springframework&lt;/groupId&gt;      &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;      &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.springframework&lt;/groupId&gt;      &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;      &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.mybatis&lt;/groupId&gt;      &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;      &lt;version&gt;1.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.aspectj&lt;/groupId&gt;      &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;      &lt;version&gt;1.8.10&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;javax.servlet&lt;/groupId&gt;      &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;      &lt;version&gt;2.5&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;javax.servlet&lt;/groupId&gt;      &lt;artifactId&gt;jstl&lt;/artifactId&gt;      &lt;version&gt;1.2&lt;/version&gt;    &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework&lt;/groupId&gt;          &lt;artifactId&gt;spring-beans&lt;/artifactId&gt;          &lt;version&gt;4.3.3.RELEASE&lt;/version&gt;      &lt;/dependency&gt;  &lt;/dependencies&gt;  &lt;build&gt;    &lt;finalName&gt;ct_web&lt;/finalName&gt;    &lt;plugins&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;        &lt;version&gt;2.12.4&lt;/version&gt;        &lt;configuration&gt;          &lt;skipTests&gt;true&lt;/skipTests&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;      &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;        &lt;version&gt;3.8.1&lt;/version&gt;        &lt;configuration&gt;          &lt;source&gt;1.8&lt;/source&gt;          &lt;target&gt;1.8&lt;/target&gt;        &lt;/configuration&gt;      &lt;/plugin&gt;    &lt;/plugins&gt;  &lt;/build&gt;&lt;/project&gt;</code></pre><p>2）创建包结构，根包：com.hsiehchou<br>bean<br>controller<br>dao<br>3）类表</p><table><thead><tr><th style="text-align:center">类名</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">CallLog</td><td style="text-align:center">用于封装数据分析结果的JavaBean</td></tr><tr><td style="text-align:center">QueryInfo</td><td style="text-align:center">用于封装向服务器发来的请求参数</td></tr><tr><td style="text-align:center">CallLogHandler</td><td style="text-align:center">用于处理请求的Controller</td></tr><tr><td style="text-align:center">CallLogDAO</td><td style="text-align:center">查询某人某个维度通话记录的DAO</td></tr></tbody></table><p>4）web目录结构，web部分的根目录：webapp</p><table><thead><tr><th style="text-align:center">文件夹名</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">css</td><td style="text-align:center">存放css静态资源的文件夹</td></tr><tr><td style="text-align:center">html</td><td style="text-align:center">存放html静态资源的文件夹</td></tr><tr><td style="text-align:center">images</td><td style="text-align:center">存放图片静态资源文件夹</td></tr><tr><td style="text-align:center">js</td><td style="text-align:center">存放js静态资源的文件夹</td></tr><tr><td style="text-align:center">jsp</td><td style="text-align:center">存放jsp页面的文件夹</td></tr><tr><td style="text-align:center">WEB-INF</td><td style="text-align:center">存放web相关配置的文件夹</td></tr></tbody></table><p>5） resources目录下创建spring相关配置文件</p><p><strong>dbconfig.properties</strong>：用于存放数据库连接配置</p><pre><code class="highlight plaintext">jdbc.user=rootjdbc.password=rootjdbc.jdbcUrl=jdbc:mysql://hsiehchou121:3306/db_telecom?useUnicode=true&amp;characterEncoding=UTF-8jdbc.driverClass=com.mysql.cj.jdbc.Driver</code></pre><p><strong>applicationContext.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"       xmlns:p="http://www.springframework.org/schema/p"       xmlns:mvc="http://www.springframework.org/schema/mvc"       xmlns:context="http://www.springframework.org/schema/context"       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd        http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd        http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd        http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee.xsd        http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt;    &lt;context:property-placeholder location="classpath:dbconfig.properties"/&gt;    &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;        &lt;property name="user" value="${jdbc.user}"/&gt;        &lt;property name="password" value="${jdbc.password}"/&gt;        &lt;property name="driverClass" value="${jdbc.driverClass}"/&gt;        &lt;property name="jdbcUrl" value="${jdbc.jdbcUrl}"/&gt;    &lt;/bean&gt;    &lt;bean id="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt;        &lt;constructor-arg name="dataSource" value="#{dataSource}"&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;bean id="namedParameterJdbcTemplate" class="org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate"&gt;        &lt;constructor-arg name="dataSource" value="#{dataSource}"&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;!-- 包扫描 --&gt;    &lt;context:component-scan base-package="controller"&gt;&lt;/context:component-scan&gt;    &lt;context:component-scan base-package="dao"&gt;&lt;/context:component-scan&gt;    &lt;!-- 配置视图解析器--&gt;    &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt;        &lt;property name="prefix" value="/"/&gt;        &lt;property name="suffix" value=".jsp"/&gt;    &lt;/bean&gt;    &lt;!--&lt;mvc:annotation-driven /&gt;--&gt;    &lt;!--&lt;mvc:default-servlet-handler /&gt;--&gt;    &lt;!--&lt;mvc:resources location="/images/" mapping="/images/**"/&gt;--&gt;    &lt;!--&lt;mvc:resources location="/js/" mapping="/js/**"/&gt;--&gt;    &lt;!--&lt;mvc:resources location="/css/" mapping="/css/**"/&gt;--&gt;&lt;/beans&gt;</code></pre><p>6） webapp的WEB-INF目录下创建web相关配置<br><strong>web.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee"         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd"         version="3.1"&gt;    &lt;display-name&gt;SpringMVC_CRUD&lt;/display-name&gt;    &lt;!-- spring拦截器 --&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;init-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;        &lt;/init-param&gt;        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;    &lt;/servlet&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;        &lt;url-pattern&gt;/&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;    &lt;welcome-file-list&gt;        &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;    &lt;/welcome-file-list&gt;    &lt;filter&gt;        &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt;        &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;        &lt;init-param&gt;            &lt;param-name&gt;encoding&lt;/param-name&gt;            &lt;param-value&gt;utf-8&lt;/param-value&gt;        &lt;/init-param&gt;        &lt;init-param&gt;            &lt;param-name&gt;forceEncoding&lt;/param-name&gt;            &lt;param-value&gt;true&lt;/param-value&gt;        &lt;/init-param&gt;    &lt;/filter&gt;    &lt;filter-mapping&gt;        &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt;        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;    &lt;/filter-mapping&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;default&lt;/servlet-name&gt;        &lt;url-pattern&gt;*.jpg&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;default&lt;/servlet-name&gt;        &lt;url-pattern&gt;*.js&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;default&lt;/servlet-name&gt;        &lt;url-pattern&gt;*.css&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;</code></pre><p>7）拷贝js框架到webapp的js目录下<br>框架名称：<br>echarts.min.js</p><h4 id="2、编写代码-2">2、编写代码</h4><p>思路：<br>a）首先测试数据通顺以及完整性，写一个联系人的测试用例。<br>b）测试通过后，通过输入手机号码以及时间参数，查询指定维度的数据，并以图表展示。<br>代码：<br>1）新建类： <strong>CallLog</strong></p><pre><code class="highlight plaintext">package bean;/** * 用于存放返回给用户的数据 */public class CallLog {    private String id_date_contact;    private String id_date_dimension;    private String id_contact;    private String call_sum;    private String call_duration_sum;    private String telephone;    private String name;    private String year;    private String month;    private String day;    public String getId_date_contact() {        return id_date_contact;    }    public void setId_date_contact(String id_date_contact) {        this.id_date_contact = id_date_contact;    }    public String getId_date_dimension() {        return id_date_dimension;    }    public void setId_date_dimension(String id_date_dimension) {        this.id_date_dimension = id_date_dimension;    }    public String getId_contact() {        return id_contact;    }    public void setId_contact(String id_contact) {        this.id_contact = id_contact;    }    public String getCall_sum() {        return call_sum;    }    public void setCall_sum(String call_sum) {        this.call_sum = call_sum;    }    public String getCall_duration_sum() {        return call_duration_sum;    }    public void setCall_duration_sum(String call_duration_sum) {        this.call_duration_sum = call_duration_sum;    }    public String getTelephone() {        return telephone;    }    public void setTelephone(String telephone) {        this.telephone = telephone;    }    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    public String getYear() {        return year;    }    public void setYear(String year) {        this.year = year;    }    public String getMonth() {        return month;    }    public void setMonth(String month) {        this.month = month;    }    public String getDay() {        return day;    }    public void setDay(String day) {        this.day = day;    }    @Override    public String toString() {        return "CallLog{" +                "call_sum='" + call_sum + '\'' +                ", call_duration_sum='" + call_duration_sum + '\'' +                ", telephone='" + telephone + '\'' +                ", name='" + name + '\'' +                ", year='" + year + '\'' +                ", month='" + month + '\'' +                ", day='" + day + '\'' +                '}';    }}</code></pre><p>2）新建类：<strong>QueryInfo</strong></p><pre><code class="highlight plaintext">package bean;/** * 该类用于存放用户请求的数据 */public class QueryInfo {    private String telephone;    private String year;    private String month;    private String day;    public QueryInfo() {        super();    }    public QueryInfo(String telephone, String year, String month, String day) {        super();        this.telephone = telephone;        this.year = year;        this.month = month;        this.day = day;    }    public String getTelephone() {        return telephone;    }    public void setTelephone(String telephone) {        this.telephone = telephone;    }    public String getYear() {        return year;    }    public void setYear(String year) {        this.year = year;    }    public String getMonth() {        return month;    }    public void setMonth(String month) {        this.month = month;    }    public String getDay() {        return day;    }    public void setDay(String day) {        this.day = day;    }}</code></pre><p>3）新建类： <strong>CallLogDAO</strong></p><pre><code class="highlight plaintext">package dao;import bean.CallLog;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate;import org.springframework.stereotype.Repository;import java.util.HashMap;import java.util.List;@Repositorypublic class CallLogDAO {    @Autowired    private NamedParameterJdbcTemplate namedParameterJdbcTemplate;    public List&lt;CallLog&gt; getCallLogList(HashMap&lt;String, String&gt; paramsMap) {        //按照年统计：统计某个用户，1年12个月的所有的数据（不精确到day）        String sql = "SELECT `call_sum`, `call_duration_sum`, `telephone`, `name`, `year` , `month`, `day` FROM tb_dimension_date t4 INNER JOIN ( SELECT `id_date_dimension`, `call_sum`, `call_duration_sum`, `telephone`, `name` FROM tb_call t2 INNER JOIN ( SELECT `id`, `telephone`, `name` FROM tb_contacts WHERE telephone = :telephone ) t1 ON t2.id_contact = t1.id ) t3 ON t4.id = t3.id_date_dimension WHERE `year` = :year AND `month` != :month AND `day` = :day ORDER BY `year`, `month`;";        BeanPropertyRowMapper&lt;CallLog&gt; beanPropertyRowMapper = new BeanPropertyRowMapper&lt;&gt;(CallLog.class);        List&lt;CallLog&gt; list = namedParameterJdbcTemplate.query(sql, paramsMap, beanPropertyRowMapper);        return list;    }}</code></pre><p>4）新建类：<strong>CallLogHandler</strong></p><pre><code class="highlight plaintext">package controller;import bean.CallLog;import bean.QueryInfo;import dao.CallLogDAO;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import java.util.HashMap;import java.util.List;@Controllerpublic class CallLogHandler {    @RequestMapping("/queryCallLogList")    public String queryCallLog(Model model, QueryInfo queryInfo){        ApplicationContext applicationContext = new ClassPathXmlApplicationContext("applicationContext.xml");        CallLogDAO callLogDAO = applicationContext.getBean(CallLogDAO.class);        HashMap&lt;String, String&gt; hashMap = new HashMap&lt;&gt;();        hashMap.put("telephone", queryInfo.getTelephone());        hashMap.put("year", queryInfo.getYear());        hashMap.put("month", queryInfo.getMonth());        hashMap.put("day", queryInfo.getDay());        List&lt;CallLog&gt; list = callLogDAO.getCallLogList(hashMap);        StringBuilder dateSB = new StringBuilder();        StringBuilder callSumSB = new StringBuilder();        StringBuilder callDurationSumSB = new StringBuilder();        for(int i = 0; i &lt; list.size(); i++){            CallLog callLog = list.get(i);            //1月, 2月, ....12月,            dateSB.append(callLog.getMonth() + "月,");            callSumSB.append(callLog.getCall_sum() + ",");            callDurationSumSB.append(callLog.getCall_duration_sum() + ",");        }        dateSB.deleteCharAt(dateSB.length() - 1);        callSumSB.deleteCharAt(callSumSB.length() - 1);        callDurationSumSB.deleteCharAt(callDurationSumSB.length() - 1);        //通过model返回数据        model.addAttribute("telephone", list.get(0).getTelephone());        model.addAttribute("name", list.get(0).getName());        model.addAttribute("date", dateSB.toString());        model.addAttribute("count", callSumSB.toString());        model.addAttribute("duration", callDurationSumSB.toString());        return "jsp/CallLogListEchart";    }}</code></pre><p>5）新建：<strong>index.jsp</strong></p><pre><code class="highlight plaintext">&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ page language="java" contentType="text/html; charset=utf-8"         pageEncoding="utf-8" %&gt;&lt;%    String path = request.getContextPath();%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;    &lt;head&gt;        &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;        &lt;title&gt;电信查询系统&lt;/title&gt;        &lt;link href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"&gt;        &lt;script src="//cdn.bootcss.com/jquery/2.1.1/jquery.min.js"&gt;&lt;/script&gt;        &lt;script src="//cdn.bootcss.com/bootstrap/3.3.6/js/bootstrap.min.js"&gt;&lt;/script&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div style="width:410px;margin: 0 auto;"&gt;            &lt;h3&gt;电信查询用户通话次数和通话时长系统&lt;/h3&gt;            &lt;br /&gt;            &lt;form role="form" action="/queryCallLogList" method="post"&gt;                &lt;div class="form-group" style="margin-bottom: 0;"&gt;                    &lt;label for="name"&gt;手机号码&lt;/label&gt;                    &lt;input type="text" name="telephone" class="form-control" id="name" placeholder="请输入手机号码"&gt;                &lt;/div&gt;                &lt;div class="form-group" style="margin-bottom: 0;"&gt;                    &lt;label for="name"&gt;年&lt;/label&gt;                    &lt;input type="text" name="year" class="form-control" id="name" placeholder="请输入年"&gt;                &lt;/div&gt;                &lt;div class="form-group" style="margin-bottom: 0;"&gt;                    &lt;label for="name"&gt;月&lt;/label&gt;                    &lt;input type="text" name="month" class="form-control" id="name" placeholder="请输入月"&gt;                &lt;/div&gt;                &lt;div class="form-group" style="margin-bottom: 0;"&gt;                    &lt;label for="name"&gt;日&lt;/label&gt;                    &lt;input type="text" name="day" class="form-control" id="name" placeholder="请输入日"&gt;                &lt;/div&gt;                &lt;button type="submit" class="btn btn-default"&gt;查询&lt;/button&gt;            &lt;/form&gt;        &lt;/div&gt;        &lt;br /&gt;        &lt;div style="width: 1000px;margin: 0 auto;"&gt;            &lt;table class="table"&gt;                &lt;h4&gt;数据库电话号码表&lt;/h4&gt;                &lt;thead&gt;                    &lt;tr&gt;                        &lt;th&gt;姓名&lt;/th&gt;                        &lt;th&gt;手机号&lt;/th&gt;                        &lt;th&gt;&lt;/th&gt;                        &lt;th&gt;姓名&lt;/th&gt;                        &lt;th&gt;手机号&lt;/th&gt;                        &lt;th&gt;&lt;/th&gt;                        &lt;th&gt;姓名&lt;/th&gt;                        &lt;th&gt;手机号&lt;/th&gt;                        &lt;th&gt;&lt;/th&gt;                        &lt;th&gt;姓名&lt;/th&gt;                        &lt;th&gt;手机号&lt;/th&gt;                        &lt;th&gt;&lt;/th&gt;                        &lt;th&gt;姓名&lt;/th&gt;                        &lt;th&gt;手机号&lt;/th&gt;                    &lt;/tr&gt;                &lt;/thead&gt;                &lt;tbody&gt;                    &lt;tr class="active"&gt;                        &lt;td&gt;李为&lt;/td&gt;                        &lt;td&gt;17078388295&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;王军&lt;/td&gt;                        &lt;td&gt;13980337439&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;时俊&lt;/td&gt;                        &lt;td&gt;14575535933&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;天机&lt;/td&gt;                        &lt;td&gt;18902496992&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;蔡铭&lt;/td&gt;                        &lt;td&gt;18549641558&lt;/td&gt;                    &lt;/tr&gt;                    &lt;tr class="success"&gt;                        &lt;td&gt;陶尚&lt;/td&gt;                        &lt;td&gt;17005930322&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;魏山帅&lt;/td&gt;                        &lt;td&gt;18468618874&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;华倩&lt;/td&gt;                        &lt;td&gt;18576581848&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;焦君山&lt;/td&gt;                        &lt;td&gt;15978226424&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;钟尾田&lt;/td&gt;                        &lt;td&gt;15542823911&lt;/td&gt;                    &lt;/tr&gt;                    &lt;tr  class="warning"&gt;                        &lt;td&gt;司可可&lt;/td&gt;                        &lt;td&gt;17526304161&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;官渡&lt;/td&gt;                        &lt;td&gt;15422018558&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;上贵坡&lt;/td&gt;                        &lt;td&gt;17269452013&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;时光机&lt;/td&gt;                        &lt;td&gt;17764278604&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;李发&lt;/td&gt;                        &lt;td&gt;15711910344&lt;/td&gt;                    &lt;/tr&gt;                    &lt;tr  class="danger"&gt;                        &lt;td&gt;蒂冈&lt;/td&gt;                        &lt;td&gt;15714728273&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;范德&lt;/td&gt;                        &lt;td&gt;16061028454&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;周朝王&lt;/td&gt;                        &lt;td&gt;16264433631&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;谢都都&lt;/td&gt;                        &lt;td&gt;17601615878&lt;/td&gt;                        &lt;td&gt;&lt;/td&gt;                        &lt;td&gt;刘何思&lt;/td&gt;                        &lt;td&gt;15897468949&lt;/td&gt;                    &lt;/tr&gt;                &lt;/tbody&gt;            &lt;/table&gt;        &lt;/div&gt;    &lt;/body&gt;&lt;/html&gt;</code></pre><p>6）新建：<strong>CallLogListEchart.jsp</strong></p><pre><code class="highlight plaintext">&lt;%--  Created by IntelliJ IDEA.  User: Z  Date: 2017/10/28  Time: 14:36  To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" isELIgnored="false" %&gt;&lt;html&gt;&lt;head&gt;    &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;    &lt;title&gt;显示通话记录&lt;/title&gt;    &lt;script type="text/javascript" src="../js/echarts.min.js"&gt;&lt;/script&gt;    &lt;%--&lt;script type="text/javascript" src="${pageContext.request.contextPath}/js/echarts.min.js"&gt;&lt;/script&gt;--%&gt;    &lt;%--&lt;script type="text/javascript" src="${pageContext.request.contextPath}/jquery-3.2.0.min.js"&gt;&lt;/script&gt;--%&gt;    &lt;%--&lt;script type="text/javascript" src="http://echarts.baidu.com/gallery/vendors/echarts/echarts-all-3.js"&gt;&lt;/script&gt;--%&gt;&lt;/head&gt;&lt;body style="height: 100%; margin: 0; background-color: #3C3F41"&gt;&lt;style type="text/css"&gt;    h3 {        font-size: 12px;        color: #ffffff;        display: inline    }&lt;/style&gt;&lt;h4 style="color: #ffffff;text-align:center"&gt;通话月单查询：${requestScope.name}&lt;/h4&gt;&lt;%--&lt;h3 style="margin-left: 70%"&gt;通话次数&lt;/h3&gt;--%&gt;&lt;%--&lt;h3 style="margin-left: 20%"&gt;通话时长&lt;/h3&gt;--%&gt;&lt;div id="container1" style="height: 80%; width: 50%; float:left"&gt;&lt;/div&gt;&lt;div id="container2" style="height: 80%; width: 50%; float:right"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt;    var telephone = "${requestScope.telephone}"    var name = "${requestScope.name}"    var date = "${requestScope.date}"//1月,2月,3月,xxxxx    var count = "${requestScope.count}"    var duration = "${requestScope.duration}"    var pieData = converterFun(duration.split(","), date.split(","))    callog1();    callog2();    function converterFun(duration, date) {        var array = [];        for (var i = 0; i &lt; duration.length; i++) {            var map = {};            map['value'] = parseFloat(duration[i]);            map['name'] = date[i];            array.push(map);        }        return array;    }    function callog1() {        var dom = document.getElementById("container1");        var myChart = echarts.init(dom);        myChart.showLoading();        var option = {            title: {                text: '通话次数',                textStyle: {                    //文字颜色                    color: '#ffffff',                    //字体风格,'normal','italic','oblique'                    fontStyle: 'normal',                    //字体粗细 'normal','bold','bolder','lighter',100 | 200 | 300 | 400...                    fontWeight: 'bold',                    //字体系列                    fontFamily: 'sans-serif',                    //字体大小                    fontSize: 13                },                itemGap: 12,            },            grid: {                x: 80,                y: 60,                x2: 80,                y2: 60,                backgroundColor: 'rgba(0,0,0,0)',                borderWidth: 1,                borderColor: '#ffffff'            },            tooltip: {                trigger: 'axis'            },            legend: {                borderColor: '#ffffff',                itemGap: 10,                data: ['通话次数'],                textStyle: {                    color: '#ffffff'// 图例文字颜色                }            },            toolbox: {                show: false,                feature: {                    dataZoom: {                        yAxisIndex: 'none'                    },                    dataView: {readOnly: false},                    magicType: {type: ['line', 'bar']},                    restore: {},                    saveAsImage: {}                }            },            xAxis: {                data: date.split(","),                axisLine: {                    lineStyle: {                        color: '#ffffff',                        width: 2                    }                }            },            yAxis: {                axisLine: {                    lineStyle: {                        color: '#ffffff',                        width: 2                    }                }            },            series: [                {                    type: 'line',                    data: count.split(","),                    itemStyle: {                        normal: {                            color: '#ffca29',                            lineStyle: {                                color: '#ffd80d',                                width: 2                            }                        }                    },                    markPoint: {                        data: [                            {type: 'max', name: '最大值'},                            {type: 'min', name: '最小值'}                        ]                    },                    markLine: {                        data: [                            {type: 'average', name: '平均值'}                        ]                    }                }            ]        };        if (option &amp;&amp; typeof option === "object") {            myChart.setOption(option, true);        }        myChart.hideLoading()    }    function callog2() {        var dom = document.getElementById("container2");        var myChart = echarts.init(dom);        myChart.showLoading();        var option = {            title: {                text: '通话时长',                textStyle: {                    //文字颜色                    color: '#ffffff',                    //字体风格,'normal','italic','oblique'                    fontStyle: 'normal',                    //字体粗细 'normal','bold','bolder','lighter',100 | 200 | 300 | 400...                    fontWeight: 'bold',                    //字体系列                    fontFamily: 'sans-serif',                    //字体大小                    fontSize: 13                },                itemGap: 12,            },            tooltip: {                trigger: 'item',                formatter: "{a} &lt;br/&gt;{b} : {c} ({d}%)"            },            visualMap: {                show: false,                min: Math.min.apply(null, duration.split(",")),                max: Math.max.apply(null, duration.split(",")),                inRange: {                    colorLightness: [0, 0.5]                }            },            series: [                {                    name: '通话时长',                    type: 'pie',                    radius: '55%',                    center: ['50%', '50%'],                    data: pieData.sort(function (a, b) {                        return a.value - b.value;                    }),                    roseType: 'radius',                    label: {                        normal: {                            textStyle: {                                color: 'rgba(255, 255, 255, 0.3)'                            }                        }                    },                    labelLine: {                        normal: {                            lineStyle: {                                color: 'rgba(255, 255, 255, 0.3)'                            },                            smooth: 0.2,                            length: 10,                            length2: 20                        }                    },                    itemStyle: {                        normal: {                            color: '#01c1c2',                            shadowBlur: 200,                            shadowColor: 'rgba(0, 0, 0, 0.5)'                        }                    },                    animationType: 'scale',                    animationEasing: 'elasticOut',                    animationDelay: function (idx) {                        return Math.random() * 200;                    }                }            ]        };        if (option &amp;&amp; typeof option === "object") {            myChart.setOption(option, true);        }        myChart.hideLoading()    }&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h4 id="3、最终预览">3、最终预览</h4><p>查询人通话时长与通话次数统计大概如下所示：</p><p><strong>首页</strong></p><p><img src="/medias/index.PNG" alt="index"></p><p><strong>统一展示</strong></p><p><img src="/medias/%E5%9B%BE%E5%BD%A2%E5%8C%96%E5%B1%95%E7%A4%BA.PNG" alt="图形化展示"></p><h3 id="八、定时任务">八、定时任务</h3><p>新的数据每天都会产生，所以我们每天都需要更新离线的分析结果，所以此时我们可以用各种各样的定时任务调度工具来完成此操作。此例我们使用crontab来执行该操作。<br>1）编写任务脚本：<strong><a href="http://analysis.sh">analysis.sh</a></strong></p><pre><code class="highlight plaintext">#!/bin/bash/root/hd/hadoop-2.8.4/bin/yarn jar /opt/jars/CT_analysis-1.0-SNAPSHOT.jar runner.CountDurationRunner -libjars /root/hd/hadoop-2.8.4/lib/*</code></pre><p>2） 制定crontab任务</p><pre><code class="highlight plaintext"># .------------------------------------------minute(0~59)# | .----------------------------------------hours(0~23)# | | .--------------------------------------day of month(1~31)# | | | .------------------------------------month(1~12)# | | | | .----------------------------------day of week(0~6)# | | | | | .--------------------------------command# | | | | | |# | | | | | |0 0 * * * /opt/jars/analysis.sh</code></pre><p>3）考虑数据处理手段是否安全<br>a、定时任务统计结果是否会重复<br>b、定时任务处理的数据是否全面</p><h3 id="九、项目总结">九、项目总结</h3><p>重新总结梳理整个项目流程和方法论<br>1、实现月查询（某个月每一天的数据展示）<br>2、用户亲密度展示<br>3、考虑Hive实现<br>4、用户按照时间区间，查找所有的通话数据<br>5、给读者建议-----按代码来-----》成功运行------》掌握此项目</p><h3 id="十、附录">十、附录</h3><h4 id="1、-flume-myagent-flume2kafka-conf">1、/flume/myagent/flume2kafka.conf</h4><pre><code class="highlight plaintext"># definea1.sources = r1a1.sinks = k1a1.channels = c1# sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F -c +0 /opt/jars/calllog.csva1.sources.r1.shell = /bin/bash -c# sinka1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.brokerList = hsiehchou121:9092,hsiehchou122:9092,hsiehchou123:9092a1.sinks.k1.topic = callloga1.sinks.k1.batchSize = 20a1.sinks.k1.requiredAcks = 1# channela1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# binda1.sources.r1.channels = c1a1.sinks.k1.channel = c1</code></pre><h4 id="2、core-site-xml">2、core-site.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;!--  Licensed under the Apache License, Version 2.0 (the "License");  you may not use this file except in compliance with the License.  You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software  distributed under the License is distributed on an "AS IS" BASIS,  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and  limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt;&lt;!-- 指定hdfs的nameservice为mycluster --&gt;&lt;property&gt;&lt;name&gt;fs.defaultFS&lt;/name&gt;&lt;value&gt;hdfs://mycluster&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop临时目录 --&gt;&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/root/hd/hadoop-2.8.4/tmp&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定zookeeper地址 --&gt;&lt;property&gt;&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;&lt;value&gt;hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181&lt;/value&gt;&lt;/property&gt;&lt;!--&lt;property&gt;&lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt;&lt;value&gt;30&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt;&lt;value&gt;1000&lt;/value&gt;&lt;/property&gt; --&gt;&lt;/configuration&gt;</code></pre><h4 id="3、hdfs-site-xml">3、hdfs-site.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;!--  Licensed under the Apache License, Version 2.0 (the "License");  you may not use this file except in compliance with the License.  You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software  distributed under the License is distributed on an "AS IS" BASIS,  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and  limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt; &lt;!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 --&gt;&lt;property&gt;&lt;name&gt;dfs.nameservices&lt;/name&gt;&lt;value&gt;mycluster&lt;/value&gt;&lt;/property&gt;&lt;!-- mycluster下面有两个NameNode，分别是nn1，nn2 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;&lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的RPC通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;&lt;value&gt;hsiehchou121:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的http通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;&lt;value&gt;hsiehchou121:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的RPC通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;&lt;value&gt;hsiehchou122:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的http通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;&lt;value&gt;hsiehchou122:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定NameNode的日志在JournalNode上的存放位置 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;&lt;value&gt;qjournal://hsiehchou121:8485;hsiehchou122:8485;/mycluster&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;&lt;property&gt;&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;&lt;value&gt;/root/hd/hadoop-2.8.4/journal&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启NameNode失败自动切换 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置失败自动切换实现方式 --&gt;&lt;property&gt;&lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;&lt;value&gt;sshfenceshell(/bin/true)&lt;/value&gt;&lt;/property&gt;&lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;&lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置sshfence隔离机制超时时间 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;&lt;value&gt;30000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="4、hbase-site-xml">4、hbase-site.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;!--/** * * Licensed to the Apache Software Foundation (ASF) under one * or more contributor license agreements.  See the NOTICE file * distributed with this work for additional information * regarding copyright ownership.  The ASF licenses this file * to you under the Apache License, Version 2.0 (the * "License"); you may not use this file except in compliance * with the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */--&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.port&lt;/name&gt; &lt;value&gt;16000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hsiehchou121,hsiehchou122,hsiehchou123&lt;/value&gt; &lt;/property&gt; &lt;!-- hbase的元数据信息存储在zookeeper的位置 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/root/hd/zookeeper-3.4.10/zkData&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;zookeeper.session.timeout&lt;/name&gt; &lt;value&gt;120000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.tickTime&lt;/name&gt; &lt;value&gt;6000&lt;/value&gt; &lt;/property&gt; &lt;!-- 保证HBase之间时间同步 --&gt;&lt;property&gt;&lt;name&gt;hbase.master.maxclockskew&lt;/name&gt;&lt;value&gt;180000&lt;/value&gt;&lt;description&gt;Time difference of regionserver from master&lt;/description&gt;&lt;/property&gt;&lt;!-- 使用HBase Coprocessor协处理器 --&gt;&lt;property&gt;&lt;name&gt;hbase.coprocessor.region.classes&lt;/name&gt;&lt;value&gt;hbase.CalleeWriteObserver&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="5、log4j-properties">5、log4j.properties</h4><pre><code class="highlight plaintext"># Licensed to the Apache Software Foundation (ASF) under one# or more contributor license agreements.  See the NOTICE file# distributed with this work for additional information# regarding copyright ownership.  The ASF licenses this file# to you under the Apache License, Version 2.0 (the# "License"); you may not use this file except in compliance# with the License.  You may obtain a copy of the License at##     http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# Define some default values that can be overridden by system propertieshbase.root.logger=INFO,consolehbase.security.logger=INFO,consolehbase.log.dir=.hbase.log.file=hbase.log# Define the root logger to the system property "hbase.root.logger".log4j.rootLogger=${hbase.root.logger}# Logging Thresholdlog4j.threshold=ALL## Daily Rolling File Appender#log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.DRFA.File=${hbase.log.dir}/${hbase.log.file}# Rollver at midnightlog4j.appender.DRFA.DatePattern=.yyyy-MM-dd# 30-day backup#log4j.appender.DRFA.MaxBackupIndex=30log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout# Pattern format: Date LogLevel LoggerName LogMessagelog4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2}: %m%n# Rolling File Appender propertieshbase.log.maxfilesize=256MBhbase.log.maxbackupindex=20# Rolling File Appenderlog4j.appender.RFA=org.apache.log4j.RollingFileAppenderlog4j.appender.RFA.File=${hbase.log.dir}/${hbase.log.file}log4j.appender.RFA.MaxFileSize=${hbase.log.maxfilesize}log4j.appender.RFA.MaxBackupIndex=${hbase.log.maxbackupindex}log4j.appender.RFA.layout=org.apache.log4j.PatternLayoutlog4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2}: %m%n## Security audit appender#hbase.security.log.file=SecurityAuth.audithbase.security.log.maxfilesize=256MBhbase.security.log.maxbackupindex=20log4j.appender.RFAS=org.apache.log4j.RollingFileAppenderlog4j.appender.RFAS.File=${hbase.log.dir}/${hbase.security.log.file}log4j.appender.RFAS.MaxFileSize=${hbase.security.log.maxfilesize}log4j.appender.RFAS.MaxBackupIndex=${hbase.security.log.maxbackupindex}log4j.appender.RFAS.layout=org.apache.log4j.PatternLayoutlog4j.appender.RFAS.layout.ConversionPattern=%d{ISO8601} %p %c: %m%nlog4j.category.SecurityLogger=${hbase.security.logger}log4j.additivity.SecurityLogger=false#log4j.logger.SecurityLogger.org.apache.hadoop.hbase.security.access.AccessController=TRACE#log4j.logger.SecurityLogger.org.apache.hadoop.hbase.security.visibility.VisibilityController=TRACE## Null Appender#log4j.appender.NullAppender=org.apache.log4j.varia.NullAppender## console# Add "console" to rootlogger above if you want to use this#log4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.target=System.errlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2}: %m%nlog4j.appender.asyncconsole=org.apache.hadoop.hbase.AsyncConsoleAppenderlog4j.appender.asyncconsole.target=System.err# Custom Logging levelslog4j.logger.org.apache.zookeeper=INFO#log4j.logger.org.apache.hadoop.fs.FSNamesystem=DEBUGlog4j.logger.org.apache.hadoop.hbase=INFO# Make these two classes INFO-level. Make them DEBUG to see more zk debug.log4j.logger.org.apache.hadoop.hbase.zookeeper.ZKUtil=INFOlog4j.logger.org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher=INFO#log4j.logger.org.apache.hadoop.dfs=DEBUG# Set this class to log INFO only otherwise its OTT# Enable this to get detailed connection error/retry logging.# log4j.logger.org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation=TRACE# Uncomment this line to enable tracing on _every_ RPC call (this can be a lot of output)#log4j.logger.org.apache.hadoop.ipc.HBaseServer.trace=DEBUG# Uncomment the below if you want to remove logging of client region caching'# and scan of hbase:meta messages# log4j.logger.org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation=INFO# log4j.logger.org.apache.hadoop.hbase.client.MetaScanner=INFO# Prevent metrics subsystem start/stop messages (HBASE-17722)log4j.logger.org.apache.hadoop.metrics2.impl.MetricsConfig=WARNlog4j.logger.org.apache.hadoop.metrics2.impl.MetricsSinkAdapter=WARNlog4j.logger.org.apache.hadoop.metrics2.impl.MetricsSystemImpl=WARN</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据项目 </tag>
            
            <tag> 电信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink练习</title>
      <link href="/2019/05/18/flink_lian_xi/"/>
      <url>/2019/05/18/flink_lian_xi/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Flink开发IDEA环境搭建与测试">一、Flink开发IDEA环境搭建与测试</h3><h4 id="1、IDEA开发环境">1、IDEA开发环境</h4><p>先虚拟机联网，然后执行yum -y install nc<br>nc是用来打开端口的工具<br>然后nc -l 9000</p><p><strong>1.pom文件设置</strong></p><pre><code class="highlight plaintext">&lt;properties&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;scala.version&gt;2.11.12&lt;/scala.version&gt;        &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;        &lt;hadoop.version&gt;2.8.4&lt;/hadoop.version&gt;        &lt;flink.version&gt;1.6.1&lt;/flink.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;            &lt;artifactId&gt;scala-library&lt;/artifactId&gt;            &lt;version&gt;${scala.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-scala_${scala.binary.version}&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-streaming-scala_${scala.binary.version}&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-table_${scala.binary.version}&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;            &lt;artifactId&gt;flink-connector-kafka-0.10_${scala.binary.version}&lt;/artifactId&gt;            &lt;version&gt;${flink.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;            &lt;version&gt;${hadoop.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;5.1.38&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;            &lt;version&gt;1.2.22&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;        &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;                &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;                &lt;version&gt;3.2.0&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                            &lt;goal&gt;compile&lt;/goal&gt;                            &lt;goal&gt;testCompile&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;args&gt;                                &lt;!-- &lt;arg&gt;-make:transitive&lt;/arg&gt; --&gt;                                &lt;arg&gt;-dependencyfile&lt;/arg&gt;                                &lt;arg&gt;${project.build.directory}/.scala_dependencies&lt;/arg&gt;                            &lt;/args&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                &lt;version&gt;2.18.1&lt;/version&gt;                &lt;configuration&gt;                    &lt;useFile&gt;false&lt;/useFile&gt;                    &lt;disableXmlReport&gt;true&lt;/disableXmlReport&gt;                    &lt;includes&gt;                        &lt;include&gt;**/*Test.*&lt;/include&gt;                        &lt;include&gt;**/*Suite.*&lt;/include&gt;                    &lt;/includes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;                &lt;version&gt;3.0.0&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;shade&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;filters&gt;                                &lt;filter&gt;                                    &lt;artifact&gt;*:*&lt;/artifact&gt;                                    &lt;excludes&gt;                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;                                    &lt;/excludes&gt;                                &lt;/filter&gt;                            &lt;/filters&gt;                            &lt;transformers&gt;                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;                                    &lt;mainClass&gt;org.apache.spark.WordCount&lt;/mainClass&gt;                                &lt;/transformer&gt;                            &lt;/transformers&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><h4 id="2、Flink开发流程">2、Flink开发流程</h4><p>Flink具有特殊类DataSet并DataStream在程序中表示数据。您可以将它们视为可以包含重复项的不可变数据集合。在DataSet数据有限的情况下，对于一个DataStream元素的数量可以是无界的</p><p>这些集合在某些关键方面与常规Java集合不同。首先，它们是不可变的，这意味着一旦创建它们就无法添加或删除元素。你也不能简单地检查里面的元素</p><p>集合最初通过在弗林克程序添加源创建和新的集合从这些通过将它们使用API方法如衍生map，filter等等</p><p>Flink程序看起来像是转换数据集合的常规程序。每个程序包含相同的基本部分：<br>1）获取execution environment,<br>final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</p><p>2）加载/创建初始化数据<br>DataStream<code>&lt;String&gt;</code> text = env.readTextFile(“file:///path/to/file”);</p><p>3）指定此数据的转换<br>val mapped = input.map { x =&gt; x.toInt }</p><p>4）指定放置计算结果的位置<br>writeAsText(String path)<br>print()</p><p>5）触发程序执行<br>在local模式下执行程序<br>execute()<br>将程序达成jar运行在线上<br>./bin/flink run <br>-m hsiehchou121:8081 <br>./examples/batch/WordCount.jar <br>–input  hdfs:///user/root/input/wc.txt <br>–output  hdfs:///user/root/output2  \</p><p>####3、WordCount案例</p><p>1）<strong>Scala代码</strong></p><pre><code class="highlight plaintext">import org.apache.flink.api.java.utils.ParameterToolimport org.apache.flink.streaming.api.scala.StreamExecutionEnvironmentimport org.apache.flink.streaming.api.windowing.time.Timeobject SocketWindowWordCountScala {  def main(args: Array[String]) : Unit = {    // 定义一个数据类型保存单词出现的次数    case class WordWithCount(word: String, count: Long)    // port 表示需要连接的端口    val port: Int = try {      ParameterTool.fromArgs(args).getInt("port")    } catch {      case e: Exception =&gt; {        System.err.println("No port specified. Please run 'SocketWindowWordCount --port &lt;port&gt;'")        return      }    }    // 获取运行环境    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment    // 连接此socket获取输入数据    val text = env.socketTextStream("hsiehchou121", port, '\n')    //需要加上这一行隐式转换 否则在调用flatmap方法的时候会报错    import org.apache.flink.api.scala._    // 解析数据, 分组, 窗口化, 并且聚合求SUM    val windowCounts = text      .flatMap { w =&gt; w.split("\\s") }      .map { w =&gt; WordWithCount(w, 1) }      .keyBy("word")      .timeWindow(Time.seconds(5), Time.seconds(1))      .sum("count")    // 打印输出并设置使用一个并行度    windowCounts.print().setParallelism(1)    env.execute("Socket Window WordCount")  }}</code></pre><p>2）<strong>Java代码</strong></p><pre><code class="highlight plaintext">import org.apache.flink.api.common.functions.FlatMapFunction;import org.apache.flink.api.java.utils.ParameterTool;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.datastream.DataStreamSource;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.api.windowing.time.Time;import org.apache.flink.util.Collector;public class WordCount {    //先在虚拟机上打开你的端口号 nc -l 9000    public static void main(String[] args) throws Exception {        //定义socket的端口号        int port;        try{            ParameterTool parameterTool = ParameterTool.fromArgs(args);            port = parameterTool.getInt("port");        }catch (Exception e){            System.err.println("没有指定port参数，使用默认值9000");            port = 9000;        }        //获取运行环境        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        //连接socket获取输入的数据        DataStreamSource&lt;String&gt; text = env.socketTextStream("192.168.1.52", port, "\n");        //计算数据        DataStream&lt;WordWithCount&gt; windowCount = text.flatMap(new FlatMapFunction&lt;String, WordWithCount&gt;() {            public void flatMap(String value, Collector&lt;WordWithCount&gt; out) throws Exception {                String[] splits = value.split("\\s");                for (String word:splits) {                    out.collect(new WordWithCount(word,1L));                }            }        })//打平操作，把每行的单词转为&lt;word,count&gt;类型的数据                .keyBy("word")//针对相同的word数据进行分组                .timeWindow(Time.seconds(2),Time.seconds(1))//指定计算数据的窗口大小和滑动窗口大小                .sum("count");        //把数据打印到控制台        windowCount.print()                .setParallelism(1);//使用一个并行度        //注意：因为flink是懒加载的，所以必须调用execute方法，上面的代码才会执行        env.execute("streaming word count");    }    /**     * 主要为了存储单词以及单词出现的次数     */    public static class WordWithCount{        public String word;        public long count;        public WordWithCount(){}        public WordWithCount(String word, long count) {            this.word = word;            this.count = count;        }        @Override        public String toString() {            return "WordWithCount{" +                    "word='" + word + '\'' +                    ", count=" + count +                    '}';        }    }}</code></pre><p>3）<strong>运行测试</strong></p><p>首先，使用nc命令启动一个本地监听，命令是：<br>[root@hsiehchou121 ~]$ nc -l 9000</p><p>通过netstat命令观察9000端口。 netstat -anlp | grep 9000，启动监听如果报错：-bash: nc: command not found，请先安装nc，在线安装命令：yum -y install nc。<br>然后，IDEA上运行flink官方案例程序<br>hsiehchou121上输入<br>[root@hsiehchou121 ~] nc -l 9000<br>learn flink<br>hadoop storm flink<br>flink flink hsiehchou</p><p>4）<strong>集群测试</strong></p><p>这里单机测试官方案例<br>[root@hsiehchou121 flink-1.6.1]$ pwd<br>/opt/flink-1.6.1</p><p>[root@hsiehchou121 flink-1.6.1]$ ./bin/start-cluster.sh<br>Starting cluster.<br>Starting standalonesession daemon on host hsiehchou121.<br>Starting taskexecutor daemon on host hsiehchou121.</p><p>[root@hsiehchou121 flink-1.6.1]$ jps<br>StandaloneSessionClusterEntrypoint<br>TaskManagerRunner<br>Jps</p><p>[root@hsiehchou121 flink-1.6.1]$ ./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000<br>单词在5秒的时间窗口（处理时间，翻滚窗口）中计算并打印到stdout。监视TaskManager的输出文件并写入一些文本nc（输入在点击后逐行发送到Flink）：</p><h4 id="4、使用IDEA开发离线程序">4、使用IDEA开发离线程序</h4><p>Dataset是flink的常用程序，数据集通过source进行初始化，例如读取文件或者序列化集合，然后通过transformation（filtering、mapping、joining、grouping）将数据集转成，然后通过sink进行存储，既可以写入hdfs这种分布式文件系统，也可以打印控制台，flink可以有很多种运行方式，如local、flink集群、yarn等.<br>1）<strong>scala程序</strong></p><pre><code class="highlight plaintext">import org.apache.flink.api.scala.ExecutionEnvironmentimport org.apache.flink.api.scala._object WordCountScala{  def main(args: Array[String]) {    //初始化环境    val env = ExecutionEnvironment.getExecutionEnvironment    //从字符串中加载数据    val text = env.fromElements(      "Who's there?",      "I think I hear them. Stand, ho! Who's there?")    //分割字符串、汇总tuple、按照key进行分组、统计分组后word个数    val counts = text.flatMap { _.toLowerCase.split("\\W+") filter { _.nonEmpty } }      .map { (_, 1) }      .groupBy(0)      .sum(1)    //打印    counts.print()  }}</code></pre><p>2） <strong>Java程序</strong></p><pre><code class="highlight plaintext">import org.apache.flink.api.common.functions.FlatMapFunction;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.tuple.Tuple2;import org.apache.flink.util.Collector;public class WordCountJava {    public static void main(String[] args) throws Exception {        //构建环境        final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();        //通过字符串构建数据集        DataSet&lt;String&gt; text = env.fromElements(                "Who's there?",                "I think I hear them. Stand, ho! Who's there?");        //分割字符串、按照key进行分组、统计相同的key个数        DataSet&lt;Tuple2&lt;String, Integer&gt;&gt; wordCounts = text                .flatMap(new LineSplitter())                .groupBy(0)                .sum(1);        //打印        wordCounts.print();    }    //分割字符串的方法    public static class LineSplitter implements FlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt; {        @Override        public void flatMap(String line, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) {            for (String word : line.split(" ")) {                out.collect(new Tuple2&lt;String, Integer&gt;(word, 1));            }        }    }}</code></pre><p>3）<strong>运行</strong></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink基础</title>
      <link href="/2019/05/16/flink_ji_chu/"/>
      <url>/2019/05/16/flink_ji_chu/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Flink概述">一、Flink概述</h3><p>官网：<a href="http://flink.apache.org/">http://flink.apache.org/</a><br>MapReduce-&gt;MaxCompute<br>HBase-&gt;部门<br>QuickBI<br>DataV<br>Hive-&gt;高德地图<br>Storm-&gt;JStorm</p><p>2019年1月 阿里正式开源Flink-&gt;Blink<br>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</p><p>大数据计算框架</p><h4 id="1、简介">1、简介</h4><p>Flink核心是一个流式的数据流执行引擎，其针对数据流的分布式计算提供了数据分布、数据通信以及容错机制等功能。基于流执行引擎，Flink提供了诸多更高抽象层的API以便用户编写分布式任务：</p><p>DataSet API，对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便地使用Flink提供的各种操作符对分布式数据集进行处理，支持Java、Scala和Python</p><p>DataStream API，对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持Java和Scala</p><p>Table API，对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类SQL的DSL对关系表进行各种查询操作，支持Java和Scala</p><p>此外，Flink还针对特定的应用领域提供了领域库，例如：<br>Flink ML，Flink的机器学习库，提供了机器学习Pipelines API并实现了多种机器学习算法<br>Gelly，Flink的图计算库，提供了图计算的相关API及多种图计算算法实现</p><h4 id="2、统一的批处理与流处理系统">2、统一的批处理与流处理系统</h4><p>在大数据处理领域，批处理任务与流处理任务一般被认为是两种不同的任务，一个大数据项目一般会被设计为只能处理其中一种任务，例如Apache Storm、Apache Smaza只支持流处理任务，而Aapche MapReduce、Apache Tez、Apache Spark只支持批处理任务。Spark Streaming是Apache Spark之上支持流处理任务的子系统，看似一个特例，实则不然——Spark Streaming采用了一种micro-batch的架构，即把输入的数据流切分成细粒度的batch，并为每一个batch数据提交一个批处理的Spark任务，所以Spark Streaming本质上还是基于Spark批处理系统对流式数据进行处理，和Apache Storm、Apache Smaza等完全流式的数据处理方式完全不同。通过其灵活的执行引擎，Flink能够同时支持批处理任务与流处理任务</p><p>在执行引擎这一层，流处理系统与批处理系统最大不同在于节点间的数据传输方式</p><p>对于一个流处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，然后立刻通过网络传输到下一个节点，由下一个节点继续处理</p><p>而对于一个批处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才开始将处理后的数据通过网络传输到下一个节点</p><p>这两种数据传输模式是两个极端，对应的是流处理系统对低延迟的要求和批处理系统对高吞吐量的要求。Flink的执行引擎采用了一种十分灵活的方式，同时支持了这两种数据传输模型。Flink以固定的缓存块为单位进行网络数据传输，用户可以通过缓存块超时值指定缓存块的传输时机。如果缓存块的超时值为0，则Flink的数据传输方式类似上文所提到流处理系统的标准模型，此时系统可以获得最低的处理延迟。如果缓存块的超时值为无限大，则Flink的数据传输方式类似上文所提到批处理系统的标准模型，此时系统可以获得最高的吞吐量</p><p>同时缓存块的超时值也可以设置为0到无限大之间的任意值</p><p>缓存块的超时阈值越小，则Flink流处理执行引擎的数据处理延迟越低，但吞吐量也会降低，<br>反之亦然。通过调整缓存块的超时阈值，用户可根据需求灵活地权衡系统延迟和吞吐量</p><h4 id="3、架构">3、架构</h4><p>要了解一个系统，一般都是从架构开始。我们关心的问题是：系统部署成功后各个节点都启动了哪些服务，各个服务之间又是怎么交互和协调的。下方是 Flink 集群启动后架构图</p><p><img src="/medias/Flink%20%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E5%90%8E%E6%9E%B6%E6%9E%84%E5%9B%BE.PNG" alt="Flink 集群启动后架构图"></p><p>当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的 TaskManager。由 Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程</p><p>Client 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager 环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming的任务），也可以不结束并等待结果返回</p><p>JobManager 主要负责调度 Job 并协调 Task 做 checkpoint，职责上很像 Storm 的 Nimbus。从 Client 处接收到 Job 和 JAR 包等资源后，会生成优化后的执行计划，并以 Task 的单元调度到各个 TaskManager 去执行</p><p>TaskManager 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动一个 Task，Task 为线程。从 JobManager 处接收需要部署的 Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理</p><p>可以看到 Flink 的任务调度是多线程模型，并且不同Job/Task混合在一个 TaskManager 进程中。虽然这种方式可以有效提高 CPU 利用率，但是个人不太喜欢这种设计，因为不仅缺乏资源隔离机制，同时也不方便调试。类似 Storm 的进程模型，一个JVM 中只跑该 Job 的 Tasks 实际应用中更为合理</p><p>Flink编程模型</p><p><img src="/medias/Flink%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.PNG" alt="Flink编程模型"></p><h3 id="二、Flink特点">二、Flink特点</h3><p>1）mapreduce<br>2）storm<br>3）spark</p><p>适用于所有企业，不同企业有不同的业务场景。处理数据量，模型都不一样</p><p><strong>Flink</strong></p><h4 id="1、随处部署应用">1、随处部署应用</h4><p>与其它组件集成！<br>flink是分布式系统，需要计算资源才可执行程序。flink可以与常见的集群资源管理器进行集成(H<br>adoop Yarn,Apache Mesos…)</p><p>可以单独作为独立集群运行</p><p>通过不同部署模式实现</p><p>这些模式允许flink以其惯有的方式进行交互</p><p>当我们部署flink应用程序时，Flink会根据应用程序配置的并行性自动识别所需资源。从资源管理<br>器中请求它们</p><p>如果发生故障，flink会请求新的资源来替换发生故障的容器</p><p>提交或控制程序都通过REST调用进行，简化Flink在许多环境的集成。孵化…</p><h4 id="2、以任何比例应用程序（小集群、无限集群）">2、以任何比例应用程序（小集群、无限集群）</h4><p>Flink旨在以任何规模运行有状态流应用程序。应用程序可以并行化在集群中分布和同时执行程<br>序</p><p>因此，我们的应用集群可以利用无限的cpu和磁盘与网络IO</p><p>Flink可以轻松的维护非常大的应用程序状态<br>用户可拓展性报告：</p><ul><li>应用程序每天可以处理万亿个事件</li><li>应用程序每天可以维护多个TB的状态</li><li>应用程序可以在数千个内核运行</li></ul><h4 id="3、利用内存中的性能">3、利用内存中的性能</h4><p>有状态Flink应用程序针对于对本地状态访问进行了优化。任务状态始终的保留在内存中，或者如果<br>大小超过了可用内存，则保存在访问高效的磁盘数据结构中(SSD 机械/固态)</p><p>任务可以通过访问本地来执行所有计算。从来产生极小的延迟</p><p>Flink定期和异步检查本地状态持久存储来保持出现故障时一次状态的一致性</p><h3 id="三、有界无界">三、有界无界</h3><h4 id="1、无界">1、无界</h4><p>有开始，没有结束…<br>处理实时数据</p><h4 id="2、有界">2、有界</h4><p>有开始，有结束…<br>处理批量数据</p><h3 id="四、无界数据集应用场景（实时计算）">四、无界数据集应用场景（实时计算）</h3><p>1）源源不断的日志数据<br>2）web应用，指标分析<br>3）移动设备终端(分析app状况)<br>4）应用在任何数据源不断产生的项目中</p><h3 id="五、Flink运行模型">五、Flink运行模型</h3><p>1）<strong>流计算</strong><br>数据源源不断产生，我们的需求是源源不断的处理</p><p>程序需要一直保持在计算的状态</p><p>2）<strong>批处理</strong><br>计算一段完整的数据集，计算成功后释放资源，那么此时工作结束</p><h3 id="六、Flink的使用">六、Flink的使用</h3><h4 id="1、处理结果准确">1、处理结果准确</h4><p>无论是有序数据还是延迟到达的数据</p><h4 id="2、容错机制">2、容错机制</h4><p>有状态：保持每次的结果往下传递，实现累加。DAG（有向无环图）</p><h4 id="3、有很强大的吞吐量和低延迟">3、有很强大的吞吐量和低延迟</h4><p>计算速度快，吞吐量处理的量级大</p><h4 id="4、精准的维护一次的应用状态">4、精准的维护一次的应用状态</h4><p>storm:会发生要么多计算一次，要么漏计算</p><h4 id="5、支持大规模的计算">5、支持大规模的计算</h4><p>可以运行在数千台节点上</p><h4 id="6、支持流处理和窗口化操作">6、支持流处理和窗口化操作</h4><h4 id="7、版本化处理">7、版本化处理</h4><h4 id="8、检查点机制实现精准的一次性计算保证">8、检查点机制实现精准的一次性计算保证</h4><p>checkpoint</p><h4 id="9、支持yarn与mesos资源管理器">9、支持yarn与mesos资源管理器</h4><h3 id="七、flink单节点安装部署">七、flink单节点安装部署</h3><p>1）下载安装包<br>2）上传<br>3）解压<br>tar -zxvf .tar<br>4）启动<br>bin/start-cluster.sh<br>5）访问ui界面<br><a href="http://192.168.116.201:8081">http://192.168.116.201:8081</a></p><h3 id="八、搭建Flink1-6-1分布式集群">八、搭建Flink1.6.1分布式集群</h3><h4 id="1、Flink的下载">1、Flink的下载</h4><p>安装包下载地址：<a href="http://flink.apache.org/downloads.html">http://flink.apache.org/downloads.html</a>  ，选择对应Hadoop的Flink版本下载<br>[root@hsiehchou121 software]$ wget <a href="http://mirrors.tuna.tsinghua.edu.cn/apache/flink/flink-1.6.1/flink-1.6.1-bin-hadoop28-scala_2.11.tgz">http://mirrors.tuna.tsinghua.edu.cn/apache/flink/flink-1.6.1/flink-1.6.1-bin-hadoop28-scala_2.11.tgz</a><br>[root@hsiehchou121 software]$ ll<br>-rw-rw-r-- 1 root root 301867081 Sep 15 15:47 flink-1.6.1-bin-hadoop28-scala_2.11.tgz<br>Flink 有三种部署模式，分别是 Local、Standalone Cluster 和 Yarn Cluster</p><h4 id="2、Local模式">2、Local模式</h4><p>对于 Local 模式来说，JobManager 和 TaskManager 会公用一个 JVM 来完成 Workload</p><p>如果要验证一个简单的应用，Local 模式是最方便的。实际应用中大多使用 Standalone 或者 Yarn Cluster，而local模式只是将安装包解压启动（./bin/start-cluster.sh）即可，在这里不在演示</p><h4 id="3、Standalone-模式">3、Standalone 模式</h4><p>快速入门教程地址：<br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.6/quickstart/setup_quickstart.html">https://ci.apache.org/projects/flink/flink-docs-release-1.6/quickstart/setup_quickstart.html</a></p><p>1）  <strong>软件要求</strong><br>•Java 1.8.x或更高版本<br>•ssh（必须运行sshd才能使用管理远程组件的Flink脚本）</p><p><strong>集群部署规划</strong></p><table><thead><tr><th style="text-align:center">节点名称</th><th style="text-align:center">master</th><th style="text-align:center">worker</th><th style="text-align:center">zookeeper</th></tr></thead><tbody><tr><td style="text-align:center">hsiehchou121</td><td style="text-align:center">master</td><td style="text-align:center"></td><td style="text-align:center">zookeeper</td></tr><tr><td style="text-align:center">hsiehchou122</td><td style="text-align:center">master</td><td style="text-align:center">worker</td><td style="text-align:center">zookeeper</td></tr><tr><td style="text-align:center">hsiehchou123</td><td style="text-align:center"></td><td style="text-align:center">worker</td><td style="text-align:center">zookeeper</td></tr></tbody></table><p>2）<strong>解压</strong></p><p>[root@hsiehchou121 software]$ <code>tar -zxvf flink-1.6.1-bin-hadoop27-scala_2.11.tgz -C /opt/module/</code><br>[root@hsiehchou121 software]$ cd /opt/module/</p><p>[root@hsiehchou121 module]$ ll<br>drwxr-xr-x 8 root root 125 Sep 15 04:47 flink-1.6.1</p><p>3）<strong>修改配置文件</strong></p><p>[root@hsiehchou121 conf]$ ls<br>flink-conf.yaml       log4j-console.properties  log4j-yarn-session.properties  logback.xml       masters  sql-client-defaults.yaml<br>log4j-cli.properties  log4j.properties          logback-console.xml            logback-yarn.xml  slaves   zoo.cfg</p><p>修改flink/conf/masters，slaves，flink-conf.yaml</p><p>[root@hsiehchou121 conf]$ sudo vi masters<br>hsiehchou121:8081</p><p>[root@hsiehchou121 conf]$ sudo vi slaves<br>hsiehchou122<br>hsiehchou123</p><p>[root@hsiehchou121 conf]$ sudo vi flink-conf.yaml<br>taskmanager.numberOfTaskSlots：2   //52行 和storm slot类似<br>jobmanager.rpc.address: hsiehchou121  //33行</p><p>可选配置：<br>•每个JobManager（jobmanager.heap.mb）的可用内存量<br>•每个TaskManager（taskmanager.heap.mb）的可用内存量<br>•每台机器的可用CPU数量（taskmanager.numberOfTaskSlots）<br>•集群中的CPU总数（parallelism.default）和<br>•临时目录（taskmanager.tmp.dirs）</p><p>4）<strong>拷贝安装包到各节点</strong></p><p>[root@hsiehchou121 module]$ scp -r flink-1.6.1/ root@hsiehchou122:<code>pwd</code><br>[root@hsiehchou121 module]$ scp -r flink-1.6.1/ root@hsiehchou123:<code>pwd</code></p><p>5） <strong>配置环境变量</strong></p><p>配置所有节点Flink的环境变量<br>[root@hsiehchou121 flink-1.6.1]$ sudo vi /etc/profile<br>export FLINK_HOME=/opt/module/flink-1.6.1<br>export PATH=<code>$PATH:$</code>FLINK_HOME/bin</p><p>[root@hsiehchou121 flink-1.6.1]$ source /etc/profile</p><p>6）<strong>启动Flink</strong></p><p>[root@hsiehchou121 flink-1.6.1]$ ./bin/start-cluster.sh<br>Starting cluster.<br>Starting standalonesession daemon on host hsiehchou121.<br>Starting taskexecutor daemon on host hsiehchou122.<br>Starting taskexecutor daemon on host hsiehchou123.</p><p>jps查看进程<br>hsiehchou121<br>2122 StandaloneSessionClusterEntrypoint<br>2172 Jps</p><p>hsiehchou122<br>1616 TaskManagerRunner<br>1658 Jps</p><p>hsiehchou123<br>1587 TaskManagerRunner<br>1627 Jps</p><p>7） <strong>WebUI查看</strong></p><p><a href="http://hsiehchou121:8081">http://hsiehchou121:8081</a></p><p>8）<strong>Flink的HA</strong></p><p>首先，我们需要知道 Flink 有两种部署的模式，分别是 Standalone 以及 Yarn Cluster 模式。对于 Standalone 来说，Flink 必须依赖于 Zookeeper 来实现 JobManager 的 HA（Zookeeper 已经成为了大部分开源框架 HA 必不可少的模块）。在 Zookeeper 的帮助下，一个 Standalone 的 Flink 集群会同时有多个活着的 JobManager，其中只有一个处于工作状态，其他处于 Standby 状态。当工作中的 JobManager 失去连接后（如宕机或 Crash），Zookeeper 会从 Standby 中选举新的 JobManager 来接管 Flink 集群</p><p>对于 Yarn Cluaster 模式来说，Flink 就要依靠 Yarn 本身来对 JobManager 做 HA 了。其实这里完全是 Yarn 的机制。对于 Yarn Cluster 模式来说，JobManager 和 TaskManager 都是被 Yarn 启动在 Yarn 的 Container 中。此时的 JobManager，其实应该称之为 Flink Application Master。也就说它的故障恢复，就完全依靠着 Yarn 中的 ResourceManager（和 MapReduce 的 AppMaster 一样）。由于完全依赖了 Yarn，因此不同版本的 Yarn 可能会有细微的差异。这里不再做深究</p><p>（1） <strong>修改配置文件</strong></p><p>修改flink-conf.yaml，HA模式下，jobmanager不需要指定，在master file中配置，由zookeeper选出leader与standby。<br><strong>jobmanager.rpc.address: hsiehchou121</strong><br>high-availability:zookeeper   //73行</p><p><strong>指定高可用模式（必须） //88行</strong><br>high-availability.zookeeper.quorum:hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181</p><p><strong>ZooKeeper仲裁是ZooKeeper服务器的复制组，它提供分布式协调服务（必须） //82行</strong><br>high-availability.storageDir:hdfs:///flink/ha/</p><p><strong>JobManager元数据保存在文件系统storageDir中，只有指向此状态的指针存储在ZooKeeper中（必须） //没有</strong><br>high-availability.zookeeper.path.root:/flink</p><p><strong>根ZooKeeper节点，在该节点下放置所有集群节点（推荐） //没有</strong><br>high-availability.cluster-id:/flinkCluster</p><p><strong>&amp;&amp;&amp;&amp;&amp;自定义集群（推荐）</strong><br>state.backend: filesystem<br>state.checkpoints.dir: hdfs:///flink/checkpoints<br>state.savepoints.dir: hdfs:///flink/checkpoints</p><p><strong>修改conf/zoo.cfg</strong><br>server.1=hsiehchou121:2888:3888<br>server.2=hsiehchou122:2888:3888<br>server.3=hsiehchou123:2888:3888</p><p><strong>修改conf/masters</strong><br>hsiehchou121:8081<br>hsiehchou122:8081</p><p><strong>修改slaves</strong><br>hsiehchou122<br>hsiehchou123<br>同步配置文件conf到各节点</p><p>（2） <strong>启动HA</strong></p><p>先启动zookeeper集群各节点（<a href="http://xn--Flinkstart-zookeeper-quorum-9r86bp2b44ht37cqv4a242b6u9g9zzb6clcimch3i22xd.sh">测试环境中也可以用Flink自带的start-zookeeper-quorum.sh</a>），启动dfs ,再启动flink<br>[root@hsiehchou121 flink-1.6.1]$ <a href="http://start-cluster.sh">start-cluster.sh</a></p><p>WebUI查看，这是会自动产生一个主Master，如下</p><p>（3） <strong>验证HA</strong></p><p>手动杀死hsiehchou122上的master，此时，hsiehchou121上的备用master转为主mater</p><p>（4）<strong>手动将JobManager / TaskManager实例添加到群集</strong></p><p>您可以使用bin/jobmanager.sh和bin/taskmanager.sh脚本将JobManager和TaskManager实例添加到正在运行的集群中</p><p>添加JobManager<br>bin/jobmanager.sh ((start|start-foreground) <code>[host] [webui-port]</code>)|stop|stop-all</p><p>添加TaskManager<br>bin/taskmanager.sh start|start-foreground|stop|stop-all</p><p>[root@hsiehchou122 flink-1.6.1]$ <a href="http://jobmanager.sh">jobmanager.sh</a> start hsiehchou122<br>新添加的为从master</p><p>9）<strong>运行测试任务</strong></p><p>[root@hsiehchou121 flink-1.6.1]$ flink run -m hsiehchou121:8081 ./examples/batch/WordCount.jar --input /opt/wcinput/wc.txt --output /opt/wcoutput/</p><p>[root@hsiehchou121 flink-1.6.1]$ bin/flink run -m hsiehchou121:8081 ./examples/batch/WordCount.jar --input hdfs:///emp.csv --output hdfs:///user/root/output2</p><h4 id="4、Yarn-Cluster模式">4、Yarn Cluster模式</h4><p>1）<strong>引入</strong><br>在一个企业中，为了最大化的利用集群资源，一般都会在一个集群中同时运行多种类型的 Workload。因此 Flink 也支持在 Yarn 上面运行。首先，让我们了解下 Yarn 和 Flink 的关系</p><p><img src="/medias/Yarn%20%E5%92%8C%20Flink%20%E7%9A%84%E5%85%B3%E7%B3%BB.PNG" alt="Yarn 和 Flink 的关系"></p><p>在图中可以看出，Flink 与 Yarn 的关系与 MapReduce 和 Yarn 的关系是一样的。Flink 通过 Yarn 的接口实现了自己的 App Master。当在 Yarn 中部署了 Flink，Yarn 就会用自己的 Container 来启动 Flink 的 JobManager（也就是 App Master）和 TaskManager</p><p>启动新的Flink YARN会话时，客户端首先检查所请求的资源（容器和内存）是否可用。之后，它将包含Flink和配置的jar上传到HDFS（步骤1）</p><p>客户端的下一步是请求（步骤2）YARN容器以启动ApplicationMaster（步骤3）。由于客户端将配置和jar文件注册为容器的资源，因此在该特定机器上运行的YARN的NodeManager将负责准备容器（例如，下载文件）。完成后，将启动ApplicationMaster（AM）</p><p>该JobManager和AM在同一容器中运行。一旦它们成功启动，AM就知道JobManager（它自己的主机）的地址。它正在为TaskManagers生成一个新的Flink配置文件（以便它们可以连接到JobManager）。该文件也上传到HDFS。此外，AM容器还提供Flink的Web界面。YARN代码分配的所有端口都是临时端口。这允许用户并行执行多个Flink YARN会话</p><p>之后，AM开始为Flink的TaskManagers分配容器，这将从HDFS下载jar文件和修改后的配置。完成这些步骤后，即可建立Flink并准备接受作业</p><p>2）<strong>修改环境变量</strong></p><p>export  HADOOP_CONF_DIR= /opt/module/hadoop-2.8.4/etc/hadoop</p><p>3）<strong>部署启动</strong></p><p>[root@hsiehchou121 flink-1.6.1]$ <a href="http://yarn-session.sh">yarn-session.sh</a> -d -s 1 -tm 800 -n 2<br>-n : TaskManager的数量，相当于executor的数量</p><p>-s : 每个JobManager的core的数量，executor-cores。建议将slot的数量设置每台机器的处理器数量</p><p>-tm : 每个TaskManager的内存大小，executor-memory</p><p>-jm : JobManager的内存大小，driver-memory</p><p>上面的命令的意思是，同时向Yarn申请3个container，其中 2 个 Container 启动 TaskManager（-n 2），每个 TaskManager 拥有两个 Task Slot（-s 2），并且向每个 TaskManager 的 Container 申请 800M 的内存，以及一个ApplicationMaster（Job Manager）</p><p>Flink部署到Yarn Cluster后，会显示Job Manager的连接细节信息<br>Flink on Yarn会覆盖下面几个参数，如果不希望改变配置文件中的参数，可以动态的通过-D选项指定，如<br>-Dfs.overwrite-files=true -Dtaskmanager.network.numberOfBuffers=16368</p><p>jobmanager.rpc.address：因为JobManager会经常分配到不同的机器上</p><p>taskmanager.tmp.dirs：使用Yarn提供的tmp目录</p><p>parallelism.default：如果有指定slot个数的情况下</p><p>yarn-session.sh会挂起进程，所以可以通过在终端使用CTRL+C或输入stop停止yarn-session</p><p>如果不希望Flink Yarn client长期运行，Flink提供了一种detached YARN session，启动时候加上参数-d或—detached</p><p>在上面的命令成功后，我们就可以在 Yarn Application 页面看到 Flink 的纪录</p><p>如果在虚拟机中测试，可能会遇到错误。这里需要注意内存的大小，Flink 向 Yarn 会申请多个 Container，但是 Yarn 的配置可能限制了 Container 所能申请的内存大小，甚至 Yarn 本身所管理的内存就很小。这样很可能无法正常启动 TaskManager，尤其当指定多个 TaskManager 的时候。因此，在启动 Flink 之后，需要去 Flink 的页面中检查下 Flink 的状态。这里可以从 RM 的页面中，直接跳转（点击 Tracking UI）</p><p>yarn-session.sh启动命令参数如下：</p><p>[root@hsiehchou121 flink-1.6.1]$ <a href="http://yarn-session.sh">yarn-session.sh</a> --help<br>Usage:<br>Required<br>-n,–container <code>&lt;arg&gt;</code>   Number of YARN container to allocate (=Number of Task Managers)<br>Optional<br>-D &lt;property=value&gt;             use value for given property<br>-d,–detached                   If present, runs the job in detached mode<br>-h,–help                       Help for the Yarn session CLI.<br>-id,–applicationId <code>&lt;arg&gt;</code>       Attach to running YARN session<br>-j,–jar <code>&lt;arg&gt;</code>                  Path to Flink jar file<br>-jm,–jobManagerMemory <code>&lt;arg&gt;</code>    Memory for JobManager Container with optional unit (default: MB)<br>-m,–jobmanager <code>&lt;arg&gt;</code>           Address of the JobManager (master) to which to connect. Use this flag to connect to a different JobManager than the one specified i<br>n the configuration.     -n,–container <code>&lt;arg&gt;</code>            Number of YARN container to allocate (=Number of Task Managers)<br>-nl,–nodeLabel <code>&lt;arg&gt;</code>           Specify YARN node label for the YARN application<br>-nm,–name <code>&lt;arg&gt;</code>                Set a custom name for the application on YARN<br>-q,–query                      Display available YARN resources (memory, cores)<br>-qu,–queue <code>&lt;arg&gt;</code>               Specify YARN queue.<br>-s,–slots <code>&lt;arg&gt;</code>                Number of slots per TaskManager<br>-st,–streaming                 Start Flink in streaming mode<br>-t,–ship <code>&lt;arg&gt;</code>                 Ship files in the specified directory (t for transfer)<br>-tm,–taskManagerMemory <code>&lt;arg&gt;</code>   Memory per TaskManager Container with optional unit (default: MB)<br>-yd,–yarndetached              If present, runs the job in detached mode (deprecated; use non-YARN specific option instead)<br>-z,–zookeeperNamespace <code> </code>   Namespace to create the Zookeeper sub-paths for high availability mode</p><p>4）<strong>提交任务</strong></p><p>之后，我们可以通过这种方式提交我们的任务<br>[root@hsiehchou121 flink-1.6.1]$ ./bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar --input /opt/wcinput/wc.txt --output /opt/wcoutput/<br>bin/flink run -m yarn-cluster -yn2 examples/batch/WordCount.jar --input /input/ --output /XZ</p><p>以上命令在参数前加上y前缀，-yn表示TaskManager个数</p><p>在这个模式下，同样可以使用-m yarn-cluster提交一个"运行后即焚"的detached yarn（-yd）作业到yarn cluster</p><p>5）<strong>停止yarn cluster</strong></p><p>yarn application -kill application_1539058959130_0001</p><p>6） <strong>Yarn模式的HA</strong></p><p>应用最大尝试次数（<strong>yarn-site.xml</strong>），您必须配置为尝试应用的最大数量的设置yarn-site.xml，当前YARN版本的默认值为2（表示允许单个JobManager失败）<br><code>&lt;property&gt;</code><br><code>  &lt;name&gt;</code>yarn.resourcemanager.am.max-attempts<code>&lt;/name&gt;</code><br><code>&lt;value&gt;</code>4<code>&lt;/value&gt;</code><br><code> &lt;description&gt;</code>The maximum number of application master execution attempts<code>&lt;/description&gt;</code><br><code>&lt;/property&gt;</code></p><p>申请尝试（<strong>flink-conf.yaml</strong>），您还必须配置最大尝试次数conf/flink-conf.yaml： yarn.application-attempts：10</p><p>示例：<strong>高度可用的YARN会话</strong><br>配置HA模式和zookeeper法定人数在conf/flink-conf.yaml：<br>high-availability: zookeeper<br>high-availability.zookeeper.quorum: hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181<br>high-availability.storageDir: hdfs:///flink/recovery<br>high-availability.zookeeper.path.root: /flink<br>yarn.application-attempts: 10</p><p>配置ZooKeeper的服务器中conf/zoo.cfg（目前它只是可以运行每台机器的单一的ZooKeeper服务器）：<br>server.1=hsiehchou121:2888:3888<br>server.2=hsiehchou122:2888:3888<br>server.3=hsiehchou123:2888:3888</p><p><strong>启动ZooKeeper仲裁</strong>：<br>$ bin / <a href="http://start-zookeeper-quorum.sh">start-zookeeper-quorum.sh</a></p><p><strong>启动HA群集</strong>：<br>$ bin / <a href="http://yarn-session.sh">yarn-session.sh</a> -n 2</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storm练习</title>
      <link href="/2019/05/14/storm_lian_xi/"/>
      <url>/2019/05/14/storm_lian_xi/</url>
      
        <content type="html"><![CDATA[<p><strong>Storm练习</strong></p><h3 id="一、需求">一、需求</h3><p>需求：统计网站访问量(实时统计)</p><p>技术选型：特点（数据量大、做计算、实时）</p><p>实时计算框架：storm<br>1）spout<br>数据源，接入数据<br>本地文件</p><p>2）bolt<br>业务逻辑处理<br>切分数据<br>查到网址</p><p>3）bolt<br>累加次数求和</p><h3 id="二、代码编写">二、代码编写</h3><ol><li>PvCountSpout.java</li></ol><pre><code class="highlight plaintext">package com.hsiehchou.pvcount;import java.io.BufferedReader;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.IOException;import java.io.InputStreamReader;import java.util.Map;import org.apache.storm.spout.SpoutOutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.IRichSpout;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Values;public class PvCountSpout implements IRichSpout {private SpoutOutputCollector collector;private BufferedReader br;private String line;@Overridepublic void nextTuple() {//发送读取数据的每一行try {while((line = br.readLine()) != null) {//发送数据到splitboltcollector.emit(new Values(line));//设置延迟Thread.sleep(500);}} catch (IOException | InterruptedException e) {e.printStackTrace();}}@Overridepublic void open(Map arg0, TopologyContext arg1, SpoutOutputCollector collector) {this.collector = collector;//读取文件try {br = new BufferedReader(new InputStreamReader(new FileInputStream("e:/weblog.log")));} catch (FileNotFoundException e) {e.printStackTrace();}}@Overridepublic void declareOutputFields(OutputFieldsDeclarer declarer) {//声明declarer.declare(new Fields("logs"));}//处理Tuple成功 回调的方法@Overridepublic void ack(Object arg0) {}//如果spout在失效的模式中，调用此方法来激活@Overridepublic void activate() {}//在spout程序关闭前执行，不能保证一定执行，kill -9是不执行  storm kill是不执行@Overridepublic void close() {}//在spout失效期间，nextTuple不会被调用@Overridepublic void deactivate() {}//处理Tuple失败回调的方法@Overridepublic void fail(Object arg0) {}//配置@Overridepublic Map&lt;String, Object&gt; getComponentConfiguration() {return null;}}</code></pre><ol start="2"><li>PvCountSplitBolt.java</li></ol><pre><code class="highlight plaintext">package com.hsiehchou.pvcount;import java.util.Map;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.IRichBolt;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Tuple;import org.apache.storm.tuple.Values;public class PvCountSplitBolt implements IRichBolt {private OutputCollector collector;private int pvnum = 0;//一个bolt即将关闭时调用，不能保证一定会被调用@Overridepublic void cleanup() {}//业务逻辑-分布式-集群-并发度-线程（接收Tuple然后进行处理）资源清理@Overridepublic void execute(Tuple input) {//1.获取数据String line = input.getStringByField("logs");//2.切分数据String[] fields = line.split("\t");String session_id = fields[1];//3.局部累加if(session_id != null) {//列累加pvnum++;//输出collector.emit(new Values(Thread.currentThread().getId(),pvnum));}}//初始化时调用@Overridepublic void prepare(Map arg0, TopologyContext arg1, OutputCollector collector) {this.collector = collector;}//声明@Overridepublic void declareOutputFields(OutputFieldsDeclarer declarer) {//声明输出字段declarer.declare(new Fields("threadid","pvnum"));}//配置@Overridepublic Map&lt;String, Object&gt; getComponentConfiguration() {return null;}}</code></pre><ol start="3"><li>PvCountBolt.java</li></ol><pre><code class="highlight plaintext">package com.hsiehchou.pvcount;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.IRichBolt;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.tuple.Tuple;public class PvCountBolt implements IRichBolt {private HashMap&lt;Long, Integer&gt; hashmap = new HashMap&lt;&gt;();@Overridepublic void cleanup() {}//全局累加求和 业务逻辑@Overridepublic void execute(Tuple input) {//1.获取数据Long threadid = input.getLongByField("threadid");Integer pvnum = input.getIntegerByField("pvnum");//2.创建集合 存储(threadid,pvnum)hashmap.put(threadid,pvnum);//3.累加求和Iterator&lt;Integer&gt; iterator = hashmap.values().iterator();//4.清空之前的数据int sumnum = 0;while(iterator.hasNext()) {sumnum += iterator.next();}System.out.println(Thread.currentThread().getName() + "总访问量为：" + sumnum);}@Overridepublic void prepare(Map arg0, TopologyContext arg1, OutputCollector arg2) {}@Overridepublic void declareOutputFields(OutputFieldsDeclarer arg0) {}@Overridepublic Map&lt;String, Object&gt; getComponentConfiguration() {return null;}}</code></pre><ol start="4"><li>PvCountDriver.java</li></ol><pre><code class="highlight plaintext">package com.hsiehchou.pvcount;import org.apache.storm.Config;import org.apache.storm.LocalCluster;import org.apache.storm.topology.TopologyBuilder;import org.apache.storm.tuple.Fields;public class PvCountDriver {public static void main(String[] args) {//1.hadoop --&gt; Job Storm --&gt; Topology 创建拓扑TopologyBuilder builder = new TopologyBuilder();builder.setSpout("PvCountSpout", new PvCountSpout(), 1);//builder.setBolt("PvCountSplitBolt", new PvCountSplitBolt(), 6).setNumTasks(4).shuffleGrouping("PvCountSpout");builder.setBolt("PvCountSplitBolt", new PvCountSplitBolt(), 6).setNumTasks(4).fieldsGrouping("PvCountSpout", new Fields("logs"));//builder.setBolt("PvCountSumBolt", new PvCountBolt(), 1).shuffleGrouping("PvCountSplitBolt");builder.setBolt("PvCountSumBolt", new PvCountBolt(), 1).fieldsGrouping("PvCountSplitBolt", new Fields("pvnum"));Config conf = new Config();conf.setNumWorkers(1);LocalCluster localCluster = new LocalCluster();localCluster.submitTopology("pvcountsum", conf, builder.createTopology());}}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storm集群和集成</title>
      <link href="/2019/05/12/storm_ji_qun_he_ji_cheng/"/>
      <url>/2019/05/12/storm_ji_qun_he_ji_cheng/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Storm集群任务提交流程">一、Storm集群任务提交流程</h3><p><img src="/medias/Storm%E9%9B%86%E7%BE%A4%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B.PNG" alt="Storm集群任务提交流程"></p><h3 id="二、Storm内部通信机制">二、Storm内部通信机制</h3><p><img src="/medias/Worker%E8%BF%9B%E7%A8%8B1.PNG" alt="Worker进程"></p><p><img src="/medias/Worker.PNG" alt="Worker"></p><h3 id="三、集成Storm">三、集成Storm</h3><h4 id="1、与JDBC集成">1、与JDBC集成</h4><ul><li><p>将Storm Bolt处理的结果插入MySQL数据库中</p></li><li><p>需要依赖的jar包<br><code>$STORM_HOME</code>\external\sql\storm-sql-core*.jar<br><code>$STORM_HOME</code>\external\storm-jdbc\storm-jdbc-1.0.3.jar<br>mysql的驱动<br>commons-lang3-3.1.jar</p></li><li><p>与JDBC集成的代码实现<br>修改主程序WordCountTopology，增加如下代码：</p></li></ul><pre><code class="highlight plaintext">//创建一个JDBCBolt将结果插入数据库中builder.setBolt("wordcount_jdbcBolt", createJDBCBolt()).shuffleGrouping("wordcount_count");</code></pre><p>增加一个新方法创建JDBCBolt组件</p><pre><code class="highlight plaintext">//创建JDBC Insert Bolt组件//需要事先在MySQL数据库中创建对应的表，resultprivate static IRichBolt createJDBCBolt(){ConnectionProvider connectionProvider = new MyConnectionProvider();JdbcMapper simpleJdbcMapper = new SimpleJdbcMapper("aaa", connectionProvider);return new JdbcInsertBolt(connectionProvider, simpleJdbcMapper).withTableName("result").withQueryTimeoutSecs(30);}</code></pre><p>实现ConnectionProvider接口</p><pre><code class="highlight plaintext">class MyConnectionProvider implements ConnectionProvider{private static String driver = "com.mysql.cj.jdbc.Driver";private static String url = "jdbc:mysql://192.168.116.121:3306/demo";private static String user = "root";private static String password = "password";//静态块static{//注册驱动try{Class.forName(driver);}catch(ClassNotFoundException e){throw new ExceptionInInitializerError(e);}}@Overridepublic Connection getConnection(){try{return DriverManager.getConnection(url, user, password);}catch{e.printStackTrace();}return null;}public void cleanup(){}public void prepare(){}}</code></pre><p>修改WordCountSplitBolt组件，将统计后的结果发送给下一个组件写入MySQL</p><pre><code class="highlight plaintext">public class WordCountSplitBolt extends BaseRichBolt {private Map&lt;String, Integer&gt; result = new HashMap&lt;String, Integer&gt;();private OutputCollector collector;@Overridepublic void execute(Tuple tuple){String word = tuple.getStringByField("word");int count = tuple.getIntegerByField("count");if(result.containsKey(word)) {int total = result.get(word);result.put(word, total+count);}else{result.put(word, 1);}//直接输出到屏幕//System.out.println("输出的结果是：" + result);//将统计结果发送下一个Bolt，插入数据this.collector.emit(new Values*(word, result.get(word));}@Overridepublic void prepare(Map arg0, TopologyContext arg1, OutputCollector collector) {this.collector = collector;}@Overridepublic void declareOutputFields(OutputFieldsDecler declare){declare.declarer(new Fields("word", "sum"));}}</code></pre><h4 id="2、与Redis集成">2、与Redis集成</h4><p>Redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。与Memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步</p><p>Redis 是一个高性能的key-value数据库。Redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Java，C/C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。</p><p>Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器</p><p>修改代码：WordCountTopology.java</p><pre><code class="highlight plaintext">builder.setBolt("wordcount_redisBolt", createRedisBolt()).shuffleGrouping("wordcount_count");//创建Redis Bolt 组件private staticIRichBolt createRedisBolt(){JedisPoolConfig.Builder builder = new JedisPoolConfig.Builder();builder.setHost("192.168.116.121");builder.setPort(6379);JedisPoolConfig poolConfig = builder.build();//RedisStoreMapper用于指定存入Redis中的数据格式return new RedisStoreBolt(poolConfig, new RedisStoreMapper(){@Overridepublic RedisDateTypeDescription getDataTypeDescription(){return new RedisDateTypeDescription(RedisDateTypeDescription.RedisDateType.HASH, "wordCount");}@Overridepublic String getValueFromTuple(){return String.valueOf(tuple.getIntegerByField("total"));}@Overridepublic String getKeyFromTuple(){return tuple.getStringByField("word");}})}</code></pre><h4 id="3、与HDFS集成">3、与HDFS集成</h4><ul><li><p>需要的jar包：<br><code>$STORM_HOME</code>\external\storm-hdfs\storm-hdfs-1.0.3.jar<br>HDFS相关的jar包</p></li><li><p>开发新的bolt组件</p></li></ul><pre><code class="highlight plaintext">//创建一个新的HDFS Bolt组件，把前一个bolt组件处理的结果存入HDFSprivate static IRichBolt createHDFSBolt(){HdfsBolt bolt = new HdfsBolt();//HDFS的位置bolt.withFsUrl("hdfs://192.168.116.121:9000");//数据保存在HDFS上的目录bolt.withFileNameFormat(new DefaultFileNameFormat().withPath("/stormdata"));//写入HDFS的数据的分隔符 | 结果：Beijing|10bolt.withRecordFormat(new DelimitedRecordFormat().withFieldDelimiter("|"));//每5M的数据生成一个文件bolt.withRotationPolicy(new FileSizeRotationPolicy(5.0f, Units.MB));//Bolt输出tuple,当tuple达到一定的大小（没1K），与HDFS进行同步bolt.withSyncPolicy(new CountSyncPolicy(1000));return bolt;}</code></pre><h4 id="4、与HBase集成">4、与HBase集成</h4><ul><li>需要的jar包：HBase的相关包</li><li>开发新的bolt组件（WordCountBoltHBase.java）</li></ul><pre><code class="highlight plaintext">/** * 在HBase中创建表，保存数据 * create 'result','info' */ public class WordCountBoltHBase extends BaseRichBolt {public void execute(Tuple tuple){//如何处理？将上一个bolt组件发送过来的结果，存入HBase//取出上一个组件发送过来的数据String word = tuple.getStringByField("word");int total = tuple.getIntegerByField("total");//构造一个Put对象Put put = new Put(Bytes.toBytes(word));put.add(Bytes.toBytes("info"), Bytes.toBytes("word"), Bytes.toBytes(word));put.add(Bytes.toBytes("info"), Bytes.toBytes("total"), Bytes.toBytes(String.valueOf(total)));//把数据插入HBasetry{table.put(put);}catch(Exception e){e.printStackTrace();}}public void prepare(Map arg0, TopologyContext arg1, OutputCollector arg2){//初始化//指定ZK的地址Configuration conf = new Configuration();conf.set("hbase.zookeeper.quorum","192.168.116.121");//创建table的客户端try{table = new HTable(conf, "result");}catch(Exception ex){ex.printStackTrace();}} }</code></pre><h4 id="5、与Apache-Kafka集成">5、与Apache Kafka集成</h4><ul><li>注意：需要把slf4j-log4j12-1.6.4.jar包去掉，有冲突（有两个）</li></ul><pre><code class="highlight plaintext">private static IRichSpout creatKafkaSpout(){//定义ZK地址BrokerHosts hosts = new ZkHosts("hadoop121:2181,hadoop122:2181,hadoop123:2181");//指定Topic的信息SpoutConfig spoutConf = new SpoutConfig(hosts, "mydemo2", "/mydemo2", UUID.randomUUID().toString());//定义收到消息的Schema格式spoutConf.scheme = new SchemeAsMultiScheme(new Scheme(){@Overridepublic Fields getOutputFields(){return new Fields("sentence");}@Overridepublic List&lt;Object&gt; deserialize(ByteBuffer buffer){try{String msg = (Charset.forName("UTF-8").newDecoder()).decode(buffer).asReadOnlyBuffer().toString();System.out.println("**********收到的数据是msg" + msg);return new Values(msg);}catch(Exception e){e.printStackTrace();}return null;}});return new KafkaSpout(spoutConf);}</code></pre><h4 id="6、与Hive集成">6、与Hive集成</h4><ul><li>由于集成Storm和Hive依赖的jar较多，并且冲突的jar包很多，强烈建议使用Maven来搭建新的工程</li></ul><pre><code class="highlight plaintext">&lt;dependencies&gt;&lt;dependency&gt;&lt;groupId&gt;org.apache.storm&lt;/groupId&gt;&lt;artifactId&gt;storm-core&lt;/artifactId&gt;&lt;version&gt;1.0.3&lt;/version&gt;&lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.apache.storm&lt;/groupId&gt;&lt;artifactId&gt;storm-hive&lt;/artifactId&gt;&lt;version&gt;1.0.3&lt;/version&gt;&lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><ul><li>需要对Hive做一定的配置（在hive-site.xml文件中）：</li></ul><pre><code class="highlight plaintext">&lt;property&gt;  &lt;name&gt;hive.in.test&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;</code></pre><ul><li>需要使用下面的语句在hive中创建表：</li></ul><pre><code class="highlight plaintext">create table wordcount(word string,total int)clustered by (word) into 10 bucketsstored as orc TBLPROPERTIES('transactional'='true');</code></pre><ul><li>启动metastore服务：hive --service metastore</li><li>开发新的bolt组件，用于将前一个bolt处理的结果写入Hive</li></ul><pre><code class="highlight plaintext">private static IRichBolt createHiveBolt(){//设置环境变量，能找到winutils.exeSystem.setProperty("hadoop.home.dir", "D:\\tools\\hadoop-2.8.4");//作用：将bolt组件处理后的结果tuple，如何存入hive表DelimitedRecordHiveMapper mapper = new DelimitedRecordHiveMapper().withColumnFields(new Fields("word", "total"));//配置Hive的参数信息HiveOptions options = new HiveOptions("thrift://hadoop121:9083",//hive的metastore  "default",//hive数据库的名字  "wordcount",//保存数据的表mapper).withTxnsPerBatch(10).withBatchSize(1000).withIdleTimeout(10);//创建一个Hive的bolt组件，将单词计数后的结果存入hiveHiveBolt bolt = new HiveBolt(options);return bolt;}</code></pre><ul><li>为了测试的方便，我们依然采用之前随机产生字符串的Spout组件产生数据</li></ul><h4 id="7、与JMS集成">7、与JMS集成</h4><p>JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持</p><p>JMS的两种消息类型：Queue和Topic<br>基于Weblogic的JMS架构 ：</p><p><img src="/medias/%E5%9F%BA%E4%BA%8EWeblogic%E7%9A%84JMS%E6%9E%B6%E6%9E%84.PNG" alt="基于Weblogic的JMS架构"></p><pre><code class="highlight plaintext">private static IRichBolt createJMSBolt(){//创建一个JMS Bolt，将前一个bolt发送过来的数据 写入JMSJmsBolt bolt = new JmsBolt();//指定JMSBolt的providerbolt.setJmsProvider(new MyJMSProvider());//指定bolt如何解析信息bolt.setJmsMessageProducer(new JmsMessageProducer(){@Overridepublic Message toMessage(Session session, ITuple tuple) throws JMSException {//取出上一个组件发送过来的数据String word = tuple.getStringByField("word");int total = tuple.getIntegerByField("total");return session.createTextMessage(word + "   " + total);}});return bolt;}</code></pre><ul><li>需要的weblogic的jar包</li></ul><p>wljmsclient.jar<br>wlclient.jar</p><ul><li>permission javax.management.MBeanTrustPermission “register”;</li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>私有网络软件仓库搭建和挂载网络系统镜像</title>
      <link href="/2019/05/10/si_you_wang_luo_ruan_jian_cang_ku_da_jian_he_gua_zai_wang_luo_xi_tong_jing_xiang/"/>
      <url>/2019/05/10/si_you_wang_luo_ruan_jian_cang_ku_da_jian_he_gua_zai_wang_luo_xi_tong_jing_xiang/</url>
      
        <content type="html"><![CDATA[<h3 id="一、私有网络软件仓库">一、私有网络软件仓库</h3><p>在集群安装的过程中，要求每个节点都必须挂载光驱， 而对于每台节点都手动的去挂载光驱太麻烦，也不方便。这里使用每个节点都指向同一个私有网络镜像来解决这个问题</p><p>我们的集群采用的是全离线安装，也不可能逐个节点的安装，同样是也使用指向同一个私有的网络软件包来解决</p><p>因此选择在hadoop-4上搭建一个私有的网络软件仓库，以下是搭建的全过程</p><h4 id="1、上传镜像">1、上传镜像</h4><p>搭建私有网络镜像使用的镜像文件最好就使用安装系统的镜像，这里是选择了CentOS6.7x64的镜像，将其上传到hadoop1的/disk下（需新建/disk目录）<br>mkdir disk<br>上传CentOS-6.7-x86_64-bin-DVD1.iso</p><h4 id="2、挂载镜像">2、挂载镜像</h4><p>首先创建文件夹 /media/CentOS ：<br>mkdir -p /media/CentOS</p><p>挂载镜像 ：<br>mount -o loop /disk/CentOS-6.7-x86_64-bin-DVD1.iso /media/CentOS/</p><p>进入目录/etc/yum.repos.d ：<br>cd /etc/yum.repos.d</p><p>修改CentOS-Base.repo的名称 ：<br>mv CentOS-Base.repo CentOS-Base.repo.bak</p><p>修改CentOS-Media.repo文件 ：<br>vim CentOS-Media.repo</p><p>修改如下 ：<br>将enable=0改成enable=1</p><p>清除yum的缓存 ：<br>yum clean metadata<br>yum clean dbcache</p><p>查看是否挂载成功 ：<br>yum list | wc -l</p><p>这是统计镜像中有多少个软件包的命令，CentOS6.7x64位的系统的软件包个数一般在3000以上</p><h4 id="3、安装http-如果已经安装可以省略，但是需要启动，一b般最小化安装不会安装此服务">3、安装http(如果已经安装可以省略，但是需要启动，一b般最小化安装不会安装此服务)</h4><p>检查是否安装<br>service httpd status</p><p>网络镜像需要通过http请求访问，因此需要安装http:<br>yum –y install http</p><p>启动http服务，并让其开机自启 ：<br>service httpd start<br>chkconfig httpd on</p><p>由于http的默认端口为80，通过浏览器访问 ：<br>192.168.116.201:80</p><p>创建网络软件仓库目录 ：<br>mkdir –p /var/www/html</p><p>http默认将上面的目录作为软件仓库的目录</p><h4 id="4、安装createrepo-如果已经安装省略">4、安装createrepo(如果已经安装省略)</h4><p>该软件使用来生成http镜像的网络识别路径的：<br>yum -y install createrepo</p><p>到此 私有的网络软件仓库搭建完成</p><h3 id="二、挂载网络系统镜像">二、挂载网络系统镜像</h3><h4 id="1、创建网络系统镜像">1、创建网络系统镜像</h4><p>将从镜像中挂载的文件拷贝到软件仓库的目录中<br>cp -r /media/CentOS /var/www/html/</p><p>删除目录repodata<br>cd /var/www/html/CentOS<br>rm -rf ./repodata</p><p>生成新的软件路径目录repodata<br>createrepo .</p><p>也可以通过网络访问查看（192.168.116.201/CentOS/）：</p><p>到此网络镜像创建成功</p><h4 id="2、使用网络系统镜像">2、使用网络系统镜像</h4><p>解除对镜像文件的挂载 ：<br>umount /media/CentOS</p><p>如下， 目录下无文件则说明解除挂载成功<br>[root@hadoop1 yum.repos.d]# ll  /media/CentOS</p><p>如果出现如下说明有进程在占用挂载点<br>[root@hadoop1 yum.repos.d]# fuser -m /media/CentOS/<br>/media/CentOS 3157</p><p>出现这种情况，表示还有进程在使用/medis/CentOS挂载点，那么此时可以借助fuser命令找出占用目录/medis/CentOS的所有进程，然后kill掉，此时就可以umount 了<br>fuser -m /media/CentOS/</p><p>修改文件CentOS-Media.repo让其指向刚才创建的网络镜像<br>vim /etc/yum.repos.d/CentOS-Media.repo</p><p>修改如下：（修改前的配置参考3.1.2）<br>baseurl=<a href="https://192.168.116.201/CentOS/">https://192.168.116.201/CentOS/</a></p><p>清楚yum的缓存， 并查看软件包个数<br>yum clean metadata<br>yum clean dbcache<br>yum list | wc -l</p>]]></content>
      
      
      <categories>
          
          <category> CentOS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> 私有网络软件仓库 </tag>
            
            <tag> 挂载网络系统镜像 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据图片汇总</title>
      <link href="/2019/05/06/da_shu_ju_tu_pian_hui_zong/"/>
      <url>/2019/05/06/da_shu_ju_tu_pian_hui_zong/</url>
      
        <content type="html"><![CDATA[<h3 id="1、大数据课程概述与大数据背景知识">1、大数据课程概述与大数据背景知识</h3><h4 id="（1）数据仓库与大数据">（1）数据仓库与大数据</h4><p><img src="/medias/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE.PNG" alt="数据仓库与大数据"></p><h4 id="（2）PageRank">（2）PageRank</h4><p><img src="/medias/PageRank.PNG" alt="PageRank"></p><h4 id="（3）MR基本原理">（3）MR基本原理</h4><p><img src="/medias/MR%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.PNG" alt="MR基本原理"></p><h4 id="（4）HDFS原理">（4）HDFS原理</h4><p><img src="/medias/HDFS%E5%8E%9F%E7%90%86.PNG" alt="HDFS原理"></p><h4 id="（5）bigtable与Habase">（5）bigtable与Habase</h4><p><img src="/medias/bigtable%E4%B8%8EHabase.PNG" alt="bigtable与Habase"></p><h3 id="2、搭建Hadoop的环境">2、搭建Hadoop的环境</h3><h4 id="（1）1-PNG">（1）1.PNG</h4><p><img src="/medias/1.PNG" alt="1"></p><h4 id="（2）2-PNG">（2）2.PNG</h4><p><img src="/medias/2.PNG" alt="2"></p><h4 id="（3）3-PNG">（3）3.PNG</h4><p><img src="/medias/3.PNG" alt="3"></p><h4 id="（4）4-PNG">（4）4.PNG</h4><p><img src="/medias/4.PNG" alt="4"></p><h3 id="3、HDFS基础与操作">3、HDFS基础与操作</h3><h4 id="（1）startup">（1）startup</h4><p><img src="/medias/startup.PNG" alt="startup"></p><h3 id="4、HDFS上传与下载的原理">4、HDFS上传与下载的原理</h3><h4 id="（1）HDFS-Upload">（1）HDFS_Upload</h4><p><img src="/medias/HDFS_Upload.PNG" alt="HDFS_Upload"></p><h4 id="（2）HDFS-DownLoad">（2）HDFS_DownLoad</h4><p><img src="/medias/HDFS_DownLoad.PNG" alt="HDFS_DownLoad"></p><h3 id="5、HDFS-工作机制">5、HDFS-工作机制</h3><h4 id="（1）namenode工作机制">（1）namenode工作机制</h4><p><img src="/medias/namenode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.PNG" alt="namenode工作机制"></p><h4 id="（2）datanode工作机制">（2）datanode工作机制</h4><p><img src="/medias/datanode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.PNG" alt="datanode工作机制"></p><h3 id="6、MapReduce基础">6、MapReduce基础</h3><h4 id="（1）mapreduce思想">（1）mapreduce思想</h4><p><img src="/medias/mapreduce%E6%80%9D%E6%83%B3.PNG" alt="mapreduce思想"></p><h3 id="7、MapReduce分布式编程模型">7、MapReduce分布式编程模型</h3><h4 id="（1）maptask决定机制">（1）maptask决定机制</h4><p><img src="/medias/maptask%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6.PNG" alt="maptask决定机制"></p><h3 id="8、MapReduce案例分析">8、MapReduce案例分析</h3><h4 id="（1）yarn工作流程">（1）yarn工作流程</h4><p><img src="/medias/yarn%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.PNG" alt="yarn工作流程"></p><h4 id="（2）日志格式">（2）日志格式</h4><p><img src="/medias/%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F.PNG" alt="日志格式"></p><h3 id="9、分区排序">9、分区排序</h3><h4 id="（1）mapreduce流程">（1）mapreduce流程</h4><p><img src="/medias/mapreduce%E6%B5%81%E7%A8%8B.PNG" alt="mapreduce流程"></p><h3 id="10、Shuffle机制">10、Shuffle机制</h3><h4 id="（1）shuffle机制">（1）shuffle机制</h4><p><img src="/medias/shuffle%E6%9C%BA%E5%88%B6.PNG" alt="shuffle机制"></p><h3 id="11、mapjoin与reducejoin">11、mapjoin与reducejoin</h3><h4 id="（1）yarn架构介绍">（1）yarn架构介绍</h4><p><img src="/medias/yarn%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D.PNG" alt="yarn架构介绍"></p><h3 id="12、Zookeeper介绍">12、Zookeeper介绍</h3><h4 id="（1）zookeeper功能">（1）zookeeper功能</h4><p><img src="/medias/zookeeper%E5%8A%9F%E8%83%BD.PNG" alt="zookeeper功能"></p><h4 id="（2）选举机制">（2）选举机制</h4><p><img src="/medias/%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6.PNG" alt="选举机制"></p><h3 id="13、Hive">13、Hive</h3><h4 id="（1）Hive架构原理">（1）Hive架构原理</h4><p><img src="/medias/Hive%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.PNG" alt="Hive架构原理"></p><h3 id="14、Flume">14、Flume</h3><h4 id="（1）多channel多sink流程">（1）多channel多sink流程</h4><p><img src="/medias/%E5%A4%9Achannel%E5%A4%9Asink%E6%B5%81%E7%A8%8B.PNG" alt="多channel多sink流程"></p><h3 id="15、HBase">15、HBase</h3><h4 id="（1）HBase架构图">（1）HBase架构图</h4><p><img src="/medias/HBase%E6%9E%B6%E6%9E%84%E5%9B%BE.PNG" alt="HBase架构图"></p><h4 id="（2）HBase数据读取流程">（2）HBase数据读取流程</h4><p><img src="/medias/HBase%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B.PNG" alt="HBase数据读取流程"></p><h4 id="（3）HBase读取数据的详细流程">（3）HBase读取数据的详细流程</h4><p><img src="/medias/HBase%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B.PNG" alt="HBase读取数据的详细流程"></p><h4 id="（4）HBase写入数据的详细流程">（4）HBase写入数据的详细流程</h4><p><img src="/medias/HBase%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B.PNG" alt="HBase写入数据的详细流程"></p><h3 id="16、Scala">16、Scala</h3><h4 id="（1）Scala高阶函数">（1）Scala高阶函数</h4><p><img src="/medias/Scala%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0.PNG" alt="Scala高阶函数"></p><h4 id="（2）Actor01">（2）Actor01</h4><p><img src="/medias/Actor01.PNG" alt="Actor01"></p><h4 id="（3）NewAkkaSystem">（3）NewAkkaSystem</h4><p><img src="/medias/NewAkkaSystem.PNG" alt="NewAkkaSystem"></p><h4 id="（4）PingPongExample">（4）PingPongExample</h4><p><img src="/medias/PingPongExample.PNG" alt="PingPongExample"></p><h3 id="17、Spark">17、Spark</h3><h4 id="（1）Spark体系架构">（1）Spark体系架构</h4><p><img src="/medias/Spark%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.PNG" alt="Spark体系架构"></p><h4 id="（2）大数据HA">（2）大数据HA</h4><p><img src="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AEHA.PNG" alt="大数据HA"></p><h4 id="（3）蒙特卡洛求PI">（3）蒙特卡洛求PI</h4><p><img src="/medias/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%B1%82PI.PNG" alt="蒙特卡洛求PI"></p><h4 id="（4）spark的调用任务过程">（4）spark的调用任务过程</h4><p><img src="/medias/spark%E7%9A%84%E8%B0%83%E7%94%A8%E4%BB%BB%E5%8A%A1%E8%BF%87%E7%A8%8B.PNG" alt="spark的调用任务过程"></p><h4 id="（5）RDD">（5）RDD</h4><p><img src="/medias/RDD.PNG" alt="RDD"></p><h4 id="（6）WordCount程序分析">（6）WordCount程序分析</h4><p><img src="/medias/WordCount%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90.PNG" alt="WordCount程序分析"></p><h4 id="（7）aggregate聚合操作">（7）aggregate聚合操作</h4><p><img src="/medias/aggregate%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C.PNG" alt="aggregate聚合操作"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 图片 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Storm基础</title>
      <link href="/2019/05/04/storm_ji_chu/"/>
      <url>/2019/05/04/storm_ji_chu/</url>
      
        <content type="html"><![CDATA[<p><strong>流式计算专题</strong><br>批量计算、实时计算、离线计算、流式计算</p><p>共同点：<br>数据源  --&gt;   采集数据   --&gt;   task worker --&gt;   task worker  --&gt;  sink 输出</p><p><strong>批量计算和流式计算</strong><br>区别：<br>处理数据粒度不一样</p><p>批量计算每次处理一定大小的数据块。流式计算，每次处理一条记录</p><p>流式计算可以提供类似批量计算的功能，为什么我们还要批量计算系统？</p><p>1、流式系统的吞吐量不如批量系统</p><p>2、流式系统无法提供精准的计算</p><ol><li>任务类型不一样</li><li>流式计算会一直运行</li><li>数据源的区别<br>对于批量计算而言，数据是有限数据<br>而对于流式计算，是无限数据</li></ol><h3 id="一、Storm-是最早流式计算框架">一、Storm----是最早流式计算框架</h3><h4 id="1、Storm概述">1、Storm概述</h4><p><strong>1）什么是Storm</strong><br>网址：<a href="http://storm.apache.org/">http://storm.apache.org/</a><br>Apache Storm是一个<strong>免费的开源分布式实时计算系统</strong>。Storm可以<strong>轻松可靠地处理无限数据流</strong>，<strong>实现Hadoop对批处理所做的实时处理</strong>。Storm非常<strong>简单</strong>，可以<strong>与任何编程语言一起使用</strong>，并且使用起来很有趣！</p><p>Storm为<strong>分布式实时计算</strong>提供了一组通用原语，可被用于“<strong>流处理</strong>”之中，<strong>实时处理消息并更新数据库</strong>。这是管理队列及工作者集群的另一种方式。 Storm也可被用于“<strong>连续计算</strong>”（continuous computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。它还可被用于“<strong>分布式RPC</strong>”，以并行的方式运行昂贵的运算</p><p>Storm可以<strong>方便地在</strong>一个计算机<strong>集群中编写与扩展复杂</strong>的<strong>实时计算</strong>，Storm用于<strong>实时处理</strong>，就好比 Hadoop 用于批处理。Storm<strong>保证每个消息都会得到处理</strong>，而且它<strong>很快</strong>——<strong>在一个小集群中</strong>，<strong>每秒</strong>可以<strong>处理数以百万计的消息</strong>。更棒的是你<strong>可以使用任意编程语言来</strong>做<strong>开发</strong></p><p>Storm有许多用例：<strong>实时分析</strong>，<strong>在线机器学习</strong>，<strong>连续计算</strong>，<strong>分布式RPC</strong>，<strong>ETL</strong>等。风暴很快：一个基准测试表示每个节点<strong>每秒处理超过一百万个元组。<strong>它具有</strong>可扩展性</strong>，<strong>容错性</strong>，可<strong>确保</strong>您的<strong>数据得到处理</strong>，并且<strong>易于设置和操作</strong></p><p>Storm<strong>集成</strong>了您<strong>已经使用的排队和数据库技术</strong>。<strong>Storm拓扑消耗数据流</strong>并<strong>以任意复杂的方式处理这些流</strong>，然后<strong>在计算的每个阶段之间重新划分流</strong></p><h4 id="2、离线计算和流式计算">2、离线计算和流式计算</h4><p>①　<strong>离线计算</strong></p><ul><li>离线计算：批量获取数据、批量传输数据、周期性批量计算数据、数据展示</li><li>代表技术：Sqoop批量导入数据、HDFS批量存储数据、MapReduce批量计算、Hive、Flume批量获取数据、Sqoop批量传输、HDFS/Hive/HBase批量存储、MR/Hive计算数据、BI</li></ul><p>②　<strong>流式计算</strong></p><ul><li>流式计算：数据实时产生、数据实时传输、数据实时计算、实时展示</li><li>代表技术：Flume实时获取数据、Kafka/metaq实时数据存储、Storm/JStorm实时数据计算、Redis实时结果缓存、持久化存储(mysql)、阿里实时展示(DataV/QuickBI)</li></ul><p>一句话总结：将源源不断产生的数据实时收集并实时计算，尽可能快的得到计算结果</p><p>③　<strong>Storm与Hadoop的区别</strong></p><table><thead><tr><th style="text-align:center">Storm用于实时计算</th><th style="text-align:center">Hadoop用于离线计算</th></tr></thead><tbody><tr><td style="text-align:center">Storm处理的数据保存在内存中，源源不断中，一批一批</td><td style="text-align:center">Hadoop处理的数据保存在文件系统</td></tr><tr><td style="text-align:center">Storm的数据通过网络传输进来</td><td style="text-align:center">Hadoop的数据保存在磁盘中</td></tr><tr><td style="text-align:center">Storm与Hadoop的编程模型相似</td><td style="text-align:center"></td></tr></tbody></table><p><strong>Storm与Hadoop</strong><br><strong>角色</strong></p><table><thead><tr><th style="text-align:center">hadoop</th><th style="text-align:center">storm</th></tr></thead><tbody><tr><td style="text-align:center">JobTracker</td><td style="text-align:center">Nimbus</td></tr><tr><td style="text-align:center">TaskTracker</td><td style="text-align:center">Supervisor</td></tr><tr><td style="text-align:center">Child</td><td style="text-align:center">Worker</td></tr></tbody></table><p><strong>应用名称</strong></p><table><thead><tr><th style="text-align:center">hadoop</th><th style="text-align:center">storm</th></tr></thead><tbody><tr><td style="text-align:center">Job</td><td style="text-align:center">Topology</td></tr></tbody></table><p><strong>编程接口</strong></p><table><thead><tr><th style="text-align:center">hadoop</th><th style="text-align:center">storm</th></tr></thead><tbody><tr><td style="text-align:center">Mapper/Reducer</td><td style="text-align:center">Spout/Bolt</td></tr></tbody></table><h4 id="3、Storm的体系结构">3、Storm的体系结构</h4><p><img src="/medias/nimbus.PNG" alt="nimbus"></p><p><img src="/medias/topology.PNG" alt="topology"></p><ul><li><p><strong>Nimbus</strong>：负责资源分配和任务调度</p></li><li><p><strong>Supervisor</strong>：负责接受Nimbus分配的任务，启动和停止属于自己管理的worker进程。通过配置文件设置当前Supervisor上启动多少个Worker</p></li><li><p><strong>Worker</strong>：运行具体处理组件逻辑的进程。Worker运行的任务类型只有两种，一种是Spout任务，一种是Bolt任务</p></li><li><p><strong>Executor</strong>：Storm 0.8之后，Executor为Worker进程中的具体的物理线程，同一个Spout/Bolt的Task可能会共享一个物理线程，一个Executor中只能运行隶属于同一个Spout/Bolt的Task</p></li><li><p><strong>Task</strong>：Worker中每一个Spout/Bolt的线程称为一个Task. 在Storm0.8之后，Task不再与物理线程对应，不同Spout/Bolt的Task可能会共享一个物理线程，该线程称为Executor</p></li></ul><p><img src="/medias/Worker%E8%BF%9B%E7%A8%8B.PNG" alt="Worker进程"></p><h4 id="4、Storm编程模型">4、Storm编程模型</h4><p><img src="/medias/Storm%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.PNG" alt="Storm编程模型"></p><p><strong>tuple</strong>：元组<br>是消息传输的基本单元</p><p><strong>Spout</strong>：水龙头<br>Storm的核心抽象。拓扑的流的来源。Spout通常从外部数据源读取数据。转换为t敺内部的源数据。<br>主要方法：<br>nextTuple() -》 发出一个新的元组到拓扑<br>ack()<br>fail()</p><p><strong>Bolt</strong>：转接头<br>Bolt是对流的处理节点。Bolt作用：过滤、业务、连接运算</p><p><strong>Topology</strong>：拓扑<br>是一个实时的应用程序<br>永远运行除非被杀死<br>Spout到Bolt是一个连接流</p><h4 id="5、Storm的运行机制">5、Storm的运行机制</h4><p><img src="/medias/Nimbus-Supervisor.PNG" alt="Nimbus-Supervisor"></p><ul><li>整个处理流程的组织协调不用用户去关心，用户只需要去定义每一个步骤中的具体业务处理逻辑</li><li>具体执行任务的角色是Worker，Worker执行任务时具体的行为则有我们定义的业务逻辑决定</li></ul><p><img src="/medias/Storm%E7%89%A9%E7%90%86%E9%9B%86%E7%BE%A4%E7%BB%93%E6%9E%84.PNG" alt="Storm物理集群结构"></p><h4 id="6、Storm的集群安装配置">6、Storm的集群安装配置</h4><p><strong>（1）Storm集群安装部署</strong><br>1）准备工作</p><table><thead><tr><th style="text-align:center">hsiehchou121</th><th style="text-align:center">hsiehchou122</th><th style="text-align:center">hsiehchou123</th></tr></thead><tbody><tr><td style="text-align:center">storm01</td><td style="text-align:center">storm02</td><td style="text-align:center">storm03</td></tr></tbody></table><p>2）下载安装包<br><a href="http://storm.apache.org/downloads.html">http://storm.apache.org/downloads.html</a></p><p>3）上传</p><p>4）解压<br>tar -zxvf apache-storm-1.1.0.tar.gz<br>mv apache-storm-1.1.0 storm</p><p>5）<strong>设置环境变量</strong><br><strong>#STORM_HOME</strong><br>export STORM_HOME=/root/hd/storm<br>export PATH=<code>$STORM_HOME/bin:$PATH</code><br>source /etc/profile</p><p>6）<strong>修改配置文件</strong><br>$ <strong>vi storm.yaml</strong></p><pre><code class="highlight plaintext">#设置Zookeeper的主机名称storm.zookeeper.servers:- "hsiehchou121"- "hsiehchou122"- "hsiehchou123"#设置主节点的主机名称nimbus.seeds: ["hsiehchou121"]#设置Storm的数据存储路径storm.local.dir: "/root/hd/storm/data"#设置Worker的端口号supervisor.slots.ports:- 6700- 6701- 6702- 6703</code></pre><p>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>注意</strong>：如果要搭建<strong>Storm的HA</strong>，只需要在<strong>nimbus.seeds</strong>中<strong>设置多个nimbus</strong>即可<br>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br>mkdir data</p><p>7）<strong>分发到其他机器</strong><br>[root@hsiehchou121 hd]# scp -r storm/ hsiehchou122:<code>$PWD</code><br>[root@hsiehchou121 hd]# scp -r storm/ hsiehchou123:<code>$PWD</code></p><h4 id="7、启动和查看Storm">7、启动和查看Storm</h4><p>0）<strong>启动ZooKeeper</strong><br><a href="http://zkServer.sh">zkServer.sh</a> start</p><p>1）在nimbus.host所属的机器上启动 nimbus服务和logviewer服务</p><p><strong>启动nimbus</strong></p><ul><li>storm nimbus &amp;</li></ul><p>**启动logviewer **</p><ul><li>storm logviewer &amp;</li></ul><p>2）在nimbus.host所属的机器上启动ui服务<br><strong>启动ui界面</strong></p><ul><li>storm ui &amp;</li></ul><p>3）在其它个节点上启动supervisor服务和logviewer服务<br><strong>启动supervisor</strong></p><ul><li>storm supervisor &amp;</li></ul><p><strong>启动logviewer</strong></p><ul><li>storm logviewer &amp;</li></ul><p>4）查看Storm集群：访问nimbus.host:/8080，即可看到storm的ui界面<br><a href="http://hsiehchou121:8080/index.html">http://hsiehchou121:8080/index.html</a></p><h4 id="8、Storm的常用命令">8、Storm的常用命令</h4><p>有许多简单且有用的命令可以用来管理拓扑，它们可以提交、杀死、禁用、再平衡拓扑</p><p><strong>1）查看命令帮助</strong><br>storm help</p><p><strong>2）查看版本</strong><br>storm version</p><p><strong>3）查看当前正在运行拓扑及其状态</strong><br>storm list</p><p><strong>4）提交任务命令格式</strong><br>storm jar 【jar路径】 【拓扑包名.拓扑类名】 【拓扑名称】<br>storm jar <code>[/路径/.jar][全类名]</code>[拓扑名称]</p><p><strong>5）杀死任务命令格式</strong><br>storm kill 【拓扑名称】 -w 10<br>（执行kill命令时可以通过-w [等待秒数]指定拓扑停用以后的等待时间）<br>storm kill topology-name -w 10</p><p><strong>6）停用任务命令格式</strong><br>storm deactivte  【拓扑名称】<br>storm deactivate topology-name</p><p><strong>7）启用任务命令格式</strong><br>storm activate【拓扑名称】<br>storm activate topology-name</p><p><strong>8）重新部署任务命令格式</strong><br>storm rebalance  【拓扑名称】<br>storm rebalance topology-name<br>再平衡使你重分配集群任务。这是个很强大的命令。比如，你向一个运行中的集群增加了节点。再平衡命令将会停用拓扑，然后在相应超时时间之后重分配工人，并重启拓扑</p><h3 id="二、Storm编程案例">二、Storm编程案例</h3><h4 id="1、WordCount及流程分析">1、WordCount及流程分析</h4><p>通过查看Storm UI上每个组件的events链接，可以查看Storm的每个组件（spout、blot）发送的消息。但Storm的event logger的功能默认是禁用的，需要在配置文件中设置：topology.eventlogger.executors: 1，具体说明如下：</p><ul><li>“topology.eventlogger.executors”: 0 默认，禁用</li><li>“topology.eventlogger.executors”: 1 一个topology分配一个Event Logger</li><li>“topology.eventlogger.executors”: nil 每个worker.分配一个Event Logger</li></ul><p><strong>WordCount的数据流程分析</strong></p><p><img src="/medias/WordCount%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90.PNG" alt="WordCount的数据流程分析"></p><h4 id="2、Storm编程案例：WordCount">2、Storm编程案例：WordCount</h4><p>流式计算一般架构图：</p><p><img src="/medias/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E4%B8%80%E8%88%AC%E6%9E%B6%E6%9E%84%E5%9B%BE.PNG" alt="流式计算一般架构图"></p><ul><li>Flume用来获取数据</li><li>Kafka用来临时保存数据</li><li>Strom用来计算数据</li><li>Redis是个内存数据库，用来保存数据</li></ul><p>代码编写：</p><ol><li>创建Spout（WordCountSpout）组件采集数据，作为整个Topology的数据源<br><strong>WordCountSpout类</strong></li></ol><pre><code class="highlight plaintext">package com.hsiehchou.wc;import java.util.Map;import org.apache.storm.spout.SpoutOutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichSpout;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Values;/** * 需求：单词计数  Hello ni hao! Hello China! *  * 实现接口：IRichSpout  IRichBolt * 继承抽象类：BaseRichSpout  BaseRichBolt * @author hsiehchou */public class WordCountSpout extends BaseRichSpout {//定义收集器private SpoutOutputCollector collector;//发送数据@Overridepublic void nextTuple() {//1.发送数据collector.emit(new Values("I am a boy!"));//2.设置延迟try {Thread.sleep(1000);} catch (InterruptedException e) {e.printStackTrace();}}//创建收集器@Overridepublic void open(Map arg0, TopologyContext arg1, SpoutOutputCollector collector) {this.collector = collector;}//声明@Overridepublic void declareOutputFields(OutputFieldsDeclarer declare) {//起别名declare.declare(new Fields("hsiehchou"));}}</code></pre><ol start="2"><li>创建Bolt（WordCountSplitBolt）组件进行分词操作<br><strong>WordCountSplitBolt类</strong></li></ol><pre><code class="highlight plaintext">package com.hsiehchou.wc;import java.util.Map;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichBolt;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Tuple;import org.apache.storm.tuple.Values;public class WordCountSplitBolt extends BaseRichBolt {//数据继续发送到下一个boltprivate OutputCollector collector;//业务逻辑@Overridepublic void execute(Tuple in) {//1.获取数据String line = in.getStringByField("hsiehchou");//2.切分数据String[] fields = line.split(" ");//3.&lt;单词,1&gt;发送出去，下一个bolt（累加求和）for(String w:fields) {collector.emit(new Values(w,1));}}//初始化@Overridepublic void prepare(Map arg0, TopologyContext arg1, OutputCollector collector) {this.collector = collector;}//声明描述@Overridepublic void declareOutputFields(OutputFieldsDeclarer declare) {declare.declare(new Fields("word","sum"));}}</code></pre><ol start="3"><li>创建Bolt（WordCountBoltCount）组件进行单词计数作</li></ol><p><strong>WordCountBoltCount类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.wc;import java.util.HashMap;import java.util.Map;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichBolt;import org.apache.storm.tuple.Tuple;public class WordCountBoltCount extends BaseRichBolt {private Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();//累加求和@Overridepublic void execute(Tuple in) {//1.获取数据String word = in.getStringByField("word");Integer sum = in.getIntegerByField("sum");//2.业务处理if(map.containsKey(word)) {//之前出现的次数Integer count = map.get(word);//已有的map.put(word, count + sum);}else {map.put(word, sum);}//3.打印控制台System.err.println(Thread.currentThread().getId() + "单位为：" + word + "\t 当前出现次数为：" + map.get(word));}@Overridepublic void prepare(Map arg0, TopologyContext arg1, OutputCollector arg2) {}@Overridepublic void declareOutputFields(OutputFieldsDeclarer arg0) {}}</code></pre><ol start="4"><li>也可以将主程序Topology（WordCountTopology）提交到Storm集群运行</li></ol><p><strong>WordCountTopology类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.wc;import org.apache.storm.Config;import org.apache.storm.LocalCluster;import org.apache.storm.topology.TopologyBuilder;import org.apache.storm.tuple.Fields;public class WordCountTopology {public static void main(String[] args) {//1.hadoop --&gt; Job Storm --&gt; Topology 创建拓扑TopologyBuilder builder = new TopologyBuilder();//2.指定设置builder.setSpout("WordCountSpout", new WordCountSpout(), 1);builder.setBolt("WordCountSplitBolt", new WordCountSplitBolt(), 4).fieldsGrouping("WordCountSpout", new Fields("hsiehchou"));builder.setBolt("WordCountBoltCount", new WordCountBolt(), 2).fieldsGrouping("WordCountSplitBolt", new Fields("word"));//3.创建配置信息Config conf = new Config();//4.提交任务LocalCluster localCluster = new LocalCluster();localCluster.submitTopology("wordcounttopology", conf, builder.createTopology());}}</code></pre><h4 id="3、集群部署">3、集群部署</h4><p><strong>对WordCountDriver类进行修改，把本地模式修改为集群模式</strong></p><pre><code class="highlight plaintext">public class WordCountDriver {//集群模式运行try {StormSubmitter.submitTopology(args[0], conf, builder.createTopology());} catch (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) {e.printStackTrace();}//4.提交任务//LocalCluster localCluster = new LocalCluster();//localCluster.submitTopology("wordcounttopology", conf, builder.createTopology());}</code></pre><p><strong>提交到集群</strong></p><p>storm jar StormWordCount.jar com.hsiehchou.wc.WordCountDriver wordcount01</p><h3 id="三、分组策略">三、分组策略</h3><p>1）fields Grouping</p><p><strong>按照字段分组</strong><br>相同字段发送到一个task中<br>fieldsGrouping<br>builder.setBolt(“WordCountSplitBolt”, new WordCountSplitBolt(), 4).fieldsGrouping(“WordCountSpout”, new Fields(“hsiehchou”));</p><p>builder.setBolt(“WordCountBolt”, new WordCountBolt(), 2).fieldsGrouping(“WordCountSplitBolt”, new Fields(“word”));</p><p>2）shuffle Grouping</p><p><strong>随机分组</strong><br>轮询。平均分配。随机分发tuple，保证每个bolt中的tuple数量相同<br>shuffleGrouping<br>builder.setBolt(“WordCountSplitBolt”, new WordCountSplitBolt(), 4).shuffleGrouping(“WordCountSpout”);</p><p>builder.setBolt(“WordCountBolt”, new WordCountBolt(), 2).shuffleGrouping(“WordCountSplitBolt”);</p><p>3）None Grouping</p><p><strong>不分组</strong><br>采用这种策略每个bolt中接收的单词不同<br>noneGrouping<br>builder.setBolt(“WordCountSplitBolt”, new WordCountSplitBolt(), 4).noneGrouping(“WordCountSpout”);</p><p>builder.setBolt(“WordCountBolt”, new WordCountBolt(), 2).noneGrouping(“WordCountSplitBolt”);</p><p>4）All Grouping</p><p><strong>广播发送</strong><br>tuple分发给每一个bolt<br>allGrouping<br>builder.setBolt(“WordCountSplitBolt”, new WordCountSplitBolt(), 4).allGrouping(“WordCountSpout”);</p><p>builder.setBolt(“WordCountBolt”, new WordCountBolt(), 2).allGrouping(“WordCountSplitBolt”);</p><p>5）Global Grouping</p><p><strong>全局分组</strong><br>分配给task id值最小的<br>根据线程id判断，只分配给线程id最小的<br>builder.setBolt(“WordCountSplitBolt”, new WordCountSplitBolt(), 4).globalGrouping(“WordCountSpout”);</p><p>builder.setBolt(“WordCountBolt”, new WordCountBolt(), 2).globalGrouping(“WordCountSplitBolt”);</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop的HA高可用</title>
      <link href="/2019/04/29/hadoop_de_ha_gao_ke_yong_ke_xing/"/>
      <url>/2019/04/29/hadoop_de_ha_gao_ke_yong_ke_xing/</url>
      
        <content type="html"><![CDATA[<p><strong>Hadoop的HA高可用（可行）</strong></p><h3 id="一、集群的规划">一、集群的规划</h3><p><strong>ZooKeeper集群</strong></p><table><thead><tr><th style="text-align:center">192.168.116.121</th><th style="text-align:center">192.168.116.122</th><th style="text-align:center">192.168.116.123</th></tr></thead><tbody><tr><td style="text-align:center">hsiehchou121</td><td style="text-align:center">hsiehchou122</td><td style="text-align:center">hsiehchou123</td></tr></tbody></table><p><strong>Hadoop集群</strong></p><table><thead><tr><th style="text-align:center">192.168.116.121</th><th style="text-align:center">192.168.116.122</th><th style="text-align:center">192.168.116.123</th><th style="text-align:center">192.168.116.124</th></tr></thead><tbody><tr><td style="text-align:center">hsiehchou121</td><td style="text-align:center">hsiehchou122</td><td style="text-align:center">hsiehchou123</td><td style="text-align:center">hsiehchou124</td></tr><tr><td style="text-align:center">NameNode1</td><td style="text-align:center">NameNode2</td><td style="text-align:center">DataNode1</td><td style="text-align:center">DataNode2</td></tr><tr><td style="text-align:center">ResourceManager1</td><td style="text-align:center">ResourceManager2</td><td style="text-align:center">NodeManager1</td><td style="text-align:center">NodeManager2</td></tr><tr><td style="text-align:center">Journalnode</td><td style="text-align:center">Journalnode</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><h3 id="二、准备工作">二、准备工作</h3><p>1、安装JDK<br>2、配置环境变量<br>3、配置免密码登录<br>4、配置主机名</p><h3 id="三、配置Zookeeper（在192-168-116-121安装）">三、配置Zookeeper（在192.168.116.121安装）</h3><p>在主节点（hsiehchou121）上配置ZooKeeper</p><h4 id="1、配置-root-hd-zookeeper-3-4-10-conf-zoo-cfg文件">1、配置/root/hd/zookeeper-3.4.10/conf/zoo.cfg文件</h4><pre><code class="highlight plaintext">dataDir=/root/hd/zookeeper-3.4.10/zkData+++++++++++++++zkconfig+++++++++++++++++server.1=hsiehchou121:2888:3888server.2=hsiehchou122:2888:3888server.3=hsiehchou123:2888:3888</code></pre><h4 id="2、在-root-training-zookeeper-3-4-6-tmp目录下创建一个myid的空文件">2、在/root/training/zookeeper-3.4.6/tmp目录下创建一个myid的空文件</h4><p>echo 1 &gt; /root/hd/zookeeper-3.4.10/tmp/myid</p><h4 id="3、将配置好的ZooKeeper拷贝到其他节点，同时修改各自的myid文件">3、将配置好的ZooKeeper拷贝到其他节点，同时修改各自的myid文件</h4><p>scp -r /root/hd/zookeeper-3.4.10/ hsiehchou122:/root/hd<br>scp -r /root/hd/zookeeper-3.4.10/ hsiehchou123:/root/hd</p><h3 id="四、安装Hadoop集群（在hsiehchou121上安装）">四、安装Hadoop集群（在hsiehchou121上安装）</h3><h4 id="1、修改hadoop-env-sh">1、<a href="http://xn--hadoop-env-yu6pe85r.sh">修改hadoop-env.sh</a></h4><pre><code class="highlight plaintext">export JAVA_HOME=/root/hd/jdk1.8.0_192</code></pre><h4 id="2、修改core-site-xml">2、修改core-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;!-- 指定hdfs的nameservice为mycluster --&gt;&lt;property&gt;&lt;name&gt;fs.defaultFS&lt;/name&gt;&lt;value&gt;hdfs://mycluster&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop临时目录 --&gt;&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/root/hd/hadoop-2.8.4/tmp&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定zookeeper地址 --&gt;&lt;property&gt;&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;&lt;value&gt;hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="3、修改hdfs-site-xml（配置这个nameservice中有几个NameNode）">3、修改hdfs-site.xml（配置这个nameservice中有几个NameNode）</h4><pre><code class="highlight plaintext">&lt;configuration&gt; &lt;!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 --&gt;&lt;property&gt;&lt;name&gt;dfs.nameservices&lt;/name&gt;&lt;value&gt;mycluster&lt;/value&gt;&lt;/property&gt;&lt;!-- mycluster下面有两个NameNode，分别是nn1，nn2 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;&lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的RPC通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;&lt;value&gt;hsiehchou121:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的http通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;&lt;value&gt;hsiehchou121:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的RPC通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;&lt;value&gt;hsiehchou122:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的http通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;&lt;value&gt;hsiehchou122:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定NameNode的日志在JournalNode上的存放位置 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;&lt;value&gt;qjournal://hsiehchou121:8485;hsiehchou122:8485;/mycluster&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;&lt;property&gt;&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;&lt;value&gt;/root/hd/hadoop-2.8.4/journal&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启NameNode失败自动切换 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置失败自动切换实现方式 --&gt;&lt;property&gt;&lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;&lt;value&gt;sshfenceshell(/bin/true)&lt;/value&gt;&lt;/property&gt;&lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;&lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置sshfence隔离机制超时时间 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;&lt;value&gt;30000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="4、修改mapred-site-xml">4、修改mapred-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="5、修改yarn-site-xml">5、修改yarn-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;!-- 开启RM高可靠 --&gt;&lt;property&gt;   &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;   &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定RM的cluster id --&gt;&lt;property&gt;   &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;   &lt;value&gt;yarncluster&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定RM的名字 --&gt;&lt;property&gt;   &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;   &lt;value&gt;rm1,rm2&lt;/value&gt;&lt;/property&gt;&lt;!-- 分别指定RM的地址 --&gt;&lt;property&gt;   &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;   &lt;value&gt;hsiehchou121&lt;/value&gt;&lt;/property&gt;&lt;property&gt;   &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;   &lt;value&gt;hsiehchou122&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定zk集群地址 --&gt;&lt;property&gt;   &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;   &lt;value&gt;hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181&lt;/value&gt;&lt;/property&gt;&lt;property&gt;   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;  &lt;value&gt;32768&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;&lt;value&gt;32768&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;&lt;value&gt;4096&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;&lt;value&gt;24&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;&lt;value&gt;/tmp/yarn-logs&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="6、修改slaves">6、修改slaves</h4><p>hsiehchou123<br>hsiehchou124</p><h4 id="7、将配置好的hadoop拷贝到其他节点">7、将配置好的hadoop拷贝到其他节点</h4><p>scp -r /root/hd/hadoop-2.8.4/ root@hsiehchou122:/root/hd/<br>scp -r /root/hd/hadoop-2.8.4/ root@hsiehchou123:/root/hd/<br>scp -r /root/hd/hadoop-2.8.4/ root@hsiehchou124:/root/hd/</p><h3 id="五、启动Zookeeper集群">五、启动Zookeeper集群</h3><h4 id="1、启动Zookeeper集群">1、启动Zookeeper集群</h4><p>[root@hsiehchou121 hadoop-2.8.4]# <strong><a href="http://zkServer.sh">zkServer.sh</a> start</strong><br>[root@hsiehchou122 hadoop-2.8.4]# <strong><a href="http://zkServer.sh">zkServer.sh</a> start</strong><br>[root@hsiehchou123 hadoop-2.8.4]# <strong><a href="http://zkServer.sh">zkServer.sh</a> start</strong></p><h3 id="六、在hsiehchou121和hsiehchou122上启动journalnode">六、在hsiehchou121和hsiehchou122上启动journalnode</h3><p><strong><a href="http://hadoop-daemon.sh">hadoop-daemon.sh</a> start journalnode</strong></p><h3 id="七、格式化HDFS（在hsiehchou121上执行）">七、格式化HDFS（在hsiehchou121上执行）</h3><h4 id="1-格式化ZooKeeper">1. 格式化ZooKeeper</h4><p>[root@hsiehchou121 hadoop-2.8.4]# <strong>bin/hdfs zkfc -formatZK</strong></p><h4 id="2、启动HDFS">2、启动HDFS</h4><p>1）在各个JournalNode节点上，输入以下命令启动journalnode服务<br>[root@hsiehchou121 hadoop-2.8.4]# <strong>sbin/hadoop-daemon.sh start journalnode</strong></p><p>2）在[nn1]上，对其进行格式化，并启动<br>[root@hsiehchou121 hadoop-2.8.4]# <strong>bin/hdfs namenode -format</strong><br>[root@hsiehchou121 hadoop-2.8.4]# <strong>sbin/hadoop-daemon.sh start namenode</strong></p><p>3）在[nn2]上，同步nn1的元数据信息<br>[root@hsiehchou122 hadoop-2.8.4]# <strong>bin/hdfs namenode -bootstrapStandby</strong></p><h3 id="八、在hsiehchou121上启动Hadoop集群">八、在hsiehchou121上启动Hadoop集群</h3><p>[root@hsiehchou121 hadoop-2.8.4]#  <strong><a href="http://start-all.sh">start-all.sh</a></strong></p><p><strong>日志</strong><br>This script is Deprecated. Instead use <a href="http://start-dfs.sh">start-dfs.sh</a> and start-yar<br>Starting namenodes on [hsiehchou121 hsiehchou122]<br>hsiehchou121: starting namenode, logging to /root/hd/hadoop-2.8.4-hsiehchou121.out<br>hsiehchou122: starting namenode, logging to /root/hd/hadoop-2.8.4-hsiehchou122.out<br>hsiehchou124: starting datanode, logging to /root/hd/hadoop-2.8.4-hsiehchou124.out<br>hsiehchou123: starting datanode, logging to /root/hd/hadoop-2.8.4-hsiehchou123.out<br>Starting journal nodes [hsiehchou121 hsiehchou122 ]<br>hsiehchou121: starting journalnode, logging to /root/hd/hadoop-2.alnode-hsiehchou121.out<br>hsiehchou122: starting journalnode, logging to /root/hd/hadoop-2.alnode-hsiehchou122.out<br>Starting ZK Failover Controllers on NN hosts [hsiehchou121 hsiehc<br>hsiehchou121: starting zkfc, logging to /root/hd/hadoop-2.8.4/logou121.out<br>hsiehchou122: starting zkfc, logging to /root/hd/hadoop-2.8.4/logou122.out<br>starting yarn daemons<br>starting resourcemanager, logging to /root/hd/hadoop-2.8.4/logs/ysiehchou121.out<br>hsiehchou123: starting nodemanager, logging to /root/hd/hadoop-2.ager-hsiehchou123.out<br>hsiehchou124: starting nodemanager, logging to /root/hd/hadoop-2.ager-hsiehchou124.out</p><p>hsiehchou122上的ResourceManager需要单独启动<br><strong>命令</strong><br>[root@hsiehchou121 hadoop-2.8.4]# <strong>./sbin/yarn-daemon.sh start resourcemanager</strong></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop HA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka</title>
      <link href="/2019/04/26/kafka/"/>
      <url>/2019/04/26/kafka/</url>
      
        <content type="html"><![CDATA[<p><strong>离线部分</strong><br>Hadoop-&gt;离线计算(hdfs / mapreduce) yarn<br>zookeeper-&gt;分布式协调（动物管理员）<br>hive-&gt;数据仓库（离线计算 / sql）easy coding<br>flume-&gt;数据采集<br>sqoop-&gt;数据迁移mysql-&gt;hdfs/hive hdfs/hive-&gt;mysql<br>Azkaban-&gt;任务调度工具<br>hbase-&gt;数据库（nosql）列式存储 读写速度</p><p><strong>实时</strong><br>kafka<br>storm</p><h3 id="一、Kafka是什么">一、Kafka是什么</h3><p>kafka一般用来缓存数据</p><h4 id="1、开源消息系统">1、开源消息系统</h4><h4 id="2、最初是LinkedIn公司开发，2011年开源">2、最初是LinkedIn公司开发，2011年开源</h4><p>2012年10月从Apache Incubator毕业</p><p>项目目标是为处理实时数据，提供一个统一、高通量、低等待的平台</p><h4 id="3、Kafka是一个分布式消息队列">3、Kafka是一个分布式消息队列</h4><p>消息根据Topic来归类，发送消息 Producer，接收 Consumer</p><p>kafka集群有多个kafka实例组成，每个实例成为broker</p><h4 id="4、依赖于-Zookeeper-集群">4、依赖于 Zookeeper 集群</h4><p>无论是kafka集群，还是 Producer、Consumer 都依赖于 Zookeeper 集群保存元信息，来保证系统可用性</p><p><img src="/medias/kafka%E4%BB%8B%E7%BB%8D.PNG" alt="kafka介绍"></p><p><strong>官网</strong><br><a href="http://kafka.apache.org/">http://kafka.apache.org/</a><br>ApacheKafka?是一个分布式流媒体平台<br>流媒体平台有三个关键功能：</p><ol><li>发布和订阅记录流，类似于消息队列或企业消息传递系统</li><li>以容错的持久方式存储记录流</li><li>记录发生时处理流</li></ol><p>Kafka通常用于两大类应用：<br>构建可在系统或应用程序之间可靠获取数据的实时流数据管道<br>构建转换或响应数据流的实时流应用程序</p><p>kafka在流计算中，kafka主要功能是用来缓存数据，storm可以通过消费kafka中的数据进行流计算，是一套开源的消息系统，由scala写成，支持javaAPI。</p><p>kafka最初由LinkedIn公司开发，2011年开源，2012年从Apache毕业，是一个分布式消息队列，kafka读消息保存采用Topic进行归类</p><h3 id="二、消息队列">二、消息队列</h3><p>点对点<br>发布、订阅模式</p><p><strong>角色</strong><br>发送消息：Producer(生产者)<br>接收消息：Consumer(消费者)</p><h3 id="三、为什么需要消息队列">三、为什么需要消息队列</h3><h4 id="1、解耦">1、解耦</h4><p>为了避免出现问题</p><h4 id="2、冗余">2、冗余</h4><p>消息队列把数据进行持久化，直到他们已经被完全处理</p><h4 id="3、扩展性（拓展性）">3、扩展性（拓展性）</h4><p>可增加处理过程</p><h4 id="4、灵活性">4、灵活性</h4><p>面对访问量剧增，不会因为超负荷请求而完全瘫痪</p><h4 id="5、可恢复性">5、可恢复性</h4><p>一部分组件失效，不会影响整个系统。可以进行恢复</p><h4 id="6、顺序保证（相对）">6、顺序保证（相对）</h4><p>kafka保证一个Partition内部的消息有序，对消息进行有序处理</p><h4 id="7、缓冲">7、缓冲</h4><p>控制数据流经过系统的速度</p><h4 id="8、异步通信">8、异步通信</h4><p>akka，消息队列提供了异步处理的机制</p><p>很多时候，用户不想也不需要立即处理消息，消息队列提供异步处理机制，允许用户把消息放入队列，但不立即处理</p><h3 id="四、Kafka架构">四、Kafka架构</h3><p><img src="/medias/kafka%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.PNG" alt="kafka系统架构"></p><h4 id="1、Producer：消息生产者">1、Producer：消息生产者</h4><p>就是往kafka中发消息的客户端</p><h4 id="2、Consumer：消息消费者">2、Consumer：消息消费者</h4><p>向kafka broker中取消息的客户端</p><h4 id="3、Topic-理解为队列">3、Topic 理解为队列</h4><h4 id="4、Consumer-Group-消费者组">4、Consumer Group 消费者组</h4><p>组内有多个消费者实例，共享一个公共的ID，即groupID<br>组内所有消费者协调在一起，消费Topic<br>每个分区，只能有同一个消费组内的一个Consumer消费</p><h4 id="5、broker">5、broker</h4><p>一台kafka服务器就是一个broker</p><h4 id="6、partition：一个topic分为多个partition">6、partition：一个topic分为多个partition</h4><p>每个partition是一个有序队列<br>kafka保证按一个partition中的顺序将消息发送个consumer<br>不能保证topic整体有序</p><h4 id="7、offset：Kafka存储文件按照offset-kafka命名">7、offset：Kafka存储文件按照offset.kafka命名</h4><p><img src="/medias/kafka%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%E5%9B%BE.PNG" alt="kafka读写流程图"></p><h3 id="五、Kafka部署">五、Kafka部署</h3><p>前提：Zookeeper</p><p>官网下载安装包<br><a href="http://kafka.apache.org/downloads">http://kafka.apache.org/downloads</a></p><p>上传tar</p><p>解压<br>[root@hsiehchou121 hd]# tar -zxvf kafka_2.11-2.1.1.tgz</p><p>[root@hsiehchou121 hd]# mv kafka_2.11-2.1.1 kafka</p><p>在kafka目录中，创建一个logs文件夹<br>[root@hsiehchou121 kafka]# mkdir logs</p><p>如果不创建，默认放在 /tmp 目录下</p><p><strong>修改文件</strong><br><strong>config/server.properties</strong><br>21 broker.id=0<br>broker 的 全局唯一编号，不能重复</p><p>新增<br>22 delete.topic.enable=true<br>允许删除topic</p><p><code>#</code>The number of threads that the server uses for receiving requests from the network and sending responses to the network<br>42 num.network.threads=3<br>处理网络请求的线程数量</p><p><code>#</code>The number of threads that the server uses for processing requests, which may include disk I/O<br>46 num.io.threads=8<br>用来处理磁盘IO的线程数量</p><p><code>#</code>A comma separated list of directories under which to store log files<br>62 log.dirs=/root/hd/kafka/logs<br>kafka运行日志存放的路径</p><p><code>#</code> The default number of log partitions per topic. More partitions allow greater<br><code>#</code>parallelism for consumption, but this will also result in more files across<br><code>#</code> the brokers.<br>67 num.partitions=1<br>当前主题在broker上的分区个数</p><p><code>#</code>· The number of threads per data directory to be used for log recovery at start        up and flushing at shutdown.<br><code>#</code> This value is recommended to be increased for installations with data dirs lo        cated in RAID array.<br>71 num.recovery.threads.per.data.dir=1<br>恢复和清理data下的线程数量</p><p>125 zookeeper.connect=hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181<br>zookeeper相关信息</p><p><code>#</code> Timeout in ms for connecting to zookeeper<br>128 zookeeper.connection.timeout.ms=6000<br>zookeeper连接超时的时间</p><p>添加全局环境变量，以便于在任何地方都可以启动<br>[root@hsiehchou121 config]# vi /etc/profile<br><code>#</code>kafka_home<br>export KAFKA_HOME=/root/hd/kafka<br>export PATH=<code>$KAFKA_HOME/bin:$PATH</code></p><p>[root@hsiehchou121 config]# source /etc/profile</p><p>分发安装包<br>注意：要修改配置文件中 borker.id的值<br>broker id 不得重复<br>21 broker.id=0 ---- hsiehchou121<br>21 broker.id=1 ---- hsiehchou122<br>21 broker.id=2 ---- hsiehchou123</p><p><strong>启动kafka集群</strong><br>首先需要先启动zookeeper<br><a href="http://zkServer.sh">zkServer.sh</a> start<br>[root@hsiehchou121 kafka]# <a href="http://zkServer.sh">zkServer.sh</a> start<br>[root@hsiehchou122 kafka]# <a href="http://zkServer.sh">zkServer.sh</a> start<br>[root@hsiehchou123 kafka]# <a href="http://zkServer.sh">zkServer.sh</a> start</p><p>（<strong>必须先启动！！！！！！！！！</strong>）<br>./bin/kafka-server-start.sh config/server.properties &amp;<br><strong>&amp;====后台运行</strong><br>[root@hsiehchou121 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;<br>[root@hsiehchou122 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;<br>[root@hsiehchou123 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;</p><p>jps命令可以看Kafka进程<br>[root@hsiehchou121 kafka]# jps<br>7104 Jps<br>6742 Kafka<br>6715 QuorumPeerMain</p><p>关闭命令：<br>./bin/kafka-server-stop.sh stop<br>或者./bin/kafka-server-stop.sh</p><h3 id="六、Kafka命令行操作">六、Kafka命令行操作</h3><h4 id="1、查看当前服务器中所有的topic">1、查看当前服务器中所有的topic</h4><p>[root@hsiehchou121 kafka]# ./bin/kafka-topics.sh <code>--zookeeper</code> hsiehchou121:2181 <code>--list</code></p><h4 id="2、创建topic">2、创建topic</h4><p>[root@hsiehchou121 kafka]# ./bin/kafka-topics.sh <code>--zookeeper</code> hsiehchou121:2181 <code>--create</code> <code>--replication-factor</code> 3 <code>--partitions</code> 1 <code>--topic</code> second</p><p>[root@hsiehchou121 kafka]# ./bin/kafka-topics.sh <code>--zookeeper</code> hsiehchou121:2181 <code>--create</code> <code>--replication-factor</code> 3 <code>--partitions</code> 1 <code>--topic</code> xz</p><p><code>--zookeeper</code> ：连接zk集群<br><code>--create</code> ：创建<br><code>--replication-factor</code>： 副本<br><code>--partitions</code> ：分区<br><code>--topic</code> ：主题名</p><h4 id="3、删除topic">3、删除topic</h4><p>[root@hsiehchou121 kafka]# ./bin/kafka-topics.sh <code>--zookeeper</code> hsiehchou121:2181 <code>--delete</code> <code>--topic</code> xz</p><h4 id="4、发送消息">4、发送消息</h4><p>[root@hsiehchou121 kafka]# ./bin/kafka-console-producer.sh <code>--broker-list</code> hsiehchou121:9092 <code>--topic</code> second<br><code>&gt;</code> 输入消息</p><h4 id="5、消费消息">5、消费消息</h4><p>[root@hsiehchou122 kafka]# ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--from-beginning</code> <code>--topic</code> second<br>接收消息</p><p>**注意：**这里的<code>--from-beginning</code>  是从头开始消费，不加则是消费当前正在发送到该topic的消息</p><h4 id="6、查看主题描述信息">6、查看主题描述信息</h4><p>[root@hsiehchou121 kafka]# ./bin/kafka-topics.sh --zookeeper hsiehchou121:2181 --describe --topic second<br>Topic:secondPartitionCount:1ReplicationFactor:3Configs:<br>Topic: secondPartition: 0Leader: 2Replicas: 2,1,0Isr: 2,1,0</p><h4 id="7、消费者组消费">7、消费者组消费</h4><p>修改 consumer.properties 配置文件<br>consumer group id<br>group.id=xz</p><h4 id="8、启动生产者">8、启动生产者</h4><p>[root@hsiehchou121 kafka]# ./bin/kafka-console-producer.sh <code>--broker-list</code> hsiehchou121:9092 <code>--topic</code> second</p><h4 id="9、启动消费者">9、启动消费者</h4><p>[root@hsiehchou122 kafka]# ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--topic</code> second <code>--consumer.config</code> config/consumer.properties</p><h3 id="七、Kafka工作流程分析">七、Kafka工作流程分析</h3><h4 id="1、Kafka生产过程分析">1、Kafka生产过程分析</h4><p>1）<strong>写入方式</strong><br>producer采用推（push）模式将消息发布到broker，每条消息都被追加（append）到分区（patition）中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障kafka吞吐率）</p><p>2） <strong>分区</strong>（Partition）<br>Kafka集群有多个消息代理服务器（broker-server）组成，发布到Kafka集群的每条消息都有一个类别，用主题（topic）来表示。通常，不同应用产生不同类型的数据，可以设置不同的主题。一个主题一般会有多个消息的订阅者，当生产者发布消息到某个主题时，订阅了这个主题的消费者都可以接收到生成者写入的新消息</p><p>Kafka集群为每个主题维护了分布式的分区（partition）日志文件，物理意义上可以把主题（topic）看作进行了分区的日志文件（partition log）。主题的每个分区都是一个有序的、不可变的记录序列，新的消息会不断追加到日志中。分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，叫做偏移量（offset），这个偏移量能够唯一地定位当前分区中的每一条消息</p><p>消息发送时都被发送到一个topic，其本质就是一个目录，而topic是由一些Partition Logs(分区日志)组成，其组织结构如下图所示：<br>下图中的topic有3个分区，每个分区的偏移量都从0开始，不同分区之间的偏移量都是独立的，不会相互影响</p><p><img src="/medias/partitions.PNG" alt="partitions"></p><p>我们可以看到，每个Partition中的消息都是有序的，生产的消息被不断追加到Partition log上，其中的每一个消息都被赋予了一个唯一的offset值</p><p>发布到Kafka主题的每条消息包括键值和时间戳。消息到达服务器端的指定分区后，都会分配到一个自增的偏移量。原始的消息内容和分配的偏移量以及其他一些元数据信息最后都会存储到分区日志文件中。消息的键也可以不用设置，这种情况下消息会均衡地分布到不同的分区</p><ol><li>分区的原因<br>（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了。<br>（2）可以提高并发，因为可以以Partition为单位读写了。<br>传统消息系统在服务端保持消息的顺序，如果有多个消费者消费同一个消息队列，服务端会以消费存储的顺序依次发送给消费者。但由于消息是异步发送给消费者的，消息到达消费者的顺序可能是无序的，这就意味着在并行消费时，传统消息系统无法很好地保证消息被顺序处理。虽然我们可以设置一个专用的消费者只消费一个队列，以此来解决消息顺序的问题，但是这就使得消费处理无法真正执行。<br>Kafka比传统消息系统有更强的顺序性保证，它使用主题的分区作为消息处理的并行单元。Kafka以分区作为最小的粒度，将每个分区分配给消费者组中不同的而且是唯一的消费者，并确保一个分区只属于一个消费者，即这个消费者就是这个分区的唯一读取线程。那么，只要分区的消息是有序的，消费者处理的消息顺序就有保证。每个主题有多个分区，不同的消费者处理不同的分区，所以Kafka不仅保证了消息的有序性，也做到了消费者的负载均衡。</li><li>分区的原则<br>（1）指定了patition，则直接使用；<br>（2）未指定patition但指定key，通过对key的value进行hash出一个patition<br>（3）patition和key都未指定，使用轮询选出一个patition。<br><strong>DefaultPartitioner类</strong></li></ol><pre><code class="highlight plaintext">public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);        int numPartitions = partitions.size();        if (keyBytes == null) {            int nextValue = nextValue(topic);            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);            if (availablePartitions.size() &gt; 0) {                int part = Utils.toPositive(nextValue) % availablePartitions.size();                return availablePartitions.get(part).partition();            } else {                // no partitions are available, give a non-available partition                return Utils.toPositive(nextValue) % numPartitions;            }        } else {            // hash the keyBytes to choose a partition            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;        }    }</code></pre><p>3）副本（Replication）<br>同一个partition可能会有多个replication（对应 server.properties 配置中的 default.replication.factor=N）。没有replication的情况下，一旦broker 宕机，其上所有 patition 的数据都不可被消费，同时producer也不能再将数据存于其上的patition。引入replication之后，同一个partition可能会有多个replication，而这时需要在这些replication之间选出一个leader，producer和consumer只与这个leader交互，其它replication作为follower从leader 中复制数据</p><p>4） 写入流程<br>producer写入消息流程如下：</p><ol><li>producer先从zookeeper的 "/brokers/…/state"节点找到该partition的leader</li><li>producer将消息发送给该leader</li><li>leader将消息写入本地log</li><li>followers从leader pull消息，写入本地log后向leader发送ACK</li><li>leader收到所有ISR中的replication的ACK后，增加HW（high watermark，最后commit 的offset）并向producer发送ACK</li></ol><h4 id="2、Broker-保存消息">2、Broker 保存消息</h4><p>1）存储方式<br>物理上把topic分成一个或多个patition（对应 server.properties 中的num.partitions=3配置），每个patition物理上对应一个文件夹（该文件夹存储该patition的所有消息和索引文件），如下：</p><pre><code class="highlight plaintext">[root @hsiehchou121 logs]$ lldrwxrwxr-x. 2 root root 4096 4月   6 14:37 first-0drwxrwxr-x. 2 root root 4096 4月   6 14:35 first-1drwxrwxr-x. 2 root root 4096 4月   6 14:37 first-2[root @hsiehchou121 logs]$ cd first-0[root @hsiehchou121 first-0]$ ll-rw-rw-r--. 1 root root 10485760 4月   6 14:33 00000000000000000000.index-rw-rw-r--. 1 root root     219 4月   6 15:07 00000000000000000000.log-rw-rw-r--. 1 root root 10485756 4月   6 14:33 00000000000000000000.timeindex-rw-rw-r--. 1 root root       8 4月   6 14:37 leader-epoch-checkpoint</code></pre><p>2）存储策略<br>无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据：</p><ol><li>基于时间：log.retention.hours=168</li><li>基于大小：log.retention.bytes=1073741824<br>需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。</li></ol><p>3）Zookeeper存储结构<br><img src="/medias/kafka%20zookeeper%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.PNG" alt="kafka zookeeper的存储结构"><br>注意：producer不在zk中注册，消费者在zk中注册</p><h4 id="3、Kafka消费过程分析">3、Kafka消费过程分析</h4><p>kafka提供了两套consumer API：高级Consumer API和低级API<br>1）消费模型<br>消息由生产者发布到Kafka集群后，会被消费者消费。消息的消费模型有两种：推送模型（push）和拉取模型（pull）</p><p>基于推送模型（push）的消息系统，由消息代理记录消费者的消费状态。消息代理在将消息推送到消费者后，标记这条消息为已消费，但这种方式无法很好地保证消息被处理。比如，消息代理把消息发送出去后，当消费进程挂掉或者由于网络原因没有收到这条消息时，就有可能造成消息丢失（因为消息代理已经把这条消息标记为已消费了，但实际上这条消息并没有被实际处理）。如果要保证消息被处理，消息代理发送完消息后，要设置状态为“已发送”，只有收到消费者的确认请求后才更新为“已消费”，这就需要消息代理中记录所有的消费状态，这种做法显然是不可取的</p><p>Kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序读取每个分区的消息。如下图所示，有两个消费者（不同消费者组）拉取同一个主题的消息，消费者A的消费进度是3，消费者B的消费进度是6。消费者拉取的最大上限通过最高水位（watermark）控制，生产者最新写入的消息如果还没有达到备份数量，对消费者是不可见的。这种由消费者控制偏移量的优点是：消费者可以按照任意的顺序消费消息。比如，消费者可以重置到旧的偏移量，重新处理之前已经消费过的消息；或者直接跳到最近的位置，从当前的时刻开始消费</p><p>在一些消息系统中，消息代理会在消息被消费之后立即删除消息。如果有不同类型的消费者订阅同一个主题，消息代理可能需要冗余地存储同一消息；或者等所有消费者都消费完才删除，这就需要消息代理跟踪每个消费者的消费状态，这种设计很大程度上限制了消息系统的整体吞吐量和处理延迟。Kafka的做法是生产者发布的所有消息会一致保存在Kafka集群中，不管消息有没有被消费。用户可以通过设置保留时间来清理过期的数据，比如，设置保留策略为两天。那么，在消息发布之后，它可以被不同的消费者消费，在两天之后，过期的消息就会自动清理掉</p><p>2）高级API</p><ol><li>高级API优点<br>高级API 写起来简单<br>不需要自行去管理offset，系统通过zookeeper自行管理。<br>不需要管理分区，副本等情况，.系统自动管理。<br>消费者断线会自动根据上一次记录在zookeeper中的offset去接着获取数据（默认设置1分钟更新一下zookeeper中存的offset）<br>可以使用group来区分对同一个topic 的不同程序访问分离开来（不同的group记录不同的offset，这样不同程序读取同一个topic才不会因为offset互相影响）</li><li>高级API缺点<br>不能自行控制offset（对于某些特殊需求来说）<br>不能细化控制如分区、副本、zk等</li></ol><p>3）低级API</p><ol><li>低级 API 优点<br>能够让开发者自己控制offset，想从哪里读取就从哪里读取。<br>自行控制连接分区，对分区自定义进行负载均衡<br>对zookeeper的依赖性降低（如：offset不一定非要靠zk存储，自行存储offset即可，比如存在文件或者内存中）</li><li>低级API缺点<br>太过复杂，需要自行控制offset，连接哪个分区，找到分区leader 等。</li></ol><p>4）消费者组<br>消费者是以consumer group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。每个分区在同一时间只能由group中的一个消费者读取，但是多个group可以同时消费这个partition。在图中，有一个由三个消费者组成的group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者</p><p>在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。另外，如果一个消费者失败了，那么其他的group成员会自动负载均衡读取之前失败的消费者读取的分区</p><p>5）消费方式<br>consumer采用pull（拉）模式从broker中读取数据</p><p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息</p><p>对于Kafka而言，pull模式更合适，它可简化broker的设计，consumer可自主控制消费消息的速率，同时consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义</p><p>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）</p><p>6） 消费者组案例</p><ol><li>需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费</li><li>案例实操<br>（1）在hsiehchou121、hsiehchou122上修改/root/hd/kafka/config/consumer.properties配置文件中的group.id属性为任意组名</li></ol><p>[root@hsiehchou122 config]$ vi consumer.properties<br>group.id=root</p><p>规划：hsiehchou121生产者，hsiehchou122消费者，hsiehchou123消费者<br>（2）在hsiehchou122、hsiehchou123上分别启动消费者</p><pre><code class="highlight plaintext">[root@hsiehchou122 kafka]$ ./bin/kafka-console-consumer.sh --bootstrap-server hsiehchou121:9092 --topic second --consumer.config config/consumer.properties[root@hsiehchou123 kafka]$ ./bin/kafka-console-consumer.sh --bootstrap-server hsiehchou121:9092 --topic second --consumer.config config/consumer.properties</code></pre><p>（3）在hsiehchou121上启动生产者</p><pre><code class="highlight plaintext">[root@hsiehchou121 kafka]$ bin/kafka-console-producer.sh --broker-list hsiehchou121:9092 --topic first&gt;hello world</code></pre><p>（4）查看hsiehchou122和hsiehchou123的接收者<br>同一时刻只有一个消费者接收到消息</p><h3 id="八、-Kafka-API实战">八、 Kafka API实战</h3><h4 id="1、-环境准备">1、 环境准备</h4><p>1）在eclipse中创建一个java工程<br>2）在工程的根目录创建一个lib文件夹<br>3）解压kafka安装包，将安装包libs目录下的jar包拷贝到工程的lib目录下，并build path<br>4）启动zk和kafka集群，在kafka集群中打开一个消费者</p><pre><code class="highlight plaintext">[root@hsiehchou121 kafka]$ bin/kafka-console-consumer.sh --zookeeper hsiehchou121:2181 --topic first</code></pre><h4 id="2、Kafka生产者Java-API">2、Kafka生产者Java API</h4><p>1）<strong>创建生产者</strong><br><strong>Producer1 类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.kafka_producer;import java.util.Properties;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerRecord;/** * kafka * @author hsiehchou */public class Producer1 {public static void main(String[] args) {//1.配置生产者的属性Properties prop = new Properties();//2.参数配置//kafka节点的地址，Kafka服务端的主机名和端口号prop.put("bootstrap.servers", "192.168.116.121:9092");//发送消息是否等待应答，等待所有副本节点的应答prop.put("acks", "all");//配置发送消息失败重试，消息发送最大尝试次数prop.put("retries", "0");//配置批量处理消息的大小，一批消息处理大小prop.put("batch.size", "16384");//配置批量处理数据的延迟，请求延时prop.put("linger.ms", "1");//配置内存缓冲区的大小，发送缓存区内存大小prop.put("buffer.memory", 33445552);//消息在发送前必须要序列化，key序列化prop.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");prop.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");//3.实例化producerKafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(prop);//4.发送消息for (int i = 0; i &lt; 50; i++) {producer.send(new ProducerRecord&lt;String, String&gt;("first", Integer.toString(i), "hello world-" + i));}//5.关闭资源producer.close();}}</code></pre><p>[root@hsiehchou122 kafka]# ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--topic</code> first <code>--consumer.config</code> config/consumer.properties<br>hello world-0<br>hello world-1<br>hello world-2<br>hello world-3<br><code>......</code><br>hello world-49</p><p>2）创建生产者带回调函数<br><strong>Producer2类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.kafka_producer;import java.util.Properties;import org.apache.kafka.clients.producer.Callback;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;public class Producer2 {public static void main(String[] args) {//1.配置生产者的属性Properties prop = new Properties();//2.参数配置//kafka节点的地址，Kafka服务端的主机名和端口号prop.put("bootstrap.servers", "192.168.116.121:9092");//发送消息是否等待应答，等待所有副本节点的应答prop.put("acks", "all");//配置发送消息失败重试，消息发送最大尝试次数prop.put("retries", "0");//配置批量处理消息的大小，一批消息处理大小prop.put("batch.size", "16384");//配置批量处理数据的延迟，请求延时prop.put("linger.ms", "1");//配置内存缓冲区的大小，发送缓存区内存大小prop.put("buffer.memory", 33445552);//消息在发送前必须要序列化，key序列化prop.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");prop.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");//3.实例化producerKafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(prop);//4.发送消息for (int i = 0; i &lt; 50; i++) {producer.send(new ProducerRecord&lt;String, String&gt;("first", Integer.toString(i), "hello world-" + i), new Callback() {public void onCompletion(RecordMetadata metadata, Exception exception) {//如果metadata不为null，拿到当前的数据偏移量与分区if(metadata != null) {System.out.println(metadata.topic() + "----" + metadata.offset() + "----" + metadata.partition());}}});}//5.关闭资源producer.close();}}</code></pre><p>[root@hsiehchou122 kafka]# ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--topic</code> three <code>--consumer.config</code> config/consumer.properties</p><p>控制台输出：<br>first<code>----</code>00<code>----</code>0<br>first<code>----</code>01<code>----</code>0<br>first<code>----</code>02<code>----</code>0<br>first<code>----</code>03<code>----</code>0<br><code>......</code><br>first<code>----</code>48<code>----</code>0<br>first<code>----</code>49<code>----</code>0</p><p>3）自定义分区生产者<br><strong>Partition1 类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.kafka_producer;import java.util.Map;import org.apache.kafka.clients.producer.Partitioner;import org.apache.kafka.common.Cluster;/** * 自定义分区 * @author hsiehchou */public class Partition1 implements Partitioner{//设置public void configure(Map&lt;String, ?&gt; configs) {}//分区逻辑，控制分区public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {return 2;}//释放资源public void close() {}}</code></pre><p><strong>Producer2类中新增</strong></p><pre><code class="highlight plaintext">prop.put("partitioner.class", "com.hsiehchou.kafka.kafka_producer.Partition1");</code></pre><p>[root@hsiehchou122 kafka]# ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--topic</code> three <code>--consumer.config</code> config/consumer.properties<br>first-----1----2<br>first-----1----2<br>first-----1----2<br><code>......</code><br>first-----1----2<br>first-----1----2</p><h4 id="3、Kafka消费者Java-API">3、Kafka消费者Java API</h4><p><strong>Consumer1 类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.kafka_consumer;import java.util.Arrays;import java.util.Properties;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;/** * 创建消费者 * @author hsiehchou */public class Consumer1 {public static void main(String[] args) {//配置消费者属性Properties prop = new Properties();//2.参数配置//kafka节点的地址，Kafka服务端的主机名和端口号prop.put("bootstrap.servers", "192.168.116.122:9092");//配置消费者组prop.put("group.id", "g1");//配置是否自动确认offsetprop.put("enable.auto.commit", "true");//序列化prop.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");prop.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");//3.实例消费者，定义consumerfinal KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(prop);//释放资源//5.释放资源，线程安全Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() {public void run() {if(consumer != null) {consumer.close();}}}));//订阅消息consumer.subscribe(Arrays.asList("first"));//4.拉消息 推push 拉pollwhile(true) {ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);//遍历消息for(ConsumerRecord&lt;String, String&gt; record:records) {System.out.println(record.topic() + "--------" + record.value());}}}}</code></pre><p><strong>Producer1 类</strong><br>跟之前的一样，此处省略</p><p><strong>strong text</strong>启动kafka集群<br>[root@hsiehchou121 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;<br>[root@hsiehchou122 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;<br>[root@hsiehchou123 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;<br>分别对Consumer1类和Producer1类依次进行Run  as  Java Application</p><p><strong>控制台输出</strong><br>first--------1556248624834-hello world-0<br>first--------1556248625017-hello world-1<br>first--------1556248625017-hello world-2<br>first--------1556248625017-hello world-3<br><code>......</code><br>first--------1556248625021-hello world-48<br>first--------1556248625021-hello world-49</p><h3 id="九、Kafka-producer拦截器-interceptor">九、Kafka producer拦截器(interceptor)</h3><h4 id="1、拦截器原理">1、拦截器原理</h4><p>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑</p><p>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如<strong>修改消息</strong>等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是<strong>org.apache.kafka.clients.producer.ProducerInterceptor</strong>，其定义的方法包括：<br>1）<strong>configure(configs)</strong><br>获取配置信息和初始化数据时调用</p><p>2）<strong>onSend(ProducerRecord)</strong><br>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。<strong>用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区</strong>，否则会影响目标分区的计算</p><p>3）<strong>onAcknowledgement(RecordMetadata, Exception)</strong><br><strong>该方法会在消息被应答或消息发送失败时调用</strong>，并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率</p><p>4）<strong>close</strong><br><strong>关闭interceptor，主要用于执行一些资源清理工作</strong><br>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外<strong>倘若指定了多个interceptor，则producer将按照指定顺序调用它们</strong>，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意</p><h4 id="2、拦截器案例">2、拦截器案例</h4><p>1）需求：<br>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。<br>2）案例实操<br>（1）增加时间戳拦截器<br><strong>TimeInterceptor 类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.interceptor;import java.util.Map;import org.apache.kafka.clients.producer.ProducerInterceptor;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;public class TimeInterceptor implements ProducerInterceptor&lt;String, String&gt; {//配置信息public void configure(Map&lt;String, ?&gt; configs) {}//业务逻辑public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) {return new ProducerRecord&lt;String, String&gt;(record.topic(), record.partition(),record.timestamp(),record.key(),System.currentTimeMillis() + "-" + record.value());}//发送失败调用public void onAcknowledgement(RecordMetadata metadata, Exception exception) {}//关闭资源public void close() {}}</code></pre><p>（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器<br><strong>CounterInterceptor 类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.interceptor;import java.util.Map;import org.apache.kafka.clients.producer.ProducerInterceptor;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;public class CounterInterceptor implements ProducerInterceptor&lt;String, String&gt; {private int errorCounter = 0;private int successCounter = 0;public void configure(Map&lt;String, ?&gt; configs) {}public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) {return record;}public void onAcknowledgement(RecordMetadata metadata, Exception exception) {//统计成功和失败的次数if(exception == null) {successCounter++;}else {errorCounter++;}}public void close() {//保存结果System.out.println("Successful sent:" + successCounter);System.out.println("Failed sent:" + errorCounter);}}</code></pre><p><strong>在Producer1类中增加</strong></p><pre><code class="highlight plaintext">//拦截器ArrayList&lt;String&gt; inList = new ArrayList&lt;String&gt;(); inList.add("com.hsiehchou.kafka.interceptor.TimeInterceptor");inList.add("com.hsiehchou.kafka.interceptor.CounterInterceptor");prop.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, inList);</code></pre><p>测试一：<br>[root@hsiehchou122 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;</p><p><code>--from beginning</code> 是从头开始消费，不加则是消费当前正在发送到该topic的消息<br>[root@hsiehchou123 kafka]#./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--topic</code> first <code>--from-beginning</code></p><p>测试二：<br>[root@hsiehchou122 kafka]# ./bin/kafka-server-start.sh config/server.properties &amp;</p><p>[root@hsiehchou122 kafka]#  ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou121:9092 <code>--topic</code> first <code>--consumer.config</code> config/consumer.properties<br>结果：<br>1556253447912-hello world-0<br>1556253448100-hello world-1<br>1556253448100-hello world-2<br>1556253448100-hello world-3<br>1556253448100-hello world-4<br><code>......</code><br>1556253448100-hello world-12<br>1556253448100-hello world-13<br>1556253448104-hello world-14<br>1556253448104-hello world-15<br>1556253448104-hello world-16<br><code>......</code><br>1556253448104-hello world-48<br>1556253448104-hello world-49</p><p>Successful sent:50<br>Failed sent:0</p><h3 id="十、Kafka-Streams">十、Kafka Streams</h3><h4 id="1、概述">1、概述</h4><p>1）Kafka Streams<br>Kafka Streams。Apache Kafka开源项目的一个组成部分。是一个功能强大，易于使用的库。用于在Kafka上构建高可分布式、拓展性，容错的应用程序</p><p>2）Kafka Streams特点</p><ol><li>功能强大<br>高扩展性，弹性，容错</li><li>轻量级<br>无需专门的集群<br>一个库，而不是框架</li><li>完全集成<br>100%的Kafka 0.10.0版本兼容<br>易于集成到现有的应用程序</li><li>实时性<br>毫秒级延迟<br>并非微批处理<br>窗口允许乱序数据<br>允许迟到数据</li></ol><p>3）为什么要有Kafka Stream<br>当前已经有非常多的流式处理系统，最知名且应用最多的开源流式处理系统有Spark Streaming和Apache Storm。Apache Storm发展多年，应用广泛，提供记录级别的处理能力，当前也支持SQL on Stream。而Spark Streaming基于Apache Spark，可以非常方便与图计算，SQL处理等集成，功能强大，对于熟悉其它Spark应用开发的用户而言使用门槛低。另外，目前主流的Hadoop发行版，如Cloudera和Hortonworks，都集成了Apache Storm和Apache Spark，使得部署更容易</p><p>既然Apache Spark与Apache Storm拥用如此多的优势，那为何还需要Kafka Stream呢？主要有如下原因<br>第一，Spark和Storm都是流式处理框架，而Kafka Stream提供的是一个基于Kafka的流式处理类库。框架要求开发者按照特定的方式去开发逻辑部分，供框架调用。开发者很难了解框架的具体运行方式，从而使得调试成本高，并且使用受限。而Kafka Stream作为流式处理类库，直接提供具体的类给开发者调用，整个应用的运行方式主要由开发者控制，方便使用和调试</p><p>第二，虽然Cloudera与Hortonworks方便了Storm和Spark的部署，但是这些框架的部署仍然相对复杂。而Kafka Stream作为类库，可以非常方便的嵌入应用程序中，它对应用的打包和部署基本没有任何要求</p><p>第三，就流式处理系统而言，基本都支持Kafka作为数据源。例如Storm具有专门的kafka-spout，而Spark也提供专门的spark-streaming-kafka模块。事实上，Kafka基本上是主流的流式处理系统的标准数据源。换言之，大部分流式系统中都已部署了Kafka，此时使用Kafka Stream的成本非常低</p><p>第四，使用Storm或Spark Streaming时，需要为框架本身的进程预留资源，如Storm的supervisor和Spark on YARN的node manager。即使对于应用实例而言，框架本身也会占用部分资源，如Spark Streaming需要为shuffle和storage预留内存。但是Kafka作为类库不占用系统资源</p><p>第五，由于Kafka本身提供数据持久化，因此Kafka Stream提供滚动部署和滚动升级以及重新计算的能力</p><p>第六，由于Kafka Consumer Rebalance机制，Kafka Stream可以在线动态调整并行度</p><h4 id="2、Kafka-Stream数据清洗案例">2、Kafka Stream数据清洗案例</h4><p>1）需求：<br>实时处理单词带有”&gt;&gt;&gt;”前缀的内容。例如输入”itstar&gt;&gt;&gt;ximenqing”，最终处理成“ximenqing”<br>2）需求分析：<br>3）案例实操</p><ol><li>创建一个工程，并添加jar包</li><li>创建主类<br><strong>Application类</strong></li></ol><pre><code class="highlight plaintext">package com.hsiehchou.kafka.kafka_stream;import java.util.Properties;import org.apache.kafka.streams.KafkaStreams;import org.apache.kafka.streams.StreamsConfig;import org.apache.kafka.streams.Topology;import org.apache.kafka.streams.processor.Processor;import org.apache.kafka.streams.processor.ProcessorSupplier;/** *  * 需求：对数据进行清洗操作 * 思路：xie-hs把-清洗掉 * @author hsiehchou */public class Application {public static void main(String[] args) {//1.定义主题 发送到 另外一个主题中 数据清洗String oneTopic = "t1";String twoTopic = "t1";//2.设置参数Properties prop = new Properties();prop.put(StreamsConfig.APPLICATION_ID_CONFIG, "logProcessor");prop.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.116.121:9092,192.168.116.122:9092,192.168.116.123:9092");//3.实例化对象StreamsConfig config = new StreamsConfig(prop);//4. 流计算 拓扑Topology builder = new Topology(); //5.定义kafka组件数据源builder.addSource("Source", oneTopic).addProcessor("Processor", new ProcessorSupplier&lt;byte[], byte[]&gt;() {public Processor&lt;byte[], byte[]&gt; get() {return new LogProcesser();}//从哪里来}, "Source")//到哪里去.addSink("Sink", twoTopic, "Processor");//6.实例化KafkaStreamKafkaStreams kafkaStreams = new KafkaStreams(builder, prop);kafkaStreams.start();}}</code></pre><p><strong>LogPRocessor类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.kafka.kafka_stream;import org.apache.kafka.streams.processor.Processor;import org.apache.kafka.streams.processor.ProcessorContext;public class LogProcesser implements Processor&lt;byte[], byte[]&gt;{private ProcessorContext context;//初始化public void init(ProcessorContext context) {//传输this.context = context;}//业务逻辑public void process(byte[] key, byte[] value) {//1.拿到消息数据String message = new String(value);//2.如果包含 -  去除if(message.contains("-")) {//3.把-去掉之后去掉左侧数据message = message.split("-")[1];//4.发送数据context.forward(key, message.getBytes());}}//释放资源public void close() {}}</code></pre><p>[root@hsiehchou121 kafka]#./bin/kafka-topics.sh <code>--zookeeper</code> hsiehchou121:2181 <code>--create</code> <code>--replication-factor</code> 3 <code>--partitions</code> 1 <code>--topic</code> t1</p><p>[root@hsiehchou122 kafka]# ./bin/kafka-console-consumer.sh <code>--bootstrap-server</code> hsiehchou122:9092 <code>--topic</code> t2 <code>--from-beginning</code> -<code>-consumer.config</code> config/consumer.properties</p><p>[root@hsiehchou121 kafka]# ./bin/kafka-console-producer.sh <code>--broker-list</code> hsiehchou121:9092 <code>--topic</code> t1</p><h3 id="十一、CDH搭建：">十一、CDH搭建：</h3><p><a href="https://juejin.im/post/5a55814e518825734859d69a">https://juejin.im/post/5a55814e518825734859d69a</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker入门操作</title>
      <link href="/2019/04/24/docker_ru_men_cao_zuo/"/>
      <url>/2019/04/24/docker_ru_men_cao_zuo/</url>
      
        <content type="html"><![CDATA[<p><strong>docker</strong><br>2013年发布</p><h3 id="一、环境配置难题">一、环境配置难题</h3><p>开发环境运行没有问题，生产不能用，因为生产缺乏某些组件</p><p>换一台机器，需要重新配置一遍</p><p>能不能从根本上解决问题：安装的时候，把原始环境，一模一样地安装一遍</p><h3 id="二、虚拟机">二、虚拟机</h3><p>带环境安装的一种解决方案</p><p>缺点：<br>占用资源多：虚拟机本身需要消耗资源，程序1MB，环境几百MB</p><p>冗余步骤多：虚拟机是完整的操作系统，一些系统级别的操作步骤，无法跳过，比如用户登录</p><p>启动慢：启动操作系统要多久，启动虚拟机就要多久</p><h3 id="三、Linux容器">三、Linux容器</h3><p>针对虚拟机的缺点，Linux发展出另外的一种虚拟化技术：Linux容器</p><p>Linux容器不是模拟完整的操作系统，而是对进程进行隔离，即在正常进程的外面，套一个保护层，对于容器里面的进程来说，它接触到的资源都是虚拟的，实现与底层系统的隔离</p><p>优点：<br>启动快：容器里面的应用，直接就是底层系统中的一个进程，启动容器相当于启动本机的进程。而不是启动操作系统</p><p>占用资源少：容器只占用需要的资源，不占用没有用到的资源</p><p>体积小：只包含用到的组件，而虚拟机包含了整个操作系统。所以容器文件比虚拟机文件小的多</p><h3 id="四、Docker是什么">四、Docker是什么</h3><p>Docker属于Linux容器的一种封装，提供了简单易用的容器使用接口</p><p>Docker将应用程序与该程序的依赖，打包到一个文件里面，运行这个文件，就会产生一个虚拟容器</p><p>程序在虚拟容器中运行，就好像运行在真正的物理机上一样</p><p>Docker提供版本管理、复制、分享、修改等功能，就像管理普通代码一样管理Docker容器</p><h3 id="五、Docker的用途">五、Docker的用途</h3><p>Docker的主要用途，目前有三大类</p><h4 id="1、提供一次性的环境">1、提供一次性的环境</h4><p>本地测试他人的软件程序</p><h4 id="2、提供弹性的云服务">2、提供弹性的云服务</h4><p>Docker容器可以随开随关，很适合动态的扩容和缩容</p><h4 id="3、组建微服务架构">3、组建微服务架构</h4><p>通过多个容器，一台机器可以跑多个服务，在本机就可以模拟出微服务架构</p><h3 id="六、Docker安装">六、Docker安装</h3><h4 id="1、Linux安装">1、Linux安装</h4><p>Docker要求CentOS内核版本高于3.10<br>uname -r 查看内核版本</p><p>安装必要的系统工具：<br>yum install -y yum-utils device-mapper-persistent-data lvm2</p><p>添加软件源信息：<br>yum-config-manager --add-repo <a href="http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a></p><p>更新 yum 缓存：<br>yum makecache fast</p><p>安装 Docker-ce：<br>yum -y install docker-ce</p><p>启动 Docker 后台服务<br>systemctl start docker</p><p>测试运行 hello-world<br>docker run hello-world</p><p>看到hello from docker证明安装成功</p><h4 id="2、windows安装">2、windows安装</h4><p>win10专业版，直接安装 docker for windows 即可</p><p>win10普通版、win7 win8 ,需要安装 docker tool box</p><p>toolbox 配置：<br>右键  Docker Quickstart Terminal<br>“C:\Program Files\Git\bin\bash.exe” <code>--login</code> -i “C:\Program Files\Docker Toolbox\start.sh”<br>把这个位置配成你本机的git位置修改后面这个脚本</p><p>DOCKER_MACHINE=“D:\Docker Toolbox\docker-machine.exe”</p><p>STEP=“Looking for vboxmanage.exe”<br>VBOXMANAGE=“C:\Program Files\Oracle\VirtualBox\VBoxManage.exe”</p><pre><code class="highlight plaintext">#if [ ! -z "$VBOX_MSI_INSTALL_PATH" ]; then#VBOXMANAGE="${VBOX_MSI_INSTALL_PATH}VBoxManage.exe"#else#VBOXMANAGE="${VBOX_INSTALL_PATH}VBoxManage.exe"#fi</code></pre><h3 id="七、image文件">七、image文件</h3><p>Docker把应用程序及其依赖，打包在image文件里面，只有通过image文件，才能生成docker容器</p><p>Docker可以根据image文件生成容器实例</p><p>image文件可以继承。在实际开发中，一个image文件往往通过继承另一个image文件，加上一些个性化的设置而生成</p><p>启动容器<br>docker run hello-world</p><p>列出所有image文件<br>docker image ls</p><p>删除image文件<br>docker image rm image文件名</p><p>使用docker-machine stop default停掉Docker的虚拟机<br>使用docker-machine start default开启Docker的虚拟机</p><h3 id="八、配置阿里云docker镜像加速器">八、配置阿里云docker镜像加速器</h3><ol><li><p>注册阿里云，获得专属加速器地址</p></li><li><p>hsiehchou@DESKTOP-KJDN870 MINGW64 /d/Docker Toolbox<br>$ docker-machine ssh default<br>docker@default:~$ sudo sed -i “s|EXTRA_ARGS=‘|EXTRA_ARGS=’–regis<br>try-mirror=<a href="https://%60">https://`</a>********`.mirror.aliyuncs.com |g” /var/lib/boot<br>2docker/profile<br>docker@default:~$ exit</p></li><li><p>hsiehchou@DESKTOP-KJDN870 MINGW64 /d/Docker Toolbox<br>$ docker-machine restart default</p></li></ol><h3 id="九、安装redis">九、安装redis</h3><h4 id="1、搜索镜像">1、搜索镜像</h4><p>docker search redis</p><h4 id="2、拉取镜像">2、拉取镜像</h4><p>docker pull redis</p><h4 id="3、启动redis">3、启动redis</h4><p>docker run <code>--name</code> myredis -p 6379:6379 -d redis redis-server</p><p>-d表示后台运行</p><p>-p表示端口号，左边的6379表示win10系统端口考，右边表示容器中redis端口号</p><p><code>--name</code>表示运行redis镜像的实例名称</p><h4 id="4、进入Image的小环境">4、进入Image的小环境</h4><p>docker exec -it  <code>COXTAINER ID</code> bash<br>redis-cli</p><p>hsiehchou@DESKTOP-KJDN870 MINGW64 /d/Docker Toolbox<br>$ docker run <code>--name</code> myredis12 -p 6379:6379 -d redis redis-server<br>9e37ae7338d05b83f666a95fe3677aa85b1481c8fa519a79e9008a5a5e9e909d</p><p>hsiehchou@DESKTOP-KJDN870 MINGW64 /d/Docker Toolbox<br>$ docker ps<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES<br>9e37ae7338d0        redis               “docker-entrypoint.s”   5 seconds ago       Up 6 seconds        0.0.0.0:6379-&gt;6379/tcp   myredis12</p><p>hsiehchou@DESKTOP-KJDN870 MINGW64 /d/Docker Toolbox<br>$ docker exec -it 9e37ae7338d0 bash<br>root@9e37ae7338d0:/data# redis-cli<br>127.0.0.1:6379&gt;</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git简单操作</title>
      <link href="/2019/04/23/git_jian_dan_cao_zuo/"/>
      <url>/2019/04/23/git_jian_dan_cao_zuo/</url>
      
        <content type="html"><![CDATA[<p><strong>git 版本控制系统</strong><br>git是一个版本控制系统</p><h3 id="一、什么是版本控制系统">一、什么是版本控制系统</h3><h4 id="1、概念">1、概念</h4><p>版本控制是一种 记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统</p><p>（<em>）记录文件的所有历史变化<br>（</em>）随时可恢复到任何一个历史状态<br>（<em>）多人协作开发或修改<br>（</em>）错误恢复<br>（*）多功能并行开发</p><p>产品–&gt; 新加功能A —&gt; 单独拉一个新分支 --&gt; 开发完成后合并到master或者丢弃</p><h4 id="2、分类">2、分类</h4><p>本地版本控制系统<br>集中化版本控制系统SVN<br>分布式版本控制系统Git</p><h4 id="3、基本概念">3、基本概念</h4><p>repository ：存放所有文件及其历史信息<br>checkout：取出或切换到执行版本的文件<br>version：表示一个版本<br>tag：记录标识一个主要版本。2.0 3.0。用来标识一个特定的version</p><h4 id="4、不同版本控制系统优缺点">4、不同版本控制系统优缺点</h4><p><strong>本地</strong><br>优点：<br>简单，很多系统中内置。适合保存文本文件（配置文件、文章、信件）</p><p>缺点：<br>只支持管理少量的文件，不支持基于项目的管理<br>支持的文件类型单一<br>不支持网络，无法实现多人协作</p><p><strong>集中式版本控制系统</strong><br>优点：<br>适合多人团队协作开发<br>代码集中化管理</p><p>缺点：<br>单点故障<br>必须联网工作，无法单机工作</p><p>解决：<br><strong>分布式版本控制系统</strong><br>集合集中式版本控制系统优点<br>支持离线工作，先提交到本地仓库，再在某个时间上传到远程仓库<br>每个计算机都是一个完整仓库：强备份</p><h3 id="二、git分布式版本管理系统">二、git分布式版本管理系统</h3><p>由Linux创始人开发，作为Linux内核代码管理系统使用</p><p>Git在设计时考虑了很多方面设计目标</p><p>特点：<br>速度<br>简单的设计<br>对非线性开发模式的强力支持（允许上千个并行开发的分支）<br>完全分布式<br>有能力管理超大规模项目（挑战：速度和数据量）</p><p>Git原理：保存快照而非保存区别<br>Git保存时，相当于保存了当下所有文件的一个整体快照<br>所以，每个版本都是独立的。随时想取某一个版本，可以很快取出来</p><h3 id="三、安装git">三、安装git</h3><p>Git 的工作区域：</p><p>Git repository：：最终确定的文件保存到仓库，作为一个新的版本<br>staging area：暂存已经修改的文件<br>woking directory：工作目录</p><p>安装git<br>从 <a href="https://git-scm.com/">https://git-scm.com/</a> 下载windows版本git<br>全使用默认值，一直下一步</p><h3 id="四、创建仓库和基本操作">四、创建仓库和基本操作</h3><p>git安装好后，需要一些基本设置<br>设置用户名：git config --global <a href="http://user.name">user.name</a> “hsiehchou”<br>设置邮箱：git config --global user.email  “<a href="mailto:417952939@qq.com">417952939@qq.com</a>”</p><p>查看所有设置：git config --list</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git init</strong><br>Reinitialized existing Git repository in C:/Users/hsiehchou/Desktop/git demo/.git/</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ ll -a</strong><br>total 52<br>drwxr-xr-x 1 hsiehchou 197121 0 4月  24 12:45 ./<br>drwxr-xr-x 1 hsiehchou 197121 0 4月  24 10:44 …/<br>drwxr-xr-x 1 hsiehchou 197121 0 4月  24 12:46 .git/</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git status</strong><br>On branch master</p><p>No commits yet</p><p>nothing to commit (create/copy files and use “git add” to track)<br>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ touch README</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ vi README</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git status</strong><br>On branch master</p><p>No commits yet</p><p><strong>未追踪的文件</strong><br><strong>Untracked files</strong>:<br>(use “git add <code>&lt;file&gt;</code>…” to include in what will be committed)<br>README</p><p>nothing added to commit but untracked files present (use “git add” to track)</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>新建文件，默认是未追踪的文件<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git add README</strong><br>warning: LF will be replaced by CRLF in README.<br>The file will have its original line endings in your working directory.</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git status</strong><br>On branch master</p><p>No commits yet</p><p>Changes to be committed:<br>(use “git rm --cached <code>&lt;file&gt;</code>…” to unstage)<br>new file:   README</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>git add 提交到了暂存区域<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git commit -m “add README”</strong><br>[master (root-commit) f50e736] add README<br>1 file changed, 1 insertion(+)<br>create mode 100644 README</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>查看历史</strong><br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git log</strong><br>commit f50e7362b5573e9b9862f7fb65a9e3f6fa98913a (HEAD -&gt; master)<br>Author: hsiehchou <a href="mailto:417952939@qq.com">417952939@qq.com</a><br>Date:   Wed Apr 24 12:52:51 2019 +0800<br>add README</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>修改文件</strong><br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ vim README</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>检测到被修改了</strong><br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git status</strong><br>On branch master<br>Changes not staged for commit:<br>(use “git add <code>&lt;file&gt;</code>…” to update what will be committed)<br>(use “git checkout – <code>&lt;file&gt;</code>…” to discard changes in working directory)</p><p>modified:   README</p><p>no changes added to commit (use “git add” and/or “git commit -a”)</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>提交到仓库</strong><br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git commit -a -m “modify README”</strong><br>warning: LF will be replaced by CRLF in README.<br>The file will have its original line endings in your working directory<br>[master 278ec6a] modify README<br>1 file changed, 1 insertion(+)</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>删除文件</strong><br>rm README<br>git rm README<br>git commit -m “delete README”</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ rm README</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git rm README</strong><br>rm ‘README’</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git commit -m “delete README”</strong><br>[master b82ec4f] delete README<br>1 file changed, 2 deletions(-)<br>delete mode 100644 README</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br><strong>checkout 某个版本</strong><br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git log</strong><br>commit b82ec4f7ccf718abac6dc630b7049618d179418f (HEAD -&gt; master)<br>Author: hsiehchou <a href="mailto:417952939@qq.com">417952939@qq.com</a><br>Date:   Wed Apr 24 12:56:45 2019 +0800</p><p>delete README</p><p>commit 278ec6a869f73af71539785f6893259726f9902e<br>Author: hsiehchou <a href="mailto:417952939@qq.com">417952939@qq.com</a><br>Date:   Wed Apr 24 12:56:00 2019 +0800</p><p>modify README</p><p>commit f50e7362b5573e9b9862f7fb65a9e3f6fa98913a<br>Author: hsiehchou <a href="mailto:417952939@qq.com">417952939@qq.com</a><br>Date:   Wed Apr 24 12:52:51 2019 +0800</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo ((b82ec4f…))<br><strong>$ git checkout 278ec6a869f73af71539785f6893259726f9902e</strong><br>Previous HEAD position was b82ec4f delete README<br>HEAD is now at 278ec6a modify README</p><p>You are in ‘detached HEAD’ state. You can look around, make experimental<br>changes and commit them, and you can discard any commits you make in this<br>state without impacting any branches by performing another checkout.</p><p>If you want to create a new branch to retain commits you create, you may<br>do so (now or later) by using -b with the checkout command again. Example:</p><p>git checkout -b <code>&lt;new-branch-name&gt;</code></p><p>HEAD is now at 278ec6a modify README</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo ((278ec6a…))<br><strong>$ ll</strong><br>total 1<br>-rw-r–r-- 1 hsiehchou 197121 22 4月  24 12:58 README</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo ((278ec6a…))<br><strong>$ cat README</strong><br>Hello World!<br>fsdggd</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo ((278ec6a…))<br><strong>$ git checkout master</strong><br>Previous HEAD position was 278ec6a modify README<br>Switched to branch ‘master’</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ ll</strong><br>total 0</p><h3 id="五、git远程仓库">五、git远程仓库</h3><p>实现代码共享<br>远程仓库实际保存了本地.git文件夹下的东西，内容几乎一样<br>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ touch README2</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ vim README2</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git add README2</strong><br>warning: LF will be replaced by CRLF in README2.<br>The file will have its original line endings in your working directory</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git commit -a -m “README2”</strong><br>[master 0c4f333] README2<br>1 file changed, 1 insertion(+)<br>create mode 100644 README2</p><p><strong>git 远程仓库访问协议</strong>：<br>ssh协议<br>git协议<br>http https协议：一般用于开源项目</p><p>常用远程仓库实现：<br>1、github<br>2、自己搭建git仓库服务器 gitlab、码云</p><p>举例：在自己的github中，关联本地仓库<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ cd ~/.ssh</strong><br>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/.ssh<br><strong>$ ll</strong><br>total 9<br>-rw-r–r-- 1 hsiehchou 197121 1823 4月  15 23:35 id_rsa<br>-rw-r–r-- 1 hsiehchou 197121  398 4月  15 23:35 id_rsa.pub<br>-rw-r–r-- 1 hsiehchou 197121 1197 4月  16 14:09 known_hosts</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/.ssh<br><strong>$ cat id_rsa.pub</strong></p><p><strong>创建公钥</strong><br>ssh-keygen -t rsa -C "<a href="mailto:417952939@qq.com">417952939@qq.com</a>"命令</p><p>测试是否能够正常连接github<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ ssh -T <a href="mailto:git@github.com">git@github.com</a></strong><br>Hi hsiehchou! You’ve successfully authenticated, but GitHub does not provide shell access.</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git remote add origin <a href="mailto:git@github.com">git@github.com</a>:hsiehchou/git-test.git</strong></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ ll</strong><br>total 1<br>-rw-r–r-- 1 root 197121 15 4月  21 22:13 README2</p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++<br>hsiehchou@DESKTOP-KJDN870 MINGW64 ~/Desktop/git demo (master)<br><strong>$ git push -u origin master</strong><br>Enumerating objects: 11, done.<br>Counting objects: 100% (11/11), done.<br>Delta compression using up to 4 threads<br>Compressing objects: 100% (4/4), done.<br>Writing objects: 100% (11/11), 826 bytes | 103.00 KiB/s, done.<br>Total 11 (delta 0), reused 0 (delta 0)<br>To <a href="http://github.com">github.com</a>:hsiehchou/git-test.git</p><ul><li>[new branch]      master -&gt; master<br>Branch ‘master’ set up to track remote branch ‘master’ from ‘origin’.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop HA和HBase HA</title>
      <link href="/2019/04/22/hadoop_ha_he_hbase_ha/"/>
      <url>/2019/04/22/hadoop_ha_he_hbase_ha/</url>
      
        <content type="html"><![CDATA[<p><strong>Hadoop  HBase HA</strong></p><p>保证所有的服务器时间都相同</p><h3 id="一、Hadoop-HA">一、Hadoop HA</h3><p><strong>HDFS HA</strong></p><p>/root/hd/hadoop-2.8.4/etc/hadoop 下是所有hadoop配置文件</p><h4 id="1、core-site-xml">1、core-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;  &lt;value&gt;hsiehchou123:2181,hsiehchou124:2181&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/root/hd/hadoop-2.8.4/tmp&lt;/value&gt;:&lt;/property&gt;&lt;/configuration&gt;</code></pre><h4 id="2、hdfs-site-xml">2、hdfs-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;hsiehchou121:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;hsiehchou122:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;hsiehchou121:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;hsiehchou122:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://hsiehchou123:8485;hsiehchou124:8485/mycluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_dsa&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><p>NameNode节点一般配置2台；<strong>qjournal</strong>------ journal节点一般配置3台<br>我这里开始只有四台，所以，journal节点我只分配了两台</p><h4 id="3、yarn-site-xml">3、yarn-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;  &lt;value&gt;yarncluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;  &lt;value&gt;rm1,rm2&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;  &lt;value&gt;hsiehchou121&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;  &lt;value&gt;hsiehchou122&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;  &lt;value&gt;hsiehchou123,hsiehchou124&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;  &lt;value&gt;32768&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;&lt;value&gt;32768&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;&lt;value&gt;4096&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;&lt;value&gt;24&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;&lt;value&gt;/tmp/yarn-logs&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre><p>scp -r  hadoop/ hsiehchou122:/root/hd/hadoop-2.8.4/etc<br>scp -r  hadoop/ hsiehchou123:/root/hd/hadoop-2.8.4/etc<br>scp -r  hadoop/ hsiehchou124:/root/hd/hadoop-2.8.4/etc</p><p>配置好后，分发到所有节点，启动ZooKeeper后<br><a href="http://start-all.sh">start-all.sh</a> 即可启动所有</p><h3 id="二、HBase-HA">二、HBase HA</h3><p>修改配置文件，分发到所有几点，启动即可<br>注意：要启动两个Master，其中一个需要手动启动</p><p>注意：Hbase安装时，需要对应Hadoop版本</p><p>hbase hbase-2.1.4  对应 hadoop  2.8.4</p><p>通常情况下，把Hadoop  core-site hdfs-site 拷贝到hbase conf下</p><p>修改 <a href="http://hbase-env.sh">hbase-env.sh</a><br>修改  hbase-site.xml</p><h4 id="1、hbase-env-sh">1、<a href="http://hbase-env.sh">hbase-env.sh</a></h4><p>export JAVA_HOME=/root/hd/jdk1.8.0_192</p><p>export HBASE_MANAGES_ZK=false<br>关闭hbase自带的zookeeper，使用集群zookeeper</p><h4 id="2、hbase-site-xml">2、hbase-site.xml</h4><pre><code class="highlight plaintext">&lt;configuration&gt;&lt;property&gt;&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;&lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt;&lt;name&gt;hbase.rootdir&lt;/name&gt;&lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt;&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;&lt;value&gt;hsiehchou123,hsiehchou124&lt;/value&gt; &lt;/property&gt; &lt;property&gt;&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;&lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt;&lt;name&gt;zookeeper.session.timeout&lt;/name&gt;&lt;value&gt;120000&lt;/value&gt; &lt;/property&gt; &lt;property&gt;&lt;name&gt;hbase.zookeeper.property.tickTime&lt;/name&gt;&lt;value&gt;6000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>启动HBase<br>需要从另一台服务器上单独启动Master<br>./hbase-daemon.sh start master</p><p>通过以下网站可以看到信息<br><a href="http://192.168.116.122:16010/master-status">http://192.168.116.122:16010/master-status</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop HA </tag>
            
            <tag> HBase HA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存数据库专题（MemCached和Redis）</title>
      <link href="/2019/04/18/nei_cun_shu_ju_ku_zhuan_ti_memcached_he_redis/"/>
      <url>/2019/04/18/nei_cun_shu_ju_ku_zhuan_ti_memcached_he_redis/</url>
      
        <content type="html"><![CDATA[<p><strong>内存数据库专题</strong><br>为什么要把数据存入内存？<br>快</p><p>常见的内存数据库：<br>MemCached：看成Redis前身，严格来说，MemCached不能叫数据库，只能叫缓存<br>不支持持久化。如果内存停电，数据丢失</p><p>Redis：内存数据库，支持持久化，支持HA</p><p>Oracle TimesTen</p><p>session一致性</p><p>MemCached + keepalive实现</p><h3 id="一、Memcached">一、Memcached</h3><h4 id="1、基本原理和体系架构">1、基本原理和体系架构</h4><p>（<em>）在内存中，维护了一张巨大的Hash表<br>（</em>）通过路由算法来决定数据存储的位置。—&gt; 客户端路由<br><img src="/medias/Memcached%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E5%92%8C%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.PNG" alt="Memcached基本原理和体系架构"></p><p>注意：默认，官方版本MemCached实例彼此不会进行通信</p><p>第三方版本可以实现通信</p><h4 id="2、安装配置MemCached">2、安装配置MemCached</h4><p>前提：<br>（1）gcc编译器<br>yum install gcc<br>gcc --version</p><p>（2）libevent库<br>tar -zxvf libevent-2.0.21-stable.tar.gz<br>cd libevent-2.0.21-stable<br>./configure <code>--prefix</code>=/root/hd/libevent<br>make<br>make install</p><p>tar -zxvf memcached-1.4.25.tar.gz<br>cd memcached-1.4.25</p><p>./configure <code>--prefix</code>=/root/hd/memcached <code>--with-libevent</code>=/root/hd/libevent<br>make<br>make install<br>cd bin/<br>./memcached -u root -d -m 128 -p 11211<br>./memcached -u root -d -m 128 -p 11212<br>./memcached -u root -d -m 128 -p 11213<br>ps -ef | grep memcached</p><p><strong>注意</strong>：<br>-u：root用户需要注明（其他用户可以不写）<br>-d：启动守护线程（在后天运行）<br>-m：占用多少内存<br>-p：运行在哪个端口</p><h4 id="3、操作MemCached">3、操作MemCached</h4><p>（*）命令行<br>telnet 192.168.116.121 11211</p><p>保存数据：<br>set 如果key存在，替换原来的值<br>add 如果key存在，返回错误</p><p>| set key1    |   0 |  0   | 4 |<br>| :-------- : |  :--------:| :------: | :------: |<br>| key名字 | 标识位 | 数据过期时间0表示不过期 | value的长度 |<br>abcd<br>get key1</p><p>统计命令<br>stats items<br>stats</p><pre><code class="highlight plaintext">package day1;import net.spy.memcached.MemcachedClient;import net.spy.memcached.internal.OperationFuture;import java.io.IOException;import java.io.Serializable;import java.net.InetSocketAddress;import java.util.ArrayList;import java.util.List;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;/** * java 操作Memcached */public class Demo1 {    public static void main(String[] args) throws Exception {    //hello();    //testGet();    //setStudent();        testSets() ;    }</code></pre><p>[root@hsiehchou121 memcached]# cd bin/<br>[root@hsiehchou121 bin]# ./memcached -u root -d -m 128 -p 11211<br>[root@hsiehchou121 bin]# ./memcached -u root -d -m 128 -p 11212<br>[root@hsiehchou121 bin]# ./memcached -u root -d -m 128 -p 11213</p><p><strong>插入数据</strong></p><pre><code class="highlight plaintext">public static void hello() throws Exception {       //连接到集群，set key       //建立MemcachedClient实例，指定Memcached服务器的IP地址和端口       MemcachedClient client = new MemcachedClient(new InetSocketAddress("192.168.116.121",11211));       Future&lt;Boolean&gt; f = client.set("key1", 0, "hello World");       if (f.get().booleanValue()){           client.shutdown();       }   }</code></pre><p>[root@hsiehchou121 ~]# telnet 192.168.116.121 11211<br>get key1</p><p><strong>查询数据</strong></p><pre><code class="highlight plaintext">public static void testGet() throws Exception{    //连接到集群，set key    //建立MemcachedClient实例，指定Memcached服务器的IP地址和端口    MemcachedClient client = new MemcachedClient(new InetSocketAddress("192.168.116.121",11211));    //按照key取值，不存在的话返回null    Object o = client.get("key1");    System.out.println("取到的值为： " + o);    client.shutdown();}</code></pre><p>取到的值为：hello World</p><p><strong>插入类</strong></p><pre><code class="highlight plaintext">public static void setStudent() throws  Exception{     //连接到集群，set key     //建立MemcachedClient实例，指定Memcached服务器的IP地址和端口     MemcachedClient client = new MemcachedClient(new InetSocketAddress("192.168.116.121",11211));     Future&lt;Boolean&gt; f = client.set("stu1", 0, new Student());     if (f.get().booleanValue()){         client.shutdown();     } }</code></pre><p>[root@hsiehchou121 ~]# telnet 192.168.116.121 11211<br>get stu1</p><p><strong>基于客户端的分布式插入数据</strong></p><pre><code class="highlight plaintext">public static void testSets() throws Exception{       //测试客户端路由算法       //构造每台Memcached服务器加入List       List&lt;InetSocketAddress&gt; list = new ArrayList&lt;&gt;();       list.add(new InetSocketAddress("192.168.116.121",11211));       list.add(new InetSocketAddress("192.168.116.121",11212));       list.add(new InetSocketAddress("192.168.116.121",11213));       //建立Memcached Client实例       MemcachedClient client = new MemcachedClient(list);       for (int i = 0; i &lt; 20; i++){           System.out.println("插入数据：" + i);           client.set("key"+i,0, "value"+i);//(key1,value1)(key2,value2)           Thread.sleep(1000);       }       client.shutdown();   }</code></pre><p>[root@hsiehchou121 ~]# telnet 192.168.116.121 11211<br>get key1<br>VALUE key1 0 6<br>value1<br>[root@hsiehchou121 ~]# telnet 192.168.116.121 11212<br>get key2<br>VALUE key2 0 6<br>value2<br>[root@hsiehchou121 ~]# telnet 192.168.116.121 11213<br>get key3<br>VALUE key3 0 6<br>value3</p><pre><code class="highlight plaintext">}class Student implements Serializable{}</code></pre><h4 id="4、MemCached路由算法">4、MemCached路由算法</h4><p>1）<strong>求余数hash算法</strong><br>用key做hash运算得到一个整数，根据余数路由<br>例如：服务器端有三台MemCached服务器<br>根据key，做hash运算<br>7%3=1，那么就路由到第2台服务器<br>6%3=0，那么路由到第1台服务器<br>5%3=2，那么路由到第3台服务器</p><p>优点：数据分布均衡在多台服务器中，适合大多数据需求<br>缺点：如果需要扩容或者有宕机的情况，会造成数据的丢失</p><p>2）<strong>一致性hash算法</strong><br><strong>基本原理</strong>：<br>key1  1-333 放在node1上<br>key2 334-666放在node2上<br>key3 667-1000放在hsiehchou121上</p><p><strong>一致性hash算法下扩容</strong><br>key1  1-333 放在node1上<br>key2 334-666放在node2上<br>key3 667-831放在hsiehchou121上<br><strong>key4 832-1000放在node4上</strong><br>如果扩容，增加一个新的节点，只影响扩容的节点，对其他节点不影响</p><p><strong>一致性hash算法下DOWN机</strong><br>key1  1-333 放在node1上<br>key2 334-666放在node2上<br>key3 667-1000放在hsiehchou121上<br>如果宕机，对key1 和 key2不产生影响，只对key3产生影响</p><h4 id="5、MemCached的主主复制和HA">5、MemCached的主主复制和HA</h4><p>1）Memcached主主复制<br><strong>架构图</strong></p><table><thead><tr><th style="text-align:center">主服务器</th><th style="text-align:center"></th><th style="text-align:center">主服务器</th></tr></thead><tbody><tr><td style="text-align:center">memcached</td><td style="text-align:center">&lt;-------&gt;</td><td style="text-align:center">memcached</td></tr></tbody></table><ol><li>安装具有复制功能的memcached版本<br>tar zxvf memcached-1.2.8-repcached-2.2.tar.gz<br>cd memcached-1.2.8-repcached-2.2<br>./configure <code>--prefix</code>=/root/hd/memcached_replication<br><code>--with-libevent</code>=/root/hd/libevent/ <code>--enable-replication</code><br>make<br>make install</li></ol><p><strong>出现以下错误</strong></p><pre><code class="highlight plaintext">memcached.c: 696: error: `IOV MAX` undeclared (first use in this function)memcached.c: 696: error: (Each undeclared identifier is reported only oncememcached.c: 696: error: for each function it appears in.)</code></pre><p><strong>解决办法</strong><br><strong>编辑memcached.c文件如下</strong><br>55 /* FreeBSD 4.x doesn’t have IOV_MAX exposed. */<br>56 #ifndef IOV_MAX<br>57 #if defined(<strong>FreeBSD</strong>) || defined(<strong>APPLE</strong>)<br>58 # define IOV_MAX 1024<br>59 #endif<br>60 #endif</p><p><strong>修改成如下形式</strong><br>55 /* FreeBSD 4.x doesn’t have IOV_MAX exposed. */<br>56 #ifndef IOV_MAX<br>57 //#if defined(<strong>FreeBSD</strong>) || defined(<strong>APPLE</strong>)<br>58 # define IOV_MAX 1024<br>59 //#endif<br>60 #endif</p><p>启动第一台MemCached，使用-x指定对端服务器的地址<br>./memcached -u root -d  -m 128 -x 192.168.116.121</p><p>启动第二台MemCached，使用-x指定对端服务器的地址<br>./memcached -u root -d  -m 128 -x 192.168.116.122</p><p><strong>出现以下错误</strong><br>./memcached: error while loading shared libraries: libevent-2.0.so.5: cannot open shared object file: No such file or directory</p><p><strong>解决办法</strong><br>查找 libevent-2.0.so.5<br>whereis libevent-2.0.so.5</p><p>使用ldd命令查看memcached命令，发现找不到<br>[root@hsiehchou121 bin]# ldd /root/hd/memcached-1.2.8-repcached-2.2/bin/memcached<br>linux-gate.so.1 =&gt; (0x00255000)<br>libevent-2.0.so.5 =&gt; not found<br>libc.so.6 =&gt; /lib/libc.so.6 (0x00110000)<br>/lib/ld-linux.so.2(0x003a4000)</p><p><strong>建立软连接</strong><br>ln -s /root/hd/libevent/lib/libevent-2.0.so.5 /usr/lib/libevent-2.0.so.5</p><p>2）Memcached的HA（High Availablity）<br>Keepalived是一个交换机制的软件。Keepalived的作用是检测服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的服务器从系统中剔除，同时使用其他服务器代替该服务器的工作，当服务器工作正常后Keepalived自动将服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的服务器</p><p>利用Keepalived实现MemCached的主主复制高可用架构<br>Keepalived在memcached主服务器产生一个虚拟IP（VIP）<br>Keepalived可以通过不断的检测memcached主服务器的11211端口是否正常工作，<br>如果发现memcached Down机，虚拟IP就从主服务器移到从服务器</p><p>配置Keepalived（每台机器都要配置）<br>rpm -ivh keepalived-1.2.13-4.el6.i686.rpm</p><p>配置：主从节点都要配置，配置文件<br>/etc/keepalived/keepalived.conf</p><p><strong>主节点配置信息</strong></p><pre><code class="highlight plaintext">! Configuration File for keepalivedglobal_defs {    notification_email {      417952939@qq.com    }    notification_email_from collen_training@126.com    smtp_server 127.0.0.1    smtp_connect_timeout 30    router_id LVS_DEVEL}vrrp_instance VI_1 {    state MASTER    interface eth0    virtual_router_id 51    priority 101    advert_int 1    authentication {     auth_type PASS     auth_pass 1111    }    virtual_ipaddress {      192.168.116.88    }}</code></pre><p><strong>从节点配置信息</strong></p><pre><code class="highlight plaintext">! Configuration File for keepalivedglobal_defs {    notification_email {       417952939@qq.com    }    notification_email_from collen_training@126.com    smtp_server 127.0.0.1    smtp_connect_timeout 30    router_id LVS_DEVEL}vrrp_instance VI_1 {    state MASTER    interface eth0    virtual_router_id 51    priority 100    advert_int 1    authentication {      auth_type PASS      auth_pass 1111    }    virtual_ipaddress {      192.168.116.88    }}</code></pre><p>验证Keepalived: 使用命令 <code>ip ad sh</code> 查看虚拟ip地址<br>inet 192.168.116.88/32 scope global eth0</p><h3 id="二、Redis">二、Redis</h3><h4 id="1、Redis简介">1、Redis简介</h4><p>（1）Redis的前身：Memcached<br>（2）和Memcached区别“<br>（<em>）支持持久化：RDB快照、AOF日志<br>（</em>）支持丰富的数据类型</p><h4 id="2、安装Redis">2、安装Redis</h4><p>833  tar -zxvf redis-3.0.5.tar.gz<br>839  cd redis-3.0.5/<br>841  make<br>842  make PREFIX=/root/hd/redis install</p><p>redis-benchmark ：    Redis提供的压力测试工具。模拟产生客户端的压力<br>redis-check-aof：检查aof日志文件<br>redis-check-dump：检查rdb文件<br>redis-cli：Redis客户端脚本<br>redis-sentinel：哨兵<br>redis-server：Redis服务器脚本</p><p>核心配置文件:redis.conf<br>[root@hsiehchou121 redis-3.0.5]# cp redis.conf /root/hd/redis/<br>[root@hsiehchou121 redis]# mkdir conf<br>[root@hsiehchou121 redis]# mv redis.conf conf/<br>[root@hsiehchou121 conf]# vi redis.conf</p><p>42 <strong>daemonize</strong> yes  //后台方式运行<br>50 port 6379</p><p>启动redis ./bin/redis-server conf/redis.conf<br>检测是否启动好<br>[root@hsiehchou121 redis]# ./bin/redis-server conf/redis.conf</p><h4 id="3、操作Redis">3、操作Redis</h4><p>1）命令行<br>redis-cli<br>./bin/redis-cli</p><p>127.0.0.1:6379&gt; set key1 value1<br>OK<br>127.0.0.1:6379&gt; get key1<br>“value1”<br>127.0.0.1:6379&gt; keys *</p><ol><li>“key1”</li></ol><p>对数据的操作：<br>127.0.0.1:6379&gt; set money 100<br>OK<br>127.0.0.1:6379&gt; incr money<br>(integer) 101<br>127.0.0.1:6379&gt; get money<br>“101”<br>127.0.0.1:6379&gt; incrby money 10000<br>(integer) 10101</p><p>2）数据类型<br>①　字符串<br>127.0.0.1:6379&gt; set key1 “hello”<br>OK<br>127.0.0.1:6379&gt; get key1<br>“hello”<br>127.0.0.1:6379&gt;<br>127.0.0.1:6379&gt; append key1 “<code>*******</code>”<br>(integer) 12<br>127.0.0.1:6379&gt; get key1<br>“hello<code>*******</code>”</p><p>②　链表<br>127.0.0.1:6379&gt;<br>127.0.0.1:6379&gt; lpush list 11 22 33 44 55<br>(integer) 5<br>127.0.0.1:6379&gt; lrange list 0 2</p><ol><li>“55”</li><li>“44”</li><li>“33”<br>127.0.0.1:6379&gt; lrange list 0 -1</li><li>“55”</li><li>“44”</li><li>“33”</li><li>“22”</li><li>“11”<br>127.0.0.1:6379&gt; lpop list<br>“55”</li></ol><p>③　Hash<br>127.0.0.1:6379&gt; hset hashkey1 name ls<br>(integer) 1<br>127.0.0.1:6379&gt; hset hashkey2 age 23<br>(integer) 1<br>127.0.0.1:6379&gt; hmset user001 name ls age 23 gender mals<br>OK<br>127.0.0.1:6379&gt; hmset user002 name xz age 24 gender mals<br>OK<br>127.0.0.1:6379&gt; hmget user001 name age gender</p><ol><li>“ls”</li><li>“23”</li><li>“mals”<br>127.0.0.1:6379&gt; hgetall user001</li><li>“name”</li><li>“ls”</li><li>“age”</li><li>“23”</li><li>“gender”</li><li>“mals”</li></ol><p>④　无序集合<br>无序，不可重复的集合<br>127.0.0.1:6379&gt; sadd setkey1 11 22 33 44 55<br>(integer) 5<br>127.0.0.1:6379&gt; sadd setkey2 33 44 55 66 77 88<br>(integer) 6<br>127.0.0.1:6379&gt; smembers setkey1</p><ol><li>“11”</li><li>“22”</li><li>“33”</li><li>“44”</li><li>“55”</li></ol><p>sdiif： 差集<br>sinter： 交集<br>suntion：并集</p><p>⑤　有序集合<br>有序可以重复的集合，根据一个score来进行排序<br>127.0.0.1:6379&gt; zadd chinese 90 Tom 92 Nary 83 Nike<br>(integer) 3<br>127.0.0.1:6379&gt; zrange chinese 0 100</p><ol><li>“Nike”</li><li>“Tom”</li><li>“Nary”<br>127.0.0.1:6379&gt; zrange chinese 0 100 withscores</li><li>“Nike”</li><li>“83”</li><li>“Tom”</li><li>“90”</li><li>“Nary”</li><li>“92”</li></ol><p>⑥　Redis数据类型案例分析：网站统计用户登录的次数<br>a.1亿个用户，有经常登录的，也有不经常登录的<br>b.如何来记录用户的登录信息<br>c.如何查询活跃用户：比如：一周内，登录3次的</p><p>解决方案一：采用关系型数据库<br>建立表：记录一周内，每天登录的情况</p><p>采用关系型数据库保存登录信息存在的问题，每天产生一亿条数据，一周就是7亿条数据</p><p>解决方案二：采用Redis存储登录信息<br>可以使用Redis的setbit，登录与否：有1和0就可以表示<br>一亿个用户，每天是否登录，用1或者0表示即可，每天产生约12M的数据<br>一亿个用户一周的登录信息：<br>12M*7=84M</p><pre><code class="highlight plaintext">3）Java Api①　基本操作    @Test    public void testString(){        Jedis jedis = new Jedis("192.168.116.121",6379);        //添加数据        jedis.set("name","ls");//向key--&gt;name中放入了value--&gt;ls        System.out.println(jedis.get("name"));//执行结果：ls        jedis.append("name"," is my lover");//拼接        System.out.println(jedis.get("name"));//执行结果：ls is my lover        jedis.del("name");//删除某个键        System.out.println(jedis.get("name"));//执行结果：null        //设置多个键值对        jedis.mset("name","tom","age","23","qq","123456789");        jedis.incr("age");//进行加1操作        System.out.println(jedis.get("name") + "-" + jedis.get("age") + "-" + jedis.get("qq"));//执行结果：tom-24-123456789        jedis.disconnect();    }</code></pre><p>②　连接池</p><pre><code class="highlight plaintext">public class RedisUtils {    private static JedisPool jedisPool = null;    static {        try {            JedisPoolConfig config = new JedisPoolConfig();            //可用连接实例的最大数目，默认值为8 如果赋值为-1，则表示不限制            config.setMaxTotal(1024);            //控制一个pool最多有多少个状态为idle（空闲的）的jedis实例，默认值也是8            config.setMaxIdle(200);            //等待可用连接的最大时间，单位毫秒，默认值为-1，表示永不超时            config.setMaxWaitMillis(10000);            //在borrow一个jedis实例时，是否提前进行validate操作，如果为true，则得到的jedis实例均是可用的            config.setTestOnBorrow(true);            jedisPool = new JedisPool(config, "192.168.116.121");        }catch (Exception e) {            e.printStackTrace();        }    }    public synchronized static Jedis getJedis(){        try {            if (jedisPool != null)                return jedisPool.getResource();        }catch (Exception e){            e.printStackTrace();        }        return null;    }    public static void returnResource(final Jedis jedis){        if (jedis != null)            jedisPool.returnResource(jedis);    }}</code></pre><p>③　使用Redis实现分布式锁<br>使用Maven搭建工程：</p><pre><code class="highlight plaintext">&lt;dependency&gt;    &lt;groupId&gt;redis.clients&lt;/groupId&gt;    &lt;artifactId&gt;jedis&lt;/artifactId&gt;    &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="4、Redis的事务：不是真正的事务，是一种模拟">4、Redis的事务：不是真正的事务，是一种模拟</h4><p>1）复习：事务（关系型数据库）<br>（*）什么是事务？<br>事务有一组DML(Data Manipulation Language)语句组成。DML 插入更新删除操作</p><p>（*）事务的特点<br>要么都成功，要么都失败</p><p>（*）Oracle中事务的本质：将事务的DML操作写入日志。日志写入成功，则事务执行成功</p><p>2）Redis事务的本质：将一组操作放入队列中，一次执行（批处理）</p><p>3）对比Oracle和Redis事务的区别</p><table><thead><tr><th style="text-align:center">操作</th><th style="text-align:center">Oracle</th><th style="text-align:center">Redis</th></tr></thead><tbody><tr><td style="text-align:center">开启事务</td><td style="text-align:center">自动开启</td><td style="text-align:center">命令：multi</td></tr><tr><td style="text-align:center">执行语句</td><td style="text-align:center">DML</td><td style="text-align:center">Redis命令</td></tr><tr><td style="text-align:center">提交事务</td><td style="text-align:center">显式提交：commit；隐式提交:DDL语句（create table）</td><td style="text-align:center">命令：exec 执行放在multi里面的操作</td></tr><tr><td style="text-align:center">回滚事务</td><td style="text-align:center">显式回滚：rollback；隐式回滚：系统掉电，客户端退出</td><td style="text-align:center">命令：discard 把队列中的操作废弃掉</td></tr></tbody></table><p><strong>注意</strong>：不是真正的事务，只是一种模拟</p><p>4）举例：模拟银行转账<br>set tom 1000<br>set mike 1000<br>tom --&gt; mike 转账操作必须在事务中，要么都成功，要么都不成功<br>multi<br>decrby tom 100<br>incrby mike 100<br>exec</p><p>127.0.0.1:6379&gt; set tom 1000<br>OK<br>127.0.0.1:6379&gt; set mike 1000<br>OK<br>127.0.0.1:6379&gt; multi<br>OK<br>127.0.0.1:6379&gt; decrby tom 100<br>QUEUED<br>127.0.0.1:6379&gt; incrby mike 100<br>QUEUED<br>127.0.0.1:6379&gt; exec</p><ol><li>(integer) 900</li><li>(integer) 1100</li></ol><p>5）举例：买票<br>set tom 1000<br>set ticket 1<br>multi<br>decrby tom 500<br>decr ticket<br>exec</p><p>在exec前，从另一个窗口，decr ticket<br>127.0.0.1:6379&gt; set tom 1000<br>OK<br>127.0.0.1:6379&gt; set ticket 1<br>OK<br>127.0.0.1:6379&gt; multi<br>OK<br>127.0.0.1:6379&gt; decrby tom 500<br>QUEUED<br>127.0.0.1:6379&gt; decr ticket<br>QUEUED<br>127.0.0.1:6379&gt; exec</p><ol><li>(integer) 500</li><li>(integer) -1</li></ol><h4 id="5、Redis锁机制">5、Redis锁机制</h4><p>执行事务操作的时候，如果监视的值发生了变化，则提交失败<br>命令：<strong>watch</strong></p><p>举例：<strong>买票</strong><br>set tom 1000<br>set ticket 1<br>watch ticket -----&gt; 相当于给ticket加了锁。认为在下面执行事务的时候，值不会变<br>multi<br>decrby tom 500<br>decr ticket<br>exec</p><p>127.0.0.1:6379&gt; set tom 1000<br>OK<br>127.0.0.1:6379&gt; set ticket 1<br>OK<br>127.0.0.1:6379&gt; watch ticket<br>OK<br>127.0.0.1:6379&gt; multi<br>OK<br>127.0.0.1:6379&gt; decrby tom 500<br>QUEUED<br>127.0.0.1:6379&gt; decr ticket<br>QUEUED<br>127.0.0.1:6379&gt; exec<br>(nil)<br>127.0.0.1:6379&gt; get tom<br>“1000”</p><p><code>nil</code> 代表操作没有执行或者执行失败</p><p><strong>Java应用程序中的事务和锁</strong><br>①　事务</p><pre><code class="highlight plaintext">@Testpublic void testTransaction(){    Jedis jedis = new Jedis("192.168.116.121",6379);    Transaction tc = null;    try{        //开启事务        tc = jedis.multi();        tc.decrBy("tom", 100);        tc.incrBy("mike", 100);        //提交事务        tc.exec();    }catch (Exception e){        e.printStackTrace();        //回滚事务        tc.discard();    }    jedis.disconnect();}</code></pre><p>②　锁</p><pre><code class="highlight plaintext">@Test   public void testLock(){       Jedis jedis = new Jedis("192.168.116.121",6379);       //对ticket加锁，如果在事务执行过程中，该值有变化，则抛出异常       jedis.watch("ticket");       Transaction tc = null;       try{           //开启事务           tc = jedis.multi();           tc.decr("ticket");//车票数量减一           Thread.sleep(5000);           tc.decrBy("tom", 100);//扣tom 100块钱买票的钱           //提交事务           tc.exec();       }catch (Exception e){           e.printStackTrace();           //回滚事务           tc.discard();       }       jedis.disconnect();   }</code></pre><h4 id="6、Redis的消息机制：消息系统">6、Redis的消息机制：消息系统</h4><p>1）消息的类型<br>（<em>）Queue消息：队列，点对点<br>（</em>）Topic消息：主题，群发：发布消息，订阅消息</p><p>2）Redis消息机制<br>只支持Topic消息</p><p>命令：发布消息 publish 格式：publish channel名称 “消息内容”</p><p>订阅：subscribe 格式：subscribe channel名称</p><p>psubscribe 订阅消息  ------ 可以用通配符来订阅消息<br>格式：psubscribe channel*名称</p><p>3）常用的消息系统：<br>Redis 只支持 Topic<br>Kafka 只支持Topic 需要Zookeeper支持<br>JMS Java Messging Service java消息服务标准。支持Queue Topic<br>产品：Weblogic</p><p>例子：<br>窗口1（发）：<br>127.0.0.1:6379&gt; PUBLISH c1 hello<br>(integer) 2<br>127.0.0.1:6379&gt; PUBLISH c1 test<br>(integer) 2</p><p>窗口2（订）：<br>127.0.0.1:6379&gt; SUBSCRIBE c1<br>Reading messages… (press Ctrl-C to quit)</p><ol><li>“subscribe”</li><li>“c1”</li><li>(integer) 1</li><li>“message”</li><li>“c1”</li><li>“hello”</li><li>“message”</li><li>“c1”</li><li>“test”</li></ol><p>窗口3（订）：<br>127.0.0.1:6379&gt; SUBSCRIBE c1<br>Reading messages… (press Ctrl-C to quit)</p><ol><li>“subscribe”</li><li>“c1”</li><li>(integer) 1</li><li>“message”</li><li>“c1”</li><li>“hello”</li><li>“message”</li><li>“c1”</li><li>“test”</li></ol><p><strong>通过通配符订阅</strong><br>窗口1（发）：<br>127.0.0.1:6379&gt; PUBLISH c2 hello<br>(integer) 1<br>127.0.0.1:6379&gt; PUBLISH c4 hello<br>(integer) 1</p><p>窗口2（发）：<br>127.0.0.1:6379&gt; PUBLISH c1 dfg<br>(integer) 1</p><p>窗口3（订）：<br>127.0.0.1:6379&gt; PSUBSCRIBE c*<br>Reading messages… (press Ctrl-C to quit)</p><ol><li>“psubscribe”</li><li>“c*”</li><li>(integer) 1</li><li>“pmessage”</li><li>“c*”</li><li>“c2”</li><li>“hello”</li><li>“pmessage”</li><li>“c*”</li><li>“c4”</li><li>“hello”</li><li>“pmessage”</li><li>“c*”</li><li>“c1”</li><li>“dfg”</li></ol><p><strong>使用Java程序实现消息的发布与订阅</strong><br>需要继承JedisPubSub类</p><pre><code class="highlight plaintext">@Test    public void testMessage(){        Jedis jedis = new Jedis("192.168.116.121", 6379);        //subscribe和psubcribe不能同时订阅        jedis.subscribe(new MyListener(), "channel");        //jedis.psubscribe(new MyListener(), "channel*");    }    class MyListener extends JedisPubSub{        public void onMessage(String channel, String message){            System.out.println("onMessage channel is " + channel + " message is " + message);        }        public void onPMessage(String pattern, String channel, String message){            System.out.println("onPMessage channel is " + pattern);            System.out.println("onPMessage channel is " + channel);            System.out.println("onPMessage message is " + message);        }        public void onPSubscribe(String arg0, int arg1){}        public void onPUnsubscribe(String arg0, int arg1){}        public void onSubscribe(String arg0, int arg1){}        public void onUnsubscribe(String arg0, int arg1){}    }</code></pre><h4 id="7、Redis持久化">7、Redis持久化</h4><p>本质：<strong>备份和恢复</strong><br>1）<strong>RDB快照</strong>：默认<br>（*）看成一种快照，备份。每隔段时间，将内存汇总的数据保存到硬盘上。产生RDB文件</p><p>（*）<strong>RDB 生成策略</strong><br><strong>redis.conf中</strong><br>147 save 900 1       900秒内，有1个key发生变化，执行RDB<br>148 save 300 10      300内，如果有10个key发生变化，执行RDB<br>149 save 60 10000    60秒内，如果有10000个key发生变化，执行RDB</p><p>save ---- 时间 ----- 发生变化的key的个数</p><p>（*）其他参数<br>164 stop-writes-on-bgsave-error yes  当后台写进程出错时，禁止写入新的数据</p><p>170 rdbcompression yes      是否压缩。如果看重性能，设置成no<br>压缩会节省空间，但会影响备份和恢复性能</p><p>182 dbfilename dump.rdb  RDB的文件名字<br>192 dir ./  RDB的文件地址</p><p>（*）RDB的优点和缺点<br>优点：快，恢复速度快<br>缺点：在两次RDB之间，可能会造成数据的丢失<br>解决：AOF</p><p>2）<strong>AOF日志</strong><br>客户端在操作Redis时，把操作记录到文件中，如果发生崩溃，读取日志，把操作完全执行一遍</p><p>（*）默认是禁用<br>509 appendonly no  参数修改成yes</p><p>（*）AOF记录策略<br>538 # appendfsync always       每条操作都记录日志：优点安全 缺点：慢<br>539 appendfsync everysec    每秒写入一次<br>540 # appendfsync no由操作系统来决定记录日志的方式。不会用的到。</p><p>（*）AOF日志重写：overwrite<br>举例：<br>set money 0<br>incr money<br>…100次</p><p>set money 100</p><p>./redis-benchmark -n 100000<br>模拟客户端100000次请求</p><p>（*）参数设置<br>561 no-appendfsync-on-rewrite <strong>no</strong>   执行重写的时候，不写入新的aof日志<br>//561 no-appendfsync-on-rewrite yes  生成rdb的时候，是否不写入aof<br>580 auto-aof-rewrite-percentage 100 aof文件比上次重写时，超过的百分比<br>581 auto-aof-rewrite-min-size 64mb  执行重写的文件大小。到64M触发重写</p><p>3）当两个同时存在时，优先执行哪个？<br>504 # If the AOF is enabled on startup Redis will load the AOF, that is the file<br>505 # with the better durability guarantees.</p><p><strong>AOF开启时，优先使用AOF</strong></p><h4 id="8、Redis的主从复制">8、Redis的主从复制</h4><p>1）<strong>Redis主从复制集群</strong><br>作用：<br>主从复制，主从备份，防止主节点down机<br>任务分离：分摊主节点压力。读写分离</p><p>Memcacached：主主复制<br>Redis：主从复制</p><p>Redis集群两种部署方式<br><strong>星型模型</strong>：<br>优点：效率高，两个slave地位一样，可以直接从主节点取出信息<br>缺点：HA比较麻烦</p><p><strong>线性模型</strong>：<br>优点：HA简单，master宕机后，可以直接切换到slave1<br>缺点：效率不如星型模型</p><p>cp redis.conf redis6379.conf<br>cp redis.conf redis6380.conf<br>cp redis.conf redis6381.conf</p><p><strong>主节点</strong>（redis6379.conf ）：关闭rdb aof<br>509 appendonly no<br>147 #save 900 1<br>148 #save 300 10<br>149 #save 60 10000</p><p><strong>从节点</strong>（redis6380.conf redis6381.conf）<br>不同机器有的可以不改<br>改端口号<br>50 port 6380<br>改aof rdb文件名：<br>182 dbfilename dump6380.rdb<br>211 slaveof 192.168.116.121 6379<br>513 appendfilename “appendonly6380.aof”</p><p><strong>改端口号</strong><br>50 port 6381<br>改aof rdb文件名：<br>182 dbfilename dump6381.rdb<br>211 slaveof 192.168.116.121 6379<br>513 appendfilename “appendonly6381.aof”</p><p>[root@hsiehchou121 redis]# ./bin/redis-server ./conf/redis6379.conf<br>[root@hsiehchou121 redis]# ./bin/redis-server ./conf/redis6380.conf<br>[root@hsiehchou121 redis]# ./bin/redis-server ./conf/redis6381.conf</p><p>[root@hsiehchou121 redis]# ps -ef | grep redis<br>root       6371      1  1 16:31 ?        00:00:00 ./bin/redis-server *:6379<br>root       6375      1  4 16:31 ?        00:00:01 ./bin/redis-server *:6380<br>root       6381      1  0 16:31 ?        00:00:00 ./bin/redis-server *:6381<br>root       6395   5432  0 16:31 pts/0    00:00:00 grep --color=auto redis</p><p>[root@hsiehchou121 redis]# ./bin/redis-cli -p 6379<br>127.0.0.1:6379&gt; set tom 10000<br>OK<br>127.0.0.1:6379&gt; quit<br>[root@hsiehchou121 redis]# ./bin/redis-cli -p 6380<br>127.0.0.1:6380&gt; get tom<br>“10000”</p><p>默认情况下，从节点只读，不可以写入数据</p><p>注意：一次性启动从节点不要太多</p><p><img src="/medias/Redis%20%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86.PNG" alt="Redis 主从服务的通信原理"></p><p>2）<strong>Redis的分片</strong><br>多个从节点分摊读的压力</p><p>客户端代理分片工具：Twemproxy</p><p><strong>解压</strong><br>[root@hsiehchou121 nutcracker-0.3.0]# ./configure <code>--prefix</code>=/root/hd/nutcracker<br>[root@hsiehchou121 nutcracker-0.3.0]# make<br>[root@hsiehchou121 nutcracker-0.3.0]# make install</p><p>cp /root/hd/nutcracker-0.3.0/conf/nutcracker.yml ./conf/</p><p><strong>修改server信息</strong></p><pre><code class="highlight plaintext">alpha:  listen: 127.0.0.1:22121  hash: fnv1a_64  distribution: ketama  auto_eject_hosts: true  redis: true  server_retry_timeout: 2000  server_failure_limit: 1  servers:   - 192.168.116.121:6380:1   - 192.168.116.121:6381:1</code></pre><p><strong>启动redis</strong><br>[root@hsiehchou121 redis]# ./bin/redis-server ./conf/redis6379.conf<br>[root@hsiehchou121 redis]# ./bin/redis-server ./conf/redis6380.conf<br>[root@hsiehchou121 redis]# ./bin/redis-server ./conf/redis6381.conf</p><p><strong>检查配置文件是否正确</strong><br>[root@hsiehchou121 nutcracker]# ./sbin/nutcracker -t conf/nutcracker.yml</p><p><strong>启动代理分片</strong><br>[root@hsiehchou121 nutcracker]# ./sbin/nutcracker -d -c conf/nutcracker.yml</p><p>[root@hsiehchou121 redis]# ./bin/redis-cli -p 22121 访问</p><h4 id="9、Redis的HA（哨兵机制）">9、Redis的HA（哨兵机制）</h4><p><strong>主从结构，存在单点故障问题</strong></p><p>redis2.4版本之后有</p><p>redis-sentinel 就是哨兵</p><p>vi redis6380.conf<br>211 slaveof 192.168.116.121 6379</p><p>vi redis6381.conf<br>211 slaveof 192.168.116.121 6379</p><p><strong>配置</strong>：<br>cp /root/hd/redis-3.0.5/sentinel.conf  ./conf/</p><p>vim sentinel.conf</p><p>53 sentinel monitor mymaster 192.168.116.121 6379 1</p><p>[root@hsiehchou121 redis]# ./bin/redis-sentinel conf/sentinel.conf</p><p>看日志：<br>3085:X 23 Apr 17:04:17.522 # +monitor master mymaster 192.168.116.121 6379 quorum 1<br>3085:X 23 Apr 17:04:18.524 * +slave slave 192.168.116.121:6380 192.168.116.121 6380 @ mymaster 192.168.116.121 6379<br>3085:X 23 Apr 17:04:18.526 * +slave slave 192.168.116.121:6381 192.168.116.121 6381 @ mymaster 192.168.116.121 6379</p><p>kill master 检测到<br>看日志：<br>try-failover master mymaster 192.168.109.134 6379<br>检测到6379挂了</p><p>3085:X 23 Apr 17:05:14.647 # +selected-slave slave 192.168.116.121:6381 192.168.116.121 6381 @ mymaster 192.168.116.121 6379<br>select slave 选举新的主节点</p><p>3085:X 23 Apr 17:05:16.830 * +slave slave 192.168.116.121:6380 192.168.116.121 6380 @ mymaster 192.168.116.121 6381<br>把其他的从节点连接到主节点上</p><p><strong>注意</strong>:一定要按步骤来，一步一步配置</p><p><strong>亲测排坑</strong><br><strong>划重点</strong><br>此处的Redis的HA高可用的redis主节点和从节点的变化会导致<strong>sentinel monitor mymaster</strong>（sentinel.conf的第53行）和<strong>slaveof</strong>一起变化（从节点的第211行）。而且这个过程是不可逆的，就是更新了变只有自己手动去修改下。</p><p>所以，如果停止重新运行，便会报错，需要自己自行修改这些内容。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 内存数据库 </tag>
            
            <tag> MemCached </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark MLlib和Spark GraphX</title>
      <link href="/2019/04/11/spark_mllib_he_spark_graphx/"/>
      <url>/2019/04/11/spark_mllib_he_spark_graphx/</url>
      
        <content type="html"><![CDATA[<p><strong>Spark MLlib</strong></p><p>MLlib 是 Spark 可以扩展的机器学习库</p><p>MLlib is Apache Spark’s scalable machine learning library.</p><h3 id="一、MLlib概述">一、MLlib概述</h3><p>MLlib 是 Spark 可以扩展的机器学习库</p><p>Spark在机器学习方面具有得天独厚的有事，有以下几个原因：</p><h4 id="1、机器学习算法">1、机器学习算法</h4><p>一般都有多个步骤迭代计算，需要在多次迭代后，获得足够小的误差或者收敛才会停止</p><pre><code class="highlight plaintext">double wucha = 1.0while(wucha&gt;=0.00001){建模  wucha -= 某个值}</code></pre><p>模型计算完毕</p><p>当迭代使用Hadoop的MapReduce计算框架时，每次都要读写硬盘以及任务启动工作，导致很大的IO开销</p><p>而Spark基于内存的计算模型天生擅长迭代计算。只有在必要时，才会读写硬盘</p><p>所以Spark是机器学习比较理想的平台</p><h4 id="2、通信">2、通信</h4><p>Hadoop的MapReduce计算框架，通过heartbeat方式来进行通信和传递数据，执行速度慢</p><p>spark 有高效的 Akka 和 Netty 的通信系统，通行效率高</p><p>Spark MLlib 是Spark 对常用的机器学习算法的实现库，同时包括相关测试和数据生成器</p><h3 id="二、什么是机器学习">二、什么是机器学习</h3><h4 id="1、机器学习的定义">1、机器学习的定义</h4><p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P,<br>if its performance at tasks in T, as measured by P, improves with experience E</p><p>三个关键词：算法、经验、模型评价</p><p>在数据的基础上，通过算法构建出模型，并进行评价<br>如果达到要求，则用该模型测试其他数据<br>如果不达到要求，要调整算法来重新建立模型，再次进行评估<br>循环往复，知道获得满意的经验</p><p>应用：金融反欺诈、语音识别、自然语言处理、翻译、模式识别、智能控制等等</p><h4 id="2、基于大数据的机器学习">2、基于大数据的机器学习</h4><p>传统的机器学习算法，由于技术和单机存储的现值，只能在少量数据上使用<br>即，依赖于数据抽样<br>问题：很难做好随机，导致学习的模型不准确</p><p>在大数据上进行机器学习，直接处理全量数据并进行大量迭代计算</p><p>Spark本身计算优势，适合机器学习</p><p>另外 spark-shell pyspark 都可以提供及时查询工具</p><h4 id="3、MLlib">3、MLlib</h4><p>MLlib是Spark机器学习库，简化机器学习的工程实践工作，方便扩展到更大规模<br>集成了通用的学习算法：分类、回归、聚类、协同过滤、降维等等</p><p>另外，MLlib本身在Spark中，数据清洗、SQL、建模放在一起</p><p><strong>sample_linear_regression_data.txt</strong><br>1 1:1.9<br>2 1:3.1<br>3 1:4<br>3.5 1:4.45<br>4 1:5.02<br>9 1:9.97<br>-2 1:-0.98</p><pre><code class="highlight plaintext">package day7import org.apache.spark.sql.SparkSessionimport org.apache.spark.ml.regression.LinearRegression/* * 1.3850645873427236 1:0.14476184437006356 2:-0.11280617018445871 3:-0.4385084538142101 4:-0.5961619435136434 5:0.419554626795412 6:-0.5047767472761191 7:0.457180284958592 8:-0.9129360314541999 9:-0.6320022059786656 10:-0.44989608519659363 *  */object Demo1 {  def main(args: Array[String]): Unit = {    val spark = SparkSession.builder().appName("Demo1").master("local").getOrCreate()        val data_path = "H:\\sample_linear_regression_data.txt"        //读取训练数据    val trainning = spark.read.format("libsvm").load(data_path)        //定义模型    val lr = new LinearRegression().setMaxIter(10000)        //训练模型    val lrModel = lr.fit(trainning)        //获取模型训练结果    val trainningSummary = lrModel.summary        //获取预测值    trainningSummary.predictions.show()        //获取误差    print(trainningSummary.rootMeanSquaredError)        spark.stop()  }}</code></pre><h2 id="Spark-Graphx">Spark Graphx</h2><h3 id="一、Spark-Graphx-是什么？">一、Spark Graphx 是什么？</h3><p>1、是Spark 的一个模块，主要用于进行以图为核心的计算，还有分布式图计算</p><p>2、Graphx 底层基于RDD计算，和RDD共用一种存储形态。在展示形态上，可以用数据集来表示，也可以用图来表示</p><h3 id="二、Spark-GraphX-有哪些抽象？">二、Spark GraphX 有哪些抽象？</h3><h4 id="1、顶点">1、顶点</h4><p>RDD[(VertexId,VD)]表示<br>VertexId 代表了顶点的ID，是Long类型<br>VD 是顶点的属性，可以是任何类型</p><h4 id="2、边">2、边</h4><p>RDD[Edge[ED]]表示<br>Edge表示一个边<br>包含一个ED类型参数来设定属性<br>另外，边还包含了源顶点ID和目标顶点ID</p><h4 id="3、三元组">3、三元组</h4><p>三元组结构用RDD[EdgeTriplet[VD,ED]]表示<br>三元组包含一个边、边的属性、源顶点ID、源顶点属性、目标顶点ID、目标顶点属性</p><h4 id="4、图">4、图</h4><p>Graph表示，通过顶点和边来构建</p><pre><code class="highlight plaintext">package day7import org.apache.spark.SparkConfimport org.apache.spark.SparkContextimport org.apache.spark.graphx.Edgeimport org.apache.spark.graphx.Graphobject Demo2 {  def main(args: Array[String]): Unit = {    val conf = new SparkConf().setAppName("Demo2").setMaster("local")        //创建Spark Context对象    val sc = new SparkContext(conf)        //定义点    val users = sc.parallelize(Array((3L,("TIme","student")),(5L,("Andy","student")),        (7L,("Mary","student")),(2L,("Lily","post"))))        //定义边    val relationship = sc.parallelize(Array(Edge(3L,7L,"col"),Edge(5L,3L,"ad"),Edge(2L,5L,"col"),Edge(5L,7L,"heh")))         //构建图    val graph = Graph(users, relationship)        //图的操作    val post_count = graph.vertices.filter{ case (id,(name,pos)) =&gt; pos=="post"}.count        println("post count is " + post_count)        val edges_count = graph.edges.filter(e =&gt; e.srcId &gt; e.dstId).count()        println("the value is " + edges_count)  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark 调优</title>
      <link href="/2019/04/07/spark_diao_you/"/>
      <url>/2019/04/07/spark_diao_you/</url>
      
        <content type="html"><![CDATA[<p><strong>Spark 调优</strong></p><p>问题：只要会用就可以，为什么还要精通内核源码与调优？<br>Spark 性能优化概览：<br>Spark的计算本质是，分布式计算<br>所以，Spark程序的性能可能因为集群中的任何因素出现瓶颈：CPU、网络带宽、或者内存</p><p>CPU、网络带宽，是运维来维护的<br>聚焦点：内存</p><p>如果内存能够容纳下所有的数据，那就不需要调优了<br>如果内存比较紧张，不足以放下所有数据（10亿量级—500G）,需要对内存的使用进行性能优化<br>比如：使用某些方法减少内存的消耗</p><p>Spark性能优化，主要针对在内存的使用调优</p><p>Spark性能优化的技术：<br>1、使用高性能序列化类库<br>2、优化数据结构<br>3、对于多次使用的RDD进行持久化、checkpoint<br>4、持久化级别：MEMORY_ONLY  —&gt;  MEMORY_ONLY_SER 序列化<br>5、Java虚拟机垃圾回收调优<br>6、Shuffle调优，1.x版本中，90%的性能问题，都是由于Shuffle导致的。</p><p>其他性能优化：<br>1、提高并行度<br>2、广播共享数据<br>等等。。。</p><h3 id="一、诊断Spark内存使用">一、诊断Spark内存使用</h3><p>首先要看到内存使用情况，才能进行针对性的优化</p><h4 id="1、内存花费">1、内存花费</h4><p>（1）每个Java对象，都有一个对象头，占用16字节，包含一些对象的元信息，比如指向他的类的指针<br>如果对象本身很小，比如int，但是他的对象头比对象自己还大</p><p>（2）Java的String对象，会比他内存的原始数据，多出40个字节<br>String内部使用的char数组来保存内部的字符串序列，并且还要保存诸如输出长度之类的信息<br>char使用的是UTF-16编码，每个字符会占2个字节。比如，包含10个字符的String，2*10+40=60字节</p><p>（3）Java中的集合类型，比如HashMap和LinkedList，内部使用链表数据结构<br>链表中的每个数据，使用Entry对象包装<br>Entry对象，不光有对象头，还有指向下一个Entry的指针，占用8字节</p><p>（4）元素类型为原始数据类型（int），内部通常会使用原始数据类型的包装类型（Integer）来存储元素</p><h4 id="2、如何判断Spark程序消耗内存情况？">2、如何判断Spark程序消耗内存情况？</h4><p>预估<br>（1）设置RDD的并行度<br>两种方法创建RDD，parallelize()  textFile() 在这两个方法中，传入第二个参数，设置RDD的partition数量<br>在SparkConfig中设置一个参数：<br>spark.default.parallelism<br>可以统一设置这个application中所有RDD的partition数量</p><p>（2）将RDD缓存 cache()</p><p>（3）观察日志：<br>driver的日志<br>/root/hd/spark-2.1.0-bin-hadoop2.7/work</p><p>Master和Worker的日志<br>/root/hd/spark-2.1.0-bin-hadoop2.7/logs</p><pre><code class="highlight plaintext">scala&gt; val rdd1 = sc.textFile("/root/hd/tmp_files/test_Cache.txt")rdd1: org.apache.spark.rdd.RDD[String] = /root/hd/tmp_files/test_Cache.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24scala&gt; rdd1.cacheres1: rdd1.type = /root/hd/tmp_files/test_Cache.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24scala&gt; rdd1.countres2: Long = 921911                                                             scala&gt; rdd1.countres3: Long = 921911</code></pre><p>/root/hd/spark-2.1.0-bin-hadoop2.7/work<br>19/04/17 17:02:10 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 22.9 MB, free 343.1 MB)<br>19/04/17 17:02:10 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 22.9 MB, free 320.2 MB)</p><p>（4）将这个内存信息相加，就是RDD内存占用量<br>22.9MB+22.9MB=45.8MB</p><h3 id="二、使用高性能序列化类库">二、使用高性能序列化类库</h3><h4 id="1、数据序列化概述">1、数据序列化概述</h4><p>数据序列化，就是将对象或者数据结构，转换成特定的格式，使其可在网络中传输，或存储在内存或文件中<br>反序列化，是相反的操作，将对象从序列化数据中还原出来<br>序列化后的数据格式，可以是二进制，xml，Json等任何格式<br>对象、数据序列化的重点在于数据的交换与传输</p><p>在任何分布式系统中，序列化都是扮演着一个重要的角色<br>如果使用的序列化技术，操作很慢，或者序列化后的数据量还是很大，会让分布式系统应用程序性能下降很多<br>所以，Spark性能优化的第一步，就是进行序列化的性能优化</p><p>Spark自身默认会在一些地方对数据进行序列化，比如Shuffle。另外，我们使用了外部数据（自定义类型），也要让其课序列化</p><p>Spark本身对序列化的便捷性和性能进行了取舍<br>默认情况下：Spark倾向于序列化的便捷性，使用了Java自身提供的序列化机制，很方便使用</p><p>但是，Java序列化机制性能不高，序列化速度慢，序列化后数据较大，比较占用内存空间</p><h4 id="2、Kryo">2、Kryo</h4><p>Spark支持使用Kryo类库来进行序列化<br>速度快，占用空间更小，比Java序列化数据占用空间小10倍</p><h4 id="3、如何使用kryo序列化机制">3、如何使用kryo序列化机制</h4><p>（1）设置Spark Conf<br>bin/spark-submit will also read configuration options from</p><p><strong>conf/spark-defaults.conf</strong>,<br>in which each line consists of a key and a value separated by whitespace. For example:</p><p>spark.master            spark://5.6.7.8:7077<br>spark.executor.memory   4g<br>spark.eventLog.enabled  true<br>spark.serializer        org.apache.spark.serializer.KryoSerializer</p><p>（2）使用kryo是，要求需要序列化的类，要提前注册，以获得高性能<br>conf.registerKryoClasses(Array(classOf[Count],…))<br>conf.registerKryoClasses(Array(classOf[类], classOf[类], …))</p><h4 id="4、kryo类库的优化">4、kryo类库的优化</h4><p>（1）优化缓存大小<br>如果注册的自定义类型，本身特别大（100个字段），会导致要序列化的对象太大<br>此时需要对kyro本身进行优化。因为kryo内部的缓存，可能不能存放这么大的class对象<br>spark.kryoserializer.buffer.max  设置这个参数，将其调大</p><p>（2）预先注册自定义类型<br>虽然不注册自定义类型，kryo也可以正常工作，但会保存一份他的全限定类名，耗费内存<br>推荐预先注册要序列化的自定义类型</p><h3 id="三、优化数据结构">三、优化数据结构</h3><h4 id="1、概述">1、概述</h4><p>要减少内存的消耗，除了使用高效的序列化类库外，还要优化数据结构<br>避免Java语法特性中所导致的额外内存开销</p><p>核心：优化算子函数内部使用到的局部数据或算子函数外部的数据<br>目的：减少对内存的消耗和占用</p><h4 id="2、如何做">2、如何做</h4><p>（1）优先使用数组以及字符串，而不是集合类。即：优先使用Array，而不是ArrayList、LinkedList、HashMap<br>使用int[] 会比List<code>&lt;Integer&gt;</code> 节省内存</p><p>（2）将对象转换成字符串<br>企业中，将HashMap、List这种数据，统一用String拼接成特殊格式的字符串</p><p>Map&lt;Integer,Person&gt; persons = new HashMap&lt;Integer,Person&gt;()</p><p>可以优化为：<br>“id:name,address”<br>String persons = “1:Andy,Beijing|2:Tom,Tianjin…”</p><p>（3）避免使用多层嵌套对象结构<br>举例：<br>下面的例子不好，因为Teacher类的内部又嵌套了大量的小的Student对象<br>public class Teacher{ private …; privage List<code>&lt;Student&gt;</code> students = new ArrayList()}</p><p>解决：转换成字符串进行处理<br>{“teacherId”: 1, “students”:[{“stuId”:1…},{}]}</p><p>（4）对于能够避免的场景，尽量使用int代替String<br>虽然String比List效率高，但int类型占用更少内存</p><p>比如：数据库主键，id，推荐使用自增的id，而不是uuid</p><h3 id="四、rdd-cache-checkpoint">四、rdd.cache checkpoint</h3><h3 id="五、持久化级别">五、持久化级别</h3><p>MEMORY_ONLY  —&gt;  MEMORY_ONLY_SER 序列化</p><h3 id="六、Java虚拟机的调优">六、Java虚拟机的调优</h3><h4 id="1、概述-2">1、概述</h4><p>如果在持久化RDD的时候，持久化了大量的数据，那么Java虚拟机的垃圾回收就可能成为一个瓶颈</p><p>Java虚拟机会定期进行垃圾回收，此时会追踪所有Java对象，并且在垃圾回收时，找到那些已经不再使用的对象</p><p>清理旧对象，给新对象腾出空间</p><p>垃圾回收的性能开销，是与内存中的对象数量成正比</p><p>在做Java虚拟机调优之前，必须先做好上面的调优工作，这样才有意义</p><p>必须注意顺序（先进行完上面的调优，再进行JVM调优）</p><h4 id="2、Spark-GC原理">2、Spark GC原理</h4><p><strong>垃圾回收期GC</strong></p><p>垃圾回收器，寻找那些对象已经不再使用，将其清除出去</p><p>GC对性能的影响在于，如果内存中数据量较大，会很频繁地造成内存空间不够，导致GC频繁发生，而GC本身是有性能消耗的，如果频繁发生，对性能影响严重</p><p>此外，如果数据量过大，每次要回收的数据量也很大，导致GC慢</p><p>另外GC发生的时候，GC是一个线程，我们Task运行时线程叫做工作线程。GC运行时会让工作线程停下来，让GC单独运行，影响Spark应用程序的运行速度，降低了性能</p><p><strong>核心：不让GC频繁发生</strong></p><p><img src="/medias/sparkGC%E5%8E%9F%E7%90%86.PNG" alt="sparkGC原理"></p><h4 id="3、监测垃圾回收">3、监测垃圾回收</h4><p>我们可以进行监测，比如多久进行一次垃圾回收以及耗费的时间等等。</p><p>spark-submit脚本中，添加一个配置<br>–conf “spark.executor.extraJavaOptions=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimesStamps”</p><p>注意：这个是输出到worker日志中，而不是driver日志<br>/root/hd/spark-2.1.0-bin-hadoop2.7/logs  worker日志<br>/root/hd/spark-2.1.0-bin-hadoop2.7/work  driver日志</p><h4 id="4、优化Executor内存比例">4、优化Executor内存比例</h4><p>目的：减少GC次数</p><p>对于GC调优来说，最重要的就是调节，RDD的缓存占用的内存空间与算子执行时创建对象所占用的内存空间的比例</p><p>Executor:Task=3:2  （Executor 占60%给RDD缓存，Task占40%）<br>对于默认情况，Spark使用每个Executor 60% 的内存空间来缓存RDD，在task运行期间所创建的对象，只有40%内存空间来存放</p><p>在默认情况下，很可能发生的事情，分配给Task的内存不够，<br>导致新创建对象时，很快占满内存，GC启动，找到不再使用的对象，清楚内存</p><p>所以，如果Task分配内存过小，可能会导致GC频繁发生，工作线程停止</p><p>可以通过调节比例，将RDD缓存空间占比调节到40%，降低Task GC频率</p><p>需要配合其他优化：<br>kryo优化<br>持久化级别优化<br>数据结构优化</p><p>使用：conf.set(“spark.storage.memoryFraction”,0.5)</p><p><img src="/medias/spark%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D.PNG" alt="spark内存分配."></p><h4 id="5、Java-GC-调优-（-）">5、Java GC 调优 （-）</h4><p>让GC更快的处理完</p><h3 id="七、shuffle原理">七、shuffle原理</h3><h4 id="1、优化前">1、优化前</h4><p>假设一个节点上，有4个shufflemaptask，有两个CPU core</p><p>每个MapTask会为每个ReduceTask创建一份bucket缓存，以及对应的ShuffleBlockFile磁盘文件</p><p>问题：假设有100个MapTask，100个ReduceTask，会产生100*100即10000个文件，磁盘io过多，影响性能</p><p>假设另外一个节点上，运行了4个ReduceTask</p><p>每个ReduceTask拉取过来的数据，其实会组成内部的RDD，叫ShuffledRDD，优先放入内存，如果不够，写入磁盘</p><p>每个ReduceTask针对数据进行聚合，最后生成MapPartitionsRDD，执行reduceByKey操作希望的到那个RDD<br><img src="/medias/shuffle%E4%BC%98%E5%8C%96%E5%89%8D.PNG" alt="Shuffle优化前"></p><h4 id="2、优化后">2、优化后</h4><p>在Spark新版本中，引入了consolidation的机制，提出了ShuffleGroup概念</p><p>一个ShuffleMapTask执行完后，写入本地文件不会变，但是，下一个ShuffleSMapTask运行的时候，可以直接将数据写入之前的本地文件</p><p>相当于，多个ShuffleMapTask的输出进行了合并，大大减少文件数量</p><p>1和2可以乘坐一组ShuffleGroup，每个文件中，都存储了多个ShuffleMapTask的数量，每个ShuffleMapTask的数据叫做segment，通过外部索引，来标记每个ShuffleMapTask的数据以及偏移量，对不同的ShuffleMapTask的数据进行区分<br><img src="/medias/shuffle%E4%BC%98%E5%8C%96%E5%90%8E.PNG" alt="shuffle优化后"></p><h3 id="八、其他调优">八、其他调优</h3><h4 id="1、提高并行度">1、提高并行度</h4><h4 id="2、广播共享数据">2、广播共享数据</h4>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark Streaming</title>
      <link href="/2019/04/03/spark_streaming_ji_chu/"/>
      <url>/2019/04/03/spark_streaming_ji_chu/</url>
      
        <content type="html"><![CDATA[<p><strong>Spark Streaming</strong><br>流式计算框架，类似于Storm</p><p>常用的实时计算引擎（流式计算）<br>1、Apache Storm：真正的流式计算</p><p>2、Spark Streaming ：严格上来说，不是真正的流式计算（实时计算）<br>把连续的流式数据，当成不连续的RDD<br>本质：是一个离散计算（不连续）</p><p>3、Apache Flink：真正的流式计算。与Spark Streaming相反<br>把离散的数据，当成流式数据来处理</p><p>4、JStorm</p><h3 id="一、Spark-Streaming基础">一、Spark Streaming基础</h3><h4 id="1、什么是-Spark-Streaming">1、什么是 Spark Streaming</h4><p>Spark Streaming makes it easy to build scalable fault-tolerant streaming applications.<br>易于构建灵活的、高容错的流式系统</p><p>Spark Streaming是核心Spark API的扩展，可实现可扩展、高吞吐量、可容错的实时数据流处理。数据可以从诸如Kafka，Flume，Kinesis或TCP套接字等众多来源获取，并且可以使用由高级函数（如map，reduce，join和window）开发的复杂算法进行流数据处理。最后，处理后的数据可以被推送到文件系统，数据库和实时仪表板。而且，您还可以在数据流上应用Spark提供的机器学习和图处理算法</p><p>特点：<br>1、易用，已经集成到Spark中<br>2、容错性：底层RDD，RDD本身具有容错机制<br>3、支持多种语言：Java Scala Python</p><p>Spark Streaming将连续的数据流抽象为discretizedstream或DStream。在内部，DStream 由一个RDD序列表示</p><h4 id="2、演示官方的Demo">2、演示官方的Demo</h4><p>往Spark Streaming中发送字符串，Spark 接收到以后，进行计数<br>使用消息服务器 netcat Linux自带<br>yum install nc.x86_64</p><p>nc -l 1234</p><p>注意：总核心数 大于等于2。一个核心用于接收数据，另一个用于处理数据</p><p>在netcat中写入数据 Spark Streaming可以取到</p><pre><code class="highlight plaintext">[root@hsiehchou121 spark-2.1.0-bin-hadoop2.7]# ./bin/run-example streaming.NetworkWordCount localhost 1234</code></pre><h4 id="3、开发自己的NetWorkWordCount程序">3、开发自己的NetWorkWordCount程序</h4><p>和Spark Core类似</p><p><strong>代码</strong></p><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Level/** * 开发自己的流式计算程序 *  * 知识点 * 1、创建一个StreamingContext对象  ----》核心：创建一个DStream *  * 2、DStream的表现形式：就是一个RDD *  * 3、使用DStream把连续的数据流变成不连续的RDD *  * Spark Streaming 最核心的内容 */object MyNetworkWordCount {  def main(args: Array[String]): Unit = {        //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyNetworkWordCount").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(3))         //创建DStream，从netcat服务器上接收数据    val lines = ssc.socketTextStream("192.168.116.121", 1234, StorageLevel.MEMORY_ONLY)        //lines中包含了netcat服务器发送过来的数据    //分词操作    val words = lines.flatMap(_.split(" "))        //计数    val wordCount = words.map((_,1)).reduceByKey(_+_)        //打印结果    wordCount.print()        //启动StreamingContext进行计算    ssc.start()        //等待任务结束    ssc.awaitTermination()  }}</code></pre><p><strong>程序中的几点说明</strong></p><p>appName参数是应用程序在集群UI上显示的名称</p><p>master是Spark，Mesos或YARN集群的URL，或者一个特殊的“local [*]”字符串来让程序以本地模式运行</p><p>当在集群上运行程序时，不需要在程序中硬编码master参数，而是使用spark-submit提交应用程序并将master的URL以脚本参数的形式传入。但是，对于本地测试和单元测试，您可以通过“local[*]”来运行Spark Streaming程序（请确保本地系统中的cpu核心数够用）</p><p>StreamingContext会内在的创建一个SparkContext的实例（所有Spark功能的起始点），你可以通过ssc.sparkContext访问到这个实例</p><p>批处理的时间窗口长度必须根据应用程序的延迟要求和可用的集群资源进行设置</p><p><strong>请务必记住以下几点</strong></p><p>一旦一个StreamingContext开始运作，就不能设置或添加新的流计算</p><p>一旦一个上下文被停止，它将无法重新启动</p><p>同一时刻，一个JVM中只能有一个StreamingContext处于活动状态</p><p>StreamingContext上的stop()方法也会停止SparkContext。 要仅停止StreamingContext（保持SparkContext活跃），请将stop() 方法的可选参数stopSparkContext设置为false</p><p>只要前一个StreamingContext在下一个StreamingContext被创建之前停止（不停止SparkContext），SparkContext就可以被重用来创建多个StreamingContext</p><p>问题：Hello Hello<br>Hello World</p><p>现在现象：（Hello,2）<br>(Hello , 1) (World , 1)</p><p>能不能累加起来？保存记录下以前的状态？<br>能，能<br>通过Spark Streaming提供的算子来实现</p><h3 id="二、高级特性">二、高级特性</h3><h4 id="1、什么是DStream？离散流">1、什么是DStream？离散流</h4><p>把连续的数据变成不连续的RDD<br>因为DStream的特性，导致Spark Streaming不是真正的流式计算</p><p><strong>离散流</strong>（DStreams）：Discretized Streams<br>DiscretizedStream或DStream 是Spark Streaming对流式数据的基本抽象。它表示连续的数据流，这些连续的数据流可以是从数据源接收的输入数据流，也可以是通过对输入数据流执行转换操作而生成的经处理的数据流。在内部，DStream由一系列连续的RDD表示</p><p>举例分析：<br>在之前的MyNetworkWordCount 的例子中，我们将一行行文本组成的流转换为单词流，具体做法为：将flatMap操作应用于名为lines的 DStream中的每个RDD上，以生成words DStream的RDD</p><p><strong>DStream中的转换操作（transformation）</strong></p><table><thead><tr><th style="text-align:center">Transformation</th><th style="text-align:center">Meaning</th></tr></thead><tbody><tr><td style="text-align:center">map(func)</td><td style="text-align:center">利用函数func处理DStreamd的每个元素，返回一个新的DStream</td></tr><tr><td style="text-align:center">flatMap(func)</td><td style="text-align:center">于map相似，但是每个输入项可被映射为0个或者多个输出项</td></tr><tr><td style="text-align:center">filter(func)</td><td style="text-align:center">返回一个新的DStream，它仅仅包含源DStream中满足函数func的项</td></tr><tr><td style="text-align:center">repartition(numPartitions)</td><td style="text-align:center">通过创建更多或者更少的partition改变这个DStream的并行级别（level of parallelism）</td></tr><tr><td style="text-align:center">union(otherStream)</td><td style="text-align:center">返回一个新的DStream，它包含源DStream和otherStream的联合元素</td></tr><tr><td style="text-align:center">count()</td><td style="text-align:center">通过计算源DStream中每个RDD的元素数量，返回一个包含单元素（single-element）RDDs的新DStream</td></tr><tr><td style="text-align:center">reduce(func)</td><td style="text-align:center">利用函数func聚焦源DStream中每个RDD的元素，返回一个包含单元素（single-element）RDDs的新DStream，函数应该是相关联的，以使计算可以并行化</td></tr><tr><td style="text-align:center">countByValue()</td><td style="text-align:center">这个算子应用于元素类型为K的DStream上，返回一个（K,long）对的新DStream，每个键的值实在原DStream的每个RDD中的频率</td></tr><tr><td style="text-align:center">reduceByKey(func,[numTasks])</td><td style="text-align:center">当在一个由（K,V）对组成的DStream上调用这个算子，返回一个新的由（K,V）对组成的DStream，每一个key的值均由给定的reduce函数聚集起来。注意：在默认情况下，这个算子利用了Spark默认的并发任务数去分组，你可以用numTasks参数设置不同的任务数</td></tr><tr><td style="text-align:center">join(otherStream,[numTasks])</td><td style="text-align:center">当应用于两个DStream（一个包含（K,V）对，一个包含（K,W）对），返回一个包含（K,（V,W））对的新DStream</td></tr><tr><td style="text-align:center">cogroup(otherStream,[numTasks])</td><td style="text-align:center">当应用于两个DStream（一个包含(K,V)对，一个包含（K,W）对），返回一个包含（K,Seq[v],Seq[W]）的元组</td></tr><tr><td style="text-align:center">transform(func)</td><td style="text-align:center">通过对源DStream的每个RDD应用RDD-to-RDD函数，创建一个新的DStream，这个可以在DStream中的任何RDD操作中使用</td></tr><tr><td style="text-align:center">updateStateByKey(func)</td><td style="text-align:center">利用给定的函数更新DStream的状态，返回一个新"state"的DStream</td></tr></tbody></table><h4 id="2、重点算子讲解">2、重点算子讲解</h4><p>（1）updateStateByKey(func)<br>默认情况下，Spark Streaming不记录之前的状态，每次发数据，都会从0开始<br>现在使用本算子，实现累加操作</p><p>操作允许不断用新信息更新它的同时保持任意状态<br>定义状态-状态可以是任何的数据类型<br>定义状态更新函数-怎样利用更新前的状态和从输入流里面获取的新值更新状态</p><p>重写MyNetworkWordCount程序，累计每个单词出现的频率（注意：累计）</p><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Levelimport javax.swing.text.DefaultEditorKit.PreviousWordAction/** * 实现累加操作 */object MyTotalNetworkWordCount {  def main(args: Array[String]): Unit = {       //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyTotalNetworkWordCount ").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(3))        //设置检查点目录，保存之前的状态信息    ssc.checkpoint("hdfs://hsiehchou121:9000/tmp_files/chkp")        //创建DStream 从netcat服务器上接收数据    val lines = ssc.socketTextStream("192.168.116.121", 1234, StorageLevel.MEMORY_ONLY)        val words = lines.flatMap(_.split(" "))        val wordPair = words.map((_,1))        /**     * 定义一个值函数，进行累加运算     * 1、当前值是多少（参数1）     * 2、之前的结果是多少（参数2）     */    val addFunc = (currentValues:Seq[Int], previousValues:Option[Int]) =&gt;{            //进行累加运算      //1、把当前的序列进行累加      val currentTotal = currentValues.sum            //2、在之前的值上再累加      Some(currentTotal + previousValues.getOrElse(0))    }        //进行累加运算    val total = wordPair.updateStateByKey(addFunc)        total.print()        ssc.start()        ssc.awaitTermination()  }}</code></pre><p>我在执行过程中遇到访问权限问题<br>解决如下：<br>在hadoop的etc/hadoop/下的hdfs-site.xml中增加如下内容即可</p><pre><code class="highlight plaintext">   &lt;property&gt;&lt;name&gt;dfs.permissions&lt;/name&gt;&lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;       &lt;name&gt;dfs.safemode.threshold.pct&lt;/name&gt;       &lt;value&gt;0f&lt;/value&gt;   &lt;/property&gt;</code></pre><p>（2）transform(func)<br>通过RDD-to-RDD函数作用于源DStream中的各个RDD，可以是任意的RDD操作，从而返回一个新的RDD</p><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Level/** * 开发自己的流式计算程序 *  * 知识点 * 1、创建一个StreamingContext对象  ----》核心：创建一个DStream *  * 2、DStream的表现形式：就是一个RDD *  * 3、使用DStream把连续的数据流变成不连续的RDD *  * Spark Streaming 最核心的内容 */object MyNetworkWordCount {  def main(args: Array[String]): Unit = {        //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyNetworkWordCount ").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(3))         //创建DStream，从netcat服务器上接收数据    val lines = ssc.socketTextStream("192.168.116.121", 1234, StorageLevel.MEMORY_ONLY)        //lines中包含了netcat服务器发送过来的数据    //分词操作    val words = lines.flatMap(_.split(" "))        //计数    val wordPair = words.transform(x =&gt; x.map(x =&gt; (x, 1)))        //打印结果    wordPair.print()        //启动StreamingContext进行计算    ssc.start()        //等待任务结束    ssc.awaitTermination()  }}</code></pre><h4 id="3、窗口操作">3、窗口操作</h4><p>窗口：对落在窗口内的数据进行处理，也是一个DStream，RDD</p><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Level/** * 窗口操作： * 需求：每10秒钟，把过去30秒的数据读取进来 */object MyNetworkWordCountByWindow {      def main(args: Array[String]): Unit = {        //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyNetworkWordCountByWindow").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(1))        //创建DStream 从netcat服务器上接收数据    val lines = ssc.socketTextStream("192.168.116.121", 1234, StorageLevel.MEMORY_ONLY)        //lines中包含了netcat服务器发送过来的数据    //分词操作 给每个单词记一次数    val words = lines.flatMap(_.split(" ")).map((_,1))    /*     * reduceByKeyAndWindow 函数的三个参数     * 1、需要进行什么操作     * 2、窗口的大小30秒     * 3、窗口滑动的距离10秒     */    val result = words.reduceByKeyAndWindow((x:Int,y:Int)=&gt;(x+y),Seconds(30),Seconds(10))        result.print()        ssc.start()        ssc.awaitTermination()        /*     * The slide duration of windowed DStream (10000 ms) must be a multiple of the slide      * duration of parent DStream (3000 ms)     *      * 注意：窗口滑动距离必须是采样时间的整数倍     */  }}</code></pre><p>举例：每10秒钟把过去30秒的数据采集过来<br>注意：先启动nc  再启动程序 local[2]</p><h4 id="4、集成Spark-SQL-使用SQL语句来处理流式数据">4、集成Spark SQL: 使用SQL语句来处理流式数据</h4><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Levelimport org.apache.spark.sql.SparkSession/** * 集成Spark SQL : 在Spark Streaming中使用SQL语句 */object MyNetworkWordCountWithSQL {     def main(args: Array[String]): Unit = {          //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyNetworkWordCountByWindow").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(10))        //创建DStream 从netcat服务器上接收数据    val lines = ssc.socketTextStream("192.168.116.121", 1234, StorageLevel.MEMORY_ONLY)        //进行单词计数    val words = lines.flatMap(_.split(" "))        //集成Spark SQL 使用SQL语句实现WordCount    words.foreachRDD(rdd =&gt;{            //创建一个Spark Session对象      //通过ssc.sparkContext.getConf 直接获取此session的conf      val spark = SparkSession.builder().config(ssc.sparkContext.getConf).getOrCreate()            //把RDD转换成DataFrame  需要用到隐式转换      import spark.implicits._      val df1 = rdd.toDF("word")//表df1 只有一个列名 名字叫word            //创建视图      df1.createOrReplaceTempView("words")            //执行SQL  通过SQL实现wordcount      spark.sql("select word,count(1) from words group by word").show      }    )    ssc.start()    ssc.awaitTermination()   }}</code></pre><h4 id="5、缓存和持久化：和RDD一样">5、缓存和持久化：和RDD一样</h4><p>与RDD类似，DStreams还允许开发人员将流数据保留在内存中。也就是说，在DStream上调用persist() 方法会自动将该DStream的每个RDD保留在内存中。如果DStream中的数据将被多次计算（例如，相同数据上执行多个操作），这个操作就会很有用。对于基于窗口的操作，如reduceByWindow和reduceByKeyAndWindow以及基于状态的操作，如updateStateByKey，数据会默认进行持久化。 因此，基于窗口的操作生成的DStream会自动保存在内存中，而不需要开发人员调用persist()</p><p>对于通过网络接收数据（例如Kafka，Flume，sockets等）的输入流，默认持久化级别被设置为将数据复制到两个节点进行容错</p><p>注意，与RDD不同，DStreams的默认持久化级别将数据序列化保存在内存中</p><h4 id="6、支持检查点：和RDD一样">6、支持检查点：和RDD一样</h4><p>流数据处理程序通常都是全天候运行，因此必须对应用中逻辑无关的故障（例如，系统故障，JVM崩溃等）具有弹性。为了实现这一特性，Spark Streaming需要checkpoint足够的信息到容错存储系统，以便可以从故障中恢复</p><p>①　一般会对两种类型的数据使用检查点：<br>1）元数据检查点（Metadatacheckpointing） - 将定义流计算的信息保存到容错存储中（如HDFS）。这用于从运行streaming程序的driver程序的节点的故障中恢复。元数据包括以下几种：<br>配置（Configuration） - 用于创建streaming应用程序的配置信息</p><p>DStream操作（DStream operations） - 定义streaming应用程序的DStream操作集合</p><p>不完整的batch（Incomplete batches） - jobs还在队列中但尚未完成的batch</p><p>2）数据检查点（Datacheckpointing） - 将生成的RDD保存到可靠的存储层。对于一些需要将多个批次之间的数据进行组合的stateful变换操作，设置数据检查点是必需的。在这些转换操作中，当前生成的RDD依赖于先前批次的RDD，这导致依赖链的长度随时间而不断增加，由此也会导致基于血统机制的恢复时间无限增加。为了避免这种情况，stateful转换的中间RDD将定期设置检查点并保存到到可靠的存储层（例如HDFS）以切断依赖关系链</p><p>总而言之，元数据检查点主要用于从driver程序故障中恢复，而数据或RDD检查点在任何使用stateful转换时是必须要有的</p><p>②　何时启用检查点：<br>对于具有以下任一要求的应用程序，必须启用检查点：<br>1）使用状态转：如果在应用程序中使用updateStateByKey或reduceByKeyAndWindow（具有逆函数），则必须提供检查点目录以允许定期保存RDD检查点<br>2）从运行应用程序的driver程序的故障中恢复：元数据检查点用于使用进度信息进行恢复</p><p>③　如何配置检查点：<br>可以通过在一些可容错、高可靠的文件系统（例如，HDFS，S3等）中设置保存检查点信息的目录来启用检查点。这是通过使用streamingContext.checkpoint(checkpointDirectory)完成的。设置检查点后，您就可以使用上述的有状态转换操作。此外，如果要使应用程序从驱动程序故障中恢复，您应该重写streaming应用程序以使程序具有以下行为：<br>1）当程序第一次启动时，它将创建一个新的StreamingContext，设置好所有流数据源，然后调用start()方法。<br>2）当程序在失败后重新启动时，它将从checkpoint目录中的检查点数据重新创建一个StreamingContext。<br>使用StreamingContext.getOrCreate可以简化此行为</p><p>④　改写之前的WordCount程序，使得每次计算的结果和状态都保存到检查点目录下<br>hdfs dfs -ls /spark_checkpoint</p><h3 id="三、数据源">三、数据源</h3><p>Spark Streaming是一个流式计算引擎，就需要从外部数据源来接收数据</p><h4 id="1、基本的数据源">1、基本的数据源</h4><p>文件流：监控文件系统的变化，如果文件有增加，读取文件中的内容</p><p>希望Spark Streaming监控一个文件夹，如果有变化，则把变化采集过来</p><p><strong>此功能为</strong>修改文件里面的内容，并修改文件名，才能检测到，单修改一个是不起作用的</p><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Level/** * 测试文件流 */object FileStreaming {    def main(args: Array[String]): Unit = {        //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyNetworkWordCountByWindow").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(1))        //直接监控某个目录，如果有新文件产生，就读取出来    val lines = ssc.textFileStream("H:\\other\\test_file_stream")        lines.print()        ssc.start()        ssc.awaitTermination()  }}</code></pre><p>RDD队列流：可以从队列中获取数据（不常用）</p><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.spark.storage.StorageLevelimport org.apache.log4j.Loggerimport org.apache.log4j.Levelimport org.apache.spark.sql.SparkSessionimport org.apache.spark.rdd.RDDimport scala.collection.mutable.Queue/** * RDD队列流 */object RDDQueueStream {  def main(args: Array[String]): Unit = {          //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("RDDQueueStream").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(3))        //需要先创建一个队列RDD[Int]    val rddQueue = new Queue[RDD[Int]]()        //往队列里面添加数据 ----&gt; 创建数据源    for(i &lt;- 1 to 3){      rddQueue += ssc.sparkContext.makeRDD(1 to 10)            //为了便于观察      Thread.sleep(1000)    }       //从队列中接收数据，创建DStream    val inputDStream = ssc.queueStream(rddQueue)        //处理数据    val result = inputDStream.map(x =&gt; (x, x*2))        result.print()        ssc.start()    ssc.awaitTermination()   }}</code></pre><p>套接字流：socketTextStream</p><h4 id="2、高级数据源">2、高级数据源</h4><p>（1）Flume<br>Spark SQL 对接flume有多种方式：<br>push方式：flume将数据推送给Spark Streaming<br>flume/myagent/a4.conf</p><pre><code class="highlight plaintext"># bin/flume-ng agent -n a4 -f myagent/a4.conf -c conf -Dflume.root.logger=INFO.console# 定义agent名，source、channel、sink的名称a4.sources = r1a4.channels = c1a4.sinks = k1# 具体定义sourcea4.sources.r1.type = spooldira4.sources.r1.spoolDir = /root/hd/tmp_files/logs# 具体定义channela4.channels.c1.type = memorya4.channels.c1.capacity = 10000a4.channels.c1.transactionCapacity = 100# 具体定义sinka4.sinks = k1a4.sinks.k1.type = avroa4.sinks.k1.channel = c1a4.sinks.k1.hostname = 192.168.116.1a4.sinks.k1.port = 1234# 组装 source、channel、sinka4.sources.r1.channels = c1a4.sinks.k1.channel = c1</code></pre><pre><code class="highlight plaintext">package day5import org.apache.spark.streaming.StreamingContextimport org.apache.spark.SparkConfimport org.apache.spark.streaming.Secondsimport org.apache.log4j.Loggerimport org.apache.log4j.Levelimport org.apache.spark.streaming.flume.FlumeUtilsobject MyFlumeStream {  def main(args: Array[String]): Unit = {        //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)        //创建一个StreamingContext对象    //local[2]表示开启了两个线程    val conf = new SparkConf().setAppName("MyFlumeStream").setMaster("local[2]")        //Seconds(3)表示采样时间间隔     val ssc = new StreamingContext(conf, Seconds(3))        //对象flume    //创建一个flumeEvent  从flume中接收push来的数据，也是一个DStream    //flume将数据push到"192.168.116.1",1234  Spark Streaming在这里监听    val flumeEventDStream = FlumeUtils.createStream(ssc, "192.168.116.1", 8888)        //将FlumeEvent中的事件转换成字符串    val lineDStream = flumeEventDStream.map(e =&gt; {       new String(e.event.getBody.array)     })        //输出结果    lineDStream.print()        ssc.start()    ssc.awaitTermination()  }}</code></pre><p>custom sink 模式：比第一种有更好的健壮性和容错性。使用这种方式，flume配置一个sink<br>a1.conf</p><pre><code class="highlight plaintext">#bin/flume-ng agent -n a1 -f myagent/a1.conf -c conf -Dflume.root.logger=INFO,consolea1.channels = c1a1.sinks = k1a1.sources = r1a1.sources.r1.type = spooldira1.sources.r1.spoolDir = /root/hd/tmp_files/logsa1.channels.c1.type = memorya1.channels.c1.capacity = 100000a1.channels.c1.transactionCapacity = 100000a1.sinks.k1.type = org.apache.spark.streaming.flume.sink.SparkSinka1.sinks.k1.channel = c1a1.sinks.k1.hostname = 192.168.116.121a1.sinks.k1.port = 1234#组装source、channel、sinka1.sources.r1.channels = c1a1.sinks.k1.channel = c1</code></pre><p>使用官方提供的spark sink组件</p><p>需要把 spark-streaming-flume-sink_2.10-2.1.0.jar 拷贝到flume lib下<br>需要把 spark-streaming-flume-sink_2.10-2.1.0.jar 拷贝到IDE的lib下添加到build path中</p><p>（2）Kafka<br>在讲Kafka时，举例</p><h3 id="四、性能优化的参数">四、性能优化的参数</h3><p>性能优化：<br>spark submit的时候，程序报OOM错误<br>程序跑的很慢</p><h4 id="1、减少批数据的执行时间">1、减少批数据的执行时间</h4><p>在Spark中有几个优化可以减少批处理的时间：<br>①　数据接收的并行水平<br>通过网络(如kafka，flume，socket等)接收数据需要这些数据反序列化并被保存到Spark中。如果数据接收成为系统的瓶颈，就要考虑并行地接收数据。注意，每个输入DStream创建一个receiver（运行在worker机器上）接收单个数据流。创建多个输入DStream并配置它们可以从源中接收不同分区的数据流，从而实现多数据流接收。例如，接收两个topic数据的单个输入DStream可以被切分为两个kafka输入流，每个接收一个topic。这将在两个worker上运行两个receiver，因此允许数据并行接收，提高整体的吞吐量。多个DStream可以被合并生成单个DStream，这样运用在单个输入DStream的transformation操作可以运用在合并的DStream上</p><p>②　数据处理的并行水平<br>如果运行在计算stage上的并发任务数不足够大，就不会充分利用集群的资源。默认的并发任务数通过配置属性来确定spark.default.parallelism</p><p>③　数据序列化<br>可以通过改变序列化格式来减少数据序列化的开销。在流式传输的情况下，有两种类型的数据会被序列化：<br>1）输入数据<br>2）由流操作生成的持久RDD<br>在上述两种情况下，使用Kryo序列化格式可以减少CPU和内存开销</p><h4 id="2、设置正确的批容量">2、设置正确的批容量</h4><p>为了Spark Streaming应用程序能够在集群中稳定运行，系统应该能够以足够的速度处理接收的数据（即处理速度应该大于或等于接收数据的速度）。这可以通过流的网络UI观察得到。批处理时间应该小于批间隔时间</p><p>根据流计算的性质，批间隔时间可能显著的影响数据处理速率，这个速率可以通过应用程序维持。可以考虑WordCountNetwork这个例子，对于一个特定的数据处理速率，系统可能可以每2秒打印一次单词计数（批间隔时间为2秒），但无法每500毫秒打印一次单词计数。所以，为了在生产环境中维持期望的数据处理速率，就应该设置合适的批间隔时间(即批数据的容量)</p><p>找出正确的批容量的一个好的办法是用一个保守的批间隔时间（5-10,秒）和低数据速率来测试你的应用程序</p><h4 id="3、内存调优">3、内存调优</h4><p>在这一节，我们重点介绍几个强烈推荐的自定义选项，它们可以减少Spark Streaming应用程序垃圾回收的相关暂停，获得更稳定的批处理时间</p><p>1）Default persistence level of DStreams：和RDDs不同的是，默认的持久化级别是序列化数据到内存中（DStream是StorageLevel.MEMORY_ONLY_SER，RDD是StorageLevel.MEMORY_ONLY）。即使保存数据为序列化形态会增加序列化/反序列化的开销，但是可以明显的减少垃圾回收的暂停</p><p>2）Clearing persistent RDDs：默认情况下，通过Spark内置策略（LUR），Spark Streaming生成的持久化RDD将会从内存中清理掉。如果spark.cleaner.ttl已经设置了，比这个时间存在更老的持久化RDD将会被定时的清理掉。正如前面提到的那样，这个值需要根据Spark Streaming应用程序的操作小心设置。然而，可以设置配置选项spark.streaming.unpersist为true来更智能的去持久化（unpersist）RDD。这个配置使系统找出那些不需要经常保有的RDD，然后去持久化它们。这可以减少Spark RDD的内存使用，也可能改善垃圾回收的行为</p><p>3）Concurrent garbage collector：使用并发的标记-清除垃圾回收可以进一步减少垃圾回收的暂停时间。尽管并发的垃圾回收会减少系统的整体吞吐量，但是仍然推荐使用它以获得更稳定的批处理时间</p><p>方法：调整spark参数<br>conf.set…</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark SQL</title>
      <link href="/2019/03/31/spark_sql/"/>
      <url>/2019/03/31/spark_sql/</url>
      
        <content type="html"><![CDATA[<p>Spark SQL 类似于Hive</p><h3 id="一、Spark-SQL-基础">一、Spark SQL 基础</h3><h4 id="1、什么是Spark-SQL">1、什么是Spark SQL</h4><p>Spark SQL is Apache Spark’s module for working with structured data.<br>Spark SQL 是spark 的一个模块。来处理 结构化 的数据<br>不能处理非结构化的数据</p><p>特点：</p><p><strong>1）容易集成</strong></p><p>不需要单独安装</p><p><strong>2）统一的数据访问方式</strong></p><p>结构化数据的类型：JDBC JSon Hive parquer文件 都可以作为Spark SQL 的数据源<br>对接多种数据源，且使用方式类似</p><p><strong>3）完全兼容hive</strong></p><p>把Hive中的数据，读取到Spark SQL中运行</p><p><strong>4）支持标准的数据连接</strong></p><p>JDBC</p><h4 id="2、为什么学习Spark-SQL">2、为什么学习Spark SQL</h4><p>执行效率比Hive高</p><p>hive 2.x 执行引擎可以使用 Spark</p><h4 id="3、核心概念：表（DataFrame-DataSet）">3、核心概念：表（DataFrame DataSet）</h4><p>mysql中的表：表结构、数据<br>DataFrame：Schema、RDD（数据）</p><p>DataSet 在spark1.6以后，对DataFrame做了一个封装</p><h4 id="4、创建DataFrame">4、创建DataFrame</h4><p>（*）测试数据：员工表、部门表<br>第一种方式：使用case class<br><strong>1）定义Schema</strong><br>样本类来定义Schema</p><p>case class 特点：<br>可以支持模式匹配，使用case class建立表结构</p><p>7521, WARD, SALESMAN,7698, 1981/2/22, 1250, 500, 30</p><p>case class Emp(empno:Int,ename:String,job:String,mgr:Int,hiredate:String,sal:Int,comm:Int,deptno:Int)</p><p><strong>2）读取文件</strong><br>val lines = sc.textFile(“/root/hd/tmp_files/emp.csv”).map(_.split(“,”))</p><p><strong>3）把每行数据，映射到Emp上</strong><br>val allEmp = lines.map(x =&gt; Emp(x(0).toInt,x(1),x(2),x(3).toInt,x(4),x(5).toInt,x(6).toInt,x(7).toInt))</p><p><strong>4）生成DataFrame</strong><br>val df1 = allEmp.toDF</p><p>df1.show</p><p><strong>第二种方式 使用Spark Session</strong><br>（1）什么是Spark Session<br><strong>Spark session available as ‘spark’.</strong><br>2.0以后引入的统一访问方式。可以访问所有的Spark组件</p><p>def createDataFrame(rowRDD: RDD[Row], schema: StructType): DataFrame</p><p>（2）使用StructType来创建Schema</p><p>val struct =<br>StructType(<br>StructField(“a”, IntegerType, true) ::<br>StructField(“b”, LongType, false) ::<br>StructField(“c”, BooleanType, false) :: Nil)</p><p>case class Emp(<br>empno:Int,<br>ename:String,<br>job:String,<br>mgr:Int,<br>hiredate:String,<br>sal:Int,<br>comm:Int,<br>deptno:Int)</p><p>—————–分割———————-<br>import org.apache.spark.sql.types._</p><p>val myschema = StructType(<br>List(<br>StructField(“empno”,DataTypes.IntegerType),<br>StructField(“ename”,DataTypes.StringType),<br>StructField(“job”,DataTypes.StringType),<br>StructField(“mgr”,DataTypes.IntegerType),<br>StructField(“hiredate”,DataTypes.StringType),<br>StructField(“sal”,DataTypes.IntegerType),<br>StructField(“comm”,DataTypes.IntegerType),<br>StructField(“deptno”,DataTypes.IntegerType)<br>))</p><p>准备数据 RDD[Row]<br>import org.apache.spark.sql.Row</p><p>val allEmp = lines.map(x =&gt; Row(x(0).toInt,x(1),x(2),x(3).toInt,x(4),x(5).toInt,x(6).toInt,x(7).toInt))</p><p>val df2 = spark.createDataFrame(allEmp,myschema)</p><p>df2.show</p><p><strong>第三种方式</strong></p><p>直接读取一个带格式的文件<br>在/root/hd/spark-2.1.0-bin-hadoop2.7/examples/src/main/resources有现成的json代码</p><p>val df3 = spark.read 读文件，默认是Parquet文件<br>val df3 = spark.read.json(“/uroot/hd/tmp_files/people.json”)</p><p>df3.show</p><p>val df4 = spark.read.format(“json”).load(“/root/hd/tmp_files/people.json”)</p><p>df4.show</p><h4 id="5、操作DataFrame">5、操作DataFrame</h4><p><strong>1）DSL语句</strong><br>mybatis Hibernate</p><p>df1.printSchema</p><p>df1.select(“ename”,“sal”).show</p><p>df1.select($“ename”,$“sal”,$“sal”+100).show<br>$”sal” 可以看做是一个变量</p><p>查询薪水大于2000的员工<br>df1.filter($”sal” &gt; 2000).show</p><p>求每个部门的员工人数<br>df1.groupBy($”deptno”).count.show</p><p>相当于select deptno,count(1) from emp group by deptno</p><p><strong>2）SQL语句</strong></p><p>注意：不能直接执行SQL，需要生成一个视图，再执行sql</p><p>scala&gt; df1.create<br>createGlobalTempView createOrReplaceTempView createTempView</p><p>一般用到 createOrReplaceTempView createTempView<br>视图：类似于表，但不保存数据</p><p>df1.createOrReplaceTempView(“emp”)</p><p>操作：<br>spark.sql(“select * from emp”).show</p><p>查询薪水大于2000的员工<br>spark.sql(“select * from emp where sal &gt; 2000”).show</p><p>求每个部门的员工人数<br>spark.sql(“select deptno,count(1) from emp group by deptno”).show</p><p><strong>3）多表查询</strong></p><p>10,ACCOUNTING,NEW YORK</p><p>case class Dept(deptno:Int,dname:String,loc:String)<br>val lines = sc.textFile(“/root/hd/tmp_files/dept.csv”).map(_.split(“,”))<br>val allDept = lines.map(x=&gt;Dept(x(0).toInt,x(1),x(2)))</p><p>df5.createOrReplaceTempView(“dept”)</p><p>spark.sql(“select dname,ename from emp,dept where emp.deptno=dept.deptno”).show</p><h4 id="6、操作DataSet">6、操作DataSet</h4><p>Dataset是一个分布式的数据收集器。这是在Spark1.6之后新加的一个接口，兼顾了RDD的优点（强类型，可以使用功能强大的lambda）以及Spark SQL的执行器高效性的优点。所以可以把DataFrames看成是一种特殊的Datasets，即：Dataset(Row)</p><p>Dataset跟DataFrame类似，是一套新的接口，是高级的Dataframe</p><p>举例：</p><p><strong>1）创建DataSet</strong></p><p>（1）使用序列来创建DataSet<br>定义一个case class<br>case class MyData(a:Int,b:String)</p><p>生成序列，并创建DataSet<br>val ds = Seq(MyData(1,”Tom”),MyData(2,”Merry”)).toDS</p><p>.toDS 生成DataSet</p><p>ds.show</p><p>（2）使用JSON数据来创建DataSet</p><p>定义case class<br>case class Person(name:String,age:BigInt)</p><p>通过Json数据来生成DataFrame<br>val df = spark.read.format(“json”).load(“/root/hd/tmp_files/people.json”)</p><p>将DataFrame转换成DataSet<br><a href="http://df.as">df.as</a>[Person].show</p><p><a href="http://df.as">df.as</a>[Person] 就是一个DataSet</p><p>（3）使用其他数据<br>RDD操作和DataFrame操作相结合 —&gt; DataSet</p><p>读取数据，创建DataSet<br>val linesDS = spark.read.text(“/root/hd/tmp_files/test_WordCount.txt”).as[String]</p><p>对DataSet进行操作：<br>val words = linesDS.flatMap(.split(” “)).filter(.length &gt; 3)</p><p>words.show<br>words.collect</p><p>执行一个WordCount程序<br>val result = linesDS.flatMap(.split(” “)).map((,1)).groupByKey( x =&gt; x._1).count<br>result.show</p><p>排序：</p><pre><code class="highlight plaintext">result.orderBy($"value").showresult.orderBy($"count(1)").show</code></pre><p><strong>2）DataSet操作案例</strong></p><p>使用emp.json 生成一个DataFrame<br>val empDF = spark.read.json(“/root/hd/tmp_files/emp.json”)</p><p>查询工资大于3000的员工<br>empDF.where($”sal” &gt;= 3000).show</p><p>创建case class</p><p>case class Emp(empno:BigInt,ename:String,job:String,mgr:String,hiredate:String,sal:BigInt,comm:String,deptno:BigInt)</p><p>生成DataSet<br>val empDS = <a href="http://empDF.as">empDF.as</a>[Emp]</p><p>查询工资大于3000的员工<br>empDS.filter(_.sal &gt; 3000).show</p><p>查询10号部门的员工<br>empDS.filter(_.deptno == 10).show</p><p><strong>3）多表查询</strong></p><p>（1）创建部门表<br>val deptRDD = sc.textFile(“/root/hd/tmp_files/dept.csv”).map(_.split(“,”))<br>case class Dept(deptno:Int,dname:String,loc:String)</p><p>val deptDS = deptRDD.map( x=&gt; Dept(x(0).toInt,x(1),x(2))).toDS</p><p>（2）创建员工表<br>case class Emp(empno:Int,ename:String,job:String,mgr:Int,hiredate:String,sal:Int,comm:Int,deptno:Int)<br>val empRDD = sc.textFile(“/root/hd/tmp_files/emp.csv”).map(_.split(“,”))</p><p>7369,SMITH,CLERK,7902,1980/12/17,800,0,20<br>val empDS = empRDD.map(x=&gt; Emp(x(0).toInt,x(1),x(2),x(3).toInt,x(4),x(5).toInt,x(6).toInt,x(7).toInt)).toDS</p><p>（3）执行多表查询：等值连接<br>val result = deptDS.join(empDS,”deptno”)<br>result.show<br>result.printSchema</p><p>val result1 = deptDS.joinWith(empDS, deptDS(“deptno”) === empDS(“deptno”) )<br>result1.show<br>result1.printSchema</p><p>join 和 joinWith 区别：连接后schema不同</p><p>join ：将两张表展开成一张更大的表<br>joinWith ：把两张表的数据分别做成一列，然后直接拼在一起</p><p><strong>4）多表连接后再筛选</strong></p><p>deptDS.join(empDS,”deptno”).where(“deptno == 10”).show</p><p>result.explain：执行计划</p><h4 id="7、Spark-SQL-中的视图">7、Spark SQL 中的视图</h4><p>视图是一个虚表，不存储数据<br>两种类型：</p><p><strong>1）普通视图（本地视图）</strong></p><p>只在当前Session中有效createOrReplaceTempView createTempView</p><p><strong>2）全局视图</strong></p><p>createGlobalTempView<br>在不同的Session中都有用，把全局视图创建在命名空间中：global_temp中。类似于一个库</p><p>scala&gt; df1.create<br>createGlobalTempView createOrReplaceTempView createTempView</p><p>举例：<br>创建一个新session，读取不到emp视图，报错<br>df1.createOrReplaceTempView(“emp”)<br>spark.sql(“select * from emp”).show<br>spark.newSession.sql(“select * from emp”)</p><p>以下两种方式均可读到全局视图中的数据<br>df1.createGlobalTempView(“emp1”)</p><p>spark.newSession.sql(“select * from global_temp.emp1”).show</p><p>spark.sql(“select * from global_temp.emp1”).show</p><h3 id="二、使用数据源">二、使用数据源</h3><p>在Spark SQL中，可以使用各种各样的数据源来操作。 结构化</p><h4 id="1、使用load函数、save函数">1、使用load函数、save函数</h4><p>load函数是加载数据，save是存储数据</p><p>注意：使用load 或 save时，默认是Parquet文件。列式存储文件</p><p>举例:<br>读取 users.parquet 文件<br>val userDF = spark.read.load(“/root/hd/tmp_files/users.parquet”)</p><p>userDF.printSchema<br>userDF.show</p><p>val userDF = spark.read.load(“/root/hd/tmp_files/emp.json”)</p><p>保存parquet文件</p><pre><code class="highlight plaintext">userDF.select($"name",$"favorite_color").write.save("/root/hd/tmp_files/parquet")</code></pre><p>读取刚刚写入的文件：<br>val userDF1 = spark.read.load(“/root/hd/tmp_files/parquet/part-00000-f9a3d6bb-d481-4fc9-abf6-5f20139f97c5.snappy.parquet”)—&gt; 不推荐</p><p>生产中直接读取存放的目录即可：<br>val userDF2 = spark.read.load(“/root/hd/tmp_files/parquet”)</p><p>读json文件 必须format<br>val userDF = spark.read.format(“json”).load(“/root/hd/tmp_files/emp.json”)<br>val userDF3 = spark.read.json(“/root/hd/tmp_files/emp.json”)</p><p>关于<strong>save函数</strong>：</p><p>调用save函数的时候，可以指定存储模式，追加、覆盖等等<br>userDF.write.save(“/root/hd/tmp_files/parquet”)</p><p>userDF.write.save(“/root/hd/tmp_files/parquet”)<br>org.apache.spark.sql.AnalysisException: path file:/root/hd/tmp_files/parquet already exists.;</p><p>save的时候覆盖<br>userDF.write.mode(“overwrite”).save(“/root/hd/tmp_files/parquet”)</p><p>将结果保存成表<br>userDF.select($”name”).write.saveAsTable(“table1”)</p><p>scala&gt; userDF.select($”name”).write.saveAsTable(“table1”)</p><p>scala&gt; spark.sql(“select * from table1”).show<br>+——+<br>| name|<br>+——+<br>|Alyssa|<br>| Ben|<br>+——+</p><h4 id="2、Parquet文件">2、Parquet文件</h4><p>列式存储文件，是Spark SQL 默认的数据源<br>就是一个普通的文件</p><p>举例：<br>1）把其他文件，转换成Parquet文件<br>调用save函数<br>把数据读进来，再写出去，就是Parquet文件</p><p>val empDF = spark.read.json(“/root/hd/tmp_files/emp.json”)<br>empDF.write.mode(“overwrite”).save(“/root/hd/tmp_files/parquet”)<br>empDF.write.mode(“overwrite”).parquet(“/root/hd/tmp_files/parquet”)</p><p>val emp1 = spark.read.parquet(“/root/hd/tmp_files/parquet”)<br>emp1.createOrReplaceTempView(“emp1”)<br>spark.sql(“select * from emp1”)</p><p>2）支持Schema的合并<br>项目开始 表结构简单 schema简单<br>项目越来越大 schema越来越复杂</p><p>举例：<br>通过RDD来创建DataFrame<br>val df1 = sc.makeRDD(1 to 5).map( i =&gt; (i,i*2)).toDF(“single”,”double”)<br>“single”,”double” 是表结构<br>df1.show</p><p>df1.write.mode(“overwrite”).save(“/root/hd/tmp_files/test_table/key=1”)</p><p>val df2 = sc.makeRDD(6 to 10).map( i =&gt; (i,i*3)).toDF(“single”,”triple”)<br>df2.show<br>df2.write.mode(“overwrite”).save(“/root/hd/tmp_files/test_table/key=2”)</p><p>合并两个部分<br>val df3 = spark.read.parquet(“/root/hd/tmp_files/test_table”)</p><p>val df3 = spark.read.option(“mergeSchema”,true).parquet(“/root/hd/tmp_files/test_table”)</p><p><strong>key是可以随意取名字的，两个key需要一致，不然合并会报错</strong></p><p>通过RDD来创建DataFrame<br>val df1 = sc.makeRDD(1 to 5).map( i =&gt; (i,i*2)).toDF(“single”,”double”)<br>“single”,”double” 是表结构<br>df1.show</p><p>df1.write.mode(“overwrite”).save(“/root/hd/tmp_files/test_table/kt=1”)</p><p>val df2 = sc.makeRDD(6 to 10).map( i =&gt; (i,i*3)).toDF(“single”,”triple”)<br>df2.show<br>df2.write.mode(“overwrite”).save(“/root/hd/tmp_files/test_table/kt=2”)</p><p>合并两个部分<br>val df3 = spark.read.parquet(“/root/hd/tmp_files/test_table”)</p><p>val df3 = spark.read.option(“mergeSchema”,true).parquet(“/root/hd/tmp_files/test_table”)</p><h4 id="3、json文件">3、json文件</h4><p>读取Json文件，生成DataFrame<br>val peopleDF = spark.read.json(“/root/hd/tmp_files/people.json”)</p><p>peopleDF.printSchema</p><p>peopleDF.createOrReplaceTempView(“peopleView”)</p><p>spark.sql(“select * from peopleView”).show</p><p>Spark SQL 支持统一的访问接口。对于不同的数据源，读取进来，生成DataFrame后，操作完全一样</p><h4 id="4、JDBC">4、JDBC</h4><p>使用JDBC操作关系型数据库，加载到Spark中进行分析和处理</p><p>方式一：</p><pre><code class="highlight plaintext">./spark-shell --master spark://hsiehchou121:7077 --jars /root/hd/tmp_files/mysql-connector-java-8.0.12.jar --driver-class-path /root/hd/tmp_files/mysql-connector-java-8.0.12.jar</code></pre><pre><code class="highlight plaintext">val mysqlDF = spark.read.format("jdbc").option("url","jdbc:mysql://192.168.116.1/company?serverTimezone=UTC&amp;characterEncoding=utf-8").option("driver","com.mysql.cj.jdbc.Driver").option("user","root").option("password","123456").option("dbtable","emp").load</code></pre><pre><code class="highlight plaintext">val mysqlDF = spark.read.format("jdbc").option("url","jdbc:mysql://192.168.116.1/company?serverTimezone=UTC&amp;characterEncoding=utf-8").option("driver","com.mysql.cj.jdbc.Driver").option("user","root").option("password","123456").option("dbtable","emp").loadmysqlDF.show</code></pre><p><strong>问题解决</strong></p><p>如果遇到下面问题，就是你本机的mysql数据库没有权限给你虚拟机访问<br>java.sql.SQLException: null, message from server: “Host ‘hsiehchou121’ is not allowed to connect to this MySQL server”</p><p><strong>解决方案</strong></p><p>1）进入你本机的数据库<br>mysql -u root -p<br>2）use mysql;<br>3）修改root用户前面的Host，改为%，意思是全部IP都能访问<br>4）flush privileges;</p><p><strong>方式二</strong><br>定义一个Properties类<br>import java.util.Properties<br>val mysqlProps = new Properties()<br>mysqlProps.setProperty(“driver”,“com.mysql.cj.jdbc.Driver”)<br>mysqlProps.setProperty(“user”,“root”)<br>mysqlProps.setProperty(“password”,“123456”)</p><p>val mysqlDF1 = spark.read.jdbc(“jdbc:mysql://192.168.116.1:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8”,“emp”,mysqlProps)</p><p>mysqlDF1.show</p><h4 id="5、使用Hive">5、使用Hive</h4><p>比较常见<br>（<em>）spark SQL 完全兼容hive<br>（</em>）需要进行配置<br>拷贝一下文件到spark/conf目录下：<br>Hive 配置文件： hive-site.xml<br>Hadoop 配置文件：core-site.xml hdfs-site.xml</p><p>配置好后，重启spark</p><p><strong>在hive的lib下和spark的jars下面增加mysql-connector-java-8.0.12.jar这边连接数据库的jar包</strong></p><p>启动Hadoop ：<a href="http://start-all.sh">start-all.sh</a><br>启动 hive：</p><pre><code class="highlight plaintext">hsiehchou121cd hive/bin/./hive --service metastorehsiehchou122cd hive/bin./hive</code></pre><p><strong>hsiehchou121启动问题</strong></p><p>java.sql.SQLSyntaxErrorException: Table ‘hive.version’ doesn’t exist<br>解决：去mysql数据库中的hive库下面创建version表<br>这里需要给本地的hive库创建下hive所必须用的表</p><p>我们去/root/hd/hive/scripts/metastore/upgrade/mysql这里面找到hive-schema-1.2.0.mysql.sql，将里面的sql语句在hive库中执行</p><p>hive-txn-schema-0.14.0.mysql.sql，这个也做好执行下，用于事务管理</p><p><strong>显示当前所在库名字</strong></p><p>set hive.cli.print.current.db=true;</p><p>j将emp.csv上传到hdfs中的/tmp_files/下面<br>hdfs dfs -put emp.csv /tmp_files</p><p>在hive中创建emp_default表</p><pre><code class="highlight plaintext">hive (default)&gt; create table emp(empno int,ename string,job string,mgr int,hiredate string,sal int,comm int,deptno int)              &gt; row format              &gt; delimited fields              &gt; terminated by ",";hive (default)&gt; load data inpath '/tmp_files/emp.csv' into table emp;Time taken: 1.894 secondshive (default)&gt; show tables;hive (default)&gt; select * from emp;</code></pre><p>hdfs dfs -put /root/hd/tmp_files/emp.csv /tmp_files</p><pre><code class="highlight plaintext">[root@hsiehchou121 bin]# ./spark-shell --master spark://hsiehchou121:7077</code></pre><p>启动Spatk时，如果出现如下错误<br>java.sql.SQLSyntaxErrorException: Table ‘hive.partitions’ doesn’t exist<br>在MySQL数据库里面创建partitions表</p><p>scala&gt; spark.sql(“select * from emp_default”).show<br>scala&gt; spark.sql(“select * from default.emp_default”).show</p><p>spark.sql(“create table company.emp_4(empno Int,ename String,job String,mgr String,hiredate String,sal Int,comm String,deptno Int)row format delimited fields terminated by ‘,’”)<br>spark.sql(“load data local inpath ‘/root/hd/tmp_files/emp.csv’ overwrite into table company.emp_4”)</p><h3 id="三、在IDE中开发Spark-SQL">三、在IDE中开发Spark SQL</h3><h4 id="1、创建DataFrame-StructType方式">1、创建DataFrame StructType方式</h4><pre><code class="highlight plaintext">package day4import org.apache.spark.sql.SparkSessionimport org.apache.spark.sql.types.StructTypeimport org.apache.spark.sql.types.StructFieldimport org.apache.spark.sql.types.IntegerTypeimport org.apache.spark.sql.types.StringTypeimport org.apache.spark.sql.Rowimport org.apache.log4j.Loggerimport org.apache.log4j.Level/** * 创建DataFrame StructType方式 */object Demo1 {  def main(args: Array[String]): Unit = {    //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)    //创建Spark Session对象    val spark = SparkSession.builder().master("local").appName("Demo1").getOrCreate()    //从指定的地址创建RDD对象    val personRDD = spark.sparkContext.textFile("H:\\other\\students.txt").map(_.split("\t"))    //通过StructType方式指定Schema    val schema = StructType(      List(        StructField("id", IntegerType),        StructField("name", StringType),        StructField("age", IntegerType)))    //将RDD映射到rowRDD上，映射到Schema上    val rowRDD = personRDD.map(p =&gt; Row(p(0).toInt,p(1),p(2).toInt))    val personDataFrame = spark.createDataFrame(rowRDD, schema)    //注册视图    personDataFrame.createOrReplaceTempView("t_person")    //执行SQL语句  desc降序   asc 升序    val df = spark.sql("select * from t_person order by age desc")    df.show    spark.stop()  }}</code></pre><h4 id="2、使用case-class来创建DataFrame">2、使用case class来创建DataFrame</h4><pre><code class="highlight plaintext">package day4import org.apache.log4j.Loggerimport org.apache.log4j.Levelimport org.apache.spark.sql.SparkSession/** * 使用case class来创建DataFrame */object Demo2 {  def main(args: Array[String]): Unit = {    //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)    //创建Spark Session对象    val spark = SparkSession.builder().master("local").appName("Demo1").getOrCreate()    //从指定的地址创建RDD对象    val lineRDD = spark.sparkContext.textFile("H:\\other\\students.txt").map(_.split("\t"))    //把数据与case class做匹配    val studentRDD = lineRDD.map(x =&gt; Student(x(0).toInt,x(1),x(2).toInt))    //生成DataFrame    import spark.sqlContext.implicits._    val studentDF = studentRDD.toDF()    //注册视图,执行SQL    studentDF.createOrReplaceTempView("student")    spark.sql("select * from student").show    spark.stop()  }}//定义case classcase class Student(stuId:Int, stuName:String, stuAge:Int)</code></pre><h4 id="3、写入MySQL">3、写入MySQL</h4><pre><code class="highlight plaintext">package day4import org.apache.log4j.Loggerimport org.apache.log4j.Levelimport org.apache.spark.sql.SparkSessionimport org.apache.spark.sql.types.IntegerTypeimport org.apache.spark.sql.types.StringTypeimport org.apache.spark.sql.Rowimport org.apache.spark.sql.types.StructTypeimport org.apache.spark.sql.types.StructFieldimport java.util.Properties/** * 写入mysql */object Demo3 {  def main(args: Array[String]): Unit = {    //减少Info日志的打印    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)    Logger.getLogger("org.eclipse.jetty.server").setLevel(Level.OFF)    //创建Spark Session对象    val spark = SparkSession.builder().master("local").appName("Demo1").getOrCreate()    //从指定的地址创建RDD对象    val lineRDD = spark.sparkContext.textFile("H:\\other\\students.txt").map(_.split("\t"))    //通过StructType方式指定Schema    val schema = StructType(      List(        StructField("personID", IntegerType),        StructField("personName", StringType),        StructField("personAge", IntegerType)))    //将RDD映射到rowRDD上，映射到Schema上    val rowRDD = lineRDD.map(p =&gt; Row(p(0).toInt,p(1),p(2).toInt))    val personDataFrame = spark.createDataFrame(rowRDD, schema)    personDataFrame.createOrReplaceTempView("myperson")    val result = spark.sql("select * from myperson")    result.show    //把结果存入mysql中    val props = new Properties()    props.setProperty("user", "root")    props.setProperty("password", "123456")    props.setProperty("driver", "com.mysql.cj.jdbc.Driver")    result.write.mode("append").jdbc("jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8", "student", props)    spark.stop()  }}</code></pre><h4 id="4、使用Spark-SQL-读取Hive中的数据，将计算结果存入MySQL">4、使用Spark SQL 读取Hive中的数据，将计算结果存入MySQL</h4><pre><code class="highlight plaintext">package day4import org.apache.spark.sql.SparkSessionimport java.util.Properties/** * 使用Spark SQL 读取Hive中的数据，将计算结果存入mysql */object Demo4 {  def main(args: Array[String]): Unit = {    //创建SparkSession    val spark = SparkSession.builder().appName("Demo4").enableHiveSupport().getOrCreate()    //执行SQL    val result = spark.sql("select deptno,count(1) from company.emp group by deptno")    //将结果保存到mysql中     val props = new Properties()    props.setProperty("user", "root")    props.setProperty("password", "123456")    props.setProperty("driver", "com.mysql.cj.jdbc.Driver")    result.write.jdbc("jdbc:mysql://192.168.116.1:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8", "emp_stat", props)    spark.stop()  } }</code></pre><p><strong>提交任务</strong></p><pre><code class="highlight plaintext">[root@hsiehchou121 bin]# ./spark-submit --master spark://hsiehchou121:7077 --jars /root/hd/tmp_files/mysql-connector-java-8.0.12.jar --driver-class-path /root/hd/tmp_files/mysql-connector-java-8.0.12.jar --class day4.Demo4 /root/hd/tmp_files/Demo4.jar</code></pre><h3 id="四、性能优化">四、性能优化</h3><p>与RDD类似</p><h4 id="1、把内存中缓存表的数据">1、把内存中缓存表的数据</h4><p>直接读取内存的值，来提高性能</p><p>RDD中如何缓存：<br>rdd.cache 或者 rdd.persist</p><p>在Spark SQL中，使用SparkSession.sqlContext.cacheTable</p><p>spark中所有context对象<br>1）sparkContext ： SparkCore<br>2）sql Context ： SparkSQL<br>3）Streaming Context ：SparkStreaming</p><p>统一起来：SparkSession</p><p>操作mysql，启动spark shell 时，需要：<br>./spark-shell <code>--master</code> spark://hsiehchou121:7077 <code>--jars</code> /root/hd/tmp_files/mysql-connector-java-8.0.12.jar <code>--driver-class-path</code> /root/hd/tmp_files/mysql-connector-java-8.0.12.jar</p><p>val mysqlDF = spark.read.format(“jdbc”).option(“driver”,”com.mysql.cj.jdbc.Driver”).option(“url”,”jdbc:mysql://192.168.116.1:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8”).option(“user”,”root”).option(“password”,”123456”).option(“dbtable”,”emp”).load</p><p>mysqlDF.show<br>mysqlDF.createOrReplaceTempView(“emp”)</p><p>spark.sqlContext.cacheTable(“emp”) —-&gt; 标识这张表可以被缓存，数据还没有真正被缓存<br>spark.sql(“select * from emp”).show —-&gt; 依然读取mysql<br>spark.sql(“select * from emp”).show —-&gt; 从缓存中读取数据</p><p>spark.sqlContext.clearCache</p><p>清空缓存后，执行查询，会触发查询mysql数据库</p><h4 id="2、了解性能优化的相关参数">2、了解性能优化的相关参数</h4><p>将数据缓存到内存中的相关优化参数<br>spark.sql.inMemoryColumnarStorage.compressed<br>默认为 true<br>Spark SQL 将会基于统计信息自动地为每一列选择一种压缩编码方式</p><p>spark.sql.inMemoryColumnarStorage.batchSize<br>默认值：10000<br>缓存批处理大小。缓存数据时, 较大的批处理大小可以提高内存利用率和压缩率，但同时也会带来 OOM（Out Of Memory）的风险</p><p>其他性能相关的配置选项（不过不推荐手动修改，可能在后续版本自动的自适应修改）<br>spark.sql.files.maxPartitionBytes<br>默认值：128 MB<br>读取文件时单个分区可容纳的最大字节数</p><p>spark.sql.files.openCostInBytes<br>默认值：4M<br>打开文件的估算成本, 按照同一时间能够扫描的字节数来测量。当往一个分区写入多个文件的时候会使用。高估更好, 这样的话小文件分区将比大文件分区更快 (先被调度)</p><p>spark.sql.autoBroadcastJoinThreshold<br>默认值：10M<br>用于配置一个表在执行 join 操作时能够广播给所有 worker 节点的最大字节大小。通过将这个值设置为 -1 可以禁用广播。注意，当前数据统计仅支持已经运行了 ANALYZE TABLE COMPUTE STATISTICS noscan 命令的 Hive Metastore 表</p><p>spark.sql.shuffle.partitions<br>默认值：200<br>用于配置 join 或聚合操作混洗（shuffle）数据时使用的分区数</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark Core</title>
      <link href="/2019/03/29/spark_core/"/>
      <url>/2019/03/29/spark_core/</url>
      
        <content type="html"><![CDATA[<p>Spark生态圈：<br>Spark Core ： RDD（弹性分布式数据集）<br>Spark SQL<br>Spark Streaming<br>Spark MLLib ：协同过滤，ALS，逻辑回归等等 –&gt; 机器学习<br>Spark Graphx ： 图计算</p><h3 id="一、Spark-Core">一、Spark Core</h3><h4 id="1、什么是Spark？特点">1、什么是Spark？特点</h4><p><a href="https://spark.apache.org/">https://spark.apache.org/</a><br>Apache Spark™ is a unified analytics engine for large-scale data processing.<br>特点：快、易用、通用性、兼容性（完全兼容Hadoop）</p><p>快：快100倍（Hadoop 3 之前）<br>易用：支持多种语言开发<br>通用性：生态系统全<br>易用性：兼容Hadoop</p><h3 id="二、安装和部署Spark、Spark-的-HA">二、安装和部署Spark、Spark 的 HA</h3><h4 id="1、Spark体系结构">1、Spark体系结构</h4><p>Spark的运行方式</p><p>Yarn</p><p>Standalone：本机调试（Demo）</p><p>Worker：从节点。每个服务器上，资源和任务的管理者。只负责管理一个节点</p><p>执行过程：<br>一个Worker 有多个 Executor。 Executor是任务的执行者，按阶段（stage）划分任务。————&gt; RDD</p><p>客户端：Driver Program 提交任务到集群中<br>1）spark-submit<br>2）spark-shell</p><h4 id="2、Spark的搭建">2、Spark的搭建</h4><p>1）准备工作：JDK 配置主机名 免密码登录</p><p>2）伪分布式模式<br>在一台虚拟机上模拟分布式环境（Master和Worker在一个节点上）<br><a href="http://xn--spark-env-9i9x315l.sh">配置spark-env.sh</a><br>vi <a href="http://spark-env.sh">spark-env.sh</a></p><pre><code class="highlight plaintext">export JAVA_HOME=/root/hd/jdk1.8.0_192export SPARK_MASTER_HOST=hsiehchou121export SPARK_MASTER_PORT=7077</code></pre><p>配置slaves<br>vi slaves<br>hsiehchou121</p><p>浏览器访问hsiehchou121:8080</p><p>在Spark中使用Scala语言</p><pre><code class="highlight plaintext">[root@hsiehchou121 bin]# ./spark-shell --master spark://hsiehchou121:7077</code></pre><p>3）全分布式环境<br>修改slave文件 拷贝到其他三台服务器 启动</p><h4 id="3、Spark的-HA">3、Spark的 HA</h4><p>回顾HA（高可用）<br>（<em>）HDFS Yarn Hbase Spark 主从结构<br>（</em>）单点故障</p><p>（1）基于文件目录的单点恢复<br>主要用于开发或测试环境。当spark提供目录保存spark Application和worker的注册信息，并将他们的恢复状态写入该目录中，这时，一旦Master发生故障，就可以通过重新启动Master进程（sbin/start-master.sh），恢复已运行的spark Application和worker的注册信息</p><p>基于文件系统的单点恢复，主要是在spark-en.sh里对SPARK_DAEMON_JAVA_OPTS设置</p><table><thead><tr><th style="text-align:center">配置参数</th><th style="text-align:center">参考值</th></tr></thead><tbody><tr><td style="text-align:center">spark.deploy.recoveryMode</td><td style="text-align:center">设置为FILESYSTEM开启单点恢复功能，默认值：NONE</td></tr><tr><td style="text-align:center">spark.deploy.recoveryDirectory</td><td style="text-align:center">Spark 保存恢复状态的目录</td></tr></tbody></table><p><strong>参考</strong>：<br>export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoveryMode=FILESYSTEM -Dspark.deploy.recoveryDirectory=/root/hd/spark-2.1.0-bin-hadoop2.7/recovery”</p><p>（*）本质：还是只有一个主节点Master，创建了一个恢复目录，保存集群状态和任务的信息<br>当Master挂掉，重新启动时，会从恢复目录下读取状态信息，恢复出来原来的状态</p><p>用途：这个只用于开发和测试，但是生产使用用ZooKeeper</p><p>export SPARK_DAEMON_JAVA_OPTS=“-Dspark.deploy.recoveryMode=FILESYSTEM -Dspark.deploy.recoveryDirectory=/root/hd/spark-2.1.0-bin-hadoop2.7/recovery”</p><p>（2）基于ZooKeeper ：和Hadoop类似<br>ZooKeeper提供了一个Leader Election机制，利用这个机制可以保证虽然集群存在多个Master，但是只有一个是Active的，其他的都是Standby。当Active的Master出现故障时，另外的一个Standby Master会被选举出来。由于集群的信息，包括Worker， Driver和Application的信息都已经持久化到ZooKeeper，因此在切换的过程中只会影响新Job的提交，对于正在进行的Job没有任何的影响</p><table><thead><tr><th style="text-align:center">配置参数</th><th style="text-align:center">参考值</th></tr></thead><tbody><tr><td style="text-align:center">spark.deploy.recoveryMode</td><td style="text-align:center">设置为ZOOKEEPER开启单点恢复功能，默认值：NONE</td></tr><tr><td style="text-align:center">spark.deploy.zookeeper.url</td><td style="text-align:center">ZooKeeper集群的地址</td></tr><tr><td style="text-align:center">spark.deploy.zookeeper.dir</td><td style="text-align:center">Spark信息在ZK中的保存目录，默认：/spark</td></tr></tbody></table><p><strong>参考</strong>：<br>export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181 -Dspark.deploy.zookeeper.dir=/spark”</p><p>（*）复习一下zookeeper：<br>相当于一个数据库，把一些信息存放在zookeeper中，比如集群的信息<br>数据同步功能，选举功能，分布式锁功能</p><p>数据同步：给一个节点中写入数据，可以同步到其他节点</p><p>选举：Zookeeper中存在不同的角色，Leader Follower。如果Leader挂掉，重新选举Leader</p><p>分布式锁：秒杀。以目录节点的方式来保存数据</p><p>修改 <a href="http://spark-env.sh">spark-env.sh</a></p><pre><code class="highlight plaintext">export JAVA_HOME=/root/hd/jdk1.8.0_192#export SPARK_MASTER_HOST=hsiehchou121#export SPARK_MASTER_PORT=7077#export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=FILESYSTEM -Dspark.deploy.recoveryDirectory=/root/hd/spark-2.1.0-bin-hadoop2.7/recovery"export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181 -Dspark.deploy.zookeeper.dir=/spark"</code></pre><p>同步到其他三台服务器<br>[root@hsiehchou121 spark-2.1.0-bin-hadoop2.7]# scp conf/spark-env.sh hsiehchou122:/root/hd/spark-2.1.0-bin-hadoop2.7/conf<br>[root@hsiehchou121 spark-2.1.0-bin-hadoop2.7]# scp conf/spark-env.sh hsiehchou123:/root/hd/spark-2.1.0-bin-hadoop2.7/conf<br>[root@hsiehchou121 spark-2.1.0-bin-hadoop2.7]# scp conf/spark-env.sh hsiehchou124:/root/hd/spark-2.1.0-bin-hadoop2.7/conf</p><p>在hsiehchou121 start-all hsiehchou121 master hsiehchou122 Worker hsiehchou123 Worker hsiehchou124 Worker<br>在hsiehchou121 start-master hsiehchou121 master hsiehchou122 master（standby） hsiehchou122 Worker hsiehchou123 Worker hsiehchou124 Worker</p><p>在hsiehchou121 上kill master<br>hsiehchou122 master（Active） hsiehchou122 Worker hsiehchou123 Worker hsiehchou124 Worker</p><p>在网页<a href="http://192.168.116.122:8080/">http://192.168.116.122:8080/</a> 可以看到相应信息</p><h3 id="三、执行Spark的任务：两个工具">三、执行Spark的任务：两个工具</h3><h4 id="1、spark-submit：用于提交Spark的任务">1、spark-submit：用于提交Spark的任务</h4><p>任务：jar</p><p>举例：蒙特卡洛求PI（圆周率）</p><p>./spark-submit <code>--master</code> spark://hsiehchou121:7077 <code>--class</code><br><code>--class</code>指明主程序的名字</p><pre><code class="highlight plaintext">[root@hsiehchou121 /]#cd /root/hd/spark-2.1.0-bin-hadoop2.7/bin[root@hsiehchou121 bin]# ./spark-submit --master spark://hsiehchou121:7077 --class org.apache.spark.examples.SparkPi /root/hd/spark-2.1.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.1.0.jar 100</code></pre><p>其中100指定执行的次数</p><h4 id="2、spark-shell-相当于REPL">2、spark-shell 相当于REPL</h4><p>spark-shell是Spark自带的交互式Shell程序，方便用户进行交互式编程，用户可以在该命令行下用scala编写spark程序<br>（*）启动Spark Shell：spark-shell<br>也可以使用以下参数：<br>参数说明：<br><code>--master</code> spark://hsiehchou121:7077 指定Master的地址<br><code>--executor-memory</code> 2g 指定每个worker可用内存为2G<br><code>--total-executor-cores</code> 2 指定整个集群使用的cup核数为2个<br>例如：</p><p>spark-shell <code>--master</code> spark://hsiehchou121:7077 <code>--executor-memory</code> 2g <code>--total-executor-cores</code> 2<br>注意：<br>如果启动spark shell时没有指定master地址，但是也可以正常启动spark shell和执行spark shell中的程序，其实是启动了spark的local模式，该模式仅在本机启动一个进程，没有与集群建立联系</p><p>作为一个独立的Application运行<br>两种模式：<br>（1）<strong>本地模式</strong><br>spark-shell 后面不接任何参数，代表本地模式<br>./spark-shell<br>Spark context available as ‘sc’ (master = local[<em>], app id = local-1554372019995).<br>sc 是 SparkContext 对象名。 local[</em>] 代表本地模式，不提交到集群中运行</p><p>（2）<strong>集群模式</strong><br>[root@hsiehchou121 bin]# ./spark-shell <code>--master</code> spark://hsiehchou121:7077<br>提交到集群运行<br>Spark context available as ‘sc’ (master = spark://hsiehchou121:7077, app id = app-20190404190030-0000).</p><p>master = spark://hsiehchou121:7077<br>Spark session available as ‘spark’<br>Spark Session 是 2.0 以后提供的，利用 SparkSession 可以访问spark所有组件</p><p>示例：<br><strong>WordCount程序</strong></p><p>程序如下：</p><pre><code class="highlight plaintext">sc.textFile("hdfs://192.168.116.121:9000/data.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).saveAsTextFile("hdfs://192.168.116.121:9000/output/wc")</code></pre><p>说明：<br>sc是SparkContext对象，该对象时提交spark程序的入口<br>textFile(“hdfs://192.168.116.121:9000/data.txt”)是hdfs中读取数据<br>flatMap(<em>.split(” “))先map在压平<br>map((</em>,1))将单词和1构成元组<br>reduceByKey(+)按照key进行reduce，并将value累加<br>saveAsTextFile(“hdfs://192.168.116.121:9000/output/wc”)将结果写入到hdfs中</p><p>（*）处理本地文件，把结果打印到屏幕上<br>vi /root/hd/tmp_files/test_WordCount.txt<br>I love China<br>I love Jiangsu<br>Jiangsu is a beautiful place in China</p><pre><code class="highlight plaintext">scala&gt; sc.textFile("/root/hd/tmp_files/test_WordCount.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collectres0: Array[(String, Int)] = Array((is,1), (love,2), (China,2), (a,1), (Jiangsu,2), (I,2), (in,1), (place,1), (beautiful,1))</code></pre><p>（*）处理HDFS文件，结果保存在HDFS上</p><pre><code class="highlight plaintext">[root@hsiehchou121 tmp_files]# hdfs dfs -mkdir /tmp_files[root@hsiehchou121 tmp_files]# hdfs dfs -copyFromLocal ~/hd/tmp_files/test_WordCount.txt /tmp_files</code></pre><pre><code class="highlight plaintext">scala&gt; sc.textFile("hdfs://hsiehchou121:9000/tmp_files/test_WordCount.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).saveAsTextFile("hdfs://hsiehchou121:9000/out/0404/test_WordCount")</code></pre><p>-rw-r–r– 3 root supergroup 0 2019-04-04 19:12 /out/0404/test_WordCount/_SUCCESS<br>-rw-r–r– 3 root supergroup 16 2019-04-04 19:12 /out/0404/test_WordCount/part-00000<br>-rw-r–r– 3 root supergroup 65 2019-04-04 19:12 /out/0404/test_WordCount/part-00001</p><p>_SUCCESS 代表程序执行成功</p><p>part-00000 part-00001 结果文件，分区。里面内容不重复</p><p>（*）单步运行WordCount —-&gt; RDD<br>scala&gt; val rdd1 = sc.textFile(“/root/hd/tmp_files/test_WordCount.txt”)<br>rdd1: org.apache.spark.rdd.RDD[String] = /root/hd/tmp_files/test_WordCount.txt MapPartitionsRDD[12] at textFile at <code>&lt;console&gt;:</code>24</p><p>scala&gt; rdd1.collect<br>res5: Array[String] = Array(I love China, I love Jiangsu, Jiangsu is a beautiful place in China)</p><p>scala&gt; val rdd2 = rdd1.flatMap(_.split(" "))<br>rdd2: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[14] at flatMap at <code>&lt;console&gt;</code>:26</p><p>scala&gt; rdd2.collect<br>res6: Array[String] = Array(I, love, China, I, love, Jiangsu, Jiangsu, is, a, beautiful, place, in, China)</p><p>scala&gt; val rdd3 = rdd2.map((_,1))<br>rdd3: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[15] at map at <code>&lt;console&gt;</code>:28</p><p>scala&gt; rdd3.collect<br>res7: Array[(String, Int)] = Array((I,1), (love,1), (China,1), (I,1), (love,1), (Jiangsu,1), (Jiangsu,1), (is,1), (a,1), (beautiful,1), (place,1), (in,1), (China,1))</p><p>scala&gt; val rdd4 = rdd3.reduceByKey(<em>+</em>)<br>rdd4: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[16] at reduceByKey at <code>&lt;console&gt;</code>:30</p><p>scala&gt; rdd4.collect<br>res8: Array[(String, Int)] = Array((is,1), (love,2), (China,2), (a,1), (Jiangsu,2), (I,2), (in,1), (place,1), (beautiful,1))</p><p><strong>RDD 弹性分布式数据集</strong></p><p>（1）依赖关系 ： 宽依赖和窄依赖<br>（2）算子：<br>函数：<br>Transformation ： 延时计算 map flatMap textFile<br>Action ： 立即触发计算 collect</p><p>说明：</p><p><strong>scala复习</strong></p><p>（*）flatten：把嵌套的结果展开<br>scala&gt; List(List(2,4,6,8,10),List(1,3,5,7,9)).flatten<br>res21: List[Int] = List(2, 4, 6, 8, 10, 1, 3, 5, 7, 9)</p><p>（*）flatmap : 相当于一个 map + flatten<br>scala&gt; var myList = List(List(2,4,6,8,10),List(1,3,5,7,9))<br>myList: List[List[Int]] = List(List(2, 4, 6, 8, 10), List(1, 3, 5, 7, 9))</p><p>scala&gt; myList.flatMap(x=&gt;x.map(_*2))<br>res22: List[Int] = List(4, 8, 12, 16, 20, 2, 6, 10, 14, 18)</p><p>myList.flatMap(x=&gt;x.map(_*2))</p><p>执行过程：<br>（1）将 List(2, 4, 6, 8, 10), List(1, 3, 5, 7, 9) 调用 map(_*2) 方法。x 代表一个List<br>（2）flatten<br>（3）在IDE中开发scala版本和Java版本的WorkCount</p><h3 id="四、WordCount（Scala版本和Java版本）">四、WordCount（Scala版本和Java版本）</h3><h4 id="1、Scala版本的WordCount">1、Scala版本的WordCount</h4><p>新建一个工程，把jar引入到工程中</p><pre><code class="highlight plaintext">package day1import org.apache.spark.SparkConfimport org.apache.spark.SparkContextobject WordCount {  def main(args: Array[String]): Unit = {    //创建一个Spark的配置文件    val conf = new SparkConf().setAppName("My Scala WordCount 0404").setMaster("local")    //创建SparkContext对象    val sc = new SparkContext(conf)    //1.从本地模式运行 .setMaster("local")   //val result = sc.textFile("hdfs://hsiehchou121:9000/tmp_files/test_WordCount.txt")      //.flatMap(_.split(" "))      //.map((_,1))      //.reduceByKey(_+_)    //result.foreach(println)    //2、在集群模式运行    val result = sc.textFile(args(0))      .flatMap(_.split(" "))      .map((_, 1))      .reduceByKey(_ + _)      .saveAsTextFile(args(1))    sc.stop()  }}</code></pre><p>export Demo1.jar 点击下一步，把jar包上传到服务器上/root/hd/tmp_files/下</p><p>在spark里面的bin目录下输入</p><p>[root@hsiehchou121 bin]# ./spark-submit <code>--master</code> spark://hsiehchou121:7077 <code>--class</code> day1.WordCount /root/hd/tmp_files/Demo1.jar hdfs://hsiehchou121:9000/tmp_files/test_WordCount.txt hdfs://hsiehchou121:9000/out/0405/Demo1</p><h4 id="2、Java版本的WordCount">2、Java版本的WordCount</h4><pre><code class="highlight plaintext">package day1;import java.util.Arrays;import java.util.Iterator;import java.util.List;import org.apache.spark.SparkConf;import org.apache.spark.api.java.JavaPairRDD;import org.apache.spark.api.java.JavaRDD;import org.apache.spark.api.java.JavaSparkContext;import org.apache.spark.api.java.function.FlatMapFunction;import org.apache.spark.api.java.function.Function2;import org.apache.spark.api.java.function.PairFunction;import scala.Tuple2;public class JavaWordCount {    public static void main(String[] args) {        SparkConf conf = new SparkConf().setAppName("JavaWordCount").setMaster("local");        //创建SparkContext对象        JavaSparkContext sc = new JavaSparkContext(conf);        //读入数据        JavaRDD&lt;String&gt; lines = sc.textFile("hdfs://192.168.116.121:9000/tmp_files/test_WordCount.txt");        //分词，第一个参数表示读进来的每一句话，第二个参数表示返回值        JavaRDD&lt;String&gt; words = lines.flatMap(new FlatMapFunction&lt;String,String&gt;(){            @Override            public Iterator&lt;String&gt; call(String input) throws Exception {                return Arrays.asList(input.split(" ")).iterator();            }        });        //每一个单词记一个数        JavaPairRDD&lt;String,Integer&gt; ones = words.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {            @Override            public Tuple2&lt;String, Integer&gt; call(String input) throws Exception {                return new Tuple2&lt;String, Integer&gt;(input,1);            }        });        //执行reduce操作        JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {            @Override            public Integer call(Integer arg0, Integer arg1) throws Exception {                return arg0 + arg1;            }        });        List&lt;Tuple2&lt;String,Integer&gt;&gt; output = counts.collect();        for(Tuple2&lt;String, Integer&gt; tuple:output) {            System.out.println(tuple._1 + ":" + tuple._2);        }        sc.stop();    }}</code></pre><p>[root@hsiehchou121 bin]# ./spark-submit <code>--master</code> spark://hsiehchou121:7077 <code>--class</code> day1.JavaWordCount /root/hd/tmp_files/Demo2.jar</p><h3 id="五、分析Spark的任务流程">五、分析Spark的任务流程</h3><h4 id="1、分析WordCount程序处理过程">1、分析WordCount程序处理过程</h4><p><img src="/medias/WordCount%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90.PNG" alt="WordCount程序分析"></p><h4 id="2、Spark调度任务的过程">2、Spark调度任务的过程</h4><p>提交到及群众运行任务时，spark执行任务调度<br><img src="/medias/spark%E7%9A%84%E8%B0%83%E7%94%A8%E4%BB%BB%E5%8A%A1%E8%BF%87%E7%A8%8B.PNG" alt="spark的调用任务过程"></p><h3 id="六、RDD和RDD特性、RDD的算子">六、RDD和RDD特性、RDD的算子</h3><h4 id="1、RDD：弹性分布式数据集">1、RDD：弹性分布式数据集</h4><p>（<em>）Spark中最基本的数据抽象<br>（</em>）RDD的特性</p><p>Internally, each RDD is characterized by five main properties:<br>*</p><p>A list of partitions<br>1）是一组分区<br>RDD由分区组成，每个分区运行在不同的Worker上，通过这种方式来实现分布式计算</p><p><img src="/medias/RDD.PNG" alt="RDD"></p><p>A function for computing each split<br>在RDD中，提供算子处理每个分区中的数据</p><p>-A list of dependencies on other RDDs<br>RDD存在依赖关系：宽依赖和窄依赖</p><p>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)<br>可以自定义分区规则来创建RDD</p><p>Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)<br>优先选择离文件位置近的节点来执行</p><p><strong>如何创建RDD</strong><br>（1）通过SparkContext.parallelize方法来创建</p><p>scala&gt; val rdd1 = sc.parallelize(Array(1,2,3,4,5,6,7,8),3)<br>rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[32] at parallelize at <code>&lt;console&gt;</code>:29</p><p>scala&gt; rdd1.partitions.length<br>res35: Int = 3</p><p>scala&gt; val rdd1 = sc.parallelize(Array(1,2,3,4,5,6,7,8),2)<br>rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[33] at parallelize at <code>&lt;console&gt;</code>:29</p><p>scala&gt; rdd1.partitions.length<br>res36: Int = 2</p><p>（2）通过外部数据源来创建<br>sc.textFile()</p><p>scala&gt; val rdd2 = sc.textFile(“/root/hd/tmp_files/test_WordCount.txt”)<br>rdd2: org.apache.spark.rdd.RDD[String] = /usr/local/tmp_files/test_WordCount.txt MapPartitionsRDD[35] at textFile at <code>&lt;console&gt;</code>:29</p><h4 id="2、-算子">2、 算子</h4><p><strong>1）Transformation</strong><br>map(func)：相当于for循环，返回一个新的RDD</p><p>filter(func)：过滤<br>flatMap(func)：flat+map 压平</p><p>mapPartitions(func)：对RDD中的每个分区进行操作<br>mapPartitionsWithIndex(func)：对RDD中的每个分区进行操作，可以取到分区号</p><p>sample(withReplacement, fraction, seed)：采样</p><p><strong>集合运算</strong><br>union(otherDataset)：对源RDD和参数RDD求并集后返回一个新的RDD<br>intersection(otherDataset)：对源RDD和参数RDD求交集后返回一个新的RDD</p><p>distinct([numTasks]))：去重</p><p><strong>聚合操作</strong>：<strong>group by</strong><br>groupByKey([numTasks]) ：在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDD<br>reduceByKey(func, [numTasks])：在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，与groupByKey类似，reduce任务的个数可以通过第二个可选的参数来设置<br>aggregateByKey(zeroValue)(seqOp,combOp,[numTasks])：按照key进行聚合</p><p><strong>排序</strong><br>sortByKey([ascending], [numTasks])：在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD<br>sortBy(func,[ascending], [numTasks])：与sortByKey类似，但是更灵活</p><p>join(otherDataset, [numTasks])：在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD<br>cogroup(otherDataset, [numTasks])：在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable,Iterable))类型的RDD<br>cartesian(otherDataset)<br>pipe(command, [envVars])<br>coalesce(numPartitions)</p><p><strong>重分区</strong>：<br>repartition(numPartitions)<br>repartitionAndSortWithinPartitions(partitioner)</p><p>举例：<br>（1）创建一个RDD，每个元素乘以2，再排序<br>scala&gt; val rdd1 = sc.parallelize(Array(3,4,5,100,79,81,6,8))<br>rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <code>&lt;console&gt;</code>:24</p><p>scala&gt; val rdd2 = rdd1.map(_*2)<br>rdd2: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[1] at map at <code>&lt;console&gt;</code>:26</p><p>scala&gt; rdd2.collect<br>res0: Array[Int] = Array(6, 8, 10, 200, 158, 162, 12, 16)</p><p>scala&gt; rdd2.sortBy(x=&gt;x,true).collect<br>res1: Array[Int] = Array(6, 8, 10, 12, 16, 158, 162, 200)</p><p>scala&gt; rdd2.sortBy(x=&gt;x,false).collect<br>res2: Array[Int] = Array(200, 162, 158, 16, 12, 10, 8, 6)</p><p>def sortBy[K](f: (T) ⇒ K, ascending: Boolean = true)<br>过滤出大于20的元素：</p><p>scala&gt; val rdd3 = rdd2.filter(_&gt;20)<br>rdd3: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[53] at filter at <code>&lt;console&gt;</code>:33+</p><p>scala&gt; rdd3.collect<br>res3: Array[Int] = Array(200, 158, 162)</p><p>（2）字符串（字符）类型的RDD<br>scala&gt; val rdd4 = sc.parallelize(Array(“a b c”,“d e f”,“g h i”))<br>rdd4: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[28] at parallelize at <code>&lt;console&gt;</code>:24</p><p>scala&gt; rdd4.flatMap(_.split(" ")).collect<br>res4: Array[String] = Array(a, b, c, d, e, f, g, h, i)</p><h4 id="3、RDD的集合运算">3、RDD的集合运算</h4><p>scala&gt; val rdd5 = sc.parallelize(List(1,2,3,6,7,8,100))<br>rdd5: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:24</console></p><p>scala&gt; val rdd6 = sc.parallelize(List(1,2,3,4))<br>rdd6: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at parallelize at <console>:24</console></p><p>scala&gt; val rdd7 = rdd5.union(rdd6)<br>rdd7: org.apache.spark.rdd.RDD[Int] = UnionRDD[2] at union at <console>:28</console></p><p>scala&gt; rdd7.collect<br>res5: Array[Int] = Array(1, 2, 3, 6, 7, 8, 100, 1, 2, 3, 4)</p><p>scala&gt; rdd7.distinct.collect<br>res6: Array[Int] = Array(100, 4, 8, 1, 6, 2, 3, 7)</p><h4 id="4、分组操作：reduceByKey">4、分组操作：reduceByKey</h4><key value="">scala&gt; val rdd1 = sc.parallelize(List(("Time",1800),("Dadi",2400),("Giu",1600)))rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[6] at parallelize at <console>:24<p>scala&gt; val rdd2 = sc.parallelize(List((“Dadi”,1300),(“Time”,2900),(“Mi”,600)))<br>rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[7] at parallelize at <console>:24</console></p><p>scala&gt; val rdd3 = rdd1 union rdd2<br>rdd3: org.apache.spark.rdd.RDD[(String, Int)] = UnionRDD[8] at union at <console>:28</console></p><p>scala&gt; rdd3.collect<br>res3: Array[(String, Int)] = Array((Time,1800), (Dadi,2400), (Giu,1600), (Dadi,1300), (Time,2900), (Mi,600))</p><p>scala&gt; val rdd4 = rdd3.groupByKey<br>rdd4: org.apache.spark.rdd.RDD[(String, Iterable[Int])] = ShuffledRDD[9] at groupByKey at <console>:30</console></p><p>scala&gt; rdd4.collect<br>res4: Array[(String, Iterable[Int])] = Array((Mi,CompactBuffer(600)),<br>(Time,CompactBuffer(1800, 2900)),<br>(Dadi,CompactBuffer(2400, 1300)),<br>(Giu,CompactBuffer(1600)))</p><p>scala&gt; rdd3.reduceByKey(<em>+</em>).collect<br>res5: Array[(String, Int)] = Array((Mi,600), (Time,4700), (Dadi,3700), (Giu,1600))<br>reduceByKey will provide much better performance.<br>官方不推荐使用 groupByKey 推荐使用 reduceByKey</p><h4 id="5、cogroup">5、cogroup</h4><p>在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable,Iterable))类型的RDD</p><p>对两个RDD中的KV元素，每个RDD中相同key中的元素分别聚合成一个集合。与reduceByKey不同的是针对两个RDD中相同的key的元素进行合并，与groupByKey返回值上与区别</p><p>scala&gt; val rdd1 = sc.parallelize(List((“Tim”,1),(“Tim”,2),(“Jert”,3),(“kiy”,2)))<br>rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[11] at parallelize at <console>:24</console></p><p>scala&gt; val rdd1 = sc.parallelize(List((“Tim”,1),(“Tim”,2),(“Jert”,3),(“Kiy”,2)))<br>rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[12] at parallelize at <console>:24</console></p><p>scala&gt; val rdd2 = sc.parallelize(List((“Jert”,2),(“Tim”,1),(“Sun”,2)))<br>rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[13] at parallelize at <console>:24</console></p><p>scala&gt; val rdd3 = rdd1.cogroup(rdd2)<br>rdd3: org.apache.spark.rdd.RDD[(String, (Iterable[Int], Iterable[Int]))] = MapPartitionsRDD[15] at cogroup at <console>:28</console></p><p>scala&gt; rdd3.collect<br>res6: Array[(String, (Iterable[Int], Iterable[Int]))] = Array(<br>(Tim,(CompactBuffer(1, 2),CompactBuffer(1))),<br>(Sun,(CompactBuffer(),CompactBuffer(2))),<br>(Kiy,(CompactBuffer(2),CompactBuffer())),<br>(Jert,(CompactBuffer(3),CompactBuffer(2))))</p><h4 id="6、reduce操作（Action）">6、reduce操作（Action）</h4><p><strong>聚合操作</strong></p><p>scala&gt; val rdd1 = sc.parallelize(List(1,2,3,4,5))<br>rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[16] at parallelize at <console>:24</console></p><p>scala&gt; rdd1.reduce(<em>+</em>)<br>res7: Int = 15</p><h4 id="7、需求：按照value排序">7、需求：按照value排序</h4><p>做法：<br>1）交换，把key 和 value交换，然后调用sortByKey方法<br>2）再次交换</p><p>scala&gt; val rdd1 = sc.parallelize(List((“tim”,1),(“jery”,3),(“kef”,2),(“sun”,2)))<br>rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[17] at parallelize at <console>:24</console></p><p>scala&gt; val rdd2 = sc.parallelize(List((“jery”,1),(“tim”,3),(“sun”,5),(“kef”,1)))<br>rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[18] at parallelize at <console>:24</console></p><p>scala&gt; val rdd3 = rdd1.union(rdd2)<br>rdd3: org.apache.spark.rdd.RDD[(String, Int)] = UnionRDD[19] at union at <console>:28</console></p><p>scala&gt; val rdd4 = rdd3.reduceByKey(<em>+</em>)<br>rdd4: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[20] at reduceByKey at <console>:30</console></p><p>scala&gt; rdd4.collect<br>res8: Array[(String, Int)] = Array((tim,4), (kef,3), (sun,7), (jery,4))</p><p>scala&gt; val rdd5 = rdd4.map(t=&gt;(t._2,t._1)).sortByKey(false).map(t=&gt;(t._2,t._1))<br>rdd5: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[25] at map at <console>:32</console></p><p>scala&gt; rdd5.collect<br>res10: Array[(String, Int)] = Array((sun,7), (tim,4), (jery,4), (kef,3))</p><p>（2）Action<br>reduce(func)：通过func函数聚集RDD中的所有元素，这个功能必须是课交换且可并联的</p><p>collect()：在驱动程序中，以数组的形式返回数据集的所有元素<br>count()：返回RDD的元素个数<br>first()：返回RDD的第一个元素（类似于take(1)）<br>take(n)：返回一个由数据集的前n个元素组成的数组</p><p>takeSample(withReplacement,num, [seed])：返回一个数组，该数组由从数据集中随机采样的num个元素组成，可以选择是否用随机数替换不足的部分，seed用于指定随机数生成器种子</p><p>takeOrdered(n, [ordering])：takeOrdered和top类似，只不过以和top相反的顺序返回元素</p><p>saveAsTextFile(path)：将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本</p><p>saveAsSequenceFile(path) ：将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统</p><p>saveAsObjectFile(path) ：saveAsObjectFile用于将RDD中的元素序列化成对象，存储到文件中</p><p>countByKey()：针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数</p><p>foreach(func)：在数据集的每一个元素上，运行函数func进行更新。<br>与map类似，没有返回值</p><p>3）特性<br>（1）<strong>RDD的缓存机制</strong><br>RDD通过persist方法或cache方法可以将前面的计算结果缓存，但是并不是这两个方法被调用时立即缓存，而是触发后面的action时，该RDD将会被缓存在计算节点的内存中，并供后面重用</p><p>通过查看源码发现cache最终也是调用了persist方法，默认的存储级别都是仅在内存存储一份，Spark的存储级别还有好多种，存储级别在object StorageLevel中定义的</p><p>缓存有可能丢失，或者存储存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition</p><p>（<em>）作用：提高性能<br>（</em>）使用：标识RDD可以被缓存 persist cache<br>（*）可以缓存的位置：</p><p>val NONE = new StorageLevel(false, false, false, false)<br>val DISK_ONLY = new StorageLevel(true, false, false, false)<br>val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2)<br>val MEMORY_ONLY = new StorageLevel(false, true, false, true)<br>val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2)<br>val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false)<br>val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2)<br>val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)<br>val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2)<br>val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false)<br>val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2)<br>val OFF_HEAP = new StorageLevel(true, true, true, false, 1)</p><p>/**</p><ul><li>Persist this RDD with the default storage level (<code>MEMORY_ONLY</code>).<br>*/<br>def persist(): this.type = persist(StorageLevel.MEMORY_ONLY)</li></ul><p>/**</p><ul><li>Persist this RDD with the default storage level (<code>MEMORY_ONLY</code>).<br>*/<br>def cache(): this.type = persist()<br>举例：测试数据，92万条<br>进入spark-shell命令</li></ul><p>./spark-shell <code>--master</code> spark://hsiehchou121:7077</p><p>scala&gt; val rdd1 = sc.textFile(“hdfs://192.168.116.121:9000/tmp_files/test_Cache.txt”)<br>rdd1: org.apache.spark.rdd.RDD[String] = hdfs://192.168.116.121:9000/tmp_files/test_Cache.txt MapPartitionsRDD[3] at textFile at <code>&lt;console&gt;</code>:24</p><p>scala&gt; rdd1.count  --&gt; 直接出发计算<br>res0: Long = 921911</p><p>scala&gt; rdd1.cache  --&gt; 标识RDD可以被缓存，不会触发计算<br>res1: rdd1.type = hdfs://192.168.116.121:9000/tmp_files/test_Cache.txt MapPartitionsRDD[3] at textFile at <code>&lt;console&gt;</code>:24</p><p>scala&gt; rdd1.count   --&gt; 和第一步一样，触发计算，但是，把结果进行缓存<br>res2: Long = 921911</p><p>scala&gt; rdd1.count   --&gt;  从缓存中直接读出结果<br>res3: Long = 921911</p><p>（2）<strong>RDD的容错机制：通过检查点来实现</strong><br>检查点（本质是通过将RDD写入Disk做检查点）是为了通过lineage（血统）做容错的辅助，lineage过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的RDD开始重做Lineage，就会减少开销</p><p>设置checkpoint的目录，可以是本地的文件夹、也可以是HDFS。一般是在具有容错能力，高可靠的文件系统上(比如HDFS, S3等)设置一个检查点路径，用于保存检查点数据</p><p>/**</p><p>Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint</p><p>directory set with SparkContext#setCheckpointDir and all references to its parent</p><p>RDDs will be removed. This function must be called before any job has been</p><p>executed on this RDD. It is strongly recommended that this RDD is persisted in</p><p>memory, otherwise saving it on a file will require recomputation.<br>*/</p><p>（*）复习检查点：<br>HDFS中的检查点：有SecondaryNamenode来实现日志的合并</p><p>（*）RDD的检查点：容错<br>概念：血统 Lineage<br>理解：表示任务执行的生命周期<br>WordCount textFile —&gt; redceByKey</p><p>如果血统越长，越容易出错</p><p>假如有检查点，可以从最近的一个检查点开始，往后面计算。不用重头计算</p><p>（*）RDD检查点的类型<br>（1）基于本地目录：需要将Spark shell 或者任务运行在本地模式上（setMaster(“local”)）<br>开发和测试</p><p>（2）HDFS目录：用于生产<br>sc.setCheckPointDir(目录)</p><p>举例：<strong>设置检查点</strong><br>scala&gt; var rdd1 = sc.textFile(“hdfs://192.168.116.121:9000/tmp_files/test_Cache.txt”)<br>rdd1: org.apache.spark.rdd.RDD[String] = hdfs://192.168.116.121:9000/tmp_files/test_Cache.txt MapPartitionsRDD[1] at textFile at <code>&lt;console&gt;</code>:24</p><p>设置检查点目录：<br>scala&gt; sc.setCheckpointDir(“hdfs://192.168.116.121:9000/sparkchkpt”)</p><p>标识rdd1可以执行检查点操作<br>scala&gt; rdd1.checkpoint</p><p>scala&gt; rdd1.count<br>res2: Long = 921911</p><p>（3）**依赖关系：宽依赖，窄依赖 **</p><p><strong>Stage是每一个job处理过程要分为的几个阶段</strong></p><p><img src="/medias/Stage%E5%88%92%E5%88%86.PNG" alt="Stage划分"></p><p>划分任务执行的stage<br>RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）</p><p><strong>窄依赖</strong>指的是每一个父RDD的Partition最多被子RDD的一个Partition使用（一（父）对一（子））<br>总结：<strong>窄依赖</strong>我们形象的比喻为<strong>独生子女</strong></p><p><strong>宽依赖</strong>指的是多个子RDD的Partition会依赖同一个父RDD的Partition（一（父）对多（子））<br>总结：<strong>宽依赖</strong>我们形象的比喻为<strong>超生</strong></p><p>DAG(Directed Acyclic Graph)叫做有向无环图，原始的RDD通过一系列的转换就就形成了DAG，根据RDD之间的依赖关系的不同将DAG划分成不同的Stage，对于窄依赖，partition的转换处理在Stage中完成计算。对于宽依赖，由于有Shuffle的存在，只能在parent RDD处理完成后，才能开始接下来的计算，因此<strong>宽依赖是划分Stage的依据</strong></p><h3 id="七、RDD的高级算子">七、RDD的高级算子</h3><h4 id="1、mapPartitionsWithIndex">1、mapPartitionsWithIndex</h4><p>对RDD中的每个分区（带有下标）进行操作，下标用index表示<br>通过这个算子，我们可以获取分区号</p><p>def mapPartitionsWithIndex&lt;a href="<br>f: %28Int, Iterator%5bT%5d%29 ⇒ Iterator%5bU%5d,<br>preservesPartitioning: Boolean = false”&gt;U(implicit arg0: ClassTag[U]): RDD[U]</p><p>通过将函数应用于此RDD的每个分区来返回新的RDD，同时跟踪原始分区的索引</p><p>preservesPartitioning指输入函数是否保留分区器，除非是一对RDD并且输入函数不修改keys，否则应该是false</p><p>参数：f是个函数参数 f 中第一个参数是Int，代表分区号，第二个Iterator[T]代表分区中的元素</p><p>举例：把分区中的元素，包括分区号，都打印出来</p><p>scala&gt; val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8),3)<br>rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[3] at parallelize at <code>&lt;console&gt;</code>:24</p><p>scala&gt; def fun1(index:Int, iter:Iterator[Int]) : Iterator[String] = {<br>| iter.toList.map(x =&gt; “[partId: “+ index +” , value = " + x + " ]”).iterator<br>| }<br>fun1: (index: Int, iter: Iterator[Int])Iterator[String]</p><p>scala&gt; rdd1.mapPartitionsWithIndex(fun1).collect<br>res3: Array[String] = Array(<br>[partId: 0 , value = 1 ], [partId: 0 , value = 2 ],<br>[partId: 1 , value = 3 ], [partId: 1 , value = 4 ], [partId: 1 , value = 5 ],<br>[partId: 2 , value = 6 ], [partId: 2 , value = 7 ], [partId: 2 , value = 8 ])</p><h4 id="2、aggregate">2、aggregate</h4><p>聚合操作。类似于分组<br>（*）先对局部进行聚合操作，再对全局进行聚合操作</p><p><strong>调用聚合操作</strong><br>scala&gt; val rdd2 = sc.parallelize(List(1,2,3,4,5),2)<br>rdd2: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[5] at parallelize at <code>&lt;console&gt;</code>:24</p><p>scala&gt; rdd2.mapPartitionsWithIndex(fun1).collect<br>res4: Array[String] = Array(<br>[partId : 0 , value = 1 ], [partId : 0 , value = 2 ],<br>[partId : 1 , value = 3 ], [partId : 1 , value = 4 ], [partId : 1 , value = 5 ])</p><p>scala&gt; import scala.math._<br>import scala.math._</p><pre><code class="highlight plaintext">scala&gt; rdd2.aggregate(0)(max(_,_),_+_)res6: Int = 7</code></pre><p>说明：aggregate</p><pre><code class="highlight plaintext">(0) 初始值是 0 (max(_,_) 局部操作的函数,   _+_   全局操作的函数)</code></pre><pre><code class="highlight plaintext">scala&gt; rdd2.aggregate(100)(max(_,_),_+_)res8: Int = 300</code></pre><p>分析结果：初始值是100，代表每个分区多了一个100<br>全局操作，也多了一个100<br>100+100+100 = 300</p><p>对RDD中的元素进行求和<br>RDD.map</p><p><strong>聚合操作（效率大于map）</strong></p><pre><code class="highlight plaintext">scala&gt; rdd2.aggregate(0)(_+_,_+_)res9: Int = 15</code></pre><p>相当于MapReduce 的 Combiner</p><pre><code class="highlight plaintext">scala&gt; rdd2.aggregate(10)(_+_,_+_)res10: Int = 45</code></pre><p>（*）对字符串操作</p><p>scala&gt; val rdd2 = sc.parallelize(List(“a”,“b”,“c”,“d”,“e”,“f”),2)<br>rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[7] at parallelize at <code>&lt;console&gt;</code>:27</p><pre><code class="highlight plaintext">scala&gt; rdd2.aggregate("")(_+_,_+_)res11: String = abcdefscala&gt; rdd2.aggregate("*")(_+_,_+_)res12: String = **def*abc</code></pre><p>结果分析:<br>*abc *def</p><p>**def*abc</p><p>（*）复杂的例子<br>1）<br>scala&gt; val rdd3 = sc.parallelize(List(“12”,“23”,“345”,“4567”),2)<br>rdd3: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[8] at parallelize at <code>&lt;console&gt;</code>:27</p><p>scala&gt; def fun1(index:Int, iter:Iterator[String]) : Iterator[String] = {<br>| iter.toList.map(x =&gt; “[partId : " + index + " , value = " + x + " ]”).iterator<br>| }</p><p>scala&gt; rdd3.mapPartitionsWithIndex(fun1).collect<br>res17: Array[String] = Array(<br>[partId : 0 , value = 12 ], [partId : 0 , value = 23 ],<br>[partId : 1 , value = 345 ], [partId : 1 , value = 4567 ])</p><p>scala&gt; rdd3.aggregate(“”)((x,y)=&gt; math.max(x.length,y.length).toString,(x,y)=&gt;x+y)<br>res13: String = 42<br>执行过程：<br>第一个分区：<br>第一次比较： “” “12” 长度最大值 2 2–&gt;”2”<br>第二次比较： “2” “23” 长度最大值 2 2–&gt;”2”</p><p>第二个分区：<br>第一次比较： “” “345” 长度最大值 3 3–&gt;”3”<br>第二次比较： “3” “4567” 长度最大值 4 4–&gt;”4”<br>结果：24 或者42</p><p>2）<br>scala&gt; rdd3.aggregate(“”)((x,y)=&gt; math.min(x.length,y.length).toString,(x,y)=&gt;x+y)<br>res18: String = 11<br>执行过程：<br>第一个分区：<br>第一次比较： “” “12” 长度最小值 0 0–&gt;”0”<br>第二次比较： “0” “23” 长度最小值 1 1–&gt;”1”</p><p>第二个分区：<br>第一次比较： “” “345” 长度最小值 0 0–&gt;”0”<br>第二次比较： “0” “4567” 长度最小值 1 1–&gt;”1”</p><p>val rdd3 = sc.parallelize(List(“12”,“23”,“345”,“”),2)<br>rdd3.aggregate(“”)((x,y)=&gt; math.min(x.length,y.length).toString,(x,y)=&gt;x+y)</p><p>scala&gt; val rdd3 = sc.parallelize(List(“12”,“23”,“345”,“”),2)<br>rdd3: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[10] at parallelize at <console>:27</console></p><p>scala&gt; rdd3.aggregate(“”)((x,y)=&gt; math.min(x.length,y.length).toString,(x,y)=&gt;x+y)<br>res19: String = 10</p><p>scala&gt; rdd3.aggregate(“”)((x,y)=&gt; math.min(x.length,y.length).toString,(x,y)=&gt;x+y)<br>res20: String = 01<br>3）aggregateByKey：类似于aggregate，区别：操作的是 key value 的数据类型</p><p>scala&gt; val pairRDD = sc.parallelize(List((“cat”,2),(“cat”,5),(“mouse”,4),(“cat”,12),(“dog”,12),(“mouse”,2)),2)<br>pairRDD: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[0] at parallelize at <code>&lt;console&gt;</code>:24</p><p>scala&gt; def fun3(index:Int, iter:Iterator[(String,Int)]) : Iterator[String] = {<br>| iter.toList.map(x=&gt;“partId : " + index + " , value = " + x + " ]”).iterator<br>| }<br>fun3: (index: Int, iter: Iterator[(String, Int)])Iterator[String]</p><p>scala&gt; pairRDD.mapPartitionsWithIndex(fun3).collect<br>res0: Array[String] = Array(<br>partId : 0 , value = (cat,2) ], partId : 0 , value = (cat,5) ], partId : 0 , value = (mouse,4) ],<br>partId : 1 , value = (cat,12) ], partId : 1 , value = (dog,12) ], partId : 1 , value = (mouse,2) ])</p><p>1.将每个动物园（分区）中，动物数最多的动物，进行求和<br>动物园0<br>[partId : 0 , value = (cat,2) ], [partId : 0 , value = (cat,5) ], [partId : 0 , value = (mouse,4) ],</p><p>动物园1<br>[partId : 1 , value = (cat,12) ], [partId : 1 , value = (dog,12) ], [partId : 1 , value = (mouse,2) ])</p><pre><code class="highlight plaintext">pairRDD.aggregateByKey(0)(math.max(_,_),_+_)scala&gt; pairRDD.aggregateByKey(0)(math.max(_,_),_+_).collectres1: Array[(String, Int)] = Array((dog,12), (cat,17), (mouse,6))</code></pre><p>2.将所有动物求和</p><pre><code class="highlight plaintext">pairRDD.aggregateByKey(0)(_+_,_+_).collectscala&gt; pairRDD.reduceByKey(_+_).collectres27: Array[(String, Int)] = Array((dog,12), (cat,19), (mouse,6))</code></pre><p>aggregateByKey效率更高</p><p>4）<strong>coalesce与repartition</strong><br>与分区有关<br>都是对RDD进行重分区</p><p>区别：<br>coalesce 默认不会进行Shuffle 默认 false 如需修改分区，需置为true</p><p>repartition 会进行Shuffle</p><p>scala&gt; val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9),2)<br>rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[5] at parallelize at <code>&lt;console&gt;</code></p><p>scala&gt; val rdd2 = rdd1.repartition(3)<br>rdd2: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[9] at repartition at <code>&lt;console&gt;</code>:26</p><p>scala&gt; rdd2.partitions.length<br>res4: Int = 3</p><p>scala&gt; val rdd3 = rdd1.coalesce(3,true)<br>rdd3: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[13] at coalesce at <code>&lt;console&gt;</code>:26</p><p>scala&gt; rdd3.partitions.length<br>res5: Int = 3</p><p>scala&gt; val rdd4 = rdd1.coalesce(4)<br>rdd4: org.apache.spark.rdd.RDD[Int] = CoalescedRDD[14] at coalesce at <code>&lt;console&gt;</code>:26</p><p>scala&gt; rdd4.partitions.length<br>res6: Int = 2</p><p>5）<strong>其他高级算子</strong><br>比较好的高级算子的博客（推荐）<br><a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html">http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html</a></p><h3 id="八、编程案例">八、编程案例</h3><h4 id="1、分析日志">1、分析日志</h4><p>需求：找到访问量最高的两个网页<br>（<em>）第一步：对网页的访问量求和<br>（</em>）第二步：排序，降序</p><p><strong>日志数据</strong><br>192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] “GET /MyDemoWeb/ HTTP/1.1” 200 259<br>192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] “GET /MyDemoWeb/head.jsp HTTP/1.1” 200 713<br>192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] “GET /MyDemoWeb/body.jsp HTTP/1.1” 200 240<br>192.168.88.1 - - [30/Jul/2017:12:54:37 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] “GET /MyDemoWeb/java.jsp HTTP/1.1” 200 240<br>192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] “GET /MyDemoWeb/mysql.jsp HTTP/1.1” 200 241<br>192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] “GET /MyDemoWeb/web.jsp HTTP/1.1” 200 239<br>192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:53 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] “GET /MyDemoWeb/mysql.jsp HTTP/1.1” 200 241<br>192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:56 +0800] “GET /MyDemoWeb/web.jsp HTTP/1.1” 200 239<br>192.168.88.1 - - [30/Jul/2017:12:54:56 +0800] “GET /MyDemoWeb/java.jsp HTTP/1.1” 200 240<br>192.168.88.1 - - [30/Jul/2017:12:54:57 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:57 +0800] “GET /MyDemoWeb/java.jsp HTTP/1.1” 200 240<br>192.168.88.1 - - [30/Jul/2017:12:54:58 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:58 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:59 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:54:59 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:55:43 +0800] “GET /MyDemoWeb/mysql.jsp HTTP/1.1” 200 241<br>192.168.88.1 - - [30/Jul/2017:12:55:43 +0800] “GET /MyDemoWeb/oracle.jsp HTTP/1.1” 200 242<br>192.168.88.1 - - [30/Jul/2017:12:55:43 +0800] “GET /MyDemoWeb/web.jsp HTTP/1.1” 200 239<br>192.168.88.1 - - [30/Jul/2017:12:55:43 +0800] “GET /MyDemoWeb/hadoop.jsp HTTP/1.1” 200 242</p><pre><code class="highlight plaintext">package day2import org.apache.spark.SparkConfimport org.apache.spark.SparkContextobject MyTomcatLogCount {  def main(args: Array[String]): Unit = {    val conf  = new SparkConf().setMaster("local").setAppName("MyTomcatLogCount")    val sc = new SparkContext(conf)    /**     * 读入日志解析     *      * 192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] "GET /MyDemoWeb/oracle.jsp HTTP/1.1" 200 242     *      */    val rdd1 = sc.textFile("H:\\other\\localhost_access_log.txt")      .map(       line =&gt; {         //解析字符串， 得到jsp的名字         //1.解析两个引号之间的字符串         val index1 = line.indexOf("\"")         val index2 = line.lastIndexOf("\"")         val line1 = line.substring(index1+1,index2)//GET /MyDemoWeb/oracle.jsp HTTP/1.1         //得到两个空格的位置         val index3 = line1.indexOf(" ")         val index4 = line1.lastIndexOf(" ")         val line2 = line1.substring(index3+1,index4)///MyDemoWeb/oracle.jsp         //得到jsp的名字         val jspName = line2.substring(line2.lastIndexOf("/"))//oracle.jsp         (jspName,1)       }      )    //统计出每个jsp的次数               val rdd2 = rdd1.reduceByKey(_+_)                               //使用value排序    val rdd3 = rdd2.sortBy(_._2, false)    rdd3.take(2).foreach(println)    sc.stop()  }}</code></pre><p>结果：<br>(/hadoop.jsp,9)<br>(/oracle.jsp,9)</p><h4 id="2、创建自定义分区">2、创建自定义分区</h4><p>根据jsp文件的名字，将各自的访问日志放入到不同的分区文件中</p><pre><code class="highlight plaintext">package day2import org.apache.spark.SparkConfimport org.apache.spark.SparkContextimport org.apache.spark.Partitionerimport scala.collection.mutable.HashMapobject MyTomcatLogPartitioner {  def main(args: Array[String]): Unit = {    System.setProperty("hadoop.home.dir", "E:\\hadoop-2.7.3")    val conf = new SparkConf().setMaster("local").setAppName("MyTomcatLogPartitioner")    val sc = new SparkContext(conf)     /**     * 读入日志解析     *      * 192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] "GET /MyDemoWeb/oracle.jsp HTTP/1.1" 200 242     *      */    val rdd1 = sc.textFile("H:\\other\\localhost_access_log.txt")      .map(       line =&gt; {         //解析字符串， 得到jsp的名字         //1.解析两个引号之间的字符串         val index1 = line.indexOf("\"")         val index2 = line.lastIndexOf("\"")         val line1 = line.substring(index1+1,index2)//GET /MyDemoWeb/oracle.jsp HTTP/1.1         //得到两个空格的位置         val index3 = line1.indexOf(" ")         val index4 = line1.lastIndexOf(" ")         val line2 = line1.substring(index3+1,index4)///MyDemoWeb/oracle.jsp         //得到jsp的名字         val jspName = line2.substring(line2.lastIndexOf("/"))//oracle.jsp         (jspName,line)       }      )                              //定义分区规则    //得到不重复的jsp的名字    val rdd2 = rdd1.map(_._1).distinct().collect()    //创建分区规则    val myPartitioner = new MyWebPartitioner(rdd2)    val rdd3 = rdd1.partitionBy(myPartitioner)    //将rdd3 输出    rdd3.saveAsTextFile("H:\\other\\test_partition")      sc.stop()  }}class MyWebPartitioner(jspList : Array[String]) extends Partitioner{  //定义一个集合来保存分区条件， String 代表jsp的名字， Int 代表序号  val partitionMap = new HashMap[String,Int]()  var partID = 0 //初始分区号  for (jsp &lt;- jspList){    partitionMap.put(jsp, partID)    partID += 1  }  //定义有多少个分区  def numPartitions : Int = partitionMap.size  //根据jsp，返回对应的分区  def getPartition(key : Any) : Int = partitionMap.getOrElse(key.toString(),0)}</code></pre><h4 id="3、使用JDBCRDD-操作数据库">3、使用JDBCRDD 操作数据库</h4><p>将RDD的数据保存到mysql数据库中</p><pre><code class="highlight plaintext">package day2import java.sql.DriverManagerimport org.apache.spark.SparkConfimport org.apache.spark.SparkContextimport org.apache.spark.rdd.JdbcRDD/** * 需求找出工资小于等于2000大于900的员工 * select * from emp where sal &gt; ? and sal &lt;= ? */object MyMysqlDemo {  val connection = () =&gt; {    Class.forName("com.mysql.cj.jdbc.Driver").newInstance()    DriverManager.getConnection("jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8","root","123456")  }  def main(args: Array[String]): Unit = {    System.setProperty("hadoop.home.dir", "E:\\hadoop-2.7.3")    val conf = new SparkConf().setMaster("local").setAppName("MyMysqlDemo")    val sc = new SparkContext(conf)    val mysqlRDD = new JdbcRDD(sc, connection, "select * from emp where sal &gt; ? and sal &lt;= ?", 900, 2000, 2, r =&gt; {      val ename = r.getString(2)      val sal = r.getInt(4)      (ename, sal)    })    val result = mysqlRDD.collect()    println(result.toBuffer)    sc.stop()      }}</code></pre><p>mysql的company的emp数据<br>1 Tom 10 2400<br>2 Alis 11 1900<br>3 Kei 12 1500<br>4 Mi 11 900<br>结果<br>ArrayBuffer((Alis,1900), (Kei,1500))</p><p>JdbcRDD参数说明</p><table><thead><tr><th style="text-align:center">参数名称</th><th style="text-align:center">类型</th><th style="text-align:center">说明</th></tr></thead><tbody><tr><td style="text-align:center">sc</td><td style="text-align:center">org.apache.spark.SparkContext</td><td style="text-align:center">Spark Context对象</td></tr><tr><td style="text-align:center">getConnection</td><td style="text-align:center">scala.Function0[java.sql.Connection]</td><td style="text-align:center">得到一个数据库Connection</td></tr><tr><td style="text-align:center">sql</td><td style="text-align:center">scala.Predef.String</td><td style="text-align:center">执行的SQL语句</td></tr><tr><td style="text-align:center">lowerBound</td><td style="text-align:center">scala.Long</td><td style="text-align:center">下边界值，即：SQL的第一个参数</td></tr><tr><td style="text-align:center">upperBound</td><td style="text-align:center">scala.Long</td><td style="text-align:center">上边界值，即：SQL的第二个参数</td></tr><tr><td style="text-align:center">numPartitions</td><td style="text-align:center">scala.Int</td><td style="text-align:center">分区的个数，即：启动多少个Executor</td></tr><tr><td style="text-align:center">mapRow</td><td style="text-align:center">scala.Function1[java.sql.ResultSet, T]</td><td style="text-align:center">得到的结果集</td></tr></tbody></table><p>JdbcRDD的缺点：从上面的参数说明可以看出，JdbcRDD有以下两个缺点：<br>（1）执行的SQL必须有两个参数，并类型都是Long<br>（2）得到的结果是ResultSet，即：只支持select操作</p><h4 id="4、操作数据库：把结果存放到数据库中">4、操作数据库：把结果存放到数据库中</h4><pre><code class="highlight plaintext">package day3import org.apache.spark.SparkConfimport org.apache.spark.SparkContextimport java.sql.Connectionimport java.sql.DriverManagerimport java.sql.PreparedStatement/** * 把Spark结果存放到mysql数据库中 */object MyTomcatLogCountToMysql {  def main(args: Array[String]): Unit = {    //创建SparkContext    val conf = new SparkConf().setMaster("local").setAppName("MyTomcatLogCountToMysql")    val sc = new SparkContext(conf)     /**     * 读入日志解析     *      * 192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] "GET /MyDemoWeb/oracle.jsp HTTP/1.1" 200 242     *      */    val rdd1 = sc.textFile("H:\\other\\localhost_access_log.txt")      .map(       line =&gt; {         //解析字符串， 得到jsp的名字         //1.解析两个引号之间的字符串         val index1 = line.indexOf("\"")         val index2 = line.lastIndexOf("\"")         val line1 = line.substring(index1+1,index2)//GET /MyDemoWeb/oracle.jsp HTTP/1.1         //得到两个空格的位置         val index3 = line1.indexOf(" ")         val index4 = line1.lastIndexOf(" ")         val line2 = line1.substring(index3+1,index4)///MyDemoWeb/oracle.jsp         //得到jsp的名字         val jspName = line2.substring(line2.lastIndexOf("/"))//oracle.jsp         (jspName,1)     }    )      //存入数据库//    var conn : Connection = null//    var pst : PreparedStatement = null//    //    try{//        /**//         * create table mydata(jspname varchar(50), countNumber Int);//         * //         * foreach 没有返回值 ， 在本需求中，只需要写数据库，不需要返回新的RDD，所以用foreach即可//         * //         * 运行Task not serializable//         *///        conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8","root","123456") //        pst = conn.prepareStatement("insert into mydata values (?,?)")//    //        rdd1.foreach(f =&gt; {//          pst.setString(1, f._1)//          pst.setInt(2, f._2)//          //          pst.executeUpdate()//        })//    }catch{//      case t : Throwable =&gt; t.printStackTrace()//    }finally{//      if(pst != null) pst.close()//      if(conn != null)  conn.close()//    }//    sc.stop()    //第一种修改方式    //存入数据库//    var conn : Connection = null//    var pst : PreparedStatement = null//    //    try{//      rdd1.foreach(f =&gt; {//        conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8","root","123456") //        pst = conn.prepareStatement("insert into mydata values (?,?)")//  //        pst.setString(1, f._1)//        pst.setInt(2, f._2)//        //        pst.executeUpdate()//      })//    }catch{//      case t : Throwable =&gt; t.printStackTrace()//    }finally{//      if(pst != null) pst.close()//      if(conn != null)  conn.close()//    }//    sc.stop()      /*     * 第一种修改方式功能上可以实现，但每条数据都会创建连接，对数据库造成很大压力     *      * 针对分区来操作：一个分区建立一个连接即可     */     rdd1.foreachPartition(saveToMysql)      sc.stop()  }  def saveToMysql(it : Iterator[(String, Int)]) = {      var conn : Connection = null      var pst : PreparedStatement = null      try{        conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8","root","123456")         pst = conn.prepareStatement("insert into mydata values (?,?)")        it.foreach(f =&gt; {          pst.setString(1, f._1)          pst.setInt(2, f._2)          pst.executeUpdate()        })      }catch{        case t : Throwable =&gt; t.printStackTrace()      }finally{        if(pst != null) pst.close()        if(conn != null)  conn.close()      }  }}</code></pre></console></key>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Akka练习</title>
      <link href="/2019/03/27/akka_lian_xi/"/>
      <url>/2019/03/27/akka_lian_xi/</url>
      
        <content type="html"><![CDATA[<h4 id="Actor并发模型">Actor并发模型</h4><p><strong>Java中的并发开发</strong><br>Java的并发编程是基于 共享数据 和 加锁 的一种机制。锁的是共享数据<br>synchronized</p><p><strong>Scala中的并发开发</strong><br>不共享数据。依赖于 消息传递 的一种并发编程模式</p><p>如果 Actor A 和 Actor B要相互沟通<br>1、A要给B传递一个消息，B有一个收件箱，B轮询自己的收件箱<br>2、如果B看到A的消息，解析A的消息并执行相应操作<br>3、有可能会回复 A 消息</p><p><strong>Actor示例</strong></p><pre><code class="highlight plaintext">package day6import akka.actor.{Actor, ActorSystem, Props}/**  * Actor示例  */class HelloActor extends Actor{  override def receive: Receive = {    case "Hello" =&gt; println("Hello Receive")    case _ =&gt; println("aaa")  }}object Demo1 extends App {  //新建一个ActorSystem  val system = ActorSystem("HelloSystem")  //构造函数  val helloActor = system.actorOf(Props[HelloActor],"helloactor")  //发消息  helloActor ! "Hello"  helloActor ! "Hello2234"}</code></pre><p><strong>建立两个Actor 相互传递消息</strong></p><pre><code class="highlight plaintext">package day6import akka.actor.{Actor, ActorRef, ActorSystem, Props}/**  * 建立两个Actor 相互传递消息  *  * 定义消息：样本类、区分 消息的不同  *///消息的定义case object PingMessagecase object PongMessagecase object StartMessagecase object StopMessageclass Ping(pong : ActorRef) extends Actor{  var count = 0  def incrementAndPing {    count += 1;    println("Ping")  }  override def receive: Receive = {    case StartMessage =&gt;      incrementAndPing      pong ! PingMessage    case PongMessage =&gt;      if(count &gt; 9){        sender() ! StopMessage      }else {        incrementAndPing        pong ! PingMessage      }  }}class Pong extends Actor{  override def receive: Receive = {    case PingMessage =&gt;    println("pong")    //给ping回复消息    sender ! PongMessage    case StopMessage =&gt;      println("pong Stop")      context.stop(self)      //context.system.finalize()  }}object Demo2 extends App{  val system = ActorSystem("PingPongSystem")  val pong =  system.actorOf(Props[Pong],name="pong")  val ping = system.actorOf(Props(new Ping(pong)),name="ping")  ping ! StartMessage}</code></pre><p>AKKA 负责来回传递消息</p><p><strong>Scala项目</strong></p><h4 id="实现一个主从管理系统">实现一个主从管理系统</h4><p><img src="/medias/NewAkkaSystem.PNG" alt="NewAkkaSystem"></p><p>Worker类<br>Master类</p><p>ActorMessage类<br>WorkerInfo类</p><p>ActorMessage 类：定义消息 5种消息</p><p><strong>WorkerInfo.scala</strong></p><pre><code class="highlight plaintext">package akka/**  * 保存worker的基本信息  */class WorkerInfo(val id : String, val workerHost : String, val memory : String, val cores : String) {  //保存心跳信息  var lastHeartBeat : Long = System.currentTimeMillis()  override def toString : String = s"WorkerInfo($id, $workerHost, $memory, $cores)"}</code></pre><p><strong>ActorMessage.scala</strong></p><pre><code class="highlight plaintext">package akka/**  * 样本类，保存所有信息  *///worker ----&gt; master注册节点case class RegisterWorker(val id : String, val workerHost : String, val memory : String, val cores : String)//worker ----&gt; master 发送心跳信号case class HeartBeat(val workerId : String)//master ----&gt; worker 注册完成 ACKcase class RegisteredWorker(val workerHost : String)//master ----&gt; master 检查超时节点case class CheckTimeOutWorker()//worker ----&gt; worker 提醒自己发送心跳信号case class SendHeartBeat()</code></pre><p><strong>Worker.scala</strong></p><pre><code class="highlight plaintext">package akkaimport java.util.UUIDimport akka.actor._import com.typesafe.config.ConfigFactoryimport scala.concurrent.duration._import scala.concurrent.ExecutionContext.Implicits.globalclass Worker extends Actor {  //Worker端持有Master端的引用（代理对象）  //因为worker会给Master发送信息，所以才要这个对象  var master : ActorSelection = null  ////生成一个UUID，作为Worker的标识  val id = UUID.randomUUID().toString  //构造方法执行完执行一次  override def preStart(): Unit = {    //Worker向MasterActorSystem发送建立连接请求    master = context.system.actorSelection("akka.tcp://MasterActorSystem@localhost:8881/user/Master")    //Worker向Master发送注册消息    master ! RegisterWorker(id, "localhost", "10240", "8")  }  //该方法会被反复执行，用于接收消息，通过case class模式匹配接收消息  override def receive : Receive = {    //Master向Worker的反馈信息    case RegisteredWorker(masterURL) =&gt; {      //启动定时任务，向Master发送心跳      context.system.scheduler.schedule(0 millis, 5000 millis, self, SendHeartBeat)    }    case SendHeartBeat =&gt; {      println("worker send hearbeat")      master ! HeartBeat(id)    }  }}object Worker extends App{  val clientPort = 8803  //创建ActorSystem的必要参数  val configStr =    s"""       |akka.actor.provider = "akka.remote.RemoteActorRefProvider"       |akka.remote.netty.tcp.port = $clientPort       """.stripMargin  val conf = ConfigFactory.parseString(configStr)  //创建ActorSystem  val actorSystem = ActorSystem("MasterActorSystem",conf)  //启动Actor，Master会被实例化，生命周期方法会被调用  actorSystem.actorOf(Props[Worker],"Worker")}</code></pre><p><strong>Master.scala</strong></p><pre><code class="highlight plaintext">package akkaimport akka.actor.{Actor, ActorSystem, Props}import com.typesafe.config.ConfigFactoryimport scala.collection.mutableimport scala.concurrent.duration._import scala.concurrent.ExecutionContext.Implicits.globalclass Master extends Actor {  //保存WorkerId 和 Worker信息的 map  val idToWorker = new mutable.HashMap[String, WorkerInfo]  //保存所有worker信息的Set  val workers = new mutable.HashSet[WorkerInfo]  //Worker超时时间  val WORKER_TIMEOUT = 10 * 1000  //构造方法执行完执行一次  override def preStart(): Unit = {    //启动定时器，定时执行    //设置在5毫秒之后，间隔10秒，给自己发一个CheckOfTimeOutWorker    context.system.scheduler.schedule(0 millis, 5000 millis, self, CheckTimeOutWorker)  }  //该方法会被反复执行，用于接收消息，通过case class模式匹配接收消息  override def receive: Receive = {    //Worker向Master发送的注册消息    case RegisterWorker(id, workerHost, memory, cores) =&gt; {        if(!idToWorker.contains(id)){          val worker = new WorkerInfo(id,workerHost,memory,cores)          workers.add(worker)          idToWorker(id) = worker          println("nrew register worker: " + worker)          sender ! RegisteredWorker(worker.id)        }      }    //Worker向Master发送的心跳消息    case HeartBeat(workerId) =&gt; {      val workerInfo = idToWorker(workerId)      println("get heartbeat message from: "+ workerInfo)      workerInfo.lastHeartBeat = System.currentTimeMillis()    }    //Master自己向自己发送的定期检查超时Worker的消息    case CheckTimeOutWorker =&gt; {      //检查超时的worker      val currentTime = System.currentTimeMillis()      val toRemove = workers.filter( w =&gt; currentTime - w.lastHeartBeat &gt; WORKER_TIMEOUT).toArray      for(worker &lt;- toRemove){        workers -= worker        idToWorker.remove(worker.id)      }      println("Worker size: " + workers.size)    }  }}object Master extends App {  val host = "localhost"  val port = 8881  //创建ActorSystem的必要参数  val configStr =    s"""       |akka.actor.provider = "akka.remote.RemoteActorRefProvider"       |akka.remote.netty.tcp.hostname = "$host"       |akka.remote.netty.tcp.port = "$port"     """.stripMargin  val conf = ConfigFactory.parseString(configStr)  //创建ActorSystem  val actorSystem = ActorSystem("MasterActorSystem",conf)  //启动Actor Master会被实例化 生命周期的方法会被调用  actorSystem.actorOf(Props[Master],"Master")}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Akka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scala编程</title>
      <link href="/2019/03/25/scala_bian_cheng/"/>
      <url>/2019/03/25/scala_bian_cheng/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Scala函数式编程">一、Scala函数式编程</h3><p>多范式：面向对象，函数式编程（程序实现起来简单）</p><p>举例：WordCount<br>sc 是 SparkContext , 非常重要</p><p>一行：</p><pre><code class="highlight plaintext">var result = sc.textFile("hdfs://xxxx/xxx/data.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect</code></pre><h4 id="1、复习函数">1、复习函数</h4><p>关键字 def</p><h4 id="2、匿名函数">2、匿名函数</h4><p>没有名字的函数</p><p><strong>举例</strong></p><pre><code class="highlight plaintext">scala&gt; var myarray = Array(1,2,3)myarray: Array[Int] = Array(1, 2, 3)scala&gt; def fun1(x:Int):Int = x*3fun1: (x: Int)Intscala&gt; (x:Int) =&gt; x*3res0: Int =&gt; Int = &lt;function1&gt;</code></pre><p>问题：怎么去调用？高阶函数</p><pre><code class="highlight plaintext">scala&gt; fun1(3)res1: Int = 9scala&gt; myarray.foreach(println)123//调用匿名函数scala&gt; myarray.map((x:Int) =&gt; x*3)res3: Array[Int] = Array(3, 6, 9)</code></pre><p><code>(_,1)  (_+_)</code> 都是匿名函数</p><h4 id="3、高阶函数（带有函数参数的函数）">3、高阶函数（带有函数参数的函数）</h4><p>把一个函数作为另外一个函数的参数值</p><p>定义一个高阶函数：<br>对10做某种运算</p><pre><code class="highlight plaintext">scala&gt; def someAction(f:(Double)=&gt;(Double)) = f(10)someAction: (f: Double =&gt; Double)Double</code></pre><p><strong>解释</strong></p><p>(Double)=&gt;(Double) 代表了f 的类型：入参是double，返回值也是double的函数</p><pre><code class="highlight plaintext">import scala.math._scala&gt; someAction(sqrt)res5: Double = 3.1622776601683795scala&gt; someAction(sin)res6: Double = -0.5440211108893698scala&gt; someAction(cos)res7: Double = -0.8390715290764524scala&gt; someAction(println)&lt;console&gt;:16: error: type mismatch;found   : () =&gt; Unitrequired: Double =&gt; Double   someAction(println)                ^def someAction(f:(Double)=&gt;(Double)) = f(10)someAction(sqrt) = sqrt(10)</code></pre><h4 id="4、高阶函数的实例">4、高阶函数的实例</h4><p>scala中提供了常用的高阶函数</p><p>（1）map : 相当于一个循环，对某个集合中的每个元素都进行操作（接收一个函数），返回一个新的集合</p><p>scala&gt; var numbers = List(1,2,3,4,5,6,7,8,9,10)<br>numbers: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</p><p>scala&gt; numbers.map((i:Int)=&gt;i*2)<br>res2: List[Int] = List(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)</p><p>scala&gt; numers.map(_*2)<br>res3: List[Int] = List(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)</p><p>说明：<br>(i:Int)=&gt;i*2 与 _*2 等价的</p><p>(i:Int,j:Int)=&gt;i+j   <code>_+_</code><br>scala&gt; numbers<br>res4: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)<br>不改变numbers本身的值</p><p>（2）foreach：相当于一个循环，对某个集合中的每个元素都进行操作（接收一个函数），不返回结果<br>scala&gt; numbers.foreach(println)<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10</p><p>numbers.foreach(_*2)<br>没有返回值</p><p>（3） filter ：过滤，选择满足的数据<br>举例：查询能被2整除的数字</p><p>scala&gt; numbers.filter((i:Int)=&gt;i%2==0)<br>res5: List[Int] = List(2, 4, 6, 8, 10)</p><p>filter函数，参数要求：要求一个返回 bool 值的函数，筛选出所有为true的数据</p><p>（4）zip操作：合并两个集合<br>scala&gt; List(1,2,3).zip(List(4,5,6))<br>res6: List[(Int, Int)] = List((1,4), (2,5), (3,6))</p><p>//少的话匹配不上就不合并<br>scala&gt; List(1,2,3).zip(List(4,5))<br>res7: List[(Int, Int)] = List((1,4), (2,5))</p><p>scala&gt; List(1).zip(List(4,5))<br>res8: List[(Int, Int)] = List((1,4))</p><p>（5）partition ： 根据断言（就是某个条件，匿名函数）的结果，来进行分区<br>举例：<br>能被2整除的分成一个区，不能被2整除的分成另外一个区<br>scala&gt; numbers.partition((i:Int)=&gt;i%2==0)<br>res9: (List[Int], List[Int]) = (List(2, 4, 6, 8, 10),List(1, 3, 5, 7, 9))</p><p>（6）find ： 查找第一个满足条件的元素<br>scala&gt; numbers.find(_%3==0)<br>res10: Option[Int] = Some(3)</p><p>_%3==0 (i:Int)=&gt;i%3==0 一样</p><p>（7）flatten：把嵌套的结果展开<br>scala&gt; List(List(2,4,6,8,10),List(1,3,5,7,9)).flatten<br>res11: List[Int] = List(2, 4, 6, 8, 10, 1, 3, 5, 7, 9)</p><p>（8）flatmap : 相当于一个 map + flatten<br>scala&gt; var myList = List(List(2,4,6,8,10),List(1,3,5,7,9))<br>myList: List[List[Int]] = List(List(2, 4, 6, 8, 10), List(1, 3, 5, 7, 9))</p><p>scala&gt; myList.flatMap(x=&gt;x.map(_*2))<br>res22: List[Int] = List(4, 8, 12, 16, 20, 2, 6, 10, 14, 18)</p><p>myList.flatMap(x=&gt;x.map(_*2))</p><p>执行过程：<br>1、将 List(2, 4, 6, 8, 10), List(1, 3, 5, 7, 9) 调用 map(_*2) 方法。x 代表一个List<br>2、flatten</p><pre><code class="highlight plaintext">package day4/**  * 对比flatmap与map  */object Demo2 {  /**    * flatmap执行分析    * 1 List(1*2)   List(2)    * 2 List(2*2)   List(4)    * 3 List('a','b')    *    * List(List(2),List(4),List('a','b')).flatten    * List(2,4,'a','b')    */  def flatMap(){    val li = List(1,2,3)    val res = li.flatMap(x=&gt;      x match{      case 3=&gt;List('a','b')      case _=&gt;List(x*2)    })    println(res)  }  /**    * map过程解析    *     * 1 2  ----&gt;List(2,2,3)    * 2 4  ----&gt;List(2,4,5)    * 3 List('a','b')----&gt;List(2,4,List('a','b'))    */  def map(){    val li = List(1,2,3)    val res = li.map(x=&gt;      x match{      case 3=&gt;List('a','b')      case _=&gt;x*2    })    println(res)  }  def main(args: Array[String]): Unit = {    flatMap()    map()  }}</code></pre><h4 id="5、概念：闭包、柯里化">5、概念：闭包、柯里化</h4><p>（1）闭包：就是函数的嵌套<br>在一个函数的里面，包含了另一个函数的定义<br>可以在内函数中访问外函数的变量</p><p>举例：</p><pre><code class="highlight plaintext">def mulBy(factor:Double) = (x:Double)=&gt;x*factor        外                           内</code></pre><p>乘以三：</p><pre><code class="highlight plaintext">scala&gt; def mulBy(factor:Double) = (x:Double)=&gt;x*factormulBy: (factor: Double)Double =&gt; Doublescala&gt; var triple = mulBy(3)triple: Double =&gt; Double = &lt;function1&gt;相当于 triple(x:Double) = x*3scala&gt; triple(10)res1: Double = 30.0scala&gt; triple(20)res2: Double = 60.0scala&gt; var half = mulBy(0.5)half: Double =&gt; Double = &lt;function1&gt;scala&gt; half(10)res3: Double = 5.0</code></pre><p>引入柯里化：<br>scala&gt; mulBy(3)(10)<br>res4: Double = 30.0</p><p>（2）柯里化<br>概念：柯里化函数：是把具有多个参数的函数，转化为一个函数链，每个节点上都是单一函数</p><p>def add(x:Int,y:Int) = x+y</p><p>def add(x:Int)(y:Int) = x+y</p><p>转化步骤：</p><p>原始：def add(x:Int,y:Int) = x+y</p><p>闭包：def add(x:Int) = (y:Int) =&gt; x+y</p><p>简写：def add(x:Int)(y:Int) = x+y</p><p>scala&gt; def add(x:Int)(y:Int) = x+y<br>add: (x: Int)(y: Int)Int</p><p>scala&gt; add(1)(2)<br>res5: Int = 3</p><h3 id="二、Scala集合">二、Scala集合</h3><h4 id="1、可变集合和不可变集合（Map）">1、可变集合和不可变集合（Map）</h4><p>immutable mutable<br>举例：<br>scala&gt; def math = scala.collection.immutable.Map(“Tom”-&gt;80,”Lily”-&gt;20)<br>math: scala.collection.immutable.Map[String,Int]</p><p>scala&gt; def math = scala.collection.mutable.Map(“Tom”-&gt;80,”Lily”-&gt;20,”Mike”-&gt;95)<br>math: scala.collection.mutable.Map[String,Int]</p><p>集合的操作：<br>获取集合中的值<br>scala&gt; math.get(“Tom”)<br>res1: Option[Int] = Some(80)</p><p>scala&gt; math(“Tom”)<br>res2: Int = 80</p><p>scala&gt; math(“Tom123”)<br>java.util.NoSuchElementException: key not found: Tom123<br>at scala.collection.MapLike$class.default(MapLike.scala:228)<br>at scala.collection.AbstractMap.default(Map.scala:59)<br>at scala.collection.mutable.HashMap.apply(HashMap.scala:65)<br>… 32 elided</p><p>scala&gt; math.get(“Tom123”)<br>res3: Option[Int] = None</p><p>scala&gt; math.contains(“Tom123”)<br>res4: Boolean = false</p><p>scala&gt; math.getOrElse(“Tom123”,-1)<br>res5: Int = -1</p><p>更新集合中的值：注意：必须是可变集合<br>scala&gt; math<br>res6: scala.collection.mutable.Map[String,Int] = Map(Mike -&gt; 95, Tom -&gt; 80, Lily -&gt; 20)</p><p>scala&gt; math(“Tom”)=0<br>scala&gt; math<br>res7: scala.collection.mutable.Map[String,Int] = Map(Mike -&gt; 95, Tom -&gt; 80, Lily -&gt; 20)</p><p>造成上述现象的原因，没有import包，如果import以后，问题解决：<br>scala&gt; import scala.collection.mutable._<br>import scala.collection.mutable._</p><p>scala&gt; var math = Map(“Tom”-&gt;80,”Lily”-&gt;20,”Mike”-&gt;95)<br>math: scala.collection.mutable.Map[String,Int] = Map(Mike -&gt; 95, Tom -&gt; 80, Lily -&gt; 20)</p><p>scala&gt; math(“Tom”)=0<br>scala&gt; math<br>res8: scala.collection.mutable.Map[String,Int] = Map(Mike -&gt; 95, Tom -&gt; 0, Lily -&gt; 20)</p><p>添加新的元素<br>scala&gt; math(“Tom”)=80<br>scala&gt; math += “Bob”-&gt;85<br>res9: scala.collection.mutable.Map[String,Int] = Map(Bob -&gt; 85, Mike -&gt; 95, Tom -&gt; 80, Lily -&gt; 20)</p><p>移出一个元素<br>scala&gt; math -= “Bob”<br>res10: scala.collection.mutable.Map[String,Int] = Map(Mike -&gt; 95, Tom -&gt; 80, Lily -&gt; 20)</p><h4 id="2、列表：可变列表，不可变列表">2、列表：可变列表，不可变列表</h4><p>不可变列表 List<br>scala&gt; var myList=List(1,2,3)<br>myList: List[Int] = List(1, 2, 3)</p><p>scala&gt; val nullList:List[Nothing] = List()<br>nullList: List[Nothing] = List()</p><p>//二维列表<br>scala&gt; val dim : List[List[Int]] = List(List(1,2,3),List(4,5,6))<br>dim: List[List[Int]] = List(List(1, 2, 3), List(4, 5, 6))</p><p>scala&gt; myList.head<br>res11: Int = 1</p><p>scala&gt; myList.tail<br>res12: List[Int] = List(2, 3)</p><p>注意：tail 是除了第一个元素外，其他的元素</p><p>可变列表：LinedList 在 scala.collection.mutable 包中</p><p>scala&gt; var myList = scala.collection.mutable.LinkedList(1,2,3,4)<br>warning: there was one deprecation warning; re-run with -deprecation for details<br>myList: scala.collection.mutable.LinkedList[Int] = LinkedList(1, 2, 3, 4)</p><p>需求：把上面列表中，每一个元素都乘以2</p><p>游标，指向列表的开始</p><pre><code class="highlight plaintext">var cur = myList//Nil意思为空while(cur != Nil ){    //把当前元素乘以2    cur.elem = cur.elem*2    //移动指针到下一个元素    cur = cur.next}</code></pre><p>scala&gt; var cur = myList<br>cur: scala.collection.mutable.LinkedList[Int] = LinkedList(1, 2, 3, 4)</p><p>scala&gt; while(cur != Nil ){<br>| cur.elem = cur.elem*2<br>| cur = cur.next<br>| }</p><p>scala&gt; myList<br>res13: scala.collection.mutable.LinkedList[Int] = LinkedList(2, 4, 6, 8)</p><p>scala&gt; myList.map(_*2)<br>warning: there was one deprecation warning; re-run with -deprecation for details<br>res14: scala.collection.mutable.LinkedList[Int] = LinkedList(4, 8, 12, 16)</p><h4 id="3、序列">3、序列</h4><p>（*）数据库中也有序列：sequence 、 auto increment<br>（1）作为主键，实现自动增长<br>（2）提高性能，序列在Oracle是在内存中的</p><p>（*）Vector Range<br>举例：<br>Vector 是一个带下标的序列，我们可以通过下标来访问Vector中的元素<br>scala&gt; var v = Vector(1,2,3,4,5,6)<br>v: scala.collection.immutable.Vector[Int] = Vector(1, 2, 3, 4, 5, 6)</p><p>Range ： 是一个整数的序列<br>scala&gt; Range(0,5)<br>res15: scala.collection.immutable.Range = Range(0, 1, 2, 3, 4)</p><p>从0开始，到5 ，但不包括5</p><p>scala&gt; println(0 until 5)<br>Range(0, 1, 2, 3, 4)</p><p>scala&gt; println(0 to 5)<br>Range(0, 1, 2, 3, 4, 5)</p><p>Range可以相加<br>scala&gt; (‘0’ to ‘9’) ++ (‘A’ to ‘Z’)<br>res16: scala.collection.immutable.IndexedSeq[Char] = Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z)</p><p>把Range转换成list<br>scala&gt; 1 to 5 toList<br>warning: there was one feature warning; re-run with -feature for details<br>res17: List[Int] = List(1, 2, 3, 4, 5)</p><h4 id="4、集（Set）">4、集（Set）</h4><p>不重复元素的集合，默认是HashSet，与java类似<br>scala&gt; var s1 = Set(1,2,10,8)<br>s1: scala.collection.immutable.Set[Int] = Set(1, 2, 10, 8)</p><p>scala&gt; s1 + 10<br>res18: scala.collection.immutable.Set[Int] = Set(1, 2, 10, 8)</p><p>scala&gt; s1 + 7<br>res19: scala.collection.immutable.Set[Int] = Set(10, 1, 2, 7, 8)</p><p>scala&gt; s1<br>res20: scala.collection.immutable.Set[Int] = Set(1, 2, 10, 8)</p><p>创建一个可排序的Set SortedSet<br>scala&gt; var s2 = scala.collection.mutable.SortedSet(1,2,3,10,8)<br>s2: scala.collection.mutable.SortedSet[Int] = TreeSet(1, 2, 3, 8, 10)</p><p>判断元素是否存在<br>scala&gt; s2.contains(1)<br>res21: Boolean = true</p><p>scala&gt; s2.contains(1231231)<br>res22: Boolean = false</p><p>集的运算：union并集 intersect 交集 diff 差集<br>scala&gt; var s1 = Set(1,2,3,4,5,6)<br>s1: scala.collection.immutable.Set[Int] = Set(5, 1, 6, 2, 3, 4)</p><p>scala&gt; var s2 = Set(5,6,7,8,9,10)<br>s2: scala.collection.immutable.Set[Int] = Set(5, 10, 6, 9, 7, 8)</p><p>scala&gt; s1 union s2<br>res23: scala.collection.immutable.Set[Int] = Set(5, 10, 1, 6, 9, 2, 7, 3, 8, 4)</p><p>scala&gt; s1 intersect s2<br>res24: scala.collection.immutable.Set[Int] = Set(5, 6)</p><p>scala&gt; s1 diff s2<br>res25: scala.collection.immutable.Set[Int] = Set(1, 2, 3, 4)</p><p>数据库里面的union操作，要求：<br>列数一样<br>列的类型一样</p><pre><code class="highlight plaintext">select A,B from ****union select C,D from *****</code></pre><p>函数的定义+返回值<br>def sum():Int =</p><p>python数据分析<br>pyspark</p><h4 id="5、模式匹配">5、模式匹配</h4><p>相当于java中的switch case语句 但是 功能更强大</p><pre><code class="highlight plaintext">package day5/**  * 模式匹配  */object Demo1 {  def main(args: Array[String]): Unit = {    //1、相当于java switch case    var chi = '-'    var sign = 0    chi match {      case '+' =&gt; sign = 1      case '-' =&gt; sign = -1      case _ =&gt; sign = 0    }    println(sign)    /**      * 2、scala中的守卫，case _ if 匹配某种类型的所有值      * 需求：匹配所有的数字      */    var ch2 = '5'    var result : Int = -1    ch2 match {      case '+' =&gt; println("这是一个加号")      case '-' =&gt; println("这是一个减号")      //这里的10表示转换成1十进制      case _ if Character.isDigit(ch2) =&gt; result=Character.digit(ch2,10)      case _ =&gt; println("其他")    }    println(result)    /**      * 3、在模式匹配中使用变量      * 如果改成var mystr = "Hello W+rld"      * 打印：加号      *      * 匹配中，则相当于break      */    var mystr = "Hello World"    //取出某个字符，赋给模式匹配的变量    mystr(7) match {      case '+' =&gt; println("加号")      case '-' =&gt; println("减号")      //case 语句中使用变量 ch代表传递进来的字符      case ch =&gt; println(ch)    }    /**      * 4、匹配类型 instance of      * 用法：case x : Int =&gt;      *      * Any : 表示任何类型，相当于java中的Object      * Unit : 表示没有值， void      * Nothing : 表示在函数抛出异常时，返回值就是Nothing      *           是scala类层级中的最低端，是任何其他类型的子类型      * Null : 表示引用类型的子类，值：null      *      * 特殊类型      * Option : 表示一个值是可选的（有值或者无值）      * Some : 如果值存在，Option[T] 就是一个Some[T]      * None : 如果值不存在，Option[T] 就是一个None      *      * scala&gt; var myMap = Map("Time"-&gt;96)      * myMap: scala.collection.immutable.Map[String,Int] = Map(Time -&gt; 96)      *      * scala&gt; myMap.get("Time")      * res0: Option[Int] = Some(96)      *      * scala&gt; myMap.get("Time12342")      * res1: Option[Int] = None      *      * Nil : 空的List      *      * 四个N总结：None Nothing Null Nil      * None : 如果值不存在，Option[T] 就是一个None      * Nothing : 如果方法抛出异常时，则异常的返回值类型就是Nothing      * Null : 可以赋值给所以的引用类型，但是不能赋值给值类型      *       class Student      *       var s1 = new Student      *       s1 = null      * Nil : 空的List      */    var v4 : Any = 100    v4 match {      case x : Int =&gt; println("这是一个整数")      case s : String =&gt; println("这是一个字符串")      case _ =&gt; println("这是其他类型")    }    //5、匹配数组和列表    var myArray = Array(1,2,3)    myArray match {      case Array(0) =&gt; println("数组中只有一个0")      case Array(x,y) =&gt; println("数组中包含两个元素")      case Array(x,y,z) =&gt; println("数组中包含三个元素")      case Array(x,_*) =&gt; println("这是一个数组，包含多个元素")    }    var myList = List(1,2,3)    myList match {      case List(0) =&gt; println("列表中只有一个0")      case List(x,y) =&gt; println("列表中包含两个元素，和是" + (x+y))      case List(x,y,z) =&gt; println("列表中包含三个元素，和是" + (x+y+z))      case List(x,_*) =&gt; println("列表中包含多个元素，和是" + myList.sum)    }  }}</code></pre><h4 id="6、样本类">6、样本类</h4><p>定义： case class</p><pre><code class="highlight plaintext">package day5/**  * 使用case class 来实现模式匹配  */class Vehiclecase class Car(name:String) extends  Vehiclecase class Bike(name:String) extends  Vehicleobject Demo2 {  def main(args: Array[String]): Unit = {    var aCar : Vehicle = new Car("Car")    aCar match {      case Car(name) =&gt; println("汽车 " + name)      case Bike(name) =&gt; println("自行车 " + name)      case _ =&gt; println("其他")    }  }}</code></pre><p>作用：<br>（1）支持模式匹配，instanceof<br>（2）定一个 Spark SQL 中的 schema ： 表结构</p><pre><code class="highlight plaintext">scala&gt; class Fruitdefined class Fruitscala&gt; class Banana(name:String) extends Fruitdefined class Bananascala&gt; class Apple(name:String) extends Fruitdefined class Applescala&gt; var a = new Apple("Apple")a: Apple = Apple@572e6fd9scala&gt; println(a.isInstanceOf[Fruit])truescala&gt; println(a.isInstanceOf[Banana])&lt;console&gt;:16: warning: fruitless type test: a value of type Apple cannot also be a Banana       println(a.isInstanceOf[Banana])                             ^false</code></pre><h3 id="三、Scala高级特性">三、Scala高级特性</h3><h4 id="1、泛型">1、泛型</h4><p>和java类似 T</p><p><strong>1）泛型类</strong><br>定义类的时候，可以带有一个泛型的参数<br>例子：</p><pre><code class="highlight plaintext">package day5/**  * 泛型类  *///需求：操作一个整数class GenericClassInt{  //定义一个整数的变量  private var content : Int = 10  //定义set get  def set(value : Int) = content = value  def get() : Int = content}//需求：操作一个字符串class GenericClassString{  //定义一个空字符串  private var content : String = ""  //定义set get  def set(value : String) = content = value  def get() : String = content}class GenericClass[T]{  //定义变量  //注意：初始值用_来表示  private var content : T = _  //定义set get  def set(value : T) = content = value  def get() : T = content}object Demo3{  def main(args: Array[String]): Unit = {    //定义一个Int 类型    var v1 = new GenericClass[Int]    v1.set(1000)    println(v1.get())    //定义一个String 类型    var v2 = new GenericClass[String]    v2.set("Ni")    println(v2.get())  }}</code></pre><p><strong>2）泛型函数</strong></p><p>定义一个函数，可以带有一个泛型的参数</p><p>scala&gt; def mkIntArray(elem:Int*)=<code>Array[Int](elem:_*)</code><br>mkIntArray: (elem: Int*)Array[Int]</p><p>scala&gt; mkIntArray(1,2,3)<br>res5: Array[Int] = Array(1, 2, 3)</p><p>scala&gt; mkIntArray(1,2,3,4,5)<br>res6: Array[Int] = Array(1, 2, 3, 4, 5)</p><p>scala&gt; def mkStringArray(elem:String*)=<code>Array[String](elem:_*)</code><br>mkStringArray: (elem: String*)Array[String]</p><p>scala&gt; mkStringArray(“a”,“b”)<br>res7: Array[String] = Array(a, b)</p><p>scala&gt; def mkArray[T:ClassTag]</p><p>ClassTag ： 表示scala在运行时候的状态信息，这里表示调用时候数据类型</p><p>scala&gt; import scala.reflect.ClassTag<br>import scala.reflect.ClassTag</p><pre><code class="highlight plaintext">scala&gt; def mkArray[T:ClassTag](elem:T*)= Array[T](elem:_*)mkArray: [T](elem: T*)(implicit evidence$1: scala.reflect.ClassTag[T])Array[T]</code></pre><p>scala&gt; mkArray(1,2)<br>res8: Array[Int] = Array(1, 2)</p><p>scala&gt; mkArray(“Hello”,“aaa”)<br>res9: Array[String] = Array(Hello, aaa)</p><p>scala&gt; mkArray(“Hello”,1)<br>res10: Array[Any] = Array(Hello, 1)<br>泛型：但凡有重复的时候，考虑使用泛型</p><p><strong>3）上界和下界</strong></p><p>Int x<br>规定x的取值范围 100 &lt;= x &lt;=1000</p><p>泛型的取值范围：<br>T</p><p>类的继承关系 A —&gt; B —&gt; C —&gt; D 箭头指向子类</p><p>定义T的取值范围 D &lt;: T &lt;: B</p><p>T 的 取值范围 就是 B C D</p><p>&lt;: 就是上下界的表示方法</p><p>概念<br>上界 S &lt;： T 规定了 S的类型必须是 T的子类或本身<br>下界 U &gt;： T 规定了 U的类型必须是 T的父类或本身</p><p>例子：</p><pre><code class="highlight plaintext">package day5/**  * 主界  *///定义父类class Vehicle{  //函数：驾驶  def drive() = println("Driving")}//定义两个子类class Car extends Vehicle{  override def drive() : Unit = println("Car Driving")}//class Bike extends Vehicle{//  override def drive(): Unit = println("Bike Driving")//}class Bike{  def drive(): Unit = println("Bike Driving")}object ScalaUpperBoud {  //定义驾驶交通工具的函数  def takeVehicle[T &lt;: Vehicle](v:T) = v.drive()  def main(args: Array[String]): Unit = {    //定义交通工具    var v : Vehicle = new Vehicle    takeVehicle(v)    var c : Car = new Car    takeVehicle(c)    //因为没有继承Vehicle，所以运行报错    var b : Bike = new Bike    takeVehicle(b)  }}</code></pre><pre><code class="highlight plaintext">scala&gt; def addTwoString[T &lt;: String](x:T,y:T) = x +" ********* " + yaddTwoString: [T &lt;: String](x: T, y: T)Stringscala&gt; addTwoString("Hello","World")res11: String = Hello ********* Worldscala&gt; addTwoString(1,2)&lt;console&gt;:14: error: inferred type arguments [Int] do not conform to method addTwoString's type parameter bounds [T &lt;: String]       addTwoString(1,2)       ^&lt;console&gt;:14: error: type mismatch; found   : Int(1) required: T       addTwoString(1,2)                    ^&lt;console&gt;:14: error: type mismatch; found   : Int(2) required: T       addTwoString(1,2)                      ^scala&gt; addTwoString(1.toString,2.toString)res13: String = 1 ********* 2</code></pre><p><strong>4）视图界定 View bounds</strong></p><p>就是上界和下界的扩展</p><p>除了可以接收上界和下界规定的类型以外，还可以接收能够通过隐式转换过去的类型</p><p>用 % 来表示</p><pre><code class="highlight plaintext">scala&gt;  def addTwoString[T &lt;% String](x:T,y:T) = x +" ********* " + yaddTwoString: [T](x: T, y: T)(implicit evidence$1: T =&gt; String)Stringscala&gt; addTwoString(1,2)&lt;console&gt;:14: error: No implicit view available from Int =&gt; String.       addTwoString(1,2)                   ^//定义隐式转换函数scala&gt; implicit def int2String(n:Int):String = n.toStringwarning: there was one feature warning; re-run with -feature for detailsint2String: (n: Int)Stringscala&gt; addTwoString(1,2)res14: String = 1 ********* 2</code></pre><p><strong>执行过程</strong></p><p>1、调用了 int2String Int =&gt; String<br>2、addTwoString(“1”,”2”)</p><p><strong>5）协变和逆变（概念）</strong></p><p>协变：表示在类型参数前面加上 + 。泛型变量的值，可以是本身类型或者其子类类型<br>例子：</p><pre><code class="highlight plaintext">package day5/**  * 协变：表示在类型参数前面加上 + 。泛型变量的值，可以是本身类型或者其子类类型  */class Animalclass Bird extends Animalclass Sparrow extends Bird//定义第四个类，吃东西的类，协变，有继承关系了class EatSomething[+T](t:T)object Demo4 {  def main(args: Array[String]): Unit = {    //定义一个鸟吃东西的对象    var c1 : EatSomething[Bird] =new EatSomething[Bird](new Bird)    //定义一个动物吃东西的对象    var c2 : EatSomething[Animal] = c1    /**      * 问题：能否把c1 赋给c2      * c1 c2都是EatSomething      * c1 c2 没有继承关系      *      * class EatSomething[T](t:T)      * var c2 : EatSomething[Animal] = c1  报错      * 原因 ： EatSomething[Bird] 并没有继承EatSomething[Animal]      *      * class EatSomething[+T](t:T)      * 报错消失      *      * 协变      */    var c3 : EatSomething[Sparrow] = new EatSomething[Sparrow](new Sparrow)    var c4 : EatSomething[Animal] = c3  }}</code></pre><p>逆变：表示在类型参数前面加上 - 。泛型变量的值，可以是本身类型或者其父类类型<br>例子：</p><pre><code class="highlight plaintext">package day5/**  * 逆变：表示在类型参数前面加上 - 。泛型变量的值，可以是本身类型或者其父类类型  */class Animalclass Bird extends Animalclass Sparrow extends Bird//定义第四个类，吃东西的类，逆变class EatSomething[-T](t:T)object Demo5 {  def main(args: Array[String]): Unit = {    //定义一个鸟吃东西的对象    var c1 : EatSomething[Bird] =new EatSomething[Bird](new Bird)    //定义一个动物吃东西的对象    var c2 : EatSomething[Sparrow] = c1  }}</code></pre><h4 id="2、隐式转换">2、隐式转换</h4><p><strong>1）隐式转换函数： implicit</strong></p><pre><code class="highlight plaintext">package day5/**  * 隐式转换  *  * 定义一个隐式转换函数  */class Fruit(name:String){  def getFruitName() : String = name}class Monkey(f:Fruit){  def say()  = println("Monkey like " + f.getFruitName())}object ImplicitDemo {  def main(args: Array[String]): Unit = {    //定义一个水果对象    var f : Fruit = new Fruit("Banana")    f.say()  }  implicit def fruit2Monkey(f:Fruit) : Monkey = {    new Monkey(f)  }}</code></pre><p><strong>2）隐式参数：使用implicit 修饰的函数参数</strong></p><p>定义一个带有隐式参数的函数：</p><pre><code class="highlight plaintext">scala&gt; def testPara(implicit name:String) = println("The value is " + name)testPara: (implicit name: String)Unitscala&gt; testPara("AAAA")The value is AAAAscala&gt; implicit val name : String = "*****"name: String = *****scala&gt; testParaThe value is *****</code></pre><p>定义一个隐式参数，找到两个值中比较小的那个值<br>100 23 –&gt;23<br>“Hello” “ABC” –&gt; ABC</p><pre><code class="highlight plaintext">scala&gt; def smaller[T](a:T,b:T)(implicit order : T =&gt; Ordered[T]) = if(a&lt;b) a else bsmaller: [T](a: T, b: T)(implicit order: T =&gt; Ordered[T])Tscala&gt; smaller(1,2)res18: Int = 1scala&gt; smaller("Hello","ABC")res19: String = ABC</code></pre><p>解释：<br>order 就是一个隐式参数，我们使用Scala中的 Ordered 类，表示该值可以被排序，也就是可以被比较</p><p>作用：扩充了属性的功能</p><p><strong>3）隐式类 在类名前 加 implicit 关键字</strong></p><p>作用：扩充类的功能</p><pre><code class="highlight plaintext">package day5/**  * 隐式类  */object Demo6 {  def main(args: Array[String]): Unit = {    //执行两个数字的求和    println("两个数字的和是： "+1.add(2))    /**      * 定义一个隐式类，类增强1的功能      *      * Calc(x:Int)      * 1是Int类型，所以就会传递进来      *      * 执行过程：      * 1---&gt;Calc类      * var a = new Calc(1)      * 在调用Calc add方法      * a.add(2)      *      */    implicit class Calc(x:Int){      def add(y: Int) : Int = x + y    }  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scala基础</title>
      <link href="/2019/03/23/scala_ji_chu/"/>
      <url>/2019/03/23/scala_ji_chu/</url>
      
        <content type="html"><![CDATA[<p>1、Scala编程语言<br>2、Spark Core ： Spark内核 ，最重要的一个部分<br>3、Spark SQL : 类似于 Hive 和Pig。数据分析引擎。sql语句提交到Spark集群中运行<br>4、Spark Streaming ：类似于 Storm，用于流式计算、实时计算。本质：一个离线计算</p><h3 id="一、Scala基础">一、Scala基础</h3><h4 id="1、Scala简介">1、Scala简介</h4><p>1）Scala是一个多范式的编程语言（支持多种方式的编程）<br>（1）使用面向对象编程：封装、继承、多态<br>（2）使用函数式编程：最大的特定<br>优点：代码非常简洁<br>缺点：可读性太差，尤其是隐式类、隐式函数、隐式参数</p><p>2）安装和配置Scala<br>（1）基于JDK，先安装JDK<br>（2）Scala：2.11.8（Spark 2.1.0）<br>（3）配置环境变量：SCALA_HOME<br>（4）%SCALA_HOME%\bin 配置到path中<br>下载地址：<a href="https://www.scala-lang.org">https://www.scala-lang.org</a><br>文档地址：<a href="https://www.scala-lang.org/api/2.11.8/#scala.math.package">https://www.scala-lang.org/api/2.11.8/#scala.math.package</a></p><p>3）开发环境<br>REPL命令行<br>IDEA ： 需要安装Scala插件</p><h4 id="2、Scala中的数据类型和变量常量">2、Scala中的数据类型和变量常量</h4><p>1）注意一点：Scala中所有的数据，都是对象<br>举例：1 Java int 。在Scala中，1 就是一个对象</p><p>2）基本数据类型<br>Byte ：8位有符号数字<br>Short ：16位有符号数字<br>Int ：32位有符号数字<br>Long ： 64位有符号数字<br>Float ：32位有符号数字<br>Double ：64位有符号数字<br>Char ：8位有符号数字<br>Boolean ： 1位有符号数字</p><p>字符串类型<br>String</p><p>字符<br>Char ：8位有符号数字</p><p>Scala中字符串的插值操作：就是相当于字符串的拼接</p><pre><code class="highlight plaintext">scala&gt; var s1 : String = "Hello "s1: String = "Hello "scala&gt; "My name is Tom and ${s1}"res1: String = My name is Tom and ${s1}</code></pre><p>插值操作时，需要加入 s</p><pre><code class="highlight plaintext">scala&gt; s"My name is Tom and ${s1}"res2: String = "My name is Tom and Hello "</code></pre><p>3）变量var和常量val</p><p>scala&gt; val s2 :String = “Hello all”<br>s2: String = Hello all</p><p>scala&gt; s2 = “Hello everyone”<br><console>:12: error: reassignment to val<br>s2 = “Hello everyone”</console></p><p>4）Unit类型和Nothing类型<br>（1）Unit类型，就是java中的void，没有返回值</p><pre><code class="highlight plaintext">scala&gt; val f = ()f: Unit = ()</code></pre><p>返回值 Unit类型<br>( ) 代表了一个函数，这个函数没有返回值</p><p>（2）Nothing类型，在执行过程中，产生了异常Exception<br>举例：<br>scala函数：scala中函数非常重要，是scala的头等公民<br>用法很多：函数式编程、高阶函数</p><p>def myFunction = 函数的实现</p><pre><code class="highlight plaintext">scala&gt; def myFun = throw new Exception("Some Error")myFun: Nothing</code></pre><h4 id="3、函数（头等公民）">3、函数（头等公民）</h4><p>（1）scala内置函数，可以直接使用的函数</p><pre><code class="highlight plaintext">scala&gt; max(1,2)&lt;console&gt;:12: error: not found: value max       max(1,2)       ^scala&gt; import scala.math   final package mathscala&gt; import scala.math._import scala.math._</code></pre><p>_ 就相当于Java中的 * 代表包内所有东西</p><pre><code class="highlight plaintext">scala&gt; max(1,2)res4: Int = 2</code></pre><p>res4: Int = 2<br>定义了一个变量 res4 ，接收了 max 函数的返回值。Scala中支持类型的推导。<br>res4 = “”</p><p>（2） 自定义函数<br>语法：<br>def 函数名称（[参数名称：参数类型]*） : 返回值类型 = {<br>函数的实现<br>}</p><p>举例：<br>1）求和</p><pre><code class="highlight plaintext">scala&gt; def sum(x:Int,y:Int):Int = x + ysum: (x: Int, y: Int)Intscala&gt; sum(1,2)res5: Int = 3</code></pre><p>2）求阶乘，5！= 5 * 4* 3 2 1</p><p><strong>递归</strong></p><pre><code class="highlight plaintext">scala&gt; def myFactor(x:Int):Int = {     | if(x&lt;=1)     | 1     | else     | x*myFactor(x-1)     | }myFactor: (x: Int)Intscala&gt; myFactor(5)res6: Int = 120</code></pre><p>注意：没有return语句<br>函数的最后一句话，就是函数的返回值</p><p>3）求输入的年份是否是闰年<br>闰年：<br>普通闰年：可以被4整除但是不能被100整除的年份<br>世纪闰年：可以被400整除的年份</p><pre><code class="highlight plaintext">scala&gt; def isLeapYear(x:Int) = {     | if(( x%4 == 0 &amp;&amp; x%100 != 0) || (x%400==0)) true     | else false     | }isLeapYear: (x: Int)Booleanscala&gt; isLeapYear(2019)res7: Boolean = falsescala&gt; isLeapYear(2008)res8: Boolean = true</code></pre><p><strong>注意</strong></p><p>1、( x%4 == 0 &amp;&amp; x%100 != 0) || (x%400==0)<br>2、函数定义的时候，可以不写返回值，因为scala支持类型推导</p><h4 id="4、循环语句">4、循环语句</h4><p>1）类似于Java的用法 while dowhile for</p><pre><code class="highlight plaintext">/**      * for循环      *      * 定义一个集合      */    var list = List("dfg","Agddg","Fd")    println("------------for循环中的第一种写法-------------")    for( s &lt;- list ) println(s)    println("------------for循环中的第二种写法-------------")    //打印长度大于3的名字    for{      s &lt;- list      if(s.length &gt; 3)    }println(s)    println("------------for循环中的第三种写法-------------")    //对第二种进一步简化    for( s&lt;- list if s.length &lt;= 3) println(s)    println("------------for循环中的第四种写法-------------")    /**      * 1、把list中所有元素都变成大写      * s &lt;- list      * s1 = s.toUpperCase      *      * 2、返回一个新的集合      * yield(s1)      *      */    var newList = for {      s &lt;- list      s1 = s.toUpperCase    }yield(s1)    for(s &lt;- newList) println(s)    println("------------while循环-------------")    //定义循环变量    var i = 0    while( i &lt; list.length){      println(list(i))      /**        * 自增        *        * 注意scala中没有i++        */      i += 1    }    println("------------do while循环-------------")    //定义循环变量    var j = 0    do{      println(list(j))      j += 1    }while( j &lt; list.length)</code></pre><p>2）foreach循环（Spark算子）</p><pre><code class="highlight plaintext">println("------------foreach循环-------------")  /**    * foreach scala里面有 spark里面    * map    *    * 没有返回值，map有返回值    * foreach是list的一个方法    */  list.foreach(println)  /**    * foreach 说明    * list.foreach(println)    *    *  我们把一个函数传入了foreach    *  高阶函数（函数式编程）    */  /**    * 判断101-200之间有多少个素数    *    * 判断素数的方法：    * x%2 -----x%sqrt(根号)x    * 当都不能被整除的时候就是素数    *    *    * 16    * sqrt(16) = 4    * 2 3 4    *    * 16%2 == 0 ?    * 16%3 == 0 ?    * 16%4 == 0 ?    *    * 编程思路：    * 两层循环：    *   第一层：101-200    *     第二层：2--sqrt第一层    *    */  println("---------循环嵌套-------------")  var count : Int = 0 //保存结果  var index_outer = 0  var index_inner = 0  for(index_outer &lt;- 101 until 200){    index_inner = 2    var b = false //标识是否能被整除    breakable{      while(index_inner &lt;= sqrt(index_outer)){        if(index_outer % index_inner ==0) {          b = true          break        }        index_inner += 1      }    }    if(!b) count += 1  }  println("个数为：" + count)  /**  * 算法分析：  * 1、比较相邻的元素。如果第一个比第二个大，就交换他们两个。  * 2、对每一对相邻元素都做上述工作，循环完第一次后，最后的元素，就是最大的元素。  * 3、针对剩下的元素，重复上面工作（除了最后一个元素）  *  * 程序分析：  * 1、两层循环  * 2、外层循环控制比较的次数  * 3、内层循环控制到达的位置，就是 结束比较 的位置  **/  println("---------冒泡排序-------------")  var a = Array(12,3,6,3,6,7,3,8,34,3)  println("---------排序前---------------")  a.foreach(println)  for(i &lt;- 0 until a.length - 1){    for(j &lt;- 0 until a.length - i - 1){      if(a(j) &gt; a(j+1)){        //交换        var tmp = a(j)        a(j) = a(j+1)        a(j+1) = tmp      }    }  }  println("---------排序后---------------")  a.foreach(println)</code></pre><h4 id="5、Scala的函数参数">5、Scala的函数参数</h4><p>1）函数参数的求值策略<br>（1）call by value :<br>对函数的实参求值，并且只求一次</p><p>（2）call by name : =&gt;<br>函数实参在函数体内部用到的时候，才会被求值</p><p>举例：</p><pre><code class="highlight plaintext">scala&gt; def test1(x:Int,y:Int) = x + xtest1: (x: Int, y: Int)Intscala&gt; test1(3+4,8)res9: Int = 14scala&gt; def test2(x : =&gt; Int,y : =&gt; Int) = x+xtest2: (x: =&gt; Int, y: =&gt; Int)Intscala&gt; test2(3+4,8)res10: Int = 14</code></pre><p>执行过程对比：<br>test1 —&gt; test1(3+4,8) —&gt; test1(7,8) —&gt; 7+7 —&gt; 14<br>test2 —&gt; test2(3+4,8) —&gt; (3+4) + (3+4) —&gt; 14</p><p>（3）复杂的例子<br>def bar(x:Int,y : =&gt; Int) : Int = 1<br>x 是 value y 是 name</p><p>定义一个死循环：<br>def loop() : Int = loop</p><p>调用bar函数的时候：<br>1、bar(1,loop)<br>2、bar(loop,1)–&gt;产生死循环</p><p>哪个方式会产生死循环？</p><pre><code class="highlight plaintext">scala&gt; def bar(x:Int,y : =&gt; Int) : Int = 1bar: (x: Int, y: =&gt; Int)Intscala&gt; def loop() : Int = looploop: ()Intscala&gt; bar(1,loop)res11: Int = 1scala&gt; bar(loop,1)</code></pre><p><strong>解析</strong></p><p>1、虽然 y 是 name, 每次调用的时候会被求值。但是，函数体内，没有调用到y.<br>2、x 是 value，对函数参数求值，并且只求一次。虽然后面没有用到x，但求值时产生了死循环</p><p>2、Scala中函数参数的类型<br>（1）默认参数<br>当你没有给参数值赋值的时候，就会使用默认值</p><pre><code class="highlight plaintext">def fun1(name:String="Ti") :String = "Hello " + namescala&gt; def fun1(name:String="Ti") :String = "Hello " + namefun1: (name: String)Stringscala&gt; fun1("An")res0: String = Hello Anscala&gt; fun1()res1: String = Hello Ti</code></pre><p>（2）代名参数<br>当有多个默认参数的时候，通过代名参数可以确定给哪个函数参数赋值。</p><pre><code class="highlight plaintext">def fun2(str:String = "Hello " , name:String = " Ti " ,age:Int = 20) = str + name + " age is " +agescala&gt; def fun2(str:String = "Hello " , name:String = " Ti " ,age:Int = 20) = str + name + " age is " +agefun2: (str: String, name: String, age: Int)Stringscala&gt; fun2()res2: String = Hello  Ti  age is 20scala&gt; fun2("An")res3: String = An Ti  age is 20scala&gt; fun2(name="An")res4: String = Hello An age is 20</code></pre><p>（3）可变参数<br>类似于Java中的可变参数，即 参数数量不固定</p><pre><code class="highlight plaintext">scala&gt; def sum(args:Int*)= { | var result = 0 | for(s&lt;-args) result +=s | result | }sum: (args: Int*)Intscala&gt; sum(1,2,3,4)res5: Int = 10scala&gt; sum(1,2,3,4,3,4)res6: Int = 17</code></pre><h4 id="6、懒值（lazy）">6、懒值（lazy）</h4><p>铺垫：Spark的核心是 RDD（数据集合），操作数据集合的数据，使用算子来操作RDD（函数、方法）</p><p>算子：<br>Transformation ： 延时加载，不会触发计算<br>Action ： 会立刻触发计算</p><p>定义：常量如果是lazy的，他的初始化会被延迟，推迟到第一次使用该常量的时候<br>举例：<br>scala&gt; var x : Int = 10<br>x: Int = 10</p><p>scala&gt; val y : Int = x+1<br>y: Int = 11</p><p>y 的值是x+1 定义后会立即进行计算</p><pre><code class="highlight plaintext">scala&gt; lazy val z : Int = x+1z: Int = &lt;lazy&gt;</code></pre><p>z的初始化会被延迟<br>scala&gt; z<br>res0: Int = 11</p><p>当我们第一次使用z的时候，才会触发计算</p><p>读文件：<br>scala&gt; val words = scala.io.Source.fromFile(“E:\student.txt”).mkString<br>words: String =<br>1 Tom 12<br>2 Mary 13<br>3 Lily 15</p><p>scala&gt; lazy val words = scala.io.Source.fromFile(“E:\student.txt”).mkString<br>words: String = <code>&lt;lazy&gt;</code><br>scala&gt; words<br>res1: String =<br>1 Tom 12<br>2 Mary 13<br>3 Lily 15</p><p>scala&gt; lazy val words = scala.io.Source.fromFile(“E:\student121.txt”).mkString<br>words: String = <code>&lt;lazy&gt;</code></p><p>定义成lazy后，初始化被延迟，所以不会抛异常<br>scala&gt; val words = scala.io.Source.fromFile(“E:\student121.txt”).mkString<br>java.io.FileNotFoundException: E:\student121.txt (系统找不到指定的文件。)<br>at java.io.FileInputStream.open0(Native Method)<br>at java.io.FileInputStream.open(FileInputStream.java:195)<br>at java.io.FileInputStream.(FileInputStream.java:138)<br>at scala.io.Source.fromFile(Source.scala:76)<br>at scala.io.Source$.fromFile(Source.scala:54)<br>… 32 elided</p><h4 id="7、例外：Exception">7、例外：Exception</h4><p>类似于Java，还是有一些变化<br>文件操作</p><pre><code class="highlight plaintext">scala&gt; var words = scala.io.Source.fromFile("E:\\server.xml").mkStringwords: String ="&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--  Licensed to the Apache Software Foundation (ASF) under one or more  contributor license agreements.  See the NOTICE file distributed with  this work for additional information regarding copyright ownership....</code></pre><pre><code>scala&gt; val words = scala.io.Source.fromFile("E:\\212.txt").mkStringjava.io.FileNotFoundException: E:\\212.txt(系统找不到指定的文件。) at java.io.FileInputStream.open0(Native Method) at java.io.FileInputStream.open(FileInputStream.java:195) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138) at scala.io.Source$.fromFile(Source.scala:91) at scala.io.Source$.fromFile(Source.scala:76) at scala.io.Source$.fromFile(Source.scala:54) ... 32 elided</code></pre><p><strong>try catch finally练习</strong></p><pre><code class="highlight plaintext"> /**    * 1、采用 try catch finally 来捕获异常和处理异常    * 试验一下，scala中文件读取    *    */  try{    // try 代码块里面写 可能抛出异常的函数    println("------------try catch finally------------------")    var words = scala.io.Source.fromFile("E:\\server.xml").mkString    println(words)  }catch {    case ex: FileNotFoundException =&gt; {      println("File Not Found Exception")    }    case ex: IllegalArgumentException =&gt;{      println("Illegal Argument Exception")    }    case _:Exception =&gt;{      println("This is an Exception")    }  }finally {    println("This is finally")  }/** * 当没有抛出异常时： * try  ---&gt;  finally * 打印： * This is finally * * 当抛出异常时： * try  --&gt; catch --&gt; finally * File Not Found Exception * This is finally */ /**  * 2、如果一个函数返回值类型是nothing，表示：在函数执行的过程中，产生了异常  *  * scala&gt; def fun1() = throw new Exception("Exception")  *  fun1: ()Nothing  */</code></pre><h4 id="8、数组">8、数组</h4><p>1）数组的类型<br>（1）定长数组：Array</p><pre><code class="highlight plaintext">scala&gt; val a = new Array[Int](10)   -----&gt;  (10) 就是数组的长度a: Array[Int] = Array(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)scala&gt; val a = new Array[String](10)a: Array[String] = Array(null, null, null, null, null, null, null, null, null, null)</code></pre><p><strong>初始化赋给默认值</strong></p><pre><code class="highlight plaintext">scala&gt; val c : Array[String] = Array("Tom","Lily")c: Array[String] = Array(Tom, Lily)scala&gt; val c : Array[String] = Array("Tom","Lily",1)&lt;console&gt;:11: error: type mismatch; found   : Int(1) required: String       val c : Array[String] = Array("Tom","Lily",1)</code></pre><p>不能往数组中添加不同类型的元素</p><p>（2）变长数组：ArrayBuffer</p><pre><code class="highlight plaintext">scala&gt; val d = ArrayBuffer[Int]()&lt;console&gt;:11: error: not found: value ArrayBuffer       val d = ArrayBuffer[Int]()       ^</code></pre><p>scala&gt; import scala.collection.mutable._<br>import scala.collection.mutable._</p><p><strong>mutable（可变的）</strong></p><p>scala&gt; val d = ArrayBufferInt<br>d: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer()</p><p>scala&gt; d += 1<br>res2: d.type = ArrayBuffer(1)</p><p>scala&gt; d += 2<br>res3: d.type = ArrayBuffer(1, 2)</p><p>scala&gt; d += (1,2,3,4)<br>res4: d.type = ArrayBuffer(1, 2, 1, 2, 3, 4)</p><p>scala&gt; d.<br>++ combinations groupBy mapResult reverse to<br>++: companion grouped max reverseIterator toArray<br>++= compose hasDefiniteSize maxBy reverseMap toBuffer<br>++=: contains hashCode min runWith toIndexedSeq<br>+: containsSlice head minBy sameElements toIterable<br>+= copyToArray headOption mkString scan toIterator<br>+=: copyToBuffer indexOf nonEmpty scanLeft toList</p><ul><li>corresponds indexOfSlice orElse scanRight toMap<br>– count indexWhere padTo segmentLength toSeq<br>–= diff indices par seq toSet<br>-= distinct init partition size toStream<br>/: drop inits patch sizeHint toString<br>:+ dropRight insert permutations sizeHintBounded toTraversable<br>:\ dropWhile insertAll prefixLength slice toVector<br>&lt;&lt; endsWith intersect prepend sliding transform<br>WithFilter equals isDefinedAt prependAll sortBy transpose<br>addString exists isEmpty product sortWith trimEnd<br>aggregate filter isTraversableAgain readOnly sorted trimStart<br>andThen filterNot iterator reduce span union<br>append find last reduceLeft splitAt unzip<br>appendAll flatMap lastIndexOf reduceLeftOption startsWith unzip3<br>apply flatten lastIndexOfSlice reduceOption stringPrefix update<br>applyOrElse fold lastIndexWhere reduceRight sum updated<br>canEqual foldLeft lastOption reduceRightOption tail view<br>clear foldRight length reduceToSize tails withFilter<br>clone forall lengthCompare remove take zip<br>collect foreach lift repr takeRight zipAll<br>collectFirst genericBuilder map result takeWhile zipWithIndex</li></ul><p>举例：去掉数组中，最后两个元素</p><pre><code class="highlight plaintext">scala&gt; dres5: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(1, 2, 1, 2, 3, 4)scala&gt; d.trimEnd(2)scala&gt; dres7: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(1, 2, 1, 2)</code></pre><p><strong>遍历数组</strong><br>for循环、foreach：</p><pre><code class="highlight plaintext">scala&gt; var a = Array("Tom","Lily","Andy")a: Array[String] = Array(Tom, Lily, Andy)scala&gt; for(s &lt;- a ) println(s)TomLilyAndyscala&gt; a.foreach(println)TomLilyAndy</code></pre><p>数组的常见操作举例：</p><pre><code class="highlight plaintext">scala&gt; val myarray = Array(1,2,7,8,10,3,6)myarray: Array[Int] = Array(1, 2, 7, 8, 10, 3, 6)scala&gt; myarray.maxres10: Int = 10scala&gt; myarray.minres11: Int = 1scala&gt; myarray.sortWith(_&gt;_)res12: Array[Int] = Array(10, 8, 7, 6, 3, 2, 1)scala&gt; myarray.sortWith(_&lt;_)res13: Array[Int] = Array(1, 2, 3, 6, 7, 8, 10)</code></pre><p>解释：(<em>&gt;</em>)<br>完整 ： sortWith函数里面，参数也是一个函数  --&gt; 高阶函数</p><pre><code class="highlight plaintext">_&gt;_   函数def comp(a:Int,b:Int) = {if(a&gt;b) true else false}(a,b) =&gt; {if(a&gt;b) true else false}(a,b) =&gt; {if(a&gt;b) true else false}   ----&gt;  _&gt;_</code></pre><p><em>&gt;</em> 是一个函数，传入两个参数，返回值是Bool （布尔型）</p><p>2）多维数组<br>和Java类似，通过数组的数组来实现</p><pre><code class="highlight plaintext">scala&gt; var matrix = Array.ofDim[Int](3,4)matrix: Array[Array[Int]] = Array(Array(0, 0, 0, 0), Array(0, 0, 0, 0), Array(0, 0, 0, 0))    Array(0, 0, 0, 0)     Array(0, 0, 0, 0)    Array(0, 0, 0, 0)</code></pre><p>三行四列的数组</p><p>scala&gt; matrix(1)(2)=10</p><p>scala&gt; matrix<br>res15: Array[Array[Int]] = Array(Array(0, 0, 0, 0), Array(0, 0, 10, 0), Array(0, 0, 0, 0))</p><p>数组下标是从0开始的</p><p>例子：<br>定义一个二维数组，其中每个元素是一个一维数组，并且长度不固定</p><pre><code class="highlight plaintext">scala&gt; var triangle = new Array[Array[Int]](10)triangle: Array[Array[Int]] = Array(null, null, null, null, null, null, null, null, null, null)</code></pre><p>初始化：</p><pre><code class="highlight plaintext">scala&gt; for(i &lt;- 0 until triangle.length){     | triangle(i) = new Array[Int](i+1)     | }scala&gt; triangle res17: Array[Array[Int]] = Array(Array(0), Array(0, 0), Array(0, 0, 0), Array(0, 0, 0, 0), Array(0, 0, 0, 0, 0), Array(0, 0, 0, 0, 0, 0), Array(0, 0, 0, 0, 0, 0, 0), Array(0, 0, 0, 0, 0, 0, 0, 0), Array(0, 0, 0, 0, 0, 0, 0, 0, 0), Array(0, 0, 0, 0, 0, 0, 0, 0, 0, 0))</code></pre><p>二维数组，如果使用 ArrayArray[Int] 声明时：<br>1、首先指定的是外层数据的长度<br>2、初始化内层数组的时候，再指定内层数组的长度</p><h4 id="9、映射-key-value-Map">9、映射 &lt;key,value&gt; Map</h4><p>举例：<br>创建一个map，来保存学生的成绩</p><p>scala&gt; val scores = Map(“Tom” -&gt; 80,”Andy”-&gt;70,”Mike”-&gt;90)<br>scores: scala.collection.mutable.Map[String,Int] = Map(Mike -&gt; 90, Tom -&gt; 80, Andy -&gt; 70)</p><p>1）Map[String,Int] key String value Int<br>2）scala.collection.mutable</p><p>scala中，映射是有两种，一种是可变map，一种是不可变map<br>scala.collection.mutable —&gt; 可变<br>scala.collection.immutable —&gt; 不可变</p><pre><code class="highlight plaintext">scala&gt; val scores2 = scala.collection.immutable.Map(“Tom” -&gt; 80,”Andy”-&gt;70,”Mike”-&gt;90) scores2: scala.collection.immutable.Map[String,Int] = Map(Tom -&gt; 80, Andy -&gt; 70, Mike -&gt; 90)</code></pre><p><strong>映射的初始化</strong></p><pre><code class="highlight plaintext">scala&gt; val scores2 = scala.collection.mutable.Map((“Tom”,80),(“Andy”,70)) scores2: scala.collection.mutable.Map[String,Int] = Map(Tom -&gt; 80, Andy -&gt; 70)scala&gt; scores2=1&lt;console&gt;:15: error: reassignment to val       scores2=1</code></pre><p><strong>映射的操作</strong><br>1）获取映射中的值</p><pre><code class="highlight plaintext">scala&gt; val chinese = scala.collection.mutable.Map(("Tom",80),("Andy",70))chinese: scala.collection.mutable.Map[String,Int] = Map(Tom -&gt; 80, Andy -&gt; 70)scala&gt; chinese("Tom")res18: Int = 80scala&gt; chinese.get("Andy")res19: Option[Int] = Some(70)scala&gt; chinese("aaaa")java.util.NoSuchElementException: key not found: aaaa  at scala.collection.MapLike$class.default(MapLike.scala:228)  at scala.collection.AbstractMap.default(Map.scala:59)  at scala.collection.mutable.HashMap.apply(HashMap.scala:65)  ... 32 elidedscala&gt; chinese.get("Andy1231312")res21: Option[Int] = Nonechinese("aaaa") get("Andy1231312")需求：判断key是否存在，若不存在，返回默认值scala&gt; if(chinese.contains("aaa")){     | chinese("aaa")     | }else{     | -1     | }res22: Int = -1scala&gt; chinese.getOrElse("aaaa",-1)res23: Int = -1</code></pre><p>2）更新映射中的值<br>注意：必须是可变映射</p><pre><code class="highlight plaintext">scala&gt; chineseres24: scala.collection.mutable.Map[String,Int] = Map(Tom -&gt; 80, Andy -&gt; 70)scala&gt; chinese("Andy")=20scala&gt; chineseres26: scala.collection.mutable.Map[String,Int] = Map(Tom -&gt; 80, Andy -&gt; 20)</code></pre><p>3）映射的迭代<br>for foreach</p><pre><code class="highlight plaintext">scala&gt; chineseres27: scala.collection.mutable.Map[String,Int] = Map(Tom -&gt; 80, Andy -&gt; 20)scala&gt; for(s&lt;-chinese) println(s)(Tom,80)(Andy,20)scala&gt; chinese.foreach(println)(Tom,80)(Andy,20)</code></pre><p>foreach  高阶函数</p><h4 id="10、元组-Tuple">10、元组 : Tuple</h4><p>scala 中的tuple ： 是不同类型值的集合</p><pre><code class="highlight plaintext">scala&gt; val t1 = Tuple("Tom","Lily",1)&lt;console&gt;:14: error: not found: value Tuple       val t1 = Tuple("Tom","Lily",1)                ^</code></pre><p>-----Tuple需要指明不同类型值的个数</p><pre><code class="highlight plaintext">scala&gt; val t1 = Tuple3("Tom","Lily",1)t1: (String, String, Int) = (Tom,Lily,1)</code></pre><p>Tuple3 代表 Tuple中有三个元素</p><pre><code class="highlight plaintext">scala&gt; val t1 = Tuple2("Lily",1)t1: (String, Int) = (Lily,1)scala&gt; val t2 = (1,2,4,"Hello")t2: (Int, Int, Int, String) = (1,2,4,Hello)</code></pre><p><strong>tuple操作</strong></p><p>访问tuple中的元素</p><pre><code class="highlight plaintext">scala&gt; val t1 = Tuple3("Tom","Lily",1)t1: (String, String, Int) = (Tom,Lily,1)scala&gt; t1._1   _3         copy     hashCode   productArity     productIterator   toString   zipped_2   canEqual   equals   invert     productElement   productPrefix     xscala&gt; t1._1res30: String = Tomscala&gt; t1._3res31: Int = 1</code></pre><p>如何遍历Tuple中的元素<br>注意：Tuple并没有提供一个foreach函数，我们使用productIterator</p><p>遍历分为两步：<br>1、使用 productIterator 生成一个迭代器<br>2、遍历</p><pre><code class="highlight plaintext">scala&gt; t1.productIterator.!=                copyToBuffer   forall               min                reduceRightOption   toIterable##                corresponds    foreach              minBy              sameElements        toIterator+                 count          formatted            mkString           scanLeft            toList++                drop           getClass             ne                 scanRight           toMap-&gt;                dropWhile      grouped              next               seq                 toSeq/:                duplicate      hasDefiniteSize      nonEmpty           size                toSet:\                ensuring       hasNext              notify             slice               toStream==                eq             hashCode             notifyAll          sliding             toStringGroupedIterator   equals         indexOf              padTo              span                toTraversableaddString         exists         indexWhere           partition          sum                 toVectoraggregate         filter         isEmpty              patch              synchronized        waitasInstanceOf      filterNot      isInstanceOf         product            take                withFilterbuffered          find           isTraversableAgain   reduce             takeWhile           zipcollect           flatMap        length               reduceLeft         to                  zipAllcollectFirst      fold           map                  reduceLeftOption   toArray             zipWithIndexcontains          foldLeft       max                  reduceOption       toBuffer            →copyToArray       foldRight      maxBy                reduceRight        toIndexedSeqscala&gt; t1.productIterator.foreach(println)TomLily1</code></pre><h4 id="11、scala中的文件操作">11、scala中的文件操作</h4><p>类似于java的IO<br>举例：<br>1、读取文件<br>2、读取二进制文件<br>3、从url中获取信息<br>4、写入文件<br>5、Scala中调用Java的类库</p><p><strong>代码练习</strong></p><pre><code class="highlight plaintext">//读取文件中的行var source = fromFile("E:\\server.xml")/**  * 1、将整个文件作为字符串输出  *  * 2、将文件的每一行读入输出  */println("--------mkString------------------")//println(source.mkString)println("----------lines-------------------")//var lines = source.getLines()//lines.foreach(println)println("-----------读取字符----------------")//for (c &lt;- source) println(c)println("-----------读取字URL----------------")var source2 = fromURL("https://hsiehchou.com","UTF-8")println(source2.mkString)/**  * 注意:scala中并不支持直接读取二进制文件  *  * 通过调用java的InputStream来实现  */println("-----------读取二进制文件----------------")//var file = new File("E:\\hsiehchou.war")//构造一个inputstream//var in = new FileInputStream(file)//构造一个buffer// var buffer = new Array[Byte](file.length().toInt)//读取//in.read(buffer)//println(buffer.length)//关闭//in.close()/**  * 写文件  */println("---------Write File----------------")var out = new PrintWriter("E:\\insert.txt")for(i &lt;- 0 until 10)  out.println(i)out.close()</code></pre><h3 id="二、Scala面向对象">二、Scala面向对象</h3><p>Scala是一个多范式的编程语言（支持多种方式的编程）<br>类似于Java 有区别</p><h4 id="1、面向对象的概念">1、面向对象的概念</h4><p>1、封装 ： 把属性和操作属性的方法，写在了一起。class<br>2、继承<br>3、多态</p><p>Java中面向对象的概念，也是用与Scala</p><h4 id="2、定义类：class">2、定义类：class</h4><p>举例：创建一个学生类</p><pre><code class="highlight plaintext">package day3/**  * 学生  */class Student1 {  //定义学生的属性  private var stuId:Int =0  private var stuName:String = "Time"  private var age:Int = 20  //定义方法（函数）get set  def getStuName():String = stuName  def setStuName(newName:String) = this.stuName = newName  def getStuAge():Int = age  def setStuAge(age:Int) = this.age = age}/**  * 注意object 和 class名字可以不一样  *  * 如果一样的话，这个object就叫作class的伴生对象  */object Student1{  def main(args: Array[String]): Unit = {    //测试    //创建一个学生对象    var s1 = new Student1    //访问他的属性并输出    println(s1.getStuName()+"\t"+s1.getStuAge())    //访问set方法    s1.setStuName("Hsieh")    s1.setStuAge(23)    println(s1.getStuName()+"\t"+s1.getStuAge())    //直接访问私有属性    println("-------访问私有属性----------")    println(s1.stuId+"\t"+s1.stuName+"\t"+s1.age)    /**      * 为什么我们可以访问私有成员      *      * s1.stuId      *      * 属性的set get 方法      * 1、当一个属性是private属性的时候，scala会自动为其生成set get方法      *      * s1.stuId   .stuId调用了get方法  get 方法的名字就叫stuId      *      * 2、如果只希望生成get方法而不生成set方法，可以定义成常量      *      * 3、如果希望属性不能被外部访问，使用private[this]关键字      */  }}</code></pre><h4 id="3、内部类（嵌套类）">3、内部类（嵌套类）</h4><p>在一个类的内部，定义了另外一个类</p><pre><code class="highlight plaintext">package day3import scala.collection.mutable.ArrayBuffer/**  * 需求：定义一个学生类，同时要保存学生的成绩信息  */class Student2 {  //定义学生的属性  private var stuName : String = "Time"  private var stuAge : Int = 23  //定义一个数组，来保存学生的课程成绩信息  private var courseList = new ArrayBuffer[Course]()  //定义一个函数，用于添加学生课程成绩  def addNewCourse(cname:String, grade:Int): Unit = {    //创建课程成绩信息    var c = new Course(cname,grade)    //添加到学生    courseList += c  }  //定义课程类  class Course(var courseName:String, var grade : Int){  }}object Student2{  def main(args: Array[String]): Unit = {    //创建学生对象    var s = new Student2    //给学生添加课程信息    s.addNewCourse("Chinese",78)    s.addNewCourse("English",80)    s.addNewCourse("Math",90)    println(s.stuName+"\t"+s.stuAge)    println("-----------课程信息------------")    for(c&lt;-s.courseList) println(c.courseName+"\t"+c.grade)  }}</code></pre><h4 id="4、类的构造器：两种">4、类的构造器：两种</h4><p>1）主构造器 ： 和类的声明在一起，并且一个类只能有一个主构造器<br>class Course(var courseName:String,var grade : Int)</p><p>2）辅助构造器 ： 一个类可以有多个辅助构造器，通过this来实现</p><h4 id="5、Object对象">5、Object对象</h4><p>相当于Java中的static<br>1）Object 对象中的内容都是静态的<br>2）如果和类名相同，则成为伴生对象<br>3）Scala中没有static关键字<br>4）举例<br>（1）使用Object来实现单例模式：一个类里面只有一个对象<br>在Java中，把类的构造器定义成private的，并且提供一个getInstance,返回对象</p><p>在Scala中，使用Object实现</p><p><strong>例子</strong></p><pre><code class="highlight plaintext">package day3/**  * 实现单例模式  */object CreditCard {  //定义一个变量来保存信用卡卡号  private [this] var creditCardNumber : Long = 0  //定义一个函数产生卡号  def generateNum : Long = {    creditCardNumber += 1    creditCardNumber  }  def main(args: Array[String]): Unit = {    println(CreditCard.generateNum)    println(CreditCard.generateNum)    println(CreditCard.generateNum)    println(CreditCard.generateNum)  }}</code></pre><p>（2）使用App对象：应用程序对象<br>好处：可以省略main方法</p><p><strong>例子</strong></p><pre><code class="highlight plaintext">package day3object HelloWorld extends App{//  def main(args: Array[String]): Unit = {//    println("Hello World!")//  }  println("Hello World!")  if(args.length&gt;0){    println("有参数")  }else{    println("没有参数")  }}</code></pre><h4 id="6、apply方法">6、apply方法</h4><p>val t1 = Tuple3(“Tom”,”Lily”,1)<br>没有new关键字，但是也创建出来对象，用了apply方法</p><pre><code class="highlight plaintext">package day3class Student4(var stuName:String)/**  * 定义Student4的apply方法  */object Student4 {  def apply(name:String) = {    println("调用apply方法")    new Student4(name)  }  def main(args: Array[String]): Unit = {    //通过主构造器来创建学生对象    var s1 = new Student4("Time")    println(s1.stuName)    //通过apply方法来创建学生对象，省略new 关键字    var s2 = Student4("Hsiehchou")    println(s2.stuName)  }}</code></pre><p>注意：apply方法必须写在伴生对象中</p><h4 id="7、继承">7、继承</h4><p>1）extends 和java一样<br>object HelloWorld extends App</p><pre><code class="highlight plaintext">package day3/**  * extends 继承  *  * 父类：Person 人  * 子类：Employee员工  *///定义父类class Person(val name:String,val age:Int){  //定义函数  def sayHello():String = "Hello "+name+" and the age is "+age}//定义子类class Employee(override val name:String,override val age:Int,salary:Int) extends Person(name,age){  //重写父类中的函数  override def sayHello(): String = "子类中的sayHello"}object Demo1 extends App {  //创建Person  var p1 = new Person("Tim",23)  println(p1.name+"\t"+p1.age)  println(p1.sayHello())  //创建一个子类对象  var p2:Person = new Employee("Nike",35,1000)  println(p2.sayHello())  //匿名子类  var p3:Person = new Person("Jike",32){    //在匿名子类中重写sayHello方法    override def sayHello(): String = "匿名子类中的sayHello"  }  println(p3.sayHello())}</code></pre><p>2）抽象类</p><pre><code class="highlight plaintext">package day3/**  * 抽象类：只能用于继承的类，可以包含抽象方法  *///父类：交通工具类abstract class Vehicle {  //定义抽象方法，没有实现的方法  def checkType():String}//子类：自行车、汽车class Car extends Vehicle{  def checkType : String = "I am a car"}class Bike extends Vehicle{  def checkType : String = "I am a bike"}object Demo2{  def main(args: Array[String]): Unit = {    //多态    var v1 : Vehicle = new Car    println(v1.checkType())    var v2 : Vehicle = new Bike    println(v2.checkType())  }}</code></pre><p>3）抽象字段</p><pre><code class="highlight plaintext">package day3/**  * 抽象字段 抽象属性  *  * 定义：没有初始值的字段  */abstract class Person1{  //定义抽象字段  val id:Int  val name:String}//如果不加abstract 报错abstract class Employee1 extends Person1{}//下面两种方式均不会报错class Employee2() extends Person1{  val id:Int = 1  val name:String = "Time"}class Employee3(val id:Int,val name:String) extends Person1{}object Demo3 {}</code></pre><h4 id="8、特质（trait）">8、特质（trait）</h4><p>抽象类，支持多重继承<br>本质：scala 的一个抽象类<br>trait</p><pre><code class="highlight plaintext">package day4/**  * trait特质  *  * 定义两个父类，就是两个trait  *  * 父类：人、动作  *  * 子类：学生  */trait Human{  //抽象字段  val id:Int  val name:String}//动作trait Action{  //定义一个抽象函数  def getActionName():String}class Student1(val id:Int,val name:String) extends Human with Action{  override def getActionName(): String = "Action is running"  /**    * 实现多重继承的方式 extends Human with Action    */}object Demo1 {  def main(args: Array[String]): Unit = {    //创建一个学生对象    var s1 = new Student1(1,"Time")    println(s1.id+"\t"+s1.name)    println(s1.getActionName())  }}</code></pre><p>关键字：extends Human with Action<br>`</p><h4 id="9、包和包对象">9、包和包对象</h4><p>package<br>package object</p><p><strong>Scala中包的定义和使用</strong></p><p><strong>包的定义</strong></p><p>1）首先是Scala中的包可以像Java一样使用，例如：</p><pre><code class="highlight plaintext">package com.my.ioclass XXX</code></pre><p>2）可以像C#的namespace一样使用package语句，例如：</p><pre><code class="highlight plaintext">package com.my.io{    class XXX}</code></pre><p>3）package也是可以嵌套的，例如：</p><pre><code class="highlight plaintext">package com.my.io{    class XXX    package test{        class T    }}</code></pre><p><strong>包的引入</strong><br>Scala中依然使用import作为引用包的关键字，例如<br>import <a href="http://com.my.io.XXX">com.my.io.XXX</a> //可以不写XXX的全路径<br>import <a href="http://com.my.io">com.my.io</a>._ //引用import com.my.io下的所有类型<br>import <a href="http://com.my.io.XXX">com.my.io.XXX</a>._ //引用import com.my.io.XXX的所有成员</p><p>而且<strong>Scala中的import可以写在任意地方</strong></p><pre><code class="highlight plaintext">def method(fruit:Fruit){    import fruit._    println(name)}</code></pre><p><strong>包对象</strong><br>包可以包含类、对象和特质，但不能包含函数或者变量的定义。很不幸，这是Java虚拟机的局限</p><p>把工具函数或者常量添加到包而不是某个Utils对象，这是更加合理的做法。Scala中，包对象的出现正是为了解决这个局限</p><p>Scala中的包对象：常量，变量，方法，类，对象，trait（特质）</p><pre><code class="highlight plaintext">package class4/**  * Scala中的包对象：常量、变量、方法、类、对象、trait（特质）  *///定义一个包对象package object MyPackageObject{    //常量    val x:Int = 0    //变量    var y:String = "Hello World"    //方法    def sayHelloWorld():String = "Hello World"    //类    class MyTestClass{    }    //对象object    object MyTestObject{    }    //trait（特质）    trait MyTestTrait{    }}class Demo3{    //测试    def method1() = {        //导入需要的包对象        import class4.MyPackageObject._        //定义MyTestClass的一个对象        var a = new MyTestClass    }   }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch（二）</title>
      <link href="/2019/03/20/elasticsearch_er/"/>
      <url>/2019/03/20/elasticsearch_er/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Java-API操作">一、Java API操作</h3><p>Elasticsearch的Java客户端非常强大；它可以建立一个嵌入式实例并在必要时运行管理任务</p><p>运行一个Java应用程序和Elasticsearch时，有两种操作模式可供使用。该应用程序可在Elasticsearch集群中扮演更加主动或更加被动的角色。在更加主动的情况下（称为Node Client），应用程序实例将从集群接收请求，确定哪个节点应处理该请求，就像正常节点所做的一样。（应用程序甚至可以托管索引和处理请求。）另一种模式称为Transport Client，它将所有请求都转发到另一个Elasticsearch节点，由后者来确定最终目标</p><h4 id="1-API基本操作">1. API基本操作</h4><p><strong>1.1 操作环境准备</strong><br>1）创建maven工程<br>2）添加pom文件</p><pre><code class="highlight plaintext">&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.10&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;        &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;        &lt;version&gt;6.1.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;        &lt;artifactId&gt;transport&lt;/artifactId&gt;        &lt;version&gt;6.1.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;        &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;        &lt;version&gt;2.9.0&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>3）等待依赖的jar包下载完成<br>当直接在ElasticSearch 建立文档对象时，如果索引不存在的，默认会自动创建，映射采用默认方式</p><p><strong>1.2 获取Transport Client</strong><br>（1）ElasticSearch服务默认端口9300<br>（2）Web管理平台端口9200</p><pre><code class="highlight plaintext">private TransportClient client;@SuppressWarnings("unchecked")@Beforepublic void getClient() throws Exception {    // 1 设置连接的集群名称    Settings settings = Settings.builder().put("cluster.name", "my-application").build();    // 2 连接集群    client = new PreBuiltTransportClient(settings);    client.addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName("hsiehchou121"), 9300));    // 3 打印集群名称    System.out.println(client.toString());}</code></pre><p>（3）显示log4j2报错，在resource目录下创建一个文件命名为log4j2.xml并添加如下内容</p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration status="warn"&gt;    &lt;Appenders&gt;        &lt;Console name="Console" target="SYSTEM_OUT"&gt;            &lt;PatternLayout pattern="%m%n"/&gt;        &lt;/Console&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level="INFO"&gt;            &lt;AppenderRef ref="Console"/&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;</code></pre><p><strong>1.3 创建索引</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void createIndex_blog(){    // 1 创建索引    client.admin().indices().prepareCreate("blog2").get();    // 2 关闭连接    client.close();}</code></pre><p><strong>1.4 删除索引</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void deleteIndex(){    // 1 删除索引    client.admin().indices().prepareDelete("blog2").get();    // 2 关闭连接    client.close();}</code></pre><p><strong>1.5 新建文档（源数据json串）</strong><br>当直接在ElasticSearch建立文档对象时，如果索引不存在的，默认会自动创建，映射采用默认方式<br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void createIndexByJson() throws UnknownHostException {    // 1 文档数据准备    String json = "{" + "\"id\":\"1\"," + "\"title\":\"基于Lucene的搜索服务器\","            + "\"content\":\"它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口\"" + "}";    // 2 创建文档    IndexResponse indexResponse = client.prepareIndex("blog", "article", "1").setSource(json).execute().actionGet();    // 3 打印返回的结果    System.out.println("index:" + indexResponse.getIndex());    System.out.println("type:" + indexResponse.getType());    System.out.println("id:" + indexResponse.getId());    System.out.println("version:" + indexResponse.getVersion());    System.out.println("result:" + indexResponse.getResult());    // 4 关闭连接    client.close();}</code></pre><p><strong>1.6 新建文档（源数据map方式添加json）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Test public void createIndexByMap() {    // 1 文档数据准备    Map&lt;String, Object&gt; json = new HashMap&lt;String, Object&gt;();    json.put("id", "2");    json.put("title", "基于Lucene的搜索服务器");    json.put("content", "它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口");    // 2 创建文档    IndexResponse indexResponse = client.prepareIndex("blog", "article", "2").setSource(json).execute().actionGet();    // 3 打印返回的结果    System.out.println("index:" + indexResponse.getIndex());    System.out.println("type:" + indexResponse.getType());    System.out.println("id:" + indexResponse.getId());    System.out.println("version:" + indexResponse.getVersion());    System.out.println("result:" + indexResponse.getResult());    // 4 关闭连接    client.close();}</code></pre><p><strong>1.7 新建文档（源数据es构建器添加json）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void createIndex() throws Exception {    // 1 通过es自带的帮助类，构建json数据    XContentBuilder builder = XContentFactory.jsonBuilder().startObject().field("id", 3).field("title", "基于Lucene的搜索服务器").field("content", "它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。")            .endObject();    // 2 创建文档    IndexResponse indexResponse = client.prepareIndex("blog", "article", "3").setSource(builder).get();    // 3 打印返回的结果    System.out.println("index:" + indexResponse.getIndex());    System.out.println("type:" + indexResponse.getType());    System.out.println("id:" + indexResponse.getId());    System.out.println("version:" + indexResponse.getVersion());    System.out.println("result:" + indexResponse.getResult());    // 4 关闭连接    client.close();}</code></pre><p><strong>1.8 搜索文档数据（单个索引）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Test public void getData() throws Exception {    // 1 查询文档    GetResponse response = client.prepareGet("blog", "article", "1").get();    // 2 打印搜索的结果    System.out.println(response.getSourceAsString());    // 3 关闭连接    client.close();}</code></pre><p><strong>1.9 搜索文档数据（多个索引）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void getMultiData() {    // 1 查询多个文档    MultiGetResponse response = client.prepareMultiGet().add("blog", "article", "1").add("blog", "article", "2", "3").add("blog", "article", "2").get();    // 2 遍历返回的结果    for(MultiGetItemResponse itemResponse:response){        GetResponse getResponse = itemResponse.getResponse();        // 如果获取到查询结果        if (getResponse.isExists()) {            String sourceAsString = getResponse.getSourceAsString();            System.out.println(sourceAsString);        }    }    // 3 关闭资源    client.close();}</code></pre><p><strong>1.10 更新文档数据（update）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void updateData() throws Throwable {    // 1 创建更新数据的请求对象    UpdateRequest updateRequest = new UpdateRequest();    updateRequest.index("blog");    updateRequest.type("article");    updateRequest.id("3");    updateRequest.doc(XContentFactory.jsonBuilder().startObject()            // 对没有的字段添加, 对已有的字段替换            .field("title", "基于Lucene的搜索服务器")            .field("content","它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。大数据前景无限")            .field("createDate", "2017-8-22").endObject());    // 2 获取更新后的值    UpdateResponse indexResponse = client.update(updateRequest).get();    // 3 打印返回的结果    System.out.println("index:" + indexResponse.getIndex());    System.out.println("type:" + indexResponse.getType());    System.out.println("id:" + indexResponse.getId());    System.out.println("version:" + indexResponse.getVersion());    System.out.println("create:" + indexResponse.getResult());    // 4 关闭连接    client.close();}</code></pre><p><strong>1.11 更新文档数据（upsert）</strong><br>设置查询条件, 查找不到则添加IndexRequest内容，查找到则按照UpdateRequest更新</p><pre><code class="highlight plaintext">@Testpublic void testUpsert() throws Exception {    // 设置查询条件, 查找不到则添加    IndexRequest indexRequest = new IndexRequest("blog", "article", "5")            .source(XContentFactory.jsonBuilder().startObject().field("title", "搜索服务器").field("content","它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。").endObject());    // 设置更新, 查找到更新下面的设置    UpdateRequest upsert = new UpdateRequest("blog", "article", "5")            .doc(XContentFactory.jsonBuilder().startObject().field("user", "李四").endObject()).upsert(indexRequest);    client.update(upsert).get();    client.close();}</code></pre><p><strong>1.12 删除文档数据（prepareDelete）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void deleteData() {    // 1 删除文档数据    DeleteResponse indexResponse = client.prepareDelete("blog", "article", "5").get();    // 2 打印返回的结果    System.out.println("index:" + indexResponse.getIndex());    System.out.println("type:" + indexResponse.getType());    System.out.println("id:" + indexResponse.getId());    System.out.println("version:" + indexResponse.getVersion());    System.out.println("found:" + indexResponse.getResult());    // 3 关闭连接    client.close();}</code></pre><h4 id="2-条件查询QueryBuilder">2. 条件查询QueryBuilder</h4><p><strong>2.1 查询所有（matchAllQuery）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void matchAllQuery() {    // 1 执行查询    SearchResponse searchResponse = client.prepareSearch("blog").setTypes("article")            .setQuery(QueryBuilders.matchAllQuery()).get();    // 2 打印查询结果    SearchHits hits = searchResponse.getHits(); // 获取命中次数，查询结果有多少对象    System.out.println("查询结果有：" + hits.getTotalHits() + "条");    for (SearchHit hit : hits) {       System.out.println(hit.getSourceAsString());//打印出每条结果    }    // 3 关闭连接    client.close();}</code></pre><p><strong>2.2 对所有字段分词查询（queryStringQuery）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void query() {    // 1 条件查询    SearchResponse searchResponse = client.prepareSearch("blog").setTypes("article")            .setQuery(QueryBuilders.queryStringQuery("全文")).get();    // 2 打印查询结果    SearchHits hits = searchResponse.getHits(); // 获取命中次数，查询结果有多少对象    System.out.println("查询结果有：" + hits.getTotalHits() + "条");    for (SearchHit hit : hits) {       System.out.println(hit.getSourceAsString());//打印出每条结果    }    // 3 关闭连接    client.close();}</code></pre><p><strong>2.3 通配符查询（wildcardQuery）</strong></p><p>：表示多个字符（0个或多个字符）<br>？：表示单个字符<br>源代码</p><pre><code class="highlight plaintext">@Testpublic void wildcardQuery() {    // 1 通配符查询    SearchResponse searchResponse = client.prepareSearch("blog").setTypes("article")            .setQuery(QueryBuilders.wildcardQuery("content", "*全*")).get();    // 2 打印查询结果    SearchHits hits = searchResponse.getHits(); // 获取命中次数，查询结果有多少对象    System.out.println("查询结果有：" + hits.getTotalHits() + "条");    for (SearchHit hit : hits) {       System.out.println(hit.getSourceAsString());//打印出每条结果    }    // 3 关闭连接    client.close();}</code></pre><p><strong>2.4 词条查询（TermQuery）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void termQuery() {    // 1 第一field查询    SearchResponse searchResponse = client.prepareSearch("blog").setTypes("article")            .setQuery(QueryBuilders.termQuery("content", "全文")).get();    // 2 打印查询结果    SearchHits hits = searchResponse.getHits(); // 获取命中次数，查询结果有多少对象    System.out.println("查询结果有：" + hits.getTotalHits() + "条");    for (SearchHit hit : hits) {       System.out.println(hit.getSourceAsString());//打印出每条结果    }    // 3 关闭连接    client.close();}</code></pre><p><strong>2.5 模糊查询（fuzzy）</strong><br><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void fuzzy() {    // 1 模糊查询    SearchResponse searchResponse = client.prepareSearch("blog").setTypes("article")            .setQuery(QueryBuilders.fuzzyQuery("title", "lucene")).get();    // 2 打印查询结果    SearchHits hits = searchResponse.getHits(); // 获取命中次数，查询结果有多少对象    System.out.println("查询结果有：" + hits.getTotalHits() + "条");    Iterator&lt;SearchHit&gt; iterator = hits.iterator();    while (iterator.hasNext()) {        SearchHit searchHit = iterator.next(); // 每个查询对象        System.out.println(searchHit.getSourceAsString()); // 获取字符串格式打印    }    // 3 关闭连接    client.close();}</code></pre><h4 id="3-映射相关操作">3. 映射相关操作</h4><p><strong>源代码</strong></p><pre><code class="highlight plaintext">@Testpublic void createMapping() throws Exception {    // 1设置mapping    XContentBuilder builder = XContentFactory.jsonBuilder()            .startObject()                .startObject("article")                    .startObject("properties")                        .startObject("id1")                            .field("type", "string")                            .field("store", "yes")                        .endObject()                        .startObject("title2")                            .field("type", "string")                            .field("store", "no")                        .endObject()                        .startObject("content")                            .field("type", "string")                            .field("store", "yes")                        .endObject()                    .endObject()                .endObject()            .endObject();    // 2 添加mapping    PutMappingRequest mapping = Requests.putMappingRequest("blog4").type("article").source(builder);    client.admin().indices().putMapping(mapping).get();    // 3 关闭资源    client.close();}</code></pre><h3 id="二、IK分词器">二、IK分词器</h3><p>针对词条查询（TermQuery）,查看默认中文分词器的效果:<br>curl -XGET ‘<a href="http://hsiehchou:9200/_analyze?pretty&amp;analyzer=standard%E2%80%99">http://hsiehchou:9200/_analyze?pretty&amp;analyzer=standard’</a> -d ‘中华人民共和国’</p><pre><code class="highlight plaintext">{ “tokens” : [ { “token” : “中”, “start_offset” : 0, “end_offset” : 1, “type” : “”, “position” : 0 }, { “token” : “华”, “start_offset” : 1, “end_offset” : 2, “type” : “”, “position” : 1 }, { “token” : “人”, “start_offset” : 2, “end_offset” : 3, “type” : “”, “position” : 2 }, { “token” : “民”, “start_offset” : 3, “end_offset” : 4, “type” : “”, “position” : 3 }, { “token” : “共”, “start_offset” : 4, “end_offset” : 5, “type” : “”, “position” : 4 }, { “token” : “和”, “start_offset” : 5, “end_offset” : 6, “type” : “”, “position” : 5 }, { “token” : “国”, “start_offset” : 6, “end_offset” : 7, “type” : “”, “position” : 6 } ] }</code></pre><h4 id="1-IK分词器的安装">1. IK分词器的安装</h4><p><strong>1.1 前期准备工作</strong><br>1）CentOS联网<br>配置CentOS能连接外网。Linux虚拟机ping <a href="http://www.baidu.com">www.baidu.com</a> 是畅通的</p><p>2）jar包准备<br>（1）elasticsearch-analysis-ik-master.zip<br>(下载地址:<a href="https://github.com/medcl/elasticsearch-analysis-ik">https://github.com/medcl/elasticsearch-analysis-ik</a>)<br>（2）apache-maven-3.6.0-bin.tar.gz</p><p><strong>1.2 jar包安装</strong><br>1）Maven解压、配置 MAVEN_HOME和PATH。<br>tar -zxvf apache-maven-3.6.0-bin.tar.gz -C /opt/module/<br>sudo vi /etc/profile</p><p><code>#MAVEN_HOME</code><br>export MAVEN_HOME=/opt/module/apache-maven-3.6.0<br>export PATH=<code>$PATH:$MAVEN_HOME/bin</code><br>source /etc/profile<br>验证命令：mvn -version</p><p>2）Ik分词器解压、打包与配置<br><strong>ik分词器解压</strong><br>unzip elasticsearch-analysis-ik-master.zip -d ./<br>进入ik分词器所在目录</p><p>cd elasticsearch-analysis-ik-master<br>使用maven进行打包</p><p>mvn package -Pdist,native -DskipTests -Dtar<br>打包完成之后，会出现 target/releases/elasticsearch-analysis-ik-{version}.zip</p><p>pwd /opt/software/elasticsearch-analysis-ik-master/target/releases<br>对zip文件进行解压，并将解压完成之后的文件拷贝到es所在目录下的/plugins/</p><p>unzip elasticsearch-analysis-ik-6.0.0.zip<br>cp -r elasticsearch /opt/module/elasticsearch-5.6.1/plugins/</p><p>需要修改plugin-descriptor.properties文件，将其中的es版本号改为你所使用的版本号，即完成ik分词器的安装<br>vi plugin-descriptor.properties<br>修改为<br>elasticsearch.version=6.1.1<br>至此，安装完成，重启ES！</p><p>注意：需选择与es相同版本的ik分词器。<br>安装方法（2种）：<br>1.<br>./elasticsearch-plugin install <a href="https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.1.1/elasticsearch-analysis-ik-6.1.1.zip">https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.1.1/elasticsearch-analysis-ik-6.1.1.zip</a></p><ol start="2"><li></li></ol><p>cp elasticsearch-analysis-ik-6.1.1.zip ./elasticsearch-6.1.1/plugins/<br>unzip elasticsearch-analysis-ik-6.1.1.zip -d ik-analyzer<br>elasticsearch-plugin install -f file:///usr/local/elasticsearch-analysis-ik-6.1.1.zip</p><h4 id="2-IK分词器的使用">2. IK分词器的使用</h4><p><strong>2.1 命令行查看结果</strong><br><strong>ik_smart模式</strong><br>curl -XGET ‘<a href="http://hsiehchou121:9200/_analyze?pretty&amp;analyzer=ik_smart%E2%80%99">http://hsiehchou121:9200/_analyze?pretty&amp;analyzer=ik_smart’</a> -d ‘中华人民共和国’</p><p>curl -H “Content-Type:application/json” -XGET ‘<a href="http://192.168.116.121:9200/_analyze?pretty%E2%80%99">http://192.168.116.121:9200/_analyze?pretty’</a> -d ‘{“analyzer”:”ik_smasysctl -prt”,”text”:”中华人民共和国”}’</p><pre><code class="highlight plaintext">{ “tokens” : [ { “token” : “中华人民共和国”, “start_offset” : 0, “end_offset” : 7, “type” : “CN_WORD”, “position” : 0 } ] }</code></pre><p><strong>ik_max_word模式</strong><br>curl -XGET ‘<a href="http://hadoop121:9200/_analyze?pretty&amp;analyzer=ik_max_word%E2%80%99">http://hadoop121:9200/_analyze?pretty&amp;analyzer=ik_max_word’</a> -d ‘中华人民共和国’</p><p>curl -H “Content-Type:application/json” -XGET ‘<a href="http://192.168.116.124:9200/_analyze?pretty%E2%80%99">http://192.168.116.124:9200/_analyze?pretty’</a> -d ‘{“analyzer”:”ik_max_word”,”text”:”中华人民共和国”}’</p><pre><code class="highlight plaintext">{ “tokens” : [ { “token” : “中华人民共和国”, “start_offset” : 0, “end_offset” : 7, “type” : “CN_WORD”, “position” : 0 }, { “token” : “中华人民”, “start_offset” : 0, “end_offset” : 4, “type” : “CN_WORD”, “position” : 1 }, { “token” : “中华”, “start_offset” : 0, “end_offset” : 2, “type” : “CN_WORD”, “position” : 2 }, { “token” : “华人”, “start_offset” : 1, “end_offset” : 3, “type” : “CN_WORD”, “position” : 3 }, { “token” : “人民共和国”, “start_offset” : 2, “end_offset” : 7, “type” : “CN_WORD”, “position” : 4 }, { “token” : “人民”, “start_offset” : 2, “end_offset” : 4, “type” : “CN_WORD”, “position” : 5 }, { “token” : “共和国”, “start_offset” : 4, “end_offset” : 7, “type” : “CN_WORD”, “position” : 6 }, { “token” : “共和”, “start_offset” : 4, “end_offset” : 6, “type” : “CN_WORD”, “position” : 7 }, { “token” : “国”, “start_offset” : 6, “end_offset” : 7, “type” : “CN_CHAR”, “position” : 8 } ] }</code></pre><p><strong>2.2 JavaAPI操作</strong><br>1）创建索引<br>//创建索引(数据库)</p><pre><code class="highlight plaintext">@Testpublic void createIndex() {    //创建索引    client.admin().indices().prepareCreate("blog4").get();    //关闭资源    client.close();}</code></pre><p>2）创建mapping<br>//创建使用ik分词器的mapping</p><pre><code class="highlight plaintext">@Testpublic void createMapping() throws Exception {    // 1设置mapping    XContentBuilder builder = XContentFactory.jsonBuilder()            .startObject()                .startObject("article")                    .startObject("properties")                    .startObject("id1")                        .field("type", "string")                        .field("store", "yes")                        .field("analyzer","ik_smart")                    .endObject()                    .startObject("title2")                        .field("type", "string")                        .field("store", "no")                        .field("analyzer","ik_smart")                    .endObject()                    .startObject("content")                        .field("type", "string")                        .field("store", "yes")                        .field("analyzer","ik_smart")                    .endObject()                    .endObject()                .endObject()            .endObject();    // 2 添加mapping    PutMappingRequest mapping = Requests.putMappingRequest("blog4").type("article").source(builder);    client.admin().indices().putMapping(mapping).get();    // 3 关闭资源    client.close();}</code></pre><p>3）插入数据<br>//创建文档,以map形式</p><pre><code class="highlight plaintext">@Testpublic void createDocumentByMap() {    HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();    map.put("id1", "2");    map.put("title2", "Lucene");    map.put("content", "它提供了一个分布式的web接口");    IndexResponse response = client.prepareIndex("blog4", "article", "3").setSource(map).execute().actionGet();    //打印返回的结果    System.out.println("结果:" + response.getResult());    System.out.println("id:" + response.getId());    System.out.println("index:" + response.getIndex());    System.out.println("type:" + response.getType());    System.out.println("版本:" + response.getVersion());    //关闭资源    client.close();}</code></pre><p>4） 词条查询<br>//词条查询</p><pre><code class="highlight plaintext">@Testpublic void queryTerm() {    SearchResponse response = client.prepareSearch("blog4").setTypes("article").setQuery(QueryBuilders.termQuery("content","提供")).get();    //获取查询命中结果    SearchHits hits = response.getHits();    System.out.println("结果条数:" + hits.getTotalHits());    for (SearchHit hit : hits) {        System.out.println(hit.getSourceAsString());    }}</code></pre><p><strong>Store 的解释</strong><br>官方文档说 store 默认是 no ，想当然的理解为也就是说这个 field 是不会 store 的，但是查询的时候也能查询出来</p><p>经过查找资料了解到原来 store 的意思是，是否在 _source 之外在独立存储一份。这里要说一下 _source 这是源文档，当索引数据的时候， elasticsearch 会保存一份源文档到 _source 。如果文档的某一字段设置了 store 为 yes (默认为 no)，这时候会在 _source 存储之外再为这个字段独立进行存储，这么做的目的主要是针对内容比较多的字段</p><p>如果放到 _source 返回的话，因为_source 是把所有字段保存为一份文档，命中后读取只需要一次 IO，包含内容特别多的字段会很占带宽影响性能。通常我们也不需要完整的内容返回(可能只关心摘要)，这时候就没必要放到 _source 里一起返回了(当然也可以在查询时指定返回字段)</p><h3 id="三、Logstash">三、Logstash</h3><h4 id="1-Logstash简介">1. Logstash简介</h4><p>Logstash is a tool for managing events and logs. You can use it to collect logs, parse them, and store them for later use (like, for searching).</p><p>logstash是一个数据分析软件，主要目的是分析log日志。整一套软件可以当作一个MVC模型，logstash是controller层，Elasticsearch是一个model层，kibana是view层</p><p>首先将数据传给logstash，它将数据进行过滤和格式化（转成JSON格式），然后传给Elasticsearch进行存储、建搜索的索引，kibana提供前端的页面再进行搜索和图表可视化，它是调用Elasticsearch的接口返回的数据进行可视化。logstash和Elasticsearch是用Java写的，kibana使用node.js框架</p><p>这个软件官网有很详细的使用说明，<a href="https://www.elastic.co/%EF%BC%8C%E9%99%A4%E4%BA%86docs%E4%B9%8B%E5%A4%96%EF%BC%8C%E8%BF%98%E6%9C%89%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%E3%80%82%E8%BF%99%E7%AF%87%E5%8D%9A%E5%AE%A2%E9%9B%86%E5%90%88%E4%BA%86docs%E5%92%8C%E8%A7%86%E9%A2%91%E9%87%8C%E9%9D%A2%E4%B8%80%E4%BA%9B%E6%AF%94%E8%BE%83%E9%87%8D%E8%A6%81%E7%9A%84%E8%AE%BE%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8">https://www.elastic.co/，除了docs之外，还有视频教程。这篇博客集合了docs和视频里面一些比较重要的设置和使用</a></p><h4 id="2-Logstash-安装">2. Logstash 安装</h4><p>直接下载官方发布的二进制包的，可以访问 <a href="https://www.elastic.co/downloads/logstash">https://www.elastic.co/downloads/logstash</a> 页面找对应操作系统和版本，点击下载即可</p><p>在终端中，像下面这样运行命令来启动 Logstash 进程：<br>输入（读取数据）：file、es。 输出：file、es、kafka</p><p>bin/logstash -e ‘input{stdin{}}output{stdout{codec=&gt;rubydebug}}’<br>-f文件 -e命令 标准输入、输出（命令行）</p><p>注意：如果出现如下报错，请调高虚拟机内存容量<br>Java HotSpot™ 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c5330000, 986513408, 0) failed; error=’Cannot allocate memory’ (errno=12)</p><p>然后你会发现终端在等待你的输入。没问题，敲入 Hello World，回车，</p><pre><code class="highlight plaintext">{ “@version” =&gt; “1”, “host” =&gt; “*“, “message” =&gt; “hello world”, “@timestamp” =&gt; 2019-03-18T02:51:18.578Z }</code></pre><p>每位系统管理员都肯定写过很多类似这样的命令<br>cat randdata | awk ‘{print $2}’ | sort | uniq -c | tee sortdata</p><p>Logstash 就像管道符一样！<br>你输入(就像命令行的 cat )数据，然后处理过滤(就像 awk 或者 uniq 之类)数据，最后输出(就像 tee )到其他地方</p><h4 id="3-Logstash-配置">3. Logstash 配置</h4><p><strong>3.1 input配置</strong><br>读取文件(File)</p><pre><code class="highlight plaintext">input {    file {        path =&gt; ["/var/log/*.log", "/var/log/message"]        type =&gt; "system"        start_position =&gt; "beginning"    }}output{stdout{codec=&gt;rubydebug}}</code></pre><p>有一些比较有用的配置项，可以用来指定 FileWatch 库的行为</p><p><strong>discover_interval</strong><br>logstash 每隔多久去检查一次被监听的 path 下是否有新文件。默认值是 15 秒</p><p><strong>exclude</strong><br>不想被监听的文件可以排除出去，这里跟 path 一样支持 glob 展开</p><p><strong>close_older</strong><br>一个已经监听中的文件，如果超过这个值的时间内没有更新内容，就关闭监听它的文件句柄。默认是 3600 秒，即一小时</p><p><strong>ignore_older</strong><br>在每次检查文件列表的时候，如果一个文件的最后修改时间超过这个值，就忽略这个文件。默认是 86400 秒，即一天</p><p><strong>sincedb_path</strong><br>如果你不想用默认的 $HOME/.sincedb(Windows 平台上在 C:\Windows\System32\config\systemprofile.sincedb)，可以通过这个配置定义 sincedb 文件到其他位置</p><p><strong>sincedb_write_interval</strong><br>logstash 每隔多久写一次 sincedb 文件，默认是 15 秒</p><p><strong>stat_interval</strong><br>logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒</p><p><strong>start_position</strong><br>logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行。如果你是要导入原有数据，把这个设定改成 “beginning”，logstash 进程就从头开始读取，类似 less +F 的形式运行</p><p><strong>启动命令</strong>：…/bin/logstash -f ./input_file.conf<br><strong>测试命令</strong>：echo ‘hehe’ &gt;&gt; test.log<br>echo ‘hehe2’ &gt;&gt; message</p><p><strong>标准输入(Stdin)</strong><br>我们已经见过好几个示例使用 stdin 了。这也应该是 logstash 里最简单和基础的插件了</p><pre><code class="highlight plaintext">input {    stdin {        add_field =&gt; {"key" =&gt; "value"}        codec =&gt; "plain"        tags =&gt; ["add"]        type =&gt; "std"    }}output{stdout{codec=&gt;rubydebug}}</code></pre><p>用上面的新 stdin 设置重新运行一次最开始的 hello world 示例。我建议大家把整段配置都写入一个文本文件，然后运行命令：…/bin/logstash -f ./input_stdin.conf。输入 “hello world” 并回车后，你会在终端看到如下输出</p><pre><code class="highlight plaintext">{       "message" =&gt; "hello world",      "@version" =&gt; "1",    "@timestamp" =&gt; "2014-08-08T06:48:47.789Z",          "type" =&gt; "std",          "tags" =&gt; [        [0] "add"    ],           "key" =&gt; "value",          "host" =&gt; "raochenlindeMacBook-Air.local"}</code></pre><p><strong>解释</strong><br>type 和 tags 是 logstash 事件中两个特殊的字段。通常来说我们会在输入区段中通过 type 来标记事件类型。而 tags 则是在数据处理过程中，由具体的插件来添加或者删除的</p><p>最常见的用法是像下面这样</p><pre><code class="highlight plaintext">input {    stdin {        type =&gt; "web"    }}filter {    if [type] == "web" {        grok {            match =&gt; ["message", %{COMBINEDAPACHELOG}]        }    }}output {    if "_grokparsefailure" in [tags] {        nagios_nsca {            nagios_status =&gt; "1"        }    } else {        elasticsearch {        }    }}</code></pre><p><strong>3.2 codec配置</strong><br>Codec 是 logstash 从 1.3.0 版开始新引入的概念(Codec 来自 Coder/decoder 两个单词的首字母缩写)</p><p>在此之前，logstash 只支持纯文本形式输入，然后以过滤器处理它。但现在，我们可以在输入期处理不同类型的数据，这全是因为有了 codec 设置</p><p>所以，这里需要纠正之前的一个概念。Logstash 不只是一个input | filter | output 的数据流，而是一个 input | decode | filter | encode | output 的数据流！codec 就是用来 decode、encode 事件的</p><p>codec 的引入，使得 logstash 可以更好更方便的与其他有自定义数据格式的运维产品共存，比如 graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等</p><p>事实上，我们在第一个 “hello world” 用例中就已经用过 codec 了 —— rubydebug 就是一种 codec！虽然它一般只会用在 stdout 插件中，作为配置测试或者调试的工具</p><p><strong>采用 JSON 编码</strong><br>在早期的版本中，有一种降低 logstash 过滤器的 CPU 负载消耗的做法盛行于社区(在当时的 cookbook 上有专门的一节介绍)：直接输入预定义好的 JSON 数据，这样就可以省略掉 filter/grok 配置！</p><p>这个建议依然有效，不过在当前版本中需要稍微做一点配置变动 —— 因为现在有专门的 codec 设置</p><p><strong>配置示例</strong></p><pre><code class="highlight plaintext">input {    stdin {        add_field =&gt; {"key" =&gt; "value"}        codec =&gt; "json"        type =&gt; "std"    }}output{stdout{codec=&gt;rubydebug}}</code></pre><p>输入：<br>{“simCar”:18074045598,”validityPeriod”:”1996-12-06”,”unitPrice”:9,”quantity”:19,”amount”:35,”imei”:887540376467915,”user”:”test”}</p><p>运行结果：<br>{<br>“imei” =&gt; 887540376467915,<br>“unitPrice” =&gt; 9,<br>“user” =&gt; “test”,<br>“@timestamp” =&gt; 2019-03-19T05:01:53.451Z,<br>“simCar” =&gt; 18074045598,<br>“host” =&gt; “zzc-203”,<br>“amount” =&gt; 35,<br>“@version” =&gt; “1”,<br>“key” =&gt; “value”,<br>“type” =&gt; “std”,<br>“validityPeriod” =&gt; “1996-12-06”,<br>“quantity” =&gt; 19<br>}</p><p><strong>3.3 filter配置</strong><br><strong>Grok插件</strong></p><p>logstash拥有丰富的filter插件,它们扩展了进入过滤器的原始数据，进行复杂的逻辑处理，甚至可以无中生有的添加新的 logstash 事件到后续的流程中去！Grok 是 Logstash 最重要的插件之一。也是迄今为止使蹩脚的、无结构的日志结构化和可查询的最好方式。Grok在解析 syslog logs、apache and other webserver logs、mysql logs等任意格式的文件上表现完美</p><p>这个工具非常适用于系统日志，Apache和其他网络服务器日志，MySQL日志等</p><p><strong>配置</strong></p><pre><code class="highlight plaintext">input {    stdin {        type =&gt; "std"    }}filter {  grok {    match=&gt;{"message"=&gt; "%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}" }  }}output{stdout{codec=&gt;rubydebug}}</code></pre><p>输入：55.3.244.1 GET /index.html 15824 0.043<br>输出：<br>{<br>“@version” =&gt; “1”,<br>“host” =&gt; “zzc-203”,<br>“request” =&gt; “/index.html”,<br>“bytes” =&gt; “15824”,<br>“duration” =&gt; “0.043”,<br>“method” =&gt; “GET”,<br>“@timestamp” =&gt; 2019-03-19T05:09:55.777Z,<br>“message” =&gt; “55.3.244.1 GET /index.html 15824 0.043”,<br>“type” =&gt; “std”,<br>“client” =&gt; “55.3.244.1”<br>}</p><p>grok模式的语法如下：<br>%{SYNTAX:SEMANTIC}</p><p>SYNTAX：代表匹配值的类型,例如3.44可以用NUMBER类型所匹配,127.0.0.1可以使用IP类型匹配。<br>SEMANTIC：代表存储该值的一个变量名称,例如 3.44 可能是一个事件的持续时间,127.0.0.1可能是请求的client地址。所以这两个值可以用 %{NUMBER:duration} %{IP:client} 来匹配</p><p>你也可以选择将数据类型转换添加到Grok模式。默认情况下，所有语义都保存为字符串。如果您希望转换语义的数据类型，例如将字符串更改为整数，则将其后缀为目标数据类型。例如%{NUMBER:num:int}将num语义从一个字符串转换为一个整数。目前唯一支持的转换是int和float</p><p>Logstash附带约120个模式。你可以在这里找到它们<a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns">https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns</a></p><p><strong>自定义类型</strong><br>更多时候logstash grok没办法提供你所需要的匹配类型，这个时候我们可以使用自定义</p><p>创建自定义 patterns 文件<br>①创建一个名为patterns其中创建一个文件postfix （文件名无关紧要,随便起）,在该文件中，将需要的模式写为模式名称，空格，然后是该模式的正则表达式。例如：</p><p>POSTFIX_QUEUEID [0-9A-F]{10,11}</p><p>②然后使用这个插件中的patterns_dir设置告诉logstash目录是你的自定义模式。</p><p><strong>配置</strong></p><pre><code class="highlight plaintext">input {    stdin {        type =&gt; "std"    }}filter {  grok {    patterns_dir =&gt; ["./patterns"]    match =&gt; { "message" =&gt; "%{SYSLOGBASE} %{POSTFIX_QUEUEID:queue_id}: %{GREEDYDATA:syslog_message}" }  }}output{stdout{codec=&gt;rubydebug}}</code></pre><p>输入：<br>Jan 1 06:25:43 mailserver14 postfix/cleanup[21403]: BEF25A72965: message-id=&lt;20130101142543.5828399CCAF@mailserver1</p><p>输出：<br>{<br>“queue_id” =&gt; “BEF25A72965”,<br>“message” =&gt; “Jan 1 06:25:43 mailserver14 postfix/cleanup[21403]: BEF25A72965: message-id=&lt;20130101142543.5828399CCAF@mailserver1”,<br>“pid” =&gt; “21403”,<br>“program” =&gt; “postfix/cleanup”,<br>“@version” =&gt; “1”,<br>“type” =&gt; “std”,<br>“logsource” =&gt; “mailserver14”,<br>“host” =&gt; “zzc-203”,<br>“timestamp” =&gt; “Jan 1 06:25:43”,<br>“syslog_message” =&gt; “message-id=&lt;20130101142543.5828399CCAF@mailserver1”,<br>“@timestamp” =&gt; 2019-03-19T05:31:37.405Z<br>}</p><p><strong>GeoIP 地址查询归类</strong><br>GeoIP 是最常见的免费 IP 地址归类查询库，同时也有收费版可以采购。GeoIP 库可以根据 IP 地址提供对应的地域信息，包括国别，省市，经纬度等，对于可视化地图和区域统计非常有用。</p><p><strong>配置</strong></p><pre><code class="highlight plaintext">input {    stdin {        type =&gt; "std"    }}filter {    geoip {        source =&gt; "message"    }}output{stdout{codec=&gt;rubydebug}}</code></pre><p>输入：183.60.92.253<br>输出：<br>{<br>“type” =&gt; “std”,<br>“@version” =&gt; “1”,<br>“@timestamp” =&gt; 2019-03-19T05:39:26.714Z,<br>“host” =&gt; “zzc-203”,<br>“message” =&gt; “183.60.92.253”,<br>“geoip” =&gt; {<br>“country_code3” =&gt; “CN”,<br>“latitude” =&gt; 23.1167,<br>“region_code” =&gt; “44”,<br>“region_name” =&gt; “Guangdong”,<br>“location” =&gt; {<br>“lon” =&gt; 113.25,<br>“lat” =&gt; 23.1167<br>},<br>“city_name” =&gt; “Guangzhou”,<br>“country_name” =&gt; “China”,<br>“continent_code” =&gt; “AS”,<br>“country_code2” =&gt; “CN”,<br>“timezone” =&gt; “Asia/Shanghai”,<br>“ip” =&gt; “183.60.92.253”,<br>“longitude” =&gt; 113.25<br>}<br>}</p><p><strong>3.4 output配置</strong><br>标准输出(Stdout)</p><p>保存成文件(File)<br>通过日志收集系统将分散在数百台服务器上的数据集中存储在某中心服务器上，这是运维最原始的需求。Logstash 当然也能做到这点</p><p>和 LogStash::Inputs::File 不同, LogStash::Outputs::File 里可以使用 sprintf format 格式来自动定义输出到带日期命名的路径</p><p><strong>配置</strong></p><pre><code class="highlight plaintext">input {    stdin {        type =&gt; "std"    }}output {    file {        path =&gt; "../data_test/%{+yyyy}/%{+MM}/%{+dd}/%{host}.log"        codec =&gt; line { format =&gt; "custom format: %{message}"}    }}</code></pre><p>启动后输入，可看到文件</p><p>服务器间传输文件(File)</p><p><strong>配置</strong><br>接收日志服务器配置</p><pre><code class="highlight plaintext">input {  tcp {    mode =&gt; "server"    port =&gt; 9600    ssl_enable =&gt; false  }}filter {    json {        source =&gt; "message"    }}output {    file {        path =&gt; "/usr/local/logstash-6.6.2/data_test/%{+YYYY-MM-dd}/%{servip}-%{filename}"        codec =&gt; line { format =&gt; "%{message}"}    }}</code></pre><p>发送日志服务器配置</p><pre><code class="highlight plaintext">input{    file {        path =&gt; ["/usr/local/logstash-6.6.2/data_test/send.log"]        type =&gt; "ecolog"        start_position =&gt; "beginning"    }}filter {    if [type] =~ /^ecolog/ {        ruby {            code =&gt; "file_name = event.get('path').split('/')[-1]                     event.set('file_name',file_name)                     event.set('servip','接收方ip')"        }        mutate {            rename =&gt; {"file_name" =&gt; "filename"}        }    }}output {    tcp {        host  =&gt; "接收方ip"        port  =&gt; 9600        codec =&gt; json_lines    }}</code></pre><p>从发送方发送message，接收方可以看到写出文件</p><p>写入到ES<br><strong>配置</strong></p><pre><code class="highlight plaintext">input {    stdin {        type =&gt; "log2es"    }}output {    elasticsearch {        hosts =&gt; ["192.168.109.133:9200"]        index =&gt; "logstash-%{type}-%{+YYYY.MM.dd}"        document_type =&gt; "%{type}"        sniffing =&gt; true        template_overwrite =&gt; true    }}</code></pre><p>在head插件中可以看到数据<br>sniffing ： 寻找其他es节点</p><p><strong>实战举例</strong>：将错误日志写入es<br><strong>配置</strong></p><pre><code class="highlight plaintext">input {    file {        path =&gt; ["/usr/local/logstash-6.6.2/data_test/run_error.log"]        type =&gt; "error"        start_position =&gt; "beginning"}}output {    elasticsearch {        hosts =&gt; ["192.168.109.133:9200"]        index =&gt; "logstash-%{type}-%{+YYYY.MM.dd}"        document_type =&gt; "%{type}"        sniffing =&gt; true        template_overwrite =&gt; true    }}</code></pre><h3 id="四、Kibana">四、Kibana</h3><p>Kibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作</p><p>你用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互</p><p>你可以轻松地执行高级数据分析，并且以各种图标、表格和地图的形式可视化数据</p><p>Kibana使得理解大量数据变得很容易。它简单的、基于浏览器的界面使你能够快速创建和共享动态仪表板，实时显示Elasticsearch查询的变化</p><p><strong>安装步骤</strong><br>解压：tar -zxvf kibana-6.6.2-linux-x86_64.tar.gz<br>修改 kibana.yml 配置文件：</p><pre><code class="highlight plaintext">server.port: 5601 server.host: “192.168.116.121” ———-部署kinana服务器的ip elasticsearch.hosts: [“http://192.168.116.121:9200“] kibana.index: “.kibana”</code></pre><p>启动kibana，报错：<br>./bin/kibana<br><code>[error][status]</code>[plugin:remote_clusters@6.6.2] Status changed from red to red - X-Pack plugin is not installed on the [data] Elasticsearch cluster.</p><p>解决，卸载x-pack插件<br>elasticsearch-plugin remove x-pack<br>kibana-plugin remove x-pack</p><p>安装好后启动即可。页面操作</p><p>访问页面<br><a href="http://192.168.116.121:5601/">http://192.168.116.121:5601/</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch（一）</title>
      <link href="/2019/03/18/elasticsearch_yi/"/>
      <url>/2019/03/18/elasticsearch_yi/</url>
      
        <content type="html"><![CDATA[<h3 id="1-全文检索技术简介">1. 全文检索技术简介</h3><h4 id="什么是搜索？">什么是搜索？</h4><p>搜索，就是在任何场景下，找寻你想要的信息，这个时候，会输入一段你要搜索的关键字，然后就期望找到这个关键字相关的有些信息</p><h4 id="如何实现搜索？">如何实现搜索？</h4><p>OA系统，比如：通过名字搜索员工等等<br>mysql :<br>select * from employee e where <a href="http://e.name">e.name</a> like “%李雷%”;<br>select * from employee e where e.comment like “%好%”;<br>问题：<br>1）性能<br>2）比如搜索“优秀工”，mysql 无法支持</p><h4 id="全文检索">全文检索</h4><p>全文数据库是全文检索系统的主要构成部分。所谓全文数据库是将一个完整的信息源的全部内容转化为计算机可以识别、处理的信息单元而形成的数据集合</p><p>全文数据库不仅存储了信息，而且还有对全文数据进行词、字、段落等更深层次的编辑、加工的功能</p><p>所有全文数据库无一不是海量信息数据库</p><h4 id="倒排索引">倒排索引</h4><p>传统数据库存储：</p><table><thead><tr><th style="text-align:center">id</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">优秀员工</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">销售冠军</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">优秀团队领导</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">优秀项目</td></tr></tbody></table><p>倒排索引处理步骤：<br>1、切词：<br>优秀员工 —— 优秀 员工<br>销售冠军 —— 销售 冠军<br>优秀团队领导 —— 优秀 团队 领导<br>优秀项目 —— 优秀 项目</p><p>2、建立倒排索引：<br>关键词 id</p><table><thead><tr><th style="text-align:center">关键词</th><th style="text-align:center">id</th></tr></thead><tbody><tr><td style="text-align:center">优秀</td><td style="text-align:center">1,3,4</td></tr><tr><td style="text-align:center">员工</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">销售</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">团队</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">。。。</td><td style="text-align:center">。。。</td></tr></tbody></table><h4 id="Lucene">Lucene</h4><p><strong>全文检索引擎</strong><br>Lucene 能够为文本类型的数据建立索引，所以你只要能把你要索引的数据格式转化的文本的，Lucene 就能对你的文档进行索引和搜索。比如你要对一些 HTML 文档，PDF 文档进行索引的话你就首先需要把 HTML 文档和 PDF 文档转化成文本格式的，然后将转化后的内容交给 Lucene 进行索引，然后把创建好的索引文件保存到磁盘或者内存中，最后根据用户输入的查询条件在索引文件上进行查询。不指定要索引的文档的格式也使 Lucene 能够几乎适用于所有的搜索应用程序</p><p>换句话说，使用 Lucene 可以轻松完成上述步骤</p><h4 id="Elasticsearch">Elasticsearch</h4><p>Elasticsearch 是一个高度可伸缩的开源全文搜索和分析引擎。它允许你以近实时的方式快速存储、搜索和分析大量的数据。它通常被用作基础的技术来赋予应用程序复杂的搜索特性和需求</p><p>Elasticsearch ，是基于 lucene 开发的，隐藏复杂性，提供简单易用的 restful api 接口、java api 接口（还有其他语言的 api 接口）</p><h4 id="Elasticsearch-特点">Elasticsearch 特点</h4><p>可以作为一个大型分布式集群（数百台服务器）技术，处理 PB 级数据，服务大公司；也可以运行在单机上，服务小公司</p><p>Elasticsearch 不是什么新技术，主要是将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的 ES</p><p>对用户而言，是开箱即用的，非常简单，作为中小型的应用，直接3分钟部署一下 ES ，就可以作为生产环境的系统来使用了，数据量不大，操作不是太复杂</p><p>数据库的功能面对很多领域是不够用的（事务，还有各种联机事务型的操作）；特殊的功能，比如全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时处理； Elasticsearch 作为传统数据库的一个补充，提供了数据库所不能提供的很多功能</p><h4 id="Elasticsearch核心概念">Elasticsearch核心概念</h4><p><strong>近实时</strong><br>近实时，两个意思，从写入数据到数据可以被搜索到有一个小延迟（大概1秒）；基于es执行搜索和分析可以达到秒级</p><p><strong>Cluster（集群）</strong><br>集群包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常</p><p><strong>Node（节点）</strong><br>集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群</p><p><strong>Index（索引-数据库）</strong><br>索引包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document</p><p><strong>Type（类型-表）</strong><br>每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type</p><p>商品index，里面存放了所有的商品数据，商品document<br>但是商品分很多种类，每个种类的document的field可能不太一样，比如说电器商品，可能还包含一些诸如售后时间范围这样的特殊field；生鲜商品，还包含一些诸如生鲜保质期之类的特殊field</p><p>type，日化商品type，电器商品type，生鲜商品type<br>日化商品type：product_id，product_name，product_desc，category_id，category_name</p><p>电器商品type：product_id，product_name，product_desc，category_id，category_name，service_period</p><p>生鲜商品type：product_id，product_name，product_desc，category_id，category_name，eat_period</p><p>每一个type里面，都会包含一堆document</p><pre><code class="highlight plaintext">{  "product_id": "1",  "product_name": "长虹电视机",  "product_desc": "4k高清",  "category_id": "3",  "category_name": "电器",  "service_period": "1年"}{  "product_id": "2",  "product_name": "基围虾",  "product_desc": "纯天然，冰岛产",  "category_id": "4",  "category_name": "生鲜",  "eat_period": "7天"}</code></pre><p><strong>Document（文档-行）</strong><br>文档是es中的最小数据单元，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document</p><p><strong>Field（字段-列）</strong><br>Field是Elasticsearch的最小单位。一个document里面有多个field，每个field就是一个数据字段</p><pre><code class="highlight plaintext">product document{  "product_id": "1",  "product_name": "高露洁牙膏",  "product_desc": "高效美白",  "category_id": "2",  "category_name": "日化用品"}</code></pre><p><strong>mapping（映射-约束）</strong><br>数据如何存放到索引对象上，需要有一个映射配置，包括：数据类型、是否存储、是否分词等</p><p>这样就创建了一个名为blog的Index。Type不用单独创建，在创建Mapping 时指定就可以。Mapping用来定义Document中每个字段的类型，即所使用的 analyzer、是否索引等属性，非常关键等。创建Mapping 的代码示例如下：</p><pre><code class="highlight plaintext">client.indices.putMapping({    index : 'blog',    type : 'article',    body : {        article: {            properties: {                id: {                    type: 'string',                    analyzer: 'ik',                    store: 'yes',                },                title: {                    type: 'string',                    analyzer: 'ik',                    store: 'no',                },                content: {                    type: 'string',                     analyzer: 'ik',                    store: 'yes',                }            }        }    }});</code></pre><h4 id="elasticsearch与数据库的类比">elasticsearch与数据库的类比</h4><table><thead><tr><th style="text-align:center">关系型数据库（比如Mysql）</th><th style="text-align:center">非关系型数据库（Elasticsearch）</th></tr></thead><tbody><tr><td style="text-align:center">数据库Database</td><td style="text-align:center">索引Index</td></tr><tr><td style="text-align:center">表Table</td><td style="text-align:center">类型Type</td></tr><tr><td style="text-align:center">数据行Row</td><td style="text-align:center">文档Document</td></tr><tr><td style="text-align:center">数据列Column</td><td style="text-align:center">字段Field</td></tr><tr><td style="text-align:center">约束 Schema</td><td style="text-align:center">映射Mapping</td></tr></tbody></table><h4 id="ES存入数据和搜索数据机制">ES存入数据和搜索数据机制</h4><p>1）索引对象（index）：存储数据的表结构 ，任何搜索数据，存放在索引对象上</p><p>2）映射（mapping）：数据如何存放到索引对象上，需要有一个映射配置， 包括：数据类型、是否存储、是否分词等</p><p>3）文档（document）：一条数据记录，存在索引对象上</p><p>4）文档类型（type）：一个索引对象，存放多种类型数据，数据用文档类型进行标识</p><h3 id="2-安装">2. 安装</h3><h4 id="单节点安装教程">单节点安装教程</h4><p>java8<br>1）下载es安装包<br>curl -L -O <a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.1.tar.gz">https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.1.tar.gz</a></p><p>2）浏览器下载上传到虚拟机安装并创建和修改文件</p><p>解压elasticsearch-6.1.1.tar.gz到/opt/module目录下</p><p>在/opt/module/elasticsearch-6.1.1路径下创建data和logs文件夹<br>mkdir data<br>mkdir logs</p><p>修改配置文件/opt/module/elasticsearch-6.1.1/config/elasticsearch.yml<br>vi elasticsearch.yml</p><pre><code class="highlight plaintext"># ----------- Cluster ----------- cluster.name: my-application# ----------- Node ----------- node.name: node-121# ----------- Paths ----------- path.data: /opt/module/elasticsearch-6.1.1/datapath.logs: /opt/module/elasticsearch-6.1.1/logs# ----------- Memory ----------- bootstrap.memory_lock: falsebootstrap.system_call_filter: false# ----------- Network ----------- network.host: 192.168.116.121# ----------- Discovery ----------- discovery.zen.ping.unicast.hosts: ["hsiehchou121"]</code></pre><p>（1）<a href="http://cluster.name">cluster.name</a><br>如果要配置集群需要两个节点上的elasticsearch配置的cluster.name相同，都启动可以自动组成集群，这里如果不改cluster.name则默认是cluster.name=my-application</p><p>（2）nodename随意取但是集群内的各节点不能相同</p><p>（3）修改后的每行前面不能有空格，修改后的“：”后面必须有一个空格</p><p>3）配置linux系统环境<br><strong>编辑limits.conf</strong><br>添加类似如下内容<br>sudo vi /etc/security/limits.conf<br>添加如下内容:</p><ul><li>soft nofile 65536</li><li>hard nofile 131072</li><li>soft nproc 4096</li><li>hard nproc 4096</li></ul><p><strong>进入limits.d目录下修改配置文件</strong><br>sudo vi /etc/security/limits.d/20-nproc.conf<br>修改如下内容：</p><ul><li>soft nproc 4096（修改为此参数，6版本的默认就是4096）</li></ul><p><strong>修改配置sysctl.conf</strong><br>sudo vi /etc/sysctl.conf<br>添加下面配置：<br>vm.max_map_count=655360<br>并执行命令：<br>sudo sysctl -p<br>然后，重新启动elasticsearch，即可启动成功</p><p><strong>启动（非root账户下启动）</strong><br>bin/elasticsearch<br>注意：can not run elasticsearch as root</p><p><strong>测试elasticsearch</strong><br>curl <a href="http://hsiehchou121:9200">http://hsiehchou121:9200</a><br>curl -XGET ‘hsiehchou121:9200/_cat/health?v&amp;pretty’</p><p><strong>注：Linux中新建账户elasticsearch</strong><br>1、Linux中新建用户命令：<br>举例：我们创建一个名字叫 elasticsearch的用户<br>使用root用户操作如下命令：<br>useradd elasticsearch———–创建用户<br>passwd elasticsearch———–为用户设置密码<br>vim /etc/sudoers ———–为用户赋予sudo权限<br>添加 elasticsearch ALL=(ALL) ALL</p><p>2、修改文件夹及其子文件夹属主命令<br>chown -R elasticsearch ./elasticsearch-6.1.1/<br>修改后即可以使用elasticsearch操作此文件夹内容</p><p>4）安装elasticsearch-head.crx插件<br>页面连接按钮前面有个输入框输入：<a href="http://192.168.116.121:9200/">http://192.168.116.121:9200/</a></p><p>5）命令行验证<br>REST API<br>curl -XGET ‘localhost:9200/_cat/health?v&amp;pretty’<br>epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent<br>1550960314 06:18:34 elasticsearch green 1 1 0 0 0 0 0 0 - 100.0%</p><p>看到status是 green，证明启动成功</p><p><strong>Green</strong> - 一切运行正常(集群功能齐全)<br><strong>Yellow</strong> - 所有数据是可以获取的，但是一些复制品还没有被分配(集群功能齐全)<br><strong>Red</strong> - 一些数据因为一些原因获取不到(集群部分功能不可用)</p><h4 id="多节点集群安装教程">多节点集群安装教程</h4><p>1）分发Elasticsearch安装包至hsiehchou122、hsiehchou123、hsiehchou124<br>xsync elasticsearch-6.1.1/<br>或者scp -r elasticsearch-6.1.1/ hsiehchou122:/opt/module/</p><p>2）修改hsiehchou121配置信息<br>[elasticsearch@hsiehchou121 config]$ vi elasticsearch.yml<br>添加如下信息：<br>node.master: true<br>node.data: true</p><p>3）修改hsiehchou122配置信息<br>修改Elasticsearch配置信息<br>[elasticsearch@hsiehchou122 config]$ vi elasticsearch.yml<br><a href="http://node.name">node.name</a>: node-122<br>node.master: false<br>node.data: true<br>network.host: 192.168.116.122</p><p>修改Linux相关配置信息（同hsiehchou121 ）</p><p>修改hsiehchou122、hsiehchou123、hsiehchou124 配置信息</p><p>因为是scp的，所以一些跟hsiehchou121一样的配置就不需要修改了</p><p>5）分别启动三台节点的Elasticsearch<br>6）使用插件查看集群状态</p><h4 id="集群安装（详细增加或者修改内容）">集群安装（详细增加或者修改内容）</h4><p>vi /opt/module/elasticsearch-6.1.1/config/elasticsearch.yml<br>hsiehchou121增加<br>node.master: true<br>node.data: true</p><p>hsiehchou121修改<br>discovery.zen.ping.unicast.hosts: [“hsiehchou121”,”hsiehchou122”,”hsiehchou123”,”hsiehchou124”]</p><p>hsiehchou122增加<br>node.master: false<br>node.data: true</p><p>hsiehchou122修改<br><a href="http://node.name">node.name</a>: node-122<br>network.host: 192.168.116.122<br>discovery.zen.ping.unicast.hosts: [“hsiehchou121”,”hsiehchou122”,”hsiehchou123”,”hsiehchou124”]</p><p>hsiehchou123增加<br>node.master: false<br>node.data: true</p><p>hsiehchou123修改<br><a href="http://node.name">node.name</a>: node-123<br>network.host: 192.168.116.123<br>discovery.zen.ping.unicast.hosts: [“hsiehchou121”,”hsiehchou122”,”hsiehchou123”,”hsiehchou124”]</p><p>hsiehchou124增加<br>node.master: false<br>node.data: true</p><p>hsiehchou124修改<br><a href="http://node.name">node.name</a>: node-124<br>network.host: 192.168.116.124<br>discovery.zen.ping.unicast.hosts: [“hsiehchou121”,”hsiehchou122”,”hsiehchou123”,”hsiehchou124”]</p><p><strong>说明</strong><br><a href="http://cluster.name">cluster.name</a> ：如果要配置集群需要两个节点上的 elasticsearch 配置的 <a href="http://cluster.name">cluster.name</a> ：相同，都启动可以自动组成集群，这里如果不改 <a href="http://cluster.name">cluster.name</a> ：则默认是 cluster.name=my-application<br>nodename ：随意取但是集群内的各节点不能相同</p><p><strong>启动es，报错：</strong><br>[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]<br>[2]: max number of threads [1024] for user [hduser] is too low, increase to at least [4096]<br>[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]<br>[4]: system call filters failed to install; check the logs and fix your configuration or disable system</p><p>配置 linux 系统环境：<br>切换到 root 用户，编辑 limits.conf 添加类似如下内容<br>vi /etc/security/limits.conf</p><p>添加如下内容：</p><ul><li>soft nofile 65536</li><li>hard nofile 131072</li><li>soft nproc 4096</li><li>hard nproc 4096<br>进入 limits.d 目录下修改配置jian</li></ul><p>vi /etc/security/limits.d/20-nproc.conf<br>把 * soft nproc 1024 改成4096<br>es6版本的我没有要改，默认就是4096</p><p>修改配置 sysctl.conf<br>vi /etc/sysctl.conf<br>添加：<br>vm.max_map_count=655360<br>执行：<br>sysctl -p</p><p>重新登录elasticsearch用户，重新启动es<br>如果还有报错，则需重启虚拟机</p><p>查看集群状态命令：<br>curl -XGET ‘your ip:9200/_cat/health?v&amp;pretty’</p><p>查看所有数据命令：</p><pre><code class="highlight plaintext">[elasticsearch@hsiehchou121 config]$ curl -XGET '192.168.116.121:9200/blog/_search?pretty' -H 'Content-Type: application/json' -d'&gt; {&gt;  "query": { "match_all": {} }&gt; }&gt; '</code></pre><p>Elasticsearch head插件安装<br>node js下载插件：<a href="https://github.com/mobz/elasticsearch-head">https://github.com/mobz/elasticsearch-head</a><br>nodejs官网下载安装包：<a href="https://nodejs.org/dist/">https://nodejs.org/dist/</a><br>node-v6.9.2-linux-x64.tar.xz<br>拷贝<br>安装nodejs：<br>解压<br>配置环境变量：<br>export NODE_HOME=/usr/local/node-v6.9.2-linux-x64<br>export PATH=<code>$PATH:$NODE_HOME/bin</code></p><p>查看node和npm版本：<br>node -v<br>v6.9.2</p><p>npm -v<br>3.10.9</p><p>解压head插件到/opt/module目录下：<br>unzip elasticsearch-head-master.zip</p><p>查看当前head插件目录下有无node_modules/grunt目录：<br>没有的话，执行下面命令创建：<br>npm install grunt <code>--save</code> <code>--registry</code>=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>安装head插件：</p><p>npm install -g cnpm <code>--registry</code>=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>安装grunt：</p><p>npm install -g grunt-cli <code>--registry</code>=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>编辑Gruntfile.js<br>vim Gruntfile.js</p><p><strong>文件93行添加</strong><br><strong>hostname: ‘0.0.0.0’,</strong></p><p>检查head根目录下是否存在base文件夹<br>没有的话，将 _site下的base文件夹及其内容复制到head根目录下<br>mkdir base<br>cp base/* …/base/</p><p>启动grunt server：<br>[root@hsiehchou121 elasticsearch-head-master]# grunt server -d</p><p>如果提示grunt的模块没有安装：<br>Local Npm module “grunt-contrib-clean” not found. Is it installed?<br>Local Npm module “grunt-contrib-concat” not found. Is it installed?<br>Local Npm module “grunt-contrib-watch” not found. Is it installed?<br>Local Npm module “grunt-contrib-connect” not found. Is it installed?<br>Local Npm module “grunt-contrib-copy” not found. Is it installed?<br>Local Npm module “grunt-contrib-jasmine” not found. Is it installed?</p><p>执行以下命令：<br>npm install grunt-contrib-clean -registry=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>npm install grunt-contrib-concat -registry=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>npm install grunt-contrib-watch -registry=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>npm install grunt-contrib-connect -registry=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>npm install grunt-contrib-copy -registry=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a><br>npm install grunt-contrib-jasmine -registry=<a href="https://registry.npm.taobao.org">https://registry.npm.taobao.org</a></p><p>最后一个模块可能安装不成功，但是不影响使用</p><p>浏览器访问head插件：<br><a href="http://192.168.116.121:9100">http://192.168.116.121:9100</a></p><p><strong>CDH上的elasticsearch的配置</strong><br>vim /etc/security/limits.conf</p><ul><li>soft nofile 65536</li><li>hard nofile 131072</li><li>soft nproc 2048</li><li>hard nproc 4096</li></ul><p>vim /etc/security/limits.d/90-nproc.conf</p><ul><li><pre><code>     soft    nproc     4096</code></pre></li></ul><p>root       soft    nproc     unlimited</p><p>vim /etc/sysctl.conf</p><p><strong>添加下面配置</strong><br>vm.max_map_count=655360</p><p>并执行命令：<br>sysctl -p</p><p><a href="http://hadoop2:9200">http://hadoop2:9200</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase 操作</title>
      <link href="/2019/03/15/hbase_cao_zuo/"/>
      <url>/2019/03/15/hbase_cao_zuo/</url>
      
        <content type="html"><![CDATA[<h4 id="1、HBase-API操作">1、HBase API操作</h4><p>1）首先将core-site.xml、hbase-site.xml、hdfs-site.xml引入maven工程的resources下面</p><p>2）配置pom.xml文件<br>增加hbase依赖</p><pre><code class="highlight plaintext">&lt;dependencies&gt;   &lt;dependency&gt;       &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;       &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;       &lt;version&gt;1.3.0&lt;/version&gt;   &lt;/dependency&gt;   &lt;dependency&gt;       &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;       &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;       &lt;version&gt;1.3.0&lt;/version&gt;   &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>3）创建HbaseTest.java</p><pre><code class="highlight plaintext">package com.hsiehchou.hbase;import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.hbase.*; import org.apache.hadoop.hbase.client.*; import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException; import java.util.ArrayList; import java.util.List;public class HbaseTest { //配置信息 public static Configuration conf; //获取配置信息 static{ //alt + enter conf = HBaseConfiguration.create(); }</code></pre><p><strong>判断HBase中表是否存在</strong></p><pre><code class="highlight plaintext">//1.判断HBase中表是否存在public static boolean isExist(String tableName) throws IOException{    //对表操作需要用HbaseAdmin    //HBaseAdmin admin = new HBaseAdmin(conf);老版本    Connection connection = ConnectionFactory.createConnection(conf);    //管理器    HBaseAdmin admin = (HBaseAdmin) connection.getAdmin();    return  admin.tableExists(TableName.valueOf(tableName));}</code></pre><p><strong>在HBase中创建表</strong></p><pre><code class="highlight plaintext">//2.在HBase中创建表public static void createTable(String tableName, String... columnFamily) throws IOException {    //1.如果对表操作需要使用管理器    Connection connection = ConnectionFactory.createConnection(conf);    HBaseAdmin admin = (HBaseAdmin)connection.getAdmin();    //2.创建描述器    HTableDescriptor hd = new HTableDescriptor(TableName.valueOf(tableName));    //3.指定多个列族    for(String cf:columnFamily){        hd.addFamily(new HColumnDescriptor(cf));    }    //4.创建表    admin.createTable(hd);    System.out.println("表已经创建成功！！！！");}</code></pre><p><strong>bin/hbase shell操作</strong><br>list<br>scan ‘ni’<br>describe ‘ni’</p><p><strong>向表中添加数据</strong></p><pre><code class="highlight plaintext">//3,向表中添加数据 put   rowkey  cf:列族public static void addData(String tableName, String rowkey, String cf, String column, String value) throws IOException {  Connection connection = ConnectionFactory.createConnection(conf);  Table table = connection.getTable(TableName.valueOf(tableName));  //添加数据 put方式  Put put = new Put(Bytes.toBytes(rowkey));  //指定列族 列 值  put.addColumn(Bytes.toBytes(cf), Bytes.toBytes(column), Bytes.toBytes(value));  table.put(put);}</code></pre><p><strong>删除一行数据</strong></p><pre><code class="highlight plaintext">//4.删除一行数据public static void deleteRow(String tableName, String rowkey) throws IOException {    Connection connection = ConnectionFactory.createConnection(conf);    Table table = connection.getTable(TableName.valueOf(tableName));    Delete delete = new Delete(Bytes.toBytes(rowkey));    table.delete(delete);}</code></pre><p><strong>删除多个rowkey的数据</strong></p><pre><code class="highlight plaintext">//5.删除多个rowkey的数据public static void deleteMore(String tableName, String... rowkey) throws IOException {    Connection connection = ConnectionFactory.createConnection(conf);    Table table = connection.getTable(TableName.valueOf(tableName));    //封装delete    List&lt;Delete&gt; d = new ArrayList&lt;Delete&gt;();    //遍历rowkey    for(String rk:rowkey){        Delete dd = new Delete(Bytes.toBytes(rk));        d.add(dd);    }    table.delete(d);}</code></pre><p><strong>全表扫描</strong></p><pre><code class="highlight plaintext">//6.全表扫描public static void scanAll(String tableName) throws IOException {    Connection connection = ConnectionFactory.createConnection(conf);    Table table = connection.getTable(TableName.valueOf(tableName));    Scan scan = new Scan();    ResultScanner rs = table.getScanner(scan);    //遍历    for(Result r:rs){        //单元格        Cell[] cells = r.rawCells();        for(Cell c:cells) {            System.out.println("rowkey为：" + Bytes.toString(CellUtil.cloneRow(c)));            System.out.println("列族为：" + Bytes.toString(CellUtil.cloneFamily(c)));            System.out.println("值为：" + Bytes.toString(CellUtil.cloneValue(c)));        }    }}</code></pre><p><strong>删除表</strong></p><pre><code class="highlight plaintext">//7.删除表public static void deleteTable(String tableName) throws IOException {    //1.如果对表操作需要使用管理器    Connection connection = ConnectionFactory.createConnection(conf);    HBaseAdmin admin = (HBaseAdmin)connection.getAdmin();    admin.disableTable(tableName);    admin.deleteTable(TableName.valueOf(tableName));}public static void main(String[] args) throws IOException { //System.out.println(isExist(“user”)); //create ‘表名’,’列族名’ //createTable(“ni”,”info1”,”info2”,”info3”); //addData(“ni”,”shanghai”,”info1”,”name”,”lilei”); //deleteRow(“ni”,”shanghai”); //deleteMore(“ni”,”shanghai1”,”shanghai2”);//scanAll(“ni”); deleteTable(“ni”); } }</code></pre><h4 id="2、HBase-MR">2、HBase-MR</h4><p>HBase主要擅长的领域是存储数据，不擅长分析数据</p><p>HBase如果想计算的话需要结合Hadoop的MapReduce</p><p>HBase-MR所需的jar包查看<br>bin/hbase mapredcp</p><p>配置临时环境变量</p><p>export HBASE_HOME=/root/hd/hbase-1.3.0<br>export HADOOP_HOME=/root/hd/hadoop-2.8.4<br>export HADOOP_CLASSPATH=<code>${HBASE_HOME}/bin/hbase mapredcp</code><br>跑hbase-mr程序<br>bin/yarn jar /root/hd/hbase-1.3.0/lib/hbase-server-1.3.0.jar rowcounter user</p><h4 id="3、HBase的表操作">3、HBase的表操作</h4><p><strong>场景一</strong>：<br>region分片<br>指定列的过滤<br>name age high<br>name</p><p><strong>代码实现</strong><br><strong>ReadLoveMapper.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mr;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableMapper;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;/** * HBase -MR * mapper类进行对数据的读取操作 * key:ImmutableBytesWritable hbase中的rowkey * value:封装的一条条的数据 */public class ReadLoveMapper extends TableMapper&lt;ImmutableBytesWritable, Put&gt; {    @Override    protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException {        //1.读取数据  根据rowkey拿到数据        Put put = new Put(key.get());        //2.过滤列 Cell单元格        for (Cell c:value.rawCells()){            //拿到info列族数据  如果是info列族  取出  如果不是info 过滤掉            if("info".equals(Bytes.toString(CellUtil.cloneFamily(c)))){                //过滤列                if("name".equals(Bytes.toString(CellUtil.cloneQualifier(c)))){                    put.add(c);                }            }        }        //3.输出到reducer端        context.write(key,put);    }}</code></pre><p><strong>WriteLoveReducer .java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mr;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableReducer;import org.apache.hadoop.io.NullWritable;import java.io.IOException;/** * keyIn:ImmutableBytesWritable * valueIn:Put * keyOut:NullWritable（在put里面已经有了rowkey了，所以不需要了） */public class WriteLoveReducer extends TableReducer&lt;ImmutableBytesWritable, Put, NullWritable&gt; {    @Override    protected void reduce(ImmutableBytesWritable key, Iterable&lt;Put&gt; values, Context context) throws IOException, InterruptedException {        for (Put p:values){            context.write(NullWritable.get(),p);        }    }}</code></pre><p><strong>LoverDriver .java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mr;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.client.Scan;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.util.Tool;import org.apache.hadoop.util.ToolRunner;public class LoverDriver implements Tool {    private Configuration conf;    public void setConf(Configuration configuration) {        this.conf = HBaseConfiguration.create(configuration);    }    public Configuration getConf() {        return this.conf;    }    public int run(String[] strings) throws Exception {        //1.创建任务        Job job = Job.getInstance(conf);        //2.指定运行的主类        job.setJarByClass(LoverDriver.class);        //3.配置job        Scan scan = new Scan();        //4.设置具体运行的mapper类        TableMapReduceUtil.initTableMapperJob("love",                    scan,                    ReadLoveMapper.class,                    ImmutableBytesWritable.class,                    Put.class,                    job                );        //5.设置具体运行的Reducer类        TableMapReduceUtil.initTableReducerJob("lovemr",                    WriteLoveReducer.class,                    job                );        //6.设置reduceTask        job.setNumReduceTasks(1);        boolean rs = job.waitForCompletion(true);        return rs?0:1;    }    public static void main(String[] args) {        try {            //状态码            int sts = ToolRunner.run(new LoverDriver(), args);            System.exit(sts);        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p><strong>场景二</strong></p><p>把HDFS中的数据导入到HBase表中<br>HBase-MR</p><p><strong>代码实现</strong></p><p><strong>ReadHdfsMapper .java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mr1;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.util.Bytes;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * 读取hdfs中的数据 * hdfs -&gt;hbase */public class ReadHdfsMapper extends Mapper&lt;LongWritable, Text, ImmutableBytesWritable, Put&gt; {    @Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {        //1.读取数据        String line = value.toString();        //2.切分数据        String[] fields = line.split("\t");        //3.封装数据        byte[] rowkey = Bytes.toBytes(fields[0]);        byte[] name = Bytes.toBytes(fields[1]);        byte[] desc = Bytes.toBytes(fields[2]);        //4.封装成put        Put put = new Put(rowkey);        put.addColumn(Bytes.toBytes("info"),Bytes.toBytes("name"),name);        put.addColumn(Bytes.toBytes("info"),Bytes.toBytes("desc"),desc);        //5.输出到reducer        context.write(new ImmutableBytesWritable(rowkey),put);    }}</code></pre><p><strong>WriteHbaseReducer.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mr1;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableReducer;import org.apache.hadoop.io.NullWritable;import java.io.IOException;public class WriteHbaseReducer extends TableReducer&lt;ImmutableBytesWritable, Put, NullWritable&gt; {    @Override    protected void reduce(ImmutableBytesWritable key, Iterable&lt;Put&gt; values, Context context) throws IOException, InterruptedException {        for(Put p:values){            context.write(NullWritable.get(),p);        }    }}</code></pre><p><strong>LoveDriver.java</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mr1;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.util.Tool;import org.apache.hadoop.util.ToolRunner;public class LoveDriver implements Tool {    private Configuration conf = null;    public void setConf(Configuration configuration) {        this.conf = HBaseConfiguration.create(configuration);    }    public Configuration getConf() {        return this.conf;    }    public int run(String[] strings) throws Exception {        //1.创建job        Job job = Job.getInstance();        job.setJarByClass(LoveDriver.class);        //2.配置mapper        job.setMapperClass(ReadHdfsMapper.class);        job.setMapOutputKeyClass(ImmutableBytesWritable.class);        job.setMapOutputValueClass(Put.class);        //3.配置reducer        TableMapReduceUtil.initTableReducerJob("lovehdfs", WriteHbaseReducer.class, job);        //4.输入配置 hdfs读数据 inputformat        FileInputFormat.addInputPath(job,new Path("/lovehbase/"));        //5.需要配置outputformat吗？不需要 reducer中已经指定了表        return job.waitForCompletion(true)? 0:1;    }    public static void main(String[] args) {        try {            int sts = ToolRunner.run(new LoveDriver(),args);            System.exit(sts);        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><h4 id="4、HBase优化">4、HBase优化</h4><p>1）预分区问题<br>region分片？表很大 bigtable</p><p>分布式？数据量大</p><p>region存储数据，如果有多个region，每个region负责维护一部分的rowkey{startrowkey, endrowkey}<br>1~10001<br>1~2001 1980<br>2001~40002</p><p>分多少片？提前规划好，提高hbase的性能<br>进行存储数据前做好rowkey的预分区优化hbase</p><p>实际操作：<br>create ‘user_p’,’info’,’partition’,SPLITS =&gt;[‘201’,’202’,’203’,’204’]</p><p><strong>Table Regions</strong></p><table><thead><tr><th style="text-align:center">Region Server</th><th style="text-align:center">Start Key</th><th style="text-align:center">End Key</th></tr></thead><tbody><tr><td style="text-align:center">hsiehchou123:16020</td><td style="text-align:center">-∞</td><td style="text-align:center">201</td></tr><tr><td style="text-align:center">hsiehchou124:16020</td><td style="text-align:center">201</td><td style="text-align:center">202</td></tr><tr><td style="text-align:center">hsiehchou124:16020</td><td style="text-align:center">202</td><td style="text-align:center">203</td></tr><tr><td style="text-align:center">hsiehchou123:16020</td><td style="text-align:center">203</td><td style="text-align:center">204</td></tr><tr><td style="text-align:center">hsiehchou122:16020</td><td style="text-align:center">204</td><td style="text-align:center">+∞</td></tr></tbody></table><p>create ‘user_pppp’,’partition’,SPLITS_FILE =&gt; ‘partitions.txt’</p><p>partitions.txt’放在hbase-shell路径下</p><p>2）rowkey如何设计<br>rowkey是数据的唯一标识，这条数据存储在哪个分区由预分区范围决定</p><p>合理设计rowkey<br>如一份数据分为5个region存储<br>但是我们需要尽可能的保持每个region中的数据量差不多</p><p>尽可能的打散数据，平均分配到每个region中即可</p><p>解决方案：<br>生成随机数、hash/散列值<br>原本的rowkey是201，hash后<br>dfgyfugpgdcjhgfd11412nod<br>202变为：<br>21dqddwdgjohfxsovbxiufq12</p><p>字符串拼接：<br>20190316_a3d4<br>20190316_g04f</p><p>反转字符串：<br>201903161-&gt;161309102<br>201903162-&gt;261309102</p><p>3）HBase基础优化<br>HBase用的HDFS存储<br>DataNode允许最大文件打开数<br>默认4096 调大<br>dfs.datanode.max.transfer.threads<br>hdfs-site.xml</p><p>优化等待时间<br>dfs.image.transfer.timeout<br>默认60000毫秒<br>调大</p><p>内存优化：<br>hadoop-env.sh设置内存的堆大小<br>30%~40%最好</p><p>2G<br>512m</p><p>export HADOOP_PORTMAP_OPTS=’-Xmx512m $HADOOP_PORTMAP_OPTS’</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase基础</title>
      <link href="/2019/03/12/hbase_ji_chu/"/>
      <url>/2019/03/12/hbase_ji_chu/</url>
      
        <content type="html"><![CDATA[<h4 id="1、hbase">1、hbase</h4><p>google:<br>gfs –&gt; hdfs<br>mapreduce –&gt; mapreduce<br>bigtable –&gt; hbase</p><p>Apache HBase™是Hadoop数据库，是一个分布式，可扩展的大数据存储</p><p>当您需要对大数据进行随机，实时读/写访问时，请使用Apache HBase™。该项目的目标是托管非常大的表 - 数十亿行X百万列 - 在商品硬件集群上。Apache HBase是一个开源的，分布式的，版本化的非关系数据库nosql，模仿Google的Bigtable： Chang等人的结构化数据分布式存储系统。正如Bigtable利用Google文件系统提供的分布式数据存储一样，Apache HBase在Hadoop和HDFS之上提供类似Bigtable的功能</p><h4 id="2、hbase集群角色">2、hbase集群角色</h4><p>hdfs: NameNode DataNode<br>yarn: ResourceManager NodeManager<br>zookeeper: QuorumPeerMain<br>hbase: HMaster RegionServer</p><p><strong>主从结构</strong><br><strong>HMaster</strong><br>1）对RegionServer监控<br>2）处理一些元数据的变更<br>3）对RegionServer进行故障转移<br>4）空闲时对数据进行负载均衡<br>5）对region进行管理<br>6）发布位置到客户端借助于zookeeper</p><p><strong>RegionServer</strong><br>1）存储hbase实际的数据<br>2）刷新缓存数据到hdfs<br>3）处理Region<br>4）可以进行压缩<br>5）对Hlog进行维护<br>6）对region分片</p><h4 id="3、hbase集群安装部署">3、hbase集群安装部署</h4><p>1）需要安装好zookeeper集群</p><p>2）需要安装好hadoop集群<br>hdfs<br>yarn</p><p>3）解压hbase压缩包<br>tar -zxvf hbase-1.3.0-bin.tar.gz</p><p>4）<a href="http://xn--hbase-env-z89nz78pizxdjt5b.sh">修改配置hbase-env.sh</a><br>export JAVA_HOME=/root/hd/jdk1.8.0_192<br>export HBASE_MANAGES_ZK=false</p><p>5）配置hbase-site.xml<br>cd /root/hd/hbase-1.3.0<br>vi hbase-site.xml</p><pre><code class="highlight plaintext">&lt;configuration&gt;    &lt;!-- 设置namenode所在位置 通过rootdir设置 也就是设置hdfs中存放的路径 --&gt;    &lt;property&gt;        &lt;name&gt;hbase.rootdir&lt;/name&gt;        &lt;value&gt;hdfs://hsiehchou121:9000/hbase&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 是否开启集群 --&gt;    &lt;property&gt;        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 0.98 后的新变动，之前版本没有.port,默认端口为 60000 --&gt;    &lt;property&gt;        &lt;name&gt;hbase.master.port&lt;/name&gt;        &lt;value&gt;16000&lt;/value&gt;    &lt;/property&gt;    &lt;!-- zookeeper集群的位置 --&gt;    &lt;property&gt;        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;        &lt;value&gt;hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181&lt;/value&gt;    &lt;/property&gt;    &lt;!-- hbase的元数据信息存储在zookeeper的位置 --&gt;    &lt;property&gt;        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;        &lt;value&gt;/root/hd/zookeeper-3.4.10/zkData&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>指定从节点regionservers</p><p>vi regionservers</p><p>hsiehchou122<br>hsiehchou123<br>hsiehchou124</p><p>6）解决依赖问题<br>HBase依赖于Hadoop，换成2.8.4的hadoop依赖包<br>hadoop-annotations-2.8.4.jar<br>hadoop-auth-2.8.4.jar<br>hadoop-common-2.8.4.jar<br>hadoop-hdfs-2.8.4.jar<br>hadoop-hdfs-client-2.8.4.jar<br>hadoop-mapreduce-client-app-2.8.4.jar<br>hadoop-mapreduce-client-common-2.8.4.jar<br>hadoop-mapreduce-client-core-2.8.4.jar<br>hadoop-mapreduce-client-hs-2.8.4.jar<br>hadoop-mapreduce-client-hs-plugins-2.8.4.jar<br>hadoop-mapreduce-client-jobclient-2.8.4.jar<br>hadoop-mapreduce-client-jobclient-2.8.4-tests.jar<br>hadoop-mapreduce-client-shuffle-2.8.4.jar<br>hadoop-yarn-api-2.8.4.jar<br>hadoop-yarn-applications-distributedshell-2.8.4.jar<br>hadoop-yarn-applications-unmanaged-am-launcher-2.8.4.jar<br>hadoop-yarn-client-2.8.4.jar<br>hadoop-yarn-common-2.8.4.jar<br>hadoop-yarn-server-applicationhistoryservice-2.8.4.jar<br>hadoop-yarn-server-common-2.8.4.jar<br>hadoop-yarn-server-nodemanager-2.8.4.jar<br>hadoop-yarn-server-resourcemanager-2.8.4.jar<br>hadoop-yarn-server-web-proxy-2.8.4.jar</p><p>zookeeper-3.4.10.jar</p><p>7）软连接core-site.xml hdfs-site.xml<br>ln -s /root/hd/hadoop-2.8.4/etc/hadoop/hdfs-site.xml<br>ln -s /root/hd/hadoop-2.8.4/etc/hadoop/core-site.xml</p><p>8）发送到其他机器<br>scp -r hbase-1.3.0 hsiehchou122:/root/hd<br>scp -r hbase-1.3.0 hsiehchou123:/root/hd<br>scp -r hbase-1.3.0 hsiehchou124:/root/hd</p><p>find /root/hd/hadoop-2.8.4/ -name hadoop-a*</p><p>9）访问ui界面<br><a href="http://192.168.116.121:16010/master-status">http://192.168.116.121:16010/master-status</a></p><p>启动hbase<br>bin/hbase-daemon.sh start master<br>bin/hbase-daemon.sh start regionserver</p><p>关闭hbase<br>bin/hbase-daemon.sh stop master<br>bin/hbase-daemon.sh stop regionserver</p><h4 id="4、hbase设计架构">4、hbase设计架构</h4><p>Rowkey行键 类似 id<br>列式存储<br>hbase操作<br>0）启动终端<br>bin/hbase shell</p><p>1）查看表操作<br>list</p><p>2）显示当前服务器状态<br>status ‘hsiehchou121’<br>1 active master, 0 backup masters, 3 servers, 0 dead, 0.5000 ave<br>rage load<br>1 active master: 1个存活的master<br>0 backup masters: 0个备份master<br>3 servers: 3个regionserver<br>0 dead: 没有挂掉的<br>0.5000 average load：平均加载</p><p>3）显示当前用户<br>whoami</p><p>4）创建表<br>create ‘表名’,’列族’<br>create ‘user’,’info1’</p><p>5）添加数据<br>put ‘表名’,’rowkey’,’列族:列’,’值’<br>put ‘user’,’1001’,’info1:name’,’xie’<br>put ‘user’,’1001’,’info1:age’,’19’</p><p><strong>删除需要ctrl+&lt;-</strong></p><p>6）全表扫描<br>scan ‘表名’<br>scan ‘user’</p><p>ROW COLUMN+CELL<br>1001 column=info1:age, timestamp=1552579563486, value=19<br>1001 column=info1:name, timestamp=1552579531260, value=xie</p><p>7）hbase没有修改，只有覆盖<br>put ‘user’,’1001’,’info1:name’,’mi’<br>只要对应上表名、rowkey、列族、列即可</p><p>8）查看表结构<br>describe ‘user’</p><p>9）变更表结构信息<br>alter ‘user’,{NAME =&gt; ‘info1’,VERSIONS=&gt;’8’}</p><p>10）查看指定的数据信息<br>指定具体的rowkey<br>get ‘user’,’1001’<br>指定具体的列<br>get ‘user’,’1001’,’info1:name’</p><p>11）清空表<br>truncate ‘user1’</p><p>12）删除表<br>需要先指定不可用<br>disable ‘表名’<br>drop ‘表名’<br>disable ‘user1’<br>drop ‘user1’</p><p>13）扫描指定范围<br>指定从某一rowkey扫描<br>scan ‘user’,{STARTROW =&gt; ‘1002’}</p><p>包含头不包含尾（1001保留，1002不扫描）<br>scan ‘user’,{STARTROW =&gt; ‘1001’, STOPROW =&gt; ‘1002’}</p><p>14）统计rowkey的个数<br>count ‘user’</p><p>15）退出hbase shell<br>quit</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Azkaban</title>
      <link href="/2019/03/08/azkaban/"/>
      <url>/2019/03/08/azkaban/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Azkaban">1、Azkaban</h4><p>官网：<a href="https://azkaban.github.io/">https://azkaban.github.io/</a><br>Azkaban是一款开源工作流管理器</p><p>Azkaban是在LinkedIn上创建的批处理工作流作业调度程序，用于运行Hadoop作业</p><p>Azkaban通过作业依赖性解决订单，并提供易于使用的Web用户界面来维护和跟踪您的工作流程</p><p>工作流作业：<br>Flume-&gt;HDFS-&gt;MR-&gt;Hive建表-&gt;导入load data脚本<br>自动化调度</p><h4 id="2、Azkaban安装部署">2、Azkaban安装部署</h4><p>1）解压<br>首先将压缩包放进/root/hd/azkaban里面<br>azkaban-executor-server-2.5.0.tar.gz –&gt;executor<br>azkaban-sql-script-2.5.0.tar.gz –&gt;azkaban-2.5.0<br>azkaban-web-server-2.5.0.tar.gz –&gt;server<br>tar -zxvf *.tar.gz</p><p>2）进入MySQL创建Azkaban库，然后将解压好的脚本导入<br>create database azkaban;<br>use azkaban;<br>source /root/hd/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql;</p><p>3）生成证书（https生成器）<br>keytool -keystore keystore -alias jetty -genkey -keyalg RSA<br>（回车，不用填，到那个CN=Unknown那行下面有个判断，输入y，后面一行继续回车）<br>将keystore移动到server文件夹下</p><p>4）时间同步配置<br>任务调度，所以和本地时间保持一致<br>开启交互窗口：<br>sudo date -s ”<br>hwclock -w</p><p>5）修改server端配置文件<br>cd /root/hd/azkaban/server/conf<br>vi azkaban.properties</p><pre><code class="highlight plaintext"># Azkaban Personalization Settingsazkaban.name=Testazkaban.label=My Local Azkabanazkaban.color=#FF3601azkaban.default.servlet.path=/indexweb.resource.dir=web/# 时区default.timezone.id=Asia/Shanghai#Azkaban UserManager class# 用户权限管理默认类user.manager.class=azkaban.user.XmlUserManager# 用户配置user.manager.xml.file=conf/azkaban-users.xml# Loader for projects#配置文件所在位置executor.global.properties=conf/global.propertiesazkaban.project.dir=projects# azkaban目前只支持mysqldatabase.type=mysqlmysql.port=3306# 当前主机名mysql.host=hsiehchou121mysql.database=azkabanmysql.user=rootmysql.password=root# 最大连接数mysql.numconnections=100# Velocity dev modevelocity.dev.mode=false# Azkaban Jetty server properties.# 最大线程数jetty.maxThreads=25jetty.ssl.port=8443jetty.port=8081jetty.keystore=keystorejetty.password=123456jetty.keypassword=123456jetty.truststore=keystorejetty.trustpassword=123456# Azkaban Executor settingsexecutor.port=12321# mail settingsmail.sender=@qq.commail.host=smtp.qq.comjob.failure.email=job.success.email=lockdown.create.projects=falsecache.directory=cache</code></pre><p><strong>azkaban-users.xml</strong></p><pre><code class="highlight plaintext">&lt;azkaban-users&gt;    &lt;user username="azkaban" password="azkaban" roles="admin" groups="azkaban" /&gt;    &lt;user username="metrics" password="metrics" roles="metrics"/&gt;    &lt;!--增加这一行  role管理员权限:admin--&gt;    &lt;user username="admin" password="admin" roles="admin,metrics"/&gt;     &lt;role name="admin" permissions="ADMIN" /&gt;    &lt;role name="metrics" permissions="METRICS"/&gt;&lt;/azkaban-users&gt;</code></pre><p>6）修改excutor端配置文件</p><p><strong>azkaban.properties</strong></p><pre><code class="highlight plaintext"># Azkaban# 时区default.timezone.id=Asia/Shanghai# Azkaban JobTypes Plugins# 插件azkaban.jobtype.plugin.dir=plugins/jobtypes#Loader for projectsexecutor.global.properties=conf/global.propertiesazkaban.project.dir=projectsdatabase.type=mysqlmysql.port=3306mysql.host=hsiehchou121mysql.database=azkabanmysql.user=rootmysql.password=rootmysql.numconnections=100# Azkaban Executor settings# 最大线程数executor.maxThreads=50executor.port=12321executor.flow.threads=30</code></pre><h4 id="3、Azkaban实战">3、Azkaban实战</h4><p>HDFS-&gt;Hive建表-&gt;导入</p><p>1）job1.job</p><p><strong>job1.job</strong><br>type=command<br>command=echo ‘Hello World!’<br>打包成zip包上传到azkaban，执行</p><p>2）job2(a.job和b.job)</p><p><strong>a.job</strong><br>type=command<br>command=echo ‘li’</p><p><strong>b.job</strong><br>type=command<br>dependencies=a<br>command=echo ‘666’<br>打包成zip包上传到azkaban，执行</p><p>3）startyarn.job</p><p><strong>startyarn.job</strong><br>type=command<br>command=/root/hd/hadoop-2.8.4/sbin/start-yarn.sh<br>打包成zip包上传到azkaban，执行</p><p>4）mapreduce.job</p><p><strong>mapreduce.job</strong><br>type=command<br>command=/root/hd/hadoop-2.8.4/bin/hadoop jar hadoop-mapreduce-examples-2.8.4.jar wordcount /wc /wc/out<br>打包成zip包上传到azkaban，执行</p><p>5）Hive操作</p><p><strong>hive.sql</strong><br>use default;<br>create table azhive(id int, name string) row format delimited fields terminated by ‘\t’;<br>load data inpath ‘/hsiehchou.txt’ into table azhive;</p><p><strong>hivef.job</strong><br>type=command<br>command=/root/hd/hive/bin/hive -f ‘hive.sql’</p><p>打包成zip包上传到Azkaban，执行</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Azkaban </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sqoop</title>
      <link href="/2019/03/04/sqoop/"/>
      <url>/2019/03/04/sqoop/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Sqoop">1、Sqoop</h4><p>Flume数据采集 采集日志数据<br>Sqoop数据迁移 HDFS-&gt;MySQL<br>Azkaban任务调度 Flume-&gt;HDFS-&gt;Shell-&gt;Hive-&gt;SQL-&gt;BI</p><p>Sqoop数据迁移=MapReduce<br>处理离线数据<br>整个过程就是数据导入处理导出过程<br>直接使用map</p><p>Sqoop作用：简化开发<br>MySQL-&gt;HDFS<br>MapReduce<br>Sqoop!</p><h4 id="2、概述">2、概述</h4><p>Apache Sqoop（TM）是一种工具，用于在Apache Hadoop和结构化数据存储（如关 系数据库）之间高效传输批量数据 。数据迁移！</p><p>Sqoop于2012年3月成功从孵化器毕业，现在是一个顶级Apache项目： 更多信息</p><h4 id="3、Sqoop安装部署">3、Sqoop安装部署</h4><p>1）下载</p><p>2）上传</p><p>3）解压</p><p>4）重命名<br>mv <a href="http://sqoop-env-template.sh">sqoop-env-template.sh</a> <a href="http://sqoop-env.sh">sqoop-env.sh</a></p><p>5）添加配置信息<br>export HADOOP_COMMON_HOME=/root/hd/hadoop-2.8.4<br>export HADOOP_MAPRED_HOME=/root/hd/hadoop-2.8.4<br>export HIVE_HOME=/root/hd/hive<br>export ZOOCFGDIR=/root/hd/zookeeper-3.4.10/conf</p><p>6）启动查看版本号<br>bin/sqoop version</p><h4 id="4、Sqoop的import导入">4、Sqoop的import导入</h4><p>import导入：MySQL-&gt;HDFS<br>export导出：HDFS-&gt;MySQL<br>MySQL-&gt;HDFS操作：<br>1）导入mysql驱动到sqoop/lib下<br>2）命令操作<br>mysql&gt; create database sqoop;<br>mysql&gt; use sqoop;<br>mysql&gt; create table user(id int primary key auto_increment,name varchar(50),addr varchar(300));</p><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop import \&gt; --connect jdbc:mysql://hsiehchou121:3306/sqoop \&gt; --username root \&gt; --password root \&gt; --table user \&gt; --target-dir /sqoop/datas \&gt; --num-mappers 1 \&gt; --fields-terminated-by "\t"</code></pre><p><strong>注意：如果显示mysql的访问权限问题，需要设置mysql的用户权限：所在库 mysql库的user表</strong></p><p>update user set host=’%’ where host=’localhost’;<br>delete from user where Host=’127.0.0.1’;<br>delete from user where Host=’hsiehchou121’;<br>delete from user where Host=’::1’;<br>flush privileges;</p><p><strong>使用query对数据进行过滤</strong></p><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop import \&gt; --connect jdbc:mysql://hsiehchou121:3306/sqoop \&gt; --username root \&gt; --password root \&gt; --target-dir /sqoop/selectimport \&gt; --num-mappers 1 \&gt; --fields-terminated-by "\t" \&gt; --query 'select * from user where id&lt;=1 and $CONDITIONS'</code></pre><p><strong>直接过滤字段</strong></p><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop import \&gt; --username root \&gt; --password root \&gt; --connect jdbc:mysql://hsiehchou121:3306/sqoop \&gt; --target-dir /sqoop/selectimport1 \&gt; --num-mappers 1 \&gt; --table user \&gt; --columns addr</code></pre><h4 id="5、MySQL导入到Hive">5、MySQL导入到Hive</h4><p>在~/.bash_profile里面增加下面配置<br>export HADOOP_CLASSPATH=<code>$HADOOP_CLASSPATH:/root/hd/hive/lib/*</code><br>export HADOOP_USER_HOME=root</p><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop import \&gt; --connect jdbc:mysql://hsiehchou121:3306/sqoop \&gt; --username root \&gt; --password root \&gt; --table user \&gt; --num-mappers 1 \&gt; --hive-import \&gt; --fields-terminated-by "\t" \&gt; --hive-overwrite \&gt; --hive-table user_sqoop</code></pre><h4 id="6、Sqoop的export命令">6、Sqoop的export命令</h4><p>Hive-&gt;MySQL<br>Hive导出到MySQL<br>首先清空mysql里面的user：truncate table user;</p><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop export \&gt; --connect jdbc:mysql://hsiehchou121:3306/sqoop \&gt; --username root \&gt; --password root \&gt; --table user \&gt; --num-mappers 1 \&gt; --export-dir /user/hive/warehouse/user_sqoop \&gt; --input-fields-terminated-by "\t"</code></pre><h4 id="7、常用参数">7、常用参数</h4><p>import ：导入数据到集群<br>export ：从集群导出数据<br>create-hive-table ：创建Hive表<br>import-all-tables ：指定关系型数据库所有表到HDFS集群<br>list-databases ：列出所有数据库<br>list-tables ：列出所有数据库表<br>merge ：合并hdfs中的不同目录下的数据<br>codegen ：获取某张表数据生成JavaBean 并打包</p><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop codegen \&gt; --connect jdbc:mysql://hsiehchou121:3306/sqoop \&gt; --username root \&gt; --password root \&gt; --table user \&gt; --bindir /root/sqoopjar/UserBean \&gt; --class-name UserBean \&gt; --fields-terminated-by "\t"</code></pre><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop list-databases \&gt; --connect jdbc:mysql://hsiehchou121:3306/ \&gt; --username root \&gt; --password root</code></pre><pre><code class="highlight plaintext">[root@hsiehchou121 sqoop]# bin/sqoop merge \&gt; --new-data /testmerge/new/ \&gt; --onto /testmerge/old/ \&gt; --target-dir /testmerge/merged table user \&gt; --jar-file /root/sqoopjar/UserBean/UserBean.jar \&gt; --class-name UserBean \&gt; --merge-key id</code></pre><p><strong>注意</strong>：<br>merge操作是一个新表替代旧表的操作，如果有冲突id的话新表数据替换旧表数据，如果没有冲突则是新表数据添加到旧表的数据</p><p>用户画像 merge<br>身高180 体重70 爱好 ……<br>身高180 体重90 爱好….</p><p>广告大数据 提高销量 广告推送更加精准<br>工业大数据 flink面试</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Sqoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flume</title>
      <link href="/2019/03/02/flume/"/>
      <url>/2019/03/02/flume/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Flume">1、Flume</h4><p><strong>概述</strong>：<br>Flume是一种分布式，可靠且可用的服务，用于有效地收集，聚合和移动大量日志数据。它具有基于流数据流的简单灵活的架构。它具有可靠的可靠性机制和许多故障转移和恢复机制，具有强大的容错性。它使用简单的可扩展数据模型，允许在线分析应用程序<br>1）数据采集（爬虫\日志数据\Flume）<br>2）数据存储（HDFS/Hive/HBase(NoSQL)）<br>3）数据计算（MapReduce/Hive/SparkSQL/SparkStreaming/Flink）<br>4）数据可视化</p><h4 id="2、Flume角色">2、Flume角色</h4><p>1）Source<br>数据源，用户采集数据，Source产生数据流，同时会把产生的数据流传输到Channel</p><p>2）Channel<br>传输通道，用于桥接Source和Sink</p><p>3）Sink<br>下沉，用于收集Channel传输的数据，将数据源传递到目标源</p><p>4）Agent<br>在Flume中使用事件作为传输的基本单元</p><h4 id="3、Flume使用">3、Flume使用</h4><p>简单易用，只需要写配置文件即可</p><h4 id="4、Flume安装配置">4、Flume安装配置</h4><p>1）下载Flume<br>2）上传到Linux<br>3）解压<br>tar -zxvf apache-flume-1.6.0-bin.tar.gz -C /root/hd</p><p>4）重命名<br>mv apache-flume-1.6.0-bin/ flume<br>cp flume-env.sh.template <a href="http://flume-env.sh">flume-env.sh</a></p><p>5）修改配置<br>vi <a href="http://flume-env.sh">flume-env.sh</a><br>export JAVA_HOME=/root/hd/jdk1.8.0_192</p><h4 id="5、Flume监听端口">5、Flume监听端口</h4><p>启动命令：<br>bin/flume-ng agent <code>--conf</code> conf/log4j.properties <code>--name</code> a1 <code>--conf-file</code> conf/flumejob_telnet.conf</p><p><strong>我已经排坑了，这里我建议–conf 后面指定的路径建议是全路径，指定到log4j.properties或，我当时老师讲的是直接conf/，我实际操作是有问题的，不能实时的反馈</strong></p><pre><code class="highlight plaintext">bin/flume-ng agent 使用ng启动agent--conf conf/log4j.properties 指定配置所在的文件夹--name a1 指定的agent别名--conf-file conf/flumejob_telnet.conf 文件-Dflume.root.logger=INFO,console 日志级别的反馈**</code></pre><p><strong>flumejob_telnet.conf</strong></p><pre><code class="highlight plaintext">#smple.conf: A single-node Flume configuration# Name the components on this agent 定义变量方便调用 加s可以有多个此角色a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the source 描述source角色 进行内容定制# 此配置属于tcp source 必须是netcat类型a1.sources.r1.type = netcat a1.sources.r1.bind = localhosta1.sources.r1.port = 44444# Describe the sink 输出日志文件a1.sinks.k1.type = logger# Use a channel which buffers events in memory（file） 使用内存 总大小1000 每次传输100a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channel 一个source可以绑定多个channel # 一个sinks可以只能绑定一个channel  使用的是图二的模型a1.sources.r1.channels = c1a1.sinks.k1.channel = c1</code></pre><pre><code class="highlight plaintext">[root@hsiehchou121 flume]# bin/flume-ng agent \&gt; --conf conf/ \&gt; --name a1 \&gt; --conf-file conf/flumejob_telnet.conf \&gt; -Dflume.root.logger=INFO.console</code></pre><p><strong>yum search telnet</strong></p><p><strong>yum install telnet.x86_64</strong></p><h4 id="6、flume监听本地linux文件采集到hdfs">6、flume监听本地linux文件采集到hdfs</h4><p>启动命令：<br>bin/flume-ng agent <code>--conf</code> conf/log4j.properties <code>--name</code> a1 <code>--conf-file</code> conf/flumejob_hdfs.conf</p><p><strong>flumejob_hdfs.conf</strong></p><pre><code class="highlight plaintext"># Name the components on this agent agent别名设置a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the source  设置数据源监听本地文件配置# exec 执行一个命令的方式去查看文件 tail -F 实时查看a1.sources.r1.type = exec# 要执行的脚本command tail -F 默认10行 man tail  查看帮助a1.sources.r1.command = tail -F /tmp/root/hive.log# 执行这个command使用的是哪个脚本 -c 指定使用什么命令# whereis bash# bash: /usr/bin/bash /usr/share/man/man1/bash.1.gz a1.sources.r1.shell = /usr/bin/bash -c# Describe the sink a1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = hdfs://hsiehchou121:9000/flume/%Y%m%d/%H#上传文件的前缀a1.sinks.k1.hdfs.filePrefix = logs-#是否按照时间滚动文件夹a1.sinks.k1.hdfs.round = true#多少时间单位创建一个新的文件夹  秒 （默认30s）a1.sinks.k1.hdfs.roundValue = 1#重新定义时间单位（每小时滚动一个文件夹）a1.sinks.k1.hdfs.roundUnit = minute#是否使用本地时间戳a1.sinks.k1.hdfs.useLocalTimeStamp = true#积攒多少个 Event 才 flush 到 HDFS 一次a1.sinks.k1.hdfs.batchSize = 500#设置文件类型，可支持压缩a1.sinks.k1.hdfs.fileType = DataStream#多久生成一个新的文件 秒a1.sinks.k1.hdfs.rollInterval = 30#设置每个文件的滚动大小 字节（最好128M,合理）a1.sinks.k1.hdfs.rollSize = 134217700#文件的滚动与 Event 数量无关a1.sinks.k1.hdfs.rollCount = 0#最小冗余数(备份数 生成滚动功能则生效roll hadoop本身有此功能 无需配置) 1份 不冗余 hdfs已经备份3份a1.sinks.k1.hdfs.minBlockReplicas = 1# Use a channel which buffers events in memory a1.channels.c1.type = memory a1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1</code></pre><pre><code class="highlight plaintext">[root@hsiehchou121 flume]# bin/flume-ng agent \&gt; --conf conf/log4j.properties \&gt; --name a1 \&gt; --conf-file conf/flumejob_hdfs.conf</code></pre><h4 id="7、监听文件夹">7、监听文件夹</h4><p><strong>flumejob_dir.conf</strong></p><pre><code class="highlight plaintext"># 定义别名a1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = spooldir# 监控的文件夹a1.sources.r1.spoolDir = /root/testdir# 上传成功后显示后缀名 a1.sources.r1.fileSuffix = .COMPLETED# 如论如何 加绝对路径的文件名 默认falsea1.sources.r1.fileHeader = true#忽略所有以.tmp 结尾的文件（正在被写入），不上传# ^以任何开头 出现无限次 以.tmp结尾的a1.sources.r1.ignorePattern = ([^ ]*\.tmp)# Describe the sink 下沉到hdfsa1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = hdfs://hsiehchou121:9000/flume/testdir/%Y%m%d/%H#上传文件的前缀a1.sinks.k1.hdfs.filePrefix = testdir-#是否按照时间滚动文件夹a1.sinks.k1.hdfs.round = true#多少时间单位创建一个新的文件夹a1.sinks.k1.hdfs.roundValue = 1#重新定义时间单位a1.sinks.k1.hdfs.roundUnit = hour#是否使用本地时间戳a1.sinks.k1.hdfs.useLocalTimeStamp = true#积攒多少个 Event 才 flush 到 HDFS 一次a1.sinks.k1.hdfs.batchSize = 100#设置文件类型，可支持压缩a1.sinks.k1.hdfs.fileType = DataStream#多久生成一个新的文件a1.sinks.k1.hdfs.rollInterval = 600#设置每个文件的滚动大小大概是 128M a1.sinks.k1.hdfs.rollSize = 134217700#文件的滚动与 Event 数量无关a1.sinks.k1.hdfs.rollCount = 0#最小副本数a1.sinks.k1.hdfs.minBlockReplicas = 1# Use a channel which buffers events in memory a1.channels.c1.type = memory a1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1 a1.sinks.k1.channel = c1</code></pre><p>[root@hsiehchou121 conf]# bin/flume-ng agent <code>--conf</code> conf/log4j.properties <code>--name</code> a1 <code>--conf-file</code> conf/flumejob_dir.conf</p><pre><code class="highlight plaintext">[root@hsiehchou121 flume]# bin/flume-ng agent \&gt; --conf conf/log4j.properties \&gt; --name a1 \&gt; --conf-file conf/flumejob_dir.conf</code></pre><h4 id="8、多个channel-sink">8、多个channel/sink</h4><p>需求：监控hive.log文件，用同时产生两个channel，一个channel对应的sink存储到hdfs中，另外一个channel对应的sink存储到本地</p><p><strong>flumejob_1.conf</strong></p><pre><code class="highlight plaintext"># name the components on this agent 别名设置a1.sources = r1a1.sinks = k1 k2 a1.channels = c1 c2# 将数据流复制给多个 channela1.sources.r1.selector.type = replicating# Describe/configure the source a1.sources.r1.type = execa1.sources.r1.command = tail -F /tmp/root/hive.loga1.sources.r1.shell = /bin/bash -c# Describe the sink# 分两个端口发送数据 a1.sinks.k1.type = avro a1.sinks.k1.hostname = hsiehchou121 a1.sinks.k1.port = 4141a1.sinks.k2.type = avro a1.sinks.k2.hostname = hsiehchou121 a1.sinks.k2.port = 4142# Describe the channel a1.channels.c1.type = memory a1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.channels.c2.type = memory a1.channels.c2.capacity = 1000a1.channels.c2.transactionCapacity = 100# Bind the source and sink to the channel a1.sources.r1.channels = c1 c2 a1.sinks.k1.channel = c1a1.sinks.k2.channel = c2</code></pre><p>[root@hsiehchou121 flume]# bin/flume-ng agent <code>--conf</code> conf/log4j.properties <code>--name</code> a1 <code>--conf-file</code> conf/flumejob_1.conf</p><p><strong>flumejob_2.conf</strong></p><pre><code class="highlight plaintext"># Name the components on this agent a2.sources = r1a2.sinks = k1 a2.channels = c1# Describe/configure the sourcea2.sources.r1.type = avro # 端口抓取数据a2.sources.r1.bind = hsiehchou121a2.sources.r1.port = 4141# Describe the sink a2.sinks.k1.type = hdfsa2.sinks.k1.hdfs.path = hdfs://hsiehchou121:9000/flume2/%Y%m%d/%H#上传文件的前缀a2.sinks.k1.hdfs.filePrefix = flume2-#是否按照时间滚动文件夹a2.sinks.k1.hdfs.round = true#多少时间单位创建一个新的文件夹a2.sinks.k1.hdfs.roundValue = 1#重新定义时间单位a2.sinks.k1.hdfs.roundUnit = hour#是否使用本地时间戳a2.sinks.k1.hdfs.useLocalTimeStamp = true#积攒多少个 Event 才 flush 到 HDFS 一次a2.sinks.k1.hdfs.batchSize = 100#设置文件类型，可支持压缩a2.sinks.k1.hdfs.fileType = DataStream#多久生成一个新的文件a2.sinks.k1.hdfs.rollInterval = 600#设置每个文件的滚动大小大概是 128M a2.sinks.k1.hdfs.rollSize = 134217700#文件的滚动与 Event 数量无关a2.sinks.k1.hdfs.rollCount = 0#最小副本数a2.sinks.k1.hdfs.minBlockReplicas = 1# Describe the channel a2.channels.c1.type = memory a2.channels.c1.capacity = 1000a2.channels.c1.transactionCapacity = 100# Bind the source and sink to the channel a2.sources.r1.channels = c1a2.sinks.k1.channel = c1</code></pre><p>[root@hsiehchou121 flume]# bin/flume-ng agent <code>--conf</code> conf/log4j.properties <code>--name</code> a2 <code>--conf-file</code> conf/flumejob_1.conf</p><p><strong>flumejob_3.conf</strong></p><pre><code class="highlight plaintext"># Name the components on this agent a3.sources = r1a3.sinks = k1 a3.channels = c1# Describe/configure the source a3.sources.r1.type = avroa3.sources.r1.bind = hsiehchou121a3.sources.r1.port = 4142# Describe the sink a3.sinks.k1.type = file_rolla3.sinks.k1.sink.directory = /root/flume2# Describe the channel a3.channels.c1.type = memory a3.channels.c1.capacity = 1000a3.channels.c1.transactionCapacity = 100# Bind the source and sink to the channel a3.sources.r1.channels = c1a3.sinks.k1.channel = c1</code></pre><p>[root@hsiehchou121 flume]# bin/flume-ng agent <code>--conf</code> conf/log4j.properties <code>--name</code> a3 <code>--conf-file</code> conf/flumejob_1.conf</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Flume </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive函数&amp;压缩</title>
      <link href="/2019/02/28/hive_han_shu_ya_suo/"/>
      <url>/2019/02/28/hive_han_shu_ya_suo/</url>
      
        <content type="html"><![CDATA[<h4 id="1、排序">1、排序</h4><p>Order By:全局排序<br>1）按照员工表的奖金金额进行正序排序<br>select * from emptable order by emptable.comm asc;<br>可以省略asc</p><p>2）按照员工表的奖金金额进行倒序排序<br>select * from emptable order by emptable.comm desc;</p><p>3）按照部门和奖金进行升序排序<br>select * from emptable order by deptno,comm;</p><p>Sort By: <strong>内部排序（区内有序，全局无序）</strong><br>设置reduce个数的属性：set mapreduce.job.reduces = 3;<br>select * from dept_partitions sort by deptno desc;</p><p>Distribute By: <strong>分区排序</strong><br>1）先按照部门编号进行排序再按照地域编号进行降序排序。<br>select * from dept_partitions distribute by deptno sort by loc desc;</p><p>Cluster By: <strong>分桶排序</strong><br>1）按照部门编号进行排序<br>select * from dept_partitions cluster by deptno;</p><p><strong>注意</strong>：如果Distrbute和Sort by 是相同字段时，可以用cluster by代替</p><h4 id="2、分桶">2、分桶</h4><p>分桶分的是文件<br>1）创建分桶表<br>clustered by(id) into 4 buckets</p><pre><code class="highlight plaintext">hive&gt; set mapreduce.job.reduces=4;hive&gt; create table emptable_buck(id int, name string)    &gt; clustered by(id) into 4 buckets    &gt; row format    &gt; delimited fields    &gt; terminated by '\t';</code></pre><p><strong>查看表的描述信息</strong></p><p>hive&gt; desc formatted emptable_buck;</p><p><strong>加载数据</strong></p><pre><code class="highlight plaintext">hive&gt; load data local inpath '/root/hsiehchou.txt' into table emptable_buck;hive&gt; create table emptable_b(id int, name string)    &gt; row format    &gt; delimited fields    &gt; terminated by '\t';</code></pre><p><strong>清空表</strong></p><pre><code class="highlight plaintext">hive&gt; truncate table emptable_buck;</code></pre><p><strong>加载数据（桶）</strong></p><pre><code class="highlight plaintext">hive&gt; load data local inpath '/root/hsiehchou.txt' into table emptable_b;</code></pre><p><strong>设置桶的环境变量(插入数据时分桶，不开启默认在一个桶里面)</strong></p><pre><code class="highlight plaintext">hive&gt; set hive.enforce.bucketing=true;hive&gt; truncate table emptable_buck;</code></pre><p>用户需要统计一个具有代表性的结果时，并不是全部结果！抽样！<br>(bucket 1 out of 2 on id）<br>1：第一桶数据<br>2：代表拿两桶</p><pre><code class="highlight plaintext">hive&gt; select * from emptable_buck  tablesample(bucket 1 out of 2 on id);</code></pre><h4 id="3、UDF自定义函数">3、UDF自定义函数</h4><p><strong>查看内置函数</strong><br>show functions;</p><p><strong>查看函数的详细内容</strong><br>desc function extended upper;</p><p>UDF:一进一出<br>UDAF:聚合函数 多进一出 count /max/avg<br>UDTF:一进多出</p><p><strong>java</strong><br>导入Hive的lib下的所有jar包<br>编程java代码</p><pre><code class="highlight plaintext">package com.hsiehchou;import org.apache.hadoop.hive.ql.exec.UDF;public class MyConcat extends UDF {    //将大写转换成小写    public String evaluate(String a, String b) {        return a + "******" + String.valueOf(b);    }   }</code></pre><p>export此文件，打包jar，放入hsiehchou121中</p><p>添加临时：<br>add jar /root/Myconcat.jar;<br>create temporary function my_cat as “com.hsiehchou.MyConcat”;</p><pre><code class="highlight plaintext">&lt;!-- 注册永久：hive-site.xml --&gt;&lt;property&gt;&lt;name&gt;hive.aux.jars.path&lt;/name&gt;&lt;value&gt;file:///root/hd/hive/lib/hive.jar&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="4、Hive压缩">4、Hive压缩</h4><p>存储：hdfs<br>计算：mapreduce</p><p><strong>Map输出阶段压缩方式</strong><br>开启hive中间传输数据压缩功能<br>set hive.exec.compress.intermediate=true;</p><p><strong>开启map输出压缩</strong><br>set mapreduce.map.output.compress=true;</p><p><strong>设置snappy压缩方式</strong><br>set <a href="http://mapreduce.map.output.compress.codec=org.apache.hadoop.io.com">mapreduce.map.output.compress.codec=org.apache.hadoop.io.com</a><br>press.SnappyCodec;</p><p><strong>Reduce输出阶段压缩方式</strong><br>设置hive输出数据压缩功能<br>set hive.exec.compress.output=true;</p><p><strong>设置mr输出数据压缩</strong><br>set mapreduce.output.fileoutputformat.compress=true;</p><p><strong>指定压缩编码</strong><br>set mapreduce.output.fileoutputformat.compress.codec=org.apache.<br>hadoop.io.compress.SnappyCodec;</p><p><strong>指定压缩类型块压缩</strong><br>set mapreduce.output.fileoutputformat.compress.type=BLOCK;</p><p><strong>测试结果</strong><br>insert overwrite local directory ‘/root/datas/rs’ select * from emptable order by sal desc;</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive的SQL操作</title>
      <link href="/2019/02/27/hive_de_sql_cao_zuo/"/>
      <url>/2019/02/27/hive_de_sql_cao_zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="1、分区表">1、分区表</h3><h4 id="1）创建分区表">1）创建分区表</h4><pre><code class="highlight plaintext">hive&gt; create table dept_partitions()      &gt; partition by()      &gt; row format      &gt; delimited fields      &gt; terminated by '';</code></pre><p>例：</p><pre><code class="highlight plaintext">hive&gt; create table dept_partitions(deptno int, dept string, loc string)    &gt; partitioned by(day string)    &gt; row format    &gt; delimited fields    &gt; terminated by '\t';hive&gt; load data local inpath '/root/dept.txt' into table dept_partitions    &gt; partition(day='0228');</code></pre><h4 id="2）查询">2）查询</h4><p><strong>全查询</strong><br>hive&gt; select * from dept_partitions;<br>注意：此时查看的是整个分区表中的数据</p><p><strong>单分区查询</strong><br>hive&gt; select * from dept_partitions where day = ‘0228’;<br>注意：此时查看的是指定分区中的数据</p><p><strong>联合查询</strong><br>hive&gt; select * from dept_partitions where day = ‘0228’ union select * from dept_partitions where day = ‘0302’;</p><p><strong>添加单个分区</strong><br>hive&gt; alter table dept_partitions add partition(day = ‘0303’);</p><p><strong>注意</strong>：如果想一次添加多个的话 空格分割即可<br>hive&gt; alter table dept_partitions add partition(day = ‘0304’) partition(day = ‘0305’);</p><p><strong>查看分区</strong><br>hive&gt; show partitions dept_partitions;</p><p><strong>删除分区</strong><br>hive&gt; alter table dept_partitions drop partition(day=’0305’);<br>分区表在hdfs中分目录文件夹</p><p>hive&gt; dfs -mkdir -p /user/hive/warehouse/dept_partitions/day=0305;</p><p>hive&gt; dfs -put /root/dept.txt /user/hive/warehouse/dept_partitions/day=0305;</p><p>hive&gt; show partitions dept_partitions;<br>此时并没有day=0305，需要进行下面操作</p><p><strong>导入数据</strong><br>相当于修复数据：msck repair table dept_partitions;</p><h3 id="2、DML数据操作">2、DML数据操作</h3><h4 id="1）数据的导入">1）数据的导入</h4><p>hive&gt; load data [local] inpath ” into table ;</p><h4 id="2）向表中插入数据">2）向表中插入数据</h4><p>hive&gt; insert into table student_partitions partition(age = 20)  values(1,’re’);<br>向表中插入sql查询结果数据<br>hive&gt; insert overwrite table student_partitions partition(age = 20) select * from hsiehchou where id&lt;3;</p><p>create方式：<br>hive&gt; create table if not exists student_partitions1 as select * from student_partitions where id = 2;</p><h4 id="3）创建表直接加载数据">3）创建表直接加载数据</h4><pre><code class="highlight plaintext">hive&gt; create table student_partitions3(id int,name string)      &gt; row format      &gt; delimited fields      &gt; terminated by '\t'      &gt; location '';</code></pre><p><strong>注意</strong>：locatition路径是hdfs路径<br>关联文件时不能有多级目录！！！<br>例：</p><pre><code class="highlight plaintext">hive&gt; create table student_partitions4(id int,name string)    &gt; row format    &gt; delimited fields    &gt; terminated by '\t'    &gt; location '/wc';</code></pre><h4 id="4）把操作结果导出到本地linux">4）把操作结果导出到本地linux</h4><p>hive&gt; insert overwrite local directory ‘/root/data’ select * from hsiehchou;</p><h4 id="5）把hive中表数据导出到hdfs中">5）把hive中表数据导出到hdfs中</h4><p>hive&gt; export table hsiehchou to ‘/hsiehchou’;</p><p>把hdfs数据导入到hive中<br>hive&gt; import table hsiehchou3 from ‘/hsiehchou/’;</p><h4 id="6）清空表数据">6）清空表数据</h4><p>hive&gt; truncate table hsiehchou3;</p><h3 id="3、查询操作">3、查询操作</h3><p>基础查询<br>select * from table;全表查询<br>hive&gt; select <a href="http://hsiehchou.id">hsiehchou.id</a>,<a href="http://hsiehchou.name">hsiehchou.name</a> from table …;指定列</p><h4 id="1）指定列查询">1）指定列查询</h4><p>hive&gt; select <a href="http://hsiehchou.name">hsiehchou.name</a> from hsiehchou;</p><h4 id="2）指定列查询设置别名">2）指定列查询设置别名</h4><p>hive&gt; select <a href="http://hsiehchou.name">hsiehchou.name</a> as myname from hsiehchou;</p><h4 id="3）创建员工表">3）创建员工表</h4><pre><code class="highlight plaintext">hive&gt; create table hive_db.emptable(empno int, ename string , job string,mgr int, birthday string, sal double, comm double, deptno int)    &gt; row format    &gt; delimited fields    &gt; terminated by '\t';hive&gt; load data local ‘/root/emp.txt’ into table hive_db.emptable;</code></pre><h4 id="4）查询员工姓名和工资-每个员工加薪1000块">4）查询员工姓名和工资(每个员工加薪1000块)</h4><p>hive&gt; select emptable.ename,emptable.sal+1000 salmoney from emptable;</p><h4 id="5）查看公司有多少员工">5）查看公司有多少员工</h4><p>hive&gt; select count(1) empnumber from emptable;</p><h4 id="6）查询工资最高的工资">6）查询工资最高的工资</h4><p>hive&gt; select max(sal) numberone from emptable;</p><h4 id="7）查询工资最小的工资">7）查询工资最小的工资</h4><p>hive&gt; select min(sal) from emptable;</p><h4 id="8）求工资的总和">8）求工资的总和</h4><p>hive&gt; select sum(sal) sal_sum from emptable;</p><h4 id="9）求该公司员工工资的平均值">9）求该公司员工工资的平均值</h4><p>hive&gt; select avg(sal) sal_avg from emptable;</p><h4 id="10）查询结果只显示前多少条">10）查询结果只显示前多少条</h4><p>hive&gt; select * from emptable limit 4;</p><h4 id="11）where语句">11）where语句</h4><p>作用：过滤<br>使用：where子句紧接着from</p><p>求出工资大于2600的员工<br>hive&gt; select * from emptable where sal&gt;2600;</p><p>求出工资在1000~2500范围的员工<br>hive&gt; select * from emptable where sal&gt;1000 and sal&lt;2500;</p><p>或者<br>hive&gt; select * from emptable where sal between 1000 and 2500;</p><p><strong>查询工资在2000和3000这两个数的员工信息</strong><br>hive&gt; select ename from emptable where sal in(2000,3000);</p><h4 id="12）is-null与is-not-null">12）is null与is not null</h4><p><strong>空与非空的过滤</strong><br>空<br>hive&gt; select * from emptable where comm is null;</p><p>非空<br>hive&gt; select * from emptable where comm is not null;</p><h4 id="13）like">13）like</h4><p><strong>模糊查询</strong><br>使用：<br>通配符% 后面零个或者多个字符<br>_代表一个字符</p><p>查询工资以1开头的员工信息<br>hive&gt; select * from emptable where sal like ‘1%’;</p><p>查询工资地第二位是1的员工信息<br>hive&gt; select * from emptable where sal like ‘_1%’;</p><p>_代表一个字符<br>查询工资中有5的员工信息<br>hive&gt; select * from emptable where sal like ‘%5%’;</p><h4 id="14）And-Not-Or">14）And/Not/Or</h4><p>查询部门号30并且工资大于1000的员工信息<br>hive&gt; select * from emptable where sal&gt;1000 and deptno=30;</p><p>查询部门号30或者工资大于1000的员工信息<br>hive&gt; select * from emptable where sal&gt;1000 or deptno=30;</p><p>查询工资在2000和3000这两个数的员工信息<br>hive&gt; select * from emptable where sal in(2000,3000);</p><p>查询工资不在2000和3000这两个数的员工信息<br>hive&gt; select * from emptable where sal not in(2000,3000);</p><h4 id="15）分组操作">15）分组操作</h4><p>Group By语句<br>通常和一些聚合函数一起使用</p><p>求每个部门的平均工资<br>hive&gt; select avg(sal) avg_sal,deptno from emptable group by deptno;<br>having<br>where：后不可以与分组函数，而having可以</p><p>求每个部门的平均工资大于2000的部门<br>hive&gt; select deptno,avg(sal) avg_sal from emptable group by deptno hav<br>ing avg_sal&gt;2000;</p><h3 id="4、Join操作">4、Join操作</h3><pre><code class="highlight plaintext">hive&gt; create table dept(deptno int, dname string, loc int)      &gt; row format      &gt; delimited fields      &gt; terminated by '\t';</code></pre><p>员工表中只有部门编号，并没有部门名称<br>部门表中有部门标号和部门名称</p><p><strong>等值join</strong></p><h4 id="1）查询员工编号、员工姓名、员工所在的部门名称">1）查询员工编号、员工姓名、员工所在的部门名称</h4><p>hive&gt; select emptable.empno,emptable.ename,dept.dname from emptable join dept on emptable.deptno=dept.deptno;</p><h4 id="2）查询员工编号、员工姓名、员工所在部门名称、部门所在地">2）查询员工编号、员工姓名、员工所在部门名称、部门所在地</h4><p>内连接：只有连接的两张表中都存在与条件向匹配的数据才会被保留下来<br>hive&gt; select e.empno,e.ename,d.dname,d.loc from emptable e join dept d on e.deptno=d.deptno;</p><h4 id="3）左外连接-left-join">3）左外连接(left join)</h4><p>查询员工编号，员工姓名，部门名称<br>hive&gt; select e.empno,e.ename,d.deptname from emptable e left join dept d on e.deptno=d.deptno;<br>特点：默认用的Left join 可以省略left<br>保留左表数据，右表没有join上 显示为null</p><h4 id="4）右外连接-right-join">4）右外连接(right join)</h4><p>hive&gt; select e.empno,e.ename,d.dname from emptable e right join dept d on e.deptno=d.deptno;<br>特点：<br>保留右表数据，左表没有join上 显示为null</p><h4 id="5）满外连接-full-join">5）满外连接(full join)</h4><p>hive&gt; select e.empno,e.ename,d.dname from emptable e full join dept d on e.deptno=d.deptno;<br>特点：结果会返回所有表中符合条件的所有记录，如果有字段没有符合条件用null值代替</p><h4 id="6）多表连接">6）多表连接</h4><pre><code class="highlight plaintext">hive&gt; create table location(loc int, loc_name string)      &gt; row format      &gt; delimited fields      &gt; terminated by '\t';</code></pre><p><strong>加载数据</strong><br>hive&gt; load data local inpath ‘/root/location.txt’ into table location;</p><p><strong>查询员工名、部门名称、地域名称</strong><br>hive&gt; select e.ename,d.dname,l.loc_name from emptable e join dept d on<br>e.deptno=d.deptno join location l on d.loc=l.loc;</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hive SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive基础</title>
      <link href="/2019/02/25/hive_ji_chu/"/>
      <url>/2019/02/25/hive_ji_chu/</url>
      
        <content type="html"><![CDATA[<h3 id="Hive">Hive</h3><p>官网：<a href="http://hive.apache.org/">http://hive.apache.org/</a><br>Apache Hive?数据仓库软件有助于使用SQL读取，编写和管理驻留在分布式存储中的大型数据集。可以将结构投影到已存储的数据中。提供了命令行工具和JDBC驱动程序以将用户连接到Hive</p><p>Hive提供了SQL查询功能 hdfs分布式存储</p><p>Hive本质HQL转化为MapReduce程序<br>环境前提：<br>1）启动hdfs集群<br>2）启动yarn集群<br>如果想用hive的话，需要提前安装部署好hadoop集群</p><h3 id="为什么要学习Hive">为什么要学习Hive</h3><p>简化开发<br>easycoding!<br>高德地图使用Hive</p><p><strong>优势</strong>：<br>1）操作接口采用类sql语法，select * from stu;<br>简单、上手快！<br>2）hive可以替代mr程序，sqoop<br>3）hive可以处理海量数据<br>4）hive支持UDF，自定义函数</p><p><strong>劣势</strong>：<br>1）处理数据延迟高，慢<br>引擎：1.2.2以前版本都是用的mr引擎<br>2.x之后用的是Spark引擎</p><p>2）HQL的表达能力有限<br>一些sql无法解决的场景，依然需要我们写MapReduce</p><h3 id="hive架构原理解析">hive架构原理解析</h3><p>sql-&gt;转换-&gt;MapReduce-&gt;job</p><h3 id="hive安装部署">hive安装部署</h3><h4 id="1）下载">1）下载</h4><h4 id="2）上传到Linux">2）上传到Linux</h4><h4 id="3）解压">3）解压</h4><p>tar -zxvf apache-hive-1.2.2-bin.tar.gz -C hd/</p><h4 id="4）重命名">4）重命名</h4><p>mv apache-hive-1.2.2-bin/ hive</p><h4 id="5）修改配置文件">5）修改配置文件</h4><p>mv hive-env.sh.template <a href="http://hive-env.sh">hive-env.sh</a><br>vi <a href="http://hive-env.sh">hive-env.sh</a><br>HADOOP_HOME=/root/hd/hadoop-2.8.4<br>export HIVE_CONF_DIR=/root/hd/hive/conf</p><h4 id="6）启动">6）启动</h4><p>bin/hive</p><h3 id="配置mysql元数据库">配置mysql元数据库</h3><h4 id="1）拷贝mysql驱动到hive-lib">1）拷贝mysql驱动到hive/lib</h4><p>cp/mv hive/lib</p><h4 id="2）添加hive-site-xml">2）添加hive-site.xml</h4><pre><code class="highlight plaintext">&lt;?xml version="1.0"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;configuration&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;&lt;value&gt;jdbc:mysql://hsiehchou121:3306/metastore?createDatabaseIfNotExist=true&lt;/value&gt;&lt;description&gt;JDBC connect string for a JDBCmetastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;&lt;value&gt;root&lt;/value&gt;&lt;description&gt;username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;&lt;value&gt;root&lt;/value&gt;&lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;</code></pre><h4 id="3）注意：重启hadoop集群">3）注意：重启hadoop集群</h4><h4 id="4）启动hive">4）启动hive</h4><p>bin/hive<br>此时mysql中创建metastore元数据库<br>hive&gt; create table hsiehchou(id int, name string)</p><p>row format<br>delimited fields<br>terminated by ‘\t’;<br>OK<br>hive&gt; load data local inpath ‘/root/hsiehchou.txt’ into table hsiehchou;<br>OK<br>hive&gt; select * from hsiehchou;<br>OK<br>1 re<br>2 mi<br>3 zk<br>4 sf<br>5 ls</p><h3 id="杀死hive进程">杀死hive进程</h3><p>[root@hsiehchou121 hive]# ps -aux|grep hive<br>root 3649 3.7 16.9 2027072 239240 pts/0 Tl 21:37 0:31<br>root 4285 0.0 0.0 112648 948 pts/0<br>[root@hsiehchou121 hive]# kill -9 3649</p><h3 id="安装mysql5-6">安装mysql5.6</h3><p>yum search libaio # 检索相关信息<br>yum install libaio # 安装依赖包<br>wget <a href="http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm">http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm</a></p><p>添加 MySQL Yum Repository 到linux系统 repository 列表中，输入<br>yum localinstall mysql-community-release-el7-5.noarch.rpm</p><p>验证是否添加成功<br>yum repolist enabled | grep “mysql.-community.”</p><p>查看 MySQL 版本，输入<br>yum repolist all | grep mysql</p><p>可以看到 5.5， 5.7 版本是默认禁用的，因为现在最新的稳定版是 5.6<br>yum repolist enabled | grep mysql</p><p>通过 Yum 来安装 MySQL，输入<br>yum install mysql-community-server</p><p>rpm -qi mysql-community-server.x86_64 0:5.6.24-3.el7</p><p>查看 MySQL 的安装目录<br>whereis mysql</p><p>启动 MySQL Server<br>systemctl start mysqld</p><p>查看 MySQL Server 状态<br>systemctl status mysqld</p><p>关闭 MySQL Server<br>systemctl stop mysqld</p><p>测试是否安装成功<br>mysql</p><p>修改mysql密码<br>use mysql;<br>update user set password=password(‘root’) where user=’root’;<br>flush privileges;</p><h3 id="数据导入操作">数据导入操作</h3><p>load data []local] inpath ‘/root/hsiehchou.txt’ into table hsiehchou;</p><p>load data:加载数据</p><p>local:可选操作，如果加上local导入是本地linux中的数据，如果去掉local 那么 导入的是hdfs中数据</p><p>inpath:表示的是加载数据的路径</p><p>into table:表示要加载的对应的表</p><h3 id="hive数据类型">hive数据类型</h3><table><thead><tr><th style="text-align:center">Java数据类型</th><th style="text-align:center">Hive数据类型</th><th style="text-align:center">长度</th></tr></thead><tbody><tr><td style="text-align:center">byte</td><td style="text-align:center">TINYINT</td><td style="text-align:center">1byte有符号整数</td></tr><tr><td style="text-align:center">short</td><td style="text-align:center">SMALLINT</td><td style="text-align:center">2byte有符号整数</td></tr><tr><td style="text-align:center">int</td><td style="text-align:center">INT</td><td style="text-align:center">4byte有符号整数</td></tr><tr><td style="text-align:center">long</td><td style="text-align:center">GINT</td><td style="text-align:center">8byte有符号整数</td></tr><tr><td style="text-align:center">boolean</td><td style="text-align:center">BOOLEAN</td><td style="text-align:center">false/true</td></tr><tr><td style="text-align:center">float</td><td style="text-align:center">FLOAT</td><td style="text-align:center">单精度浮点</td></tr><tr><td style="text-align:center">double</td><td style="text-align:center">DOUBLE</td><td style="text-align:center">双精度浮点</td></tr><tr><td style="text-align:center">string</td><td style="text-align:center">STRING</td><td style="text-align:center">字符</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">BINARY</td><td style="text-align:center">字节数组</td></tr></tbody></table><h3 id="DDL数据定义">DDL数据定义</h3><h4 id="1）查看数据库">1）查看数据库</h4><p>show databases;</p><h4 id="2）创建库">2）创建库</h4><p>create database hive_db;</p><h4 id="3）创建库-标准写法">3）创建库 标准写法</h4><p>create database if not exists hive_db;</p><h4 id="4）创建库指定hdfs路径">4）创建库指定hdfs路径</h4><p>create database hive_db location ‘/hive_db’;</p><h4 id="5）创建表">5）创建表</h4><p>如果指定了hdfs路径<br>创建的表存在于这个路径</p><h4 id="6）查看数据库结构">6）查看数据库结构</h4><p>desc database hive_db;</p><h4 id="7）添加额外的描述信息">7）添加额外的描述信息</h4><p>alter database hive_db set dbproperties(‘created’=’hsiehchou’);<br>注意：查询需要使用desc database extended hive_db;</p><h4 id="8）查看指定的通配库-过滤">8）查看指定的通配库:过滤</h4><p>show databases like ‘h*’;</p><h4 id="9）删除空库">9）删除空库</h4><p>drop database hive_db;</p><h4 id="10）删除非空库">10）删除非空库</h4><p>drop database hive_db2 cascade;</p><h4 id="11-删除非空库标准写法">11) 删除非空库标准写法</h4><p>drop database if exists hive_db cascade;</p><h3 id="创建表">创建表</h3><p>create <code>[external]</code> table <code>[if not exists]</code> table_name(字段信息) <code>[partitioned by(字段信息)][clustered by(字段信息)]</code> [sorted by(字段信息)]row format delimited fields terminated by ‘切割符’;</p><h3 id="管理表">管理表</h3><p>默认不加external创建的就是管理表，也称为内部表。<br>MANAGED_TABLE管理表<br>Table Type:MANAGED_TABLE</p><p>查看表类型：<br>desc formatted hsiehchou2;</p><h3 id="外部表">外部表</h3><p>EXTERNAL_TABLE外部表<br>创建方式：<br>create external table student(id int,name string)</p><p>区别：如果是管理表删除hdfs中数据删除，如果是外部表删除hdfs数据不删除！</p><h3 id="hive命令">hive命令</h3><h4 id="1）不登录hive客户端直接输入命令操作Hive">1）不登录hive客户端直接输入命令操作Hive</h4><p>[root@hsiehchou121 hive]# bin/hive -e “select * from hsiehchou;”<br>19/02/28 03:09:23 WARN conf.HiveConf: HiveConf of name hive.cli,print.current.db does not exist<br>Logging initialized using configuration in jar:file:/root/hd/hive/lib/hive-common-1.2.2.jar!/hive-log4j.properties<br>OK<br><a href="http://hsiehchou.id">hsiehchou.id</a> <a href="http://hsiehchou.name">hsiehchou.name</a><br>1 re<br>2 mi<br>3 zk<br>4 sf<br>5 ls</p><h4 id="2）直接把sql写入到文件中">2）直接把sql写入到文件中</h4><p>bin/hive -f /root/hived.sql</p><h4 id="3）查看hdfs文件">3）查看hdfs文件</h4><p>dfs -ls /;<br>dfs -cat /wc/in/words.txt;</p><h4 id="4）查看历史操作">4）查看历史操作</h4><p>[root@hsiehchou121 hive]# cat ~/.hivehistory</p><p>在hive/conf/hive-site.xml中增加</p><pre><code class="highlight plaintext">&lt;!--是否显示当前表头--&gt;&lt;property&gt;        &lt;name&gt;hive.cli.print.header&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!--是否显示当前所在库名--&gt;&lt;property&gt;        &lt;name&gt;hive.cli.print.current.db&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;&lt;/property</code></pre><p><strong>显示效果</strong><br>hive&gt; select * from hsiehchou;<br>OK<br><a href="http://hsiehchou.id">hsiehchou.id</a> <a href="http://hsiehchou.name">hsiehchou.name</a><br>1 re<br>2 mi<br>3 zk<br>4 sf<br>5 ls</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ZooKeeper练习</title>
      <link href="/2019/02/23/zookeeper_lian_xi/"/>
      <url>/2019/02/23/zookeeper_lian_xi/</url>
      
        <content type="html"><![CDATA[<h3 id="命令行操作">命令行操作</h3><p>配置环境变量：vi /etc/profile<br>export ZOOKEEPER_HOME=<code>/root/hd/zookeeper-3.4.10</code><br>export PATH=<code>$ZOOKEEPER_HOME/bin:$PATH</code></p><p>声明环境变量：source /etc/profile</p><p>发送到其他机器<br>scp /etc/profile hsiehchou122:/etc/<br>scp /etc/profile hsiehchou123:/etc/<br>scp /etc/profile hsiehchou124:/etc/</p><p>启动zookeeper<br><a href="http://zkServer.sh">zkServer.sh</a> start</p><p>查看zookeeper状态<br><a href="http://zkServer.sh">zkServer.sh</a> status</p><h4 id="1）启动客户端">1）启动客户端</h4><p>bin/zkCli.sh</p><h4 id="2）连接其它机器客户端操作">2）连接其它机器客户端操作</h4><p>没有太大必要，每台机器内容都一样<br>connect hsiehchou122:2181<br>connect hsiehchou123:2181<br>connect hsiehchou124:2181</p><h4 id="3）查看历史操作记录">3）查看历史操作记录</h4><p>history</p><h4 id="4）查看当前节点的内容">4）查看当前节点的内容</h4><p>ls /</p><h4 id="5）存储：创建节点">5）存储：创建节点</h4><p>create /hsiehchou 10(存储的数据)</p><h4 id="6）查看节点的值">6）查看节点的值</h4><p>get /hsiehchou</p><p>10<br>cZxid = 0x400000004<br>ctime = Sat Feb 23 20:05:58 PST 2019<br>mZxid = 0x400000004<br>mtime = Sat Feb 23 20:05:58 PST 2019<br>pZxid = 0x400000004<br>cversion = 0<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0x0<br>dataLength = 2<br>numChildren = 0</p><h4 id="7）创建节点的可选项">7）创建节点的可选项</h4><p>create <code>[-s] [-e]</code> path data acl</p><p>[-p]永久节点–默认<br>[-e] 短暂节点<br>[-s] 带序号</p><p>create -e /re hm<br>注意：此时-e创建的是临时的短暂节点，退出客户端后消失<br>退出客户端：quit</p><p>create -s /re hm<br>注意：此时-s创建是带序号的节点，可以创建节点名相同的，序号依次累加</p><p>[zk: localhost:2181(CONNECTED) 1] create -s /mm hm<br>Created /mm0000000002<br>[zk: localhost:2181(CONNECTED) 2] create -s /mm hm<br>Created /mm0000000003<br>[zk: localhost:2181(CONNECTED) 3] create -s /mm hm<br>Created /mm0000000004<br>[zk: localhost:2181(CONNECTED) 4] create  /re hm<br>Created /re<br>[zk: localhost:2181(CONNECTED) 5] create  /re hm<br>Node already exists: /re<br>创建短暂带序号节点<br>create -e -s /tt bt</p><h4 id="8）修改节点值">8）修改节点值</h4><p>set path data [version]<br>例如：set /re hm2 1<br>[version] 版本<br>注意：设置版本号 必须从0开始</p><h4 id="9）删除节点">9）删除节点</h4><p>delete path<br>[zk: localhost:2181(CONNECTED) 12] ls /<br>[mm0000000004, re, zookeeper, mm0000000002, mm0000000003, hsiehchou]<br>[zk: localhost:2181(CONNECTED) 13] delete /mm0000000002<br>[zk: localhost:2181(CONNECTED) 14] ls /<br>[mm0000000004, re, zookeeper, mm0000000003, hsiehchou]</p><h4 id="10）创建子节点">10）创建子节点</h4><p>create /re/pa qi</p><h4 id="11）递归删除">11）递归删除</h4><p>rmr /re</p><h4 id="12）监听">12）监听</h4><p>获得监听（文件）：get path watch<br>获得当前节点下增减变化（文件夹）：ls path watch</p><h4 id="13）查看当前节点的状态">13）查看当前节点的状态</h4><p>stat /hsiehchou</p><h3 id="节点状态信息">节点状态信息</h3><p>czxid：ZooKeeper事务id<br>ctime：节点创建时间<br>mZxid：最后更新的czxid<br>mtime：最后修改的时间*<br>pZxid：最后更新子节点的czxid<br>cversion：子节点的变化号、子节点修改次数<br>dataVersion：数据变化号<br>aclVersion：访问控制列表的变化号<br>ephemeralOwner：临时节点判断<br>dataLength：节点数据长度<br>numChildren：子节点个数</p><h3 id="JAVA-API-练习">JAVA-API 练习</h3><p><strong>pom.xml</strong></p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0"         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.hsiehchou&lt;/groupId&gt;    &lt;artifactId&gt;ZKTest&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;dependencies&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;            &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;            &lt;version&gt;3.4.10&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;RELEASE&lt;/version&gt;            &lt;scope&gt;compile&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre><h3 id="练习1">练习1</h3><p><strong>ZkClient类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.zk;import org.apache.zookeeper.*;import org.apache.zookeeper.data.Stat;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.util.List;public class ZkClient {    private String conected = "hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181";    //毫秒    private int timeout = 2000;    ZooKeeper zkCli = null;    //连接zookeeper集群    @Before    public void init() throws IOException {        //String:连接集群的IP端口号，Int：超时设置，Watcher：监听        zkCli = new ZooKeeper(conected, timeout, new Watcher() {            //回调方法，显示/节点            public void process(WatchedEvent watchedEvent) {                List&lt;String&gt; children;                //获得节点信息 get                try {                    children = zkCli.getChildren("/",true);                } catch (KeeperException e) {                    e.printStackTrace();                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        });    }    //测试 是否连通集群  创建节点    @Test    public void createNode() throws KeeperException, InterruptedException {        String p = zkCli.create("/bq", "sk".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);        System.out.println(p);    }    //查看子节点    @Test    public void getChild() throws KeeperException, InterruptedException {        List&lt;String&gt; children = zkCli.getChildren("/", true);        for(String c:children){            System.out.println(c);        }    }    //删除子节点数据:delete path    @Test    public void deleteData() throws KeeperException, InterruptedException {        zkCli.delete("/da", -1);    }    //修改数据:set path data    @Test    public void setData() throws KeeperException, InterruptedException {        zkCli.setData("/hsiehchou","nihao".getBytes(),-1);        //查看/hsiehchou        byte[] data = zkCli.getData("/hsiehchou", false, new Stat());        System.out.println(new String(data));    }    //指定节点是否存在    @Test    public void testExist() throws KeeperException, InterruptedException {        Stat exists = zkCli.exists("/hsiehchou", false);        System.out.println(exists == null ? "no have":"have");    }}</code></pre><h3 id="练习2">练习2</h3><p><strong>WatchDemo类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.watch;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import java.io.IOException;public class WatchDemo {    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {        String connected = "hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181,";        //毫秒        int timeout = 2000;        //1.连接zookeeper集群        ZooKeeper zkCli = new ZooKeeper(connected, timeout, new Watcher() {            //监听回调            public void process(WatchedEvent watchedEvent) {                System.out.println("正在监听中.........");            }        });        //2.监听： ls / watch    get / watch        zkCli.getChildren("/", new Watcher() {            public void process(WatchedEvent watchedEvent) {                System.out.println("此时监听的路径是："+watchedEvent.getPath());                System.out.println("此时监听的类型为："+watchedEvent.getType());                System.out.println("有人正在修改数据！！！");            }        },null);        Thread.sleep(Long.MAX_VALUE);    }}</code></pre><p><strong>WatchDemo1类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.watch;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import java.io.IOException;public class WatchDemo1 {    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {        ZooKeeper zkCli = new ZooKeeper("hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181", 2000, new Watcher() {            public void process(WatchedEvent watchedEvent) {            }        });        byte[] data = zkCli.getData("/re", new Watcher() {            //具体监听的内容            public void process(WatchedEvent watchedEvent) {                System.out.println("此时监听的路径是：" + watchedEvent.getPath());                System.out.println("此时监听的类型为：" + watchedEvent.getType());                System.out.println("有人正在修改数据！！！");            }        }, null);        System.out.println(new String(data));        Thread.sleep(Long.MAX_VALUE);    }}</code></pre><h3 id="练习3">练习3</h3><p><strong>ZkClient类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.qq;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * 实现对zookeeper / 的监听 */public class ZkClient {    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {        //1.获取zookeeper的连接        ZkClient zkCli = new ZkClient();        zkCli.getConnect();        //2.指定监听的节点路径        zkCli.getServers();        //3.写业务逻辑，一直监听        zkCli.getWatch();    }    //1.获得zookeeper连接    private String connected = "hsiehchou121:2181,hsiehchou122:2181,hsiehchou123:2181,hsiehchou124:2181";    //毫秒    private int timeout = 2000;    ZooKeeper zkCli;    public void getConnect() throws IOException {        zkCli = new ZooKeeper(connected, timeout, new Watcher() {            public void process(WatchedEvent watchedEvent) {                List&lt;String&gt; children;                try {                    children = zkCli.getChildren("/", true);                    //服务器列表                    ArrayList&lt;String&gt; serverList = new ArrayList&lt;String&gt;();                    //获取每个节点的数据                    for (String c:children){                        byte[] data = zkCli.getData("/" + c, true, null);                        serverList.add(new String(data));                    }                    //查看服务器列表                    System.out.println(serverList);                } catch (KeeperException e) {                    e.printStackTrace();                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        });    }    //2.指定监听节点路径    public void getServers() throws KeeperException, InterruptedException {        List&lt;String&gt; children = zkCli.getChildren("/", true);        //存储服务器列表        ArrayList&lt;String&gt; serverList = new ArrayList&lt;String&gt;();        for (String c:children){            byte[] data = zkCli.getData("/" + c, true, null);            //添加集合中            serverList.add(new String(data));        }        //打印服务器列表        System.out.println(serverList);    }    //3.一直监听    public void getWatch() throws InterruptedException {        //循环监听        Thread.sleep(Long.MAX_VALUE);    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ZooKeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper介绍</title>
      <link href="/2019/02/21/zookeeper_jie_shao/"/>
      <url>/2019/02/21/zookeeper_jie_shao/</url>
      
        <content type="html"><![CDATA[<h3 id="ZooKeeper">ZooKeeper</h3><p>官网：<a href="http://zookeeper.apache.org/">http://zookeeper.apache.org/</a><br>介绍：Apache ZooKeeper致力于开发和维护开源服务器，实现高度可靠的分布式协调</p><p>ZooKeeper是一种集中式服务，用于维护配置信息，命名，提供分布式同步和提供组服务。所有这些类型的服务都以分布式应用程序的某种形式使用。每次实施它们都需要做很多工作来修复不可避免的错误和竞争条件。由于难以实现这些类型的服务，应用程序最初通常会吝啬它们，这使得它们在变化的情况下变得脆弱并且难以管理。即使正确完成，这些服务的不同实现也会在部署应用程序时导致管理复杂性</p><h4 id="1、ZooKeeper工作原理">1、ZooKeeper工作原理</h4><p>ZooKeeper功能：存储+监听</p><h4 id="2、ZooKeeper角色">2、ZooKeeper角色</h4><p>主从结构<br>1）Leader领导者-》主<br>2）Follower追随者-》从<br>3）ZooKeeper由一个领导者多个追随者组成<br>ZK集群中只要有半数以上的节点存活，zk集群就能正常工作。所以搭建ZK集群最好搭建<br>奇数台（3,5,11）</p><h4 id="3、ZooKeeper功能">3、ZooKeeper功能</h4><p>大数据中使用ZooKeeper业务<br>1）做统一的配置管理<br>2）做统一的命名服务<br>3）做统一的集群管理<br>4）做服务器的动态上下线感知（代码）</p><h4 id="4、单节点安装部署">4、单节点安装部署</h4><p>1）下载安装包</p><p>2）上传安装到linux<br>alt+p</p><p>3）解压<br>tar -zxvf zookeeper-3.4.10.tar.gz -C hd/</p><p>4）修改配置文件<br>重命名：mv zoo_sample.cfg zoo.cfg</p><p>5）创建文件夹zkData<br>添加到配置文件：zoo.cfg<br>dataDir=/root/hd/zookeeper-3.4.10/zkData</p><p>6）启动ZooKeeper<br>bin/zkServer.sh start</p><p>7）启动ZooKeeper客户端<br>bin/zkCli.sh</p><h4 id="5、ZooKeeper集群安装部署">5、ZooKeeper集群安装部署</h4><p>1）下载安装包</p><p>2）上传安装到linux<br>alt+p</p><p>3）解压<br>$ tar -zxvf zookeeper-3.4.10.tar.gz -C hd/</p><p>4）修改配置文件名<br>重命名：mv zoo_sample.cfg zoo.cfg<br>或者拷贝：cp zoo_sample.cfg zoo.cfg</p><p>5）修改配置<br>vi zookeeper-3.4.10/conf/zoo.cfg</p><p>dataDir=/root/hd/zookeeper-3.4.10/zkData</p><p>----------------zkconfig------------<br>server.1=hsiehchou121:2888:3888<br>server.2=hsiehchou122:2888:3888<br>server.3=hsiehchou123:2888:3888<br>server.4=hsiehchou124:2888:3888</p><p>创建文件<strong>myid</strong></p><p>添加服务器编号：1<br>[root@hsiehchou121 zookeeper-3.4.10]# cd zkData/<br>[root@hsiehchou121 zkData]# touch myid</p><h4 id="6）拷贝ZooKeeper到其它机器">6）拷贝ZooKeeper到其它机器</h4><p>scp -r zookeeper-3.4.10/ hsiehchou122:<code>$PWD</code><br>scp -r zookeeper-3.4.10/ hsiehchou123:<code>$PWD</code><br>scp -r zookeeper-3.4.10/ hsiehchou124:<code>$PWD</code></p><h4 id="7）注意需要修改每台机器的myid文件">7）注意需要修改每台机器的myid文件</h4><p>设置为当前的机器编号即可</p><h4 id="8）启动ZooKeeper集群">8）启动ZooKeeper集群</h4><p>bin/zkServer.sh start</p><h4 id="9）查看ZooKeeper状态">9）查看ZooKeeper状态</h4><p>bin/zkServer.sh status</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> ZooKeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据常用基本算法</title>
      <link href="/2019/02/18/da_shu_ju_chang_yong_ji_ben_suan_fa/"/>
      <url>/2019/02/18/da_shu_ju_chang_yong_ji_ben_suan_fa/</url>
      
        <content type="html"><![CDATA[<h4 id="1、冒泡排序">1、冒泡排序</h4><p>冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法，它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有<br>相邻元素需要交换，也就是说该元素已经排序完成这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“<strong>冒泡排序</strong>”</p><p>冒泡排序算法的原理如下：<br>1）比较相邻的元素。如果第一个比第二个大，就交换他们两个</p><p>2）对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数</p><p>3）针对所有的元素重复以上的步骤，除了最后一个</p><p>4）持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较</p><p>列如：<br>数组元素&gt;<br>5 1 7 2 6 4 3 16</p><p>1）由于第一个元素5比第二个元素大1，交换它们的位置。<br>1 5 7 2 6 4 3 16</p><p>2）对比每个相邻的元素，此时到第二个元素5与第三个元素7，不交换位置<br>1 5 7 2 6 4 3 16</p><p>3）对比每个相邻的元素，此时到第三个元素7与第四个元素2，交换位置<br>1 5 2 7 6 4 3 16</p><p>4）对比每个相邻的元素，此时到第四个元素7与第五个元素6，交换位置<br>1 5 2 6 7 4 3 16</p><p>5）对比每个相邻的元素，此时到第五个元素7与第六个元素4，交换位置<br>1 5 2 6 4 7 3 16</p><p>6）对比每个相邻的元素，此时到第六个元素7与第七个元素3，交换位置<br>1 5 2 6 4 3 7 16</p><p>7）对比每个相邻的元素，此时到第七个元素7与第八个元素16，不换位置<br>1 5 2 6 4 3 7 16</p><h4 id="2、双冒泡排序">2、双冒泡排序</h4><p>双向冒泡算法，极大的减少了循环排序的次数<br>1）传统冒泡气泡排序的双向进行，先让气泡排序由左向右进行，再来让气泡排序由右往左进行，如此完成一次排序的动作</p><p>2）使用left与right两个旗标来记录左右两端已排序的元素位置</p><p>3）当往左递进left &gt;=往右递进的 right时，则排序完成<br>例子如下所示：<br>排序前：45 19 77 81 13 28 18 19 77 11<br>往右排序：19 45 77 13 28 18 19 77 11 [81]<br>向左排序：[11] 19 45 77 13 28 18 19 77 [81]<br>往右排序：[11] 19 45 13 28 18 19 [77 77 81]<br>向左排序：[11 13] 19 45 18 28 19 [77 77 81]<br>往右排序：[11 13] 19 18 28 19 [45 77 77 81]<br>向左排序：[11 13 18] 19 19 28 [45 77 77 81]<br>往右排序：[11 13 18] 19 19 [28 45 77 77 81]<br>向左排序：[11 13 18 19 19] [28 45 77 77 81]<br>此时28&gt;=19条件成立排序完成</p><h4 id="3、快速排序">3、快速排序</h4><p>快速排序（Quicksort）是对冒泡排序的一种改进快速排序的基本思想：<br>首先选取一个记录作为枢(shu)轴，不失一般性，可选第一个记 录，依它的关键字为基准重排其余记录，将所有关键字比它大的记录都安置在它之后，而将所有关键字比它小的记录都安置在之前，由此完成一趟快速排序；之后，分别对由一趟排序分割成的两个子序列进行快速排序，在大数据情况下要使用快速排序</p><p>列如：<br>数组元素&gt;<br>5 1 7 2 6 4 3 16</p><p>思路：<br>取第一个数，把小于它的数往左移动，把大于它的数右移动<br>1）最左侧大于5的为7，最右侧小于5的为3,7与3对调<br>以5为枢轴&gt;<br>5 1 3 2 6 4 7 16</p><p>2）全部对调完成，此时左侧小于5，右边大于5<br>5 1 3 2 | 6 4 7 16</p><p>3）5移动到分割位置<br>1 3 2 5 6 4 7 16</p><p>4）如果把数组元素分为三部分的话 左侧&lt;中间&lt;右侧<br>1 3 2 | 5 | 6 4 7 16<br>此时只需对两侧再重复以上操作就可以了</p><p>5）重复以上操作<br>1 3 2 &gt;<br>1 2 3<br>此时左侧<br>6 4 7 16 &gt;<br>4 6 7 16<br>简单来说：定义基数，比它小的往左排，比它大的往右排</p><h4 id="4、归并排序">4、归并排序</h4><p><strong>归并排序（MERGESORT）</strong><br>是建立在归并操作上的一种有效的排序算法,该算法是采用<br>分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并</p><p>归并操作(merge)，也叫归并算法，指的是将两个顺序序列合并成一个顺序序列的方法<br>如 设有数列1 8 2 9 3 5 6 4 10</p><p>1）第一次归并后：{1 8},{2 9},{ 3 5},{ 4 6}，{10}此时两两元素排序完的归并</p><p>2）第二次归并后：{1 2 8 9}，{ 3 4 5 6} ，{10}此时两两元素归并<br>1与2 寻找最小数 1<br>8与2 寻找最小数 2<br>8与9寻找最小数 8<br>{1 2 8 9}</p><p>3）第三次归并后：{1 2 3 4 5 6 8 9} , {10}此时两两元素归并<br>1与3寻找到最小数1 {1}<br>2与3寻找最小数2 {1 2}<br>8与3寻找最小数3 {1 2 3}<br>8与4寻找最小数4 {1 2 3 4}<br>8与5寻找最小数5 {1 2 3 4 5}<br>8与6寻找最小数6 {1 2 3 4 5 6}<br>8 9 落下{1 2 3 4 5 6 8 9}<br>4）第四次归并后：{1 2 3 4 5 6 8 9 10}<br>思路：循环找到最小值落下</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据压缩、数据倾斜join操作</title>
      <link href="/2019/02/17/shu_ju_ya_suo_shu_ju_qing_xie_join_cao_zuo/"/>
      <url>/2019/02/17/shu_ju_ya_suo_shu_ju_qing_xie_join_cao_zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="1、数据压缩发生阶段">1、数据压缩发生阶段</h3><table><thead><tr><th style="text-align:center">端</th><th style="text-align:center">操作</th><th style="text-align:center">Col3</th></tr></thead><tbody><tr><td style="text-align:center">数据源</td><td style="text-align:center">》数据传输</td><td style="text-align:center">数据压缩</td></tr><tr><td style="text-align:center">mapper</td><td style="text-align:center">map端输出压缩</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">》数据传输</td><td style="text-align:center">数据压缩</td></tr><tr><td style="text-align:center">reducer</td><td style="text-align:center">reduce端输出压缩</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">》数据传输</td><td style="text-align:center">数据压缩</td></tr><tr><td style="text-align:center">结果数据</td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p><strong>设置map端输出压缩</strong><br>1）开启压缩<br>conf.setBoolean<br>//开启map端输出压缩<br>conf.setBoolean(“mapreduce.map.output.compress”,true);</p><p>2）设置具体压缩编码<br>conf.setClass<br>//设置压缩方式<br><a href="//conf.setClass">//conf.setClass</a>(“mapreduce.map.output.compress.codec”, BZip2Codec.class, CompressionCodec.class);</p><p>conf.setClass(“mapreduce.map.output.compress.codec”, DefaultCodec.class, CompressionCodec.class);</p><p><strong>设置reduce端输出压缩</strong><br>1）设置reduce输出压缩<br>FileOutputFormat.setCompressOutput</p><p>//设置reduce端输出压缩<br>FileOutputFormat.setCompressOutput(job,true);</p><p>2）设置具体压缩编码<br>FileOutputFormat.setOutputCompressorClass</p><p>//设置压缩方式<br><a href="//FileOutputFormat.setOutputCompressorClass">//FileOutputFormat.setOutputCompressorClass</a>(job,BZip2Codec.class);</p><p><a href="//FileOutputFormat.setOutputCompressorClass">//FileOutputFormat.setOutputCompressorClass</a>(job, GzipCodec.class);</p><p>FileOutputFormat.setOutputCompressorClass(job,DefaultCodec.class);<br>hive数据仓库：mapreduce 用hsql处理大数据</p><h3 id="2、压缩编码使用场景">2、压缩编码使用场景</h3><h4 id="1-Gzip压缩方式">1-&gt; Gzip压缩方式</h4><p>压缩率比较高，并且压缩解压缩速度很快<br>hadoop自身支持的压缩方式，用gzip格式处理数据就像直接处理文本数据是完全一样<br>的；<br>在linux系统自带gzip命令，使用很方便简洁<br>不支持split<br>使用每个文件压缩之后大小需要在128M以下（块大小）<br>200M-》设置块大小</p><h4 id="2-LZO压缩方式">2-&gt;LZO压缩方式</h4><p>压缩解压速度比较快并且，压缩率比较合理<br>支持split<br>在linux系统不可以直接使用，但是可以进行安装<br>压缩率比gzip和bzip2要弱，hadoop本身不支持<br>需要安装</p><h4 id="3-Bzip2压缩方式">3-&gt;Bzip2压缩方式</h4><p>支持压缩，具有很强的压缩率。hadoop本身支持<br>linux中可以安装<br>压缩解压缩速度很慢</p><h4 id="4-Snappy压缩方式">4-&gt;Snappy压缩方式</h4><p>压缩解压缩速度很快，而且有合理的压缩率<br>不支持split</p><h3 id="3、数据倾斜">3、数据倾斜</h3><p>reduce join<br>数据倾斜就是我们在计算数据的时候，数据的分散度不够，导致大量的数据集中到了一台或者几台机器上计算，这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢</p><h3 id="4、Hadoop中有哪些组件">4、Hadoop中有哪些组件</h3><p>HDFS：数据的分布式存储<br>MapReduce:数据的分布式计算<br>Yarn:资源调度(cpu/内存…)<br>Yarn节点：resourceManager、nodeManager</p><h3 id="5、优化">5、优化</h3><p>MapReduce程序的编写过程中考虑的问题<br>优化目的：提高程序运行的效率<br>优化方案：<br>存储和处理海量数据，如何优化MR<br>影响MR程序的因素<br>1）硬件<br>压缩<br>CPU/磁盘(固态、机械)/内存/网络…</p><p>2）I/O优化<br>传输<br>-》maptask与reducetask合理设置个数<br>-》数据倾斜（reducetask-》merge）<br>避免出现数据倾斜<br>-》大量小文件情况 （combineTextInputFormat）<br>-》combiner优化（不影响业务逻辑）</p><p>具体优化方式：<br>MR（数据接入、Map、Reduce、IO传输、处理倾斜、参数优化）<br>数据接入：小文件的话 进行合并 ，namenode存储元数据信息，sn<br>解决方式：CombineTextInputFormat</p><p>Map:会发生溢写，如果减少溢写次数也能达到优化<br>溢写内存增加这样就减少了溢写次数<br>解决方式：mapred-site.xml<br>属性：<br>mapreduce.task.io.sort.mb<br>100<br>调大</p><p>mapreduce.map.sort.spill.percent<br>0.8<br>调大</p><p>combiner:map后优化</p><p>Reduce:reduceTask设置合理的个数<br>写mr程序可以合理避免写reduce阶段<br>设置map/reduce共存<br>属性：<br>mapred-site.xml<br>mapreduce.job.reduce.slowstart.completedmaps<br>0.05<br>减少</p><p><strong>IO传输：压缩</strong><br>数据倾斜：避免出现数据倾斜，map端合并。手动的对数据进行分段处理，合理的<br>分区</p><p><strong>JVM重用</strong><br>不关JVM<br>一个map运行一个jvm,开启重用，在运行完这个map后JVM继续运行其它map。<br>线程池<br>属性：mapreduce.job.jvm.numtasks<br>20<br>启动40%运行时间</p><h3 id="6、进行两个表的拼接">6、进行两个表的拼接</h3><p><strong>DistributedCacheMapper类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mapjoin;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.BufferedReader;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStreamReader;import java.net.URI;import java.util.HashMap;/** * mapjoin * 完成两张表数据的关联操作 */public class DistributedCacheMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; {    HashMap&lt;String, String&gt; pdMap = new HashMap&lt;String, String&gt;();    @Override    protected void setup(Context context) throws IOException, InterruptedException {        //1.加载缓存文件        URI[] cacheFiles = context.getCacheFiles();        BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(cacheFiles[0].getPath()), "UTF-8"));        //这里可以将文件放在当前项目文件下，如果不放就用上面的那两句        //BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream("pd.txt"), "UTF-8"));        String line;        //2.判断缓存文件不为空        while(StringUtils.isNotEmpty(line = br.readLine())){            //切割数据            String[] fields = line.split("\t");            //缓冲 到 集合; 商品ID  商品名            pdMap.put(fields[0],fields[1]);        }        br.close();    }    @Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {        //1.获取数据        String line = value.toString();        //2.切分数据        String[] fields = line.split("\t");        //3.获取商品的pid,商品名称        String pid = fields[1];        String pName = pdMap.get(pid);        //4.拼接        line = line + "\t" + pName;        //5.输出        context.write(new Text(line),NullWritable.get());    }}</code></pre><p><strong>DistributedCacheDriver类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.mapjoin;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;import java.net.URI;import java.net.URISyntaxException;public class DistributedCacheDriver {    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException, URISyntaxException {      //创建job任务      Configuration conf = new Configuration();      Job job = Job.getInstance(conf);      //指定jar包位置      job.setJarByClass(DistributedCacheDriver.class);      //关联使用的Mapper      job.setMapperClass(DistributedCacheMapper.class);      //设置最终的输出的数据类型      job.setOutputKeyClass(Text.class);      job.setOutputValueClass(NullWritable.class);      //设置数据输入的路径      FileInputFormat.setInputPaths(job,new Path("e://test//table//in"));      //设置数据输出的路径      FileOutputFormat.setOutputPath(job,new Path("e://test//table//out"));      //加载缓存数据      job.addCacheFile(new URI("file:///e:/test/inputcache/pd.txt"));      //注意：没有跑reducer  需要指定reduceTask为0      job.setNumReduceTasks(0);      //提交任务      boolean rs = job.waitForCompletion(true);      System.exit(rs? 0:1);    }}</code></pre><p><strong>本地模式测试</strong><br>URI[] cacheFiles = context.getCacheFiles();<br>BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(cacheFiles[0].getPath()), “UTF-8”));</p><p><strong>集群模式时</strong><br>conf.set(“<a href="http://mapreduce.framework.name">mapreduce.framework.name</a>”, “yarn”);yarn模式<br>job.addCacheFile(new URI(“hdfs:///test2/pd.txt”));//添加hdfs文件做缓存</p>]]></content>
      
      
      <categories>
          
          <category> 大数据实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> combiner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据之排序、combiner、压缩</title>
      <link href="/2019/02/16/da_shu_ju_zhi_pai_xu_combiner_ya_suo/"/>
      <url>/2019/02/16/da_shu_ju_zhi_pai_xu_combiner_ya_suo/</url>
      
        <content type="html"><![CDATA[<h4 id="1、自定义分区">1、自定义分区</h4><p>需求：统计结果进行分区，根据手机号前三位来进行分区<br>总结：<br>1）自定义类继承partitioner&lt;key,value&gt;<br>2）重写方法getPartition()<br>3）业务逻辑<br>4）在driver类中加入<br>setPartitionerClass<br>5）注意：需要指定setNumReduceTasks(个数=分区数+1)</p><p><strong>新增PhonenumPartitioner类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs1;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Partitioner;/** * 自定义分区，根据手机号前三位 * 默认分区方式，hash */public class PhonenumPartitioner extends Partitioner&lt;Text, FlowBean&gt; {    @Override    public int getPartition(Text key, FlowBean value, int numPartitions) {        //1.获取手机号的前三位        String phoneNum = key.toString().substring(0, 3);        //2.分区        int partitioner = 4;        if ("135".equals(phoneNum)){            return 0;        }else if ("137".equals(phoneNum)){            return 1;        }else if ("138".equals(phoneNum)){            return 2;        }else if("139".equals(phoneNum)){            return 3;        }        return partitioner;    }}</code></pre><p><strong>FlowCountDriver类</strong>中增加</p><pre><code class="highlight plaintext">//加入自定义分区job.setPartitionerClass(PhonenumPartitioner.class);//注意，结果文件几个？job.setNumReduceTasks(5);//7.设置数据输入的路径FileInputFormat.setInputPaths(job, new Path("E:/test/flow/in"));//8.设置数据输出的路径FileOutputFormat.setOutputPath(job, new Path("E:/test/flow/out2"));</code></pre><h4 id="2、排序">2、排序</h4><p>需求：每个分区内进行排序？<br>总结：<br>1）实现WritableComparable接口<br>2）重写compareTo方法</p><p>combineTextInputFormat设置切片的大小 maptask</p><p>实现</p><p><strong>FlowBean类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs2;import org.apache.hadoop.io.WritableComparable;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;public class FlowBean implements WritableComparable&lt;FlowBean&gt; {    //定义属性：上行流量 下行流量 总流量总和    private long upFlow;    private long dfFlow;    private long flowsum;    public FlowBean(){}    public FlowBean(long upFlow,long dfFlow){        this.upFlow = upFlow;        this.dfFlow = dfFlow;        this.flowsum = upFlow + dfFlow;    }    public long getUpFlow(){        return upFlow;    }    public void setUpFlow(long upFlow){        this.upFlow = upFlow;    }    public long getDfFlow(){        return dfFlow;    }    public void setDfFlow(long dfFlow){        this.dfFlow = dfFlow;    }    public long getFlowsum(){        return flowsum;    }    public void setFlowsum(long flowsum){        this.flowsum = flowsum;    }    //序列化    public void write(DataOutput out) throws IOException {        out.writeLong(upFlow);        out.writeLong(dfFlow);        out.writeLong(flowsum);    }    //反序列化    public void readFields(DataInput in) throws IOException {        upFlow = in.readLong();        dfFlow = in.readLong();        flowsum = in.readLong();    }    @Override    public String toString() {        return upFlow + "\t" + dfFlow + "\t" + flowsum;    }    public int compareTo(FlowBean o) {        //倒序        return this.flowsum &gt; o.getFlowsum() ? -1:1;    }}</code></pre><p><strong>FlowSortMapper类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs2;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;public class FlowSortMapper extends Mapper&lt;LongWritable,Text,FlowBean,Text&gt; {    @Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {        //1.接入数据        String line = value.toString();        //2.切割 \t        String[] fields = line.split("\t");        //3.拿到关键字段:手机号 上行流量 下行流量        String phoneNr = fields[0];        long upFlow = Long.parseLong(fields[1]);        long dfFlow = Long.parseLong(fields[2]);        //4.写出到reducer        context.write(new FlowBean(upFlow,dfFlow),new Text(phoneNr));    }}</code></pre><p><strong>FlowSortReducer类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs2;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;public class FlowSortReducer extends Reducer&lt;FlowBean, Text, Text, FlowBean&gt; {    @Override    protected void reduce(FlowBean key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {        //手机号 流量        context.write(values.iterator().next(),key);    }}</code></pre><p><strong>FlowSortPartitioner类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs2;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Partitioner;public class FlowSortPartitioner extends Partitioner&lt;FlowBean, Text&gt; {    @Override    public int getPartition(FlowBean key, Text value, int numPartitions) {        //1.获取手机号的前三位        String phoneNum = value.toString().substring(0, 3);        //2.分区        int partitioner = 4;        if ("135".equals(phoneNum)){            return 0;        }else if ("137".equals(phoneNum)){            return 1;        }else if ("138".equals(phoneNum)){            return 2;        }else if("139".equals(phoneNum)){            return 3;        }        return partitioner;    }}</code></pre><p><strong>FlowSortDriver类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs2;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;public class FlowSortDriver {    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {        //1.创建job任务        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        //2.指定kjar包位置        job.setJarByClass(FlowSortDriver.class);        //3.关联使用的Mapper        job.setMapperClass(FlowSortMapper.class);        //4.关联使用的Reducer类        job.setReducerClass(FlowSortReducer.class);        //5.设置mapper阶段输出的数据类型        job.setMapOutputKeyClass(FlowBean.class);        job.setMapOutputValueClass(Text.class);        //6.设置reducer阶段输出的数据类型        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(FlowBean.class);        //加入自定义分区        job.setPartitionerClass(FlowSortPartitioner.class);        //注意，结果文件几个        job.setNumReduceTasks(5);        //7.设置数据输入的路径        FileInputFormat.setInputPaths(job, new Path("E:/test/flow/out"));        //8.设置数据输出的路径        FileOutputFormat.setOutputPath(job, new Path("E:/test/flow/out4"));        //9.提交任务        boolean  rs = job.waitForCompletion(true);        System.exit(rs? 0:1);    }}</code></pre><h4 id="3、combiner-合并">3、combiner 合并</h4><p>1）combiner是一个组件<br>注意：是Mapper和Reducer之外的一种组件<br>但是这个组件的父类是Reduer</p><p>2）如果想使用combiner继承Reduer即可</p><p>3）通过编写combiner发现与Reducer代码相同<br>只需在Driver端指定<br>setCombinerClass(WordCountReduer.class)<br>注意：前提是不能影响业务逻辑&lt;a,1&gt;&lt;c,1&gt; &lt;a,2&gt;&lt;a,1&gt; = &lt;a,3&gt;<br>数学运算：<br>(3 + 5 + 7)/3 = 5<br>(2 + 6)/2 = 4<br>不进行局部累加：（3 + 5 + 7 + 2 + 6）/5 = 23/5<br>进行了局部累加：（5+4）/2 = 9/2=4.5 不等于 23/5=4.6</p><h4 id="4、数据压缩">4、数据压缩</h4><p>为什么对数据进行压缩？<br>MapReduce操作需要对大量数据进行传输<br>压缩技术有效的减少底层存储系统读写字节数，HDFS<br>压缩提高网络带宽和磁盘空间效率<br>数据压缩节省资源，减少网络I/O</p><p>通过压缩可以影响到MapReduce性能。(小文件优化，combiner)代码角度进行优化</p><p>注意：利用好压缩提高性能，运用不好会降低性能<br>压缩 -》 解压缩</p><p><strong>mapreduce常用的压缩编码</strong></p><table><thead><tr><th style="text-align:center">压缩格式</th><th style="text-align:center">是否需要安装</th><th style="text-align:center">文件拓展名</th><th style="text-align:center">是否可以切分</th></tr></thead><tbody><tr><td style="text-align:center">DEFAULT</td><td style="text-align:center">直接使用</td><td style="text-align:center">.deflate</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">bzip2</td><td style="text-align:center">直接使用</td><td style="text-align:center">.bz2</td><td style="text-align:center">是</td></tr><tr><td style="text-align:center">Gzip</td><td style="text-align:center">直接使用</td><td style="text-align:center">.gz</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">LZO</td><td style="text-align:center">需要安装</td><td style="text-align:center">.lzo</td><td style="text-align:center">是</td></tr><tr><td style="text-align:center">Snappy</td><td style="text-align:center">需要安装</td><td style="text-align:center">.snappy</td><td style="text-align:center">否</td></tr></tbody></table><p><strong>性能测试</strong></p><table><thead><tr><th style="text-align:center">压缩格式</th><th style="text-align:center">原文件大小</th><th style="text-align:center">压缩后大小</th><th style="text-align:center">压缩速度</th><th style="text-align:center">解压速度</th></tr></thead><tbody><tr><td style="text-align:center">gzip</td><td style="text-align:center">8.3GB</td><td style="text-align:center">1.8GB</td><td style="text-align:center">20MB/s</td><td style="text-align:center">60MB/s</td></tr><tr><td style="text-align:center">LZO</td><td style="text-align:center">8.3GB</td><td style="text-align:center">3GB</td><td style="text-align:center">50MB/s</td><td style="text-align:center">70MB/s</td></tr><tr><td style="text-align:center">bzip2</td><td style="text-align:center">8.3GB</td><td style="text-align:center">1.1GB</td><td style="text-align:center">3MB/s</td><td style="text-align:center">10MB/s</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 大数据实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> HDFS </tag>
            
            <tag> combiner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据之MapReduce小实战</title>
      <link href="/2019/02/14/da_shu_ju_zhi_mapreduce_xiao_shi_zhan/"/>
      <url>/2019/02/14/da_shu_ju_zhi_mapreduce_xiao_shi_zhan/</url>
      
        <content type="html"><![CDATA[<h3 id="手写wordcount的程序">手写wordcount的程序</h3><h4 id="1、pom-xml">1、pom.xml</h4><pre><code class="highlight plaintext">&lt;dependencies&gt;  &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs-client --&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;          &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;          &lt;version&gt;2.7.3&lt;/version&gt;      &lt;/dependency&gt;  &lt;/dependencies&gt;</code></pre><h4 id="2、新建Mapper类">2、新建Mapper类</h4><pre><code class="highlight plaintext">package com.hsiehchou.wordcount;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * 海量数据 * * hello hsiehchou * nihao * * 数据的输入与输出以Key value进行传输 * keyIN:LongWritable(Long) 数据的起始偏移量 * valuewIN:具体数据 * * mapper需要把数据传递到reducer阶段（&lt;hello,1&gt;） * keyOut:单词 Text * valueOut:出现的次数IntWritable * */public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {    //对数据进行打散 ctrl+o    @Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {        //1、接入数据 hello nihao        String line = value.toString();        //2、对数据进行切分        String[] words = line.split(" ");        //3、写出以&lt;hello,1&gt;        for (String w:words){            //写出reducer端            context.write(new Text(w), new IntWritable(1));        }    }}</code></pre><p><strong>mapper端原理</strong></p><p><img src="../../mapper%E7%AB%AF%E5%8E%9F%E7%90%86.PNG" alt="mapper端原理"></p><h4 id="3、新建Reducer类">3、新建Reducer类</h4><pre><code class="highlight plaintext">package com.hsiehchou.wordcount;import org.apache.curator.framework.recipes.locks.InterProcessReadWriteLock;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;/** * reducer阶段接收的是Mapper输出的数据 * mapper的输出是reducer输入 * * keyIn:mapper输出的key的类型 * valueIn:mapper输出的value的类型 * * reducer端输出的数据类型，想要一个什么样的结果&lt;hello,1888&gt; * keyOut:Text * valueOut:IntWritalble * */public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {    //key--&gt;单词  value--&gt;次数    @Override    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {        //1、记录出现的次数        int sum = 0;        for (IntWritable v:values){            sum += v.get();        }        //2、l累加求和输出        context.write(key, new IntWritable(sum));    }}</code></pre><h4 id="4、新建驱动类">4、新建驱动类</h4><pre><code class="highlight plaintext">package com.hsiehchou.wordcount;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;public class WordCountDriver {    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {        //1、创建job任务        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        //2、指定jar包位置        job.setJarByClass(WordCountDriver.class);        //3、关联使用的Mapper类        job.setMapperClass(WordCountMapper.class);        //4、关联使用的Reducer类        job.setReducerClass(WordCountReducer.class);        //5、设置mapper阶段输出的数据类型        job.setMapOutputKeyClass(Text.class);        job.setMapOutputValueClass(IntWritable.class);        //6、设置reducer阶段输出的数据类型        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(IntWritable.class);        //7、设置数据输入的路径        FileInputFormat.setInputPaths(job, new Path(args[0]));        //8设置数据输出的路径        FileOutputFormat.setOutputPath(job, new Path(args[1]));        //9、提交任务        boolean rs = job.waitForCompletion(true);        System.exit(rs ? 0:1);    }}</code></pre><p>运行结果<br>[root@hsiehchou121 ~]# hadoop jar mapreduce-1.0-SNAPSHOT.jar com.hsiehchou.wordcount.WordCountDriver /wc/in /wc/out<br>[root@hsiehchou121 ~]# hdfs dfs -cat /wc/out/part-r-00000<br>fd  1<br>fdgs    1<br>fdsbv   1<br>gd  1<br>hello   3</p><h4 id="5、IDEA的相关使用">5、IDEA的相关使用</h4><p>Ctrl+O导入相关未实现的方法<br>Maven中的Lifecycle的package可以直接打包成jar</p><p>案例分析<br>需求：运营商流量日志<br>10086<br>计算每个用户当前使用的总流量<br>思路？总流量 = 上行流量+下行流量<br>三个字段：手机号 上行流量 下行流量<br>技术选型：PB+<br>数据分析：海量数据(存储hdfs)<br>海量数据计算(分布式计算框架MapReduce)</p><h4 id="4、实现">4、实现</h4><p><strong>FlowBean类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs;import org.apache.hadoop.io.Writable;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;/** * 封装数据类型需要怎么做 * hadoop数据类型实现了序列化接口 * 如果自定义需要实现这个序列化接口 */public class FlowBean implements Writable {    //定义属性：上行流量 下行流量 总流量总和    private long upFlow;    private long dfFlow;    private long flowsum;    public FlowBean(){}    public FlowBean(long upFlow, long dfFlow){        this.upFlow = upFlow;        this.dfFlow = dfFlow;        this.flowsum = upFlow + dfFlow;    }    public long getUpFlow(){        return upFlow;    }    public void setUpFlow(long upFlow){        this.upFlow = upFlow;    }    public long getDfFlow(){        return dfFlow;    }    public void setDfFlow(long dfFlow){        this.dfFlow = dfFlow;    }    public long getFlowsum(){        return flowsum;    }    public void setFlowsum(long flowsum){        this.flowsum = flowsum;    }    //序列化    public void write(DataOutput out) throws IOException {        out.writeLong(upFlow);        out.writeLong(dfFlow);        out.writeLong(flowsum);    }    //反序列化    public void readFields(DataInput in) throws IOException {        upFlow = in.readLong();        dfFlow = in.readLong();        flowsum = in.readLong();    }    @Override    public String toString() {        return upFlow + "\t" + dfFlow + "\t" + flowsum;    }}</code></pre><p><strong>FlowCountMapper类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * keyIN: * valueIN: * * 思路：根据想要的结果的kv类型  手机号  流量总和（上行+下行）自定义类 * keyOut: * valueOut: */public class FlowCountMapper extends Mapper&lt;LongWritable, Text, Text, FlowBean&gt; {    @Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {        //1、接入数据源        String line = value.toString();        //2、切割   \t        String[] fields = line.split("\t");        //3、拿到关键字段        String phoneNr = fields[1];        long upFlow = Long.parseLong(fields[fields.length - 3]);        long dfFlow = Long.parseLong(fields[fields.length - 2]);        //4、写出到reducer        context.write(new Text(phoneNr), new FlowBean(upFlow,dfFlow));    }}</code></pre><p><strong>FlowCountReducer类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;public class FlowCountReducer extends Reducer&lt;Text, FlowBean, Text, FlowBean&gt; {    @Override    protected void reduce(Text key, Iterable&lt;FlowBean&gt; values, Context context) throws IOException, InterruptedException {        long upFlow_sum = 0;        long dfFlow_sum = 0;        for (FlowBean v:values){            upFlow_sum += v.getUpFlow();            dfFlow_sum += v.getDfFlow();        }        FlowBean rsSum = new FlowBean(upFlow_sum, dfFlow_sum);        //输出结果        context.write(key, rsSum);    }}</code></pre><p><strong>FlowCountDriver类</strong></p><pre><code class="highlight plaintext">package com.hsiehchou.logs;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;public class FlowCountDriver {    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {        //1.创建job任务        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        //2.指定kjar包位置        job.setJarByClass(FlowCountDriver.class);        //3.关联使用的Mapper        job.setMapperClass(FlowCountMapper.class);        //4.关联使用的Reducer类        job.setReducerClass(FlowCountReducer.class);        //5.设置mapper阶段输出的数据类型        job.setMapOutputKeyClass(Text.class);        job.setMapOutputValueClass(FlowBean.class);        //6.设置reducer阶段输出的数据类型        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(FlowBean.class);        //优化含有大量小文件的数据        //设置读取数据切片的类        job.setInputFormatClass(CombineTextInputFormat.class);        //最大切片大小8M        CombineTextInputFormat.setMaxInputSplitSize(job, 8388608);        //最小切片大小6M        CombineTextInputFormat.setMinInputSplitSize(job, 6291456);        //7.设置数据输入的路径        FileInputFormat.setInputPaths(job, new Path(args[0]));        //8.设置数据输出的路径        FileOutputFormat.setOutputPath(job, new Path(args[1]));        //9.提交任务        boolean  rs = job.waitForCompletion(true);        System.exit(rs? 0:1);    }}</code></pre><p>运行结果<br>[root@hsiehchou121 ~]# hdfs dfs -mkdir -p /flow/in<br>[root@hsiehchou121 ~]# hdfs dfs -put HTTP_20180313143750.dat /flow/in<br>[root@hsiehchou121 ~]# hadoop jar mapreduce-1.0-SNAPSHOT.jar com.hsiehchou.logs.FlowCountDriver /flow/in /flow/out<br>[root@hsiehchou121 ~]# hdfs dfs -cat /flow/out/part-r-00000<br>13480253104    120       1320      1440<br>13502468823    735       11349     12084<br>13510439658    1116      954       2070<br>13560436326    1136      94        1230<br>13560436666    1136      94        1230<br>13560439658    918       4938      5856<br>13602846565    198       910       1108<br>13660577991    660       690       1350<br>13719199419    240       0         240<br>13726130503    299       681       980<br>13726238888    2481      24681     27162<br>13760778710    120       120       240<br>13822544101    264       0         264<br>13884138413    4116      1432      5548<br>13922314466    3008      3720      6728<br>13925057413    11058     4243      15301<br>13926251106    240       0         240<br>13926435656    132       1512      1644<br>15013685858    369       338       707<br>15889002119    938       380       1318<br>15920133257    316       296       612<br>18212575961    1527      2106      3633<br>18320173382    9531      212       9743</p><p><strong>小文件优化</strong></p><p>如果企业中存在海量的小文件数据<br>TextInputFormat按照文件规划切片，文件不管多小都是一个单独的切片，启动mapt<br>ask任务去执行，这样会产生大量的maptask，浪费资源</p><p><strong>优化手段</strong></p><p>小文件合并大文件，如果不动这个小文件内容</p>]]></content>
      
      
      <categories>
          
          <category> 大数据实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> HDFS </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据基础之HDFS3</title>
      <link href="/2019/02/12/da_shu_ju_ji_chu_zhi_hdfs3/"/>
      <url>/2019/02/12/da_shu_ju_ji_chu_zhi_hdfs3/</url>
      
        <content type="html"><![CDATA[<h4 id="1、hdfs的副本的配置">1、hdfs的副本的配置</h4><p>修改hdfs-site.xml文件</p><pre><code class="highlight plaintext">&lt;!-- 注释配置数据块的冗余度，默认是3 --&gt;&lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;!--注释配置HDFS的权限检查，默认是true--&gt;&lt;property&gt;    &lt;name&gt;dfs.permissions&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; &lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;hsiehchou122:50090&lt;/value&gt;&lt;/property&gt;</code></pre><p>需要同步到其它机器：<br>scp hdfs-site.xml hsiehchou122:<code>$PWD</code><br>scp hdfs-site.xml hsiehchou123:<code>$PWD</code><br>scp hdfs-site.xml hsiehchou124:<code>$PWD</code></p><p>这里我划重点(亲自经历)<br>如果原来的分布式hadoop集群的主节点有Secondary NameNode，需要配置到其他节点，因为如果主节点挂了，其也是挂了，它的作用是在HDFS中提供一个检查点，相当于NameNode的助手节点<br>职责是：合并NameNode的edit logs到fsimage文件中</p><h4 id="2、hadoop启动方式">2、hadoop启动方式</h4><p>1）启动hdfs集群<br><a href="http://start-dfs.sh">start-dfs.sh</a></p><p>2）启动yarn集群<br><a href="http://start-yarn.sh">start-yarn.sh</a></p><p>3）启动hadoop集群<br><a href="http://start-all.sh">start-all.sh</a></p><h4 id="3、大数据干什么的">3、大数据干什么的</h4><p>1）海量数据的存储(mysql/oracle)<br>分布式文件系统hdfs<br>dfs-&gt;Hdfs<br>mapreduce-&gt;mapreduce<br>bigtable-&gt;hbase<br>分而治之！</p><p>2）海量数据的计算<br>分布式计算框架mapreduce<br>配置checkpoint时间</p><pre><code class="highlight plaintext">&lt;property&gt;&lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;&lt;value&gt;7200&lt;/value&gt;&lt;/property&gt;</code></pre><p>systemctl set-default graphical.target由命令行模式更改为图形界面模式<br>systemctl set-default multi-user.target由图形界面模式更改为命令行模式</p><h4 id="4、hdfs-namenode工作机制">4、hdfs-namenode工作机制</h4><p>1）加载编辑日志与镜像文件到内存（NameNode）<br>edits_0001<br>edits_0002<br>fsimage fsimage fsimage</p><p>2）户端发起命令（client）<br>hdfs dfs -ls /</p><p>3）动正在写的edits（NameNode）</p><p>4）录操作日志更新 滚动日志（NameNode）</p><p>5）贝到Secondary NameNode<br>NameNode请求是否需要checkpoint</p><p>Secondary NameNode 触发checkpoint条件：<br>1）定时的时间<br>Secondary NameNode询问NameNode是否需要checkpoint<br>直接带回NameNode是否检查结果</p><p>2）edits中数据已满<br>Secondary NameNode请求执行checkpoint</p><p>3）NameNode滚动正在写的edits日志</p><p>4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode</p><p>5）Secondary NameNode加载编辑日志和镜像文件到内存，并行合并</p><p>6）生成新的镜像文件fsimage.checkpoint</p><p>7）拷贝fsimage.chkpoint到NameNode</p><p>8）NameNode对fsimage.checkpoint重命名成fsimage</p><h4 id="5、hadoop2-8-4安装部署">5、hadoop2.8.4安装部署</h4><p>1）准备工作<br>设置主机名：vi /etc/hostname<br>注意：需要重启 reboot<br>设置映射：vi /etc/hosts<br>设置免密登录：ssh-keygen<br>ssh-copy-id hsiehchou121</p><p>2）安装jdk<br>上传安装包<br>CRT:alt+p</p><p>解压<br>tar -zxvf .tar.gz</p><p>配置环境变量<br>export JAVA_HOME=/root/hd/jdk1.8.0_192<br>export PATH=<code>$JAVA_HOME/bin:$PATH</code></p><p>注意：需要source /etc/profile<br>分发jdk<br>scp jdk hsiehchou122:/root/hd<br>scp /etc/profile hsiehchou122:/etc/<br>source /etc/profile</p><p>3）安装hadoop<br>上传安装包<br>alt + p<br>解压<br>tar -zxvf .tar.gz<br>修改配置文件<br>core-site.xml</p><pre><code class="highlight plaintext">&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hsiehchou121:9000&lt;/value&gt;&lt;/property&gt;hdfs-site.xml&lt;property&gt;    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;    &lt;value&gt;/root/hd/dfs/name&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;    &lt;value&gt;/root/hd/dfs/data&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;hsiehchou122:50090&lt;/value&gt;&lt;/property&gt;mapred-site.xml&lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;yarn-site.xml&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;hsiehchou121&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="6、配置环境变量">6、配置环境变量</h4><p>export HADOOP_HOME=/root/hd/hadoop-2.8.4<br>export PATH=<code>$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</code><br>修改slaves文件加入从节点<br>格式化namenode<br>hadoop namenode -format<br>启动:start-all.sh</p><h4 id="7、hadoopMapReduce">7、hadoopMapReduce</h4><p>官方：Apache™Hadoop®项目开发了用于可靠，可扩展的分布式计算的开源软件<br>Apache Hadoop软件库是一个框架，允许使用简单的编程模型跨计算机集群分布式处理 大型数据集。它旨在从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和 存储。该库本身不是依靠硬件来提供高可用性，而是设计用于检测和处理应用层的故 障，从而在计算机集群之上提供高可用性服务，每个计算机都可能容易出现故障<br>阿里的Flink（9000万欧元） Blink</p><p>MapReduce分布式计算程序的编程框架。基于hadoop的数据分析的应用<br>MR优点：<br>1)框架易于编程<br>2)可靠容错（集群）<br>3)可以处理海量数据（1T+ PB+） 1PB = 1024TB<br>4)拓展性，可以通过动态的增减节点来拓展计算能力</p><h4 id="8、MapReduce的思想">8、MapReduce的思想</h4><p>数据:海量单词<br>hello reba<br>hello mimi<br>hello liya<br>mimi big<br>需求：对每个单词出现的次数统计出来<br>思想：分而治之！<br>解决方式：<br>1）每个单词记录一次(map阶段)<br>&lt;hello,1&gt; &lt;reba,1&gt; &lt;hello,1&gt; &lt;mimi,1&gt;</p><p>2）相同单词的key不变，value累加求和即可（reduce阶段）<br>&lt;hello,1+1+1&gt;<br>对数据进行计算</p><h4 id="9、对wordcount例子程序分析">9、对wordcount例子程序分析</h4><p>1）整个wordcount分为几个阶段？<br>三个</p><p>2）有哪几个阶段？<br>mapper<br>reducer<br>driver</p><p>3）每个阶段有什么作用<br>mapper:对数据进行打散&lt;hello,1&gt;&lt;mimi,1&gt;<br>reducer:对数据进行聚合&lt;hello,1+1+1&gt;<br>driver:提交任务</p><p>4）详解</p><p><strong>Mapper阶段</strong></p><p>将数据转换为String<br>对数据进行切分处理<br>把每个单词后加1<br>输出到reducer阶段</p><p>Reducer阶段<br>根据key进行聚合<br>输出key出现总的次数</p><p>Driver阶段<br>创建任务<br>关联使用的Mapper/Reducer类<br>指定mapper输出数据的kv类型<br>指定reducer输出的数据的kv类型<br>指定数据的输入路径与输出路径<br>提交</p><h4 id="10、hadoop数据类型">10、hadoop数据类型</h4><p>我们看到的wordcount程序中的泛型中的数据类型其实是hadoop的序列化的数据类<br>型<br>为什么要进行序列化？用java的类型行不行？（可以）<br>Java的序列化:Serliazable太重<br>hadoop自己开发了一套序列化机制。Writable，精简高效。海量数据<br>hadoop序列化类型与Java数据类型</p><table><thead><tr><th style="text-align:center">Java数据类型</th><th style="text-align:center">Hadoop序列化类型</th></tr></thead><tbody><tr><td style="text-align:center">int</td><td style="text-align:center">IntWritable</td></tr><tr><td style="text-align:center">long</td><td style="text-align:center">LongWritable</td></tr><tr><td style="text-align:center">boolean</td><td style="text-align:center">BooleanWritable</td></tr><tr><td style="text-align:center">byte</td><td style="text-align:center">ByteWritable</td></tr><tr><td style="text-align:center">float</td><td style="text-align:center">FloatWritable</td></tr><tr><td style="text-align:center">double</td><td style="text-align:center">DoubleWritable</td></tr><tr><td style="text-align:center">String</td><td style="text-align:center">Text</td></tr></tbody></table><h4 id="11、wordcount测试">11、wordcount测试</h4><p>1）本地模式<br>2）集群模式<br>hadoop jar .jar wordcount /wc/in /wc/out</p><p>hadoop jar mapreduce-1.0-SNAPSHOT.jar 全类名 /wc/in /wc/out</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据基础之HDFS2</title>
      <link href="/2019/02/09/da_shu_ju_ji_chu_zhi_hdfs2/"/>
      <url>/2019/02/09/da_shu_ju_ji_chu_zhi_hdfs2/</url>
      
        <content type="html"><![CDATA[<h4 id="1、HDFS下载文件原理">1、HDFS下载文件原理</h4><p>1、请求<br>2、创建client<br>DFS –&gt;DFSClient<br>3、建立RPC通信<br>4、得到代理对象proxy，通过代理对象请求得到文件元信息<br>5、查找元信息<br>6、返回元信息<br>7、创建输入流<br>8、下载数据块<br>FSDataInputStream<br>9、整合下载文件</p><p>注意：HDFS维护失败列表</p><h4 id="2、安全模式-safe-mode">2、安全模式 safe mode</h4><p>检查副本率是否满足配置要求。副本率不够的时候，会水平复制，当下次那个挂掉的节点如果又活过来的话，副本数就会超过N了，就超了，系统会自动选一个多余的副本删掉<br>（1）冗余度：dfs.replication 3.有几个冗余的副本<br>hdfs-site.xml</p><pre><code class="highlight plaintext">&lt;!--注释配置数据块的冗余度，默认是3--&gt;&lt;property&gt;       &lt;name&gt;dfs.replication&lt;/name&gt;       &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;</code></pre><p>（2）副本率：数据块实际冗余度（M），HDFS配置的数据块应该具有的冗余度（N）<br>M/N*100%;<br>例如：知否知否.avi M=2；HDFS配置的 N=3；<br>2/3=0.667。要求的副本率为 0.99，系统会水平复制数据块到其他节点<br>如果是副本率过高，M=6，N=3，副本率=2；大于0.99.系统会删除多余的数据块<br>在安全模式下 无法操作HDFS，因为正在进行副本率的检查工作<br>进入或查看安全模式的命令：<br>hdfs dfsadmin -safemode get/enter/leave/wait</p><h4 id="3、快照：是一种备份，默认：HDFS快照是关闭">3、快照：是一种备份，默认：HDFS快照是关闭</h4><p>一般不建议使用<br>快照的本质：将需要备份的数据放到一个隐藏目录下<br>（1）开启和关闭快照<br>hdfs dfsadmin -allowSnapshot <code>&lt;snapshotDir&gt;</code><br>hdfs dfsadmin -disallowSnapshot<br>hdfs lsSnapshottableDir //查看开启快照的所有文件夹</p><p>（2）创建快照<br>需要创建快照的目录 快照目录的名字<br>hdfs dfs -createSnapshot /test1 backup_test1_20190216<br>快照打出的日志：<br>Created snapshot /test1/.snapshot/backup_test1_20190216</p><p>（3）删除快照<br>hdfs dfs -deleteSnapshot /test1 backupt1_test1_20190216</p><p>（4）恢复快照<br>hdfs dfs -cp /test1/.snapshot/backup_test1_20190216/a.txt /test1</p><h4 id="4、回收站：默认HDFS的回收站禁用">4、回收站：默认HDFS的回收站禁用</h4><p>（1）回收站的配置：<br>core-site.xml fs.trash.interval(时间间隔 分钟)<br>关闭集群后才能起作用</p><pre><code class="highlight plaintext">&lt;!--配置回收站，单位是分钟，默认是0--&gt;&lt;property&gt;    &lt;name&gt;fs.trash.interval&lt;/name&gt;    &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt;</code></pre><p>（2）本质是剪切：回收站开启之后，会把删除的文件放到一个/user/root/.Trash/Current<br>（3）回收站恢复也就是粘贴的过程<br>hdfs dfs -cp /user/root/.Trash/Current /</p><h4 id="5、配额：Quota">5、配额：Quota</h4><p>（1）名称配额<br>限定HDFS目录下，存放文件（目录）的个数&gt;1，最多存放N-1个<br>setQuota–指定名称配额<br>clrQuota–清除名称配额<br>例如：<br>hdfs dfs -mkdir /myquota1<br>hdfs dfsadmin -setQuota 3 /myquota1<br>hdfs dfs -put ~/a.txt /myquota1—-第1个<br>hdfs dfs -put ~/student01.txt /myquota1–第2个<br>hdfs dfs -put ~/students01.txt /myquota1—第3个 无法放<br>错误：put: The NameSpace quota (directories and files) of directory /myquota1 is exceeded: quota=3 file count=4</p><p>（2）空间配额 –必须要大于 默认数据块大小<br>setSpaceQuota<br>clrSpaceQuota</p><h4 id="6、HDFS底层原理-RPC">6、HDFS底层原理-RPC</h4><p>Remote Procedure Call：远程过程调用，调用代码不在本地执行，实现调用者与被调用者之间的连接和通信</p><p>基于Client server，相当于 DFSClient 相当于客户端。NameNode集群相当于Server</p><h4 id="7、HDFS底层原理-代理对象Proxy">7、HDFS底层原理-代理对象Proxy</h4><p>（1）代理—明星的经纪人<br>是一种设计模式，提供了对目标对象的另一种访问方式。通过代理对象访问目标对象<br>（2）代理分为静态代理和动态代理<br>a、静态代理：接口的定义 实现接口，被代理对象与对象实现相同的接口<br>b、动态代理：接口的定义 不需要实现接口（匿名内部类+反射 invoke）</p><h4 id="8、RPC与Proxy程序示例">8、RPC与Proxy程序示例</h4><p>针对log4j warn<br>log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).<br>log4j:WARN Please initialize the log4j system properly.<br>log4j:WARN See <a href="http://logging.apache.org/log4j/1.2/faq.html#noconfig">http://logging.apache.org/log4j/1.2/faq.html#noconfig</a> for more info.<br>可以在src/resource/通过 增加 log4j.properties解决</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据基础之HDFS1</title>
      <link href="/2019/02/07/da_shu_ju_ji_chu_zhi_hdfs1/"/>
      <url>/2019/02/07/da_shu_ju_ji_chu_zhi_hdfs1/</url>
      
        <content type="html"><![CDATA[<h4 id="1、免密码登录的原理和配置">1、免密码登录的原理和配置</h4><p>ssh不对称加密算法（加密和解密是两个文件）（对称加密： 加密和解密文件是同一个）<br>（1）公钥–锁：给出去 给其他机器<br>（2）私钥–钥匙：自己留着，解密<br>step1:ssh-keygen -t rsa(3次回车)<br>step2:ssh-copy-id -i ~/.ssh/id_rsa.pub root@hsiehchou121(自己也要拷贝给自己)</p><h4 id="2、Hadoop安装—全分布模式-（重点）">2、Hadoop安装—全分布模式 （重点）</h4><p>（1）规划：<br>192.168.116.121 hsiehchou121 ：主节点<br>192.168.116.122 hsiehchou122 ：从节点<br>192.168.116.123 hsiehchou123 ：从节点<br>192.168.116.124 hsiehchou124 ：从节点</p><p>（2）准备工作:<br>step 1: jdk、防火墙、ssh免密码登录（3次拷贝）、在etc/hosts 添加主机名<br>对于同时操作多台机器可通过 工具-》发送键输入到所有会话 在选项卡排列 实现 水平排列</p><p>step 2:时间同步（如果能够上网） 使用网络时间（GUI设置）默认的都是一致的<br>不能上网： date -s 2019-01-10(同时操作多台机器) 集群紊乱<br>ntp：在机器里面指定一个服务器 作为时钟服务器</p><p>step 3: 修改配置文件</p><p>主要在hsiehchou 121操作，其他机器通过scp拷贝</p><h4 id="3、slaves-和自己的从节点机器名字一致">3、slaves(和自己的从节点机器名字一致)</h4><p>hsiehchou122<br>hsiehchou123<br>hsiehchou124</p><h4 id="4、通过hdfs-namenode-格式化">4、通过hdfs namenode 格式化</h4><p>hdfs namenode -format<br>成功的标志： Storage directory /opt/module/hadoop-2.7.3/tmp/dfs/name has been successfully formatted</p><h4 id="5、通过scp拷贝">5、通过scp拷贝</h4><p>scp -r /opt/module/hadoop-2.7.3/ root@hsiehchou122:/opt/module/<br>scp -r /opt/module/hadoop-2.7.3/ root@hsiehchou123:/opt/module/<br>scp -r /opt/module/hadoop-2.7.3/ root@hsiehchou124:/opt/module/<br>学会看 vi /opt/module/hadoop-2.7.3/logs/hadoop-root-datanode-hsiehchou123.log<br>Shift+G 看启动日志<br>hdfs体系架构（Yarn资源放在后面）</p><h4 id="6、HDFS-NameNode：名称节点">6、HDFS-NameNode：名称节点</h4><p>（1）职责：对HDFS的节点进行管理，管理员<br>接收客户端（命令行、Java）的请求：创建目录、上传数据、下载数据和删除数据<br>管理和维护hdfs的日志和元信息</p><p>（2）dfs/name:<br>a、current：主要存放日志和元信息 存贮路径：/opt/module/hadoop-2.7.3/tmp/dfs/name/current<br>edits文件：二进制文件，体现了hdfs的最新状态</p><p>hdfs oev -i edits_inprogress_0000000000000000003 -o ~/a.xml<br>o:表示 offline<br>inprogress:表示最新的</p><pre><code class="highlight plaintext">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;EDITS&gt;  &lt;EDITS_VERSION&gt;-63&lt;/EDITS_VERSION&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_START_LOG_SEGMENT&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;4&lt;/TXID&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;  &lt;RECORD&gt;    &lt;OPCODE&gt;OP_MKDIR&lt;/OPCODE&gt;    &lt;DATA&gt;      &lt;TXID&gt;5&lt;/TXID&gt;      &lt;LENGTH&gt;0&lt;/LENGTH&gt;      &lt;INODEID&gt;16386&lt;/INODEID&gt;      &lt;PATH&gt;/input&lt;/PATH&gt;      &lt;TIMESTAMP&gt;1550209288319&lt;/TIMESTAMP&gt;      &lt;PERMISSION_STATUS&gt;        &lt;USERNAME&gt;root&lt;/USERNAME&gt;        &lt;GROUPNAME&gt;supergroup&lt;/GROUPNAME&gt;        &lt;MODE&gt;493&lt;/MODE&gt;      &lt;/PERMISSION_STATUS&gt;    &lt;/DATA&gt;  &lt;/RECORD&gt;&lt;/EDITS&gt;</code></pre><p>b、元信息文件 fsimage：记录的数据块的位置信息和数据块冗余信息，没有体现hdfs的最新状态，二进制文件</p><p>hdfs oiv -i fsimage_0000000000000000002 -o ~/b.xml -p XML</p><p>（3）in_use.lock 避免同一文件被多使用，只能启动一个namenode</p><h4 id="7、hdfs-DataNode：数据节点">7、hdfs-DataNode：数据节点</h4><p>（1）主要用来进行数据的存储<br>1.x 64M<br>2.x 128M( hdfs-site.xml 可以修改 blocksize)</p><p>（2）数据块的表现形式就是一个个的blk文件<br>位置：/opt/module/hadoop-2.7.3/tmp/dfs/data/current/BP-298124919-192.168.116.121-1550208140930 ###/current/finalized/subdir0/subdir0<br>尝试上传一个 大于128M的文件（128<em>1024</em>1024）<br>Hadoop 3.x 有 纠删码技术，节约存储空间</p><h4 id="8、上传文件">8、上传文件</h4><p>首先创建文件夹<br>hdfs dfs -mkdir /software/input<br>上传我本地文件到hdfs上<br>hdfs dfs -put hdfs dfs -put /opt/software/hadoop-2.7.3.tar.gz /software/input<br>就OK了<br>之后可以使用上面的命令查看</p><h4 id="9、hdfs-SecondaryNameNode：第二名称节点">9、hdfs-SecondaryNameNode：第二名称节点</h4><p>（1）进行日志信息的合并，根据checkpoint或者时间间隔（3600s）或者edits文件达到64M</p><p>（2）edits文件合并到fsimage里面 edits文件可以清空<br>看日志<br>/opt/moudle/hadoop-2.7.3/logs vi shift+G</p><h4 id="10、hdfs-Web-Console">10、hdfs-Web Console</h4><p>hdfs dfsadmin -report<br><a href="http://192.168.116.125:50070/dfshealth.html#tab-overview">http://192.168.116.125:50070/dfshealth.html#tab-overview</a></p><p>（1） Overview–展示hdfs的基本信息<br>Safemode is off.—高级特性</p><p>（2）DataNodes-数据节点信息<br>增加和删除数据节点（Decomissioning–&gt;Dead）</p><p>（3）Datanode Volume Failures–数据节点 硬件错误</p><p>（4）Snapshot（快照）—高级特性<br>快照实现数据的备份，防止数据的误操作和丢失。默认是关闭的</p><p>（5）Startup Progress–启动过程</p><p>（6）Uitlities:<br>Browse 文件 —hdfs -dfs -ls /<br>logs—查看日志</p><h4 id="11、hdfs-普通操作命令–hdfs-dfs-hadoop-dfs">11、hdfs 普通操作命令–hdfs dfs(hadoop dfs)</h4><p>（1）创建目录–mkdir<br>hdfs dfs -mkdir /</p><p>（2）查看–ls<br>查看目录和子目录 hdfs dfs -ls -R /<br>hdfs dfs -lsr /</p><p>（3）上传数据<br>hdfs dfs -put hadoop-root-namenode-hsiehchou125.log /test1<br>-put ：<br>-copyFromLocal： 本地路径 hdfs路径<br>hdfs dfs -copyFromLocal ~/temp/a.txt /test0113/<br>-moveFromLocal: 会删除本地文件 剪切</p><p>（4）下载数据<br>-get:<br>-copyToLocal:从hdfs下载到本地</p><p>（5）删除数据<br>-rm<br>-rmr: 删除hdfs的目录和子目录<br>删除日志： Deleted /test1<br>回收站—高级特性 默认是关闭</p><p>（6）合并数据–（为hive表数据操作做准备）<br>-getmerge :hdfs 把某个hdfs的目录下的文件进行先合并后下载<br>*：通配符 ？<br>hdfs dfs -getmerge /students /root/students.txt</p><p>（7）计数和文件大小<br>-count 显示 文件夹、文件个数 文件总的大小<br>-du 显示每个文件夹和文件的大小<br>[root@hsiehchou125 ~]# hdfs dfs -count /students<br>1 4 38/students<br>hdfs[root@hsiehchou125 ~]# hdfs dfs -du /students<br>25 /students/students01.txt<br>13 /students/students02.txt</p><p>（8）负载均衡 balancer<br>实现DataNode 数据存储均衡</p><p><code>##hdfs balancer ##</code></p><h4 id="12、hdfs-管理员命令">12、hdfs 管理员命令</h4><p>（1）hdfs dfsadmin -report 打印报告</p><p>（2） -safemode &lt;enter | leave | get | wait&gt;<br>enter:手动进入安全模式<br>leave:手动离开安全模式<br>get:获得当前安全模式的状态<br>hdfs dfsadmin -safemode get<br>[root@hsiehchou125 ~]# hdfs dfsadmin -safemode enter<br>Safe mode is ON</p><p>（3）快照命令<br>[-allowSnapshot <code>&lt;snapshotDir&gt;</code>]<br>[-disallowSnapshot <code>&lt;snapshotDir&gt;</code>]</p><p>（4）Quota 配额<br>a、名称配额–数量<br>[-setQuota <code>&lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;</code>]<br>[-clrQuota <code>&lt;dirname&gt;...&lt;dirname&gt;</code>]</p><p>b、空间配额–空间大小</p><p>[-setSpaceQuota <code>&lt;quota&gt;</code> [-storageType <code>&lt;storagetype&gt;</code>] <code>&lt;dirname&gt;...&lt;dirname&gt;</code>]<br>[-clrSpaceQuota [-storageType <code>&lt;storagetype&gt;</code>] <code>&lt;dirname&gt;...&lt;dirname&gt;</code>]</p><h4 id="13、IDEA-Maven工程简介">13、IDEA Maven工程简介</h4><p>（1）IDEA 下载地址：<br><a href="https://www.jetbrains.com/idea/download/">https://www.jetbrains.com/idea/download/</a><br>破解方法自行查找</p><p>（2）File-new Project-&gt;Maven<br>GroupID: 公司名字<br>artifactId：工程名字<br>java程序在：src-》main-&gt;java 右键 新建 java class文件<br>target: 是运行程序生成的class文件</p><p>（3）管理包<br>/opt/moudle/hadoop-2.7.3/share/hadoop/common/<em>.jar<br>/opt/moudle/hadoop-2.7.3/share/hadoop/common/lib/</em>.jar<br>/opt/moudle/hadoop-2.7.3/share/hadoop/hdfs/<em>.jar<br>/opt/moudle/hadoop-2.7.3/share/hadoop/hdfs/lib/</em>.jar<br>通过maven只需要配置POM文件<br>a、 下载一个maven版本<br><a href="http://maven.apache.org/index.html">http://maven.apache.org/index.html</a></p><p>b、通过 File-settings-Maven<br>修改： E:\apache-maven-3.6.0\conf\settings.xml<br>55行：<br><code>&lt;localRepository&gt;</code>E:\Maven\m2\Repository<code>&lt;/localRepository&gt;</code><br>MaveHome：E:\apache-maven-3.6.0<br>User settings:E:\apache-maven-3.6.0\conf\settings.xml</p><p>c、POM中写入包的依赖<br>参考：<a href="https://mvnrepository.com/search?q=hadoop">https://mvnrepository.com/search?q=hadoop</a></p><pre><code class="highlight plaintext">&lt;dependencies&gt;      &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;          &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;          &lt;version&gt;2.7.3&lt;/version&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;          &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;          &lt;version&gt;2.7.3&lt;/version&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;          &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;          &lt;version&gt;2.7.3&lt;/version&gt;      &lt;/dependency&gt;  &lt;/dependencies&gt;</code></pre><h4 id="14、文件夹的创建">14、文件夹的创建</h4><pre><code class="highlight plaintext">import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import java.io.IOException;public class hdfsMkDir {public static void main(String[] args) throws IOException {System.setProperty("HADOOP_USER_NAME","root");//step1 配置参数，指定namenode地址Configuration conf = new Configuration();conf.set("fs.defaultFS","hdfs://192.168.116.125:9000");//step2 创建客户端FileSystem client = FileSystem.get(conf);//step3 创建目录client.mkdirs(new Path("/test2"));client.close();System.out.println("Successful");   }}</code></pre><h4 id="15、hdfs权限问题">15、hdfs权限问题</h4><p>针对用户操作没有权限 permission denied：<br>（1）修改 hdfs-site.xml 去掉权限检查（关闭hdfs服务 <a href="http://stop-all.sh">stop-all.sh</a>;修改后 重新 <a href="http://Start-all.sh">Start-all.sh</a>）</p><pre><code class="highlight plaintext">&lt;property&gt;    &lt;name&gt;dfs.permissions&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;</code></pre><p>（2）通过设定用户名字 rootSystem.setProperty(“HADOOP_USER_NAME”,”root”);</p><p>（3）通过java的-D参数传递。 HADOOP_USER_NAME=root （命令行的方式）<br>public static void main(String[] args)</p><p>Java -D命令对应的代码中获取-D后面的参数 和 多个参数时-D命令的使用</p><p>Java代码：</p><pre><code class="highlight plaintext">public class DP {public static void main(String[] args) {  String fg = System.getProperty("P");  System.err.println(fg);    }}</code></pre><p>cmd命令：<br>java -DP=hdfshdfs DP</p><p>执行命令后输出：hdfshdfs<br>注意：-D和Para之间不能有空格</p><p>使用多个参数，如P、P1</p><pre><code class="highlight plaintext">public class DP {public static void main(String[] args) {String fg = System.getProperty("P");System.out.println(fg);String fg1 = System.getProperty("P1");System.out.println(fg1);    }}</code></pre><p>java -DP=hdfshdfs -DP1=1212 DP<br>执行命令后输出：<br>hdfshdfs<br>1212</p><p>（4）hdfs dfs -chmod 777 /input 让所有用户访问</p><p>（5）针对hdfs权限问题，有kerberos认证<br>Kerberos: The Network Authentication Protocol<br><a href="https://www.cnblogs.com/wukenaihe/p/3732141.html">https://www.cnblogs.com/wukenaihe/p/3732141.html</a></p><h4 id="16、IDEA-Maven工程实现hdfs的文件上传与下载">16、IDEA Maven工程实现hdfs的文件上传与下载</h4><p>Maven环境中 只有当 POM文件中所有的依赖包全部变成白色<br>pom.xml</p><pre><code class="highlight plaintext">&lt;dependencies&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;            &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;            &lt;version&gt;2.7.3&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;            &lt;version&gt;2.7.3&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;            &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;            &lt;version&gt;2.7.3&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;            &lt;artifactId&gt;hadoop-core&lt;/artifactId&gt;            &lt;version&gt;1.2.1&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;</code></pre><p>（1）hdfs文件上传<br>查看源码：crtl+鼠标左键<br><code>## Failed to locate the winutils binary in the hadoop binary path java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries. ## </code><br>step1:<br>下载：hadoop2.7.3 winutils binary<br><a href="https://github.com/rucyang/hadoop.dll-and-winutils.exe-for-hadoop2.7.3-on-windows_X64">https://github.com/rucyang/hadoop.dll-and-winutils.exe-for-hadoop2.7.3-on-windows_X64</a></p><p>step2: 配置环境变量 拷贝进入 D:\hadoop-2.7.3\bin文件下<br>hadoop.home.dir —bin/winutils.exe<br>HADOOP_HOME:D:\hadoop-2.7.3,然后再path里面增加 %HADOOP_HOME%\bin<br>或者：System.setProperty(“hadoop.home.dir”, “D:\hadoop-2.7.3”);</p><pre><code class="highlight plaintext">import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IOUtils;import java.io.*;public class hdfsUpload {    public static void main(String[] args) throws IOException {        System.setProperty("HADOOP_USER_NAME","root");        //System.setProperty("hadoop.home.dir","E:\\hadoop-2.7.3");        //step1 建立客户端        Configuration conf = new Configuration();        conf.set("fs.defaultFS","hdfs://192.168.116.125:9000");        //使用IP地址  因为没有指定hsiehchou125对应的IP        FileSystem client = FileSystem.get(conf);        //step2 创建本地数据 hdfs dfs -put copyFromLocal        File file1 = new File("C:\\Users\\hsiehchou\\Desktop\\hadooplibs\\test.txt");        InputStream input = new FileInputStream(file1);//多态        //step3 创建本地输出流 指向hdfs        OutputStream output = client.create(new Path("/test8/a.txt"),true);        //step4 开始写入hdfs        /**方法1**///        byte[] buffer = new byte[1024];//        int len = 0;//        //因为read 当读到文件末尾的时候 会返回-1//        while((len=input.read(buffer)) != -1){//            output.write(buffer, 0, len);//        }//循环写入数据//        output.flush();//        input.close();//        output.close();        /**方法2 IOUtils**/        IOUtils.copyBytes(input,output,1024);    }}</code></pre><p>（2）hdfs文件下载<br><code>### 使用IOUtils 输入路径 输出路径### </code><br>IOUtils.copyBytes(input,output,1024);</p><pre><code class="highlight plaintext">import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IOUtils;import java.io.*;public class hdfsDownload {    public static void main(String[] args) throws IOException {        System.setProperty("HADOOP_USER_NAME","root");        //step1 建立客户端        Configuration conf = new Configuration();        conf.set("fs.defaultFS","hdfs://192.168.116.125:9000");        //使用IP地址  因为没有指定hsiehchou125对应的IP        FileSystem client = FileSystem.get(conf);        //step2 创建数据输入 指向hdfs  从hdfs读取数据  hdfs dfs -get copyToLocal        InputStream input = client.open(new Path("/test8/a.txt"));        //step3 创建本地输出流 指向hdfs        OutputStream output = new FileOutputStream("E:\\test\\b.txt");        //step4 开始写入hdfs        /**IOUtils**/        IOUtils.copyBytes(input,output,1024);    }}</code></pre><p>文件元信息</p><pre><code class="highlight plaintext">{ 文件名: *.txt 路径: /text 大小: 100KB 冗余度: 3 数据块1: DNS1,DNS2,DNS3 (如果文件大切分) }</code></pre><h4 id="17、hdfs上传文件原理">17、hdfs上传文件原理</h4><p>1、请求上传数据<br>2、创建客户端<br>3、建立RPC通信<br>4、NameNode对象<br>代理对象NameNodeProxies<br>5、请求创建文件元信息<br>6、创建文件元信息<br>7、缓存文件元信息(1000M)<br>8、返回元信息<br>9、根据元信息创建输出流<br>10、上传第一个数据块<br>11、数据块自动复制<br>12、循环上传</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
            <tag> HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据基础2</title>
      <link href="/2019/02/05/da_shu_ju_ji_chu_2/"/>
      <url>/2019/02/05/da_shu_ju_ji_chu_2/</url>
      
        <content type="html"><![CDATA[<h4 id="1、什么是大数据？">1、什么是大数据？</h4><p>2002 大数据提出 美国引入。—麦肯锡报告<br>维克托·迈尔-舍恩伯格—大数据之父<br>4V特征：<br>即<br>Volume（数据量大）：PB级<br>Variety（数据多样性）：文本、图像、视频、音频等<br>Velocity（输入和处理速度快）：流式数据<br>Value（价值密度低）： 积累很多的数据才能发掘大数据隐含的意义</p><p>只要能发挥和挖掘数据隐藏的价值，不用纠结与数据量大小<br>大数据核心问题存储、计算和分析—-通过组件（计算框架）解决了</p><h4 id="2、数据仓库和大数据">2、数据仓库和大数据</h4><p>（1）传统方式：DW（Data Warehouse），基于传统的关系数据库（Oracle、MySQL等），一般只做 查询分析，TD（Teradata 天睿）–数据仓库一体机</p><p>（2）大数据的方式–分布式<br>GP：greenplum</p><h4 id="3、OLTP和OLAP">3、OLTP和OLAP</h4><p>（1）OLTP：Online Transaction Processing 联机事务处理：（insert update、delete）<br>ACID：所有的数据可追溯。——-传统关系型数据库（Oracle Mysql Postgresql等）</p><p>（2）OLAP：Online Analytic Processing 联机分析处理<br>真正生产中是二者的结合：OLTP（后台操作 前台展示 数据设计等）+OLAP（Hive Hbase Spark等）</p><h4 id="4、Google的基本思想：三篇论文重点">4、Google的基本思想：三篇论文重点</h4><p>（1）GFS: Google File System—-HDFS —解决存储<br>a、数据库太贵。主要是为了解决 google搜索内容的存储问题。–造价低 易扩展</p><p>b、倒排索引（Reverted Index）：<br>int arry[ ] = {1,2,3,4}<br>索引不一定提高查询速度。—key value</p><p>c、没有公布源码，—-Hadoop之父 Doug Cutting<br>HDFS 默认文件块大小 128M（Hadoop 2.X） 64M（Hadoop 1.x），<br>默认3副本</p><p>（2）MapReduce:分布计算模型<br>PageRank</p><p>（3）BigTable：大表<br>对HDFS进行封装和二次开发，提高查询效率。把所有数据存入一张表中，通过牺牲空间，换取时间</p><h4 id="5、Hadoop的简介">5、Hadoop的简介</h4><p><a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a><br>Hadoop YARN: A framework for job scheduling and cluster resource management.<br>Apache：HDFS+MapReduce+<br>Yarn<br><a href="https://hbase.apache.org/">https://hbase.apache.org/</a></p><h4 id="6、HDFS的体系架构">6、HDFS的体系架构</h4><p>HDFS 副本数可以再 hdfs-site.xml中修改。不超过机器个数 建议不超过3<br>/opt/module/hadoop-2.7.3/etc/hadoop<br>HDFS=NameNode（主节点 名称节点）+SecondaryNameNode（第二名称节点）+DataNode（数据节点）</p><h4 id="7、MR编程模型">7、MR编程模型</h4><p>包含两个阶段 key value 的设计是关键</p><h4 id="8、大数据典型应用场景">8、大数据典型应用场景</h4><p>（1）商品推荐–协同过滤<br>（2）画像<br>（3）套牌车</p><h4 id="9、Hadoop的安装准备工作">9、Hadoop的安装准备工作</h4><p>Hadoop名字来源–Doug Cutting<br>（1）安装好linux操作系统（IP配置）<br>（2）关闭防火墙<br>systemctl stop（disable） firewalld.service<br>（3）安装Jdk–winscp 上传 opt/software 解压到 opt/module<br>（4）Hadoop安装包—虚拟机的克隆 scp（拷贝）</p><p>a、提前准备好 mkdir /opt/module<br>tar -zxvf hadoop-2.7.3.tar.gz -C /opt/module/</p><p>b、vi ~/.bash_profile （用于当前用户）或者/etc/profile（所有用户都可以用）增加下面内</p><p>export JAVA_HOME=<code>/opt/module/jdk1.8.0_192</code><br>export PATH=<code>$JAVA_HOME/bin:$PATH</code></p><p>HADOOP_HOME=<code>/opt/module/hadoop-2.7.3</code><br>export HADOOP_HOME</p><p>PATH=<code>$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</code><br>export PATH</p><p>c、 环境变量生效<br>source ~/.bash_profile<br>通过 输入 start 按两下tab 看是否有内容</p><p>虚拟机克隆<br>（1）保证虚拟机处于关闭状态<br>（2）右键-&gt;管理-&gt;克隆 当前状态 完整克隆–&gt;<br>（3）hostname–修改<br>ip修改 – reboot</p><p>Hadoop（HDFS+Yarn） 本地 伪分布 全分布</p><h4 id="10、Hadoop安装—本地安装">10、Hadoop安装—本地安装</h4><p>（1）特点：没有HDFS和Yarn 只能够测试MR程序是否成功， 作为一个普通的java程序。<br>（2）修改文件：<br>vi <a href="http://hadoop-env.sh">hadoop-env.sh</a><br>set number<br>修改25行（行数不一 hadoop版本不一致）</p><p>JAVA_HOME=/opt/module/jdk1.8.0_181<br>cd /root/<br>mkdir temp<br>touch a.txt<br>vi a.txt<br>mapred-site.xml 默认没有，我克隆的文件里面有 这个文件没有被覆盖指定了yarn资源</p><h4 id="11、Hadoop安装—本地安装伪分布模式">11、Hadoop安装—本地安装伪分布模式</h4><p>（1）特点：在一台机器上模拟一个分布式环境具备hadoop的所有功能。<br>HDFS：NameNode+DataNode+SecondaryNameNode<br>Yarn：ResourceManager+NodeManager</p><p>（2）修改的文件：<br>step1:hadoop-env.sh<br>vi ----- :set number  修改25行<br>JAVA_HOME=<code>/opt/module/jdk1.8.0_192</code><br><code>&lt;!--测试hadoop是否成功--&gt;</code><br>hadoop jar hadoop-mapreduce-examples-2.7.3.jar wordcount ~/temp/a.txt ~/temp/output/wc0107</p><p>step2:hdfs-site.xml</p><pre><code class="highlight plaintext">&lt;!--注释配置数据块的冗余度，默认是3--&gt; &lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;!--注释配置HDFS的权限检查，默认是true--&gt; &lt;!-- &lt;property&gt;    &lt;name&gt;dfs.permissions&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; --&gt;</code></pre><p>step3:core-site.xml</p><pre><code class="highlight plaintext">&lt;!--配置HDFS主节点，namenode的地址,9000是RPC通信端口--&gt;  &lt;property&gt;     &lt;name&gt;fs.defaultFS&lt;/name&gt;     &lt;value&gt;hdfs://hsiehchou121:9000&lt;/value&gt;  &lt;/property&gt; &lt;!--配置HDFS数据块和元数据保存的目录,一定要修改--&gt;   &lt;property&gt;     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;     &lt;value&gt;/opt/moudle/hadoop-2.7.3/tmp&lt;/value&gt;  &lt;/property&gt;</code></pre><p>step4：mapred-site.xml(默认没有)</p><pre><code class="highlight plaintext">cp mapred-site.xml.template  mapred-site.xml&lt;!--配置MR程序运行的框架--&gt;&lt;property&gt;      &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre><p>step5：yarn-site.xml</p><pre><code class="highlight plaintext">&lt;!--配置Yarn的节点--&gt;&lt;property&gt;     &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;   &lt;value&gt;hsiehchou121&lt;/value&gt;&lt;/property&gt; &lt;!--NodeManager执行MR任务的方式是Shuffle洗牌--&gt;&lt;property&gt;     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;</code></pre><p>step 6：通过HDFS namenode 格式化<br>在第4步中，hadoop.tmp.dir–格式化<br>cd /opt/module/hadoop-2.7.3/tmp/<br>[root@hsiehchou121 hadoop]# cd /opt/module/hadoop-2.7.3/tmp/<br>[root@hsiehchou121 tmp]# hdfs namenode -format</p><p>重复格式化:hadoop.tmp.dir   先停止集群，需要删除原来的tmp文件。 rm -rf 重新格式化 启动集群</p><p>命令：hdfs namenode -format<br>验证：是否格式化成功：<br>Storage directory /opt/moudle/hadoop-2.7.3/tmp/dfs/name has been successfully formatted.</p><p>最后启动，通过start-all.sh启动<br>验证：<br>[root@hsiehchou121 tmp]# jps<br>2336 NameNode<br>2867 NodeManager<br>3972 Jps<br>2629 SecondaryNameNode<br>2774 ResourceManager<br>2441 DataNode<br>web访问:<br><a href="http://192.168.116.121:8088">http://192.168.116.121:8088</a> yarn<br><a href="http://192.168.116.121:50070">http://192.168.116.121:50070</a> HDFS</p><h4 id="12、免密码登录的原理和配置">12、免密码登录的原理和配置</h4><p>SSH无密码登录<br>1）配置ssh<br>（1）基本语法<br>ssh 另一台电脑的ip地址<br>（2）ssh连接时出现Host key verification failed的解决方法<br>[root@hsiehchou121 opt]# ssh 192.168.116.103<br>The authenticity of host ‘192.168.116.103 (192.168.116.103)’ can’t be established.<br>RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:06.<br>Are you sure you want to continue connecting (yes/no)?<br>Host key verification failed.<br>（3）解决方案如下：直接输入yes</p><p>2）无密钥配置<br>（1）进入到我的home目录<br>[root@hsiehchou121 opt]$ cd ~/.ssh</p><p>（2）生成公钥和私钥：<br>[root@hsiehchou121 .ssh]$ ssh-keygen -t rsa<br>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>（3）将公钥拷贝到要免密登录的目标机器上<br>[root@hsiehchou121 .ssh]$ <code>ssh-copy-id hsiehchou121</code><br>[root@hsiehchou121 .ssh]$ <code>ssh-copy-id hsiehchou122</code><br>[root@hsiehchou121 .ssh]$ <code>ssh-copy-id hsiehchou123</code><br>[root@hsiehchou121 .ssh]$ <code>ssh-copy-id hsiehchou124</code></p><p>（4）在hsiehchou122、hsiehchou123、hsiehchou124上分别执行所有操作</p><h4 id="13、Hadoop安装—全分布模式">13、Hadoop安装—全分布模式</h4><p>作业：准备3台机器。完成1 的准备工作<br>加入到 etc/hosts<br>192.168.116.121 hsiehchou121<br>192.168.116.122 hsiehchou122<br>192.168.116.123 hsiehchou123<br>192.168.116.124 hsiehchou124</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git快速上手</title>
      <link href="/2019/02/03/git_kuai_su_shang_shou/"/>
      <url>/2019/02/03/git_kuai_su_shang_shou/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Linux-平台上安装">一、Linux 平台上安装</h3><p>Git 的工作需要调用 curl，zlib，openssl，expat，libiconv 等库的代码，所以需要先安装这些依赖工具<br>在有 yum 的系统上（比如 Fedora）或者有 apt-get 的系统上（比如 Debian 体系），可以用下面的命令安装：<br>各 Linux 系统可以很简单多使用其安装包管理工具进行安装：</p><h4 id="1、Debian-Ubuntu">1、Debian/Ubuntu</h4><p>Debian/Ubuntu Git 安装命令为：</p><pre><code class="highlight plaintext">apt-get install libcurl4-gnutls-dev libexpat1-dev gettext  libz-dev libssl-devapt-get install git-coregit --version</code></pre><h4 id="2、Centos-RedHat">2、Centos/RedHat</h4><p>如果你使用的系统是 Centos/RedHat 安装命令为：</p><pre><code class="highlight plaintext">yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develyum -y install git-coregit --version</code></pre><h4 id="3、Git-配置">3、Git 配置</h4><p><code>--system</code> 针对所有用户<br><code>--global</code> 针对当前用户<br>什么都不加参数，当前项目<br>优先级别：当前项目&gt;global&gt;system</p><h4 id="4、用户信息">4、用户信息</h4><p>配置个人的用户名称和电子邮件地址：</p><pre><code class="highlight plaintext">git config --global user.name ""git config --global user.email @qq.com</code></pre><h4 id="5、查看配置信息">5、查看配置信息</h4><p>要检查已有的配置信息，可以使用 git config <code>--list</code> 命令：<br>git config <code>--list</code><br>也可以直接查阅某个环境变量的设定，只要把特定的名字跟在后面即可，像这样：<br>git config <a href="http://user.name">user.name</a><br>hsiehchou</p><h4 id="6、设置SSH">6、设置SSH</h4><p>[root@test ~]# ssh-keygen -t rsa -C “@qq.com”</p><h4 id="7、Linux环境">7、Linux环境</h4><p>vi /etc/hosts<br>添加一行：13.229.188.59　　<a href="http://github.com">github.com</a><br>linux下</p><p>在~/下， touch创建文件 .git-credentials, 用vim编辑此文件，输入：<br>vi ~/.git-credentials<br>https://{用户名}:@{密码}@github.com<br>注意去掉{}</p><p>在终端下执行 git config –global credential.helper store</p><p>可以看到~/.gitconfig文件，会多了一项：<br>[credential]<br>helper = store</p><h3 id="二、Windows环境">二、Windows环境</h3><p>C:\Windows\System32\drivers\etc\hosts<br>添加一行：13.229.188.59　　<a href="http://github.com">github.com</a></p><h4 id="1、Github端的操作">1、Github端的操作</h4><p>在Github的setting里面的SSH and GPG key的SSH keys添加公钥<br>公钥的获取方法是：<br>cat id_rsa_github.pub<br>连接成功<br>[root@test .ssh]# ssh -T <a href="mailto:git@github.com">git@github.com</a></p><p>-i ~/.ssh/id_rsa_github</p><h4 id="2、使用命令">2、使用命令</h4><p>在git bash 中执行<br>设置记住密码（默认15分钟）：<br>git config <code>--global</code> credential.helper cache</p><p>如果想自己设置时间，可以这样做：<br>git config credential.helper  cache <code>--timeout</code>=7200’<br>这样就设置l两个小时之后失效</p><p>长期存储密码：<br>git config <code>--global</code> credential.helper store</p><h4 id="3、在git-bash里边输入-git-remote-v">3、在git bash里边输入 git remote -v</h4><p>git remote rm origin //删除http<br>git remote add origin <a href="mailto:git@github.com">git@github.com</a>:~/~.git //添加ssh<br>git push origin //执行更改</p><p>[root@test ~]# mkdir test<br>[root@test ~]# cd test/<br>[root@test test]# git init<br>Initialized empty Git repository in /root/test/.git/<br>[root@test test]# vim <a href="http://readme.md">readme.md</a><br>[root@test test]# git status<br>[root@test test]# git add <a href="http://readme.md">readme.md</a><br>[root@test test]# git status<br>[root@test test]# vim test1<br>[root@test test]# git add test1<br>[root@test test]# git status<br>[root@test test]# git commit -m “first commit”</p><p>简易提交显示<br>oneline 将 每个提交放在一行显示<br>[root@test test]# git log <code>--pretty</code>=oneline</p><p>图示表示版本提交<br>[root@test test]# git log <code>--graph</code></p><p>commit 8dd0b3d1a2be7064f7bb27e83a6ddc91146d38d0<br>| Author:<br>| Date:<br>|<br>| first commit<br>|</p><p>commit 5c2519af68ea0d0746894122b51a77cd11071ab8</p><p>reset<br>a-&gt;b-&gt;c-&gt;d使用git reset方法回到版本c，有3种方式：<br><code>--hard</code><br>版本库：c<br>暂存区：c，删掉版本d的暂存区<br>工作区：c，删掉版本d的工作区</p><p><code>--sort</code><br>版本库：c<br>暂存区：c，保留版本d的暂存区<br>工作区：c，保留版本d的工作区</p><p><code>--mixed</code>(默认)<br>版本库：c<br>暂存区：c，删除版本d的暂存区<br>工作区：回到版本c，同时保留版本d的工作区</p><p>git diff：暂存区 （比较前的文件）和工作区比较（比较后的文件）<br>git diff <code>--cached</code>：版本库（比较前的文件）和暂存区比较<br>git diff HEAD：版本库（比较前的文件）和工作区比较</p><p>— a/a<br>+++ b/a<br>@ -1 +1 @@<br>-1<br>+123</p><p>工作区：就是电脑上看到的目录，比如目录下test里的文件(.git隐藏目录版本库除外)。或者以后需要再新建的目录文件等等都属于工作区范畴</p><p>版本库(Repository)：工作区有一个隐藏目录.git,这个不属于工作区，这是版本库。其中版本库里面存了很多东西，其中最重要的就是stage(暂存区)，还有Git为我们自动创建了第一个分支master,以及指向master的一个指针HEAD</p><p>git add 把文件添加进去，实际上就是把文件添加到暂存区<br>git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支上</p><p>diff<br>[root@test diff]# git diff<br>diff –git a/a b/a (a（编辑前的版本，暂存区）/a ，b（编辑后的版本，工作区）/a<br>index 14cf074…ac80211 100644（两个文件的哈希值比较）<br>— a/a（—文件变动前的版本，暂存区）<br>+++ b/a（+++文件变动后的版本，工作区）<br>@ -1,2 +1,2 @@（-代表变动前，+代表变动后，1代表第一行，1,2代表连续两行）<br>-123:代表原版本<br>+123 4:代表变动后的版本在前版本上面的增加后的<br>fd</p><p>log<br>git reflog ：查询所有的提交历史<br>git log：看不到commit id的删除记录<br>例如：<br>[root@test log]# git reset <code>--hard</code> 7677a3235b46c<br>HEAD is now at 7677a32 b<br>[root@test log]# git log</p><p>ls ：显示不隐藏的文件与文件夹<br>ls -a：显示当前目录下的所有文件及文件夹包括隐藏的.和…等<br>ls -l ：显示不隐藏的文件与文件夹的详细信息<br>ls -al ：显示当前目录下的所有文件及文件夹包括隐藏的.和…等的详细信息</p><p>mkdir head<br>……<br>项目在创建的时候，git init在.git目录下有个HEAD文件，里面的内容指向了/refs/heads/master，但是没有master文件，说明没有任何提交</p><p>master<br>创建分支：git branch dev<br>切换到分支：git checkout dev</p><p>HEAD告诉我们当前在哪个分支上面，而且是哪一次提交</p><p>合并分支merge<br>[root@test branch]# git log <code>--oneline</code><br>74a5c98 a<br>[root@test branch]# git merge feature<br>Updating 74a5c98…1636fd2<br>Fast-forward<br>b | 1 +<br>c | 1 +<br>d | 1 +<br>3 files changed, 3 insertions(+)<br>create mode 100644 b<br>create mode 100644 c<br>create mode 100644 d<br>[root@test branch]# git log –oneline<br>1636fd2 d<br>8837eb1 b<br>1ef174d c<br>74a5c98 a</p><p>创建并切换新分支<br>[root@test merge]# git checkout -b feature</p><p>在当前分支基础上创建新的分支<br>[root@test merge]# git branch hotfix feature<br>[root@test merge]# git branch -v</p><p>git merge （直接合并到主分支）</p><p>合并并再次提交（合并到主分支，再次提交一次）<br>[root@test merge]# git merge hotfix <code>--no-ff</code></p><p>分支的内容合并后放到主分支里面<br>[root@test merge]# git merge hotfix <code>--squash</code></p><p>查看本地分支<br>git branch -v</p><p>如果新建的项目没有任何提交，是不能创建分支的</p><p>切换分支：git checkout <code>&lt;branchname&gt;</code><br>删除分支：不能再当前分区上删除当前分区</p><p>删除分支：git branch -d <code>&lt;branchname&gt;</code><br>如果当前分支有提交，而没有合并，就只能使用强制删除分支</p><p>强制删除分支：git branch -D <code>&lt;branchname&gt;</code><br>重命名分支：git branch -m <code>&lt;oldbranchname&gt; &lt;newbranchname&gt;</code><br>重命名分支可以在当前分支操作</p><p>创建远程分支：git push -u origin <code>&lt;branchname&gt;</code><br>拉取远程分支：git pull origin <code>&lt;branchname&gt;</code><br>删除远程分支： git push origin <code>--delete</code> <code>&lt;branchname&gt;</code><br>重命名远程分支：<br>1、先删除本地分支<br>2、重命名本地分支<br>3、向远程增加分支</p><p>远程分支覆盖本地分支<br>git pull origin master<br>git reset <code>--hard</code> FETCH_HEAD</p><p>git merge：会有清晰的提交历史<br>git rebase：整洁的提交历史</p><p>git rebase合并中出现冲突情况的解决<br>1、git rebase<br>2、git status<br>3、vim &lt;冲突文件&gt;<br>4、git add &lt;解决完的冲突文件&gt;<br>5、git status<br>6、git rebase <code>--continue</code></p><p>情形1<br>开发新功能问题<br>解决步骤：<br>1、拉取远程仓库代码<br>git pull origin master<br>2、创建新的分支，并在这个分支上写代码，提交<br>3、将自己的代码合并到master分支<br>4、然后将这个master分支推送到远程master分支<br>例如：<br>[root@test newfeature]# git remote add origin <a href="mailto:git@github.com">git@github.com</a>:Hsiehchou/hsiehchou001.git<br>[root@test newfeature]# git pull origin master<br>[root@test newfeature]# vim <a href="http://README.md">README.md</a><br>[root@test newfeature]# git add <a href="http://README.md">README.md</a><br>[root@test newfeature]# git commit -m “new feature develop over”<br>[root@test newfeature]# git checkout master<br>[root@test newfeature]# git push origin master</p><p>情形2<br>自己正在开发新代码，而且暂存区和本地仓库都有代码，在这个时候，老板说线上有个棘手的bug需要修复，自己需要停止手上的新功能开发<br>解决步骤：<br>1、git stash 将现有的暂存区和工作区的代码保留<br>2、然后创建新分支，修复bug<br>3、重新将stash里面的内容拿取出来</p><p>例如：<br>git checkout -b session<br>vim a<br>git add a<br>vim b<br>git status</p><p>git stash<br>git checkout -b hotfix<br>git checkout session<br>git stash pop</p><p>git stash <code>--help</code></p><p>情形3<br>自己在某个分支开发代码，然后别人在 另外的分支开发代码，现在别人已经提交好了代码，然后你想要别人的某几次提交，间隔，或者某一个提交<br>解决步骤：<br>git cherry-pick 合并某一个，或者某几个提交</p><p>git cherry-pick <code>&lt;commit id&gt; &lt;commit id&gt;</code><br>git cherry-pick <code>&lt;commit id&gt;...&lt;commit id&gt;</code><br>合并的时候不包括左边的，但是包括右边的</p><p>[root@test cherry]# git init<br>Initialized empty Git repository in /root/cherry/.git/<br>[root@test cherry]# touch a<br>[root@test cherry]# git add a<br>[root@test cherry]# git commit -m “a”<br>[master (root-commit) 47f4286] a<br>[root@test cherry]# git checkout -b hotfix<br>[root@test cherry]# touch b<br>[root@test cherry]# git add b<br>[root@test cherry]# git commit -m “b”<br>[hotfix 1b01f55] b<br>[root@test cherry]# touch c<br>[root@test cherry]# git add c<br>[root@test cherry]# git commit -m “c”<br>[root@test cherry]# touch d<br>[root@test cherry]# git add d<br>[root@test cherry]# git commit -m “d”<br>[root@test cherry]# git log <code>--oneline</code><br>45e8c64 d<br>cb1f9ef c<br>1b01f55 b<br>47f4286 a<br>[root@test cherry]# git checkout master<br>[root@test cherry]# git cherry-pick cb1f9ef<br>[root@test cherry]# git log <code>--oneline</code><br>c00f63d c<br>47f4286 a</p><p>[root@test cherry]# git log <code>--oneline</code><br>9b2ac83 d<br>8accef7 f<br>ca85346 e<br>c00f63d c<br>47f4286 a<br>[root@test cherry]# git checkout master<br>[root@test cherry]# git log <code>--oneline</code><br>c00f63d c<br>47f4286 a<br>[root@test cherry]# git cherry-pick ca85346 9b2ac83<br>[root@test cherry]# git log <code>--oneline</code><br>413b51b d<br>62fa796 e<br>c00f63d c<br>47f4286 a</p><p>git format-patch生成补丁<br>master a-&gt;b<br>feature a-&gt;b-&gt;c，将bc两次提交的不同生成patch给master，然后master应用补丁</p><p>远程仓库你没有权限，然后你fork远程仓库，代码，然后你clone到本地，接着修改，这是一个很小的修改，然后你又没有权限直接push到别人的仓库，这个时候你就把修改的代码生成一个patch</p><p>git format-patch <code>&lt;commit id&gt;</code>生成patch</p><p>git apply <code>--check</code> *.patch 检查这个patch是否能用</p><p>git am *.patch应用patch，创建git.am这个应用环境</p><p>git apply <code>--reject</code> *.patch会在当前文件夹下生成这个.rej，看这个.rej文件说明，去修改相应冲突的文件，修改完之后，用git add&lt;冲突的文件&gt;</p><p>git am <code>--resolved</code><br>例如：<br>[root@test ~]# mkdir patch<br>[root@test ~]# cd patch/<br>[root@test patch]# git init<br>[root@test patch]# touch a<br>[root@test patch]# git add a<br>[root@test patch]# git commit -m “a”<br>[root@test patch]# git checkout -b feature<br>[root@test patch]# vim b<br>[root@test patch]# git add b<br>[root@test patch]# git commit -m “b”<br>[root@test patch]# vim a<br>[root@test patch]# git add a<br>[root@test patch]# git commit -m “feature a”<br>[root@test patch]# git log <code>--oneline</code><br>01fd4c5 feature a<br>0445b79 b<br>ff994db a<br>[root@test patch]# git checkout master<br>[root@test patch]# vim a<br>[root@test patch]# git add a<br>[root@test patch]# git commit -m “master a”<br>[root@test patch]# git log <code>--oneline</code><br>f8af4f3 master a<br>ff994db a<br>[root@test patch]# git checkout feature<br>[root@test patch]# git log <code>--oneline</code><br>01fd4c5 feature a<br>0445b79 b<br>ff994db a<br>[root@test patch]# git format-patch <code>--help</code><br>[root@test patch]# git format-patch ff994db<br>[root@test patch]# git checkout master<br>[root@test patch]# git apply <code>--check</code> 0001-b.patch<br>[root@test patch]# git apply <code>--check</code> 0002-feature-a.patch<br>[root@test patch]# git am <em>.patch<br>[root@test patch]# git apply 0002-feature-a.patch <code>--reject</code><br>[root@test patch]# cat a.rej<br>diff a/a b/a (rejected hunks)<br>@ -0,0 +1 @@<br>+a<br>[root@test patch]# cat b<br>b<br>[root@test patch]# cat a<br>master a<br>[root@test patch]# vim a<br>[root@test patch]# git add a<br>[root@test patch]# git status<br>[root@test patch]# git am <code>--resolved</code><br>[root@test patch]# cat a<br>master a<br>b<br>[root@test patch]# git status<br>[root@test patch]# cat a.rej<br>diff a/a b/a (rejected hunks)<br>@ -0,0 +1 @@<br>+a<br>[root@test patch]# cat a<br>master a<br>b<br>[root@test patch]# rm -rf a.rej<br>[root@test patch]# rm -rf 000</em></p><p>[root@test patch]# git checkout -b hotfix<br>[root@test patch]# vim a<br>[root@test patch]# git add a<br>[root@test patch]# git commit -m “hotfix”<br>[root@test patch]# git log <code>--oneline</code><br>1cde42d hotfix<br>6b1b69b feature a<br>8301986 b<br>f8af4f3 master a<br>ff994db a<br>[root@test patch]# git format-patch <code>--help</code><br>[root@test patch]# git format-patch 6b1b69b -o /root<br>[root@test patch]# git checkout master<br>[root@test patch]# vim a<br>[root@test patch]# git add a<br>[root@test patch]# git commit -m “master2”<br>[root@test patch]# git apply <code>--check</code> /root/0001-hotfix.patch<br>[root@test patch]# git am /root/0001-hotfix.patch<br>[root@test patch]# git status<br>nothing to commit, working directory clean<br>[root@test patch]# git apply <code>--reject</code> /root/0001-hotfix.patch<br>[root@test patch]# ll<br>[root@test patch]# cat a.rej<br>diff a/a b/a (rejected hunks)<br>@ -1,2 +1,5 @@<br>master a<br>b<br><code>+ </code><br>+hotfix<br><code>+ </code><br>[root@test patch]# vim a<br>[root@test patch]# git add a<br>[root@test patch]# git am <code>--resolved</code><br>[root@test patch]# git status</p>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git快速上手 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据基础1</title>
      <link href="/2019/02/03/da_shu_ju_ji_chu_1/"/>
      <url>/2019/02/03/da_shu_ju_ji_chu_1/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Linux下命令行中的复制和粘贴">1、Linux下命令行中的复制和粘贴</h4><p>安装gpm：yum install -y gpm*</p><p>开启gpm服务：systemctl start gpm</p><h4 id="2、打开网卡">2、打开网卡</h4><p>vi /etc/sysconfig/network-scripts/ifcfg-ens33</p><h4 id="3、修改为静态IP">3、修改为静态IP</h4><p>BOOTPROTO=”dhcp” 这个是动态IP<br>BOOTPROTO=”static”这个是静态IP<br>BOOTPROTO=”none”这个是无</p><h4 id="4、IP地址">4、IP地址</h4><p>IPADDR=192.168.116.121</p><h4 id="5、网关">5、网关</h4><p>GATEWAY=192.168.116.2</p><h4 id="6、子网掩码">6、子网掩码</h4><p>NETMASK=255.255.255.0</p><h4 id="7、DNS服务器1、2">7、DNS服务器1、2</h4><p>DNS1=8.8.8.8<br>DNS2=8.8.4.4</p><h4 id="8、vi-etc-resolve-conf">8、vi /etc/resolve.conf</h4><p>nameserver 8.8.8.8<br>nameserver 8.8.4.4</p><h4 id="9、重启网卡">9、重启网卡</h4><p>service network restart</p><h4 id="10、-如何测试可以ping通">10、 如何测试可以ping通</h4><p>ping 192.168.116.2<br>ping <a href="http://www.baidu.com">www.baidu.com</a></p><h4 id="11、解压JDK命令">11、解压JDK命令</h4><p>tar -zxvf jdk-8u192-linux-x64.tar.gz -C /opt/module/</p><h4 id="12、系统JDK环境变量的位置">12、系统JDK环境变量的位置</h4><p>vi /etc/profile</p><h4 id="13、写入">13、写入</h4><p>export JAVA_HOME=<code>/opt/module/jdk1.8.0_192</code><br>export PATH=<code>$JAVA_HOME/bin:$PATH</code></p><h4 id="14、环境变量生效">14、环境变量生效</h4><p>source /etc/profile</p><h4 id="15、检验JDK是否生效">15、检验JDK是否生效</h4><p>输入javac，回车</p><h4 id="16、解压Hadoop">16、解压Hadoop</h4><p>使用windscp上传<br>tar -zxvf hadoop-2.7.3.tar.gz -C /opt/module/</p><h4 id="17、解压Hadoop">17、解压Hadoop</h4><p>使用windscp上传<br>tar -zxvf hadoop-2.7.3.tar.gz -C /opt/module/</p><h4 id="18、创建日志logs和临时目录tmp">18、创建日志logs和临时目录tmp</h4><p>mkdir logs tmp</p><p>[root@localhost hadoop-2.7.3]#cd etc/hadoop/</p><h4 id="19、vi-hadoop-env-sh">19、vi <a href="http://hadoop-env.sh">hadoop-env.sh</a></h4><p>export JAVA_HOME=/opt/module/jdk1.8.0_192</p><h4 id="20、vi-core-site-xml">20、vi core-site.xml</h4><pre><code class="highlight plaintext">&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hsiehchou121:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-2.7.3/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="21、vi-hdfs-site-xml">21、vi hdfs-site.xml</h4><pre><code class="highlight plaintext">&lt;!-- 指定HDFS副本的数量 --&gt;&lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;</code></pre><h4 id="22、修改主机名">22、修改主机名</h4><p>hostnamectl set-hostname 主机名<br>如：hostnamectl set-hostname hsiehchou121</p><h4 id="23、检查主机名">23、检查主机名</h4><p>hostname</p><h4 id="24、格式化-hdfs">24、格式化 hdfs</h4><p>[root@localhost hadoop-2.7.3]#bin/hdfs namenode -format</p><h4 id="25、启动-hdfs">25、启动 hdfs</h4><p>[root@localhost hadoop-2.7.3]#sbin/start-dfs.sh</p><h4 id="26、关闭-hdfs">26、关闭 hdfs</h4><p>[root@localhost hadoop-2.7.3]#sbin/stop-dfs.sh</p><h4 id="27、查看进程">27、查看进程</h4><p>jps</p><p>[root@localhost hadoop-2.7.3]# jps<br>39668 DataNode<br>39547 NameNode<br>39932 Jps<br>39823 SecondaryNameNode</p><h4 id="28、页面">28、页面</h4><p>IP地址:50070<br>如:192.168.116.121:50070<br>显示页面就对了</p><h4 id="29、临时关闭防火墙">29、临时关闭防火墙</h4><p>systemctl stop firewalld.service</p><h4 id="30、永久禁用防火墙">30、永久禁用防火墙</h4><p>systemctl disable firewalld.service</p><h4 id="31、查看防火墙状态">31、查看防火墙状态</h4><p>systemctl status firewalld.service</p><h4 id="32、SSH无密码登录">32、SSH无密码登录</h4><p>[root@localhost hadoop-2.7.3]$ ssh-keygen -t rsa<br>然后敲（三个回车）</p><p>[root@localhost hadoop-2.7.3]# ssh-copy-id hsiehchou121<br>[root@localhost hadoop-2.7.3]# ssh hsiehchou121<br>[root@hsiehchou121 ~]#<br>[root@hsiehchou121 ~]# exit<br>logout</p><h4 id="33、关闭selinux防火墙">33、关闭selinux防火墙</h4><p>vi /etc/selinux/config</p><p>SELINUX=enforcing 改成<br>SELINUX=disabled</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker基本使用</title>
      <link href="/2019/02/01/docker_ji_ben_shi_yong/"/>
      <url>/2019/02/01/docker_ji_ben_shi_yong/</url>
      
        <content type="html"><![CDATA[<h2 id="Docker在Linux中的安装">Docker在Linux中的安装</h2><h3 id="一、rpm离线安装docker17-12">一、rpm离线安装docker17.12</h3><h4 id="1-下载docker安装包">1.下载docker安装包</h4><p>在<a href="https://download.docker.com/linux/centos/7/x86_64/stable/Packages/%E4%B8%8B%E8%BD%BDdocker-ce-17.12.0.ce-1.el7.centos.x86_64.rpm">https://download.docker.com/linux/centos/7/x86_64/stable/Packages/下载docker-ce-17.12.0.ce-1.el7.centos.x86_64.rpm</a></p><h4 id="2-下载9个依赖">2.下载9个依赖</h4><p>在<a href="http://mirrors.163.com/centos/7/os/x86_64/Packages/%E4%B8%8B%E8%BD%BD8%E4%B8%AA%E4%BE%9D%E8%B5%96">http://mirrors.163.com/centos/7/os/x86_64/Packages/下载8个依赖</a><br>audit-libs-python-2.7.6-3.el7.x86_64.rpm<br>checkpolicy-2.5-4.el7.x86_64.rpm<br>libcgroup-0.41-13.el7.x86_64.rpm<br>libseccomp-2.3.1-3.el7.x86_64.rpm<br>libsemanage-python-2.5-8.el7.x86_64.rpm<br>policycoreutils-python-2.5-17.1.el7.x86_64.rpm<br>python-IPy-0.75-6.el7.noarch.rpm<br>setools-libs-3.3.8-1.1.el7.x86_64.rpm</p><p>在<a href="http://rpm.pbone.net/index.php3?stat=3&amp;limit=1&amp;srodzaj=1&amp;dl=40&amp;search=container-selinux&amp;field%5B%5D=1&amp;field%5B%5D=2%E4%B8%8B%E8%BD%BDcontainer-selinux-2.9-4.el7.noarch.rpm">http://rpm.pbone.net/index.php3?stat=3&amp;limit=1&amp;srodzaj=1&amp;dl=40&amp;search=container-selinux&amp;field[]=1&amp;field[]=2下载container-selinux-2.9-4.el7.noarch.rpm</a></p><p>rpm -ivh /root/docker/*.rpm –nodeps –force</p><p>curl -sSL <a href="http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet">http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet</a> | sh -</p><p>###二、 启动Docker引擎<br>sudo systemctl enable docker<br>sudo systemctl start docker</p><h3 id="三、建立docker用户组">三、建立docker用户组</h3><p>sudo groupadd docker</p><h3 id="四、将用户加入docker组">四、将用户加入docker组</h3><p>sudo usermod -aG docker $USER</p><p>这里使用阿里云的容器镜像服务，目前公测，免费的。</p><ol><li>去阿里云官网，登录控制台，在产品与服务里面找到容器镜像服务<br>2）点击开通</li><li>点击镜像加速器，变有了加速地址（不用镜像加速器的话，镜像都是国外的，因为墙，所有下载是龟速）</li></ol><h3 id="五、镜像加速器">五、镜像加速器</h3><p>vi /etc/systemd/system/multi-user.target.wants/docker.service<br>ExecStart=/usr/bin/dockerd –registry-mirror=https://….mi<br><a href="http://rror.aliyuncs.com">rror.aliyuncs.com</a></p><p>sudo systemctl daemon-reload<br>sudo systemctl restart docker</p><h3 id="六、检查加速器是否生效">六、检查加速器是否生效</h3><p>sudo ps -ef | grep dockerd<br>root 5346 1 0 19:03 ? 00:00:00 /usr/bin/dockerd<br>–registry-mirror=https://*****.mirror.aliyuncs.com</p><p>docker -v</p><p>systemctl start docker</p><p>验证 docker 是否安装成功并在容器中执行一个测试的镜像<br>docker run ubuntu echo hello docker</p><p>docker run nginx</p><p>docker run -p 8080:80 -d nginx<br><a href="http://192.168.116.104:8080/">http://192.168.116.104:8080/</a></p><p>[root@test3 share]# docker cp index.html<br>[root@test3 share]# docker commit -m ‘fun’ d0e976512485 nginx-fun</p><h3 id="七、删除镜像">七、删除镜像</h3><p>docker rmi IMAGE ID</p><h3 id="八、查看镜像">八、查看镜像</h3><p>docker images<br>docker ps -a</p><h3 id="九、小结">九、小结</h3><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">用途</th></tr></thead><tbody><tr><td style="text-align:center">docker pull</td><td style="text-align:center">获取image</td></tr><tr><td style="text-align:center">docker build</td><td style="text-align:center">创建image</td></tr><tr><td style="text-align:center">docker images</td><td style="text-align:center">列出image</td></tr><tr><td style="text-align:center">docker run</td><td style="text-align:center">运行container</td></tr><tr><td style="text-align:center">docker ps</td><td style="text-align:center">列出container</td></tr><tr><td style="text-align:center">docker rm</td><td style="text-align:center">删除container</td></tr><tr><td style="text-align:center">docker rmi</td><td style="text-align:center">删除image</td></tr><tr><td style="text-align:center">docker cp</td><td style="text-align:center">在host 和container之间拷贝文件</td></tr><tr><td style="text-align:center">docker commit</td><td style="text-align:center">保存改动为新的image</td></tr></tbody></table><h3 id="十、Dockerfile语法">十、Dockerfile语法</h3><p>FROM alpine:latest<br>MAINTAINER hsiehchou<br>CMD echo ‘hello docker’</p><p>touch Dockerfile</p><p>++++++++++++++++++++++++++++++++++++++++<br>FROM ubuntu<br>MAINTAINER hsiehchou<br>RUN sed -i ‘s/archive.ubuntu.com/mirros.ustc.edu.cn/g’ /etc/apt/sources.list<br>RUN apt-get update<br>RUN apt-get install -y nginx<br>COPY index.html /var/www/html<br>ENTRYPOINT [“/usr/sbin/nginx”, “-g”, “daemon off;”]前台运行<br>EXPOSE 80</p><p>docker build -t hsiehchou/hello-nginx .</p><p>docker run -d -p 80:80 hsiehchou/hello-nginx</p><h3 id="十一、小结">十一、小结</h3><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">用途</th></tr></thead><tbody><tr><td style="text-align:center">FROM</td><td style="text-align:center">base image</td></tr><tr><td style="text-align:center">RUN</td><td style="text-align:center">执行命令</td></tr><tr><td style="text-align:center">ADD</td><td style="text-align:center">添加文件</td></tr><tr><td style="text-align:center">COPY</td><td style="text-align:center">拷贝文件</td></tr><tr><td style="text-align:center">CMD</td><td style="text-align:center">执行命令</td></tr><tr><td style="text-align:center">EXPOSE</td><td style="text-align:center">暴露端口</td></tr><tr><td style="text-align:center">WORKDIR</td><td style="text-align:center">指定路径</td></tr><tr><td style="text-align:center">MIANTAINER</td><td style="text-align:center">维护者</td></tr><tr><td style="text-align:center">ENV</td><td style="text-align:center">设定环境变量</td></tr><tr><td style="text-align:center">ENVRYPOINT</td><td style="text-align:center">容器入口</td></tr><tr><td style="text-align:center">USER</td><td style="text-align:center">指定用户</td></tr><tr><td style="text-align:center">VOLUME</td><td style="text-align:center">mount point</td></tr></tbody></table><h3 id="十二、镜像分层">十二、镜像分层</h3><p>Dockerfile中的每一行都产生一个新层</p><h3 id="十三、Volume">十三、Volume</h3><p>提供独立于容器之外的持久化存储</p><p>docker run -d –name nginx -v /usr/share/nginx/html nginx</p><p>docker exec -it nginx /bin/bash</p><p>docker run -v $PWD/html:/usr/share/nginx/html nginx</p><p>++++++++++++++++++++++++++++<br>docker create -v $PWD/data:/var /mydata –name data_container ubuntu</p><p>docker run -it –volumes-from data_container ubuntu /bin/bash<br>mount</p><h3 id="十四、Registry">十四、Registry</h3><p>镜像仓库</p><h3 id="十五、术语">十五、术语</h3><table><thead><tr><th style="text-align:center">English</th><th style="text-align:center">中文</th></tr></thead><tbody><tr><td style="text-align:center">host</td><td style="text-align:center">宿主机</td></tr><tr><td style="text-align:center">image</td><td style="text-align:center">镜像</td></tr><tr><td style="text-align:center">container</td><td style="text-align:center">容器</td></tr><tr><td style="text-align:center">registry</td><td style="text-align:center">仓库</td></tr><tr><td style="text-align:center">daemon</td><td style="text-align:center">守护程序</td></tr><tr><td style="text-align:center">client</td><td style="text-align:center">客户端</td></tr></tbody></table><p>docker search whalesay<br>docker pull docker/whalesay<br>docker push myname/whalesay</p><p>国内的一些仓库<br>daocloud<br>时速云<br>aliyun</p><p>[root@test3 dockerfiler2]# docker run docker/whalesay cowsay Docker你好！</p><p>docker tag docker/whalesay hch/whalesay</p><p>curl -L <a href="https://github.com/docker/compose/releases/download/1.9.0/docker-compose-">https://github.com/docker/compose/releases/download/1.9.0/docker-compose-</a>(uname -m) &gt; /usr/local/bin/docker-compose</p><p><strong>docker-compose.yml常用命令</strong></p><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">用途</th></tr></thead><tbody><tr><td style="text-align:center">build</td><td style="text-align:center">本地创建镜像</td></tr><tr><td style="text-align:center">command</td><td style="text-align:center">覆盖缺省命令</td></tr><tr><td style="text-align:center">depends_on</td><td style="text-align:center">连接容器</td></tr><tr><td style="text-align:center">ports</td><td style="text-align:center">暴露端口</td></tr><tr><td style="text-align:center">volumes</td><td style="text-align:center">卷</td></tr><tr><td style="text-align:center">image</td><td style="text-align:center">pull镜像</td></tr></tbody></table><p><strong>docker-compose命令</strong></p><table><thead><tr><th style="text-align:center">命令</th><th style="text-align:center">用途</th></tr></thead><tbody><tr><td style="text-align:center">up</td><td style="text-align:center">启动服务</td></tr><tr><td style="text-align:center">stop</td><td style="text-align:center">停止服务</td></tr><tr><td style="text-align:center">rm</td><td style="text-align:center">删除服务中的各个容器</td></tr><tr><td style="text-align:center">logs</td><td style="text-align:center">观察各个容器的日志</td></tr><tr><td style="text-align:center">ps</td><td style="text-align:center">列出服务相关的容器</td></tr></tbody></table><h3 id="十六、docker基本命令">十六、docker基本命令</h3><p><strong>docker ps</strong>：查看正在运行的容器<br><strong>docker images</strong>：查看现有的镜像<br><strong>docker logs</strong>： 查看某个容器的日志<br><strong>docker run</strong>： 运行某个容器<br><strong>docker inspect</strong>：查看某个容器<br><strong>docker exec</strong>：进入某个容器<br><strong>docker start/stop</strong>：启动或者停止某个容器</p><p>[root@test3 hadoop-docker]# touch Dockerfile<br>[root@test3 hadoop-docker]# ll<br>total 0<br>-rw-r–r– 1 root root 0 Feb 27 19:18 Dockerfile<br>[root@test3 hadoop-docker]# vim Dockerfile</p><pre><code class="highlight plaintext">FROM  ubuntu:14.04MAINTAINER hsiehchouWORKDIR /root# install openssh-server, openjdk and wgetRUN apt-get update &amp;&amp; apt-get install -y openssh-server openjdk-7-jdk wget# install hadoop 2.7.2RUN wget https://github.com/kiwenlau/compile-hadoop/release/download/2.7.2/hadoop-2.7.2.tar.gz &amp;&amp; \        tar -zxvf hadoop-2.7.2.tar.gz &amp;&amp; \        mv hadoop-2.7.2 /usr/local/hadoop &amp;&amp; \        rm hadoop-2.7.2.tar.gz# set environment variableENV JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd-64ENV HADOOP_HOME=/usr/local/hadoopENV PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin# ssh without keyRUN ssh-keygen -t rsa -f ~/.ssh/id_rsa -p '' &amp;&amp; \        cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keysRUN mkdir -p ~/hdfs/namenode &amp;&amp; \    mkdir -p ~/hdfs/datanode &amp;&amp; \    mkdir $HADOOP_HOME/logsCOPY config/* /tmp/RUN mv /tmp/ssh_config ~/.ssh/config &amp;&amp; \    mv /tmp/hadoop-env.sh /usr/local/hadoop/etc/hadoop/hadoop-env.sh &amp;&amp; \    mv /tmp/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml &amp;&amp; \    mv /tmp/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml &amp;&amp; \    mv /tmp/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml &amp;&amp; \    mv /tmp/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml &amp;&amp; \    mv /tmp/slaves $HADOOP_HOME/etc/hadoop/slaves &amp;&amp; \    mv /tmp/start-hadoop.sh ~/start-hadoop.ssh &amp;&amp; \    mv /tmp/run-wordcount.sh ~/run-wordcount.shRUN chmod +x ~/start-hadoop.sh &amp;&amp; \    chmod +x ~/run-wordcount.sh &amp;&amp; \    chmod +x $HADOOP_HOME/sbin/start-dfs.sh &amp;&amp; \    chmod +x $HADOOP_HOME/sbin/start-yarn.sh# format namenodeRUN /usr/local/hadoop/bin/hdfs namenode -formatCMD ["sh", "-c", "service ssh start: bash"]</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker基本使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java之MySQL的使用</title>
      <link href="/2019/01/30/java_zhi_mysql_de_shi_yong/"/>
      <url>/2019/01/30/java_zhi_mysql_de_shi_yong/</url>
      
        <content type="html"><![CDATA[<h4 id="1、MySQL概要">1、MySQL概要</h4><p>关系型数据库。—Access数据库 oracle数据库、Postgresql-<br>非关系型数据库。—-Hbase等<br>库：—package<br>表：–class<br>字段：–属性<br>Oracle旗下产品—-分两种 （GPL协议的 社区版和企业版）<br>CDH HDP–后面大数据给大家讲 Apache–hive hdfs hadoop</p><p>RDBMS：关系数据库管理系统。将数据存储在不同的库表里面<br>支持标准的SQL语句100%<br>体积小 速度快<br><a href="https://www.mysql.com/%E2%80%94%E3%80%8BMySQL">https://www.mysql.com/—》MySQL</a> Community Edition (GPL)-》MySQL OnWindows<br>MySQL Installer-》Windows (x86, 32-bit), MSI Installer 8.0.13 313.8M</p><p>mysql-installer-community-8.0.13.0.msi</p><h4 id="2、MySQL安装">2、MySQL安装</h4><p>DBA–数据库管理员<br>黑框框+workbench<br>show databases;–展示所有库<br>show tables;–展示所有表;<br>describe city;–展示表里面的字段信息<br>select * from city limit 10;</p><h4 id="3、Navicat安装与操作MySQL">3、Navicat安装与操作MySQL</h4><p>Navicat Premium 是一套数据库开发工具，让你从单一应用程序中同时连接 MySQL、MariaDB、MongoDB、SQL Server、Oracle、PostgreSQL 和 SQLite 数据库。它与 Amazon RDS、Amazon Aurora、Amazon Redshift、Microsoft Azure、Oracle Cloud、MongoDB Atlas、<br>阿里云、腾讯云和华为云等云数据库兼容。可以快速轻松地创建、管理和维护数据库</p><p>更新数据库的密码<br>ALTER USER ‘root’@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘密码’;</p><h4 id="4、MySQL数据类型">4、MySQL数据类型</h4><p>（1）数值类型<br>a、整型<br>tinyint 1个字节<br>smallint 2个字节<br>mediumint 3个字节<br>int 4<br>bigint 8<br>b、浮点型（float double）<br>float(M,D) 小数位数部分会四舍五入。M=3 D=2 3.15<br>c、定点数<br>可变长度 decimal(M,D) M:表示总的有效位数，D表示小数的位数<br>3.14<br>3.145</p><p>（2）字符串类型<br>char:定长字符串 255个<br>varchar：变长字符串 varchar(25) 最大65535字符<br>blob:二进制字符串–文件 图片等<br>text:非二进制字符串–长文本</p><p>（3） 日期数据类型<br>datetime：2018-12-22 21:04:55<br>timestamp：时间戳 2019021600000 ms</p><h4 id="5、MySQL外键、主键、唯一键">5、MySQL外键、主键、唯一键</h4><p>（1）外键 Foreign Key<br>如果换教室 302-303教室 需要对所有的数据进行 更新。30个学生 然后就得跟新30次<br>（2） 主键 Primary Key 唯一不可重复 只能有一个主键，不能为null<br>（3）唯一键 一个表可以有多个 唯一键 unique</p><h4 id="6、SQL语句–增删改查">6、SQL语句–增删改查</h4><p>SQL：Structure Query Language。—HiveQL Spark SQL<br>查询：<br>select字段(*) from 表明 (limit count) (where);</p><p>插入语句：<br>insert into 表名 [字段名] values(值列表);</p><p>修改语句：<br>update 表名 set 字段=值 where 条件;</p><p>删除语句：<br>delete from 表名 [where 条件];</p><p>例如：<br>SELECT * FROM classroom;<br>insert into classroom VALUES(“001”,”9年级”,”11”,”CC”);<br>update classroom SET classroom.classroomid=”0003” where classroom.classroomid=”001”;<br>DELETE FROM classroom where classroom.classroomid=”0003”;<br>TRUNCATE student;</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java之MySQL的使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java反射</title>
      <link href="/2019/01/29/java_fan_she/"/>
      <url>/2019/01/29/java_fan_she/</url>
      
        <content type="html"><![CDATA[<h4 id="1、反射获取Class对象的三种方式">1、反射获取Class对象的三种方式</h4><p>反编译<br>不是自己写的类，也不知道类里面有哪些方法 变量，让你能够使用程序上线了，修改程序但不终止程序的运行—-反射<br>（1）Object类 getClass 方法<br>getClass 返回此Object的运行时类<br>getName() 返回由 类对象表示的实体（类，接口，数组类，原始类型或空白）的名称，作为 String</p><p>（2）通过Class属性获得<br>都有一个静态的class属性</p><p>（3）通过 forName<br>static 类&lt;?&gt; forName(String className) 返回与给定字符串名称的类或接口相关联的 类对象</p><h4 id="2、反射获得构造方法">2、反射获得构造方法</h4><p>（1）获得构造方法</p><pre><code class="highlight plaintext">Constructor&lt;T&gt; getDeclaredConstructor(类&lt;?&gt;... parameterTypes) 返回一个 Constructor对象，该对象反映 Constructor对象表示的类或接口的指定 类函数Constructor&lt;?&gt;[] getDeclaredConstructors() 返回一个反映 Constructor对象表示的类声明的所有 Constructor对象的数组 类 Constructor&lt;T&gt; getConstructor(类&lt;?&gt;... parameterTypes) 返回一个 Constructor对象，该对象反映 Constructor对象表示的类的指定的公共类函数Constructor&lt;?&gt;[] getConstructors() 返回包含一个数组 Constructor对象反射由此表示的类的所有公共构造 类对象</code></pre><p>（2）使用构造方法<br>public T newInstance() throws InstantiationException, IllegalAccessException<br>访问私有的构造方法。必须通过Accessible设置为true。强行访问</p><p>public void setAccessible(boolean flag) throws SecurityException将此对象的accessible标志设置为指示的布尔值</p><p>true的值表示反射对象应该在使用时抑制Java语言访问检查。 false的值表示反映的对象应该强制执行Java语言访问检查</p><h4 id="3、反射获得成员变量">3、反射获得成员变量</h4><p>（1）获得字段<br>Field[] getDeclaredFields()<br>返回的数组 Field对象反映此表示的类或接口声明的所有字段 类对象</p><p>getField(String name)<br>返回一个 Field对象，它反映此表示的类或接口的指定公共成员字段 类对象</p><p>Field[] getFields()<br>返回包含一个数组 Field对象反射由此表示的类或接口的所有可访问的公共字段 类对象</p><h4 id="4、反射获得成员方法">4、反射获得成员方法</h4><p>Declared–所有的<br>Methods–公共的<br>使用成员方法<br>Object invoke(Object obj, Object… args)<br>在具有指定参数的 方法对象上调用此 方法对象表示的底层方法</p><h4 id="5、泛型">5、泛型</h4><p>安全检测机制<br>例如：</p><pre><code class="highlight plaintext">ArrayList&lt;T&gt; arrylist=new ArrayList&lt;T&gt;();</code></pre><p>存在类型错误 类型无法转换成功</p><h4 id="6、泛型方法">6、泛型方法</h4><p>如何写一个方法 实现对 整数 浮点数 字符的输出。–泛型<br>基本原则：</p><p>a、所有泛型方法的声明都有一个类型参数声明的部分（<code>&lt;T&gt;</code>）–表示所有的类型参数<br>b、泛型方法只能是引用数据类型，（int double）<br>例如：</p><pre><code class="highlight plaintext">public static&lt;T&gt; void show(){}</code></pre><h4 id="7、泛型类">7、泛型类</h4><p>泛型类 增加了类型参数声明部分<br>例如：</p><pre><code class="highlight plaintext">class Test&lt;T&gt;{    private T t;    Test(T t){        this.t=t;    }}</code></pre><h4 id="8、泛型擦除">8、泛型擦除</h4><p>java本身不存在泛型。增加了泛型机制。—java虚拟机中都是确定的类型 泛型擦除</p><h4 id="9、类型通配符">9、类型通配符</h4><!--?-->–代替具体的类型参数 <p>例如：</p><pre><code class="highlight plaintext">public void print(List&lt;?&gt; data){   data.get(0);     }</code></pre><p><code>&lt;T&gt;</code>–指所有的数据类型</p><h4 id="10、反射与泛型">10、反射与泛型</h4><p>泛型：允许程序员在编译时检测到非法的数据类型，运行期间Object，泛型擦除<br>通过反射可以添加不同的数据类型</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java反射 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java多线程</title>
      <link href="/2019/01/28/java_duo_xian_cheng/"/>
      <url>/2019/01/28/java_duo_xian_cheng/</url>
      
        <content type="html"><![CDATA[<h4 id="1、ObjectInputStream">1、ObjectInputStream</h4><p>反序列化<br>（1）构造函数<br>ObjectInputStream(InputStream in) 创建从指定的InputStream读取的ObjectInputStream</p><p>（2）主要方法<br>Object readObject() 从ObjectInputStream读取一个对象</p><h4 id="2、POI-实现对word、Excel等文件操作">2、POI 实现对word、Excel等文件操作</h4><p>Apache–Download 安装包，根据操作系统<br>例如windows .zip<br>导包–build path-&gt;configure build path-&gt;add external jars</p><h4 id="3、多线程简介">3、多线程简介</h4><p>进程：系统资源分配的单位。（cpu 磁盘 内存 网络）<br>线程：独立调度和分配的基本单位，共享进程资源<br>一个进程 包含多个线程，用来完成不同的工作，称之为多线程<br>进程是为了提高系统资源的利用率和系统吞吐量<br>线程是为了减少程序在并发执行时付出的时空开销</p><h4 id="4、线程的使用">4、线程的使用</h4><p>（1）继承 thread 类<br>public class Thread extends Object implements Runnable<br>a、Thread类构造函数<br>Thread()<br>分配一个新的 Thread对象</p><p>Thread(String name)<br>分配一个新的 Thread对象</p><p>主要方法：<br>void run()<br>主要是运行线程所负责的主要任务</p><p>void setName(String name)<br>将此线程的名称更改为等于参数 name</p><p>void setPriority(int newPriority)<br>更改此线程的优先级</p><p>start()<br>导致此线程开始执行; Java虚拟机调用此线程的run方法</p><p>void setDaemon(boolean on)<br>将此线程标记为 daemon线程或用户线程</p><p>static Thread currentThread() 返回对当前正在执行的线程对象的引用</p><p>b、声明方式：</p><pre><code class="highlight plaintext">public class 线程类名 extends Thread{     //重写run方法     public void run(){     } }</code></pre><p>c、调用和开启线程<br>线程类名 初始化<br>线程类名.start();<br>start() 导致此线程开始执行; Java虚拟机调用此线程的run方法</p><p>（2）实现Runnable接口<br>Interface Runnable<br>void run()<br>当实现接口的对象 Runnable被用来创建一个线程<br>启动线程使对象的 run在独立执行的线程中调用的方法</p><pre><code class="highlight plaintext">public class 线程名 implements Runnable{    //实现 run方法    public void run(){      }}</code></pre><p>a、建立一个类实现runnable的接口<br>b、使用参数为Runnable对象的Thread构造方法。–Thread(Runnable target) 分配一个新的 Thread对象<br>c、 调用 start方法 开启线程</p><h4 id="5、线程的优先级">5、线程的优先级</h4><p>默认的线程优先级：5<br>线程优先级最高为：10<br>最低的优先级为：1<br>优先级指的是一种概率</p><h4 id="6、守护线程">6、守护线程</h4><p>用户线程：User Thread<br>守护线程：Daemon Thread ：主要提供服务的，为其他线程。比如 gc 垃圾回收线程<br>守护线程主要是在用户线程都执行完的情况下执行，如果没有用户线程执行，守护线程自动退出</p><h4 id="7、窗口卖票小案例">7、窗口卖票小案例</h4><p>卖票 是针对同一个票额 同一个票库，两个线程同时访问<br>抢占资源，同一张票 卖给多个人<br>等待<br>保证数据在任何时刻只有一个线程访问，保证数据的完整性</p><h4 id="8、线程的同步">8、线程的同步</h4><p>锁机制<br>（1）同步代码块<br>static{} {}<br>synchronized(){<br>//代码<br>}—-同步代码块</p><p>（2）同步方法<br>synchronized 修饰的方法</p><p>（3）互斥锁<br>lock，保证数据的完整性 一山不容二虎<br>ReentrantLock<br>构造方法–ReentrantLock() 创建一个 ReentrantLock的实例<br>主要方法：<br>void lock() 获得锁<br>void unlock() 尝试释放此锁</p><h4 id="9、线程的wait和notify">9、线程的wait和notify</h4><p>wait：线程等待，直到另一个线程调用该对象的notify()方法或notifyAll()方法<br>notify:唤醒正在等待对象监视器的单个线程<br>notifyall:唤醒正在等待对象监视器的所有线程<br>sleep:long—睡眠时间 Thread类自带的方法—-自然醒<br>wait：继承于object的方法—-被叫醒</p><h4 id="10、线程池概述">10、线程池概述</h4><p>多个线程运行时运行机制，包括排队策略 包括线程存活时间，框架策略<br>管理 创建 释放</p><h4 id="11、线程池使用">11、线程池使用</h4><p>ThreadpoolExecutor<br>（1）构造方法<br>ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue)<br>corePoolSize：核心池<br>maximumPoolSize：线程池最大线程数<br>keepAliveTime：线程没有任务执行时，最多多长时间会终止&gt;corePoolSize 起作用<br>TimeUnit：keepAliveTime的时间单位<br>workQueue：用于存放待执行的任务<br>ArrayBlockingQueue、LInkedBlockingQueue、SynchronousQueue等<br>10个工人 一个工人同时做一个任务；<br>10个人都在干活，还有任务来了，任务排队<br>活太多，最多招5个人，<br>15个人还是赶不过来。放弃任务<br>额外找来的5个人，3个月后辞去，还是10个人干活<br>corePoolSize：10<br>maximumPoolSize：15<br>keepAliveTime:3个月</p><p>（2）主要方法<br>void execute(Runnable command) 在将来某个时候执行给定的任务<br>submit 提交任务<br>shutdown：关闭线程池<br>shutdownnow：立即关闭</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java多线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java的IO流</title>
      <link href="/2019/01/26/java_de_io_liu/"/>
      <url>/2019/01/26/java_de_io_liu/</url>
      
        <content type="html"><![CDATA[<h4 id="1、IO概述">1、IO概述</h4><p>Input ：将磁盘或硬盘、键盘等数据读入到内存的<br>Output：从内存输出到 磁盘、硬盘等<br>主要是以内存为基准</p><h4 id="2、输入输出流分类">2、输入输出流分类</h4><p>（1）字节流<br>1Byte =8 bit<br>1KB=1024B<br>1MB=1024KB<br>1GB=1024MB<br>1TB=1024GB<br>1PB=1024TB——-商业的存储空间 都是以 1000为单位<br>字节流可以处理所有数据类型的数据，在Java中 以 Stream结尾的</p><p>（2）字符流<br>一个字符=2Byte<br>字符流对于处理文本数据有优势，在Java中 以 Reader 和 Writer结尾</p><p>（3）IO包<br><a href="http://Java.IO">Java.IO</a>—HDFS 离线计算</p><h4 id="3、File-类">3、File 类</h4><p>文件和目录的抽象表示<br>（1）构造方法<br>File(String pathname)<br>pathname:<br>绝对路径：D:\TZ\Java黄埔9期\jdk+api+1.8_google<br>相对路径：day23 课程笔记.txt 相对我们的当前路径来说<br>./test/a.txt<br>File file=new File(pathname);<br>可以写文件目录 也可以写 具体文件</p><p>（2）常用方法<br>boolean exists() 测试此抽象路径名表示的文件或目录是否存在<br>String getAbsolutePath() 返回此抽象路径名的绝对路径名字符串<br>boolean isDirectory() 测试此抽象路径名表示的文件是否为目录<br>boolean isFile() 测试此抽象路径名表示的文件是否为普通文件<br>File[] listFiles() 返回一个抽象路径名数组，表示由该抽象路径名表示的目录中的文件</p><h4 id="4、FileInputStream–输入字节流">4、FileInputStream–输入字节流</h4><p>FileInputStream用于读取诸如图像数据的原始字节流<br>public class FileInputStreamextends InputStream<br>（1）构造函数<br>FileInputStream(File file) 通过打开与实际文件的连接创建一个 FileInputStream ，<br>该文件由文件系统中的 File对象 file命名<br>File file=new File(“”);<br>FileInputStream fis=new FileInputStream(file);</p><p>（2）主要方法<br>int read() 从该输入流读取一个字节的数据，，如果达到文件的末尾， -1<br>int read(byte[] b) 从该输入流读取最多 b.length个字节的数据为字节数组。 -1</p><h4 id="5、FileOutputStream–输出字节流">5、FileOutputStream–输出字节流</h4><p>把内存中的内容 输出到文件中去<br>文件输出流是用于将数据写入到输出流File<br>public class FileOutputStream extends OutputStream</p><p>（1）构造函数<br>FileOutputStream(File file)<br>创建文件输出流以写入由指定的 File对象表示的文件。–默认 append 为 false 覆盖更新文件内容<br>FileOutputStream(File file, boolean append)<br>创建文件输出流以写入由指定的 File对象表示的文件。追加模式可以设置为true</p><p>（2）主要函数<br>void write(int b)<br>将指定的字节写入此文件输出流</p><p>void write(byte[] b)<br>将 b.length个字节从指定的字节数组写入此文件输出流</p><p>void write(byte[] b, int off, int len)<br>将 len字节从位于偏移量 off的指定字节数组写入此文件输出流</p><p>void flush() 刷新此输出流并强制任何缓冲的输出字节被写出</p><h4 id="6、FileReader–输入字符流">6、FileReader–输入字符流</h4><p>（1）构造函数<br>FileReader(File file) 创建一个新的 FileReader ，给出 File读取</p><p>（2）主要函数<br>public int read() 每次读取一个字符 -1表示到文件结尾；<br>public int read(char[] cbuf, int offset, int length)</p><h4 id="7、FileWriter-输出字符流">7、FileWriter-输出字符流</h4><p>（1）构造函数<br>FileWriter(File file) 给一个File对象构造一个FileWriter对象<br>FileWriter(File file, boolean append) 给一个File对象构造一个FileWriter对象</p><p>（2）主要函数<br>public void write(char)<br>public void write(char[] cbuf,int off,int len)–写入字符数组<br>public void write(String str,int off,int len)–写入字符串</p><h4 id="8、BufferdReader">8、BufferdReader</h4><p>(1) InputStreamReader–字符输入流<br>字节流 转为字符流的桥梁<br>编码问题，可以指定编码。–utf-8 GBK<br>InputStreamReader(InputStream in)<br>创建一个使用默认字符集的InputStreamReader</p><p>InputStreamReader(InputStream in, String charsetName)<br>创建一个使用命名字符集的InputStreamReader。</p><p>int read() 读一个字符<br>int read(char[] cbuf, int offset, int length) 将字符读入数组的一部分</p><p>（2）可以把字符流的效率提高，提供缓冲<br>可以使用 FIleReader、InputStreamReader等作为参数<br>实现字节流到字符流的缓冲<br>a、构造函数<br>BufferedReader(Reader in) 创建使用默认大小的输入缓冲区的缓冲字符输入流<br>BufferedReader(Reader in, int sz) 创建使用指定大小的输入缓冲区的缓冲字符输入流</p><p>b、主要函数<br>int read() 读一个字符<br>int read(char[] cbuf, int off, int len) 将字符读入数组的一部分。<br>String readLine() 读一行文字 —特色</p><h4 id="9、BufferedWriter">9、BufferedWriter</h4><p>（1）OutputStreamWriter–指定字符集<br>将字节流转换为字符流的桥梁<br>OutputStreamWriter(OutputStream out, String charsetName)<br>创建一个使用命名字符集的OutputStreamWriter</p><p>主要方法：<br>void write(char[] cbuf, int off, int len)<br>写入字符数组的一部分</p><p>void write(int c)<br>写一个字符</p><p>void write(String str, int off, int len)<br>写一个字符串的一部分</p><p>（2）BufferedWriter<br>a、构造函数<br>BufferedWriter(Writer out)<br>创建使用默认大小的输出缓冲区的缓冲字符输出流</p><p>BufferedWriter(Writer out, int sz)<br>创建一个新的缓冲字符输出流，使用给定大小的输出缓冲区</p><p>b、主要方法<br>newLine()<br>写一行行分隔符</p><p>void write(char[] cbuf, int off, int len)<br>写入字符数组的一部分</p><p>void write(int c)<br>写一个字符</p><p>void write(String s, int off, int len)<br>写一个字符串的一部分</p><h4 id="10、序列化与反序列化">10、序列化与反序列化</h4><p>序列化 就是把对象转换为字节序列的过程<br>反序列化 就是把字节恢复为对象的过程</p><h4 id="11、ObjectOutputStream–序列化">11、ObjectOutputStream–序列化</h4><p>（1）构造函数<br>ObjectOutputStream() 为完全重新实现ObjectOutputStream的子类提供一种方法，不必分配刚刚被ObjectOutputStream实现使用的私有数据</p><p>ObjectOutputStream(OutputStream out)<br>创建一个写入指定的OutputStream的ObjectOutputStream</p><p>（2）主要方法<br>void write(byte[] buf) 写入一个字节数组<br>void write(byte[] buf, int off, int len) 写入一个子字节数组<br>void write(int val) 写一个字节<br>void writeObject(Object obj)<br>将指定的对象写入ObjectOutputStream<br>把类进行序列化 需要首先实现 Serializable接口<br>加密传输数据的一种方式</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java的IO流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java异常</title>
      <link href="/2019/01/24/java_yi_chang/"/>
      <url>/2019/01/24/java_yi_chang/</url>
      
        <content type="html"><![CDATA[<p>Java异常</p><h4 id="1、异常概述">1、异常概述</h4><p>（1）异常分为：编译时异常 运行时异常<br>（2）编译时异常：Javac IDE（，‘’），一般是指的 语法错误，比较容易修正<br>（3）运行时的异常：运行错误和逻辑错误<br>1/0;<br>（4）不正常的事件<br>异常的类，创建对象<br>NullPointException：空指针异常<br>Student stu;stu—&gt;对象<br>（5）异常处理机制<br>抛出异常—110<br>catch 异常— 依靠自己</p><h4 id="2、异常的分类">2、异常的分类</h4><p>（1）Throwable—异常类的鼻祖。Throwable类是Java语言中所有错误和异常的Throwable类<br>（2）Error：错误<br>（3）Exception：<br>CheckedException：try catch来显示的捕获<br>例如：<br>RuntimeException<br>ArithmeticException：算术异常 例如 除数为0<br>IndexOutOfBoundsException:数组越界<br>NullPointException：空指针异常<br>IOException ：IO异常<br>FileNotFoundException：文件异常<br>ClassNotFoundException：找不到指定类<br>SQLException：SQL执行语句</p><h4 id="3、异常-方法抛出异常-throw-关键字">3、异常-&gt;方法抛出异常 throw 关键字</h4><p>（1） throw 抛出异常，手动引发异常<br>例如： throw new IOException();<br>（2） throws 抛出异常，会抛出多个异常并不是处理异常 推卸责任<br>谁调用 抛给谁。 多个异常之间可以通过 ，分割</p><h4 id="4、异常-异常的处理方式-try…catch…finally">4、异常-&gt;异常的处理方式 try…catch…finally</h4><pre><code class="highlight plaintext">try{  可能出现异常的代码；}catch(异常处理的类型1 变量){    处理异常的代码}catch(异常处理类型2 变量){}...</code></pre><p>（1） catch 可以有多个<br>（2）异常的捕获必须从小类的异常 到 大类型的异常<br>（3）最多执行1个 catch语句块<br>finally ：一定会执行的代码，一般用来做资源的释放<br>例如：数据库连接的关闭<br>try catch finally 也可以直接与 try 连用<br>try finally<br>try catch finally 不能都单独存在。 catch 与 finally 必须与try 连用</p><h4 id="5、自定义异常">5、自定义异常</h4><p>写一个子类 继承 RuntimeException。主要应对 Exception类内置异常无法解决问题时</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java异常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java集合</title>
      <link href="/2019/01/20/java_ji_he/"/>
      <url>/2019/01/20/java_ji_he/</url>
      
        <content type="html"><![CDATA[<h4 id="1、集合概念">1、集合概念</h4><p>回忆数组–数组有固定的长度<br>int[] arry=new int[10];</p><p>针对数据长度可变的情况—》集合<br>Java集合 应对动态增长数据（在编译的时候无法知道具体的数据量）<br>集合类–&gt;可变容器类</p><h4 id="2、集合和数组的区别">2、集合和数组的区别</h4><p>都是容器<br>（1）数组是固定长度，集合的长度是可变的<br>（2）数组放的数据都是基本类型数据（四类8种），但是集合放的数据都是引用数据类型<br>（String、自定义的对象、Integer–int、Long）<br>（3）集合中对于基本数据会转换为引用数据类型再存储</p><h4 id="3、集合包含内容">3、集合包含内容</h4><p>（1）Collection–接口 Interface</p><pre><code class="highlight plaintext">Interface Collection&lt;E&gt;---add 方法public abstract class AbstractCollection&lt;E&gt; extends Object implements Collection&lt;E&gt;public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt;</code></pre><p>a、List（接口）集合—特定顺序的元素</p><pre><code class="highlight plaintext">public interface List&lt;E&gt; extends Collection&lt;E&gt;</code></pre><p>add(int index, E element) —指定索引处增加元素的位置<br>iterator() 以正确的顺序返回该列表中的元素的迭代器</p><p>b、Set（接口）集合–不能够有重复的元素</p><p>（2）Map–类似于数据库<br>主要存储”键值对” key-value MapReduce</p><p>（3）Iterable 集合的访问迭代 返回此集合中的元素的迭代器<br>没有关于元素返回顺序的保证（除非这个集合是提供保证的某个类的实例）</p><h4 id="4、集合框架-集合的继承关系图">4、集合框架-&gt;集合的继承关系图</h4><p>Collection接口 Map<br>Collection 、Map 、List 、Set 等都是 Interface<br>AbstractCollection、 Abstractlist等 抽象类 实现了 Interface的部分方法<br>ArrayList 、LinkedList等 具体实现类 实现了 所有方法</p><h4 id="5、List集合介绍">5、List集合介绍</h4><p>List集合是一个有序（索引有序）、可重复的集合，集合中每个元素都有对应的顺序索引<br>List允许加入重复元素是因为可以通过索引来访问指定位置的元素<br>List集合默认按照元素的添加顺序增加元素的索引</p><h4 id="6、List集合-ArrayList">6、List集合-&gt;ArrayList</h4><p>（1）ArrayList简介<br>ArrayList 是基于数组实现的List类。实现所有可选列表操作，并允许所有元素，包括null</p><p>（2）初始化 ArrayList</p><pre><code class="highlight plaintext">ArrayList&lt;E&gt; arrayList=new ArrayList&lt;E&gt;（）；---初始数据类型为E，容量大小为10的List</code></pre><p>（3）主要方法<br>boolean add(E e) 将指定的元素追加到此列表的末尾<br>void add(int index, E element) 在此列表中的指定位置插入指定的元素<br>boolean addAll(Collection&lt;? extends E&gt; c) 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾<br>boolean addAll(int index, Collection&lt;? extends E&gt; c) 将指定集合中的所有元素插入到此列表中，从指定的位置开始<br>boolean contains(Object o) 如果此列表包含指定的元素，则返回 true<br>E get(int index) 返回此列表中指定位置的元素<br>E remove(int index) 删除该列表中指定位置的元素<br>E set(int index, E element) 用指定的元素替换此列表中指定位置的元素<br>Object[] toArray() 以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组</p><p>（4）List集合遍历的四种方法<br>a、通过 List.size<br>b、通过Iterator<br>boolean hasNext() 如果迭代具有更多元素，则返回 true<br>E next() 返回迭代中的下一个元素</p><h4 id="7、List集合-LinkedList">7、List集合-&gt;LinkedList</h4><p>LinkedList 指的是链表类数据结构<br>与ArrayList的不同<br>（1）链表中的元素可以任意的增加和删除，效率很高，但是 查询效率不如ArrayList（有索引）<br>a-&gt;b-&gt;c….<br>（2）将对象存放在独立的空间中，而且每个空间保存了下一个连接的索引<br>（3）初始化<br>LinkedList linkedlist=new LinkedList();<br>（4）主要的方法<br>void addFirst(E e) 在该列表开头插入指定的元素<br>void addLast(E e) 将指定的元素追加到此列表的末尾<br>E peekFirst() 检索但不删除此列表的第一个元素，如果此列表为空，则返回 null<br>peekLast() 检索但不删除此列表的最后一个元素，如果此列表为空，则返回 null<br>pop() 从此列表表示的堆栈中弹出一个元素</p><h4 id="8、Set接口的介绍">8、Set接口的介绍</h4><p>set集合存放无序不可重复的元素<br>list集合 存放有序可重复的元素。—索引<br>set集合不按照特定方式进行排序，只是放元素放在集合<br>set主要是由 HashSet和TreeSet具体实现类实现</p><h4 id="9、Set集合-HashSet">9、Set集合-&gt;HashSet</h4><p>Hash（哈希算法）—-哈希函数定义的好坏<br>HashCode—哈希值<br>（1）equals（）方法判断两个元素的HashCode值是否相同</p><p>（2）如果Hashcode值相同，继续与集合的元素作比较，<br>如果还相同则视为同一个对象，不保存在HashSet中<br>如果对象不相同，理论上要存储（比价麻烦）–避免发生</p><p>（3）如果HashCode值不相同，直接把元素存放在该元素的Hashcode位置<br>public class HashSet extends AbstractSet implements Set, Cloneable, Serializable</p><p>（4）构造函数<br>HashSet hashSet=new HashSet();<br>boolean add(E e) 将指定的元素添加到此集合（如果尚未存在）<br>boolean contains(Object o) 如果此集合包含指定的元素，则返回 true</p><h4 id="10、Set集合-TreeSet">10、Set集合-&gt;TreeSet</h4><p>TreeSet 是一个有序集合，默认将元素按照升序排列，Comparable接口<br>equals方法 判断元素是否重复<br>比较器 比较一下大小顺序</p><h4 id="11、Map-集合">11、Map 集合</h4><p>Set 与list 都属于 Collection<br>Map每个元素的值都包含两个对象：key-value 键值对<br>key不能够重复；唯一的key 可以对应多个value<br>map中不存在索引，有key<br>循环访问的方式</p><h4 id="12、Map集合-HashMap">12、Map集合-&gt;HashMap</h4><p>Hash算法<br>public class HashMap&lt;K,V&gt;extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable<br>允许null的值和null键<br>（1）初始化<br>HashMap&lt;key,value&gt; hashMap=new HashMap&lt;key,value&gt; ();</p><p>（2）主要的方法<br>put(K key, V value) 将指定的值与此映射中的指定键相关联<br>get(Object key) 返回到指定键所映射的值，或 null如果此映射包含该键的映射<br>Set keySet() 返回此地图中包含的键的Set视图<br>boolean containsKey(Object key) 如果此映射包含指定键的映射，则返回 true<br>boolean containsValue(Object value) 如果此地图将一个或多个键映射到指定值，则返回 true</p><h4 id="13、Map集合-HashTable">13、Map集合-&gt;HashTable</h4><p>不接受 Null<br>为了成功的在hashtable中存储和获取对象，用作键的对象必须实现 hashcode和equals方法</p><h4 id="14、总结">14、总结</h4><p>集合动态可扩展<br>Set代表无序集合不重复，（TreeSet 有序）<br>List集合有序可重复<br>Map 集合存储键值对- key value<br>自定义对象 要重写 方法（HashCode Comparator equals等）</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java常用API</title>
      <link href="/2019/01/18/java_chang_yong_api/"/>
      <url>/2019/01/18/java_chang_yong_api/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Java-API概述">1、Java API概述</h4><p>Java写好的包 类 方法的使用—API<br>Application Programing Interface：应用程序编程接口。Java提供的一些预定义的函数目的：基于API实现程序的快速编写。只需了解实现的作用，无需关注源代码</p><p>针对一个API首先看 概述了解 类的作用，然后看 构造函数了解如何创建类之后看方法，了解如何调用<br>Java lang–核心包 提供对Java编程语言设计至关重要的类，可以直接使用，不用import</p><h4 id="2、数值运算-Math类">2、数值运算 Math类</h4><p>Math类为Java提供的支持数值运算的类<br>Math类包含执行基本数字运算的方法，如基本指数，对数，平方根和三角函数</p><p>public final class Math—-完美类<br>（1）Math类提供的基本方法：<br>static double abs(double a) 返回值为 double绝对值<br>static double acos(double a) 返回值的反余弦值; 返回的角度在0.0到pi的范围内<br>static double atan(double a)<br>向上取整：<br>static double ceil(double a) 返回大于或等于参数的最小（最接近负无穷大） double值，等于一个数学整数<br>向下取整：<br>static double floor(double a) 返回小于或等于参数的最大（最接近正无穷大） double值，等于一个数学整数<br>四舍五入：<br>static long round(double a) 返回参数中最接近的 long ，其中 long四舍五入为</p><p>static double log(double a) 返回的自然对数（以 e为底） double值<br>static double log10(double a) 返回一个 double的基数10对数值<br>static int max(int a, int b) 返回两个 int值中的较大值<br>static double random() 返回值为 double值为正号，大于等于 0.0 ，小于 1.0<br>public static double sqrt(double a)</p><h4 id="3、字符串运算-String类">3、字符串运算 String类</h4><p>特殊的引用数据类型<br>public final class String—完美类<br>String a;<br>int a;</p><p>类名 对象名=new 类名();<br>String str = “abc”;<br>相当于：<br>char data[] = {‘a’, ‘b’, ‘c’};<br>String str = new String(data);—-不常见</p><p>char charAt(int index) 返回 char指定索引处的值</p><p>boolean contains(CharSequence s) 当且仅当此字符串包含指定的char值序列时才返回true</p><p>boolean equals(Object anObject) 将此字符串与指定对象进行比较</p><p>indexOf(String str) 返回指定子字符串第一次出现的字符串内的索引</p><p>length() 返回此字符串的长度。—循环的中止条件</p><p>boolean matches(String regex) 告诉这个字符串是否匹配给定的 regular expression</p><p>String replace(char oldChar, char newChar) 返回从替换所有出现的导致一个字符串 oldChar在此字符串 newChar</p><p>String[] split(String regex) 将此字符串分割为给定的 regular expression的匹配</p><p>String substring(int beginIndex) 返回一个字符串，该字符串是此字符串的子字符串</p><p>String toLowerCase() 将所有在此字符 String使用默认语言环境的规则，以小写</p><p>String toUpperCase() 将所有在此字符 String使用默认语言环境的规则大写</p><p>String trim() 返回一个字符串，其值为此字符串，并删除任何前导和尾随空格</p><p>/类型转换 将基本数据类型转换为 字符串/<br>static String valueOf(boolean b)<br>返回 boolean参数的字符串 boolean形式</p><p>static String valueOf(char c)<br>返回 char参数的字符串 char形式</p><p>static String valueOf(char[] data)<br>返回 char数组参数的字符串 char形式</p><p>static String valueOf(char[] data, int offset, int count)<br>返回 char数组参数的特定子阵列的字符串 char形式</p><p>static String valueOf(double d)<br>返回 double参数的字符串 double形式</p><p>static String valueOf(float f)<br>返回 float参数的字符串 float形式</p><p>static String valueOf(int i)<br>返回 int参数的字符串 int形式</p><p>static String valueOf(long l)<br>返回 long参数的字符串 long形式</p><p>static String valueOf(Object obj)<br>返回 Object参数的字符串 Object形式</p><p>String == 与equals的区别</p><p>如果声明String 是通过 String str=”” ，可以用 ==和equals<br>声明String 通过 new String(“”),不可以用 ==（调用 Object的equals方法） 只能用 equals</p><h4 id="4、字符串运算-大写字母-小写字母-数字出现的次数">4、字符串运算-大写字母 小写字母 数字出现的次数</h4><p>getCount(string s) AscII码对比 length 遍历</p><h4 id="5、字符串运算-查找父字符串中某一个子字符串出现的次数">5、字符串运算-查找父字符串中某一个子字符串出现的次数</h4><p>indexof 循环遍历子字符串出现的字数 就需要 截取 substring 把已找到的部分截取遍历后面的<br>边界条件</p><h4 id="6、字符串运算-split方法">6、字符串运算-split方法</h4><p>public String[] split(String regex)<br>该方法的工作原理是通过使用给定表达式和限制参数为零调用双参数split方法<br>因此，尾随的空字符串不会包含在结果数组中<br>例如：String s=“1#2#3#4#5#”<br>String[] res=s.split(“#”);<br>res=[“1”,”2”,”3”,”4”,”5”]</p><p>返回的子串的次数 应该是 数组的长度-1</p><p>前后台交互或者进行数据接口会用到</p><h4 id="7、字符串运算-规则匹配">7、字符串运算-规则匹配</h4><p>正则表达式 身份证号 电话号码 邮箱 QQ号等等<br>字符类：</p><table><thead><tr><th style="text-align:center">表示</th><th style="text-align:center">规则解释</th></tr></thead><tbody><tr><td style="text-align:center">[abc]</td><td style="text-align:center">a或b或c 都可以</td></tr><tr><td style="text-align:center">[a-zA-Z]</td><td style="text-align:center">a-z或者A到Z 两头的字母包含在内，所有字母都可以</td></tr><tr><td style="text-align:center">[0-9]</td><td style="text-align:center">0-9的数字都可以</td></tr><tr><td style="text-align:center">\d</td><td style="text-align:center">0-9的数字都可以</td></tr><tr><td style="text-align:center">\D</td><td style="text-align:center">[^0-9] 不是数字</td></tr><tr><td style="text-align:center">\w</td><td style="text-align:center">表示字母数字 下划线在内的任何字符 [a-zA-Z0-9_]</td></tr><tr><td style="text-align:center">X?</td><td style="text-align:center">X出现一次或一次也没有</td></tr><tr><td style="text-align:center">X*</td><td style="text-align:center">X零次或多次</td></tr><tr><td style="text-align:center">X+</td><td style="text-align:center">X至少出现一次</td></tr><tr><td style="text-align:center">X{n}</td><td style="text-align:center">恰好只有n次</td></tr><tr><td style="text-align:center">X{n,m}</td><td style="text-align:center">n=</td></tr></tbody></table><p>规则表达式：<br>^: 表示正则表达式的开头<br>$ : 表示正则表达式的结尾</p><p>例如：验证一个QQ号码<br>要求：<br>（1）QQ号码 5-15位<br>（2）0不能开头<br>规则表达式(字符串)：<br>regex=”[1-9]\d{4,14}”</p><p>public boolean matches(String regex)<br>告诉这个字符串是否匹配给定的regular expression<br>这种形式为str .matches( regex )方法的)产生与表达式完全相同的结果</p><p>Pattern. matches(regex, str)<br>参数<br>regex - 要匹配此字符串的正则表达式<br>结果<br>true如果，并且只有这个字符串与给定的正则表达式匹配<br>异常<br>PatternSyntaxException - 如果正则表达式的语法无效<br>//两个反斜杠 是转义的意思 (.\w{2,3})+ 表示 点出现一次或多次<br>// +号所跟的内容 如果在括号里面 表示 \w{2,3} 可以出现 多次</p><h4 id="8、Date">8、Date</h4><p>（1）概述<br>包含集合框架，旧集合类，事件模型，日期和时间设施<br>国际化和其他实用程序类（字符串tokenizer，随机数生成器和位数组）<br>Java.util.* 工具包<br>在JDK 1.1之前， Date有两个附加功能，它允许将日期解释为年，月，日，小时，分钟和第二个值。 它还允许格式化和解析日期字符串。 不幸的是，这些功能的API不适合国际化。 从JDK 1.1开始， Calendar类应该用于在日期和时间字段之间进行转换，<br>并且DateFormat类应用于格式化和解析日期字符串。 在相应的方法Date被弃用<br>允许JDBC将其标识为 SQlDate值<br>格林尼治标准时间（GMT）定义的，相当于世界时间（UT）<br>（2）构造方法<br>Date()<br>分配一个 Date对象，并初始化它，以便它代表它被分配的时间，测量到最近的毫秒</p><p>Date(long date)<br>分配一个 Date对象，并将其初始化为表示自称为“时代”的标准基准时间以后的指定毫秒数，即1970年1月1日00:00:00 GMT</p><p>（3）常用方法<br>boolean after(Date when)<br>测试此日期是否在指定日期之后</p><p>boolean before(Date when)<br>测试此日期是否在指定日期之前</p><p>Object clone()<br>返回此对象的副本</p><p>int compareTo(Date anotherDate)<br>比较两个日期进行订购</p><p>boolean equals(Object obj)<br>比较两个日期来平等</p><p>static Date from(Instant instant)<br>从 Instant对象获取一个 Date的实例</p><p>getTime()<br>返回自1970年1月1日以来，由此 Date对象表示的00:00:00 GMT的毫秒数</p><h4 id="9、Calendar">9、Calendar</h4><p>（1）简介<br>相对比较新的日期类，抽象类</p><p>public abstract class Calendar extends Object<br>implements Serializable, Cloneable, Comparable<calendar><br>所述Calendar类是一个抽象类<br>可以为在某一特定时刻和一组之间的转换的方法calendar fields如<br>YEAR ， MONTH ， DAY_OF_MONTH ， HOUR 等等，以及用于操纵该日历字段</calendar></p><p>（2）初始化<br>Calendar提供了一种类方法getInstance 用于获取此类型的一般有用的对象<br>Calendar的getInstance方法返回一个Calendar对象，其日历字段已使用当前日期和时间进行初始化<br>Date date=new Date(); —- 对象的初始化<br>Calendar rightNow = Calendar.getInstance(); —抽象类自带方法 获得对象</p><p>（3）常用的方法<br>boolean after(Object when)<br>返回 Calendar是否 Calendar指定时间之后的时间 Object</p><p>boolean before(Object when)<br>返回此 Calendar是否 Calendar指定的时间之前指定的时间 Object</p><p>int getWeekYear()<br>返回这个 Calendar</p><p>set(int year, int month, int date)<br>—Date的时候 需要计算一下 距离 1970 ms数</p><p>public abstract void add(int field,int amount)<br>根据日历的规则，将指定的时间量添加或减去给定的日历字段</p><p>例如，要从当前日历的时间减去5天，可以通过调用以下方法来实现<br>add(Calendar.DAY_OF_MONTH, -5)<br>public abstract void roll(int field,boolean up)<br>在给定时间字段上添加或减少单个时间单位，而不改变较大的字段</p><p>字段可以直接访问 static final ，使用 get set 方法 获得或设置字段值</p><p>public static final int YEAR—直接通过类名可以访问到年<br>public static final int MONTH<br>public static final int WEEK_OF_YEAR<br>public static final int WEEK_OF_MONTH<br>public static final int DAY_OF_YEAR</p><h4 id="10、DateFormat–xxxx年xx月xx日">10、DateFormat–xxxx年xx月xx日</h4><p>格式化日期<br>（1）简介<br>public abstract class DateFormat extends Format<br>DateFormat可帮助格式化和解析任何区域设置的日期</p><p>（2）初始化<br>public static final DateFormat getDateInstance()<br>// 抽象类<br>DateFormat df=DateFormat.getDateInstance;</p><p>（3）主要方法<br>String format(Date date) 将日期格式化成日期/时间字符串<br>Date parse(String source) 从给定字符串的开始解析文本以生成日期</p><h4 id="11、simpleDateFormat–DateFormat子类">11、simpleDateFormat–DateFormat子类</h4><p>（1）实现了 DateFormat 不是抽象类–优秀的实现类<br>public class SimpleDateFormat extends DateFormat</p><p>例如：转换成 2018/12/5 2018年12月5日<br>SimpleDateFormat允许从选择日期时间格式化的任何用户定义的模式开始。<br>yyyy年MM月dd日</p><p>（2）构造方法<br>SimpleDateFormat() 构造一个 SimpleDateFormat使用默认模式和日期格式符号为默认的 FORMAT区域设置<br>SimpleDateFormat(String pattern) 使用给定模式 SimpleDateFormat并使用默认的 FORMAT语言环境的默认日期格式符号<br>（不需要再使用后面的 applyPattern方法 可以直接赋值）</p><p>（3）主要方法<br>applyPattern(String pattern) 给定的模式字符串应用于此日期格式<br>String format(Date date) 将日期格式化成日期/时间字符串。—进行了重写<br>Date parse(String source) 从给定字符串的开始解析文本以生成日期。–进行了重写</p><p>小案例：我活了多久</p><h4 id="12、StringBuffer">12、StringBuffer</h4><p>（1）简介<br>和String一样 final –完美类 可以任意调节数据字符串的长度和内容<br>public final class StringBuffer<br>extends Object<br>implements Serializable, CharSequence</p><p>字符串缓冲区就像一个String ，但可以修改。 在任何时间点，它包含一些特定的字符序列。但可以通过某些方法调用来更改序列的长度和内容。 —-可以变化<br>例如： string s =”abc“;<br>s+=”1”;–abc1<br>Stringbuffer sbuffer =new StringBuffer();</p><p>（2）构造函数<br>StringBuffer() 构造一个没有字符的字符串缓冲区，初始容量为16个字符</p><p>（3）主要方法<br>append(String str) 将指定的字符串附加到此字符序列<br>—相当于 String+insert(int offset, String str) 将字符串插入到此字符序列中<br>toString() 将字符串转为string型</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java常用API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java面向对象3</title>
      <link href="/2019/01/16/java_mian_xiang_dui_xiang_3/"/>
      <url>/2019/01/16/java_mian_xiang_dui_xiang_3/</url>
      
        <content type="html"><![CDATA[<h4 id="1、访问控制权限（public，private，protected，default）">1、访问控制权限（public，private，protected，default）</h4><p>public&gt;protected&gt;default&gt;private<br>Java中用来控制类及类的方法和变量访问权限<br>（1）public ：公共的 表示包（package）内及包外的任何类（包括子类和普通类）都可以访问。—最开放<br>（2）protected：受保护的 表示包内的任何类及包外继承了该类的子类才能访问，突出继承<br>（3）default：默认的 表示包内的任何类都可以访问，但是包外的任何类都不能访问<br>（4）private：私有的 只有本类可以访问，包内外的任何类均不能访问。—封装</p><table><thead><tr><th style="text-align:center">访问控制修饰符</th><th style="text-align:center">同类</th><th style="text-align:center">同包</th><th style="text-align:center">子类</th><th style="text-align:center">不同的包</th></tr></thead><tbody><tr><td style="text-align:center">public</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">protected</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">default</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">private</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table><h4 id="2、多态定义">2、多态定义</h4><p>多态分为编译时的多态和运行时多态。其中编译时多态 也可称为静态多态<br>运行时的多态为动态多态，主要通过动态绑定来实现，常说默认的多态<br>多态 为了应对不同的变现形式</p><h4 id="3、静态多态">3、静态多态</h4><p>其实就是 方法的重载，主要根据参数列表的不同来区分不同的函数<br>静态多态 不需要继承</p><h4 id="4、动态多态">4、动态多态</h4><p>例如：品酒大师<br>三个杯子 倒了 3杯酒<br>酒 a= 五粮液；<br>酒 b= 茅台酒；<br>酒 c= 二锅头。<br>声明一个 酒的类，三种不同的酒 相当于不同的子类<br>只有在运行时 才能知道 喝的什么酒<br>所谓动态多态就是指 引用在不同的情况下所表现的实际对象<br>（1）继承（实现接口）。在多态中必须存在 父类与子类的关系<br>（2）重写。子类必须对父类的某些方法进行重新定义，在调用这些方法时 就会调用子类的方法<br>（3）向上转型：父类引用指向子类的对象</p><h4 id="5、向上转型">5、向上转型</h4><p>向上转型：子类的对象转换为父类类型<br>例如：<br>Wine wine=new WLY();—向上转型<br>Wine wine=new Wine();–正常实例化对象<br>子类的单独定义的方法会丢失，能访问子类重写父类的方法</p><h4 id="6、动态多态小案例–动物喂食">6、动态多态小案例–动物喂食</h4><p>养了一堆宠物 有狗 有猫。宠物喜欢吃什么 也要根据宠物的类型 来选择喂食<br>狗–骨头<br>猫–鱼</p><pre><code class="highlight plaintext">if(animal is dog ){ food=bone； eat food; }else if(animal is cat){ food= fish; eat fish. }</code></pre><p>可否写一个方法 来实现所有宠物的喂食</p><h4 id="7、向下转型">7、向下转型</h4><p>向下转型是把父类对象转换为子类对象<br>Animal animal=new Animal();<br>Cat cat = （Cat）animal —-不对的<br>把一个动物强制转换为 猫，如果这个动物是只狗，狗是变不成猫的<br>向下转型必须得有向上转型作为前提。因为只有子类相对应的才可以转换<br>代表这个动物是 猫，之后 把动物再变回为猫。—打回原形</p><h4 id="8、-内部类定义">8、.内部类定义</h4><p>在Java当中的一个类中在声明一个类 就叫 内部类<br>例如：</p><pre><code class="highlight plaintext">class Outter{   成员变量；   class Inner{   }   成员方法；}</code></pre><h4 id="9、内部类分类">9、内部类分类</h4><p>（1）（普通）成员内部类：与成员level一样，内部类中不能存在 static 关键字，不能够声明静态的方法、属性、静态代码块；<br>最普通的内部类<br>（2）静态（成员）内部类：使用static修饰的成员内部类<br>（3）（普通）局部内部类：局部范围内有效的内部类（例如：方法里面）<br>（4）匿名（局部）内部类：没有名字的局部内部类</p><p><strong>成员内部类定义</strong><br>（1）定义：与我们的成员变量一样，可以声明类名，在成员内部类中可以声明属性和方法<br>（2）作用：<br>a、成员内部类可以无限制访问外部类的变量和方法（包括private修饰的）<br>b、内部类可以有多个<br>c、成员内部类与外部类如果存在同名的成员变量或方法，优先是内部的。如果访问外部类的<br>需要 Outter.this.(变量或方法名)</p><h4 id="10、成员内部类与外部类的访问">10、成员内部类与外部类的访问</h4><p>（1）成员内部类访问外部类 无限制<br>（2）外部类访问内部类的成员，不是无限制的<br>首先要传建一个内部类的对象，然后通过对象来访问</p><h4 id="11、成员内部类的初始化">11、成员内部类的初始化</h4><p>不是在类里面操作，如果是其他类要访问时，要访问内部类，首先实现外部类的实例化之后再实例化内部类<br>（1）在外部类对象初始化基础之上初始化内部类，调用内部类的构造函数<br>Outter.Inner inner=outter.new Inner();<br>（2）通过外部类的成员方法获得成员内部类的对象，然后访问其变量和方法</p><h4 id="12、静态内部类">12、静态内部类</h4><p>使用 static修饰的成员内部类叫做静态内部类<br>定义格式如下：</p><pre><code class="highlight plaintext">class Outter{static  class inner{    }}</code></pre><p>外部类不是静态也可以声明静态内部类<br>静态内部类 要类比 静态成员变量<br>静态内部类可以通过外类直接调用 new Outter.Inner();<br>静态内部类内部可以直接访问外部类中所有的静态变量和方法（包含private）</p><h4 id="13、局部内部类">13、局部内部类</h4><p>定义在代码块、方法体等的类叫局部内部类<br>—局部变量 类比<br>不能够有 public protected private 以及 static 修饰</p><pre><code class="highlight plaintext">class Outter{    public void func(){         class inner{         }     }}</code></pre><p>局部内部类只是在一个方法或区域里起作用</p><h4 id="14、匿名内部类">14、匿名内部类</h4><p>没有名字的局部内部类<br>必须要继承一个父类或者实现一个接口<br>定义形式：<br>正常初始化对象：</p><pre><code class="highlight plaintext">类名 对象名=new 类名（）；匿名内部类：  new 父类构造方法（）{     //重写一个函数     修饰符 返回参数类型 方法名（参数列表）{      } }；</code></pre><p>局部内部类的区别 局部的位置不同<br>匿名内部类当中不能够有静态属性和静态方法<br>匿名内部类 不需要新建一个类 而是通过匿名的形式吧 实现方法的重写<br>匿名内部类尤其针对 Android开发 例如 监听 鼠标事件 键盘 触屏输入</p><pre><code class="highlight plaintext">Lisenter（）{    @override    MouseMoniter（）{    }}；</code></pre><h4 id="15、总结内部类">15、总结内部类</h4><p>（1）成员内部类<br>（2）静态内部类<br>（3）局部内部类<br>（4）匿名内部类<br>a、每个内部类都可以独立的继承或实现一个接口，而外部类也可以继承一个直接父类。 —多继承的一种表现<br>b、通过内部类可以实现对外界的隐藏。–封装<br>c、内部类可以无限制的使用外部类的成员变量（包括私有），不用生成外部类的对象<br>d、匿名内部类可以简化代码的编写，方便编写事件驱动的程序、线程程序<br>e、成员内部类 静态内部类 可以对比 成员变量和静态变量<br>局部内部类 匿名内部类 可以对比局部变量</p><h4 id="16、面向对象总结">16、面向对象总结</h4><p>封装 继承 多态<br>面向对象的思路去设计程序</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java面向对象 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java面向对象2</title>
      <link href="/2019/01/14/java_mian_xiang_dui_xiang_2/"/>
      <url>/2019/01/14/java_mian_xiang_dui_xiang_2/</url>
      
        <content type="html"><![CDATA[<h4 id="1、static关键字">1、static关键字</h4><p>（1）主要用来修饰类的成员（成员变量、方法）<br>例如：main函数 static 修饰<br>（2）static 特点<br>a、static 修饰的成员在类加载的时候直接运行，优先级要高<br>b、通过类直接访问 类名.成员<br>c、static是针对所有对象的属性值相同时才使用 static 修饰<br>d、被static修饰的方法 无法是有非静态变量；非静态方法 不受限制</p><h4 id="2、静态构造代码块">2、静态构造代码块</h4><p>形如：</p><pre><code class="highlight plaintext">class 类名{ static{ 变量; } }</code></pre><p>主要是为了 方便变量的统一初始化 执行且只执行一次</p><h4 id="3、构造代码块">3、构造代码块</h4><p>直接在类中定义没有被 static修饰的代码块<br>形如：</p><pre><code class="highlight plaintext">class 类名{ { 变量; }–构造代码块 func（）{ {}–普通代码块} }</code></pre><p>构造代码块可以执行多次，在创建对象的时候使用<br>优先级：先是 静态构造代码块&gt;构造代码块&gt;构造函数</p><h4 id="4、继承的介绍与使用">4、继承的介绍与使用</h4><p>（1） extends 多个类中存在相同属性和行为时，将这些内容抽象到单独的一个类中，那么多个类<br>无序再定义这些属性和行为，只需要继承即可<br>父类：又叫基类，超类<br>子类：派生类<br>（2）子类可以访问父类中的非私有的属性和行为<br>（3）子类不能够继承父类的构造方法<br>（4）父类可以被多个子类继承，但是子类只有一个直接父类<br>（5）继承多以存在多级</p><h4 id="5、方法重写">5、方法重写</h4><p>重载：在同一类中 方法名一样 参数列表不同<br>重写：在继承中出现的，是子类与父类具有相同的方法，子类的这一个方法 叫做重写<br>方法名、返回值、参数列表相同（不同的是函数体） 覆盖</p><h4 id="6、super关键字">6、super关键字</h4><p>super 作用<br>（1）在子类的构造方法中直接通过super关键字 调用父类的构造方法<br>如果父类有多个构造函数 根据 参数列表来区分 必须放在第一行<br>（2）如果父类与子类中有同名成员变量，此时要访问父类成员变量可以通过super<br>（3）如果子类重写了父类的方法 ，可以通过 super调用父类的方法<br>this–当前对象 子类的方法、属性<br>super–父类对象 父类的方法、属性<br>（4）子类而言 是不是继承了我们父类的所有，自然我们继承了 父类的父类的成员变量和方法<br>所以可以直接通过super调用<br>super.super 多余了<br>（5）破坏了 Java的封装性 只有一个直接父类</p><h4 id="7、final关键字的使用">7、final关键字的使用</h4><p>final关键字 是一个修饰符，用来修饰 类 方法 变量<br>（1）final修饰一个类，则不能够被继承<br>final类 不想被重新进行重写方法、扩展属性—-直接用 不想被人改变 完美<br>例如：String<br>（2）final 修饰方法，则方法不能够被重写<br>（3）final修饰变量，如果这个值一旦被指定 则 无法改变</p><h4 id="8、static-与-final-关键字">8、static 与 final 关键字</h4><p>static：静态变量 只保留一个副本<br>final：用来表示变量不可变<br>被static 修饰以后 只有一个值<br>final 有多个值 因为每次都会赋予一个值 只是保证赋予的这个值不变</p><h4 id="9、Object-类">9、Object 类</h4><p>顶级父类，是任何类的父类，可以显式的继承 也可以隐式的继承<br>需要重写的方法<br>toString 方法：需要重写 来满足业务需求<br>equals 方法。比较的是地址<br>应用比较广泛</p><h4 id="10、抽象方法">10、抽象方法</h4><p>（1）抽象方法是一种特殊的方法，只有声明没有方法体<br>（2）声明的格式为：<br>abstract 返回值类型 func(参数列表)–抽象方法<br>(public static void main(){方法体})<br>（3）抽象方法存在的意义在于 父类不想或者无法提供方法的方法体（具体实现）<br>只知道有这个方法（针对不同的类 实现方法 不一样）</p><h4 id="11、抽象类">11、抽象类</h4><p>（1）如果一个类中含有抽象方法，则该类必须被定义为抽象类<br>反过来 抽象类中不一定含有抽象方法<br>（2）声明的格式：<br>abstract class 类名{}—抽象类<br>（3）抽象类特点：<br>a、抽象方法与抽象类均不可以被 final修饰<br>b、如果一个类继承抽象类，则必须完全实现其抽象方法，否则声明为抽象类<br>c、抽象方法必须为 public 或 protected 修饰，不能够用 private 或 static</p><h4 id="12、接口-interface">12、接口(interface)</h4><p>//数据接口–数据接口协议<br>（1）抽象类的延伸–在一个类中如果所有的方法都是抽象的，则可定义成接口<br>接口比抽象类 更加纯粹。全抽象的<br>（2）接口实现 implements —-对比 继承 extends<br>（3）Java中 子类只能够有一个直接父类，要多继承，必须使用接口<br>接口可以实现多次<br>例如：<br>class A implements I1,I2{</p><p>}<br>//可以组合写 接口可以实现无限个<br>class A extends B implements I1,I2{</p><p>}<br>（4）接口的声明：<br>interface 接口名{}<br>（5）接口不可以实例化，只能够用于实现。<br>（6）接口当中可以含有成员变量和方法，方法都是抽象的<br>变量–public static final<br>一般情况下不要在接口中定义变量<br>（7） 接口中可以定义默认的方法 default 和静态方法</p><h4 id="13、接口与抽象类的区别">13、接口与抽象类的区别</h4><p>（1）抽象类可以实现接口，接口可以继承接口<br>（2）接口中定义的方法都是抽象的，而抽象类中可以含有普通方法<br>（3）接口中的成员变量 都是public static final的，而抽象类中可以有普通变量<br>（4）接口中一定不含有构造方法，但抽象类中可以有构造方法<br>（5）接口不可以实例化，抽象类可以在子类创建对象的时候自动创建抽象类的对象<br>（6）接口可以多实现，但是抽象类只能够单继承</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java面向对象 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java面向对象1</title>
      <link href="/2019/01/12/java_mian_xiang_dui_xiang_1/"/>
      <url>/2019/01/12/java_mian_xiang_dui_xiang_1/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Eclipse-使用">1、Eclipse 使用</h4><p>IDE：<br>idea myeclipse eclipse NetBeans （visual studio）<br>idea 目前比较流行 有兴趣的可以了解下<br>Git：版本管理工具 从GIt上下载工程<br>JSP：页面 web应用 开发jsp应用<br>点击右上角–》Java<br>（1）选择一个工作空间 —workspace<br>就是电脑上的一个路径，默认的工作空间<br>eclipse-workspace 可以有中文路径<br>（2）project 项目<br>file-&gt;new Java project-&gt;输入工程名-&gt;finish<br>（3）package 包<br>file-&gt;new package-&gt;包的名字（com.ali.entity…）<br>（4）class 类<br>file-&gt;new class-&gt;类的名字（符合规范 字母 数字 下划线 $）<br>（5） run 运行<br>点击 绿色的小三角 run<br>结果在 consonle 去查看<br>WorkSpace-&gt;project-&gt;package-&gt;class run(Javac Java)<br>（6）Eclipse 设置字体大小<br>preference——&gt;font-&gt; Java –设置字体的大小<br>（7）Eclipse 常用快捷键<br>// /<strong>/<br>ctrl+/ 单行注释 //<br>ctrl+shift+/ 多行注释 /</strong>/<br>ctrl+shift+\ 取消多行注释<br>ctrl+s 保存 没事 多按按<br>ctrl+shit+s 工程保存<br>alt+/ 自动补齐<br>ctrl+d 删除<br>ctrl+z 撤销<br>ctrl+shift+f：代码格式化（注意跟 输入法的冲突）<br>ctrl+shift+o：实现包的组织。去除无用的包 实现未导入包的导入</p><h4 id="2、面向对象概述">2、面向对象概述</h4><p>Java语言最大的特点<br>面向对象是对现实世界理解和抽象的一种方法<br>核心思想：<br>大象放冰箱里<br>大象：（定义一个类 规定一些属性 身高 体重）<br>冰箱：（定义成一个类 品牌 功率 大小 ）<br>猴子对象<br>冰箱.OpenDoor();<br>冰箱.Save(大象)；<br>冰箱.Close();</p><h4 id="3、面向对象与面向过程">3、面向对象与面向过程</h4><p>面向过程：传统程序设计的设计思路。将一个问题看成是一系列函数或者模块的集合<br>自顶向下<br>例如：<br>方法1： 开冰箱门<br>方法2： 放大象<br>方法3：关冰箱门<br>关猴子 重新写方法2<br>最大的区别：面向对象的程序设计具有更高的灵活性，便于程序的扩展和升级<br>面向过程主要是针对特定需求满足某业务条件下的设计<br>面向对象的三大特征：封装 继承 多态</p><h4 id="4、对象">4、对象</h4><p>对象指的是一个具体实例，包含属性和方法<br>例如：<br>夏天属性：身高 体重 年龄 姓名<br>夏天方法：能吃 能睡 工作</p><h4 id="5、类">5、类</h4><p>具有相同属性和方法的一组对象的集合</p><h4 id="6、类和对象的关系">6、类和对象的关系</h4><p>对象指的是一个具体的实例<br>类：例如 同学<br>没有指名道姓就不是对象<br>类下面可以有子类 例如： 老鼠是个类 田鼠也是一个类 是老鼠的子类<br>老师、 数学老师、物理老师等都是类</p><h4 id="7、类的创建">7、类的创建</h4><p>（1）4类8种 基本数据类型<br>（2）引用数据类型：String 数组 接口等<br>自定义的数据类型–用户自己创建的类<br>（3） 修饰符（public等）</p><pre><code class="highlight plaintext">class 类名{ 属性：成员变量； 方法：成员函数； } 例如:手机类 public class Phone {}</code></pre><h4 id="8、类和对象的创建与使用">8、类和对象的创建与使用</h4><p>类名 对象名=new 类名（）;<br>（1）类名 对象名=new 类名（）；–基本形式。<br>可以调用不同参数类型的构造函数 –带参数的形式<br>（2）对象里面的属性（成员变量）、方法<br>通过 对象名.属性<br>对象名.函数<br>实现访问<br>（3）不同的对象 的属性值是不同的 ，而且不交叉<br>相当于一个独立的个体<br>具有独立的地址和存储空间<br>（4）实现对象之间的交互</p><h4 id="9、成员变量与局部变量">9、成员变量与局部变量</h4><p>（1）成员变量：对象的属性，放在对象之内<br>（2）局部变量：是在 方法里面 或者 for(int i)<br>成员变量：堆中<br>局部变量 栈中<br>Heap：堆 是临时的 由创建对象时所开辟的一块空间，对象销毁之后，系统回收<br>栈：是方法生成的时候，压栈生成。整个程序结束后才结束。<br>封装 继承 多态 三大特征—-面向对象</p><h4 id="10、封装">10、封装</h4><p>封装：在生活中 包裹。隐私性比较好<br>程序：通过封装成接口，通过方法来调用<br>（1）实现数据的访问权限控制，不是所有人都可以访问<br>（2）实现数据赋值的规范化、标准化的管控<br>例如： person中的性别<br>（3）实现封装的方法是<br>成员变量 加修饰符 private 私有的 无法直接访问 需要生成方法</p><h4 id="11、自动生成-getters-和-setters">11、自动生成 getters 和 setters</h4><p>右键-&gt;source-&gt;generate getters and setters-&gt;选中对象的私有属性-&gt;直接生成方法</p><h4 id="12、构造函数">12、构造函数</h4><p>new 对象的时候 直接初始化 用到构造函数。–&gt;直接赋值<br>例如： int[] arr=new int[]{1,2,3};<br>Person p=new Person(“张三”，20，’男’);<br>构造函数是一种特殊的方法，<br>主要是用来对对象初始化。总是与new 放在一起使用<br>构造函数的函数名是与类名一致<br>构造函数的重载。参数列表不一致的，但是函数名一致的方法<br>按住 ctrl+ 鼠标左键 Open declaration 进入到具体的函数或变量定义的地方</p><h4 id="13、构造函数注意事项">13、构造函数注意事项</h4><p>（1）构造函数 没有返回值<br>（2）构造函数默认存在一个无参的， 自己写一个无参构造函数后 会把默认的冲掉<br>（3）对象在生成的时候调用且只调用一次构造函数<br>（4）如果构造函数调用失败 则无法创建对象<br>（5）对象实例化时 由虚拟机自动调用的</p><h4 id="14、this关键字">14、this关键字</h4><p>this 表示当前类的对象，哪个对象调用了this所属的方法，this表示哪个对象<br>通过this 可以调用当前对象的 成员变量和方法<br>this(); 表示调用当前对象的无参构造函数</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java面向对象 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础5</title>
      <link href="/2019/01/11/java_ji_chu_5/"/>
      <url>/2019/01/11/java_ji_chu_5/</url>
      
        <content type="html"><![CDATA[<h4 id="1、数组概述">1、数组概述</h4><p>数组是相同数据类型的一组数据集合。 4类8种基本数据类型<br>数组有索引–代表不同的数值<br>football[7]–&gt;C罗<br>Basketball[23]–&gt;乔丹<br>不同的球队 可以看成不同的数组<br>同一个球队里面 每个球员的编号 唯一<br>数组的长度固定<br>数组的索引从0开始<br>length 数组大小</p><h4 id="2、一维数组">2、一维数组</h4><p>（1）定义数组<br>dataType 数组名[]<br>dataType[] 数组名—-》<br>例如： int[] array;<br>（2）初始化数组<br>a、首先要确定数组的大小<br>定义时候直接确定：dataType[] array=new dataType[size];<br>dataType[] array;<br>array=new dataType[size];<br>(3) 数组的赋值<br>给数组的元素进行赋值<br>a、 动态赋值<br>b、静态赋值</p><pre><code class="highlight plaintext">dataType[] array=new dataType[]{}; dataType[] array={};</code></pre><h4 id="3、二维数组">3、二维数组</h4><p>矩阵。 m[i][j] 第i行 j列<br>表示一个 由行列组成的数据，例如 表格<br>10个班级 每个班级有 20 学生 成绩 记录下来<br>用行数 表示 班级<br>用列数表示 每个班级的学生<br>a[10][20]=成绩<br>比如： 小明 第2 班级的底1号学生<br>a[1][0]=90;<br>String[] s;<br>(1)二维数组的声明<br>dataType[][] d_arr=new dataType[row][col];<br>(2)二维数据的初始化<br>a、动态赋值<br>嵌套for循环 遍历二维数组的每个元素<br>b、静态赋值</p><pre><code class="highlight plaintext">dataType[][] d_arr=new dataType[][]{{},,…,{}}; dataTyep[][] d_arr={{},{},…,{}};</code></pre><p>二维数组实现 矩阵相乘</p><h4 id="4、方法的概述">4、方法的概述</h4><p>解决某件事情的办法；函数 main<br>计算一个结果<br>处理一段业务逻辑<br>有助于程序的模块化开发和处理<br>方法=函数<br>main函数里面 String[] args 表示的 main函数接受的参数</p><h4 id="5、方法的定义格式">5、方法的定义格式</h4><p>修饰符 返回值类型 方法的名字（参数列表…）{<br>方法的功能主体<br>return ；// 也可以没有<br>}</p><h4 id="6、方法定义的注意事项">6、方法定义的注意事项</h4><p>（1）方法不能定义在其他方法之中 独一性<br>（2）方法如果有返回值类型 一定要返回相应类型的数据<br>例如： double func1（） { return double；不能为 int}<br>（3）调用方法的时候 参数列表一定要对应好<br>例如 func1（int a,b,c）{ (a+b)*c}<br>（4）方法不能重复定义 如果一个方法名字 已经用过了 如果还要用 就需要重载<br>（5） 参数类型与返回值类型无关</p><h4 id="7、方法的重载特性">7、方法的重载特性</h4><p>同一个类中 允许出现同名的方法，只是方法的参数列表不同，这样的方法称为重载<br>参数列表不同：表示 参数的个数不同 参数数据类型不同<br>（1）重载与参数变量名无关<br>（2）重载与返回值类型无关<br>（3）重载与修饰符无关</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础4</title>
      <link href="/2019/01/09/java_ji_chu_4/"/>
      <url>/2019/01/09/java_ji_chu_4/</url>
      
        <content type="html"><![CDATA[<h4 id="1、位运算符">1、位运算符</h4><p>主要针对二进制数。 只有 0 1 两种形态。加快运行速度<br>&amp;：位与 两个数同时为1 则为1 否则为0<br>|：位或 两个数中有一个为1 则为1 否则为0<br>^: 异或 相同为0 不同为1</p><p>: 右移运算符 代表位数向右移动<br>&lt;&lt;:左移运算符 代表位数向左移动</p><p>: 无符号右移<br>移动位数很多时，其实按数据的实际有效位数例如 32位，移动位数100%最大位数32 肯定是在32位之内</p><h4 id="2、三元运算符">2、三元运算符</h4><p>布尔表达式？结果1：结果2<br>如果布尔表达式的结果为 true ，进行结果1<br>如果布尔表达式的结果为 false ，进行结果2</p><h4 id="3、转义运算符">3、转义运算符</h4><p>字符并不是你看起来的那个样子，转义了<br>a、八进制转义<br>+用1-3位的8进制数字，范围‘000’-‘377’<br>例如： \0;<br>b、unicode 转义字符<br>\u+ 4位十六进制数字：0-65535<br>\u0000<br>c、特殊字符<br>\”：表示双引号<br>\’:单引号<br>:反斜线<br>d、控制字符<br>\r :回车<br>\n: 换行<br>\t: tab<br>\b:退格</p><p>程序控制语句（顺序 条件 循环）</p><h4 id="4、-if-条件语句">4、 if 条件语句</h4><p>只要满足某种条件就处理，不完全是 顺序结构，可以跳着执行<br>（1） if （条件语句）{<br>—建议将{ 起始位置写在 if条件之后 便于知道 if语句的范围<br>执行语句；<br>}<br>if else 如果满足条件，我将如何做，否则我该如何做<br>（2） if(条件语句){</p><pre><code class="highlight plaintext">if(条件语句){ 执行语句1； }else{ 执行语句2； }</code></pre><p>（3） if…else if（多个）… else</p><pre><code class="highlight plaintext">if(1){ 学习； }else if(2){ 运动； }else if(3){ 看电视剧;}else{ 睡觉}</code></pre><h4 id="5、-switch-条件语句">5、 switch 条件语句</h4><p>形式如下：与 if else if else 很类似</p><pre><code class="highlight plaintext">switch （条件表达式）{ case 值1： 语句1； break ； case 值2： 语句2； break ； …. default : 语句n； break ； }</code></pre><h4 id="6、-for-循环语句—使用非常广泛">6、 for 循环语句—使用非常广泛</h4><p>（1）单层 for 循环语句<br>for(表达式1；表达式2；表达式3){<br>循环体。//就是表示此部分语句需要执行多次。 回旋 跑圈<br>}<br>表达式1：主要是赋一个初始化值， 循环变量的最开始值；<br>表达式2：用来判断 循环变量的值 是否达到 临界值<br>表达式3：主要用来实现 循环变量的增加或减少<br>执行顺序：表达式1 表达式2 循环体 表达式3 表达式2 循环体 表达式3 表达式2 循环体<br>{}–注意 循环体的花括号 可以省略 但是是针对循环体内只有一条语句的情况。<br>(2)嵌套for循环–》在for循环体里面又至少写了一层for循环</p><pre><code class="highlight plaintext">for(;;){ for(;;){ …. } }</code></pre><h4 id="7、-while-循环语句">7、 while 循环语句</h4><p>while(条件表达式){<br>循环体；<br>}<br>注意 ：条件表达式 一定要注意终止和结束 出现死循环</p><h4 id="8、-do-while-循环语句">8、 do while 循环语句</h4><p>do{</p><p>}while(条件表达式)<br>区别： do while 是先执行后判断，至少执行一次<br>while 循环 是先判断后执行</p><h4 id="9、-break-中止语句">9、 break 中止语句</h4><p>应用：循环体 + 条件语句 switch case<br>（1）针对单层循环结构，表示退出循环<br>（2）针对嵌套循环，表示退出当前的循环<br>（3）switch 条件语句 表示中止 条件语句</p><h4 id="10、-continue-语句">10、 continue 语句</h4><p>继续。循环语句里面 使用 continue，并不是中止循环体</p><h4 id="11、-return-语句">11、 return 语句</h4><p>return 的作用主要是<br>（1）用来返回方法的指定类型值<br>（2）结束方法的执行<br>都能中止方法的运行</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础3</title>
      <link href="/2019/01/07/java_ji_chu_3/"/>
      <url>/2019/01/07/java_ji_chu_3/</url>
      
        <content type="html"><![CDATA[<h4 id="1、数据类型的转换">1、数据类型的转换</h4><p>主要是指的 不同的数据类型之间进行转换<br>（1）自动类型转换<br>范围小的数据类型值，转换为范围大的数据类型的值<br>例如 byte int 自动 byte 转换为 int<br>byte-&gt;short-&gt;int-&gt;long-&gt;float-&gt;double<br>（2）强制数据类型转换<br>数据范围大的转换为数据类型小的<br>强制类型转换不会报错，只是损失了精度<br>例如：喝多了：：： 记不住 精度 就丢失了<br>double 2.134 –&gt; int 2 0.134 没了<br>数据类型之间进行强制转换。比如：<br>int 转换为 String 或者 String转换为 int<br>String与日期类型 转换<br>“2018-11-6 20:37:66:002”–&gt;Date 先记住 后面会在API<br><a href="//Integer.Valueof">//Integer.Valueof</a>() ParseInt()</p><h4 id="2、算术运算符">2、算术运算符</h4><p>加减 乘除 求余运算。 + - * / %<br>运算后赋值。赋值运算。<br>+= 相当于 +完之后 赋值 例如 int a=0; a+=10; a=a+10;<br>-=<br>/=<br>关于/，一定要记得 0不能作为除数。异常</p><h4 id="3、自增自减运算符">3、自增自减运算符</h4><p>++ – int a； 都代表 1次<br>a++:表示自己增加1 表示 先使用变量a 再进行自加运算<br>++a:表示自己增加1 表示 先自加运算 再使用变量a<br>a–:表示自己减少1 表示 先使用变量a 再进行自加运算<br>–a:表示自己减少1 表示 先自减运算 再使用变量a</p><p>一般是在 循环的时候使用–后面讲流程控制时 会详细讲</p><h5 id="4、比较运算符">4、比较运算符</h5><p>&lt; &lt;= &gt;= == !=<br>进行数据的比较，最后的结果为一个 boolean类型的结果<br>条件语句。（if else case while）</p><h4 id="5、逻辑运算符">5、逻辑运算符</h4><p>逻辑与：<br>&amp;：表示只有表达式两边都是 true 结果才为 true<br>&amp;&amp;：表示只有表达式两边都是 true 结果才为 true<br>区别：短路，提前结束这个判断过程<br>&amp;&amp; 如果第一个条件为 false 则 后面的语句不再运行。 可以加快速度<br>&amp;： 不具有短路功能，从左到右 依次执行<br>逻辑或<br>||：有一个为 true 就为 true<br>|：有一个为 true 就为 true<br>区别： 短路，提前结束这个判断过程<br>||：如果第一个条件为 true 那么后面不再判断，直接输出为 true；<br>|：不具有短路功能，从左到右 依次执行<br>逻辑非<br>！非真即假 非假即真</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础2</title>
      <link href="/2019/01/06/java_ji_chu_2/"/>
      <url>/2019/01/06/java_ji_chu_2/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Java注释">1、Java注释</h4><p>(1)单行注释 //<br>只能注释一行，而且注释使用实在 // 之后。不会运行<br>例如：<br>(2)多行注释 /**/<br>可以注释多行内容。 主要用来说明一段代码或者一个函数的作用<br>(3)文档注释 /*/<br>主要用来说明类的功能，包含的函数、字段以及主要的作者、版本 相关的参数 异常等<br>author：作者<br>version：版本<br>see：参考 一个url链接<br>param：参数<br>return 返回值<br>代码注释很重要 因为不止是对别人看你或理解你的代码，而且对自己也有好处</p><h4 id="2、Java标识符">2、Java标识符</h4><p>所谓标识符就是对Java当中的 变量、类名、对象名、函数等自己的名字，<br>名字必须得符合规范<br>字母、数字、下划线和美元符号组成<br>注意：a、不能以数字开头<br>例如： 1a 错误 但是可以写成 a1<br>b、一般情况下不以美元开头<br>c、见名知意：<br>例如：zhidao licheng juli xingming—不可取<br>Distance Name—推荐用英语 并不是完全的英语照搬<br>xuehao –StudentNumber–&gt;StuNumber、 StdNum StdId<br>d、Java严格区分大小写<br>例如： a 与 A 就是两个变量<br>e、不要使用关键字：<br>例如： public static void if else switch<br>f、驼峰命名法<br>变量： 头一个字母小写 stdName<br>类名：首字母大写 Student StudentInfo<br>具体与单位的要求有关</p><h4 id="3、Java关键字">3、Java关键字</h4><p>（1）所有Java里面被赋予了特殊含义的单词，就叫做关键字<br>（2）Java关键字都是小写<br>a、用于定义数据类型： int class 等<br>b、数据类型值： true false null 等<br>c、流程控制的： for if 等<br>d、访问控制权限的： public 等<br>e、变量、函数等修饰的： static 等<br>f、异常处理的： try catch 等</p><h4 id="4、Java基础数据类型">4、Java基础数据类型</h4><p>计算机里面存储设备的最小单元：位（bit）<br>最小存储单元：1 B=8位 Bit<br>1KB=1024B<br>1MB=1024KB<br>1GB=1024MB<br>1TB=1024GB<br>PB级 的数据量 大数据<br>1PB=1024TB</p><h4 id="5、基本数据类型-4类8种">5、基本数据类型 4类8种</h4><p>（1）整数类型： byte ：1个字节（8位） 范围比较小：-128~127<br>short ：2<br>int:4<br>long :8<br>（2）浮点型（小数）：<br>float ：4 单精度<br>double ：8 双精度 精度高<br>（3）字符型：<br>char ：2 一个字符<br>例如：’笑’、’A’<br>（4）布尔型： boolean ：1个字节 true false</p><h4 id="6、引用数据类型（包含自定义）">6、引用数据类型（包含自定义）</h4><p>String 型<br>“大家好，欢迎来TZ学习。”<br>数组<br>类等</p><h4 id="7、常量">7、常量</h4><p>常量是一种特殊的变量，只不过是值被设定后，不能改变<br>例如： final(关键字) PI=3.1415926;</p><h4 id="8、变量">8、变量</h4><p>变量是可以随着程序的变化而改变赋值<br>int a=10;<br>a=11;</p><h4 id="9、定义基本数据类型变量">9、定义基本数据类型变量</h4><p>三要素： 指明类型（整数型、浮点型等）、变量命名、变量赋值（可以没有）</p><h4 id="10、字符串变量的定义">10、字符串变量的定义</h4><p>字符串变量 引用数据类型。应用比较广泛。<br>字符串变量赋值变化时，相当于重新指向了一个对象</p><h4 id="11、数据类型的转换">11、数据类型的转换</h4><p>主要是指的 不同的数据类型之间进行转换<br>（1）自动类型转换<br>范围小的数据类型值，转换为范围大的数据类型的值<br>例如 byte int 自动 byte 转换为 int<br>（2）强制数据类型转换<br>数据范围大的转换为数据类型小的<br>数据类型之间进行强制转换。比如：<br>int 转换为 String 或者 String转换为 int<br>String与日期类型 转换</p><h4 id="12、算术运算符">12、算术运算符</h4><p>加减 乘除 求余运算<br>+=<br>-=<br>/=<br>自增自减运算符</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础1</title>
      <link href="/2019/01/03/java_ji_chu_1/"/>
      <url>/2019/01/03/java_ji_chu_1/</url>
      
        <content type="html"><![CDATA[<h4 id="1、计算机语言发展史">1、计算机语言发展史</h4><p>Java语言是计算机语言的一种<br>（1）语言：汉语 英语 阿拉伯语 日语—&gt;人与人进行沟通的 一种方式<br>语义。—-》自然语言处理 人工智能中 文本分析 NLP<br>（2）机器语言：人与计算机沟通的语言。—Java 就是其中一种<br>类似于英语在自然语言中的地位 很流行 很主流<br>a、机器语言–初级形态：用二进制编码来表示计算机能够识别和执行的一种机器指令集合<br>例如：0 1 二进制编码 10进制<br>101010110—》启动声卡<br>b、机器语言—中级形态：汇编语言，用一种助记符来机器指令，成为符号语言。<br>例如：mov–表示数据的移动<br>rm-删除<br>add<br>c、机器语言—-高级形态：高级语言。一种接近人们使用习惯高级程序语言<br>例如：c=a+b; 实现数据的加和<br>常见的高级程序语言：Java、C、C++、C#、R、Python、Scala、VB、PHP等等</p><h4 id="2、Java语言概述">2、Java语言概述</h4><p>Java语言是一门非常年轻的语言 90后。最早是SUN —–Jamse Gosling（Java之父）<br>Oak–橡树。—Java 看到一个人 拿着爪哇杯 喝咖啡<br>Java语言随着互联网的发展，跨系统、跨平台 能够运行<br>Java语言获得了飞速的发展<br>Java 也形成了自己的一套方法 体系。封装了很多成熟可用的方法可以直接调用<br>API文档 —葵花宝典 Java 字典</p><h4 id="3、Java语言的特性和优点">3、Java语言的特性和优点</h4><p>（1）跨平台—一次编写 到处运行<br>（2）面向对象—万事万物，皆为对象。 类<br>（3）相对简单—有C语言基础或者其他语言基础，语言之间是有相同性<br>要知道 Java语言的基本语法、基本数据类型、基本程序控制</p><h4 id="4、Java的开发环境">4、Java的开发环境</h4><p>（1）JDK：Java development Kit： 开发者工具包<br>（2）JRE：Java Runtime Environment：Java 运行环境—只做运行 不做开发时<br>（3）JVM：Java Virtual Machine：Java 虚拟机<br>所有的Java程序都运行在 jvm上<br>JDK或JRE具备后，程序会调用生成 JVM<br>JDk包含JRE</p><h4 id="5、JDK的安装与配置">5、JDK的安装与配置</h4><p>jdk 下载官网地址：<a href="https://www.oracle.com/technetwork/Java/Javase/downloads/jdk8-downloads-2133151.html">https://www.oracle.com/technetwork/Java/Javase/downloads/jdk8-downloads-2133151.html</a><br>（1）针对从官网上下载的 .exe的安装包<br>a、 选择适合你电脑操作系统和位数的 JDK版本<br>例如Mac linux 还有 32位或64位<br>b、要增加以下<br>1）Java_HOME:jdk 安装的目录。C:\Program Files\Java\jdk1.8.0_171<br>2）在 Path里面 增加 ：<br>英文的字符<br>;%Java_HOME%\bin;%Java_HOME%\jre\bin<br>一定要记得点确定。还要把cmd给关掉，重新打开 cmd 输入Java、Javac等命令验证<br>（2）考一个jdk安装包，之后再Java_home里面进行更改<br>（3）classpath可以不添加</p><h4 id="6、Java程序的概述">6、Java程序的概述</h4><p>Java程序需要首先完成：<br>（1）Java源文件， .Java 结尾的文件<br>（2）编译生成字节码文件，.class 结尾的文件 很多编码 二进制（16进制）组成的文件<br>（3）将字节码文件 编译器（compiler） JVM能够识别和运行的文件<br>首先编写源文件–》其次通过编译成.class文件–》最后JVM运行</p><h4 id="7、DOS常见的命令">7、DOS常见的命令</h4><p>dir:列出当前目录下的文件及文件夹<br>换盘：直接输入盘符：，例如 切换到D盘 D:<br>cd:换目录 tab键 可以自动补齐。把目录的名字进行补齐<br>md:新建文件目录<br>del:删除文件目录<br>cls:清屏<br>exit：退出<br>上下箭头：可以调用之前输出的命令</p><h4 id="8、第一个Helloworld-Java程序">8、第一个Helloworld Java程序</h4><p>（1）helloworld 的文件名字一定要与 类名（class 后面紧跟的 名字）保持一致<br>（2）设置一下 .Java 源文件编码方式 UTF-8<br>（3）如果设置为 UTF-8 会发现中文输出为乱码，原因是 Java源文件的编码方式与<br>Java编译时的编码方式不一样，造成了乱码</p><h4 id="9、Java注释">9、Java注释</h4><p>单行注释 //<br>多行注释 /**/<br>文档注释 /*/<br>代码注释很重要 因为不止是对别人看你或理解你的代码，而且对你自己也有好处。</p><h4 id="10、Java标识符">10、Java标识符</h4><p>所谓标识符就是对Java当中的 变量、类名、对象名、函数等自己的名字，名字必须得符合规范<br>字母、数字、下划线和美元符号组成</p><h4 id="11、Java关键字">11、Java关键字</h4><p>以Java来编码的 文件 ，蓝色的字符 关键字</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
